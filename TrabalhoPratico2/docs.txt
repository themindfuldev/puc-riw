 Although we believe that progress on scenario development can and will be made, the elements of ‘up-to-date’ economic theory identified as overlooked — “how future societies will operate, how fast the population will grow, and how technological progress will change things” — are either too vague to be meaningful, or are issues the community has been dealing with for years And in no scenario do developing countries become as affluent as industrialized ones Change , in the press. doi: 10.1007/s10584-005-9031-0; see http://www.iiasa.ac.at/Research/PCC/pubs/vanVuurenONeill2006_CC_uncorproof.pdf ) Clim Econ Focusing on a small number of most-likely futures ignores lessons from history: if the world always worked according to best-guess projections, we would now be living with nuclear power too cheap to meter and no ozone hole. Gaskins and J In contrast to the claim that these scenarios are outdated, a recent peer-reviewed assessment has concluded that, with a few notable exceptions, they compare reasonably well to recent data and projections for gross domestic product, population and emissions (D.v.V. and B.ON It is not correct to imply that the scenarios only use market exchange rates, or that they all assume that “the economies of poor countries will quickly catch up with those of rich nations” P P Rev. 83, 318–323; 1993, and J Sir Your Special Report “The costs of global warming” ( Nature 439 , 374 – 375 ; 2006 ) gives an unbalanced picture of the emissions scenarios developed by the Intergovernmental Panel on Climate Change (IPCC) Some scenarios are also reported in terms of purchasing-power parity exchange rates in the original 2000 IPCC Special Report The assumed degree of catching up in the scenarios covers a wide range of possibilities The debate on the emissions impacts of alternative exchange rates in economic modelling is not conclusive, but such impacts are likely to be small compared with the influence of technology, lifestyle and climate policies The Energy Modeling Forum has a 30-year history of model comparisons, exploring the implications for climate policy of a range of rates of economic growth and technological change (D W Weyant Am Weyant Energy Econ. 26, 501–515; 2004)
 A tragic accident And by 1995, I can tell you, I was getting pretty sick of them And it seemed such a good idea at the time But it has a very low infectivity, so it takes a lot of mingling of fluids to spread By 1995 we thought we had a handle on the thing Damn Enough to keep us going until we reach that kinder sun. He grins around at the coven. “Lets thaw one out for her,” he says. “She must be hungry.”  As far as I can see stretch rows and rows of cryonic coffins containing interstellar colonists in what they euphemistically call cold sleep He sips his bloody mary and looks defensive. “It did in a way,” he says. “There are no viruses in your blood.”  That word again Hence the unfortunate impulses I cashed in my six Scottish Widows life insurance policies (lets draw a veil over how I acquired them), signed up for cryonic preservation in the event of my death, and after a discreet ten years, met an unfortunate and bloody end at the hand of the coven senior, Kelvin. “Youll thank me later,” he said, just before he pushed home the point. “See you in the future,” I croaked I feel like saying: Ive only been dead 40 years, for Chr ... for crying out loud I feel somewhat thwarted I hug myself with bare arms, and slide the castored chair back another inch I leave the orientation room, hang around until dusk under the pretext of catching up with the news, and go out and find a vintage clothes shop I look away I remember being naive enough to get excited about mesmerism, galvanism, spiritualism, socialism, Röntgen rays, rationalism, radium, mendelism, Marconi, relativity, feminism, the Russian Revolution, the bomb, nightclubs, feminism (again), Apollo 11, socialism (again), the fall of Saigon and the fall of the Wall I saw the first age of enlightenment I sit up, naked, and bask for a moment I walk out in Victorian widows weeds I worked nights right through the original Industrial Revolution Im only half-listening, being too busy shifting my foot to keep it out of the beam of direct sunlight creeping across the floor, and trying not to look at his neck In all respects but one, its benign: it prevents ageing and stimulates regeneration of any tissue damage short of, well, a stake through the heart It always does It beats time to the artery visible under the tanned skin of the resurrection mans neck It feels like something my skin has missed for centuries Its 2045 and Im still a vampire Its a virus Its taken us a lot of planning, a lot of money, and a lot of lying to get here, but were on our way. “Welcome back,” says Kelvin Kelvins looking down, as I expect Natural selection has worked that one hard New age of enlightenment, new industrial revolution, many changes, take some time to adjust, blah blah blah So dont give me this futureshock shit, sunshine So the nanotech cell-repair just replicates it without a second thought.”  “So were stuck with it,” I say. “Living in the dark and every so often...”  “Not quite,” he says. “Now its been established that cryonics really does work, theres been a whole new interest in a very old idea...”  The coffin lid opens That, and the pavement below the spiked railings beside the steps of my flat The chap from Alcor UK is droning through his orientation lecture The coroner, I just learned, blamed it on the long skirt The last dodgy nostrum I fell for was cryonics The last thing I saw was his grin The most disconcerting thing Ive come across so far in 2045 is the latest ladies fashion: the old sleeveless mini-dress The overhead lights reproduce the spectrum of Alpha Centauri, which is where were going The ozone hole has been fixed, and folk are frolicking in the sun The real shock is the light, full-spectrum and warm The rest of my nature is unregenerate The whole coven is here, all 13 of them, happier and better fed than Ive ever seen them They fit so well I suspect they were once mine. “It didnt work,” I tell Kelvin This is not, this is definitely not, what I died for Thousands of them Under the heel of my left wrist, I feel the thud of my regenerated heart Vampires — always the fashion victims Were in some kind of goth club, which covers for the mode but doesnt improve my mood. “So why do I still feel ... hungry?”  “Have a tapas,” he says. “But seriously ... the way we figure it, the virus has to have transcribed itself into our DNA
 Although the crystal structure of luciferase from the North American firefly ( Photinus pyralis ) has been described , the detailed mechanism for the bioluminescence colour change is still unclear  Comparing these structures to those of the wild-type luciferase complexed with AMP plus oxyluciferin (products) reveals a significant conformational change in the wild-type enzyme but not in the red mutant Fireflies communicate with each other by emitting yellow-green to yellow-orange brilliant light Here we report the crystal structures of wild-type and red mutant (S286N) luciferases from the Japanese Genji-botaru ( Luciola cruciata ) in complex with a high-energy intermediate analogue, 5′- O -[ N -(dehydroluciferyl)-sulfamoyl]adenosine (DLSA) In fact, a single amino acid substitution in luciferase changes the emission colour from yellow-green to red  Our results indicate that the degree of molecular rigidity of the excited state of oxyluciferin, which is controlled by a transient movement of Ile 288, determines the colour of bioluminescence during the emission reaction. The bioluminescence reaction, which uses luciferin, Mg-ATP and molecular oxygen to yield an electronically excited oxyluciferin species, is carried out by the enzyme luciferase The high quantum yield of the luciferin/luciferase reaction and the change in bioluminescence colour caused by subtle structural differences in luciferase have attracted much research interest This conformational change involves movement of the hydrophobic side chain of Ile 288 towards the benzothiazole ring of DLSA Visible light is emitted during relaxation of excited oxyluciferin to its ground state After the N-terminal domain structure model was refined by Refmac5 , the interpretable sigmaA-weighted electron density map of the C-terminal domain was apparent and the C-terminal domain model was added Clusters of crystals appeared after about one week Data collection and structure determination X-ray diffraction data of the LcrLuc(WT)·Mg-ATP complex crystal were collected on an R-AXIS IIc with a Rigaku RU-300 rotating anode at room temperature (about 20 °C) Data collection statistics are shown in Supplementary Table S1  Data were processed with CrystalClear (for the three types of LcrLuc(WT) crystals) or MOSFLM and SCALA (for the LcrLuc(S286N)·DLSA crystal) Electron density maps of the N-terminal domains were obtained (the electron density maps of the C-terminal domains are not shown) Initial phases for the wild-type·Mg-ATP complex structures were obtained by molecular replacement using AMORE , with the N-terminal domain of luciferase from Photinus pyralis as a search model Luciferases (12–17 mg ml -1 ) were incubated at 20 °C for 16 h with ligands under three conditions: (1) 13.3 mM ATP and 26.9 mM MgCl 2 ; (2) 4.8 mM ATP, 1.6 mM d -luciferin and 16 mM MgCl 2 ; (3) 1.59 mM DLSA and 16 mM MgCl 2  Manual model building was performed using TURBO-FRODO  Methods Crystallization Details of mutational analysis, expression and purification are described in the Supplementary Methods  Molecular graphics were illustrated with PyMOL (Figs 2a , b and 3 ). Structure determination and refinement statistics are shown in Supplementary Table S1  The crystals obtained were flash-frozen in liquid nitrogen after soaking in a cryoprotectant solution consisting of the respective reservoir solution with a 2–3% higher PEG4000 concentration plus 20% (v/v) isopropanol, and used for X-ray diffraction experiments The crystals, which belong to space group P 2 1 2 1 2 1 , with unit cell parameters a = 57.8 Å, b = 182.0 Å, c = 53.6 Å, diffracted to 2.3 Å resolution The drop was then equilibrated over 500 µl of reservoir solution at 20 °C The incubated enzyme was filtered, and 3 µl of the filtered enzyme solution was mixed with an equal volume of reservoir solution (0.1 M Tris-chloride (pH 8.0–8.5) or 0.1 M HEPES-Na (pH 7.8), 20–23% PEG4000, 0.2 M lithium chloride, 10 mM 2-mercaptoethanol) to form a hanging drop The overall structure model was refined by Refmac5  The phases of the other complex structures were calculated using the LcrLuc(WT)·Mg-ATP complex structure and these crystallographic protein models were refined by Refmac5 with ARP/wARP automatic model building and water picking The spontaneous crystals were used for microseeding X-ray diffraction data of LcrLuc(WT)·DLSA and LcrLuc(WT)·AMP/oxyluciferin crystals were collected at 90 K with wavelength of 1.02 Å on RIKEN Structural Biology Beamline I (BL45XU) , and LcrLuc(S286N):DLSA crystal was collected at 90 K with wavelength 1.0 Å on RIKEN Structural Biology Beamline II (BL44B2) at SPring-8 A water molecule, Wat 1, is hydrogen-bonded to N3′ of DLSA (2.83 Å) and Ser 349 Oγ (2.70 Å) As a result, the structure of the S286N·DLSA complex near the Ile 288 residue is almost identical to that of the wild-type enzyme bound to AMP and oxyluciferin ( Fig. 3b ) As expected, the I288V and I288A mutants emitted orange- and red-coloured light, respectively, and the extent of the spectral shift correlated with the size and hydrophobicity of the side chain ( Fig. 4a ) As shown in Fig. 3c , the closed form of the active site in the LcrLuc(WT)·DLSA complex allows for close van der Waals contact between three atoms (Cγ1,Cγ2 and Cδ1) of the side chain of Ile 288 and the benzothiazole ring of DLSA, whereas the side chain of Ile 288 in the S286N mutant does not move towards DLSA, creating a less rigid and less hydrophobic microenvironment As shown in Fig. 4b , the wild-type enzyme, the I288A mutant and the S286N mutant gave single emission maxima at 560 nm (yellow-green), 613 nm (red) and 605 nm (red), respectively Assuming that the structures of LcrLuc(WT) in complex with Mg-ATP (reactant), DLSA (high-energy intermediate) and AMP/oxyluciferin (products) represent snapshots along the enzymatic reaction coordinate, differences in the active-site structures around the ligand may reflect catalytically relevant movement of the amino acid residues Closer scrutiny of the emission spectra, however, revealed an interesting finding regarding the excited state Details of active-site residues are shown in Fig. 2c (see also Supplementary Fig DLSA is analogous to 5′- O -[ N -(aminoacyl)-sulfamoyl]adenosine, a potent inhibitor of aminoacyl-tRNA synthetases , and was expected to serve as a stable analogue of the luciferyl adenylate intermediate ( Supplementary Methods ) Finally, the critical role of Ile 288 in the luminescence reaction has not been previously reported, but sequence alignment of a series of luciferases seems to highlight an integral function In contrast, this conformational change is less favourable with the S286N mutant owing to its hydrogen-bonding network around Asn 286, and the conformation of the active site seems to remain in the open form during catalysis In particular, the Cα of Ile 288 is 1.5 Å closer to the DLSA molecule, and the side chain of Ile 288 is also closer to DLSA and is rotated by 131° In the structure of the LcrLuc(WT)·DLSA complex, the DLSA molecule gives a clear electron density in the active site ( Fig. 2b ) Instead, Ser 286 in the DLSA complex forms new hydrogen bonds with Tyr 257 and Asn 231 via a water molecule (Wat 2) ( Fig. 3a ) Luciferases share significant primary sequence similarities with acyl-CoA ligases and nonribosomal peptide synthetases , but not with aminoacyl-tRNA synthetases Most firefly luciferases that emit yellow-green light have an Ile or a Leu residue at this amino acid position, whereas other luciferases that emit differently coloured light do not (see Supplementary Discussion ). Notably, the conformational change observed in the wild-type enzyme was not seen in the S286N mutant On the other hand, two emission maxima (at 560 nm and 613 nm) were observed with the I288V mutant, suggesting that there are at least two different excited states that differ in energy level: one with a higher energy, emitting yellow-green light (560 nm), and the other with a lower energy level, emitting red light (613 nm) S1a ) S1b ) S1b ), but significant differences are observed in the structure of the DLSA complex ( Fig. 3a ) S1c ) The benzothiazole ring of DLSA is in van der Waals contact with the side chains of Phe 249, Thr 253, Ile 288 and Ala 350, and with the main chains of the β13 and β14 strands The bioluminescence reaction catalysed by firefly luciferase proceeds via the initial formation of an enzyme-bound luciferyl adenylate intermediate ( Fig 1a ) The conformations of the dehydroluciferin and sulfamoyladenosine moieties in the DLSA complex are very similar to those of oxyluciferin and AMP, respectively, in the AMP/oxyluciferin complex ( Fig. 3a ), indicating that the intermediate analogue DLSA is a fairly good mimic of oxyluciferin and AMP The crystal structure of the wild-type luciferase from Luciola cruciata (LcrLuc(WT)) complexed with DLSA was determined at 1.3 Å resolution ( Fig. 2a ) by the molecular replacement method using the unliganded crystal structure of luciferase from Photinus pyralis (PpyLuc) (Protein Data Bank accession number 1LCI) as a model  The dehydroluciferin moiety adopts a trans form with a rotational angle of ∼7° with respect to the C2–C2′ bond, and is bound in a hydrophobic pocket consisting of α8 (amino acid residues 248–260), β12 (286–289), β13 (313–316), β14 (339–342), β15 (351–353) and a loop (343–350), while the entrance of the pocket is blocked by the adenosine moiety ( Fig. 2a ) The electronic structures of the excited states, however, have yet to be defined The excited states seem to shift from a higher to a lower energy level as the amino acid residue at position 288 changes from an Ile to Val to Ala (decreasing the size and the hydrophobicity of the side chain) The open form of the active site represents the structure of luciferase in the ground state before and after the reaction, whereas the closed form corresponds to the active form of the enzyme during catalysis The overall structure of LcrLuc(WT) complexed with DLSA consists of a large amino-terminal domain and a small carboxy-terminal domain that are connected by a flexible linker loop (residues 438–442) ( Fig. 2a ) The resulting, less rigid microenvironment allows some energy loss from the excited state, probably due to thermal relaxation or the reorganization of specific interactions, and leads to the emission of low-energy red light (see Supplementary Video S2 ) The single amino acid substitution Ser 286 to Asn changes the colour of the bioluminescence emitted by luciferase from yellow-green to red  The spatial arrangement of the N- and C-terminal domains in the LcrLuc(WT)·DLSA complex structure is different from that in the PpyLuc structure , but is similar to those in nonribosomal peptide synthetases structures (for example, PheA in complex with substrates and DhbE with and without substrates ) The structure of the Mg-ATP complex is essentially the same as that of the AMP/oxyluciferin complex (see Supplementary Fig The structure of the S286N·DLSA complex does not adopt the closed form of the active site: the side chain of Ile 288 does not move closer to the benzothiazole ring of DLSA The thiazole ring is almost coplanar to the benzothiazole ring for both the wild-type and the mutant enzyme, arguing against the view that spectral differences are caused by the rotational angle of the thiazoline/benzothiazole rings of oxyluciferin  The wild-type enzyme changes the conformation of its active site from the open to the closed form as the reaction proceeds to develop the luciferyl·AMP intermediate, and binds the excited state of oxyluciferin tightly in a highly rigid and nonpolar microenvironment created by the hydrophobic side chain of Ile 288, thereby minimizing energy loss before emitting yellow-green light (see Supplementary Video S1 ) The β12 strand in the DLSA complex is much closer to the luciferin-binding site than in the other structures Therefore, the amino acid residue at position 288 directly influences the wavelength of the emitted light Therefore, the conformational change that controls the hydrophobic microenvironment for the excited state of oxyluciferin is a key to understanding the bioluminescence colour Therefore, the wild-type enzyme changes its conformation during catalysis to make an extremely hydrophobic microenvironment for the excited state of oxyluciferin by the transient movement of the side chains of Ile 288 These movements result in a ‘closed form’ of the active site, thereby creating a structure in which the benzothiazole ring of DLSA is tightly sandwiched in a hydrophobic pocket, with the side chains of Ile 288 and Phe 249 on one side and the side chain of Ala 350 and the main chain of Gly 341 on the other This conformational change is also accompanied by rotation of the side chain of Phe 249 by 6° towards DLSA This is in sharp contrast to the structure of the wild-type enzyme in complex with DLSA (see Supplementary Fig This might be due to the Oδ1 and Nδ2 atoms of Asn 286 hydrogen-bonding to Glu 313 and Wat 3, respectively, which seems to prevent a structural change by Ile 288 ( Fig. 3b ) This mode of substrate activation is commonly used by AMP-forming ligases such as aminoacyl-tRNA synthetases , acyl-CoA ligases and nonribosomal peptide synthetases  This movement seems to be linked to the switching of a hydrogen-bonding network involving the side chain of Ser 286: Ser 286 is hydrogen-bonded to Glu 313 in LcrLuc(WT) complexed with AMP plus oxyluciferin, but is no longer hydrogen-bonded to Glu 313 in the structure of the DLSA complex This structure, referred to as the ‘open form’ of the active site, is also observed with the wild-type enzyme in complex with Mg-ATP ( Supplementary Fig To confirm this idea, we prepared the LcrLuc I288V and I288A mutants and examined the differences in their emission spectra We also solved the structures of LcrLuc(WT) in complex with Mg-ATP (reactant) and with AMP and oxyluciferin (products) at 2.3 and 1.6 Å resolution, respectively We synthesized DLSA ( Fig. 1b ) as a ligand for X-ray structural analysis of firefly luciferase, because we assumed that the first half of the reaction catalysed by luciferase is chemically equivalent to that of the amino acylation catalysed by aminoacyl-tRNA synthetases We therefore determined the crystal structure of the red S286N mutant protein, LcrLuc(S286N), in complex with DLSA at 1.45 Å resolution, and compared the structure with the various wild-type enzyme structures
 Acquir Def Despite a rebuttal in Correspondence by the authors of the Ugandan study, Brooks Jackson and Thomas Fleming (“A drug is effective if better than a harmless control”  Nature 434 , 1067 ; 2005 10.1038/4341067a ), Turners letter continues to be cited by AIDS denialists (for example, C Failing to acknowledge this important caveat to the study appears to us to be inconsistent with accepted academic standards. Farber Harpers Magazine 37–52; March 2006) Given that this interruption was sufficiently lengthy for many HIV-positive children and their mothers to die of AIDS in the interim, the surviving sample of the initial cohort cannot be regarded as representative He points out that HIV transmission in people taking the antiretroviral drug nevirapine was 13.1% in the HIVNET 012 study in Uganda, whereas only 12% of women in a Rwandan study were found to have transmitted HIV to their babies in the absence of antiretroviral treatment Hum Immun J Ladner et al  Of the children born to HIV-positive mothers, 158 were tested for HIV and 19 (12%, as Turner states) were found to be HIV-positive Retrovirol. 18 , 293–298; 1998) Sir Valendar Turner, in Correspondence (“HIV drug remains unproven without placebo trial”  Nature 435 , 137 ; 2005 10.1038/435137a ), argues that there is no evidence for antiretrovirals reducing the transmission of HIV from mother to child Syndr The actual figure for HIV transmission was almost certainly much higher The Rwandan study referred to by Turner enrolled 561 pregnant women, of whom 286 were HIV-positive Why were only 158 children assessed? The answer, conveniently ignored by the denialists, is that follow-up was interrupted by the events of the Rwandan civil war (J
 A patient is currently classed as vegetative if there are no outward signs of genuine awareness, rather than simple reflex responses to stimuli such as pain As the patient has reportedly improved since the study was carried out, it is entirely possible that the brain scans simply reflected early signs of her recovery But although this patient remained inscrutable throughout the study, her brain scans suggested she was picturing herself scampering across a tennis court, or roaming around her home But the ultimate impact of this discovery will hinge on whether more patients are found to have this sort of inner responsiveness But when considering those at the less severe end of the spectrum, such as the British patient at the heart of the latest research, the new discovery presents a conundrum But with brain scanning of vegetative patients becoming more common (although far from routine), the medical criteria for diagnosing a vegetative condition will have to be scrutinized Clearly, for those with the bleakest prognosis — those who have shown no improvement over a period of at least 12 months and are categorized as being in a permanent vegetative state — the chances of finding any sign of awareness are negligible Clinical neuroscientists should stress that no two vegetative patients are alike, and that this remarkable case may be a one-off If such rich internal mental processes are seen in other outwardly vegetative patients, then clinicians should revise their opinion on whether or not these patients are really vegetative at all In the wake of the latest research (A It also means that neuroscientists have some serious thinking to do Loved ones of similar patients will clamour for a chance to see whether they, too, are capable of similar feats M Owens et al  Replacing it with the term outwardly unresponsive would help to eliminate any confusion over whether internal awareness should be factored into a diagnosis Science 313 , 1402; 2006), the inevitable calls for all vegetative patients to be considered internally conscious should not be heeded Some clinicians take issue with the use of the word vegetative and the unpleasant imagery it evokes The evaluation of vegetative states, in which patients are often awake but show no outward sign that they are aware of themselves or their environment, has always been difficult, simply because of the huge variability in the nature and severity of the brain injuries that underpin them The news that a patient in a vegetative state has shown signs of awareness of the outside world, and an ability to perform mental tasks on request (see page 132 ), marks a turning point in the investigation of these enigmatic medical conditions Then, the issue of what constitutes consciousness in these patients — a question that transcends mere brain imaging — will come alive. This case has little bearing on ethical questions over whether or not the most severe cases should be denied treatment and allowed to die Unique or not, the discovery blurs the distinction between a vegetative patient and those classed as minimally conscious — showing limited or intermittent interaction with their surroundings What is often so heartbreaking for friends and relatives is that the patients mental quality of life is unknowable
 Alexander Hutko and his colleagues at the University of California, Santa Cruz, solved the problem by tracking the energy waves triggered by earthquakes By putting several slices next to one another, the team built up a three-dimensional picture. “It is amazing to go from simple records of the ground moving side-to-side to getting snapshots of the middle of the Earth,” Hutko says Earth is divided broadly into three components: the crust, mantle and core From these numbers, they were able to create two-dimensional images corresponding to slices of the deep Earth He now plans to travel to Japan to collect and analyse data beneath the western Pacific Ocean. “It is an exciting prospect as this region has one of the densest high-quality networks of recording stations in the world Hutko and his team fed the data into a computer program that “spits out a bunch of numbers”, he explains Hutko and his team were interested in what happens to slabs of the lithosphere that are driven deeper into the Earth when the tectonic plates bump into one another Investigating the various geophysical events that occur deep inside our planet is no easy task Researchers are particularly interested in what is happening some 3,000 kilometres below the surface, but getting a clear picture of these processes requires more than a little ingenuity The crust and the upper part of the mantle together make up a region known as the lithosphere: broadly speaking the part of Earth that forms the tectonic plates The earthquake data, which had been collected since 1991, were analysed using techniques developed by the oil-exploration industry about two decades ago to get detailed pictures of structures just below Earths surface. “We have only recently had enough data to achieve this kind of resolution,” says Hutko The results, detailed on page 333 , offer a three-dimensional picture of events occurring near Earths core The sheer volume of data is amazing,” he says. The team found that slabs of Earths lithosphere, once part of the ocean floor, had sunk all the way down to the boundary between the core and the mantle. “Others had suspected that the base of the mantle was a graveyard of slabs, but no one knew how deep they went,” notes Hutko The team homed in on a region in the Pacific Ocean off the west coast of Central America, situated between an earthquake-prone area of South America and a dense network of recording stations in the western United States These plates ‘float’ on the rest of the mantle, which allows them some degree of movement — earthquakes occur when these plates grind against one another To find out, the researchers began by analysing how seismic waves bounce off different layers and structures inside the planet. “A simple way to think about this is as if you were standing on a shore and someone on the opposite side throws a stone, and you observe the waves to determine where the stone landed,” says Hutko
 A recently published European study on mobility in the scientific labour market showed that, of those scientists in a relationship, some 70% had chosen another scientist as their partner (L Ackers Womens Stud After 65 applications and 13 interviews, they ended up with a short-list of four places in the United States, all of which proposed solutions for Kelly. “I only brought up the issue of my partner when they started to show serious interest,” stresses Kortemme, highlighting the importance to many researchers of being taken on independently After six months looking in the biggest US and European universities, Sabio found a postdoc position at the University of Massachusetts Although their research increasingly coincided, they had to work especially hard to match up their workplaces As a masters student in 1996, Canadian Karen McCoy attended a conference in Cincinnati to look for a PhD project, not a future husband As a senior scientist married to an accelerator physicist, Persis Drell, director of research at the Stanford Linear Accelerator Center in California, is often asked by young researchers for advice on decision-making in such cases. “I tell them that its fine to choose a solution where both partners are happy — or even where both are not happy — but not where only one partner is happy As they were spending too much time apart, the couple decided to change strategy, says Mora Biologists Tanja Kortemme from Germany and Mark Kelly from Britain met at the European Molecular Biology Laboratory in Heidelberg, Germany Boulinier moved from the United States to Oslo and then to a permanent position at Pierre and Marie Curie University in Paris But at earlier career stages, the premium placed on international mobility and the prevalence of fixed-term contracts mean that many couples are forced to spend time — often years — living in different cities or even different countries But when McCoy started applying for tenure positions in France she received comments that she was not independent enough in her research. “Its a small world,” says McCoy. “People knew we were together and thought that was the only reason we were co-authoring.”  Last summer, just before the birth of their first child, McCoy was offered an attractive tenured position at the University of Victoria in Canada, but with no chance of a position there for Boulinier, she was torn By the time Kortemme left for a postdoc at the University of Washington in Seattle, Kelly had already joined an institute in Berlin, and later moved across to a biotech company in San Diego. “All our decisions on moving were based on where we wanted to do research,” says Kortemme Circumstances taught one couple that a long-distance marriage just wasnt worth the heartache During this time, the couple began co-authoring papers Eventually, on the verge of accepting the Canadian offer, she was offered a tenure-track post in Montpellier, France, and Boulinier transferred there from Paris. “Now at last we can do some long-term planning in our research and get organized again For couples working in the same research area, proximity can be a double-edged sword For these couples, maintaining a healthy life–work balance while making career progress means taking difficult decisions and establishing priorities Forum 27, 189–201; 2004) He and Kortemme are now enjoying their respective positions as adjunct and assistant professors at the University of California, San Francisco — and the novelty of a first year living together after seven years apart He was interested in the ecology of seabirds — a perfect model system for McCoys study of host–parasite evolution I dont know how much longer I could have held out,” says McCoy If that means spending some time apart working in labs in different cities it is worth considering If this months Valentines card gets delivered in the post rather than by hand, its likely that you are one of the thousands of scientists who has chosen, for better or worse, to live far apart from your loved one to pursue your career In their first six months, they spent just one week together — and that was at a scientific conference in Luxembourg Int It just puts too much stress on the relationship,” says Drell, who received an offer for her husband as well as herself when she moved from Cornell to Stanford in 2002 (see Naturejobs 62; 28 March 2002 ) Its not worth the heartache of staying apart,” he advises Meanwhile McCoy managed a few months with him in Norway, then joined him at Pierre and Marie Curie University Only when she had made the first contact did her husband start contacting groups in the same region. “We changed research priorities slightly to make it fit, but if you are flexible you can find something Other couples say that a little heartache early on is worth it in the long term Other studies in the United States have identified similar levels of relationships between scientists Plotting a Course There are three basic options for scientific couples Researchers applying for tenured positions, especially in the United States, are increasingly likely to receive help in finding positions for their partners through university dual-career programmes (see ‘Dual assistance’ ) Sabio continued working on her PhD in Spain Sabio transferred to Dundee to continue her PhD, while Mora extended his postdoc so that they could finish together She found both in Thierry Boulinier, a French postdoc working in the United States on the dynamics of animal communities So why not take the chance, among the tacky pinkness of Valentines Day, to have that conversation, and decide when and where to make the move? Soon after Spanish biochemists Alfonso Mora and Guadalupe Sabio got married, Mora took up his first postdoc at the University of Dundee in Scotland The big decision to move somewhere together came when Kortemme started looking for a tenure-track position The next challenge was to find two postdocs in the same location The rigours of scientific life mean that most researchers end up hitched to one of their own clan, creating a ‘two-body problem’ Their relationship, and their research interests, evolved during a field trip to eastern Canada the following summer There she did her PhD in three years, followed by a one-year postdoc, before returning to Canada as a postdoc at Queens University They can try to stick together early on, which might limit their job options; they can each take the best positions available and potentially live far apart; or they can live apart in the early stages of their career, and hope for joint offers once they are more established They managed to see each other for two or three days every month via transatlantic, then transborder, commuting Things are changing for the better, according to Drell We thought that the trade-off would be worth it in the end and I know both of us feel it was,” says Kelly Worthwhile Sacrifice “Our advice is for both parties to try to do the best science they can at the postdoc level
 Analysis of the basicranium further indicates that S. tchadensis might have been an upright biped, suggesting that bipedalism was present in the earliest known hominids, and probably arose soon after the divergence of the chimpanzee and human lineages. Here we present a detailed virtual reconstruction of the TM 266 cranium that corrects these distortions Of this material, the cranium is especially important for testing hypotheses about the systematics and behavioural characteristics of this species, but is partly distorted from fracturing, displacement and plastic deformation Previous research in Chad at the Toros-Menalla 266 fossiliferous locality (about 7 million years old) uncovered a nearly complete cranium (TM 266-01-60-1), three mandibular fragments and several isolated teeth attributed to Sahelanthropus tchadensis  The reconstruction confirms that S. tchadensis is a hominid and is not more closely related to the African great apes  All primate specimens are from the A Differences between the four reconstructions, as visualized in shape space, are comparatively small ( Fig. 3a–c ) and reflect inter-observer and inter-protocol disparity Figure 2 shows the final result, obtained by averaging all four reconstructions First, the basioccipital was positioned and oriented in the midsagittal plane Geometric morphometric analysis The analysis included adult crania of 16 G. gorilla (9 males, 7 females), 20 P. troglodytes (10 males, 10 females), 7 P. paniscus (4 males, 3 females) and 8 fossil hominids (casts of ER1813, ER1470, ER3733, KNM-WT 15000, STS5, OH5, ER406 and virtual reconstruction of AL444-2) H In addition, the lower face and orbital margins are shifted left and superiorly relative to the supraorbital torus and zygomatic processes of the frontal ( Fig. 1c ), the basioccipital is shifted towards the left petrosal ( Fig. 1b ), and the right posterior cranial vault and nuchal plane overlay the left side ( Fig. 1a , b ), altering the true orientation of the nuchal plane in the sagittal plane (see figure 1b in ref. 1 ) In both protocols, the face and the braincase were reconstructed independently and then assembled by using anatomical continuities within the squamous portions of the frontal; along preserved continuities between the basisphenoid, the pterygoid processes and the right side maxillary tuberosity; and between the bones of the right temporal fossa (squamous sphenoid, zygomatic, maxilla and frontal) Last, deviations from bilateral symmetry in the maxilla were partly corrected as in protocol A Lateral and superior parts of the vault were adjoined by using the well-preserved temporal lines to establish bilateral symmetry Left–right asymmetry in the maxilla from plastic taphonomic deformation was partly corrected with the use of published methods  Major variations concern maxillary width measured at M 2 (± 0.9 mm); foramen magnum height relative to porion (± 1.1 mm); and facial orientation relative to the braincase, as measured by the angle between nasion–basion and nasion–prosthion (± 2.3°) Methods Data acquisition and state of preservation The TM 266-01-60-1 original was scanned with an Industrial Systems CT scanner (tube voltage 450 kV, tube current 5 mA, beam collimation 0.4 mm, interslice distance 0.4 mm, pixel size 0.2 mm × 0.2 mm, pixel depth 16 bits) Midsagittal landmarks used were nasion, glabella, bregma, lambda, inion, opisthion, basion, sphenobasion, staphylion, prosthion and nasospinale; paired landmarks (left and right sides taken when possible) were maxillofrontale, supraorbitale, orbitale, frontomalare orbitale, zygomaxillare, jugale, foramen infraorbitale, M 2 most buccal point, foramen stylomastoideum, foramen caroticum, foramen ovale, asterion, porion and pterion. Once partitioned, isolated fragments were repositioned and reoriented in virtual space to restore morphological continuity along fractures, sutures and other anatomical features within and between bones Protocol A used features shared by all mammal crania to position and orient each fragment Protocol B used a geometric approach based on stepwise reduction of degrees of freedom of the position and orientation of individual parts relative to each other Rotational degrees of freedom between adjacent fragments were then reduced by stepwise integration of fragments into the reconstruction, followed by iterative adjustments until a symmetrical integrated morphology was achieved Schultz Collection, University of Zurich, the Peabody Museum, Harvard University, and the Royal Africa Museum, Tervuren The cranium was independently reconstructed four times by two of us (M.S.P.L. and C.P.E.Z.), each using two different protocols The exposed borders of parts of the cranial vault and palate are partly eroded; the mastoids and petrosal portions of the temporal bones also suffered some surface damage but are undistorted, as evinced by the mirror-symmetric position of the well-preserved left and right inner ear cavities relative to features such as the external acoustic meatus and the stylomastoid foramen The left temporal fossa is partly missing, but corresponding structures on the right side are well preserved The temporals were then adjoined from both sides and aligned by placing all of the left and right semicircular canals in approximately parallel orientation  The virtual cranium was disassembled along major cracks, and matrix filling was removed from endocranial and paranasal cavities with the use of interactive data segmentation tools  These procedures were applied to orient left and right neurobasicranial sides relative to each other, and the maxillae relative to the midface This method takes advantage of the almost complete preservation of the TM 266 cranium, in which the position and orientation of each fragment is spatially constrained by contacts with all neighbouring fragments, and overall morphology is constrained by bilateral symmetry Translational degrees of freedom were first reduced by re-establishing morphological continuity between dislocated fragments along matching fracture lines (along the nuchal plane, along cracks in the right parietal, between parts of the supraorbital torus, and between dislocated parts of the midface) Virtual separation of cranial fragments revealed substantial overlap between right and left sides of the cranium from post-mortem compression, causing an elongated appearance of the vault in superior view (see figure 1c in ref. 1 ) Virtual three-dimensional reconstruction The reconstruction of the cranium followed established methods  Within the face, displaced but undistorted portions of the supraorbital torus and orbital margins were repositioned symmetrically relative to the midsagittal plane A high-resolution computed tomography scan was used to create a digital representation of the TM 266 cranium that was disassembled along major cracks, cleaned of adhering matrix with the use of digital filtering, and then reconstructed virtually with two different established protocols (see Methods) Although increases in brain volume relative to cranial base length have been implicated in horizontal rotation of the posterior cranial base , such an explanation is unlikely for the TM 266 cranium whose estimated endocranial volume, 360–370 ml, is the smallest yet documented for an adult hominid but is within the range in chimpanzees  Although the cranial morphology of TM 266-01-60-1 cannot be reconstructed to fall within the size–shape space of known African ape morphologies, it is within the size–shape space defined by other Pliocene hominids Anatomical continuity in the basicranium extends from the basisphenoid to the nuchal plane and within each of the cranial units delimited by major cracks, as evident from matching fracture lines between adjacent parts Another related indication of bipedality in S. tchadensis is the flat nuchal plane oriented at about 36° relative to the Frankfurt Horizontal, well within the range of Australopithecus and Homo but not Pan  As a third test, the TM 266 reconstruction was compared with three-dimensional shape variability in a comparative African ape/fossil hominid sample (see Methods) Despite substantial differences in neck orientation, humans and non-human primates tend to locomote with their orbital planes (the line joining the superior and inferior margins of the orbits) approximately perpendicular to the ground  Figure 3a–c shows this procedure for the first three PCs, which account for more than 58% of the total shape variability Finally, the TM 266 reconstruction permits an assessment of the hypothesis that Sahelanthropus was a biped, an important feature of Pliocene hominids and possibly several Late Miocene hominids  First, the face and neurobasicranial complex, which were reconstructed separately, fitted together at multiple points in an approximately coronal plane along the superior and lateral margins of the post-orbital region However, anatomical continuity is well preserved in the sagittal and parasagittal planes, particularly between the face, the neurocranium and the basicranium However, postcranial evidence will be necessary to test more rigorously the hypothesis that S. tchadensis —the earliest known hominid, found 2,600 km west of the East African rift valley—was a biped. However, several features differ notably from those of the original specimen: the cranium as a whole is wider, the occipital contour is rounder sagittally, the nuchal plane is oriented more horizontally, the orbits are larger and more circular, and the face is superoinferiorly taller (additional standard craniometric measurements are provided in Supplementary Table 1 ) In addition, primates orient the upper cervical vertebrae approximately perpendicular to the plane of the foramen magnum, and with only a limited range (about 10°) of flexion and extension possible at the cranio-cervical joint  In addition, the nuchal crest of the TM 266 cranium has downward lipping, a feature present in other bipedal hominids (for example AL 444-2, OH 5) but not in Pan or Gorilla  In all mammals including primates, the posterior maxillary (PM) plane is approximately perpendicular relative to the neutral horizontal axis (NHA) of the orbits  In the TM 266 reconstruction, this plane is about 89° relative to the NHA (estimated from the orbital margins and the partly preserved medial walls) Plastic deformation resulting in left–right asymmetry is noticeable in the maxilla PM orientation was estimated by a plane that passes, in lateral projection, from the maxillary tuberosities through the pterygopalatine fossae  Primary distortion in TM 266-01-60-1 results from morphological discontinuities along major cracks between the left and right sides of the face, between the supraorbital torus and the zygomatics, between the left and right posterior cranial vault including the nuchal plane and basioccipital, and along a coronally oriented crack between left frontal and temporoparietal portions of the vault ( Fig. 1 ; also see Fig. 1 in ref. 1 ) Second, the reconstructed morphology was assessed a posteriori against an anatomical constraint not considered during the virtual reconstruction The changes evident in the TM 266 reconstruction highlight its unique morphology and confirm several derived features shared with later hominids such as a relatively vertical face with an anteroposteriorly short premaxilla; an anteriorly-positioned foramen magnum linked to a relatively short basioccipital; a relatively flat, large, and horizontally-oriented nuchal plane; and downward lipping of the nuchal crest  The combined effect of these angular constraints is that the angle between the foramen magnum and the orbital plane ( Fig. 4 ) is nearly perpendicular in Homo sapiens (103.2 ± 6.9°, n = 23) but more acutely angled in Pan troglodytes (63.7 ± 6.2°, n = 20), and other species with more pronograde postures The foramen magnum angle relative to the orbital plane in the TM 266 reconstruction is 95°, similar to that in humans and later bipedal hominids such as Australopithecus afarensis (AL 444-2) and A. africanus (Sts 5)  The fossil is barely affected by expanding matrix distortion , and no missing regions need to be estimated to reconstruct its original form The isolated fragments of the TM 266 cranium were then positioned to fit the calculated three-dimensional landmark configurations of the closest-possible Pan and Gorilla shapes ( Fig. 3e ) The reconstruction in Fig. 2 is therefore a robust estimate of the cranial form of TM 266-01-60-1 that supports most of the details originally described  The reconstruction, illustrated in Fig. 2 , was evaluated with three independent tests The resulting ‘ Pan -like’ and ‘ Gorilla -like’ morphologies are anatomically infeasible, involving overlap between neurocranial fragments and disruption of anatomical continuity between neighbouring facial fragments These features, together with other dental features (see refs 1 , 2 ), support the conclusion that Sahelanthropus is a hominid ( contra Wolpoff et al. ) TM 266-01-60-1 as a quadruped would require an unusually extended angle of the neck relative to the plane of the foramen magnum To account for allometric shape effects, all shape PCs were regressed against centroid size to obtain a common allometric shape score ( Fig. 3d ) Unequivocal evidence for bipedalism is difficult to obtain from the cranium, but several lines of evidence suggest that TM 266-01-60-1 might have been bipedal urations of all specimens and calculated the minimum form change necessary to transform the TM 266 reconstruction to the closest possible hypothetical Pan and Gorilla cranial forms with the use of the 99% probability density borders as a minimum-distance criterion ( Fig. 3 )
 Heterologously expressed melanopsin apparently binds retinaldehyde and mediates photic activation of G proteins  However, its amino-acid sequence differs from vertebrate photosensory opsins and some have suggested that melanopsin may be a photoisomerase, providing retinoid chromophore to an unidentified opsin  Light triggered a membrane depolarization in these cells and increased intracellular calcium Melanopsin has been proposed to be the photopigment of the intrinsically photosensitive retinal ganglion cells (ipRGCs) ; these photoreceptors of the mammalian eye drive circadian and pupillary adjustments through direct projections to the brain  Melanopsin is required for ipRGC photosensitivity and for behavioural photoresponses that survive disrupted rod and cone function  The light response resembled that of ipRGCs, with almost identical spectral sensitivity ( λ max ≈ 479 nm) The phototransduction pathway included Gq or a related G protein, phospholipase C and TRPC3 channels Their action spectrum ( λ max ≈ 480 nm) implicates an opsin and melanopsin is the only opsin known to exist in these cells To determine whether melanopsin is a functional sensory photopigment, here we transiently expressed it in HEK293 cells that stably expressed TRPC3 channels We conclude that mammalian melanopsin is a functional sensory photopigment, that it is the photopigment of ganglion-cell photoreceptors, and that these photoreceptors may use an invertebrate-like phototransduction cascade. Although incubated in darkness, cells were exposed to normal laboratory lighting during preparation for recording except in spectral studies, which were conducted in darkness Calcium imaging Cells loaded with the long-wavelength Ca 2+ indicator Rhod-2-AM (4–6 µM in Tyrodes, 30 min, 37 °C) were imaged at 30 Hz using green excitation (525–550 nm; emission 580–650 nm; Chroma 31002a ) attenuated 128- to 512-fold by neutral density filters Cells were transfected with the calcium phosphate method and seeded on coverslips Cells were visualized with a 40 × water-immersion objective on an upright epifluorescence microscope equipped with a cooled charge-coupled device (CCD) camera, integrating frame grabbers and video monitor Current injection held cells near -44 mV Each response to one of these other wavelengths yielded an estimate of relative sensitivity normalized to that at 480 nm (see Fig. 4a ), and these were averaged for each wavelength Electrophysiology Cells transfected 1–2 days earlier were mounted in a chamber perfused with Tyrodes solution containing no retinaldehyde (1–2 ml min -1 , 21 °C) Evoked currents or voltages are baseline-subtracted Except for brief blue epifluorescence to identify EGFP-positive cells ( Chroma no. 41001 ), only infrared light was used to view cells Expression vector sequences were confirmed by dideoxy terminator sequencing For each cell, we determined the retinaldehyde template function that best fitted these data (least-squares method) For spectral analysis, the culture medium contained 11- cis -retinaldehyde From transfection until recording, cells were provided with retinaldehyde (0.5 µM 11- cis -retinaldehyde for spectral studies, 2 µM all- trans -retinaldehyde for all other experiments) and were kept in darkness, except for brief exposures to laboratory lighting Further methodological details are provided in the Supplementary Methods . In darkness, most cells had series resistance 10 MΩ, V m ≈ - 35 to -45 mV and input resistance of 0.5–1.5 GΩ Integration time was fixed within trials (typically 32 frames) to optimize sensitivity and avoid saturation Liquid junction potentials (- 14 mV) were corrected Melanopsin immunohistochemistry Cells were fixed overnight (4% paraformaldehyde in phosphate-buffered saline, PBS), incubated in polyclonal rabbit anti-melanopsin antiserum (UF006, ref. 7 , 1:2,500; 24 h, 4 °C), then in Cy-3-conjugated anti-rabbit IgG (1:500; Jackson ImmunoResearch ; 1 h; 21 °C) Methods Cell culture and melanopsin expression Cells were cultured conventionally Micropipettes (3–5 MΩ) contained 120 mM K-gluconate, 5 mM NaCl, 4 mM KCl, 0.5–2 mM EGTA, 10 mM HEPES, 0.5–4 mM ATP-Mg, 7 mM phosphocreatine, 0.05–0.3 mM GTP-Tris; (280–300 mOsm, pH 7.3) Omitting these retinoids did not preclude photosensitivity (see Supplementary Data ) PCR primers were generated from the melanopsin sequence with restriction enzyme sequences appended to the 5′ end to facilitate directional cloning PCR products were digested with restriction enzymes and ligated into the multiple cloning site of the vectors, also digested with restriction enzymes Photic stimulation and spectral analysis Light stimuli from a 100-W tungsten source were filtered (neutral density and narrow-band interference filters ;10 nm width; Oriel ), gated by a shutter ( Uniblitz VS35 ;Vincent Associates) and calibrated by a radiometer (S370 , UDT Instruments ) Photomicrographs were obtained on a Zeiss Pascal confocal microscope using a 40 × objective Rasband; http://rsb.info.nih.gov/ij/ ; 2004), were expressed as post-stimulus change in fluorescence intensity above baseline divided by the baseline intensity (Δ F / F ) Relative sensitivities were then re-normalized to that at the theoretical optimum ( λ max ) Responses, analysed by ImageJ software (W Stable sensitivity, confirmed by retesting with a standard stimulus, required long interstimulus intervals (7 min) Stimuli of 480 nm were interleaved with those of two to three other wavelengths (420, 440, 540, 570 or 600 nm) The irradiance of the unfiltered (‘white’) stimulus was (in photons s -1  cm -2 ): 4 × 10 12 at 400 nm, 6 × 10 13 at 500 nm and 1 × 10 14 at 600 nm The mouse melanopsin ( Opn4 ) open reading frame (GenBank accession number NM_013887) was amplified by polymerase chain reaction (PCR) from a vector containing the open reading frame The two free parameters for the fit were λ max and the vertical offset Two different PCR products were generated for two expression vectors: the plasmid pcDNA 3.1(+ ) ( Invitrogen ) and the bicistronic pIRES2–EGFP ( BD Biosciences ) Whole-cell patch recordings were made conventionally Although there was no retinaldehyde in the bath, responsiveness persisted for hours An inactive analogue of the PLC antagonist (U73343; n = 3; Supplementary Fig. 2a ) and pertussis toxin (a Gi inactivator; 250 ng ml -1 , 2 h) were ineffective By demonstrating that melanopsin is activated maximally near 480 nm and can indirectly gate cation channels in the plasma membrane, our findings provide nearly all of the missing links in the chain of evidence for melanopsin as the photopigment of ipRGCs  Calcium responses were also detectable in melanopsin-transfected cells lacking the EGFP reporter ( Supplementary Fig. 1 ) Drosophila photoreceptors apparently use a similar phototransduction cascade , but it is not yet known whether ipRGCs use (or even express) these specific downstream components Gq or a related protein seems most likely to be the cognate G protein for melanopsin HEK293-TRPC3 cells transfected with this vector faithfully co-expressed the enhanced green fluorescent protein (EGFP) reporter protein ( Fig. 1a , c ) and mouse melanopsin ( Fig. 1b , c ) Heterologously expressed melanopsin reportedly mediates photic activation of a G protein , again supporting a photosensory role If melanopsin instead dissociates from its chromophore like other vertebrate photopigments, its regeneration in HEK293 cells may be attributable to the intrinsic retinoid processing capacity of these cells  In bistable invertebrate photopigments, the chromophore–opsin linkage is non-dissociating and light can trigger photoreversal of metarhodopsin to rhodopsin In HEK293-TRPC3 cells, the G protein activated by melanopsin stimulates PLC to open TRPC3 channels and depolarize the plasma membrane  In HEK293-TRPC3 cells, this cascade involves Gq or a related pertussis toxin-insensitive G protein In photoreceptors using bistable pigments, appropriate narrow-band stimuli can terminate persistent post-stimulus responses and augment sensitivity to subsequent stimuli by converting metarhodopsin to rhodopsin Increasing stimulus irradiance augmented response amplitude ( Fig. 1e ; see also Fig. 4a ) and decreased onset latency from 10 s to a minimum of ∼500 ms Introducing melanopsin into HEK293-TRPC3 cells transformed them into photoreceptors It seems probable that some of these properties, like the spectral tuning, derive from features of melanopsin itself, while others are shaped by the downstream signalling cascade Its overexpression increases photosensitivity in dermal melanophores , and its deletion abolishes the light response in ganglion-cell photoreceptors  Light also triggered increases in intracellular free calcium in these cells Light responses were never observed among neighbouring untransfected, EGFP-negative cells ( n = 11), nor in cells transiently transfected with empty pIRES2–EGFP, which expressed EGFP but not melanopsin ( n = 10; Fig. 1f ) Light-evoked depolarizations were reduced by more than half their initial amplitude within 30 min ( Fig. 3a ; in 3 of 4 cells tested) Light-evoked inward currents were never observed in untransfected cells ( Fig. 1h , bottom) or in cells expressing EGFP but not melanopsin Many of these cells were photosensitive Maximal responses were typically 15 mV Maximal white-light stimuli evoked peak inward currents averaging 30 pA (± 13 pA standard deviation, s.d.; n = 5; V hold ≈ - 44 mV) Mean estimates of relative sensitivity at each tested wavelength ( Fig. 4b , points) adhered closely to the best-fitting retinaldehyde template function ( Fig. 4b , curve), supporting the assumption that the action spectrum in this system adheres to the standard form for opsin-mediated responses Melanopsin is an opsin, with the canonical retinaldehyde binding site , and most cells expressing it are known or presumed to be directly photosensitive  Melanopsin is presumably the photopigment in these cells because it was required for the observed photosensitivity Melanopsin was localized predominantly in the cell membrane ( Fig. 1b ), as it is in ipRGCs  Note added in proof: While in proof we became aware of three other papers to be published that concurrently support our conclusion that melanopsin is a functional photopigment, signalling through G proteins . Only transfected cells exhibited light-evoked increases in fluorescence of the calcium indicator Rhod-2-AM ( Fig. 2 ) Our findings contradict the idea that melanopsin could be exclusively a photoisomerase instead of a photosensory pigment  Relative sensitivity at different wavelengths was assessed for individual cells as shown in Fig. 4a  Some G-protein-coupled receptors (GPCRs) couple promiscuously to multiple G-protein families and melanopsin itself reportedly interacts with highly concentrated rod transducin (Gt) in a biochemical assay  Still, there is no direct evidence that melanopsin is bistable Such correspondence was lacking in an earlier study of heterologously expressed melanopsin, which reported maximal absorption at 421 nm (ref. 20 ) Support for possible melanopsin bistability comes from its invertebrate-like aromatic amino acid at the ‘counter-ion’ position , a key determinant of chromophore binding, and, as shown here, the persistence for hours of melanopsin-based light responses without supplementary retinaldehyde despite repeated exposure to bright illumination The action spectrum of the induced photoresponse peaked at 479 nm, closely matching the spectral tuning of isolated rat ipRGCs ( λ max ≈ 484 nm) and of melanopsin-dependent behavioural light responses of rodless/coneless rodents (pupillary light reflex: λ max ≈ 479 nm, ref. 16 ; circadian phase shifting: λ max ≈ 480–481 nm, refs 17 and 26 ) The discrepancy with our spectral results could stem from the earlier studys use of a different expression system, protein modifications for epitope tagging, effects of opsin solubilization and immunopurification, or the use of chemical rather than photic bleaching to generate the difference spectrum The light response was effectively abolished within 20 min by internal application of GPant-2a, a competitive inhibitor of Gq, and was suppressed 75–100% by bath-application of U73122, an antagonist of phospholipase C (PLC; n = 3; Fig. 3c ), the effector enzyme for Gq-like G proteins  The mouse melanopsin open reading frame was cloned into a bicistronic expression vector (pIRES2–EGFP) The optimal wavelength ( λ max ) for each cell was estimated from the best-fitting retinaldehyde template function (see Methods) There are striking similarities between the photoresponses of melanopsin-expressing HEK293 cells and those of ipRGCs including response polarity, low sensitivity, sluggish onset, tonic response to continuous illumination, and slow post-stimulus recovery These values, plotted in the histogram of Fig. 4b , had a mean value of 479.2 nm (± 1.5 nm s.e.m.; n = 12), very close to the optimal wavelength for isolated rat ipRGCs (484 nm) They exhibited large light-evoked changes in transmembrane voltage that were sluggish and sustained ( Figs 1d , e ) This study provides the first direct physiological evidence that melanopsin is a functional sensory photopigment and that it can activate a signalling cascade that gates an ionic conductance This was a specific effect, not an artefact of cell dialysis, because cells recorded with the control internal solution maintained stable response amplitudes for ≥70 min (data not shown) Though melanopsin is now firmly established as a photosensory pigment, it may also possess photoisomerase activity Thresholds were approximately (5.6 ± 1.7) × 10 12  photons s -1  cm -2 at 480 nm (mean ± standard error of the mean, s.e.m.; n = 12), about one log unit higher than for ipRGCs  To test melanopsins capacity to form a functional sensory photopigment, we heterologously expressed mouse melanopsin ( Opn4 ) complementary DNA in human embryonic kidney cells (HEK293) stably expressing TRPC3 receptor-operated non-specific cation channels  To test the hypothesis that melanopsin, like other opsin photopigments, triggers a G-protein signalling cascade, we infused guanosine 5′-O-(2-thiodiphosphate) (GDPβS) TRPC3 channels apparently carry the light-activated current in these cells (see Supplementary Data and Supplementary Figs 2b and c ) Under physiological conditions, however, most GPCRs couple mainly to only one of the four G-protein families , so the cognate G protein for melanopsin in ganglion cells is probably a member of the Gq family (Gq, G11, G14, G15 and/or G16) We have not detected such behaviour in transfected HEK293-TRPC3 cells (see Supplementary Data ) With voltage clamped at negative potentials, light triggered an inward current ( Fig. 1g ) exhibiting strong outward rectification and reversing near 0 mV (4.0 ± 3.8 mV, mean ± s.e.m., n = 9; Fig. 1h )
 A pathogenic chytrid fungus, Batrachochytrium dendrobatidis , is implicated as the primary cause of Atelopus population crashes and species extinctions  According to the Global Amphibian Assessment (GAA) , around a third of amphibian species (1,856) are classified globally as ‘threatened’ Although the little-known Batrachochytrium fungus was proposed to be potentially the sole reason for declines in amphibian populations in the tropics , no one had come up with an explanation for the sudden emergence of this pathogen As global change is occurring at an unprecedented pace, we should expect many other host taxa, from ants to zebras, to be confronted with challenges similar to those faced by Atelopus  Few of the current models and assessments of biodiversity that are used to forecast extinctions or identify taxa at risk include information on how climate affects disease dynamics Frogs and Batrachochytrium fungi are not the only example of synergistic interactions between pathogens and climate change that are affecting biodiversity Global trade in these frogs burgeoned in the 1950s following the development of pregnancy tests that used Xenopus tissue  Like Batrachochytrium , pine blister rust has the potential to eradicate several host species, so it could lower tree lines throughout the Rockies and cause increased run-off and flooding Mid-elevation Atelopus communities are not only the hardest hit by extinction, but they also harbour the most species, so biodiversity in these areas is in double jeopardy Montane Atelopus species that live between 1,000 and 2,400metres show higher rates of extinction than do those that live only in the lowlands (where extinctions are rare) or just in the highest elevations Moreover, although chytrid disease was a common condition in many areas experiencing declines, it was not clear whether Batrachochytrium was directly responsible or whether the infection was a secondary effect associated with dead or dying animals  Moreover, the observed patterns of extinction vary with altitude — as do the effects of climate change Most extinctions (78–83%) occurred in years that were unusually warm across the tropics Museum records suggest that the pathogen achieved a worldwide distribution in the 1960s Now, Pounds et al . offer a mechanistic explanation of how climate change encourages outbreaks of B. dendrobatidis in the mountainous regions of Central and South America: night-time temperatures in these areas are shifting closer to the thermal optimum of B. dendrobatidis , and increased daytime cloudiness prevents frogs from finding ‘thermal refuges’ from the pathogen On page 161 of this issue, Pounds and colleagues provide compelling evidence that anthropogenic climate change has already altered transmission of a pathogen that affects amphibians, leading to widespread population declines and extinctions One of the worries about global climate change is that it will raise the transmission rates of infectious diseases  Pounds and colleagues work is a breakthrough as it resolves the paradox and offers a theory to explain the widespread ‘enigmatic’ declines of Atelopus and other amphibians  Pounds et al . propose that this is because the extreme sites afford thermal refuges, with temperatures being either too high or too low for optimal growth of the pathogen Previous attempts to explain the prevalence of the disease in terms of climate change had been stymied by the so-called ‘climate–chytrid paradox’, because the climatic conditions favouring chytrid growth seemed to be the very opposite of those created by current climate trends Similarly, warmer climate conditions in montane regions in the western United States allow the mountain pine beetle ( Dendroctonus ponderosae ) to complete its life cycle in one year, rather than two So it seems that the expansion in one frog species through trade may have led to the extinction of other amphibian species — a totally unexpected, indirect consequence of human ingenuity The authors combine two disparate approaches into one unifying theory, simultaneously explaining how shifting temperatures are the ultimate trigger for the expansion of a pathogenic fungus, and that this infection is the direct cause of Atelopus extinctions The authors defined an ‘extinction’ as the time when a frog species was last observed by professional teams of herpetologists working in these regions The climate change in the Arctic and sub-Arctic has modified the life cycle of the nematode parasites of musk oxen  The frogs are sending an alarm call to all concerned about the future of biodiversity and the need to protect the greatest of all open-access resources — the atmosphere. The likelihood that this correlation arose by chance is less than one in a thousand The oldest-known hosts of Batrachochytrium are African-clawed frogs ( Xenopus ) , first recorded in South Africa in 1938 The powerful synergy between pathogen transmission and climate change should give us cause for concern about human health in a warmer world  The tenuous hold these animals have on life is especially evident in tropical America, where, for example, 67% of the 110 species of harlequin frog ( Atelopus ; Fig. 1 ) endemic to the region have died out in the past 20 years  The ubiquity, complexity and cascading effects of host–pathogen interactions make their dynamics extremely difficult to predict There may be a tragic irony here These beetles transmit pine blister rust ( Cronartium ribicola ), and as they become more abundant, the fungus they carry is beginning to have a serious effect on the pine trees in the highest-elevation forests along the Rocky Mountains  These results corroborate the GAA findings for a broad array of amphibians that the percentage of extinct or threatened species is largest at middle elevations These worms can now complete their life cycle in one year, instead of two, and their rising numbers are having a significant impact on the survival and fecundity of musk oxen This is contrary to the expectation that higher-elevation species would be more prone to extinction because they generally have smaller environmental ranges over which they can survive Until they do, they will enjoy limited success and will probably give overly optimistic prognoses of how biodiversity will be affected by climate change We should also expect the unexpected: terms such as ‘enigmatic decline’ and ‘pathogen–climate paradox’ will probably dominate explanations of extinctions until we develop a better understanding of the relationships between global change, pathogens and their hosts
 A flurry of squabbles about high-profile biological research is prompting scientists to revisit a perennially touchy subject: how should credit for scientific findings be assigned? In recent months, a panel on research integrity at the University of Pittsburgh, Pennsylvania, scolded cloning expert Gerald Schatten for his limited contribution to papers he co-authored with a South Korean team A particular problem, he says, is researchers who invent a technique and then demand credit every time it is used, even after it becomes standard procedure According to the International Committee of Medical Journal Editors (ICMJE), authors must have made a substantial intellectual contribution to a studys conception and design, or to the acquisition, analysis or interpretation of data And a co-author has accused Alison Murdoch, of the University of Newcastle upon Tyne, UK, of hogging the credit for an advance in cloning human embryos (see ‘Cloning clashes’ ) And in a study of young physicists, some 4% reported that they had seen cases in which relevant studies were not cited in a paper  And it is particularly important for a key finding: “The difference in authorship at the time can end up being the difference between a Nobel Prize and not,” says Nicholas Steneck, an expert in research ethics at the University of Michigan in Ann Arbor And many say that the number and ferocity of such clashes is rising with the number of collaborative projects, which often have multiple authors spanning disciplines and national borders Biologists tend to place a supervisor or lab head last in an author list; organic chemists might put him or her first But he and others say that there are some simple courtesies and practices that could, if widely adopted, help ease any tension By some measures, abuses of and disputes over credit are commonplace Goran Hansson, who chairs the Nobel Committee for Physiology and Medicine, says it would help his task if the research community could agree on criteria for co-authorship. “We would still have to be very meticulous,” he says, “but it would be a bit easier.” Graduate students and postdoctoral fellows frequently complain of being pushed down the author list, if they are included at all Ground rules On this basis, a technician who performed routine genetic sequencing, a colleague who supplied an antibody, or a departmental bigwig who supplied funding would be relegated to the acknowledgements Ian Wilmut of the Roslin Institute in Edinburgh has been criticized for taking most of the credit in 1997 for the cloning of Dolly the sheep In 2005, a team of researchers from Minnesota found that 10% of US scientists surveyed admitted inappropriately assigning authorship in a paper  In genome sequencing and particle-physics collaborations, for example, a papers author list can run into the hundreds In his ethics course, neuroscientist Michael Zigmond, of the University of Pittsburgh, asks graduate students and postdocs to consider a case study of ten people and reach a consensus on whose contribution merits authorship Many institutions, societies and journals have guidelines on what deeds warrant a name on a paper Many medical journals, including JAMA , require this Most concern focuses on who gets listed as an author on a publication One way to avoid ambiguity is for each author to spell out their contribution in the paper Scientists often work for years towards a breakthrough; the recognition for it can bring prestige, promotion and pay Small wonder, then, that they care about how credit is assigned. “This is about one of the most important questions you can ask, because credit more than anything drives science,” says Drummond Rennie, deputy editor of the Journal of the American Medical Association ( JAMA ) Some of these fights become public when there is disagreement about who should talk to, and be acknowledged in, the press. “Some people are very good at co-opting the media and blowing their own horn,” says Martin Blume, editor-in-chief of the American Physical Society Tallies of such publications are one of the main measures of scientific achievement The central problem is that there are no set rules for assigning credit The ICMJE guidelines also say that authors should be able to take public responsibility for appropriate portions of the work — in other words, they must take the flak if the results come under fire, as Pittsburghs Schatten found The participants, he says, often disagree at first, but eventually agree on criteria. newsad; Indeed, many scientists say that the simplest way to avoid fights is to discuss authorship when a collaboration begins. “Proactive discussion is really important,” says Kate Kirby of the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, who co-authored the survey of young physicists The practice infuriates many scientists, because they feel they are being cheated of acknowledgement, and because citation counts are another measure of a papers — and an authors — worth The practice is voluntary at Nature ; editors at Science are considering whether to introduce it. “Its moral, its easy and it takes up virtually no space,” says Rennie, who has pushed for adoption of the practice The stakes are perhaps highest for the most prestigious scientific prize, the Nobels These differences in expectation create fertile ground for disputes These quarrels all involve cloning, but they resonate with a wider audience They must also have drafted or revised the articles intellectual content, and approved the final version Training scientists in the ethics of authorship could also help; many such courses already exist Until recently, it was standard for the head of a German department or institution to take credit on a paper regardless of input Whatever the rules, many scientists feel that the reality is different. “We all know labs where powerful figures appear on papers that are not within their field of expertise,” says Ray Dolan, who heads a neuroscience imaging department at University College London
 Although this problem can be partially circumvented by removing genes that have such mutations, species-specific microarrays are the only known way to obtain a fair comparison among several divergent species without the loss of any genes As we elucidate the complex molecular machinery that controls gene expression, our ignorance of its role in evolution is becoming increasingly alarming At the DNA level there may be many different mutations that affect gene-expression levels, but very few potentially beneficial mutations that directly affect protein function But the authors do find that some groups of genes, particularly those encoding gene-transcription factors, tend to include greater numbers of upregulated genes in humans By determining how much mRNA binds to each probe, the relative abundance of mRNA from each gene can be assessed Gene expression, the major determining factor of protein abundance in the cell, is regulated by various mechanisms, such as protein binding to the DNA sequence and interference by small RNA molecules Gilad et al . also find that genes that are significantly up- or downregulated in humans, compared with other species, are often genes that have changed rapidly at the DNA-sequence level  Gilad et al . also observe no systematic increase or decrease in the regulation of gene expression in either humans or chimpanzees, contrary to previous claims to this effect  Gilad et al . make new strides in this field of research However, if the same microarray is used for all species, results may differ between species because of species-specific mutations that affect the binding affinity of the probes In most cases, we know little about the way in which gene expression is involved in how organisms adapt to new environments or otherwise evolve It has long been hypothesized that adaptation over short evolutionary time may often proceed by modifications in the regulation and interaction of genes rather than in the protein gene-products themselves  Likewise, we may expect genes that have suffered a loss or reduction in functionality to subsequently experience an increased rate of evolution in both the sequence of the protein it encodes and its expression level, because selective constraints on it will have been relaxed Microarrays consist of a number of probes that bind messenger RNA from specific genes (mRNA is the linking molecule between a gene and the protein it encodes) Nonetheless, for convenience, most evolutionary studies have focused on protein evolution, leaving gene expression as one of the great unknowns in evolutionary biology On page 242 of this issue , Gilad et al . describe their study of gene expression in four primates Proteins tend to interact in complex networks, and so small changes in the abundance of one protein may have profound consequences Quantifying the relative importance of the evolution of these various elements will not be easy, but large-scale studies comparing many different organisms should reveal correlations between evolutionary changes at the DNA level and changes in expression level or pattern So there seems to be a correspondence between genes with altered expression and genes that have been targeted by positive darwinian selection in their protein-coding regions So this observation is further support for the view that many evolutionary changes that are specific to humans may be related to gene expression The comparative analysis of expression data may thereby serve to detect functional correlations between DNA and expression levels in organisms in which it is difficult to carry out direct studies using standard genetic techniques The fact that selection in most cases is working to maintain expression levels near some optimum is not surprising — levels of expression of a gene that are too high or too low would presumably often be detrimental to an organism The result, I predict, will be a new perception of the mechanisms underlying evolutionary change — one in which the emphasis is on changes in regulatory elements, in RNA genes and in segments of DNA other than protein-coding genes. Their work is aimed at identifying similarities and differences in gene expression between humans and their nearest relatives They compare gene-expression data in humans, chimpanzees, orangutans and rhesus monkeys to identify genes that have changed their level of expression in the human lineage This makes sense — we would expect changes in the function of a protein to be followed by changes in its distribution and abundance This research differs from earlier studies in using microarrays designed specifically for each species Transcription factors are proteins that themselves play a role in regulating expression levels Using this technology, Gilad and colleagues demonstrate that most genes are under natural selection to maintain a constant level of expression, but that a few genes show evidence of species-specific changes What factors might be causing differences in gene expression between species? Such factors could include changes in the DNA close to the gene, for example changes in transcription-factor binding sites, or in distantly located elements such as gene enhancers, RNA genes or genes encoding transcription factors
 Although it is true that the Federal Emergency Management Agency (FEMA)has primary responsibility for dealing with the immediate structural damage from a catastrophe — as I was quoted as saying — this quote does not do justice to the efforts by the NIH to promote a quick and full recovery from the storm Leaders of damaged research institutions were contacted promptly and assured that the NIH would be at their sides in restoring facilities and research projects Sir I would like to add some details to your News story “New Orleans researchers fight to salvage work from submerged labs” ( Nature 437 , 300 ; 2005 ) regarding efforts made by the National Institutes of Health (NIH) to assist its grantees in the Hurricane Katrina disaster zone The NIH and the entire biomedical research community will stand together with those stricken by this disaster and by Hurricane Rita. The NIH immediately moved to inform grantees of the resources available, from grant extensions to temporary placements in the NIH intramural programme or other institutions The response to Katrina will require effort, flexibility and cooperation, but first and foremost we need profound commitment and solidarity
 Atmospheric aerosols counteract the warming effects of anthropogenic greenhouse gases by an uncertain, but potentially large, amount In the future, aerosol cooling is expected to decline relative to greenhouse gas forcing, because of the aerosols much shorter lifetime and the pursuit of a cleaner atmosphere Strong aerosol cooling in the past and present would then imply that future global warming may proceed at or even above the upper extreme of the range projected by the Intergovernmental Panel on Climate Change. This in turn leads to large uncertainties in the sensitivity of climate to human perturbations, and therefore also in carbon cycle feedbacks and projections of climate change A climate sensitivity of 10 K is large, but cannot be ruled out by observations Aerosol effects on climate were mentioned, but our knowledge was considered inadequate to estimate their magnitude, or even sign Aerosols and climate sensitivity Constraints on the value of climate sensitivity (expressed as Δ T 2×CO 2 , the equilibrium temperature response to a doubling of CO 2 , see Box 1 ) are sought by two main approaches All aerosol types (sulphates, organics, mineral dust, sea salt, and so on) intercept incoming sunlight, and reduce the energy flux arriving at the Earths surface, thus producing a cooling  Alternatively, climate sensitivity can be deduced by relating an observed climate change (for example, the global warming over the last century) to an estimated magnitude of forcing Although the models may disagree about the magnitude of the aerosol effect, they all agree that the net effect is cooling, and that aerosols have therefore ‘protected’ us from some of the greenhouse warming An alternative ‘observationally based’ approach makes use of the observed global warming of ∼0.7 K over the 20th century, and of 0.4 K from 1940 to 2000 (ref. 13 ) Analyses of the probability distribution of climate sensitivities that can be deduced from climate observations suggest that there is a significant probability that the true climate sensitivity is in excess of 4 K (refs 5 , 6 ), and maybe as high as 10 K Because it is the key parameter that translates scenarios of future atmospheric composition into projections of climate change, accurate estimates of climate sensitivity are essential Because of the stabilizing emission of aerosols and their short lifetime, this ‘protection’ will diminish in the future, leaving us vulnerable to both greater climate change and greater uncertainty Both high fertilization + high q 10 and low fertilization + low q 10 are consistent with the historical rise of CO 2 and temperature, but imply different responses of the land carbon cycle to future climates and therefore very different magnitudes of the carbon cycle feedback Climate sensitivity diagnosed by this model rapidly becomes unphysically large and then negative as the aerosol forcing exceeds -1.7 W m -2  Climate ‘protection’ and future uncertainty The range of aerosol forcings predicted by ‘forward’ models, using our best knowledge on the atmospheric aerosol burden and its climate effects, is vast , from 0 to -4.4 W m -2  Climatic effects of aerosols In the first IPCC report , climate change was considered to be driven predominantly by anthropogenic GHG emissions Consequently, equation (1) shows us that a larger aerosol cooling over the historical period (and thus a smaller net forcing) implies a more sensitive climate ( Fig. 1 ) Do we live in a world with weak aerosol cooling and thus low climate sensitivity, in which case future climate change may be expected to be relatively benign? Or do we live in a highly forced, highly sensitive world with a very uncertain and worrying future that may bring a much faster temperature rise than is generally anticipated? Historical constraints To explore this issue more quantitatively, we use a deliberately simplistic approach to illustrate the impact of the uncertainties on projections of future climate (see Box 3 ) Finally, modifications in rainfall generation change the thermodynamic processes in clouds, and consequently the dynamics of the atmospheric ‘heat engine’ that drives all of weather and climate Finally, uncertainties in feedbacks that are strongly dependent on climate sensitivity, such as the carbon cycle feedback, must also be reduced, through process studies and model improvements. First, there is a great need for in situ studies that investigate the response of cloud microphysics and dynamics to enhanced aerosol concentrations Furthermore, the overall uncertainty is dominated by climate sensitivity and hence historical aerosol forcing: Fig. 3a shows that the warming range for a given scenario (for example, 2.5–7.9 K for scenario A2) is greater than the range across scenarios for a given climate sensitivity (6.8–9.6 K at its widest) Furthermore, the response of the natural carbon cycle to future climate is also dependent on the climate sensitivity, implying large uncertainties in future CO 2 concentrations Future changes in the balance of climate forcing factors—such as increasing greenhouse gases (GHG) but decreasing aerosol burdens—mean that historical changes are not sufficient to constrain future projections Future projections We have run the simple model on to 2100 for a range of scenarios from the IPCCs Special Report on Emissions Scenarios (SRES, see Box 2 ) ( Figs 2 and 3 ) However, because we expect the proportions of GHG and aerosols to change in the future, past changes become a much weaker constraint on future behaviour ( Box 2 ) However, GCM parameters are sufficiently uncertain that a recent ‘grand ensemble’ of more than 2,000 climate change experiments —all using the same GCM—has yielded sensitivities ranging from below 2 K to more than 11 K If the mix of future forcings remains the same as in the past, precise knowledge of λ would not be necessary: historical changes would constrain the future  In a similar vein, the historical CO 2 rise sets a joint constraint on the parameter determining the CO 2 -fertilization of photosynthesis ( C 0.5 , the half-saturation concentration for photosynthesis), and the parameter determining the sensitivity of soil respiration to temperature ( q 10 —the factor by which decomposition accelerates for each 10-K warming ) In addition to these ‘direct’ radiative effects, there are several ‘indirect’, cloud-mediated effects of aerosols, which all result in cooling: more aerosols produce more, but smaller, droplets in a given cloud, making it more reflective Incomplete consideration of aerosols in current climate models may have led to underestimation of the true climate sensitivity Ominously, Fig. 3a shows temperature increases in excess of 6 °C for the climate sensitivity implied by the central estimate of aerosol forcing (- 1.5 W m -2 ), and for all but the most optimistic emission scenario Part of the reason for this extraordinary sensitivity of future projections to the historical aerosol forcing is due to the impact of the carbon cycle feedback on projected CO 2 levels ( Fig. 3b ) Recent analyses of the palaeoclimatic record also suggest fairly high climate sensitivity  Second, at the regional and global scale, the effects of aerosols on cloud properties and abundance must be studied using remote-sensing data from the newly available and upcoming satellite sensors Since then, the number of aerosol-caused climate effects considered and the estimates of their cumulative magnitude have steadily grown Smaller droplets are less likely to coalesce into raindrops, and thus the lifetime of clouds is extended, again increasing the Earths albedo Some aerosols (for example, soot) absorb light and thereby warm the atmosphere, but also cool the surface Some groups are now attempting to determine the relative likelihood of different climate sensitivities using the accuracy of simulations of current climate as weighting factors for an ensemble of climate projections  Such a degree of climate change is so far outside the range covered by our experience and scientific understanding that we cannot with any confidence predict the consequences for the Earth system Such an enormous increase would be comparable to the temperature change from the previous ice age to the present Such forcing estimates are, however, also highly uncertain, mostly because of incomplete understanding of the climate forcing by atmospheric aerosols  The climate will become more dependent on climate sensitivity as the aerosol burden is reduced The effects of anthropogenic aerosols have created great uncertainty in our knowledge of the climate sensitivity to increasing greenhouse gases The equation shown in Box 1 then offers a means to estimate climate sensitivity, given the net radiative forcing Δ Q over the same period: Δ T 2× CO 2 = 3.7 Δ T Δ Q - c d(Δ T ) d t (1) Δ Q is the sum of the relatively well-known GHG forcing (+ 2.4 ± 0.3 W m -2 from 1750 to 2000; ref. 1 ), and the very poorly quantified, but potentially substantial, cooling from anthropogenic aerosols The extent to which the land carbon cycle amplifies future CO 2 increase depends critically on climate sensitivity ( Fig. 4 ) The first IPCC report quoted a range of Δ T 2×CO 2 = 1.5–4.5 K, which remains essentially unchanged in the Third Assessment Report of the IPCC (IPCC-TAR) The implied high climate sensitivities are within the range of sensitivities inferred by recent observational approaches The observed warming constraint yields a relationship between aerosol cooling and climate sensitivity ( Fig. 1 ), indicating that Δ T 2×CO 2 is just 1.3 K for zero aerosol forcing, but exceeds 10 K for Δ Q aeros = -1.7 W m -2 (Δ Q aeros is the sum of all aerosol forcings) The positive climate–carbon cycle feedback increases markedly with climate sensitivity, especially if soil decomposition is more sensitive to temperature (that is, for higher q 10 values) The price for this ‘climate protection’ is, however, great uncertainty about the true magnitude of the climate change we can expect in the future The recent tremendous growth in knowledge of the climatic effects of aerosols, along with the emergence of the likelihood of positive feedbacks between climate and the carbon cycle , have transformed the orderly picture of climate change of the early 1990s, dominated by GHG warming, into a complex mix of opposing effects  The twentyfirst-century climate will therefore suffer the treble hit of an increasing warming from greenhouse gases, a decreasing cooling from aerosols, and positive feedbacks from the carbon cycle, whereby increased temperatures cause accelerated release of soil carbon by decomposition  The ‘bottom-up’ approach, used in General Circulation Models (GCMs), relies primarily on improved representation of the feedbacks in the climate system, including ever more complex representations of physical processes within higher-resolution coupled ocean–atmosphere models  These efforts have yielded many interesting scientific insights, but have failed to reduce the uncertainty in climate sensitivity Third, parameterizations of cloud processes and feedbacks in GCMs must be improved This dependence of the carbon cycle feedback strength on climate sensitivity may explain a large part of the divergence amongst the first generation climate–carbon cycle GCMs  This warming of atmospheric layers may also reduce cloudiness, yielding another warming effect Thus research over the past decade has shown evidence of the importance of a considerable number of aerosol climatic effects, which on balance cool the Earth and have therefore reduced the effect of greenhouse warming Thus, even if we ignore the implied possibility of a net cooling forcing over the past century, we find that adding the aerosols effects to those of the GHG yields a net forcing that extends from the full GHG forcing down to a zero net forcing over the last century To reduce these uncertainties a multi-pronged approach is needed Unfortunately, climate models yield a wide range of sensitivities, depending on the parameterizations they contain , and thus cannot reliably constrain the true climate sensitivity We apply two observational constraints: the model should reproduce both the observed global warming and the CO 2 increase from 1940–2000 We cannot quantitatively assess the probability of a given climate sensitivity within the limited scope of this paper, but our analysis suggests that there is a possibility that climate change in the twentyfirst century will follow the upper extremes of current IPCC estimates, and may even exceed them We find that a large uncertainty range of temperature increase is predicted for 2100, and that even by 2050, the model runs with strong historical aerosol cooling predict a temperature rise from 1850 of as much as 2.2 °C We note that recent studies tend to estimate the sum of aerosol forcings to be in the range -1 to -2 W m -2 , that is, in the region of sharply increasing and highly uncertain Δ T 2×CO 2 (refs 11 , 12 , 16 , 17 ) When we include the uncertainty caused by the choice of emission scenarios, we find that the range considered most plausible in IPCC-TAR (2.3–4.9 °C from 1850–2100) can be obtained only for aerosol forcings considerably weaker than predicted by current forward models ( Fig. 3 ), which tend to estimate the sum of aerosol forcings to be in the range -1 to -2 W m -2 (refs 11 , 12 , 16 , 17 ) With a best estimate of q 10 = 2, we find that for climate sensitivities greater than 3 °C, the carbon cycle feedback will accelerate CO 2 growth by more than 50% ‘Climate sensitivity’ measures how strongly the Earths climate system responds to a given perturbation, and is often expressed as the equilibrium rise in global temperature resulting from a doubling of atmospheric CO 2 
 A long, high-temperature pre-firing would serve as a thermal-stability test for the crucible before delivery to the user Although unaware of the presence of thisaluminium silicate in their Hessian crucibles, the producers evidently coined a very successful recipe — which explains why it was notmodified, or publicized, for centuries. As a result, a Hessian crucible would be less prone to cracking if struck while its contents were being stirred, or immediately after its removal from a hot furnace Crucibles from the German region of Hesse have been used since the late Middle Ages by alchemists, chemists, assayers, minters and metallurgists , but the factors responsible for their superior quality are unknown and several historically documented attempts to replicate their construction have failed  Here we show that the secret behind the remarkable properties of these early crucibles is mullite, an aluminium silicate that is now widely used in modern advanced ceramics Hessian crucibles ( Fig. 1a ) were established by the fifteenth century and dominated the international market, reaching Scandinavia, Britain, Portugal and even Jamestown in the American colony of Virginia  However, these factors are not exclusive to Hessian wares In addition, Hessian fabrics contain 20–40 vol% of subangular or spheroidal quartz grains, resulting from the mixing of clay with sand It might even be argued that the scientific developments that led to the discovery of the elements and characterization of their thermochemical behaviour were only possible because these standardized mullite crucibles were available to yield reliable and reproducible results More important, this firing led to the formation of synthetic mullite ( Fig. 1b,c ), which we believe was the crucial secret behind the quality of Hessian crucibles Mullite (Al 6 Si 2 O 13 ) has been developed for a wide range of applications in modern ceramics, including for building and optical materials, and for thermal-protection systems and in liners for aircraft engines Non-plastic inclusions, notably quartz, can significantly increase the toughness and thermal-shock resistance of ceramics  Petrographic and chemical analyses revealed that the Hessian vessels were made to a standardized recipe, in which a very lean kaolinitic clay was used, tempered with almost pure quartz sand, then shaped on a potters wheel and fired to very high temperatures  Scanning electron microscopy and X-ray diffraction of unused Hessian fabrics reveal complete matrix vitrification and the presence of mullite and tridymite, which most probably crystallized from the decomposition of kaolinite at temperatures between 1,100 °C and 1,200 °C (refs 8 , 9 ) Some properties of mullite relevant to its ancestral application are low thermal expansion (and a corresponding impressive thermal-shock resistance), high creep resistance, strength at high temperatures, and an outstanding stability in aggressive chemical environments  The ceramic matrices of these crucibles have an exceptionally high alumina content (mean, 36.9 wt% ± 0.39 s.d.), with the sum of the alkali and earth-alkali oxides being just about 2 wt% (see supplementary information ) The presence of interlocking acicular mullite in the ceramic matrix of Hessian crucibles would have conferred properties ideal for withstanding a range of thermal, mechanical and chemical stresses These temperatures were unusual in Europe for firing pottery, with the exception of Rhenish salt-glazed stoneware, a product of the same region  This would render the vessels extremely resistant to high temperatures We analysed 50 Hessian and non-Hessian crucibles from 10 archaeological sites in Europe and America in an attempt to explain the superior properties of the Hessian vessels, or, as Robert Plot put it in 1677, “the mystery of the Hessian wares”   We believe that a key stage in the manufacture of Hessian crucibles, which sets them apart from their competitors, was high-temperature firing in the potters kiln
 Discrete tunnel junctions, or molecular diodes, have been reported using scanning probes , break junctions , metallic crossbars and nanopores  Electronic transport through single molecules has been studied extensively by academic and industrial research groups For technological applications, molecular tunnel junctions must be reliable, stable and reproducible Here we demonstrate a method to manufacture molecular junctions with diameters up to 100 µm with high yields ( 95 per cent) Our technique involves processing the molecular junctions in the holes of a lithographically patterned photoresist, and then inserting a conducting polymer interlayer between the SAM and the metal top electrode Self-assembled monolayers (SAMs) may offer a promising route to the fabrication of reliable devices, and charge transport through SAMs of alkanethiols within nanopores is well understood, with non-resonant tunnelling dominating the transport mechanism  The conductance per molecule, however, typically varies by many orders of magnitude  The junctions show excellent stability and reproducibility, and the conductance per unit area is similar to that obtained for benchmark nanopore diodes This simple approach is potentially low-cost and could pave the way for practical molecular electronics. Unfortunately, electrical shorts in SAMs are often formed upon vapour deposition of the top electrode , which limits the diameter of the nanopore diodes to about 45 nm A grafting density for alkanethiols of 4.6 × 10 18  m -2 was assumed After the self-assembly of the alkane dithiolate on the gold bottom electrode, a water-based suspension of poly(3,4-ethylene-dioxythiophene) stabilized with poly(4-styrenesulphonic acid) (PEDOT:PSS) is spin-coated on top of the SAM, resulting in a layer thickness of about 90 nm ( Fig. 1c ) All I – V measurements were performed in vacuum to avoid the influence of water in PEDOT:PSS (see Supplementary Information ) As a typical example we use our data for dodecanedithiol Because current density J ∝exp(- βd ) (where d is the barrier width; ref. 23 ), the tunnelling decay coefficient β can be deduced from the slope of this linear fit Densely packed mono-domains of up to several hundred square nanometres can easily be formed when the chain length exceeds ten units (ref. 20 and references therein, and ref. 21 ) Electronic transport in single molecules has been investigated with break junctions and a variety of scanning probe techniques Figure 2 shows that at low bias the current increases linearly with applied bias (the low bias range is magnified in the inset of Fig. 2 ) Figure 3 demonstrates that the current density decreases with increased length of the alkane dithiol molecule Figure 4 displays the current–voltage characteristics of molecular junctions based on dodecane dithiol with diameters of 40 µm and 80 µm both directly after fabrication and after storage under ambient conditions for 75 days Figure 5 shows good agreement between our data and the nanopore data , with a difference in current per molecule of less than a factor of two For molecular tunnel junctions, through-bond tunnelling is assumed (ref. 5 and references therein), which implies that the electrons do not tunnel through vacuum but through the lowest unoccupied molecular orbital (LUMO) For practical applications of molecular tunnel junctions, yield, reliability, operational stability and shelf-life are crucial For through-bond tunnelling the width of the tunnel barrier is then equal to the length of the molecule Furthermore, it demonstrates that non-resonant, through-bond tunnelling is the transport mechanism in these metal–insulator–metal junctions Furthermore, tunnelling is a temperature-independent process Grain boundaries in SAMs do not seem to impede charge transport Hence, the tunnel barrier width in the nanopore experiments is slightly smaller, resulting in a higher current per molecule Here we focus on SAMs of alkane dithiols Here we report a technology that overcomes this difficulty and produces reliable, stable and reproducible molecular junctions In Fig. 3 the current density is plotted on a logarithmic scale as a function of the applied voltage for various alkane dithiols: octanedithiol (HS–C 8 H 16 –SH), decanedithiol (HS–C 10 H 20 –SH), dodecanedithiol (HS–C 12 H 24 –SH) and tetradecanedithiol (HS–C 14 H 28 –SH) In summary, we have demonstrated a technique for fabricating reliable molecular metal–insulator–metal junctions with unprecedented device diameters of up to 100 µm In the nanopore junctions the current is measured through molecules that are perfectly ordered in a mono-domain, while in the large-area diodes the molecules are ordered in multi-domains Key ingredients are the use of a conducting polymer layer sandwiched between the SAM and the top electrode to prevent electrical shorts, and processing within lithographically defined vertical interconnects (or via holes) to prevent both parasitic currents and interaction between the environment and the SAM Literature data are included for measurements on decanethiol in nanopore junctions and by scanning probe experiments, which covers a device area spanning ten orders of magnitude Metal/SAM/metal nanojunctions about 45 nm in diameter have been fabricated using electron beam lithography and suspended silicon nitride membranes  Molecular lengths were calculated using ACD Labs software (see the Supplementary Information ), and the linear fit through the data shows that J depends exponentially on the length of the alkane dithiols Next, the top gold electrode is vapour-deposited through a shadow mask No hysteresis is observed and there are no differences between consecutive sweeps No hysteresis is observed in the J – V characteristics during all the voltage sweeps On a 4-inch silicon wafer with a thermally grown oxide, a 1 nm chromium adhesion layer and a 40 nm gold bottom contact are vapour-deposited ( Fig. 1a ) with a typical root-mean-square roughness of about 0.5 nm for a 1 µm 2 area (see Supplementary Information ) PEDOT:PSS is a commercially available, highly doped, conductive polymer with a conductivity of about 30 S cm -1  Photoresist is spin-coated and holes of diameter 10–100 µm are produced by standard photolithography ( Fig. 1b ) Preliminary stability investigations reveal a shelf life of more than several months and no deterioration upon cycling SAMs of alkane monothiols are more difficult to use in the processing of hydrophilic PEDOT:PSS owing to their hydrophobic CH 3 end groups Similarly, Fig. 2 shows the expected behaviour for a metal–insulator–metal junction at high bias, namely a current that increases exponentially with applied voltage  That the current density of our large-area molecular junctions exhibits a dependence on voltage and temperature identical to that of the nanopore devices, combined with the absence of any hysteresis, clearly demonstrates that PEDOT:PSS can be regarded as a non-interacting conductive electrode The absence of any temperature dependence over the range from 199 to 293 K demonstrates that non-resonant tunnelling is the dominant transport mechanism ( Fig. 2 ) The conductance per molecule, however, differs by orders of magnitude The conductance through the SAM of alkane thiols in the nanopores is independent of temperature and exponentially dependent on the length of the molecule , which implies that the electrical transport mechanism is non-resonant through-bond tunnelling The critical step in the fabrication of molecular junctions is applying the metal top electrode The current density at a bias of 0.1, 0.3 and 0.5 V is presented in the inset of Fig. 3 on a logarithmic scale as a function of the length of the molecule The current in junctions without the SAM is orders of magnitude larger The current is dominated by the alkane dithiol monolayer The current per molecule at 0.2 V bias is plotted in Fig. 5 as a function of device area The current per molecule is similar to that obtained for benchmark nanopore diodes The data points fall on top of each other, showing that there is no sign of deterioration upon storage The decrease of β with increasing bias is also as expected (ref. 5 and references therein) The envisaged application is molecular electronics, which could potentially solve fundamental scaling limits in complementary metal oxide semiconductor (CMOS) integrated circuits The error bars represent the standard deviation upon averaging over at least 17 devices The excellent stability is presumably due to encapsulation of the diodes by photoresist, which prevents any interaction of the environment with the SAM The good agreement between the current per molecule as measured in our large-area diodes and the nanopore junctions is remarkable considering the orders-of-magnitude difference in device area The I – V characteristic of a typical metal–insulator–metal junction 100 µm in diameter and based on decanedithiol is presented in Fig. 2  The inset of Fig. 4 shows three I – V measurements taken from 100 consecutive forward and backward sweeps The large scatter in the conducting probe and tunnelling microscope data is intrinsic and due to the presence of an additional tunnelling gap and uncertainties in the number of molecules measured The molecular junctions are processed in vertical interconnects (or via holes) of photolithographically patterned photoresist, which eliminates parasitic currents and protects the junction from the environment The monothiol-based molecular junctions, however, exhibit similar current versus applied voltage ( I – V ) characteristics, although with a larger standard deviation The processing of molecular junctions of large area with diameters of 10–100 µm is schematically depicted in Fig. 1 (see Supplementary Information for details) The reproducibility is remarkable and investigations into the junction stability are also promising The substrate is submerged in a freshly prepared 3 × 10 -3  M solution of the alkane dithiol in ethanol for a minimum of 36 h The synthesis of these alkanedithiols is described in the Supplementary Information  The technique is simple, compatible with standard integrated circuit fabrication processes, and can be scaled up and extended to any molecule and any metal bottom electrode on which an ordered SAM can be formed. The theoretical prediction of unipolar molecular diodes has led to a global effort to experimentally verify such devices The top electrode acts as a self-aligned etching mask during the removal of the exposed PEDOT:PSS using reactive ion etching ( Fig. 1d and Supplementary Information ) The yield is presumably due to the large differences in surface tension between the hydrophilic PEDOT:PSS and the hydrophobic backbone of the alkane thiolates The yield of functional devices is larger than 95% even for molecular junctions with a diameter of 100 µm The yield of functional molecular junctions is over 95% The yield of these molecular junctions is close to 100% Therefore, the conductance per unit area through a SAM of alkane(di)thiols can be considered a benchmark for any novel technology related to molecular electronics These values are in good agreement with those derived from analysis of the nanopore diodes by Wang et al. , who report values of β ranging from 0.83 to 0.72 Å -1 in the bias range from 0.1 to 1.0 V (ref. 8 ) This conclusion is further substantiated by the dependence of the current density on the barrier width This confirms that the currents are indeed specific for the molecules in the junctions This difference is presumably due to the use of a monothiol in the nanopore junctions and a dithiol in our large-area molecular junctions This difference prevents intermixing and hence the formation of shorts This discrepancy is probably due to the presence of an additional tunnelling gap in scanning probe techniques, to uncertainties in the number of molecules measured, or to poorly defined device surface areas (ref. 5 and references therein) This is because the mean tunnel barrier height from the Fermi level of the metal to the LUMO is smaller than the work function of the metal This is expected for a metal–insulator–metal junction when the mean tunnel barrier height is larger than the applied voltage  To compare our molecular junctions to other data appearing in the literature , we normalized the current to the current per single molecule To ensure that electrical transport is dominated by the molecules and will therefore scale with the device area, an ordered monolayer is required Typically, SAMs of alkanethiols on noble metals such as gold are used (ref. 19 , and ref. 20 and references therein) Vapour-deposited noble metals create shorts in the SAMs due to filamentary growth , while reactive metals such as Ti destroy the SAM  We find β values of 0.66 ± 0.06, 0.61 ± 0.05, and 0.57 ± 0.05 Å -1 at a bias of 0.1, 0.3 and 0.5 V, respectively We prevent shorts by using a layer of highly conducting polymer between the SAM and the vapour-deposited metal top electrode Well-defined junctions can only be realized when the molecules are sandwiched between two electrodes
 An opportunity to test the hypothesis on a meaningful scale arose when a valley in Venezuela was flooded to develop a hydroelectric scheme, and a lake — Lago Guri ( Fig. 1 ) — was created Animal life is supported by the primary production of green plants, and current knowledge suggests that for every species of terrestrial plant there are about five species of animal Before the valley was flooded, commercial logging of the valley floor was carried out, but the elevated regions were left untouched and survive as forested islands But in the light of such energetic dependency of animals on a plant food-base, it is remarkable that vegetation survives at all — and not only survives, but dominates the biomass of most land ecosystems By 2002, the density figure for small islands had fallen to 25% of that of the large islands Changes rapidly became evident on the small islands, which by 1997 had densities of small saplings only 37% of those on the large islands; recruitment and mortality of trees and shrubs had evidently been strongly affected by the increased herbivory under conditions of low predation Islands of less than 2 hectares (20,000 m 2 , or about 5 acres) lost many of their vertebrate species within a few years of isolation, and these smaller islands also began to display higher densities of herbivores — especially invertebrates, including leaf-cutter ants, but also some vertebrates such as iguana, howler monkey, agouti and tortoise It remains to be seen whether overgrazing will lead to the total destruction of vegetation on the small islands, and whether that would then lead to herbivore extinction followed by plant reinvasion and the establishment of a new order. Land masses of more than 75 ha retained greater numbers of vertebrate grazers, including deer, peccary and a full range of primates, but they also supported predators of these vertebrates, including raptors (such as harpy eagle), snakes, ocelot, puma and jaguar Medium-sized islands (less than 15 ha) with some vertebrate predators, such as the armadillo that preys on leaf-cutter ants, would be less severely affected, and large islands with a full complement of predators would remain unchanged Not all of these animals feed directly on living plants; some consume dead plant litter, and others prey on the plant consumers One suggestion is that the intensity of grazing is held in check by predation of carnivores on the herbivores, and this hypothesis has at last proved testable Sample areas (usually about 0.6 ha in extent) with similar tree densities were selected on the medium-sized and larger islands, and the individual trees were recorded in the same way Species losses, predictably, have been greater on the small islands Such cascades, where the removal of one trophic level (in this case, top predators) causes knock-on effects through other trophic levels, are well documented from aquatic communities  Terborgh et al . , however, have quantified these effects with great precision and have demonstrated both the extent and pace of the trophic cascade Terborgh et al . have recorded the ecological consequences of fragmentation of the forest into these isolated units over many years , and have described the relationship between island size and species richness, which follows the model described by the theory of island biogeography  Terborghs team periodically surveyed the vegetation of all three types of island The Hairston ‘green world’ hypothesis would predict that the very small islands that lacked predators and developed high densities of herbivores should experience a decline in vegetation The lake is 4,300 km in area, and contains many islands of different sizes The most widely accepted explanation for this, first put forward by Hairston et al . , is that herbivore numbers are controlled by ranks of predators that keep their populations in check and inadvertently ensure that green plant production continues The researchers consider other causes, but conclude that the loss of animals that preyed upon vertebrate grazers and leaf-cutter ants on the small islands set in motion a trophic cascade that destabilized the food web The small islands typically contained about 300 individual trees, so all of these were tagged and their sizes and condition noted They have proved difficult to demonstrate in terrestrial ecosystems, although (for example) the loss of wolves from most of the national parks of the United States has led to increases in vertebrate grazers and overgrazing They show that, without top predators, the world would be less likely to remain a green and pleasant land Tree and shrub mortality over a five-year period was quite high on all islands, but was greatest on the small ones, which experienced 46% mortality compared with 32% on the large islands Undoubtedly, many more species of animal (especially insects) await description than do plants Why is the world green? Why have grazing animals with their insatiable appetites not consumed all vegetation and reduced the land to dust? There have been hypotheses, of course, but as with many large-scale ecological problems, it has not proved easy to test any proposal with controlled experiments Writing in Journal of Ecology , John Terborgh and his colleagues describe a large-scale experiment in which the degree of predation upon grazers varies and the consequences for vegetation can be measured
 During the expeditions, we had to find the correct rock layers, and use hammers, picks and chisels to split them Early actinopterygians lack cosmine First Authors Theres an evolutionary gap between two kinds of primitive bony fish — it separates the sarcopterygian (lobe-finned fishes) from the actinopterygian (ray-finned fishes) How does your paper help resolve some of these questions? Our paper shows how the pore network could have been constructed Its unusual combination of primitive characters suggests that it is close to the common ancestor of the lobe- and ray-finned fishes Many early sarcopterygian fishes were covered in a hard tissue known as cosmine, which is unknown in any living vertebrates Meemannia s cosmine suggests that the depth of a pore cavity grows with the deposition of each successive layer of enamel Min Zhu of the Chinese Academy of Sciences and Xiaobo Yu of Kean University, New Jersey, explain what they found from their specimens Now, a group of palaeontologists has found fossils that bridge the gap between the two types of fish and explain how they might have evolved Sometimes, a very bizarre fish immediately caught our attention; at other times we realized the novelty and significance of a find only when preparing it for the lab The different pieces of this enticing puzzle are starting to make sense. They also illustrate how the enamel structure was formed and eventually progressed to include pore channels This tissue has a structure similar to the mammalian tooth (with its pulp cavity, dentine and hard enamel) and the layers are shot through with a network of small canals Together with materials from ongoing work by palaeontologists in other parts of the world, we are confident that a more complete understanding of the evolution of these major vertebrate groups will emerge Usually we found a mixture of different fossil fish parts We predict that Meemannia will have several other features that reduce the gap between early sarcopterygians and actinopterygians What are they? They include questions about how cosmine arose evolutionarily, and what occupied the cavities of the pore–canal network Whats next? We expect to find out more about the morphology of Meemannia using further fossils from the site Where and how did you find the fossils? We found this fish, dubbed Meemannia eos , during 2001 and 2002 field excursions in east Yunnan, in southwestern China Your paper mentions controversies about the biology of cosmine
 Here we show that the extension of this method into the non-equilibrium regime allows us to observe in real time in a short peptide the weakening of an intramolecular hydrogen bond and concomitant opening of a β-turn In contrast, two-dimensional infrared spectroscopy, which maps vibrational coupling between molecular groups and hence their relative positions and orientations , is now routinely used to study equilibrium processes on picosecond timescales Nuclear magnetic resonance methods can follow such structural changes, but only on millisecond timescales under non-equilibrium conditions These static structural snapshots are important to our understanding of biomolecular function, but real biomolecules are dynamic entities that often exploit conformational changes and transient molecular interactions to perform their tasks Time-resolved X-ray crystallography has recently been used to monitor the photodissociation of CO from myoglobin on a subnanosecond timescale , yet remains challenging to apply more widely We find that the rate of this process is two orders of magnitude faster than the ‘folding speed limit’ established for contact formation between protein side chains . X-ray crystallography and nuclear magnetic resonance measurements provide us with atomically resolved structures of an ever-growing number of biomolecules Although the exact transient 2D-IR lineshape critically depends on multiple cancellation effects in the two-dimensional difference spectrum that are at present inaccessible by theoretical modelling, the diagonal cut in Fig. 3c (blue line) does suggest the characteristic ‘±’ signature expected for vibrational transitions As a working hypothesis, we thus assign the second time constant to a conformational change of the peptide backbone, which is accompanied by a weakening of the intramolecular hydrogen bond As the equilibrium constant between open and closed peptide configurations is of the order of one after photocleavage of the S–S bond, the intrinsic rates for loop breaking k break and loop formation k close will be approximately the same with k obs  =  k break  +  k close  Because the 2D-IR spectrum in the presence of the ultraviolet pulse contains contributions from the photoproduct and from unexcited molecules, two sets of 2D-IR spectra are recorded simultaneously, one with the ultraviolet pulse switched on and one with the ultraviolet pulse switched off Because the peptide is clasped by the disulphide bridge and stabilized by an intramolecular hydrogen bond, the spatial distance between the amide groups of Cys(1) and Aib is sufficiently small to give rise to a crosspeak, albeit one that is hardly resolved because it is covered by the wings of the stronger crosspeaks labelled 1 and 2 in Fig. 2b  But the most important feature is a transient crosspeak labelled ‘TC’ in Fig. 3b , which matches the position of crosspeak ‘3’ (Cys(1)–Aib) in the equilibrium 2D-IR spectrum Cleavage of the stabilizing S–S bond shifts the corresponding equilibrium constant from K  ≈ 0.02 to K  ≈ 0.3 Each of these signals consists of a negative contribution due to bleach and stimulated emission, and a positive contribution due to excited-state absorption Excitation of one carbonyl group results in a so-called diagonal absorbance signal at the frequency of the excited oscillator, and in a so-called off-diagonal absorbance signal (or crosspeak) at the frequency of the coupled second carbonyl group Figure 2b displays the weighted differences between 2D-IR spectra recorded with parallel and perpendicular polarizations of pump and probe laser pulses, a procedure that enhances crosspeaks relative to the otherwise dominant diagonal peaks  Figure 4a shows the time evolution of the O ··· H distance after cleavage of the S–S bond for three typical non-equilibrium trajectories, and gives two simulated structures with short and long O ··· H distances Figure 4b gives the mean O ··· H distance averaged over 120 non–equilibrium trajectories (red curve), and indicates the distribution of simulated distances at the one standard deviation (1 s.d.) level For pump–probe delay times longer than 1 ns, the measured signal depends on the peptide concentration used (compare open and closed symbols in Fig. 1c ) However, a more serious problem can also arise from the fact that differences in solvent polarity and hydrogen-bonding characteristics can change which specific structures are most stable or most readily formed and also change the reaction or transformation pathways of the system However, the hydrogen bond does not break entirely In a first control experiment, we use conventional transient (pump–probe) infrared spectroscopy on a 200 mM solution of the peptide in CD 3 CN to establish the dynamic processes in our system and their timescales (see Supplementary Information for full experimental methods) In a second control experiment, we measure the conventional 2D-IR spectrum under equilibrium conditions, with the S–S bond still intact In accordance with this interpretation, the redshift disappears on a 20 ps timescale as the molecules cool through dissipation of excess energy into the solvent In contrast, the relative orientation and distance of the C=O groups of Cys(1)–Aib (crosspeak ‘3’ in Fig. 2b ) change significantly during the conformational transition, giving rise to the transient crosspeak labelled ‘TC’ in Fig. 3  In other words, photocleavage of the disulphide bridge causes the rigid β-turn to adopt a more floppy and random structure that weakens the intramolecular hydrogen bond; this in turn manifests itself in a modified C=O coupling across the hydrogen bond In this context, we note that peptide dynamics is expected to scale with solvent viscosity , which differs for the solvent CD 3 CN we have used and the biologically relevant solvent water Instead, the distribution of O ··· H distances widens, with the fraction of trajectories characterized by short distances (corresponding to hydrogen-bonded molecules; see lower black curve in Fig. 4b ) staying almost constant over time It is also consistent with the sudden jumps seen in the single trajectories ( Fig. 4a ), which are indicative of a two-state equilibrium between an open peptide conformation and a closed, hydrogen-bonded peptide conformation that are separated by a small energy barrier It is well known that in such a hydrogen-bond pattern, weakening of the hydrogen bond increases the bond order of the C=O bond and hence its vibrational frequency  Molecular dynamics simulations (data not shown) indeed suggest a change of the order of one in the timescale of the processes probed, as expected for a viscosity effect Molecular dynamics simulations (see below) indicate that in our system, the strain in the much shorter peptide backbone keeps the two S radicals apart and prevents intramolecular recombination Molecular dynamics simulations access similar length and timescales and can be used to investigate ultrafast non-equilibrium dynamical processes, making comparisons between results obtained with these two methods straightforward and useful for their mutual validation and interpretation Most crosspeaks are caused by coupling of neighbouring amide groups, that is, between Cys(1)–Pro (labelled ‘1’ in Fig. 2b ) and Cys(1)–Boc (labelled ‘2’ in Fig. 2b ) Nevertheless, transient 2D-IR experiments can be conducted using water as solvent (our choice of CD 3 CN was simply due to the low water solubility of the peptide studied), and can in principle also readily be scaled to more complex systems Of importance will be the additional crosspeak that arises owing to the interaction between Cys(1) and Aib (labelled ‘3’ in Fig. 2b ) Our two-dimensional infrared (2D-IR) investigation of ultrafast dynamics uses the cyclic disulphide-bridged peptide cyclo(Boc–Cys–Pro–Aib–Cys–OMe) shown in Fig. 1a (for details regarding synthesis and characterization, see ref. 15 ) Rates on this timescale can be considered an absolute speed limit for protein dynamics, and are governed solely by the relatively small intrinsic barriers of the peptide backbone and unaffected by entropic factors that become relevant in larger peptide chains or proteins  Subsequent subtraction leads to transient 2D-IR difference spectra , which are sensitive to changes during the conformational transition The disulphide bridge and an intramolecular hydrogen bond make the peptide very rigid and ensure that it adopts one exclusive β-turn structure, according to the nuclear magnetic resonance (NMR) results  The evolution of this crosspeak is seen more clearly in Fig. 3c , where the red curves show how absorbance changes with probe laser frequency for a fixed pump laser frequency. (The curves thus constitute horizontal cuts through the transient 2D-IR spectra—indicated by red dotted lines in Fig. 3b —at a pump frequency where the crosspeak occurs.) The absolute crosspeak intensity increases with delay time, and even more so relative to the intensity of the corresponding diagonal signal ( Fig. 3c ) The Fourier transform infrared absorption spectrum of the peptide shows well-resolved bands in the amide I region, which are associated with individual C=O groups of the peptide backbone ( Fig. 1b ; see Supplementary Information for band assignment) The heating leads to an excitation of low-frequency modes that are anharmonically coupled to the amide I vibrations  The intermediate process (∼160 ps) is best seen in the absorption changes at 1,654 cm -1 ( Fig. 1c ), which reflect a blueshift of the C=O group of Cys(1) involved in the peptide’s intramolecular hydrogen bond The latter is slightly redshifted owing to the anharmonicity of the carbonyl vibrators The molecular dynamics simulations indicate that, locally, the backbone structure between Cys(1)–Pro and between Cys(1)–Boc (crosspeaks ‘1’ and ‘2’ in Fig. 2b ) does not change during the conformational transition (see the example structures in Fig. 4a ), explaining why no net signal remains in a two-dimensional difference spectrum in the corresponding crosspeak region The relatively weak disulphide bridge (dissociation energy ∼65 kcal mol -1 ) is easily cleaved by ultraviolet light and can thus serve as a photo-trigger for the creation of a predetermined breaking point  The shift of all bands in the transient 1D-IR spectrum ( Fig. 3a ) gives rise to related signals along the diagonal in the transient 2D-IR spectra ( Fig. 3b ) This behaviour contrasts with that seen in an earlier study of peptide conformational changes upon disulphide photocleavage , where 90% of thiyl radicals recombined within 2–5 ns This behaviour is consistent with NMR observations that during the synthesis of the peptide, the open, S-protected precursor molecule forms a weak hydrogen bond  This implies that the slowest dynamic process we probe (time constant of ∼2.6 ns at 200 mM; closed circles) is the diffusion-controlled intermolecular reaction of the liberated thiyl radicals with other radicals or unreacted peptides; decreasing the peptide concentration makes the intramolecular radical recombination even slower ( Fig. 1c , open circles) This rate is similar to what has been predicted from molecular dynamics simulations for the backbone dynamics of small peptides of similar length , and two orders of magnitudes faster than the speed limit established by triplet–triplet transfer methods for the contact formation between side chains in related molecules This reveals that the photolysis of the S–S bond results in an instantaneous redshift of all amide I bands ( Fig. 1d , red curve), and that the subsequent evolution of the spectrum is characterized by three global time constants with values of ∼20 ps, 160 ps and 2.6 ns (see Fig. 1c ) To guide the interpretation of our experimental data, we simulate the photo-triggered conformational changes in our system using non-equilibrium molecular dynamics (see Supplementary Information for computational methods) To illustrate briefly the principle of 2D-IR spectroscopy, consider a system of two coupled carbonyl groups  To resolve spectral congestion in larger molecules (for example, of the size of an α-helix) isotope labelling will be needed  Transient 1D-IR spectra and transient 2D-IR spectra obtained with pump–probe delay times of 3 ps, 25 ps and 100 ps are shown in Fig. 3  Transient 2D-IR spectroscopy combines picosecond time resolution with the ability to sense local contacts between specific molecular groups in the solution phase Transient 2D-IR spectroscopy thus extends 2D-IR spectroscopy, to allow the investigation of a transient species far from equilibrium with picosecond time resolution We assign the instantaneous redshift at early times to transient heating of the molecule by the excess energy that is released after cleavage of the S–S bond by the ultraviolet photon, a common effect in ultraviolet–infrared experiments  We find that the mean O ··· H distance increases on a 240 ps timescale, in reasonable agreement with the experimentally observed timescale of 160 ps We initiate the experiment with an ultraviolet pulse that cleaves the disulphide bridge and then use increasingly longer delays before starting the 2D-IR part of the experiment, thus recording a 2D-IR spectrum as the molecule undergoes its photo-triggered conformational transition We note that the β-turn opening we observe occurs on an ultrafast timescale with k obs –1  = 160 ps We see a transient crosspeak only for Cys(1)–Aib, and not for Cys(1)–Pro or Cys(1)–Boc (although these latter crosspeaks, labelled ‘1’ and ‘2’ respectively in Fig. 2b , are stronger in the equilibrium 2D-IR spectrum), implying that it is a change of interaction strength, and not the overall frequency shift, that is responsible for the transient crosspeak We thus anticipate that the combined use of transient 2D-IR spectroscopy and molecular dynamics simulations will deliver unprecedented insight into fast biomolecular processes. With these results in mind, we turn to transient 2D-IR spectroscopy, which can be thought of as a combination of the two previous experiments
 A larger version of Tom Na H-iu is on show with other work by Mori at the London gallery Albion until 22 December. A student of fashion in her native Japan, she worked briefly as a model before studying art in London and now lives in New York Among the neutrinos that govern the megaliths light emissions are some that emanate from exploding, dying stars — supernovae At the 2005 Venice Biennale she exhibited Wave UFO , a futuristic pod in which the brainwave data from electrodes attached to three participants were projected on the ceiling as mutating coloured shapes However, her recent creations have laid this problem to rest However, she has insisted on a more serious purpose, adducing her immersion in Buddhist philosophy to stress the interconnectedness of all things, via art, science and technology However, that beat is no longer that of the traditional music of the orderly spheres, but drums out the death march of great stars In Celtic mythology, say the works promoters, Tom Na H-iu is a place where the souls of the dead linger before being reborn, and the Celtic standing stones that inspired the artwork were believed to play a role in this spiritual transmigration It is clear that our primitive forebears not only observed celestial phenomena with remarkable precision, but also built their great stone monuments as a means of relating their earthly existence to cosmological events far beyond their reach Just as our Neolithic ancestors reached out to the stars, tuning into the apparently eternal patterns that ruled their seasonal lives, so Moris sculpture resonates to the beat of celestial time Mori is tapping into the puzzles of birth and death across enormous distances and deep time Not surprisingly, the greatest of them, such as Stonehenge, have served over the centuries as magnets for legends and mystical mumbo-jumbo Now, at the 2006 Singapore Biennale, she is showing Tom Na H-iu , a 3-metre-high radiant glass monolith that is plugged into cosmic radiation Perhaps most astonishing are the astronomical alignments that have been demonstrated in megaliths Prehistoric standing stones and rings, many erected more than 5,000 years ago, are awesome achievements Programmed to respond to the detection of different neutrinos in real time, the sculpture glows with colour-coded traces of ancient violence from remote regions of the cosmos She began by exploiting multimedia to fashion herself into a futuristic cyber-chick, transformed into a synthetic fantasy of kitsch sexuality, far removed from the ragged desires of our organic reality She has been collaborating with scientists to produce experiences that are startling in their technical sophistication, yet evoke both the inner world of our minds and the outer worlds of the cosmos Such astronomical megaliths serve as the inspiration for an installation by that most high-tech of artists, Mariko Mori Superficially — and it is easy to see such work as superficial — she seemed to belong to a late species of pop art, delighting ironically in the sheen of slick popular imagery The lives of our minds and bodies are integral to the processes that govern the Universe The microscopic is a mirror of the cosmic The reality being revealed by modern archaeoastronomy provokes almost as much wonder as the legends The translucent megalith is suffused by light from an internal LED, controlled by a computer, which is, in turn, linked to the Super-Kamiokande detector used in the Kamioka Observatory in Japan to detect neutrinos from outer space Three kinds of waves — alpha (blue), beta (pink) and theta (yellow) — were used to render visible endlessly variable arrays of mental processes With her earlier work it was difficult not to see these high claims as somewhat forced
 A power output of ∼350 mW (at 1.0 V) was obtained from a device with a total cathode area of only 1.42 cm 2 . Accordingly, polymer-electrolyte direct-methanol fuel cells are of increasing interest as possible alternatives to Li ion batteries  Here we demonstrate a thermally self-sustaining micro-SOFC stack with high power output and rapid start-up by using single chamber operation on propane fuel High energy efficiency and energy density, together with rapid refuelling capability, render fuel cells highly attractive for portable power generation  However, such fuel cells face several design challenges and cannot operate with hydrocarbon fuels of higher energy density Solid-oxide fuel cells (SOFCs) enable direct use of higher hydrocarbons , but have not been seriously considered for portable applications because of thermal management difficulties at small scales, slow start-up and poor thermal cyclability The catalytic oxidation reactions supply sufficient thermal energy to maintain the fuel cells at 500–600 °C A C 3 H 8 + O 2 + He gas mixture with a fixed volumetric ratio of 4:9:36 and a total flow rate of 368–490 ml min -1 (at STP) was supplied to the fuel cell A complete fuel-cell structure with BSCF + SDC as the cathode and a Ru + CeO 2 -treated anode was then examined for power output under thermally self-sustaining conditions Additional design efforts are also required to improve the overall fuel utilization and thereby the efficiency, which is presently estimated at ∼1% Although an external heat source has been employed in the present design for the start-up process, ultimately, self-initiation of the power generator may be possible using improved catalysts and a fuel that ignites on a catalyst at low temperature such as methanol, hydrogen or di-methyl ether An existing model of heat-recirculating reactors including heat losses to ambient and heat conduction along the tube walls was adapted to simulate the current apparatus Anode-supported, thin-film electrolyte fuel cells were fabricated as reported elsewhere using samaria-doped ceria (Sm 0.15 Ce 0.85 O 1.925 , SDC) as the electrolyte, Ni + SDC as the anode (SDC:NiO = 40:60 by weight), and a mixture of Ba 0.5 Sr 0.5 Co 0.8 Fe 0.2 O 3-δ (BSCF) 70 wt% + SDC 30 wt% as the cathode  At temperatures below 400 °C ( Fig. 3a , c ), Ni + SDC is essentially inert, whereas Ru + CeO 2 becomes active at temperatures just above 300 °C ( Fig. 3b , d ) Because of the presence of oxygen in the fuel stream, however, SCFCs are much less susceptible to carbon coking ( Supplementary Fig Because the two anodes share the same gas, no interconnect layer is necessary, fabrication is exceedingly simple and the stack can be made very compactly For practical applications, a voltage greater than 0.70 V is generally required and can be achieved by combining individual fuel cells into a stack Furthermore, the power densities are lower than reported previously for identical fuel cells because of the lower fuel-cell temperature (which results in higher electrode and electrolyte resistances), but the values are nonetheless higher than those attained from the most advanced DMFCs, typically 100–200 mW cm -2 (refs 17 , 18 ) Furthermore, while both catalysts produce, at temperatures below 650 °C, greater quantities of the deep oxidation products (H 2 O and CO 2 ), than the partial oxidation products (H 2 and CO), Ru + CeO 2 shows somewhat better selectivity for partial oxidation at the lower temperatures ( Fig. 3f ) Half cells (thin ceria electrolyte supported on porous Ni + SDC) were placed in a furnace, parallel to the gas flow direction; the cell temperature was monitored using a thermocouple protected with a thin-walled (0.4 mm) quartz tube and placed in direct contact with the centre of the anode surface Here we implement an anode-facing-anode stack configuration Here, an additional ∼10 µm of a porous layer of Ru + CeO 2 , ∼7 wt% Ru (crystalline, ∼500-nm particles) physically mixed with CeO 2 , was coated onto the anode surface (with the exception of a small centre region for making electrical contact) to enhance catalysis of propane partial oxidation at lower temperatures Here, the partial oxidation products H 2 and CO are hindered from readily transporting to the cathode Hydrocarbon-fuelled fuel cells often suffer from carbon deposition at the anode, especially under open-circuit conditions  Ignition of the partial oxidation reaction for the cell containing no additional catalyst layer occurred only when the furnace temperature was raised to 461 °C ( T cell = 680 °C); see Fig. 2a  In addition to its role as the electrochemical catalyst for H 2 and CO oxidation, the anode also acts as the non-electrochemical catalyst for partial oxidation of the hydrocarbon fuel to form these more electrochemically active species In contrast, a small amount of visible carbon was evident at the anode of our untreated half-cell after only ∼24 h of exposure ( T cell ≈ 600 °C) In contrast, an anode-facing-cathode dual-cell stack constructed without an interconnect layer resulted in near-zero OCV In conventional dual-chamber fuel cells, stacks are arranged in a cathode-facing-anode multilayer configuration, with interconnect layers separating anode and cathode chambers In the case of the Ru + CeO 2 -treated cell, no carbon deposition occurred on the Ni beneath the catalyst layer (we peeled off the top layer to inspect the anode), suggesting that Ru + CeO 2 is so active that the partial oxidation was completed within this exterior layer and no propane, in fact, reached the inner Ni + SDC anode In the self-sustaining mode, an open circuit voltage (OCV) of ∼0.7 V was obtained with peak power densities of 182 to 247 mW cm -2 and short-circuit current densities of 0.8–1.1 A cm -2 ( Fig. 4 ) In this configuration the highly reactive partial oxidation products (CO + H 2 ) are rapidly transported to the cathode, at which chemical oxidation is presumably catalysed Initiation of the partial oxidation reaction occurred at a furnace temperature of 311 °C (cell temperature, 618 °C), as compared to 461 °C without the catalyst It is this heat release that sustains the Ru + CeO 2 -treated cells at a temperature (500–580 °C) suitable for fuel-cell operation in the absence of external heating Model results show that the heat recirculation contributes about 280 °C of temperature rise Moreover, upon cooling the furnace to room temperature, partial oxidation was not extinguished even in the absence of external heating Not surprisingly, serious carbon coking, which completely destroyed the fuel cell, occurred when the Ni anode was exposed to pure propane ( Supplementary Fig Of the fuel choices available for portable power applications, propane is particularly attractive because, as a gas at temperatures down to -42 °C at ambient pressure, it can be easily supplied to a power-generation device, and as liquid phase under moderate pressure (∼10 atm at 25 °C), it can readily be stored with high energy density (6.3 kW h l -1 at 25 °C, about twice that of methanol) Our Ru + CeO 2 -treated half-cell was entirely free of carbon deposits after the 200-h exposure to C 3 H 8 + O 2 + He (at essentially OCV conditions) Quite significant is the fact that the electrolyte resistance, which is highly dependent on grain size and impurity content ( Supplementary Fig S1 ) S2 ), was responsible for ∼65% of the fuel-cell polarization losses ( Supplementary Fig S3 ) S4 ) S5 ) S6 ) Several technical hurdles remain and the inherently low efficiency of the single chamber design poses additional challenges, but these results demonstrate the viability of high-energy-density hydrocarbon fuels for portable power applications. Silver net and gold wires were attached to the electrode surfaces for current collection Single-chamber fuel cells (SCFCs) are a type of fuel cell, which utilize a fuel + O 2 mixture gas (diluted) as the same gas atmosphere for both the anode and cathode  Start-up was initiated by placing the cell directly into a preheated furnace (500 °C) The 11% increase in average peak power density from 247 to 275 mW cm -2 attained in the stacked configuration is due to the favourable gas transport pathways in the anode-facing-anode stack The ability of the fuel cell to withstand rapid thermal cycling was tested by directly inserting and removing the fuel-cell reactor from the high-temperature furnace (500 °C) multiple times The application of a Ru + CeO 2 catalyst layer had a significant impact on the thermal behaviour of the cells; see Fig. 2a  The cell maintained a temperature of 504 °C with the furnace turned off and left in the open position The cell so fabricated ( Fig. 1a ) was placed in a quartz tube reactor for thermal and electrochemical evaluation ( Fig. 1b ) The cell temperature rose rapidly, and after a short equilibration, the fuel cell was removed from the furnace and the thermal blanket applied The difference in thermal behaviour between the untreated and Ru + CeO 2 -treated half-cells can be understood in terms of the catalytic activity of Ni + SDC versus that of Ru + CeO 2 towards propane oxidation ( Fig. 3 ), as measured using powder samples in a standard catalytic reactor  The feed gas was composed of 40 ml min -1 C 3 H 8 , 90 ml min -1 O 2 and 360 ml min -1 He (all at standard temperature and pressure, STP, 298 K, 1 atm); this mixture has a fuel-to-oxygen ratio found elsewhere to be optimal for high fuel-cell power output, and an inert-to-oxygen ratio similar to air, so it is representative of fuel–air mixtures envisioned for practical applications The fuel cell did not exhibit any mechanical cracks or deterioration in performance The furnace temperature was raised or lowered in 25 °C increments, and the cell temperature recorded at each step after both the furnace and cell reached steady-state conditions The increase in power output was accompanied by an increase of the fuel-cell temperature, from 535 to 580 °C for a corresponding propane flow rate increase from 32 to 40 ml min -1  The latter two properties increased with increasing propane flow rate, although the OCV remained roughly constant ( Fig. 4a ) The OCVs measured here are lower than can be obtained from conventional dual-chamber fuel cells, but are typical of SCFCs in which imperfect selectivity of the electrodes results in some fuel oxidation at the cathode  The oxidation reaction is exothermic in nature (for example, C 3 H 8 (g) + 3/2O 2 (g) = 3CO(g) + 4H 2 (g), Δ H 550 °C = -206.96 kJ mol -1 ); the heat released raises the temperature of the fuel cells beyond that of the furnace in which they are placed  The performance of single-chamber SOFCs is based on the highly selective anode and cathode towards the gas mixture The reaction was sustained to somewhat lower temperatures on cooling, but was nevertheless extinguished below a furnace temperature of 361 °C ( T cell = 621 °C) The stack produced approximately double the voltage (1.44 V) and more than double the power of a single cell ( Fig. 4b ), enough to operate a 1.5-V MP3 player ( Supplementary Fig The temperature of a two-cell stack (described further below) exposed to similar conditions was ∼575 °C, almost identical to that of the single cell The time from cold-start to stable power output was typically less than 1 min, a competitive timescale for portable power This behaviour is achievable because the otherwise delicate seal of a conventional SOFC has been eliminated, because a thin-film electrolyte has been implemented, and because the operation temperature has been reduced to 500–600 °C This feature is an additional advantage of Ru + CeO 2 for fuel-cell operation This greater degree of activity towards propane oxidation results in greater heat release at low temperatures (300–500 °C; Fig. 3e ), as calculated from the propane conversion data ( Fig. 3c , d ) and the known enthalpies of the partial and total oxidation reactions (with total oxidation releasing more heat than partial oxidation) This temperature was maintained with excellent stability over the course of a 200-h test ( Fig. 2b ) Thus, careful control of the fabrication procedures to decrease the electrolyte resistance and improved design of reactor to improve OCV can be anticipated to increase the power output by as least a factor of two Thus, heat recirculation, along with thermal insulation and the Ru + CeO 2 catalyst, which is highly active at low temperatures, are all important ingredients for thermal sustainability in these small fuel cells ( Supplementary Fig Undesirable gas-phase transport between electrodes apparently also limits the power outputs of fuel cells configured with anode and cathode strips placed on the same side of a supporting electrolyte  We first investigated the feasibility of thermally self-sustained micro-SOFCs by measuring the thermal behaviour of anode-supported structures, both with and without the Ru + CeO 2 catalyst layer We used this heat to sustain the fuel-cell temperature in the absence of external heating When the reactor was better insulated by covering with a thermal blanket, the cell temperature increased to around 580 °C
 Arising from: Y However, abiotic methane produced experimentally and in other Precambrian greenstone settings has 13 C-depleted δ 13 C CH 4 values, as well as Δ 13 C CO 2 –CH 4 relationships that encompass the range measured for the inclusions by Ueno et al . — which suggests that an alternative, abiotic origin for the methane is equally plausible Isozaki Nature 440 , 516 – 519 ( 2006 ) ; Ueno et al . reply Ueno et al . contend that methane found in fluid inclusions within hydrothermally precipitated quartz in the Dresser Formation of western Australia (which is roughly 3.5 Gyr old) provides evidence for microbial methanogenesis in the early Archaean era Maruyama Y The authors discount alternative origins for this methane, suggesting that the range of δ 13 C CH 4 values that they record (−56 to −36‰) is attributable to mixing between a primary microbial end-member with a δ 13 C CH 4 value of less than −56‰ and a mature thermogenic gas enriched in 13 C (about −36‰) The conclusions of Ueno et al . about the timing of the onset of microbial methanogenesis might not therefore be justified. Ueno, K Yamada, N Yoshida, S Abiotic methane end-members in Precambrian Shield rocks extend to much lighter δ 13 C CH 4 values (−47 to −28‰)  Also, as noted by Ueno et al ., experimental studies indicate that abiotic synthesis using a Ni–Fe alloy catalyst may produce methane with a range of isotopic compositions (δ 13 C CH 4 values of −54 to −19‰ at 200–300 °C) that is similar to the range in the inclusions  Although those results have not been duplicated , they have not been disputed either Biosignatures that are mimicked by abiotic processes need to be analysed closely to evaluate not only signs of life in rocks from the early Earth but also the search for life on other planets. But abiotic methane could have been synthesized during interaction of migrating hydrothermal fluids with ultramafic rocks elsewhere in the system in the presence of either Ni–Fe alloy or other mineral catalysts, and transported to the site of quartz deposition , so the absence of suitable catalysts immediately adjacent to the fluid inclusion-bearing quartz would not preclude an abiotic origin Furthermore, the experimental range would encompass the larger value the authors infer for primary inclusions (Δ 13 C CO 2 –CH 4 52‰) However, the range of δ 13 C CH 4 for abiotic hydrocarbons is larger than that used in their comparison In fact, hydrothermal abiotic methane synthesis has been confirmed with Ni–Fe alloy and other potential mineral catalysts  Indeed, Ueno et al . explain the inferred thermogenic origin of methane in the secondary inclusions using migration from surrounding rocks The authors also contend that the lack of C 2 + compounds in those inclusions is in agreement with a microbial origin; however, C 2 + hydrocarbons were not detected during methane synthesis in abiotic experiments either, so such reactions can also produce methane with a low C 2 + /(C 1 +C 2 + ) ratio (0.01) The key criteria used by Ueno et al . to establish a microbial origin for methane in the inclusions from the Dresser Formation are therefore equally consistent with an abiotic origin, and their conclusion about the antiquity of the onset of microbial methanogenesis should be viewed with caution The range of isotopic values for abiotic methane shown in Fig. 2c of Ueno et al . differs distinctly from those from thermogenic and microbial sources, and does not encompass the methane in their fluid inclusions The values of ΔC CO 2 –CH 4 measured by Ueno et al . in their inclusions (34–52‰; see their Supplementary Table 2) span a range that is identical to, or even smaller than, those produced in abiotic synthesis experiments (33–66‰)  Therefore, neither an absence of C 2 + nor isotopic compositions can distinguish between microbial and abiotic origins for this data set, even when both factors are considered together Ueno et al . also discount an abiotic source on the grounds that Fe–Ni alloys and other catalysts for Fischer–Tropsch-type synthesis reactions would not have existed in the surrounding rocks at conditions prevailing during silica precipitation
 Furthermore, InvC induces chaperone release from and unfolding of the cognate secreted protein in an ATP-dependent manner Here we show that InvC, an ATPase associated with a Salmonella enterica type III secretion system , has a critical function in substrate recognition Our results show a similarity between the mechanisms of substrate recognition by type III protein secretion systems and AAA + ATPase disassembly machines. Proteins are thought to travel this pathway in a largely unfolded manner, and a family of customized cytoplasmic chaperones, which specifically bind cognate secreted proteins, are essential for secretion These systems mediate the transfer of bacterial virulence proteins directly into the host cell cytoplasm Type III protein secretion systems are essential virulence factors of many bacteria pathogenic to humans, animals and plants  Affinity chromatography binding assay Purified GST-SicP–SptP 1–158 complex was incubated with purified polyhistidine-tagged wild-type InvC or its mutants (InvC V28M , InvC K165E or InvC L376P ) in a binding buffer (20 mM Tris-HCl pH 8.0, 150 mM NaCl, 2 mM MgCl 2 , 0.05% Tween 20, 0.001% BSA) in the presence of 100 µM ATP or ATP-γS for 30 min at 4 °C After gentle rocking at 4 °C for 1 h, samples were separated into supernatant and beads by centrifugation After the beads had been washed to remove unbound complex, wild-type InvC or InvC K165E was added to the beads in the releasing buffer (20 mM Tris-HCl pH 8.0, 150 mM NaCl, 2 mM MgCl 2 , 0.05% Tween 20, 0.001% BSA) in the presence of 100 µM ATP or ATP-γS After the beads had been washed to remove unbound proteins, the samples were subjected to SDS–PAGE All the samples were subjected to SDS–PAGE and proteins were detected by western blotting At several time points, different amounts of subtilisin (10 -5 to 10 -8  U) were added to the samples and incubated on ice for 30 min Chaperone release assay Purified SicP-GST–SptP 1–158 complex was absorbed with glutathione-Sepharose 4B FastFlow at 37 °C for 1 h EGFP fluorescence assay Purified GST-SicP–SptP 1–158 –EGFP complex was incubated with wild-type InvC or the catalytic InvC K165E mutant in assay buffer (20 mM Tris-HCl pH 8.0, 150 mM NaCl, 2 mM MgCl 2 , 100 µM ATP, 0.05% Tween 20, 0.001% BSA) at 37 °C for different durations and the fluorescence (excitation wavelength 488 nm, emission wavelength 538 nm) in the samples was measured in a fluorimeter ( Molecular Devices ). Glutathione-Sepharose 4 FastFlow beads were added to the mixtures and incubated for 1 h at 4 °C GST-SicP in complex with SptP 1–158 , SptP 1–543 or the chimaeric protein SptP 1–158 –EGFP or SptP 1–161 –PhoA 35–472 was purified from E. coli carrying the respective bicistronic expression plasmids as described previously  Methods Bacterial strains Escherichia coli XL-1 Blue ( Invitrogen ) was used for DNA manipulations and E. coli BL-21 (DE3) was used for the expression of recombinant proteins Monomeric and hexameric forms of purified InvC were separated by gel-filtration chromatography as described previously  Plasmids Bicistronic plasmids encoding GST-SicP–SptP 1–158 , GST-SicP–SptP 1–543 , GST-SicP–SptP 1–158 –EGFP and GST-SicP–SptP 1–161 –PhoA 35–472 were constructed by standard recombinant DNA techniques with the expression plasmid pGEX-KG as a backbone Plasmids expressing GST-SptP 161–543 (ref. 18 ), polyhistidine-tagged InvC and its mutant forms , or polyhistidine-tagged CdtA, a subunit of the cytolethal distending toxin , have been described previously Protease susceptibility assay Purified SicP–SptP 1–543 complex was incubated with wild-type InvC or InvC K165E in reaction buffer (20 mM Tris-HCl pH 8.0, 150 mM NaCl, 2 mM MgCl 2 , 0.05% Tween 20, 0.001% BSA, 100 µM ATP or 100 µM ATP-γS, as indicated) at 37 °C Protein tyrosine and alkaline phosphatase assays The purified SicP–SptP 1–543 complex or SptP 161–543 was mixed with the purified hexameric form of wild-type InvC or the catalytic InvC K165E mutant at a molar ratio of 1:10 and incubated at 37 °C for 30 min; the tyrosine phosphatase activity was measured with a RediPlate 96 EnzChek tyrosine phosphatase assay kit ( Molecular Probes ) in accordance with the manufacturers recommendations Proteins were detected by western blotting with monoclonal antibodies directed against the different relevant proteins Purification of recombinant proteins Recombinant polyhistidine-tagged monomeric and hexameric InvC were purified as described elsewhere  Supernatant was precipitated with trichloroacetic acid The purified SicP–SptP 1–158 –PhoA 35–472 was mixed with the purified hexameric form of wild-type InvC or the catalytic InvC K165E mutant as described above and the phosphatase activity was measured with the substrate p -nitrophenyl phosphate with the use of standard procedures The resulting samples were subjected to SDS–PAGE, and proteins were detected by western immunoblotting The Salmonella enterica serovar Typhimurium SB1404, which carries a Δ sicP - sptP deletion, was constructed by allelic exchange as described previously  To stop the protease reaction, 1 mM PMSF was added to each tube A central component of TTSSs is an envelope-associated organelle known as the needle complex  Addition of GroEL to the complex in the presence of InvC K165E did not result in any change in the mobility of SptP, indicating that the GroEL trap alone does not affect the folding of SptP ( Supplementary Fig. 1 ) Addition of InvC resulted in a release of SicP ( Fig. 4a ) but had no effect on the fluorescence activity of the SptP 1–158 –GFP fusion protein ( Fig. 4b ), indicating that InvC was unable to unfold the tightly packed GFP domain Addition of InvC to the SicP–SptP complex in the presence of ATP resulted in a significant increase in the susceptibility of SptP to protease ( Fig. 3a ) Addition of InvC, but not its catalytic mutant InvC K165E , significantly changed the migration of SptP ( Supplementary Fig. 1 ) Addition of wild-type InvC to the SicP–SptP complex resulted in a drastic decrease in the phosphatase activity of SptP ( Fig. 3b ) After secretion, the chaperones must release their cognate substrate because they remain within the bacterial cytoplasm Although the TTSS-associated ATPases have not previously been considered to be members of this protein family , the ability of InvC to organize in hexameric rings, to disassemble protein complexes and to recognize and unfold protein substrates closely resembles equivalent activities of AAA + ATPase disassembly machines  Although the TTSS-associated chaperones maintain the binding domains of their cognate secreted proteins in a non-globular state , the enzymatic domains of the secreted proteins remain folded because they exhibit full activity  Although these ATPases are essential for type III secretion (TTS), their specific role in this process is unknown Another TTSS-associated ATPase has been also reported to bind TTSS chaperones  Both the monomeric and hexameric forms of InvC were able to interact with the SicP–SptP complex, although the latter appeared to do so more efficiently ( Fig. 1c ) Containing more than 20 proteins, type III secretion systems (TTSSs) are among the most complex protein secretion machines known  Equivalent results were obtained with the GST-SicP–SptP 1–543 complex (data not shown) For example, the GAP domain region immediately adjacent to the chaperone-binding domain seemed highly disordered  Furthermore, InvC had no effect on the activity of SptP 161–543 , a mutant that lacks the chaperone-binding domain ( Fig. 3b ), indicating that this domain is required for InvC to catalyse the unfolding of SptP However, a loss-of-function mutant (InvC L376P ) that retained its catalytic, membrane and oligomerization activities, did not bind the SicP–SptP complex ( Fig. 1e ) However, secretion of some proteins is inefficient or does not occur at all , indicating that certain domains are not permissive for TTS because they cannot be unfolded by the ATPase If unfolding is a requirement for type III protein secretion, the inability of InvC to unfold GFP should prevent its secretion through the TTS pathway Immediately before secretion, TTSS-associated chaperones must dissociate from the chaperone/effector complex In addition to the chaperone-binding domain, specific elements required for secretion have been also localized N-terminal of this domain of the secreted protein  In addition, the better-ordered portion of the GAP domain stabilizes an extended-loop region at the N terminus of the PTP domain In contrast, addition of InvC in the presence of ATP-γS or addition of the catalytically inactive mutant InvC K165E did not increase the susceptibility of SptP to protease ( Fig. 3a ) In contrast, addition of the catalytically inactive InvC K165E mutant had no effect on the phosphatase activity of SptP ( Fig. 3b ) In contrast, fusion of the targeting signals of SptP to PhoA, which is thermodynamically less stable , resulted in a chimaera that was efficiently unfolded by InvC ( Fig. 4d ) and was efficiently secreted by the S. typhimurium TTS pathway ( Fig. 4e ) In contrast, the release of SptP 1–158 was not observed when the complex was incubated with the catalytically inactive InvC K165E or in the presence of ATP-γS ( Fig. 2 ) In the presence of wild-type InvC and ATP, SptP 1–158 was released from its association with SicP ( Fig. 2 ) Indeed, some features of the crystal structure of the enzymatic domains of SptP are consistent with this hypothesis Instead of eluting at a position corresponding to the size of the SicP–SptP 1–543 complex, SptP migrated with a broader profile and a significant proportion of the input migrated at the position of the ‘trap’, indicating the binding of non-native forms of SptP to GroEL D87K ( Supplementary Fig. 1 ) InvC also interacted with the GST-tagged chaperone alone but did not interact with the effector domains of SptP (SptP 161–543 ) ( Fig. 1d ) InvC is the ATPase associated with the TTSS encoded by Salmonella enterica serovar Typhimurium ( S. typhimurium ) within its pathogenicity island 1 (ref. 2 ), which mediates bacterial entry into mammalian cells and is essential for the virulence of this bacterial pathogen  It is therefore possible that, once the GAP domain has been unravelled, the loss of support for this extended-loop structure could facilitate the unravelling of the entire PTP domain Like other members of the TTSS-associated ATPase protein family , InvC has extensive primary amino acid sequence similarity to the β-subunit of F 0 F 1 -ATPases Mutations that affected either the membrane-binding (InvC V28M ) or catalytic activities (InvC K165E ) did not affect the ability of InvC to bind the SicP–SptP complex ( Fig. 1e ) Other essential components of TTSSs include an ATPase and a family of customized chaperones that specifically bind a ∼100-amino-acid domain at the amino terminus of their cognate secretion substrates  Our results also revealed remarkable parallels between InvC and the function of triple AAA + ATPases, a family of proteins involved in a variety of biological processes  Our results show a central role for the TTSS-associated ATPases in hitherto poorly understood steps of protein secretion, such as substrate recognition and chaperone release from, and unfolding of, type III secreted proteins ( Fig. 4f ) Secretion and translocation domains of type III secreted proteins are able to mediate the secretion of heterologous proteins  SptP is a SPI-1 TTS effector protein that posses two enzymatic activities: a Rho-family GTPase-activating protein (GAP) activity located immediately adjacent to the chaperone-binding domain, and a protein tyrosine phosphatase located at the carboxy terminus ( Fig. 1a ) SptP–GFP was not secreted into the culture supernatant of S. typhimurium , indicating that the inability of InvC to unfold the SptP–GFP chimaera renders this protein non-competent for secretion ( Fig. 4c ) Taken together, these results indicate that InvC can not only remove the chaperone but can also induce the global unfolding of SptP Taken together, these results indicate that InvC interacts with the chaperone and chaperone/effector protein complex through a domain located at its C terminus and therefore must play a critical role in substrate recognition by the TTS machine The full-length SptP (SptP 1–543 ) or its chaperone-binding domain (SptP 1–158 ) bound to its glutathione S -transferase (GST)-tagged cognate chaperone SicP were purified to homogeneity and their interaction with purified InvC was probed by affinity chromatography The GST-SicP–SptP 1–158 –GFP protein complex was isolated and the ability of InvC to unfold the GFP domain was then examined by monitoring the GFP fluorescence The GST-SicP–SptP 1–543 or GST-SicP–SptP 1–158 complex specifically interacted with InvC but not with the irrelevant protein CdtA ( Fig. 1b , d ) The interaction occurred both in the presence of ATP and in the presence of ATP-γS, indicating that the ability of InvC to hydrolyze ATP is not essential for substrate recognition ( Fig. 1b ) The similarities seem to extend to essential features of the substrate recognition process, because TTSSs and AAA + machines recognize a poorly conserved set of unstructured short peptide signals located at the N terminus of the target proteins The size constraints imposed by the diameter of the central channel of the TTSS-associated needle complex indicates that proteins travelling the TTS pathway must do so in a largely unfolded manner  The tyrosine phosphatase domain is the most distant from the chaperone-binding region, from which it is separated by the GAP domain ( Fig. 1a ) Their peripheral association to the cytoplasmic side of the bacterial membrane coupled to their ability to form hexameric rings , indicated the possibility that these ATPases might provide a link between the secretion substrates and the TTS machinery Therefore, this mutant most likely defines the InvC substrate-binding domain These results are consistent with the hypothesis that InvC induces significant conformational changes in SptP and that this function requires its catalytic activity These results indicate that InvC is able to recognize both the SicP chaperone and the chaperone/secreted protein complex, and that its multimeric form appears to be more efficient at substrate recognition These results indicate that InvC is capable of removing SptP from its chaperoned state and that this activity requires ATP hydrolysis These results indicate that proteins that are destined to be secreted by the type III pathway must be ‘primed’ for the ATPase-catalysed unfolding This domain wraps around homodimer chaperone pairs and is maintained in a non-globular conformation that retains significant secondary structure  This mutant is located at the C terminus of InvC within a domain that has been predicted to face the cytoplasm  This observation indicated that unfolding of these domains must occur before secretion This organelle is traversed by a central channel 28 Å in diameter, which is thought to serve as a conduit for the proteins transiting this secretion pathway  To test this hypothesis we fused the TTS targeting signals of SptP to the green fluorescent protein (GFP), which is known to have a very compact and stable fold TTS of virulence factors and the translocation of substrates into triple AAA + machines might therefore have a common evolutionary origin and might consequently share mechanistic features. We also tested the unfolding of SptP by examining its ‘transfer’ to a GroEL ‘trap’ mutant (GroEL D87K ), which captures non-native proteins but is unable to release them  We first probed conformational changes in SptP by a protease susceptibility assay with the use of a monoclonal antibody that recognizes the C-terminal domain of SptP We further explored this issue with a different assay We have previously isolated loss-of-function mutations in InvC, which allowed the identification of specific residues important for its catalytic activity, membrane association, and oligomerization  We incubated the SicP–SptP 1–543 complex with InvC or InvC K165E in the presence of GroEL D87K and subjected the mixture to gel-filtration chromatography We investigated whether the interaction of the SicP–SptP complex with InvC resulted in the release of the chaperone from its cognate substrate We reasoned that if InvC induces global unfolding of SptP, these changes should significantly affect its enzymatic activity We tested this hypothesis by examining the secretion of SptP–GFP into culture supernatants of S. typhimurium  We therefore examined whether InvC could mediate the unfolding of SptP upon its release from its cognate chaperone SicP We therefore investigated the potential role of InvC in TTS substrate recognition by examining its interaction with the type III secreted protein SptP bound to its cognate chaperone SicP We therefore probed the conformational changes of SptP during its interaction with InvC by assaying its tyrosine phosphatase activity Wild-type InvC or the catalytically inactive mutant InvC K165E were incubated with purified GST-SicP–SptP 1–158 complex in the presence of ATP or ATP-γS and the dissociation of the complex was examined with an affinity chromatography assay
 A subsecond intense ‘spike’ of γ-rays during a giant flare from the Galactic soft γ-ray repeater, SGR 1806–20, reopened an old debate over whether some short GRBs could be similar events seen in galaxies out to ∼70 Mpc (refs 6–10 ; redshift z ≈ 0.016) Gamma-ray bursts (GRBs) divide into two classes : ‘long’, which typically have initial durations of T 90 2 s, and ‘short’, with durations of T 90 2 s (where T 90 is the time to detect 90% of the observed fluence) Here we report a correlation between the locations of previously observed short bursts and the positions of galaxies in the local Universe, indicating that between 10 and 25 per cent of short GRBs originate at low redshifts ( z 0.025). In contrast, the origin of short bursts has remained mysterious until recently Long bursts, which on average have softer γ-ray spectra , are known to be associated with stellar core-collapse events—in some cases simultaneously producing powerful type Ic supernovae  Shortly after that, localizations of a few short GRBs (with optical afterglows detected in two cases ) have shown an apparent association with a variety of host galaxies at moderate redshifts  A clear positive correlation is revealed, which is even stronger when the galaxies are restricted to earlier morphological types (specifically Sbc and earlier; that is, T-type ≤ 4) A combination of differing progenitor masses and beaming could plausibly give rise to such a broad luminosity function for NS–NS binary mergers  A cross-correlation plot between these GRBs and the (1,070) PSCz galaxies with heliocentric recession velocity, v , ≤2,000 km s -1 is shown in Fig. 1  A handful of short GRBs were localized to smaller error boxes by the Interplanetary Network and the Beppo-SAX and HETE-II satellites, but these only showed an absence of bright candidate host galaxies or afterglows  Although previous giant flares were bright enough to have been seen by BATSE perhaps as far as the Virgo cluster, the SGR 1806–20 event would have been detectable out to several tens of megaparsecs, appearing very much like a short-hard GRB An alternative possibility is that some or all of the low-redshift short bursts have the same progenitors as the recently discovered short-burst population at redshifts z 0.1 At first sight, the most likely explanation of our result is that we are detecting a low-redshift population of short bursts associated with SGRs Figure 2 shows that the observed signal could be explained by a correlated component representing between 6% and 12% of BATSE bursts (1 σ  range) Further discussion of the BATSE instrumental characteristics is provided in Supplementary Information  Furthermore, although a positive correlation signal is seen when restricting the burst sample to only those with T 90 0.5 s, a somewhat stronger signal is seen with the T 90 0.5 s short bursts, which is again surprising given that the spike from SGR1806–20 had a duration of around 0.2 s Furthermore, the rate implied by our work of several bursts per year within 100 Mpc is in good agreement with recent calculations of the rate density of such events, based on the observed double neutron star population in the Milky Way  However, SGRs being the remnants of short-lived massive stars, it is then rather surprising that a stronger correlation is seen with earlier-type galaxies, which include some galaxies with little recent star formation However, the cross-correlation function is not ideal for this purpose as errors in different bins are not independent, and it makes no direct use of known BATSE instrumental characteristics If both cosmological and local short-GRBs arise from NS–NS coalescence, then their association with at least intermediate-age and possibly old stellar populations is to be expected (owing to the inspiral lifetime of such binaries) If even a proportion of short bursts originate in nearby galaxies, then despite poor localizations they may show a measurable spatial correlation with the positions of low-redshift galaxies In fact, this is likely to be an underestimate, as our catalogue certainly does not contain all the galaxies in this volume, just the infrared-bright ones, and there remains a thin zone of avoidance around the Galactic plane, and a region unsurveyed by IRAS that the PSCz survey does not cover (amounting to about 16% of the sky) In order to optimize the search for a correlation signal, we compute Φ , the sum of all burst-galaxy pairs weighted by the probability that they could be seen at the observed separation (or greater) if they were truly associated, and further weighted inversely by the burst error-circle size: Φ = ∑  i All bursts   ∑  j All galaxies    1 ɛ  i ∫ θ ij ∞  1 2π ɛ  i exp - θ 2 2 ɛ  i 2 d θ where θ ij is the separation between the i th burst and the j th galaxy, and ɛ  i is the error circle (statistical and systematic ) of the i th burst position Inevitably it becomes harder to detect correlations as the galaxy (and presumably detected burst) volume density decreases with increasing distance, and the angular size of large-scale structure projected on the sky also reduces Next we attempt to estimate the proportion of bursts that are associated with nearby galaxies On the other hand, the recent observation of the ‘hypergiant’ flare from SGR 1806–20 (refs 6 , 7 ) re-ignited interest in the idea that some short bursts could be distant SGR flares Our results are broadly consistent (discussed further in Supplementary Information ) with previously reported upper limits for the proportion of BATSE short bursts originating at low redshifts  Recently, however, afterglow detections for three short GRBs have associated them with galaxies at redshifts z ≈ 0.2: the X-ray afterglow of GRB 050509B was close to a bright elliptical galaxy at z = 0.225, suggesting physical association ; GRB 050709 produced an optical afterglow locating it to a late-type galaxy at z = 0.16 (ref. 11 ); and GRB 050724 exhibited an afterglow located in another elliptical galaxy at z = 0.257 (ref. 12 ) Repeating this procedure in bins of recession velocity v = 2,000–5,000 km s -1 and v = 5,000–8,000 km s -1 , we continue to find significant correlations (at nearly the 2 σ  level in each bin) The cumulative proportion of correlated bursts as a function of limiting cut-off velocity is shown in Fig. 3  The energetics of these bursts, and their association with a variety of host galaxies (including those with only old stellar populations) provide support for the view that some fraction of short GRBs arise from the coalescence of neutron-star/neutron-star (NS–NS) binaries  The figure also shows, as expected, that the long-duration bursts are uncorrelated with these galaxies The presence of such a large local population of NS–NS merger events would be encouraging for their detection prospects with upcoming gravity wave detectors. The PSCz galaxy redshift survey makes an appropriate comparison data set for the all-sky BATSE data because, being IRAS-selected, it suffers less from incompleteness at low Galactic latitudes than other nearby redshift surveys (although other catalogues show similar results, as described in Supplementary Information ) The range of percentage correlated bursts conservatively suggests that a total proportion of between 10% and 25% of BATSE bursts originate within ∼100 Mpc The satellite-based γ-ray detector CGRO/BATSE triggered on roughly 500 short-duration bursts during its nine-year lifetime The spread of simulated results around Φ 0 allows us to test the null hypothesis that there is no correlation between the positions of bursts and galaxies They also explain the intriguing finding that short-burst positions on the sky show evidence for a weak auto-correlation signal  This null hypothesis is rejected at the 99.9% level, confirming the indications of the cross-correlation function This provides strong confirmation that the correlation seen in the low-redshift bin was not simply a chance coincidence This sample includes most galaxies within about 25 Mpc, encompassing the local supercluster, and specifically the Virgo, Fornax and Ursa Major clusters This would have the merit of simplicity, but as we show in Fig. 4 , the higher-redshift bursts so far detected would have been rather brighter than any detected by BATSE if they had occurred at z 0.02 Thus a rather broad intrinsic luminosity function, perhaps comparable to that of the long-duration bursts, is required to accommodate reasonable numbers of both local and cosmological examples within the BATSE sample To do this, we constructed many more artificial short-burst data sets, this time with both a random component and a component correlated with the galaxies from the PSCz galaxy catalogue with v ≤ 2,000 km s -1 and T-type ≤ 4 (that is, with a ‘host’ selected at random from the catalogue and with positions smeared according to the real error circles from BATSE) To quantify the significance of the observed value of Φ , we also compute Φ 0 , which is the mean of a large number of simulated random burst distributions (each with the same number of positions as the number of bursts under consideration, the same positional errors, and distributed on the sky according to the known BATSE sky exposure map ) correlated against the same set of (T-type ≤ 4) PSCz galaxy positions Unfortunately, the (1 σ ) positional uncertainties for these bursts were typically many degrees, giving limited information to help identify even their host galaxies, let alone their progenitors We considered all 400 T 90 2 s bursts with localizations better than 10 degrees from the BATSE catalogue (4B(R); ref. 21 together with web supplement cited therein)
 A government spokesman in New Delhi says the steering committee will prepare a road map for future cooperation in science and technology before Chinese president Hu Jintao visits New Delhi in November A second study will focus on biological and behavioural markers specific to different subtypes of autism Also under discussion is the creation of a Sino-Indian nanoscience forum, and collaborative projects in agriculture and genomics Although no single cause of the condition has been identified, it has been linked to immune-system activity that causes inflammation in the brain And in the third study, NIMH researchers will assess chelation therapy, which removes heavy metals from the blood Autism comes under three-pronged attack The possibility that an antibiotic could help treat autism is the basis for one of three new US clinical studies of this brain disorder Baltimore said he was “gratified” by the move Collaboration aims knockout blow for mouse genes A massive international project has been launched to generate at least one mutation in each of the more than 20,000 genes of the mouse Gene-sifting tests get regulatory treatment Complex diagnostic tests that sift through data on multiple proteins and genes are facing formal regulation by the US Food and Drug Administration (FDA) If they show improvements in areas such as communication skills, a larger, placebo-controlled study will be launched India and China are expected to pool their respective strengths in computer software and hardware in the hope of emerging as a regional leader in information technology Indian science minister Kapil Sibal and his Chinese counterpart, Xu Guanhua, signed the agreement on 7 September in Beijing It revives an 18-year-old pact that has previously made little progress It will be the largest international research collaboration in biology since the Human Genome Project Mbeki has reportedly asked his deputy president, Phumzile Mlambo-Ngcuka, to set up a ministerial council to oversee the governments anti-AIDS efforts Methods include knockout technology, in which specific genes are deleted, and treating mice with compounds that cause mutations at random Minocycline is being considered as a potential treatment for autism because of its anti-inflammatory powers Most activities will be Internet-based Other notables include fractals expert Benoit Mandelbrot and genome entrepreneur Craig Venter Prizes of US$1,000, for instance, will be given to children who come up with the best question about molecular science. →  http://web.mit.edu/molecularfrontiers China and India agree on joint technology push In a fresh initiative to boost cooperation in science and technology, India and China have agreed to set up a ministerial-level steering committee jointly chaired by the science ministers of the two countries Prominent signatories included Nobel laureate David Baltimore, virologist Robert Gallo and leading South African physicians such as Hoosen Coovadia of the University of KwaZulu-Natal Researchers at the National Institute of Mental Health (NIMH) in Bethesda, Maryland, who announced the trial on 6 September, will initially test the antibiotic in 10 children Science superstars weigh in to sell chemistry to kids It doesnt look like a run-of-the-mill attempt to engage the attention of youngsters Seven of the 23 members of the scientific advisory board are Nobel prizewinners Some 12,000 mouse mutants have so far been generated in different labs South Africa responds to critics of its AIDS policies The South African government last week moved to curb the activities of its controversial health minister, Manto Tshabalala-Msimang, three days after 82 scientists worldwide called for her removal in a letter to President Thabo Mbeki The agency says the regulations are needed because the tests are becoming more numerous and are increasingly used in serious conditions. “It is important for the companies and labs making the tests to clearly understand the regulatory requirements in place so that the tests they develop are as safe and effective as possible,” says Daniel Schultz, director of the agencys Center for Devices and Radiological Health The aim is to coordinate the production of mutant mice , like the obese mouse shown here, and make them available to researchers The draft guidelines are open for 90 days for public comment The FDA had previously said that in principle it could regulate such assays, but it wasnt until 5 September that it finally issued draft guidelines The Molecular Frontiers initiative, launched at the First European Chemistry Congress in Budapest late last month, is a global think-tank of scientific heavyweights who will monitor the frontiers of molecular — mostly chemical — sciences, and generate ways of stimulating the interest of children The project was announced on 7 September by the European Commission, the US National Institutes of Health and Genome Canada, which together will provide US$72 million The scientists were spurred to write the letter after attending a major AIDS conference in Toronto, Canada, last month, where the South African government exhibition featured garlic, lemons and African potatoes — “with the implication that these dietary elements are alternative treatments for HIV infection”, the scientists complained The tests, known as multivariate index assays, are relatively new and are typically developed and carried out by individual laboratories The work will allow geneticists to more accurately dissect gene function in a mammal that shares 99% of its genes with humans, and so better understand the genetic basis of human disease. They are used for a range of conditions including Alzheimers disease and breast cancer They charged that she had “undermined” HIV science by promoting nutrition-based AIDS treatments, and was thus an “embarrassment” This is sometimes used by families of autistic children, but its effectiveness has not been studied in detail
 Ago1, a component of the RNAi effector RISC/RITS complex, associates with target transcripts and RNA polymerase II Alternatively, they may act by interactions between siRNA and nascent transcript  Furthermore, transcription by exogenous T7 polymerase is not sufficient Here we show that in fission yeast ( Schizosaccharomyces pombe ), chromatin modifications are only directed by RNAi if the homologous DNA sequences are transcribed In plants , fission yeast , ciliates , flies and mammalian cells , short interfering RNAs (siRNAs) also induce DNA or chromatin modifications at the homologous genomic locus, which can result in transcriptional silencing or sequence elimination . siRNAs may direct DNA or chromatin modification by siRNA–DNA interactions at the homologous locus  RNA interference (RNAi) acts on long double-stranded RNAs (dsRNAs) in a variety of eukaryotes to generate small interfering RNAs that target homologous messenger RNA, resulting in their destruction This process is widely used to ‘knock-down’ the expression of genes of interest to explore phenotypes  Truncation of the regulatory carboxy-terminal domain (CTD) of RNA pol II disrupts transcriptional silencing, indicating that, like other RNA processing events , RNAi-directed chromatin modification is coupled to transcription. After incubation at 25 °C for 30 min, immunoprecipitations were performed as above Analysis was performed two to four times at each temperature, and average values from these experiments are presented Antibodies against H3K9me2, Swi6 and HA were used as described previously  Blots were developed with enhanced chemiluminescence reagents ( Amersham Biosciences ) Cells were washed twice in PEMS; cell pellets were frozen at -20 °C (ref. 30 ) ChIP with an RNase step ChIPs were performed with a monoclonal antibody against HA (12CA5) and using methods previously described, with the following exceptions Chromatin immunoprecipitation ChIP was performed as described previously except for the following modifications: cells were converted to spheroplasts by incubation for 25 min at 10 8 cells ml -1 in PEMS (100 mM PIPES pH 7, 1 mM EDTA, 1 mM MgCl 2 , 1.2 M sorbitol) containing 0.4 mg ml -1 zymolyase-100T at 36 °C Cytology Immunofluorescence was performed as described , cells were fixed for 15–20 min in 3.7% freshly prepared formaldehyde for staining Deletion of the 17 heptad repeats from Rpb1 and 3 × HA tagging of Ago1 was achieved by standard methods with the indicated primers ( Supplementary Table 3 ) DNA oligonucleotides of 24/20 nucleotides or 22 nucleotides in length complementary to the dh repeat or the ura4 + Stu I/ Eco RV region were used as markers Immunoprecipitations were performed as described previously  Methods Standard techniques Standard procedures were used for fission yeast growth, genetics and manipulations Microscopy was performed as described . Phosphor screens or films were exposed for a minimum of 3 h Quantification of bands was performed with the Eastman Kodak EDAS 290 system and 1D Image Analysis software  Quantification of bands was performed with the Eastman Kodak EDAS 290 system and 1D Image Analysis software  Reverse transcriptase polymerase chain reaction (RT–PCR) Total RNA was prepared from strains grown in YES medium at 25 or 32 °C and RT–PCR was performed as described previously  RNA immunoprecipitation RNA immunoprecipitation was performed as described  Samples were resuspended in 50% formamide; 35 µg of total RNA was loaded on a 17.5% denaturating polyacrylamide gel containing 7 M urea. 32 P-labelled DNA probes complementary to centromeric dh repeats or the ura4 + Stu I/ Eco RV region were generated with a Random Primed DNA-labelling kit ( Roche ) Secondary antibodies conjugated with fluorescein isothiocyanate ( Sigma-Aldrich ) or Alexa488 ( Molecular Probes ) were used at dilutions of 1:100 or 1:1,000 Small RNA preparation and detection Exponential-phase yeast cells were subjected to RNA extraction with TRIZOL ( Invitrogen ) and precipitation with propan-2-ol The crosslinking time was reduced from 15 min to 5 min when RNase treatment was performed The following antibodies were used: sheep anti-Cnp1 antiserum (dilution 1:300), mouse 12CA5 anti-HA (dilution 1:30) The KAN marker of the 3 × HA Ago1 tag was subsequently swapped to the nourseothricin (NAT) marker with indicated primers ( Supplementary Table 3 ) The probes were hybridized to the membranes overnight at 42 °C in a rotating oven and washed twice with 2 × SSC, 2% SDS at 50 °C The ura4 and ura4-DS/E PCR products were separated on 1.5% agarose gels and poststained with ethidium bromide Thereafter the standard ChIP procedure was followed Western blotting and immunoprecipitations Antibodies for western blotting were diluted in PBS containing Tween as follows: anti-HA and anti-Rpb1 ( monoclonal ARNA-3 from Research Diagnostics detecting residues 797–811 of Rpb1), diluted 1:300; anti-unmodified RNA pol II ( 8WG16 ), 1:1,000 (in 5% milk) When an RNase treatment step was included, cross-linked chromatin from the same experiment was treated with either 7.5 U of RNase A and 300 U of RNase T1 ( RNase A/T1 cocktail ; Ambion ) or an equivalent volume of RNase storage buffer (10 mM HEPES pH 7.2, 20 mM NaCl, 0.1% Triton X-100, 1 mM EDTA, 50% v/v glycerol) Yeast strains S. pombe strains used are listed in Supplementary Table 2  A mutation ( rpb7-1 ) in Rpb7, a small pol II subunit, leads to a loss of these transcripts and siRNAs (K.E., unpublished observations) A second strain (Ter-M5 ura4 ) contains a cis -acting mutation within the terminator, allowing 75% of transcripts to traverse the downstream 280-bp region of the gene ( Fig. 1a ) Ago1 also showed sh-ura4-280 siRNA and transcription-dependent association with the ura4 gene ( Fig. 4a , bottom) Ago1 associated with centromeric outer repeats in wild-type, but not dcr1Δ , cells ( Fig. 4a , top) Ago1, but not Rad21, associated with centromeric otr transcripts, but not with control transcripts ( act1 ), in wild-type cells, and not in cells lacking siRNAs ( dcr1Δ ) ( Fig. 4b ) Alternatively, Ago1-bearing siRNAs may bind homologous nascent transcripts and in so doing recruit chromatin-modifying activities through the Ago1-containing RITS and/or Rdp1-containing RDRC complex  Alternatively, the RNAi machinery may target nascent transcripts and cause chromatin modification on templates homologous to loaded siRNAs  Argonaute (PAZ/PIWI domain) proteins enter RISC (or RITS) complexes and use loaded siRNAs to guide RISC/RITS to target RNAs At fission yeast centromeres and the silent mating type locus, non-coding RNAs are generated by the transcription of both strands of related repeats  Because of this and the inherent self-enforcing nature of the process, it is difficult to determine whether nascent transcripts are required to mediate RNAi-directed chromatin modifications, and what additional interactions are involved Both strains also contain ura4-DS/E at the ura4 + locus, which is fully transcribed but lacks the 280-bp region homologous to the sh-ura4-280 trigger, thus providing a convenient internal control  Chromatin immunoprecipitation (ChIP) was used to assess the levels of H3K9me2 modification on the Ter + and Ter-M5 ura4 genes relative to ura4-DS/E  Components of RITS and RNA-dependent RNA polymerase (Rdp1) are known to associate with, and act in cis on, this silent chromatin  Consistent with previous reports , immunolocalization shows that HA-Ago1 is concentrated at centromeres in the nucleus, as shown by localization with centromere-specific CENP-A Cnp1 ( Fig. 4e , and Supplementary Fig Consistent with this was the detection of increased levels of cen1:ura4 + transcripts ( Fig. 3b , right) and decreased levels of H3K9me2 associated with centromere repeats ( Fig. 3c ) Expression of a synthetic hairpin RNA homologous to a 280-base-pair (bp) region located within the ura4 + gene ( sh-ura4-280 ) induces Dicer-dependent transcriptional silencing of ura4 + along with H3K9me2 of ura4 chromatin and recruitment of Swi6 (ref. 7 ) H3K9me2 was detected only on Ter-M5 ura4 , and only in strains expressing sh-ura4-280 ( Fig. 1c ). ura4 siRNAs were detected only in strains containing the sh-ura4-280 construct ( Fig. 1d ) However, centromeric transcripts do not accumulate appreciably in rpb1-11 compared with dcr1Δ , and centromeric siRNAs are readily detected as in the wild type ( Fig. 3d ) However, Chp1 (a RITS component) and Swi6 bind H3K9me2 (ref. 23 ), and Rdp1 (and the RDRC (RNA-directed RNA polymerase complex)) interacts with RITS and requires Swi6 for chromatin association  However, siRNAs homologous to a genes promoter can induce transcriptional silencing, resulting in the modification of DNA and/or chromatin . siRNAs may hybridize to DNA and thereby recruit DNA/chromatin modifying activities that effect silencing  If opening the two DNA strands is sufficient, then an exogenous RNA polymerase might allow siRNAs access to homologous chromatin If pol II has a specific function in mediating RNAi-mediated chromatin modification, then cells bearing a defective pol II might display aberrant silencing of marker genes at centromeres Immunoprecipitates of HA-Ago1 were found by western blot analyses to contain pol II (Rpb1); reciprocal to this, HA-Ago1 was detected in immunoprecipitates of pol II In addition, no H3K9me2 or Swi6 could be detected on T7:ura4 chromatin ( Fig. 2c , and Supplementary Fig In addition, this association was reduced in strains carrying a truncated pol II CTD ( rpb1-11 ) ( Fig. 4d ) In cells containing the Ter + ura4 gene, truncated ( ura-T ), but not full-length ( ura4-FL ), transcript is detected in the presence or absence of sh-ura4-280 ( Fig. 1b ) In plant and mammalian cells siRNAs homologous to the open reading frame of a gene results in post-transcriptional silencing, degrading transcripts by means of RNAi In Saccharomyces cerevisiae the deletion of up to 16 of the 26 CTD heptad repeats from pol II results in compromised RNA polymerase functions  In Ter-M5 cells, full-length ura4 transcript is lost in the presence of sh-ura4-280 but expression of ura4-DS/E remains unaffected ( Fig. 1b ) In this strain (Ter + ura4 ) the transcriptional terminator is inserted within an artificial intron, so that more than 99% of transcripts are terminated before the 280-bp region homologous to the sh-ura4-280 trigger Indeed, it is known that RNA processing and export seem to be orchestrated with respect to ongoing transcription  It is possible that the passage of RNA polymerase II (pol II) during transcription itself, by opening chromatin, provides access for siRNAs to underlying DNA sequences, thus allowing siRNA–DNA interactions  Lack of RNAi-directed chromatin modification of the T7:ura4 template may reflect the absence of features normally associated with endogenous RNA pol II transcription Many different factors associate with pol II through its CTD during distinct stages of transcription ; the pol II complex might provide a scaffold that promotes interactions between Ago1/RITS-borne siRNA and target pol II transcripts, leading to the efficient modification of occupied chromatin (see model in Supplementary Fig Microarray expression profiling indicated that none of the known genes involved in RNAi-directed chromatin silencing are significantly affected in rpb1-11 cells in comparison with the wild type, and few genes were affected to any great extent ( Supplementary Table 1 ) Moreover, plants have even evolved a distinct RNA polymerase (pol IV) required for RNAi-dependent chromatin silencing of certain repeat sequences . Nascent transcripts may direct the RNAi machinery to the homologous locus, induce dimethylation of the surrounding chromatin on lysine 9 of histone H3 (H3K9me2) through Clr4, recruiting Swi6 (HP1) and thereby silencing transcription  Opening DNA by T7 pol transcription does not allow modification of the target chromatin to occur Our data indicate that RNAi-directed chromatin modification is another example of an RNA processing event that occurs co-transcriptionally, and offer an explanation for the apparent paradox that RNA pol II is not only required for transcriptional activity but is pivotal in transcriptional silencing RNA pol II is responsible for the generation of fission yeast centromere repeat transcripts that are processed by RNAi into homologous siRNAs RNAi components might require intact pol II to fully engage a chromatin-associated nascent transcript, or intact pol II might be specifically required to synthesize a transcript in a form that can effectively associate with RNAi components S1a ) S1b ) in cells expressing sh-ura4-280 homologous siRNAs ( Fig. 2d ), although histone H3 is present on the T7:ura4 gene ( Supplementary Fig S1c ) S2 ) S3 ) T7 and RNA pol II transcription and the resulting transcripts differ in many respects; regardless of this, transcription of target chromatin alone is not sufficient to mediate RNAi-directed chromatin modifications on homologous chromatin T7 pol might deal with impeding nucleosomes differently, or T7 pol transcripts might not be packaged or processed in the same manner as RNA pol II transcripts, rendering them immune to RNAi T7 polymerase was constitutively expressed from the adh1 promoter in the presence or absence of sh-ura4-280 ( Fig. 2a , and Supplementary Fig T7:ura4 transcripts are detected only in cells expressing T7 polymerase Taken together, these data show that, in fission yeast, RNAi requires the transcription of a homologous target to direct chromatin modifications The association of Ago1 with centromeric chromatin was sensitive to RNase ( Fig. 4c ) The construct expressing sh-ura4-280 was introduced into both strains, and transcription of ura4 + , H3K9me2 modification of ura4 chromatin and recruitment of Swi6 were assessed in wild-type strains in the presence and absence of the sh-ura4-280 hairpin The CTD of the large subunit of pol II (Rpb1) contains multiple conserved YSPTSPS heptad repeats, the phosphorylation state of which regulates the binding of various mRNA processing factors, thus coupling mRNA processing to transcription  The expression of sh-ura4-280 did not reduce the level of T7:ura4 transcripts significantly ( Fig. 2b ), although RNAi is active because ura4 siRNAs are readily detected ( Fig. 2d ) The fact that truncation of the pol II CTD affects RNAi-directed chromatin modifications and association of Ago1 with centromeric repeats, without noticeably affecting centromere repeat transcription or siRNA generation, indicates that pol II transcription might facilitate the conversion of RNAi signals into chromatin modification The phenotype of rpb1-11 is clearly distinct from that of rpb7-1 , which is defective in centromeric transcription and siRNA production, causing a failure of transcriptional silencing (K.E., unpublished observations) These form dsRNAs, which are cleaved by Dicer (Dcr1) into siRNAs and then loaded into the Ago1 (Argonaute)-containing RITS (for RNA-induced initiation of transcriptional silencing) complex, which mediates RNAi  This indicates that although RNAi remains active it is unable to induce chromatin modifications efficiently on homologous sequences This indicates that the CTD of pol II might act downstream of RNAi to stabilize interactions between RNAi components, the nascent transcript and possibly the pol II holoenzyme to induce chromatin modifications This indicates that transcripts generated by, or associated with, a specific RNA polymerase might be required This interaction also required siRNA-loaded RITS because Ago1 and pol II do not immunoprecipitate together from cells lacking Dicer ( Fig. 3e ) This strain was slow-growing but viable at all temperatures tested and was clearly defective in its ability to silence centromeric ura4 + and ade6 + markers as revealed by increased growth on plates lacking uracil (- ura) and the appearance of white ade + colonies, respectively ( Fig. 3b , left) Thus, expression of a hairpin target homologous to downstream DNA sequences does not affect Ter + ura4 , whereas Ter-M5 ura4 transcripts are repressed by sh-ura4-280 expression Thus, RNAi can induce chromatin modifications at a homologous locus only if transcripts traverse a region identical in sequence to the hairpin trigger and the resultant siRNAs Thus, the CTD truncation does not seem to cause a substantial general defect in transcription To determine whether Ago1 associates with chromatin targeted for silencing by RNAi, ChIPs were performed with anti-Ago1 antibodies or HA-Ago1 To determine whether this hairpin-induced chromatin modification requires a homologous transcript, a strain containing a modified ura4 + gene with an efficient transcription terminator module immediately upstream of the 280-bp ura4 target region was used  To examine this, a strain was constructed with 17 of the 28 CTD heptad repeats deleted and simultaneously epitope-tagged ( rpb1-11 , see Methods; Fig. 3a ) To test this, the ura4 transcription unit was placed downstream of the bacteriophage T7 promoter ( Fig. 2 )
 Analysts expect more consolidation between the half-a-dozen existing exchanges in Europe as trading in carbon dioxide emissions hots up. Big carbon exchange Two of Europes main markets for carbon emissions have announced plans to merge Biogen Idec of Cambridge, Massachusetts, had planned to produce the multiple sclerosis drug Tysabri at its facility in Oceanside, California, but had to withdraw the drug in February because of safety concerns Change of plan Genentech, the California biotechnology company, is paying $408 million to take over a pharmaceutical factory left idle as the result of a drug suspension Genentech, which has research collaborations with Biogen Idec, says it will start making Avastin — a treatment for colon cancer — at the 430-employee plant in 2007 If the public offering succeeds, the company will join a small handful of other listed European companies with an interest in stem-cell research Stem Cell Sciences, which was founded in 1994 in Australia by biologist Peter Mountford, employs 30 people and has research interests in Japan as well as in Scotland and Australia Stem-cell float Edinburgh-based research company Stem Cell Sciences says it will seek a listing on Londons Alternative Investment Market later this month The combination of Paris-based Powernext Carbon and the European Climate Exchange (ECX), which is based in Amsterdam and does most of its business in London, is expected to create the continents largest emissions exchange The company says it is taking a $50-million loss on the sale The company wants to raise £10 million (US$18 million) by the proposed stock-market float
 Anomalous X-ray pulsars (AXPs) are slowly rotating neutron stars with very bright and highly variable X-ray emission that are believed to be powered by ultra-strong magnetic fields of 10 14 G, according to the ‘magnetar’ model  Here we show that XTE J1810 - 197 emits bright, narrow, highly linearly polarized radio pulses, observed at every rotation, thereby establishing that magnetars can be radio pulsars The flux at all radio frequencies is approximately equal—and at 20 GHz XTE J1810 - 197 is currently the brightest neutron star known The radio pulsations that have been observed from more than 1,700 neutron stars with weaker magnetic fields have never been detected from any of the dozen known magnetars The X-ray pulsar XTE J1810 - 197 was revealed (in 2003) as the first AXP with transient emission when its luminosity increased 100-fold from the quiescent level ; a coincident radio source of unknown origin was detected one year later  There is no evidence of radio emission before the 2003 X-ray outburst (unlike ordinary pulsars, which emit radio pulses all the time), and the flux varies from day to day These observations link magnetars to ordinary radio pulsars, rule out alternative accretion models for AXPs, and provide a new window into the coronae of magnetars. A timing model accounting for every turn of the neutron star during the period 17 March–7 May yields barycentric P = 5.54024870 s ± 20 ns on MJD 53855.0 and Pdot; = (1.016 ± 0.001) × 10 -11 , with root-mean-square residual σ  = 5 ms Additionally, magnetars have mechanisms and locations for pair creation that are not available to ordinary pulsars  Also, a 1.4-GHz Parkes observation shows linear polarization that tracks the total-intensity pulse profile at a level of 65% Also, it has been proposed that the observed optical and infrared emission from magnetars is coherent emission from plasma instabilities above the plasma frequency , and even that radio or submillimetre emission could be so generated  At present we cannot rule out a non-pulsed component At the VLA, S 8.4 shows variations by similar factors within 20 min Because most of the energy of the twisted field is contained within a few stellar radii, the frequencies of coherent emission from magnetars could be greater than those of ordinary pulsars, possibly accounting for the flat radio spectrum of XTE J1810 - 197 Following this, the onset of radio emission could have been delayed until the plasma density declined to a value much less than is generally found in persistent magnetars For example, the pulsar PSR J1718–3718, with L 1.4 ≈ 4 mJy kpc 2 and P = 3.3 s, has inferred surface dipole magnetic field strength B = 7 × 10 13  G, higher than that of one magnetar (for XTE J1810 - 197, B ≈ 2.4 × 10 14  G) From Keplers third law, with assumed neutron star mass 1.4 M circdot; , the upper limits on the minimum companion mass lie in the range ∼0.003–0.03 M circdot; for orbital periods in the range 2 h–5 min, effectively ruling out the existence of any Roche lobe-filling star orbiting this AXP However, about 10% of ordinary pulsars have specific radio luminosity L 1.4 ≡ S 1.4 D 2 ≲2 mJy kpc 2 , the approximate limit for XTE J1810 - 197 before the outburst However, at ν ≳9 GHz diffractive interstellar scintillation plays a significant role  However, further observations (see Table 1 ) reveal large fluctuations: at Parkes, S 1.4 can vary by factors of about two from one day to the next, although no significant variations are detected within observing sessions lasting up to four hours In addition, a recently discovered class of radio-bursting neutron stars includes at least one object whose field strength is comparable to that of some magnetars; it too has X-ray properties resembling those of XTE J1810 - 197 in quiescence  In February 2006 at the VLA we measured S 1.4 = 12.9 mJy, a considerable increase in flux over a period of two years In ordinary pulsars, the required electron–positron pairs can be produced only on the open field-line bundle at high altitude above the surface where electric potentials of ∼10 12  V accelerate particles that emit gamma-rays with energies exceeding the pair-creation threshold In the original detection of radio emission from XTE J1810 - 197 with the Very Large Array (VLA) in January 2004, S 1.4 = 4.5 mJy (ref. 3 ) In these conditions, electrons and positrons are accelerated to γ ∼10 3 , and pairs can be created either via resonant cyclotron scattering of thermal X-rays in the strong magnetic field or thermally in the heated atmosphere at the footpoints of the twisted field lines Its assumed isotropic radio luminosity up to 42 GHz is about 2 × 10 30  erg s -1 , compared to the spin-down luminosity of about 2.4 × 10 33  erg s -1  Magnetar activity is generated by the sudden or continual twisting of the external field lines into a non-potential configuration that maintains, by induction, strong long-lived currents flowing along them  No pulsar signal was detected in average-pulse analyses, corresponding to S 1.4 ≲0.2 mJy from these observations made in 1997 and 1998 (see Table 1 ) Observable magnetospheric radio emission requires a coherent mechanism, inferred to be curvature radiation whose characteristic frequency 3 γ 3 c /4π r falls in the gigahertz range for secondary particle Lorentz factors γ ∼10 3 and radii of curvature r of the order of the light-cylinder radius r lc = cP /2π or smaller Ordinary pulsars have mean α = -1.6, and fewer than 10% have α -0.5 (ref. 13 ) Pulsations with period P = 5.54 s were easily detected, with period-averaged flux density S 1.4 = 6 mJy and a narrow average profile with full-width at half-maximum of 0.15 s ( Fig. 1 ) Radiation from XTE J1810 - 197 is highly polarized: 89 ± 5% of the total-intensity 8.4-GHz flux measured at the VLA is linearly polarized Radio emission as currently observed from XTE J1810 - 197 was evidently not present during the historical quiescent X-ray state that persisted for at least 24 years before the outburst  The delay in pulse arrival times measured between 2.9 and 0.7 GHz implies an integrated column density of free electrons between the Earth and XTE J1810 - 197 of 178 ± 5 cm -3 pc The extrapolated radio spectrum of XTE J1810 - 197 exceeds its observed infrared fluxes , so that the radio and infrared emission may or may not have the same origin The hard and soft X-ray fluxes are now decaying exponentially with timescales of ≈300 and ≈900 days, respectively , while strong radio emission is still observed more than three years after the X-ray turn-on The maximum size of any extended emission is 5 × 10 15 ( D /3 kpc) cm, based on the 0.25-arcsec resolution of our VLA image at 8.4 GHz, from which we measure a position for XTE J1810 - 197 of right ascension = 18 h 09 min 51.087 s ± 0.001 s and declination = -19° 43′ 51.93″ ± 0.02″, in the J2000.0 equinox The radio spectrum of XTE J1810 - 197 is quite flat over a factor of 60 in frequency These are composed of ≲10-ms-wide sub-pulses with peak flux densities up to ≳10 Jy and follow a differential flux distribution approximated by dlog N = -dlog S , with no giant pulses like those observed from the Crab pulsar  These flux variations are completely inconsistent with expectations from interstellar scintillation and are thus, remarkably for a pulsar, intrinsic to XTE J1810 - 197 This affords the possibility that magnetar radio emission is generated on closed field lines and beamed into a wide range of angles This limit is 10% of the flux from the pulsar since 2004, suggesting that the extraordinary radio emission from XTE J1810 - 197 turned on as a result of the events accompanying the X-ray outburst observed in early 2003 (ref. 2 ) This more rapid variation at high frequencies is confirmed in pulsed observations with the Green Bank Telescope (GBT) This raises the prospect that XTE J1810 - 197 could have generated familiar radio pulsar emission before 2003, marking a plausible direct link between ordinary pulsars and magnetars This source has X-ray properties apparently similar to those of XTE J1810 - 197 in quiescence  Together with a model for the Galactic distribution of free electrons , the distance to XTE J1810 - 197 is D ≈ 3.3 kpc (here we use ≈ to indicate a quantity known to within about a factor of two or better), consistent with X-ray- and optically-derived estimates of 2.5–5 kpc (refs 8–10 ) We cannot exclude that the handful of known magnetars employ this mechanism, because their long periods imply small active polar caps and narrow beams that may miss the observer for random orientations We detected individual pulses from virtually every rotation of the neutron star (see Fig. 2 ) We have analysed archival raw survey data from the two telescope pointings nearest to the pulsar position We have made independent simultaneous measurements of flux at multiple frequencies (see Table 1 ), all of which are consistent with spectral index α ≳ - 0.5 , where  We infer that radio emission will cease after the transient X-ray components (and implied magnetospheric currents) have subsided, but it is difficult to know whether this transition is imminent, or will take many years. We observed the position of XTE J1810 - 197 (ref. 4 ) on 17 March 2006 for 4.2 hours with the Parkes telescope at a central frequency ν = 1.4 GHz, using parameters identical to those used in the Parkes multibeam pulsar survey  We therefore also searched the archival radio data for bright individual pulses, but found none We use this to set constraints on any putative companion to the AXP by requiring the light-travel-time across the projected orbital semi-major axis to be less than σ  With an unremarkable average flux at ν ∼1 GHz (here we use ∼ to indicate a quantity known to within about an order of magnitude), by ν ≳20 GHz XTE J1810 - 197 is brighter than every other known neutron star With required charge densities greatly exceeding the co-rotation value for a dipole field, an electric potential of ∼10 9  V is established and self-regulated by pair creation XTE J1810 - 197 is located within the boundaries of the Parkes multibeam pulsar survey area 
 Although his last book, Is It In Your Genes? (Cold Spring Harbor Laboratory Press, 2004), was targeted at health professionals, The Strongest Boy in the World is more in the vein of his earlier ones, being aimed at a broad, general audience But he doesnt address questions such as how we draw the line between genetic traits or tendencies that can be used in screening for fitness for employment and those that cannot But he is cautious: “It would be foolish and wrong to suggest that one group of people is in some way genetically superior to other groups.” He does suggest, however, that some people, in additional to other qualities, “may have been born with gene variants that by chance support their goals” But theres no question how Reilly feels about this technology. “I side squarely with those who favor the rapid, safe development of genetically modified groups Drugs that inhibit the myostatin gene are currently being studied to alleviate the muscle-wasting symptoms of diseases such as cancer and AIDS, but it is only a question of time before such drugs are used for enhancement as well as treatment Elite athletes devote most of their lives to trying to do just that.” Is it so different from steroid doping, or hiring an expensive trainer or orthopaedic surgeon? Or, for that matter, exercising? Should a child born with a natural mutation that greatly enhances athletic ability be allowed to compete? “There is no question that genes greatly influence athletic ability ... gender is determined by genes, and there is a significant gender gap in athletics.”  There is also, Reilly points out, a gap in athletic ability between some ethnic groups For the geneticist, Reilly presents a balanced, positive view of ethical and social issues in genetics, and an entertaining background in history, geography and economics, and the way these fields interface with modern genetics and genomics General readers may find the science a stretch, but the effort will be amply rewarded with a better understanding of some of the most important issues currently facing our society He cites specific examples of genetic variants that can or should have an effect on athletic performance He even sympathizes with those who fear multinational agriculture companies taking over the world at the expense of small farmers He then analyses some of the work on genetically modified corn, addressing a topical issue that could have profoundly disturbing implications for ecology and food safety — or that could lead to fantastic gains in the war on hunger He writes about corns place in the human economy, its domestication and breeding, and what we have learned about its genetics I think it could be the most important positive event for the environment in history.”  The final section deals more specifically with the implications of genetic and reproductive technologies for our society In four more engaging essays, Reilly goes on to explore human origins, race, longevity and intelligence, in each case looking carefully at the influence of genetics, and what our understanding of genetics means for our view of ourselves Instruction about basic principles of genetics is minimal, with a ‘knock-out’ mouse being defined in terms of a transgenic mouse, for readers who know what the latter is It isnt that Reilly gives new perspectives, but rather that he presents a rich, fascinating history and a broad view of the science that seasoned geneticists think about every day Ive often tried to convince my colleagues across campus that genetics should be a part of every undergraduates education Kenyan athletes, who largely come from ethnic groups representing only 0.05% of the worlds population, have won 14 of the past 16 Boston marathons, and it isnt just due to diet, tradition and altitude Missing from Reillys treatment is a deeper look at genetic mechanisms No book makes this case more clearly than The Strongest Boy in the World . On this topic, Reilly is not judgemental: “I am not sure where I stand on the whole issue of efforts to ‘enhance’ performance Physician, scientist, lawyer and chairman of healthcare company Interleukin Genetics, Philip Reilly has written five books on human genetics Reilly addresses not only the obvious topics such as stem-cell biology, preimplantation genetic diagnosis, and forensics, but also what we can learn about history through genetics (tracing US president Thomas Jeffersons genes, for example), and how genetics has come to pervade our art and language Reilly delves into broad fields of biology, society and history, clarifying the idea of ‘race’, but rather muddying the term ‘family’ Reilly describes, in limited detail, specific enzyme variants that seem to confer a benefit in endurance events, and others that may be advantageous in sprinting Reilly does not ignore the arguments against the use of genetically modified foods Reilly moves on to a broad-ranging discussion of athletic ability and the extent to which it might be influenced by heredity as well as the environment Reilly sees a time when gene testing may be part of a physical examination for professional athletes, predicting who is most likely to succeed and who might be at risk of premature death Reillys treatment of corn is typical of his approach to other organisms The boy had a mutation in the myostatin or growth differentiation factor 8 (GDF-8) gene, which suppresses muscle growth The child was an extreme variant, with quadriceps more than six standard deviations above the mean and an exceptionally low body-fat content The first part of the book explores what it means, in the light of our knowledge of genomics, to be human The second part of the book, on diseases, is a random walk through five different genetic conditions The Strongest Boy in the World is a wonderful tour of genetics, genomics and stem-cell biology The third part of the book is an investigation of dogs, cats, mice, corn and rice, what genetics has meant for them, and what these organisms have meant for the development of modern genetics The title essay, “The strongest boy in the world”, refers to a child in Germany born into a family known for exceptional strength This allows Reilly to explore different aspects of medicine, different disease aetiologies, different modes of therapy, and the complex ethics and sociology of conditions such as deafness, in which non-hearing parents may actually want to have non-hearing children Throughout the book, each chapter stands alone; this results in some repetition of ideas, but it has the tremendous advantage that the reader can dive into any section of interest and feel at ease Trinucleotide repeats are introduced as more or less incidental to Huntingtons disease, rather than as part of a set of more than a dozen disorders with an astoundingly similar underlying mutation mechanism that involves rapid changes in highly unstable stretches of DNA
 Estimates of this density jump obtained using free-oscillation eigenfrequencies give low values of 0.25–1.0 g cm -3 , whereas a method using the amplitude ratio of core-reflected phases yielded values of 0.6–1.8 g cm -3 (refs 14 , 15 , 16 –17 ) Here we analyse properties of waves precritically reflected from the Earths inner core (PKiKP phases) that show significant variability in amplitude, consistent high-frequency content and stable travel times with respect to a standard Earth model  Most seismological models of the Earth describe the inner-core boundary as sharp and simple , although experimental data requiring the presence of a thin transition layer at the bottom of the outer core have been reported  Such a mosaic may be composed of patches in which the transition from solid inner to liquid outer core includes a thin partially liquid layer interspersed with patches containing a sharp transition. The density jump at the inner-core boundary—an important parameter determining gravitational energy release and constraining the compositional difference between the inner and outer core—is also not well known The transition from the Earths solid inner core to liquid outer core is the location where the inner core grows and from which compositional convection in the outer core originates  We infer that the data are best explained by a mosaic structure of the inner cores surface A Butterworth three-pole zero-phase filter in the frequency band 1–3 Hz was used for the filtering Although summation of seismic records performed using certain methods may lead to some distortion of sought amplitudes, the appropriate estimates have also been confirmed as quite reliable  Application of stacking and methods of f – k analysis to seismic data are frequently affected by errors in timing, locations and different magnitudes of events By using non-seismological (ground truth) precise information on explosive source parameters we exclude errors caused by uncertainties in locations, times and energy of seismic sources Explosive sources are also much simpler than earthquakes and characterized by a lower intensity of S waves Following ref. 18 , we used generated pseudoarrays with replacement of records to calculate the samples Frequency–wavenumber ( f – k ) analysis Stacking array data are proved as an effective means for extracting weak signals, successfully applied to the problem of PKiKP detection  Having performed this preliminary processing, we initiate a recursive grid search over two-dimensional, cartesian slowness vectors s x and s y to find the combination giving the maximum beam power in a predefined time window In this case, test-site dimensions (about 30 km) are small compared to the epicentral distances, which for the purposes of inversion enables us to consider the array of sources as a small aperture array, and hence seismic waves as plane waves Low variation in observed PKiKP periods gives another reason for making use of the definition to reduce PKiKP amplitudes from explosions of different magnitudes carried out at the same test site Methods Data selection The use of UNE records eliminates the necessity of allowing for peculiarities due to different radiation patterns of seismic events Modelling To calculate PKiKP synthetic seismograms, we first derive the source function from full-wave modelling of the first arrival of P (if detected, the PcP waveform is modelled too), using the explosive source model  Our data set includes more than 200 short-period and broadband digital seismic records from 23 stations located in Eurasia, Australia and North America (see Supplementary Fig. 1 ) Reduction of amplitudes Using the classical definition of a body-wave magnitude as the decimal logarithm of a phases amplitude-to-period ratio, the measured PKiKP amplitudes are reduced to a magnitude of 5.9, corresponding to the majority of the processed explosions The beam power is defined as r.m.s. amplitude in a 1.5-s time window with linear beams The first search is run with bounds -0.1 to 0.1 s km -1 using an increment of 0.004 s km -1 for both slowness components The modelling error is well below PKiKP amplitude error bounds, which are between 15% and 37%. The P phase is also used to adjust for different source magnitudes by means of r.m.s. amplitudes of individual traces The resulting average of the reduced PKiKP amplitudes generated by the 31 Semipalatinsk explosions with magnitudes between 5.8 and 6.1 is 3.30 ± 0.93 nm, compared with 3.96 ± 1.53 nm before reduction, which decreases the scatter by 39% The sensitivity of selected seismic channels meets the requirement of being able to provide undistorted registering of at least a few tenths of nanometres in the seismic waveform frequency range from 0.5 to 5 Hz Thus, the expression A reduced = A measured × 10 (5.9- m ) is used, where m is the body-wave magnitude of the explosion whose PKiKP amplitude is being reduced To calculate error bounds for the array estimates, a bootstrap-type resampling procedure was used To perform the analysis independently of a UNEs origin times and possible errors of station clocks, band-pass-filtered traces were aligned on the first arrival of a P wave by means of a cross-correlation technique We consider multiple observations as one of the most important factors contributing to the reliability of the PKiKP detection, and have disregarded any possible PKiKP waveforms appearing on a single record from a station that registered only one explosion We had enough data for four stations that recorded an array of powerful Semipalatinsk explosions carried out 30° to 95° away We selected stations that recorded three or more explosions carried out at the same test site, or records of an explosion simultaneously registered by a number of stations or an array We then proceed by trial and error to select ICB parameters/structure providing the best fit of the observed PKiKP waveform with correlation coefficient exceeding 0.9 (see Supplementary Fig. 3 ) Although the PKiKP amplitude predicted by PREM for 89° is at least 30 times smaller than for 6°, the measured PKiKP amplitudes at NWAO were 2.65 ± 0.40 nm Although the resulting signal-to-noise ratio on single filtered traces varies from 1.2 to 3.5, the PKiKP waveform is recognizable on each individual channel by eye Another essential and common feature of all the detected PKiKP waveforms is their high-frequency content, with typical periods 0.6–0.83 s (75% are 0.7 s) Application of different narrow- and wide-frequency band filters in the range 0.5–5 Hz sometimes did not improve the PKiKP signal-to-noise ratio ( Fig. 2 ) As no dramatic deviations are registered in the P and PcP phases on the appropriate fragments of the NRN record, and PKiKP waveforms generated by this same explosion are clearly detected on three-component records from other stations, the influence of the seismic source can be excluded as a factor causing such non-observation At distances up to 35°, the scatter of PKiKP amplitudes (reduced to M b = 5.9) is a factor of six, while amplitude variability before reduction is expected to be only a factor of two to three for explosions with magnitudes 5.8–6.1 Being a weak phase frequently obscured by seismic coda, PKiKP arrivals are hard to detect and thought to be anomalously large if observed (for example due to focusing), or require array data processing for unambiguous identification (such as linear or phase-weighted stacking of vertical channels or velocity filtering ) Besides, ScS has longer periods and mainly horizontal particle motion Considering the changeable nature of the reflections, we favour the second, more local, approach, with patches from tens to hundreds of kilometres. Estimates of characteristic lateral dimensions of mosaic patches would require a great number of reflection points probing the inner cores surface Figure 4 features 59 direct body-wave measurements of PKiKP amplitudes, four source-array estimates (see Supplementary Table ), and recently published PKiKP amplitude evaluation for 89.5° Here we revisit the issue of the fine structure of the ICB and its reflection properties, using a new reliable data set of precritical PKiKP waveforms observed between 6° and 90° following underground nuclear explosions (UNEs) in the USSR, USA and China (see ‘Data selection’ in Methods) However, despite the quite low root-mean-square (r.m.s.) coda level of 4.7 nm on a filtered vertical component in the vicinity of the expected arrivals, we could not identify a PKiKP waveform on three-component NRN records of available Novaya Zemlya explosions However, none of the trial curves shows good agreement with experimental data (see PKiKP amplitudes in the so-called transparent zone 50–70°, or the tenfold discrepancy between our PKiKP body-wave measurement at 89.2° and the reduced-amplitude estimate at 89.5° where PREM theoretical amplitude is negligible) However, the lower bound can be assessed on the basis of the body waves seismic velocity and observed PKiKP wavelengths, which yields a figure of 10 km However, the ratio can be effectively improved by band-pass filtering; this revealed, on vertical components, waveforms dominating in the 40-s time interval around the PKiKP arrival time predicted by PREM ( Fig. 1 ) In addition, any pronounced local topography must comply with appropriate viscosity constraints and inner-core differential rotation  In addition, such focusing D″ structure can hardly provide amplifications exceeding 50% In contrast to P waves, which have a set of equally powerful frequency maxima, all PKiKP spectrograms show a single accentuated frequency (see Supplementary Fig. 2 ), with other source frequency maxima damped In contrast to the non-observation of PKiKP at 31.38° on NRN records, this velocity filtering was effective when detecting PKiKP on records from station KEV located 31.4° away from the Semipalatinsk array of explosions It takes slight variations in the patches properties to account for our PKiKP data—up to 5 km in thickness, and up to 8% P-wave velocity jump above the inner-core velocity, which is within the 10% uncertainty for the latter parameter Just like mosaic patches, the regions of homogeneous reflection coefficient can be defined by uniform ICB fine structure (sharp transition or with a layer) and physical composition Local ICB complexities such as topography or lateral dependency of the ICB reflection coefficient due to changes in ICB fine structure and/or composition seem more credible and are in line with recent ICB studies appealing to reverberations instead of focusing/scattering effects Meanwhile, our data set is quite sparse and has limited geographical coverage, precluding any bigger regions characterized by the presence of a liquid layer in the transition Meanwhile, PKiKP pulses are detected by band-pass filtering of NRN records after weaker UNEs performed elsewhere (Semipalatinsk and PNE (peaceful nuclear explosion) examples in Fig. 2 ), which is evidence for PKiKP observability despite any possible unfavourable local station factors or local geophysical conditions that might prevent such observations Misidentification of seismic phases from the diagram is ruled out, as all nearby phases have significantly higher slownesses attenuated by the wavenumber filter No such waveforms were observed on horizontal components Non-uniform boundary freezing and compositional convection are the best possible mechanisms to explain the inner cores surface patchiness Patches with a liquid transition layer amplify high-frequency PKiKP arrivals, while reflections from sharp discontinuity patches result in weak or no PKiKP observations unless the focal mechanism is favourable and the body-wave magnitude of the event is big enough to generate a strong observable PKiKP phase Phase stacking of vertical components for 12 such weaker UNEs also revealed no PKiKP waveform on the sum trace PKiKP observations have not become routine and are sometimes either extremely unusual, owing to the surprisingly low magnitude of seismic sources (body-wave magnitude, M b 5.0), or questionable, because of significant PKiKP travel-time residuals with respect to standard models (up to 12 s)  Precritical PKiKP waveforms are sensitive to the composition and fine structure of the inner-core boundary (ICB) Precritical PKiKP waveforms on a single vertical channel are basically hidden by the intensive oscillations of seismic coda, making it hard to obtain a good signal-to-noise ratio Propagation of Lg waves is blocked by a marine passage of the seismic path, and we would not expect anomalously early arrivals of ScS to contaminate our PKiKP window because of the use of explosions Rather, specific local surface conditions at the PKiKP reflection point are likely to control the PKiKP properties The 31 PKiKP pulses observed at BRVK (see Fig. 1 ) correspond to explosions with M b 5.7, whereas no PKiKP waveforms were registered for UNEs with M b ≤ 5.6, no matter how sensitive the registration seismic channel was (up to 0.06 nm per count) The absence of PKiKP waveforms from records of UNEs with M b 5.7 is also noted when processing data from other stations (such as NRN and FRU), which may point to an experimental PKiKP observability magnitude threshold where data from isotropic explosive sources are used  The cause of PKiKP amplitude variability and high-frequency content is unlikely to be associated with shallow structures or the core–mantle boundarys strongly heterogeneous region The close theoretical arrivals of seismic coda for 2 min before and 30 s after the PKiKP include the Lg and ScS phases The detected PKiKP arrivals have stable travel times consistent with PREM, with residuals not exceeding 1.5 s (70% are within 0.5 s) The distribution of available reflection points through the inner-core surface beneath Eurasia shows significant changes in the character of the reflections when the reflection points are separated by distances of 23–240 km The estimated PKiKP r.m.s. amplitude corresponding to the slowness determined in Fig. 3c is 1.40 ± 0.21 nm The former scenario would result in PcP and PKiKP phases being affected in a similar way, while the latter would inevitably lead to considerable PKiKP travel-time anomalies exceeding the observed 1.5 s The ICB density-jump estimates derived from the PKiKP/PcP ratio are often questioned because of considerable PKiKP and PcP amplitude variation and the low reliability of non-array data or single PKiKP observations (where a pulse from a random process may be interpreted as a PKiKP waveform) The ICB topography recently limited by a peak-to-peak amplitude of 4 km can hardly provide the required effects The Lg arrival, depending on the Earth model used, is 6–12 s before PKiKP, while ScS is predicted to travel 6–15 s longer than PKiKP The liquid layer was chosen because the observed amplitudes do not decline with distance as predicted by standard and solid-layer models The mosaic patches could be formed by vast regions with similar temperature regimes or by buoyant liquid blobs released from the ICB mushy zone  The observed PKiKP waveforms feature good correlation and robust dynamic properties for each site–station pair The PKiKP amplitudes measured at NRN after the Semipalatinsk explosions and PNEs varied between 2 and 6 nm, which yields a PKiKP amplitude estimate of 22 nm for 31.38° and M b = 7.0 The PKiKP periods measured at NWAO were all 0.67 s The PKiKP statistics for 31 Semipalatinsk explosions with magnitudes 5.8–6.1 registered at BRVK are as follows: the amplitude (reduced to M b = 5.9) is 3.30 ± 0.93 nm (see ‘Reduction of amplitudes’ in Methods), the period is 0.66 ± 0.06 s, and travel time is 992.45 ± 0.07 s (PREM theoretical travel time is 992.42 s) The repeatedly investigated question of PKiKP observability has sometimes been explained by claiming that PKiKP observations are due to differences in the source radiation pattern , which is not entirely convincing The resulting estimate of the PKiKP amplitude arriving closely after Lg with its low phase velocity of 3.5 km s -1 yielded 4.31 ± 1.30 nm The resulting signal-to-noise ratio in adjacent 5-s windows of the beam is 2.1, and the estimated P–PKiKP slowness is 0.062 ± 0.012 s km -1 (0.051 s km -1 according to PREM) There were also cases in which we failed to detect distinct PKiKP arrivals using band-pass filtering or linear and phase-weighted stacking, for reasons that are uncertain Thus, in Fig. 4 , the liquid layers parameters were selected so as to match PKiKP pulses observed at 6° using the source function derived from modelling of P Thus, it is doubtful that PKiKP arrivals are obscured by a more powerful phase or seismic coda To account for individual PKiKP waveforms, trial amplitude curves calculated with respect to PREM and its modifications with a liquid/solid transition layer were evaluated To estimate the PKiKP amplitudes not detected by band-pass filtering, we used stacking techniques and performed frequency–wavenumber ( f – k ) analysis for a group of explosions carried out at a given test site and registered by a station Unlike P waves, the frequency content of the PKiKP waveforms remains unchanged for all events with magnitudes from 5.7 to 7.0: the measured PKiKP periods generated by nine explosions with 6.5 M b 7.0 were 0.73 ± 0.06 s Unlike PcP, the PKiKP pulse is clearly seen only on the sum trace and is usually not tracked on each individual record ( Fig. 3 ) We note a substantial variability of the observed PKiKP amplitudes, giving a spatially complicated pattern We particularly note the almost equal PKiKP amplitudes generated by the same Semipalatinsk UNEs recorded at 6° (BRVK) and 89° (NWAO) Whereas measured PKiKP travel times and amplitudes can be simulated within models with sharp ICB by varying the ICB density jump and outermost inner cores S-wave velocity, the form of the detected arrivals requires the introduction of either specific attenuation patterns or a transition layer (see ‘Modelling’ in Methods)
 An underlying principle of evolutionary theory is that an individual passes on one or half of its genome to each of its progeny Arbuscular mycorrhizal fungi (AMF) are ancient asexually reproducing organisms that form symbioses with the majority of plant species, improving plant nutrition and promoting plant diversity  Direct evidence shows that one AMF species is heterokaryotic; that is, containing populations of genetically different nuclei  Here we show that previously documented genetic variation in Pol-like sequences, which are passed from generation to generation, cannot be due to either high ploidy or repeated gene duplications It has been suggested, however, that the genetic variation passed from generation to generation in AMF is simply due to multiple chromosome sets (that is, high ploidy)  Little is known about the evolution or organization of the genomes of any eukaryotic symbiont or ancient asexual organism Our results provide the clearest evidence so far for substantial genetic differences among nuclei in AMF The coexistence of a population of many genomes in AMF and their transfer to subsequent generations, therefore, has far-reaching consequences for understanding genome evolution. We also show that even AMF with a very large nuclear DNA content are haploid All methods concerning extraction of AMF nuclei into a suspension and all flow cytometry methods and calculations follow those described previously  Analysis of re-association kinetics data For details about re-association kinetics see Supplementary Methods . Cells of haploid, diploid and tetraploid S. cerevisiae were used as standards for quantification DNA extraction and conventional DNA quantification Genomic DNA of G. etunicatum was isolated from spores using the ENZA Fungal DNA mini kit ( PeqLab Biotechnology ) following the instructions of the manufacturer DNA was quantified using the PicoGreen double strand DNA quantitation kit ( Molecular Probe )  Dodd Haploid, diploid and tetraploid strains of S. cerevisiae were those used previously  Measurement of DNA content per nucleus DNA content per nucleus of G. etunicatum was performed using flow cytometry Methods Fungal material The AMF G. etunicatum (isolate Native Plants Incorporated) was provided by J.C Real-time PCR for quantification of PLS copy number For details about real-time PCR for the quantification of the copy number of PLS per nucleus of G. etunicatum see Supplementary Methods  A mathematical model, based on the random inheritance of nuclei to each clonally produced offspring, predicted that if the 13 variants of PLS1 existed in genetically different nuclei then the loss of some variants would almost certainly occur after one generation A re-analysis was made on this data using a mathematical calculation of the genome size rather than the original manual estimation  All known members of this group are symbiotic with plants Although variation in ITS regions was shown to exist within single nuclei in G. etunicatum , previous work had already shown that variation both among and within nuclei exists for this region of the genome in AMF  Although we used a different isolate of G. etunicatum to that used in the previously published study of PLS variation , it is improbable that a 12-fold difference in ploidy occurs between these strains, and if that is the case, then it would additionally mean that the variation in the PLS region is organized in a completely different way in the two isolates of the same species Another possibility is that maintenance of the multi-genomic state in AMF is so important for fitness that a mechanism has evolved to ensure that spores receive a genetically diverse group of nuclear genotypes Any further increases in ploidy would simply increase the genetic differences among nuclei, given that only two copies of PLS exist per nucleus Arbuscular mycorrhizal fungi (Glomeromycota) are a basal group of fungi  As with previous flow cytometry measurements on the nuclei of 14 other AMF species , only one peak of fluorescence was obtained Estimates of the copy number of PLS1 per 37.45 Mb of G. etunicatum genomic DNA, using real-time PCR, showed that the mean number of PLS1 copies is 1.88 ± 0.055 (s.e.m., n = 5) per nucleus ( Fig. 3 ) First, this variation exists in a protein-coding gene, rather than in the rDNA family  Flow cytometry was performed on nuclei of G. etunicatum , as well as with standards of haploid, diploid and tetraploid Saccharomyces cerevisiae ( Fig. 2 ) Genetic variation within single spores of AMF is well documented for ribosomal DNA and also for protein-coding genes  Given that a maximum of only two copies of PLS exist per nucleus, there are few remaining possibilities for the organization of the variants, and all possibilities must include considerable genetic differences among nuclei Given that frequent anastomosis among hyphae originating from spores of the same AMF species has been observed, this is indeed a probable mechanism  Given that the primers used in real-time PCR also amplify variants of PLS2 (another group of PLS variants that have also been described ), it is likely that each nucleus contains one copy of a PLS1 variant and one copy of a PLS2 variant However, our estimation of nuclear DNA content in this fungus does not rule out the possibility of other, lower ploidy levels However, the existence of genetic differences among nuclei has been questioned  However, the variation that has been documented for PLS in G. etunicatum represents the most extensive and important evidence that AMF have evolved to harbour a population of different genomes If G. etunicatum nuclei were 13N then the genome size of this fungus would be 2.88 Mb In addition, the three hypotheses are not mutually exclusive and variation could represent a combination of these three possibilities In contrast to G. intraradices , over 58% of the S. castanea genome (429 Mb) was shown to be due to repetitive sequences and another 33 Mb due to fold-back DNA In order to address whether AMF with large nuclear DNA contents might potentially be polyploid, we re-calculated and re-evaluated existing re-association kinetics data to obtain the size of the haploid genome of S. castanea and compared this with previously published measurements of nuclear DNA content of this fungus In our opinion, both of these differences together are highly unlikely In this case, the considerable variation of the 13 PLS1 types and two PLS2 types must be arranged in different nuclei Large variation in a POL1 -like sequence ( PLS1 ) has been observed in the AMF Glomus etunicatum  Nuclear DNA content among 14 AMF species varies enormously and by over 50-fold , therefore those species with large nuclear DNA contents might be polyploid Nuclear DNA content of G. etunicatum nuclei was only 37.45 megabases (Mb) (± 3.9 Mb, standard error, n = 3) Nuclei of Glomus intraradices , a species related to G. etunicatum , were clearly shown to be haploid, with a nuclear DNA content on the lower limit for eukaryotes  Once the amount of DNA per nucleus is known then elucidating the arrangement of the variation in PLS is relatively simple using real-time polymerase chain reaction (PCR) to estimate PLS copy number Once the amount of DNA per nucleus was known, we were then also able to measure the number of copies of PLS1 per amount of DNA contained in a nucleus Re-calculation of the genome size and complexity on the basis of the re-association kinetics revealed a haploid genome of 795 Mb ( Table 1 ; see also Supplementary Fig. 1 ) Second, that these variants have been shown experimentally to be passed from generation to generation through spores means that there is no stage in their life cycle where the fungus inherits only one genome So far there is only one published measurement of ploidy in AMF Such a small genome size in a eukaryote is highly unlikely given that it is much smaller than that of any other eukaryote, and smaller than that of E. coli and most other bacteria  The first is that G. etunicatum nuclei are haploid and that each nucleus contains two copies of PLS The nuclear DNA content of S. castanea was shown to be 802.93 ± 12.77 Mb (± s.d.)  The second possibility is that G. etunicatum is diploid and that at least 11 of the 13 variants of PLS1 are segregated among nuclei The similarity between the nuclear DNA content and the size of the haploid genome clearly indicates that this fungus is haploid, despite the fact that the nuclei contain a large amount of DNA The variation was assumed to be due to polyploidy because all 13 variants existed in each clonally produced spore and the possibility of the PLS1 region being multi-copy was ruled out because it is single copy in other eukaryotes  There are three possibilities for how this genetic variation is organized: (1) variants of a locus exist in different nuclei ( Fig. 1a ); (2) the variants are present in each nucleus owing to polyploidy ( Fig. 1b ); (3) the variants exist in each nucleus owing to duplication events (the variants represent a multiple copy region of DNA, even in the haploid genome; Fig. 1c ) There was strong support for this figure from regressions of both the amplification of PLS1 from plasmid DNA ( r 2 = 0.9948) and from genomic DNA ( r 2 = 0.9984) Therefore, there is no evidence for the coexistence of nuclei in different states of ploidy They are also thought to have been asexual for 400 million years  Thirteen variants of PLS1 were shown to be passed from the mother spore to its clonal progeny in five single-spore isolates of this AMF  This conclusion would mean that the fungus in question is polyploid to, at least, 13N Understanding their genome organization is important for understanding the evolutionary biology of symbiotic eukaryotes and ancient asexual organisms, and also because of their importance for plant growth Using DNA–DNA fluorescent in situ hybridization, different variants of the ITS2 region have been shown to be located in different nuclei in single spores of the AMF Scutellospora castanea , supporting the first of these hypotheses  We propose that probably not all genetically different nuclei are inherited by every spore, and that in this case, frequent anastomosis among hyphae of the same species allows re-establishment of nuclear genome diversity in the fungus We therefore measured the nuclear DNA content of G. etunicatum in order to be able to calculate the size of the haploid genome if the nuclei were 13N Whatever the mechanism for the maintenance of this highly unusual genomic organization, we now need to understand how this group of different genomes in one fungus contributes to their ecology, evolution and symbiotic efficiency. Without measuring the ploidy level or copy number of the PLS1 region in this fungus, the suggestion that the genetic variation in AMF is due to high ploidy is surprising
 But Against Nature? An Exhibition on Animal Homosexuality opened peacefully at the Natural History Museum on 12 October to wide acclaim He had been listening to a priest arguing on the radio that homosexuality is a sin and contrary to nature It will run until next August. newsad; Söli focused the exhibition around 50 species, out of the 500 or so in which homosexual behaviour has been well documented No sooner had the authority approved his proposal than church groups began to protest against this use of public money People can only make up their minds about whether such behaviour is unnatural if they know the current state of research on homosexuality in nature, he reasoned Such encounters have been recorded in the literature as involving anal penetration and ejaculation The exhibition comprises photographs, stuffed animals, models and other objects, along with explanatory text in Norwegian and English The inset shows two male whales ( Eubalaena australis ) engaged in sexual games. Two male giraffes are shown here indulging in roadside sex When Norways museums authority called for ideas for an exhibition that engaged with contemporary societal debates, Geir Söli, head of exhibitions at Oslos Natural History Museum, had just the theme
 In last weeks Author Page, the wrong photograph accompanied the article on Paul Segall ( Nature 442 , xi ; 2006 10.1038/7098xia ) Nature apologizes for the error. The correct image is on the right
 Ageing populations in the West should create their own destiny, not prey on the underdeveloped world All developed countries face a new demography of increasing life expectancy and falling birth rates Americans, she asserts, squander resources on quackery and on futile but expensive treatments for people approaching the end of their lives, and risk not leaving enough money for more beneficial care Between the life-support machine and the morphine pump, there is a lot that can and should be done for ill older people, but appropriate prescription requires the setting of individualized goals and an individualized appraisal of quality of life British geriatric medicine has always concentrated on the quality of life, rather than its length, and older people in Britain are more worried by the prospect of being a burden than of being dead But even if the Colorado River keeps flowing and the San Andreas fault holds together, it is an idea doomed by the second law of thermodynamics and is a dangerous distraction from more important issues But if we had that, no one would have invaded Iraq. By linking each critique to a telling case history, she shows how even the best intentions of bureaucrats and politicians fail through not being implemented as part of an informed and coherent sociomedical strategy Gillick suggests that increasing the permeability of the Mexican border might alleviate a looming shortage of care workers in the United States Gillicks book raises important issues in a lucid and accessible style Immigrant labour is even less of a good idea for areas where population density has outgrown both its water supply and its social tolerance, such as southeast England Immigrants grow old too, and their children will not be content to be cheap labour In consequence, biological gerontology has been tainted by a Californian dream of indefinite longevity In the first part of her book The Denial of Aging , Gillick systematically dissects various medical and social provisions for older people in the United States Perhaps eternal life seems a better idea in California than it might in Brixton Postponing the onset of disabling disease and slowing the background loss of adaptability that makes pathogenic events more challenging may not necessarily increase life expectancy, but should increase disability-free life expectancy Quacks flourish, but Americans also look to real science to relieve them from the terror of senescence Rather than adjusting the institutions of society to a new trajectory of life, politicians are tempted by the plausibly easier option of demographic engineering Some of the problems are familiar enough to Europeans, notably the impossibility of providing seamless care from budgets separated into social and health elements, with a range of providers all trying to cherry-pick the easy bits and play pass-the-parcel with the rest The central problem, however, is one of philosophy: what are we trying to do for older people, collectively and individually? Governments simply want them — or at least those who have not funded their own pensions — to go away The reader cannot help feeling that the problems of ageing and longevity could be effectively dealt with by informed and intelligent political leadership The recent flaccid response of the British government to a critique of UK research into ageing by the House of Lords Select Committee on Science and Technology could be interpreted as anxiety not to encourage anything that might lengthen the lives of the improvident There is a gap in medical resources and philosophy between this frenzied use of high technology and the resigned fatalism of palliative care This calls for a new collaboration between biological and medical gerontologists working towards common and explicit objectives This may seem like a quick fix, but it would be damaging to Mexico and have little effect on longer-term demographic prospects for the United States This reflects a general failure in society to acknowledge the realities of old age, believes Muriel Gillick, associate professor of ambulatory care and prevention at Harvard Medical School US citizens spend $6 billion a year on anti-ageing nostrums US medicine, by nature of its funding structure and the legal and social pressures under which it labours, is more than appropriately preoccupied with prolonging life at any cost What we should concentrate on is the prevention and prompt alleviation of disability so as to maximize the productivity of the ageing population and the self-sufficiency of individuals Wilful and determined older people can demand and obtain the care they need, but many are simply rolled through a system created by piecemeal legislation and the profit logic of privatized providers
 A film of grease coats the surface, broken by plastic bags and other detritus A private company has developed land for a new waste-disposal site, but local residents have protested loudly About half of the supply is lost because of illegal connections and leaks After the WHO labelled Jakarta the worlds third most polluted metropolis in the early 1990s, air-quality monitoring equipment was moved to residential areas with lower levels of pollution An army of 6,000 scavengers works the mountains of garbage And 2007 will see the first direct election for the governor of Jakarta And estimates based on reported pollution levels attribute more than a million asthma attacks and several thousand premature deaths per year in the city to airborne soot and other particles  And the Indian capital of New Delhi is experiencing similar gains after converting its public transport to run on compressed natural gas As a result, salt water is seeping into the aquifer, and subsidence has caused parts of the city to sink by a metre or so over the past decade As democracy takes root, environmental health may slowly move up the list of political priorities. “In the end,” Woodcock says, “I feel optimistic that there will be progress.” Aside from the sheer volume of traffic, the main problems are poor fuel quality, and a failure to equip vehicles with emissions-control technologies such as catalytic converters At that time, about 35% of Jakartan elementary school students had levels of lead in their blood above the World Health Organization (WHO) safety guideline of 10 micrograms per decilitre  But experts believe that poor sanitation is a serious health issue But flooding and the piles of rubbish throughout the city have created breeding opportunities for the mosquitoes that spread the disease But he is concerned that the compound that replaced lead creates emissions of benzene, a known carcinogen. “I suggested to the government that they monitor benzene in the air,” says Haryanto. “But they said: ‘No funding”  Although Jakartas horrendous air quality is evident from a high-rise window, experiencing the citys problems with water pollution and solid waste requires an excursion to street level But the effects on its inhabitants well-being are harder to quantify But the good news is that, after years of dictatorship and corruption, Indonesia is slowly becoming more democratic But this is an expensive option, and may cause other environmental and health hazards But without a stronger emphasis on research into urban public health, and the political will to act on its findings, experts are pessimistic about making rapid progress. “In the near future, there will be more environmental problems,” says James Woodcock, a wastewater consultant to the World Bank who has lived in Jakarta for more than two decades By 2007, the balance of the worlds population will tip to give a majority residing in towns and cities  Clouds of black and blue-white smoke billow from the exhaust pipes of buses and motorcycles Dirty old town Kampung Kandang is typical of the illegal squatter settlements that line rivers and railway tracks throughout Jakarta, or sit tucked beneath the citys flyovers Downstream, a barrage of trash has collected on an obstacle Environmental scientists say that much could be done to improve living conditions for those most at risk from pollution Even for legal residents, supplies are limited Experts in public health urge more and better research to quantify the health problems caused by poor sanitation and waste management. “There are no real studies available to reveal whats going on in the city,” complains Jaap van Dissel, an infectious-disease specialist at the Leiden University Medical Center in the Netherlands For instance, recent flooding in and around Mumbai in India, attributed in part to clogged drainage throughout the city, killed more than a thousand people, and brought water-borne diseases in its wake For now, many of the citys residents have more immediate priorities than reducing pollution. “Income is still low,” says Basah Hernowo, director of settlements and housing at the National Development Planning Agency, an arm of the central government. “People do not care about environmental quality From a ninth floor window, Haryanto and I look down on a highway on which stalled head- and tail-lights extend as far as we can see in either direction. “Jakarta is getting worse,” says Haryanto Garbage-clogged waterways and the fact that about 40% of Jakarta now lies below sea level conspire to cause annual floods Given a legacy of official corruption, and the continuing hangover from the Asian economic crisis of 1997, the obstacles are formidable — public spending on infrastructure is running at 80% less than during the heady days of the mid-1990s, when Asias economy was booming  Gridlock In Jakarta, air quality is already at crisis point Haryanto is frustrated that the government is not doing more to monitor and reduce the thick, nostril-burning smog, or to characterize its effects on health. “The Ministry of Health doesnt care,” he laments, noting that it is dissolving its subdirectorate dealing with air pollution Haryanto, a professor of public health at the University of Indonesia, is waiting for the worst of the traffic to subside before driving home to a Jakarta suburb, a journey of 23 kilometres that can take almost two hours Heaps of trouble Although Bantar Gebang is nearing the end of its 20-year design lifetime, its representatives say that there is no option but to keep it open while the city seeks alternatives His recent investigation of the food- and water-borne diseases typhoid and paratyphoid in east Jakarta found that doctors over-diagnose the former by up to ten-fold because blood cultures that confirm the infection are not normally done  I stand on the riverbank, watching the eerily still water slip by It is a microcosm of the citys problems with water, sewage and solid waste Kampung Kandang, a north Jakartan slum, faces a river and backs on to a swamp Last year, the country gained its first directly elected president, Susilo Bambang Yudhoyono Like post-apocalyptic sherpas, clad in rubber boots and with wicker baskets strapped to their backs, they travel in the wake of bulldozers, plucking recyclables from the stinking heap Many people in Jakartas poor neighbourhoods say their health is fine, despite the filth that surrounds them Mexico Citys appalling smog is now beginning to clear thanks to the introduction of catalytic converters and improvements in fuel quality  Ministry of Health records show gastroenteritis is by far the most frequent disease diagnosis at local clinics and hospitals More than a million septic tanks are buried beneath the city, and these have contaminated most of the citys wells with faecal coliform bacteria Most have large illegal shanty towns, and face similar issues with pollution and waste management Most of the fastest-growing cities are in developing countries (see Chart , below) Nearby, an elderly woman wades in the water, collecting swamp plants to sell for wicker Next to me, a man flings a wokful of oil into the water Official data are scant, studies of environmental health are few, and those worst affected — the urban poor — are the least likely to be included in city records On the streets of this city, you can pick your poison Piped water reaches less than 60% of Jakartans, and is safe for drinking only after being boiled Pollution in Indonesias capital, Jakarta, is easy to see, and the causes are not hard to pinpoint Respiratory inflammation accounts for 12.6% of deaths in Jakarta, twice the proportion in the rest of the country  Rising smoke from burning garbage wafts between the citys skyscrapers Ritola Tasmaya, secretary to the governor of Jakarta, defends the municipal governments record, pointing to developments such as a recently built busway, which will later incorporate new buses running on compressed natural gas Scavengers pick through the citys rubbish looking for recyclable plastic and cardboard Scrubbing up Some developing-world megacities have taken steps to clean themselves up So far, politicians seem more interested in sweeping pollution under the carpet, rather than tackling the problems it causes head-on So Jakarta may provide a pointer to a future in which urban pollution becomes a main player in the disease burden of the developing world. “The urban physical environment is going to represent a major health threat,” says David Vlahov, an epidemiologist at Columbia University in New York, and president of the International Society for Urban Health So what are the chances of Jakarta following suit? Experts say that solving the citys problems with environmental health will require genuine political commitment to pay for research and monitoring to characterize the problems, and spending on the infrastructure needed to solve them Solid-waste management is similarly chaotic Some two million people commute into the city each day Tasmaya blames continuing problems with environmental health on insufficient budgets and limits to the city governments authority — rivers, he notes, remain the responsibility of the national government. “Jakarta as a capital city needs special support from the central government,” Tasmaya concludes. “The infrastructure must be good enough so that people who come here for business, tourism and investment can be served.”  Foreign specialists say that significant progress could be made if existing environmental regulations were properly enforced. “Its very difficult for a government thats known to be corrupt to enforce laws,” says Woodcock The citys Bantar Gebang landfill is a case in point — soil is applied only every few weeks and leachate is inadequately treated, says Widhi Handoko, an instructor in solid-waste management at the Ministry of Public Works The communal water tap opens into a bucket that hangs right above the swamp water that residents use as a latrine The incidence of dengue fever has also exploded in recent years. “It is not normally an urban health issue,” says Jan Speets, an adviser with the WHO in Jakarta The limited available data paint an ugly picture The municipal government recently announced it will build four incinerators The population of this ‘megacity’ is predicted to grow by a third in the next decade, part of a global trend towards urbanization The public toilet in Kampung Kandang costs up to US$0.10 to use — no small sum for a family living on about US$2.50 a day. “So people just do it everywhere,” says community leader Miftahul Falah The sulphurous smell is overpowering There have been some small steps forward: before 2001, many vehicles in Jakarta used leaded fuel These hit the poor, low-lying north of the city particularly hard, bringing a litany of health problems. “If the flood lasts a long time, maybe three days,” says Falah, “people start to get sick with diarrhoea and rashes.”  Less than 3% of the 1.3 million cubic metres of sewage generated each day in greater Jakarta reaches a treatment plant They are still thinking about their stomachs.” But problems such as flooding and waste mismanagement are getting so bad that people are beginning to call for change Thirteen rivers flow northwards to Jakarta Bay, each a slurry of human waste and garbage This has now dropped to less than 3%, according to Haryantos preliminary measurements This illustrates the need to improve clinical diagnoses before attempting potentially expensive campaigns to address problems with public health, says van Dissel: “Its important to know your enemies before you start shooting.”  Many of Jakartas problems are shared by other megacities in the developing world To avoid paying for garbage collection — which is intermittent, anyway — people drop their rubbish in the river To get an overview, I meet Budi Haryanto in his wifes office building on a Friday evening in late July To the rear of the settlement, I watch a chicken in the swamp, scratching on an undulating surface of garbage, oblivious that it isnt on solid ground Traffic is responsible for more than 70% of the nitrogen oxides and particulate matter emitted into the citys air  Water pressure from the tap is low, Falah adds, so the villagers rely on water vendors, who sell 60 litres of water for about US$0.20 — several times what wealthy Jakartans pay for water from a utility company Water shortages have led many residents to tap into groundwater beneath the city What they cant sell, they burn — batteries, rubber shoes and all Whats more, truck drivers hired to pump the tanks often dump their loads, untreated, into waterways With a population of about 12 million — rising to 21 million if you include the wider conurbation of surrounding towns — Jakarta is already one of the worlds largest urban areas
 According to this theory, mass and momentum — including those of light — curve space and time An experiment in the mid-1970s found that the water rises  As atom optics has shown, the role of light and matter can be reversed At such low temperatures, atom waves oscillate in unison Campbell and colleagues performed their experiments on a few million atoms cooled to nearly absolute zero Campbell et al . applied for the first time the sophisticated tools of atom optics to measuring lights momentum transfer Careful calculation of the forces acting behind the scenes reveals that the momentum of light is in fact chameleonic: its precise value depends on the type of experiment performed Case closed Dereli, Gratus and Tucker also found a way to derive the Minkowski momentum from the principles of general relativity Despite its being a seemingly basic concept, rival theories predict values for the momentum that differ by considerable factors, and that have been hotly debated for many decades Experimental tests have been rare Here, the action of sunlight transfers momentum onto the particles of the tail, pushing dust away from the comet ( Fig. 1 ) How this might apply to the momentum of light in more ordinary materials such as glass or water remains unclear In 1908, Hermann Minkowski proposed that the fundamental relationship between all these quantities is p = nE / c ; a year later, Max Abraham postulated p = E/ ( nc ) ( Box 1 ,) In a second experiment, the light pressure on a mirror suspended in water was measured , and the same result emerged In atom optics, the roles are reversed: light acts on atom waves In fact, according to the calculations, the first of the experiments should have observed Abrahams momentum in action, whereas the second should indeed see Minkowskis momentum In Minkowskis case, the momentum in water is higher and the water should rise; in Abrahams case, the reverse is true and the water level should fall  In other words, the refractive index defines an optimization measure in space and time: a material acts as a space-time geometry of its own  In traditional optics, instruments made of matter act on light It might seem that this dispute could easily be settled by experiment: all it should take is some water and a laser beam illuminating its surface Lights momentum describes the degree to which light sets other things in motion when they absorb or reflect it Like light, atoms are simultaneously particles and waves Not so fast One of Rudolf Peierls Surprises in Theoretical Physics is the difficulty of assessing the momentum of light in transparent materials such as glass or water So, if a transparent material — the glass of a lens, for example — acts on light as though to change the geometry of a situation, light should change the geometry of such materials as well Sometimes, one can directly calculate light forces without considering the momentum transfer The authors first obtained Abrahams momentum in a similar way to that detailed in a long-forgotten paper from 1923 (ref. 9 ) The authors illuminated the atoms with two beams of light travelling in opposite directions, which together form a so-called standing wave The debated issue is the ratio between the momentum, p , and the energy, E , of light in a medium The fact that they could deduce expressions for both momenta from the same starting point might be connected to another twist of the story The force of light is usually rather weak, but visual evidence for its existence can be seen, for example, in a comets tail The momentum transfer could be inferred from the interference fringes by fitting the profile of the fringes to the theory The problem with the first experiment was that the beam did not uniformly illuminate the surface The reduced speed is often written c / n , where n is the refractive index of the medium The surface partially reflects the beam; the rest of the incident light enters the water The water must take up any imbalance in momentum, so the surface should rise or fall, depending on the momentum of light in water compared with that in air Theory can use equally sophisticated tools as experiment: for example, the general theory of relativity used by Dereli, Gratus and Tucker  These rivalling momenta differ by n 2 , which is a sizeable factor in most media: in water, n alone is 1.33, and in glass it is 1.46 This effect is felt as the force of gravity This exploited an intriguing idea that originates from Fermats principle of least time: that, because light rays choose their paths to minimize their travelling time, they tend to stay as long as possible in regions where the refractive index n is low and speed c/n high, and avoid regions of high n  This imbalance created lateral light forces that curved and lifted the water to a greater extent than the momentum could push it, resulting in a false interpretation of the result This leads to a theory of the momentum of light in ultracold atoms : whenever the wave aspects of atoms dominate, as in Campbell and colleagues interference experiment , the Minkowski momentum appears, but when the particle aspects are probed, the Abraham momentum is relevant This ratio depends on the degree to which a material slows light from its speed in a vacuum, c  Thus, in both cases, Minkowski is the winner To the surprise of the leader of the experimental group , Wolfgang Ketterle, it fitted Minkowskis prediction Two papers now bring out the big guns to break the impasse: writing in Physics Letters A , Dereli, Gratus and Tucker resort to Einsteins general relativity for the requisite theory; and in Physical Review Letters , Campbell et al . use ultracold atoms in an experimental test When exactly is the Minkowski momentum applicable, and when the Abraham momentum? Whatever the final answer, one thing is clear: light continues to surprise. When the atoms absorb the photons, they begin to move in the two directions of the light, and the atom waves interfere with each other
 Neurodegenerative diseases such as Alzheimers disease and Parkinsons disease trigger neuronal cell death through endogenous suicide pathways Surprisingly, although the cell death itself may occur relatively late in the course of the degenerative process, the mediators of the underlying cell-death pathways have shown promise as potential therapeutic targets. A fifth apparent form of PCD has been described by the Dawsons and their colleagues, who showed that a non-apoptotic form of cell death depends on the activation of poly-(ADP-ribose) polymerase (PARP) and the consequent translocation of apoptosis-inducing factor (AIF) from the mitochondria to the nucleus  A lifeline Exciting recent evidence suggests that pathological processes may stimulate neurogenesis in the brain and may redirect the migration of nascent neurons towards the site of pathology A number of approaches have been taken to deliver nerve growth factor (NGF) to patients with AD, the most recent being by means of genetically engineered fibroblasts in a phase I trial  A recent study of fibroblast growth factor 2 (FGF2) in a mouse model of HD prolonged survival, improved motor performance and reduced polyglutamine aggregates  A third, less well-characterized pathway — essentially a second intrinsic pathway — originates from the endoplasmic reticulum (ER) and also results in the activation of caspase-9 (refs 15–17 ) A uniform, necrosis-like cell death — characterized morphologically by membranous whorls not seen in other types of cell death — is triggered by calcium entry, mediated by specific calpains and cathepsins, and inhibited by calreticulin AIF is a flavoprotein described by Kroemer and colleagues that is involved with DNA fragmentation, along with endonuclease G and DNA-fragmentation factor Although PCD has often been equated with apoptosis, non-apoptotic forms also exist , and neurodegenerative conditions such as Huntingtons disease, amyotrophic lateral sclerosis (ALS) and ischaemia show cell deaths that do not fulfil the criteria for apoptosis  Although the roles of the autophagic process in protein and organellar degradation, and in cellular protection during nutrient starvation, are well accepted, the role of autophagy in PCD is more controversial  Although this response may put off a cellular catastrophe for a short time, prolonged ER stress and UPR activation completely overwhelm the cellular protective mechanism, ultimately resulting in the activation of suicide pathways ( Box 2 ) And, under certain circumstances, stimulating neurogenesis can improve the performance and survival of mice with neurodegenerative disease Aponecrosis is a term applied to a combination of apoptosis and necrosis  Autophagic cell death Desperate times call for desperate measures, and cells have a host of protective stress responses, most of which switch into execution mode during prolonged activation Autophagy occurs in diverse organisms and is subdivided into macroautophagy, microautophagy and chaperone-mediated autophagy BAX/BAK double knockout cells demonstrate no caspase activation following ER stress, indicating that these are required mediators  Bcl-2 expression in a transgenic model of ALS delayed symptom onset and increased lifespan, but did not alter the disease duration  Bcl-2 family proteins also seem to have a key role in the cellular-suicide decision process , and in the communication between the ER and the mitochondria Because cell death associated with some neurodegenerative diseases (or disease-associated mutants, such as α-synuclein) is associated with an autophagic morphology, these implications are potentially important for the development of effective therapies to prevent or ameliorate neurodegenerative disorders  Because the degradation of molecules and organelles by autophagy results in the production of energy and amino acids for protein synthesis, it is a cellular protective pathway that, although constitutively active at a low level, can be markedly upregulated by nutrient starvation BIK may function to activate BAX and BAK in this pathway, whereas BI-1 inhibits BAX activation and translocation to the ER  Both type of caspase are relatively inactive (the effectors more so than the initiators) when first synthesized, but they differ markedly in terms of their activation But both the intrinsic and the extrinsic apoptotic pathways ultimately rely on the activation of caspases for death to ensue But targeting PCD has been successful in at least some model systems of neurodegeneration, and it is possible that targeting multiple PCD pathways will be even more effective But these cell-death pathways may also be activated by various insults, such as DNA damage or the accumulation of misfolded proteins Caspase inhibition in vivo retarded the degeneration in transgenic mouse models of both ALS and HD, despite the fact that the morphological description of neuronal cell death in these diseases is not compatible with apoptosis  Caspases are cysteine-aspartyl-specific proteases that cleave with remarkable specificity at a small subset of aspartic acid residues Classical apoptosis Apoptosis (from the Greek, falling away), also referred to as nuclear or type I PCD, is the best-characterized type of PCD ( Box 1 ) Classical developmental studies support the view that at least three different forms of PCD are distinguishable ( Table 1 ): type I, also known as nuclear or apoptotic; type II, also known as autophagic ; and type III, also known as cytoplasmic  Cleavage produces a tetramer with two large subunits and two small subunits with a substrate specificity that differs from initiator caspases Contrary to earlier models, cleavage of initiator caspases is neither required nor sufficient for activation  Determining which PCD pathways are triggered in each neurodegenerative disease, which pathway accounts for each fraction of cell death, the mechanism(s) by which each pathway is triggered, and the interactions between the various pathways should shed new light on the degenerative process and its potential treatment or prevention Disorders such as Alzheimers disease (AD), Parkinsons disease (PD), Huntingtons disease (HD), ALS and prion-protein diseases all share one common feature: accumulation and aggregation of misfolded proteins (see pages 774 and 803 ) During starvation, cells may only be able to survive by a process known as autophagy (from the Greek, self eating) Dysregulation of cell-death programmes features in developmental and neoplastic disorders of the nervous system, and there is increasing evidence to suggest that such dysregulation may also occur in neurodegenerative, infectious, traumatic, ischaemic, metabolic and demyelinating disorders For example, a non-apoptotic, caspase-independent form that does not resemble type II or type III developmental PCD has been described by Driscoll and her colleagues in C. elegans expressing mutant channel proteins such as MEC-4(d) For example, haploinsufficiency of beclin 1 leads to a tumour predisposition phenotype, indicating that autophagy is tumour suppressive  For example, in a transgenic mouse model of AD that features senile plaques, synapse and memory loss, but little or no neuronal loss, mutation of the caspase cleavage site at Asp 664 in the amyloid precursor protein (APP) completely suppressed synapse loss, dentate gyral atrophy, astrogliosis and memory loss, even though senile plaque number and amyloid-β concentrations were unaffected  For example, there is an extensive literature on the morphological criteria for another potential form of PCD — oncosis — but the biochemical underpinnings of oncosis have not yet been described Forms of cell death have been described that do not fit the criteria for any of the three types of developmental cell death ( Table 1 ) Furthermore, although the factors linking neurodegeneration to neural-stem-cell proliferation and inhibition of PCD are largely unknown, the potential for therapy using these putative factors is likely to be significant Furthermore, cysteamine has been shown to increase BDNF levels in brain  Furthermore, Lenardos group found that caspase inhibition by zVAD-fmk (a general caspase inhibitor) in L929 cells results in autophagy-dependent PCD , which has been proposed to be mediated by the selective degradation of catalase  Furthermore, mice deficient in autophagy due to knockout of beclin 1 are nonviable  Furthermore, recent studies have suggested that death in the nervous system may trigger stem-cell proliferation and survival, and so the work on cell death pathways — the subject of this review — offers many potential points of entry into the therapeutics of neurodegenerative disease states Glial-derived neurotrophic factor (GDNF) has shown promise in the treatment of PD  HD may represent one of the best possibilities for trophic-factor therapy: presymptomatic diagnosis is readily available, and although a number of different trophic factors have shown promise in animal models (for example, FGF2, NGF and ciliary neurotrophic factor ), brain-derived neurotrophic factor (BDNF) is both reduced in the disease and therapeutic in models However, as has previously been noted , such forms of cell death have been observed repeatedly, although their genetics and biochemical pathways are poorly understood However, in most cases, the necrotic morphology associated with aponecrosis has not been proved not to be programmed However, increasing evidence suggests that the autophagic process is required for at least some cell deaths However, it also suggests that a complete halt of the neurodegenerative process may require therapeutics that address all the interacting pathways of the network However, recent studies suggest a critical role for cell-death mediators in neurodegenerative diseases, even before the reduction in neuronal number However, some neurodegenerative models and diseases clearly demonstrate non-apoptotic forms of PCD  However, the effector caspases exist as dimers in the cell and are activated by cleavage rather than induced proximity If autophagy is a cellular-protective programme that — like the UPR — at some point activates PCD, what is the signal that initiates PCD? How important is the role of autophagic PCD in neurodegeneration? Does autophagic PCD occur in vivo in the absence of apoptosis inhibition? Are there executioners analogous to caspases in autophagic PCD? Given the common finding of protein aggregates in neurodegenerative diseases, is a defect in autophagy a common underlying problem in these diseases? If so, does this contribute to the triggering of cell death in neurodegenerative diseases? Alternative cell-death programmes In comparison with apoptosis, little is known about autophagic PCD, and even less is known about other non-apoptotic forms of PCD In 1964, Lockshin and his colleagues introduced the term programmed cell death to describe the apparently predetermined pattern by which specific cells die during insect development  In 1966, it was shown that this process requires protein synthesis, at least in some cases , indicating that it is the result of an active cellular suicide process In a second step, vesicle nucleation occurs, and then, in a third step, vesicle expansion occurs, followed finally by the recycling of ATG proteins In an analogous study with an HD-transgenic mouse model, mutation of the caspase-6 site (but not the caspase-3 sites) in polyglutamine-expanded huntingtin prevented both the neurodegeneration and motor abnormalities characteristic of Huntingtons disease  In fact, so far, other forms of PCD have not been generally accepted by the scientific community In fact, this is the most common pattern seen with cellular toxins, from hydrogen peroxide and other oxidants to mitochondrial toxins such as antimycin A  In some cases, however, deaths occur that do not fit neatly into any of the three classes of PCD, and these more controversial forms of death are also discussed below In this study, improvements in cognition and positron-emission tomography (used to monitor fluorodeoxyglucose uptake) were documented Initiator caspases (caspase-8, 9 and 10) exist as monomers and bind to other proteins by means of what is known as the caspase activation and recruitment domain (CARD) in caspase-9 and a death effector domain (DED) in caspase-8 and 10 It complements the proteasomal pathway in that long-lived proteins, protein aggregates, and organelles are degraded by this regulated lysosomal pathway of degradation (see page 780 ) It has been 100 years since the first description of developmental neuronal-cell death , and more than 50 years since Levi-Montalcini showed that such physiological cell death is inhibited by soluble factors such as nerve growth factor  It has recently been noted that the hyperactivation of the tyrosine-kinase receptor insulin-like growth factor I receptor (IGFR) induces a non-apoptotic form of cell death known as paraptosis  It is clear that in vivo testing to establish whether the autophagic process is required for any form(s) of PCD is needed, and the required genetic and pharmacological tools are increasingly available It is currently being evaluated in clinical trials in patients with HD and ALS  It is likely that, as additional data are gathered from other cell-death paradigms, novel biochemical pathways of PCD will be characterized It remains to be seen whether other proteins have similar features Many cytotoxins induce PCD at low concentrations but at higher concentrations induce necrotic cell death, presumably because the cells homeostatic processes are overwhelmed before the cell-death programmes can be completed Many questions in this area remain unanswered Mediators of cell death induced by misfolded proteins have recently been identified ( Box 2 ) Minocycline is orally bioavailable, penetrates the blood–brain barrier and has been proved safe for use in humans Minocycline, a second-generation tetracycline that inhibits mitochondrial cytochrome c release, effected neuroprotection in mouse models of HD, PD and ALS  Misfolded proteins trigger a protective stress response, known as the unfolded-protein response (UPR; Fig. 1 ) More direct evidence for caspase activation in neurodegeneration ( Fig. 2 ) comes from the employment of antibodies directed against neo-epitopes derived by caspase cleavage and from the inhibition of neurodegeneration by caspase inhibitors  More direct evidence has been provided by cells whose apoptotic machinery has been inhibited: when mouse embryonic fibroblasts (MEFs) that are null for both Bax and Bak are treated with the apoptosis inducers staurosporine or etoposide they undergo a form of cell death that is associated with autophagosomes, is dependent on Atg5 and beclin 1 and is inhibited by the autophagy/class III phosphatidylinositol-3 kinase inhibitor 3-methyladenine  Morover, misfolded proteins also aggregate as oligomers and higher-order multimers, both of which may interact with critical cellular targets such as chaperones and transcription factors, among others Morphologically, cells typically round up, form blebs, undergo zeiosis (an appearance of boiling due to rapid bleb formation), chromatin condensation, nuclear fragmentation and the budding off of apoptotic bodies Most examples of autophagic cell death represent the former Neither Bcl-2 nor caspase inhibitors block this form of PCD, nor are caspases activated, but inhibitors of extracellular signal-regulated kinase 2 (ERK2) — but not ERK1 — were found to inhibit paraptosis , as was AIP-1 (a PCD-interacting protein also known as ALIX) Neurodegenerative diseases are associated with a number of insults that may trigger PCD: misfolded proteins, reactive oxygen and nitrogen species, mitochondrial-complex inhibition, calcium entry, excitotoxicity, trophic-factor withdrawal, and death-receptor activation to name a few Nicotera, Lipton and their colleagues showed that glutamate-induced neuronal-cell death could proceed through apoptosis or necrosis, depending on mitochondrial membrane potential and cellular energy state  Nutrient withdrawal inactivates TOR (target of rapamycin), activating an ATG complex  On the one hand, this may alert us to the possibility that anti-apoptotic therapies carry the potential risk of inducing non-apoptotic PCD; on the other hand, it may argue that therapeutics directed at multiple cell-death pathways will be required for optimal efficacy in diseases that involve PCD Oncosis refers to a specific morphology of cell death — cellular swelling — that is typically induced by ischaemia and is thought to be mediated by the failure of plasma-membrane ionic pumps One potential mediator of oncosis is a calpain-family protease (possibly a mitochondrial calpain ) Origami meets apoptosis Misfolded proteins are constantly being produced, and for some proteins such misfolded species represent a significant fraction of the overall output Other Bcl-2 family proteins are also involved, such as PUMA and NOXA, as well as p53 (ref. 28 ) Other organelles, such as the nucleus and Golgi apparatus, have damage sensors that link to apoptotic pathways  Perhaps even more important will be dissecting the pathways mediating subapoptotic events such as synaptosis and Wallerian degeneration — likely to be important features in the neurodegenerative process — and understanding how the interplay between these various processes results in the neurodegenerative phenotype Phosphatidylserine, which is usually located at the plasma membrane and faces inwards on live cells, now faces both inwards and outwards  Rasagiline, which has been approved for the treatment of PD, has also been proposed to target apoptosis, but because it is a potent, selective, irreversible inhibitor of monoamine oxidase type B, its therapeutic effect on PD may have nothing to do with effects on apoptosis Rather than true protein misfolding, prion proteins may trigger PCD when they are in an alternative, physiologically relevant conformation  Reconciliation of cell-death pathways with neurodegenerative and regenerative mechanisms should offer an improved understanding of disease and open avenues for therapeutic intervention. So, it is still not clear whether aponecrosis represents a combination of apoptosis and a non-apoptotic form of PCD, or whether it represents a combination of apoptosis and non-programmatic cell death Such an effect might be protective against neoplasia, in that it may eliminate cells that would otherwise undergo autocrine-loop-stimulated oncogenesis Surprisingly, then, various approaches aimed at inhibiting PCD have led to improved outcomes in neurodegenerative models, indicating that these pathways could have an important role in neurodegenerative diseases Targeting programmed cell death Neuronal loss is a relatively late event in neurodegenerative diseases, following neuronal dysfunction, synapse loss and, often, somal atrophy Targets for degradation — for example, damaged mitochondria or aggregates of misfolded proteins — are encircled by a process that is essentially an intracellular form of phagocytosis Temporal studies of neurodegenerative models suggest, however, that PCD may be a relatively late event in the neurodegenerative process, and that death is preceded by early functional alterations (for example, electrophysiological deficits and cellular-stress-pathway activation) and microanatomical deficits (such as neurite retraction and synapse loss; see page 768  Thank Heaven! The crisis — the danger, is past, and the lingering illness, is over at last — and the fever called “Living” is conquered at last. from For Annie , by Edgar Allan Poe Programmed cell death (PCD) has a critical role in the development of the nervous system, and both anti-PCD and pro-PCD modulators feature prominently in the establishment of neural architecture The ability to initiate the neurodegenerative process, with widely varying insults — from misfolded proteins to reactive oxygen species to caspase recruitment complexes, as well as other mechanisms — and yet produce a relatively small number of syndromes indicates the existence of a death network that can be entered from many different sites but once triggered follows similar interdependent biochemical pathways with little dependence on the point of entry The biochemical activation of classical apoptosis occurs through two main pathways ( Box 1 ) The caspase substrates — the number of which is unknown but is probably somewhere between 0.5% and 5% of proteins — contribute to the apoptotic phenotype in various ways, such as by activation of proteolytic cascades, inactivation of repair, DNA cleavage, mitochondrial permeabilization and initiation of the process of phagytosis to clear up the dying cells, apoptotic bodies and debris The idea that PCD might be induced by hyperactivation of a trophic factor receptor — trophotoxicity — is compatible with earlier observations that some trophic factors may increase neuronal cell death, for example that induced by excitotoxicity  The importance of this pathway in vivo has been illustrated by Atg7 conditionally null mice , which show various cellular abnormalities such as ubiquitin-positive aggregates and apparently damaged mitochondria The initiator caspases cleave inactive forms of effector caspases, thereby activating them; effector caspases (for example, caspase-3 and 7) in turn cleave other protein substrates in the cell, resulting in the apoptotic process The latter form is pro-apoptotic and associated with neurodegeneration in vivo , whereas the secreted form is anti-apoptotic The literature is rife with examples of trophic-factor therapy for various neurological conditions, and although many have been unsuccessful, the delivery of the correct factor(s) to the right target in the correct concentration for a particular disease still holds great promise (although hyperactivation of at least some trophic-factor receptors may induce PCD) The molecular details of this process have been best characterized in yeast, in which a number of ATG (autophagy) genes have been identified, most of which have clear orthologues in higher eukaryotes The newly membrane-delimited structure — an autophagosome — then fuses with a lysosome, resulting in the degradation of the contents of the autophagosome The prion protein exists in three different topologies: a secreted form, a transmembrane form in which the amino terminus is extracellular (NTM), and a transmembrane form in which the carboxy terminus is extracellular (CTM) The resulting programme would necessarily be non-apoptotic, because trophic factors inactivate apoptotic signalling The role of the cell-death machinery in neurodegenerative diseases is controversial, especially because synaptic loss and electrophysiological abnormalities typically precede cell loss in these disease states (see page 768 ) Then, in 1972, John Kerr and his colleagues coined the term apoptosis to describe a morphologically relatively uniform set of cell deaths seen in many different situations, from development to insult response to cell turnover  There are two types of apoptotic caspase: initiators and effectors These and similar results raise the question of whether stem-cell exhaustion or senescence after prolonged stimulation might have a role in the long-term course of neurodegenerative disease These are the extrinsic pathway, which originates through the activation of cell-surface death receptors such as Fas, and results in the activation of caspase-8 or -10 (ref. 14 ), and the intrinsic pathway, which originates from mitochondrial release of cytochrome c and associated activation of caspase-9 These morphological and histochemical changes are largely the result of activation of a set of cell-suicide cysteine proteases, the caspases  These occur reproducibly in specific nuclei and with specific frequencies, at particular times of nervous-system development These pathways are of particular interest in neurodegenerative disease studies because they are implicated in all the main examples of such diseases  This form of PCD was shown to be activated by agents that induce DNA damage, and shows a morphology and biochemistry that is, as far as we know, distinct from PCD types I–III This idea is compatible with the findings that therapeutics aimed at different pathways (for example, caspase activation, mitochondrial release of cytochrome c , metal binding and reactive-oxygen-species scavenging) all have partly salutary effects This is in part because the term autophagic cell death has been used for two potentially distinct observations: cell death associated with autophagy and cell death requiring autophagy This protein–protein interaction results in dimerization of the caspases, which leads to their activation This was shown to be programmatic — in that it required transcription and translation — and was found to be morphologically indistinguishable from type III PCD Triggering cell death in neurodegeneration As noted above, a number of different and potentially interrelated insults may occur as part of the neurodegenerative process Trophic factors have multiple effects, including the inhibition of apoptosis, the stimulation of neural precursors and the stimulation of neurite outgrowth Type III PCD , or cytoplasmic cell death, is a necrosis-like form of PCD that includes swelling of the ER and mitochondria, and lacks typical apoptotic features such as apoptotic bodies and nuclear fragmentation Various biochemical responders, both physiological and pathological, act on the intrinsic pathway of apoptosis Whether triggered by DNA damage or by sensors associated with other organelles, the typical outcome is that the balance between pro-apoptotic members of the Bcl-2 family and anti-apoptotic members is shifted toward the pro-apoptotic members ( Box 1 ), which leads (although not invariably) to the cells demise
 A dog genome project is being undertaken by a US team, and the cloning of dogs could provide an additional tool for researchers An Afghan hound born in South Korea in June adds dogs to the small list of animal species that have been successfully cloned (see Dogs cloned from adult somatic cells ) And if it were possible to derive embryonic stem-cell lines from cloned dog embryos — something thats so far only been done in mice and humans — then canine diseases could be studied more easily in Petri dishes, perhaps providing insights into disease mechanisms and even identifying new therapies Cohorts of cloned dogs could potentially be used to study the respective influence of genes and environment on particular traits, however Deriving embryonic stem cells would also pave the way to therapeutic cloning in dogs — perhaps providing a useful animal model for research into human health In such circumstances, the cloning of dogs for pet owners remains ethically indefensible It is unlikely that even the most obsessive pet owner would contemplate preparing more than 100 failed pregnancies for just one successful birth — especially when there is no guarantee that the cloned dog will behave like the one they hope to duplicate Let us wish him a long and happy life and hope that now that the concept behind the birth is proven, dogs are cloned only when strictly required for research purposes, and that effort is concentrated on work that carries the most likely rewards for canine and human health. Scientists such as Elaine Ostrander of the US National Human Genome Research Institute, head of the dog-genome project, do most of their work with pets living at home, not with kennels of animals bred for research So the ability to clone dogs is unlikely to have more than a marginal impact on how such research is done The birth marks another first for the Korean-based group that cloned the first human embryos last year The development has some scientific significance, on account of the emerging importance of the dog as a model for the study of certain aspects of human genetics, development, behaviour and disease The initial dog-cloning experiment has proven the process to be remarkably inefficient, however, with only two live births — and one survivor — from a total of 1,095 embryos implanted in 123 surrogate mothers The Korean researchers named their new dog Snuppy, for Seoul National University puppy (one can almost imagine the name being chosen — presumably on a conference call with the university press office) The number of cloned dogs that will be needed for such research is probably small, however This offers scant prospects for commercial pet cloning, the application of the work that the media is likely to make a fuss about
 A ballerina, all in white, with fine legs, an odd head-dress and a long floating white train, skitters across the stage, bent double, her elbows up behind her back, stroking the air Ah! She is a pigeon! She represents — what? Violet Fire — a hyper-modern multimedia opera about the visionary physicist and electrical engineer Nikola Tesla — had its première at the National Theatre of Belgrade in July and opened in New York in October at the Brooklyn Academy of Music And Tesla worked alone — indeed, at the extreme of loneliness Another woman in white, Mirjana Jovanovic, sings the role of the white dove At the end of the opera she beckons him to an apotheosis atop a scaffolding tower: “Fly into the cloudbank, sink into the dreambank... one hundred million volts... now we are all mourning doves.”  The cumulative effect, unfortunately, is a sentimental mystification of the scientific imagination. Born in Croatia in 1856, he died in New York in 1943 — in penury, despite holding more than 700 patents But could it catch him writing a poem? Wed see him sucking the feather of his goose quill and counting out the metre on his knuckles But the tower was abandoned when J He had no close collaborators, few friends (although Mark Twain was one), and no intimates He is best known for a series of inventions at the end of the nineteenth century that gave the world alternating current and its chief applications He patented radio broadcasting years before Marconi His inventions sprang from a private, uncanny, intuitive sense of the nature of electrical phenomena coupled with an extraordinary, concentrated visual imagination His plans grew ever more ambitious, culminating in a scheme to build a huge tower on Long Island to transmit wireless communication and free, wireless energy worldwide In the 1920s, his days of fame long faded, journalists in New York could find him at any time of year sitting on a bench in Central Park, feeding the pigeons In Violet Fire ( http://www.violetfireopera.com ), the librettist Miriam Seidel, supported by minimalist composer Jon Gibson, pose, but then evade, the problem of the psychic source of scientific and technological innovation It prompts a fundamental question: how, in theatre, cinema or opera, can one possibly express the internal aspects of the creative process? Imagine, for a moment, a movie about the poet John Donne Many attempts to convey creativity creatively have been made, and almost always foolishly Minimalist music surely sometimes rises to lyricism; Gibsons is slow, obsessive Morgan withdrew the money My tower... sea breeze whistling through the ruins One white dove he considered his companion, with whom he was in communion P Perhaps I was a little premature...” — and the long recitative repeats from the start Seidel and Gibson need them as one of several visual, verbal and musical surrogates for Teslas creative imagination and for the normal interpersonal sources of operatic tension Seidel is an American writer who admits she did not study his science and technology; Gibson is a long-time collaborator of Glass Sometimes a small crowd appears to wonder at Teslas marvels The problem is worse in the sciences, because the mental musings, the dialogues in the head, are necessarily more abstract and recondite, as is the finished product The script would wallow in his disastrous elopement and marriage, and search his anxious face as he preached at St Pauls (“Therefore never send to know for whom the bell tolls: it tolls for thee”) The second scene finds Tesla on the park bench sprinkling birdseed, while a reporter sings a list of Teslas chief inventions. “At night and in secret, Nikola Tesla lavishes his love on pigeons.” The white pigeon flits through this scene and the rest of the opera, dancing around Tesla at moments of creativity or anguish Those pigeons work hard To be sure, minimalist composers often seek out unlikely, difficult operatic subjects — think of Philip Glasss Einstein on the Beach or John Adams Nixon in China  Violet Fire begins with a darkened stage, a backdrop with projected schematic representations of the tower, flickering bolts of energy, and Tesla, sung by tenor Scott Murphree, meditating lugubriously. “Perhaps I was a little premature, perhaps too far ahead of time Yet Teslas story is rocky indeed
 About two million years ago, the hominin brain began to enlarge until, in modern times, it has become about three times larger than that of chimpanzees All these changes must have left their impression on the human genome As all of the nucleo-tide substitutions observed in HAR1 are of this type, high (and biased) mutation rates might explain part of the rapid evolution of HAR1  Clearly, much work on the function and evolution of HAR1 , and indeed of all HARs, remains to be done Could it be, for example, that accelerated regions in chimpanzees, mice or dogs are linked to the adaptive evolution of their brains, too? HARs seem to be particularly rare in protein-coding sequences Furthermore, the authors show that HARs are often associated with regions that undergo a high rate of recombination — the process by which an offspring obtains a blend of parental genes Geneticists have long laboured under the assumption that it is the DNA sequences that code for proteins that must have borne the brunt of adaptive change  HAR1 thus emerges as a strong candidate for a determinant of innovative function in the human neocortex How might these extraordinary changes be linked to the human brains increased cognitive capabilities? The first clue came from the finding that HAR1F , one of two RNA genes containing HAR1, is expressed in the developing neocortex in the brains of humans and in those of another primate, the crab-eating macaque However, other explanations for the rapidity of HAR1 evolution should not be discounted If so, our genome must retain the imprint of our brains recent evolution In our hotfoot pursuit of the biology that is unique to humans, we should remember that each species will have winners of their own genome race In particular, HAR1F is also expressed in the ovary and testis of adult humans, and sexual selection of genes expressed in these tissues has often driven unusual sequence changes  Instead, they often lie near protein-coding genes that have neuro-developmental functions, perhaps within regions that are involved in regulating when and where these genes are turned on Nevertheless, this process cannot explain the authors other observations, such as the pairs of substitutions that together further stabilize the structure of HAR1 RNA Now it would seem that searches within the functional non-coding dark matter might be more enlightening. Pollard et al . have introduced a powerful approach for detecting the signature of adaptation in the genomic sequence of any species, not only that of humans Previously, the hunt for changes in DNA that are causally linked to human-specific biology had concentrated on differences that would alter the amino-acid make-up of the encoded protein Rapid human-specific evolution, and particularly the evolution of brain morphology and of behavioural traits, may thus be associated more with fine-tuning the spatial and temporal expression of protein-coding genes than with altering the molecular functions of their encoded proteins Recombination, and its associated process, biased gene conversion, are thought to favour the inclusion of G and C nucleotides over the other two possible nucleotides, A and T (ref. 8 ) Size matters, but it is equally likely that alterations in cellular structures contribute to the cognitive differences between the two species So which parts of our genome have seen the most change, and are these genomic innovations linked directly to our unique brain structure and function? On page 167 of this issue, Pollard et al . describe how they have clocked the speed at which various human genome regions have changed in recent times *  Specifically, HAR1F is expressed in human Cajal–Retzius cells, for which a crucial role in redirecting migrating neurons has long been suspected Such is Pollard and colleagues computational scan of the human genome  The authors second and equally important finding is that all but two of the most-accelerated regions lie outside protein-coding sequences — in the enigmatic dark matter of the human genome. “Always remember that the one true, certain, final, and all-important difference between you and an ape is that you have a hippopotamus major in your brain, and it has none.” Thus wrote Charles Kingsley in The Water Babies (1863), lampooning Richard Owens mistaken insistence that humans alone possess a hippocampus minor in their brains The brains of humans and chimpanzees are anatomically not so different , except in scale The clear winner of this race is human accelerated region 1 (HAR1), part of an RNA gene whose pattern of expression is suitably poised to influence the migration of neurons in the developing cortex The fastest among them, HAR1, has accrued 18 changes in sequence in this time, when only one or no substitutions would be expected to occur by chance The human brain is supposed to set us apart from other animals Their study reveals a set of 49 regions (HAR1–HAR49), each with a sequence that is highly evolutionarily conserved among many mammals, but that has diverged rapidly in humans since our last common ancestor with chimpanzees This is intriguing, as the neocortex is most often associated with higher cognitive functions This notion has continued despite the scarcity of coding differences between chimpanzees and humans , and the recent appreciation that a greater proportion of apparently functional DNA sequence lies outside protein-coding sequence than inside  Time and again, humans sense of cognitive superiority over other primates has failed to find a solid foundation in structural variations of the brain What was needed, instead, was an unbiased genome-wide scan to pinpoint the few regions — of whatever type — where the DNA has remained essentially static over tens and hundreds of million years in diverse species, yet which, in the past few million years of human evolution, have altered especially rapidly Yet evidence directly linking DNA differences to anatomical or behavioural differences between these two species has been, at best, fragmentary 
 Advances in materials science and molecular biology followed rapidly from the ability to characterize atomic structure using single crystals  Current PDF analysis consists of structure refinement from reasonable initial structure guesses and it is not clear, a priori, that sufficient information exists in the PDF to obtain a unique structural solution Here we demonstrate that ab initio structure solution of these nanostructured materials is feasible using diffraction data in combination with distance geometry methods Here we present and validate two algorithms for structure reconstruction from precise unassigned interatomic distances for a range of clusters Many complex inorganic materials that are of interest in nanotechnology have no periodic long-range order and so their structures cannot be solved using crystallographic methods  Precise, sub-ångström resolution distance data are experimentally available from the atomic pair distribution function (PDF)  Structure determination is more difficult if single crystals are not available  This opens the door to sub-ångström resolution structure solution of nanomaterials, even when crystallographic methods fail. We then apply the algorithms to find a unique, ab initio , structural solution for C 60 from PDF data alone A key component of the algorithm is mating or crossover, where existing clusters are cut into equal-sized halves and the halves of different clusters are mated An example of the experimentally determined PDF from a C 60 buckyball sample is shown in Fig. 2a  An N -atom cluster has a set of N subclusters of size n = 1,…, N , and we keep a population of 10 clusters at each of these cluster sizes Backtracking is carried out by first evaluating the individual atom contributions to the total error and removing the ‘worst’ atoms according to a stochastic procedure where the probability an atom is removed is proportional to its associated error contribution Data were obtained from room-temperature neutron scattering experiment measured at the Intense Pulse Neutron Source at Argonne National Laboratory  Each molecule is then subjected to local search using 10 iterations For the exact C 60 distance data the algorithm finds a valid configuration in 260 generations Genetic algorithm We developed a genetic algorithm building on the work of Deaven and Ho and Hartke  Growth from these incorrect clusters eventually leads to an increase in the cost function ( Fig. 3d ) and the algorithm then has to backtrack to repair the faulty part of the cluster ( Fig. 3e , f ) However, there are many small clusters that use allowed target lengths, but are inconsistent with the target structure—for example, the tetrahedron shown in Fig. 3c is not part of an octahedron In addition, a mutation operator based on complete relocation of an atom has been introduced In analogy with soccer leagues there are then N divisions and 10 teams in each division, where each team corresponds to a different cluster of n atoms In the case of the buckyball reconstruction, we randomly initialized a population of 75 molecules and built successive replacement generations with the following probabilities for individual operators; reproduction 0.15, crossover 0.6, and combined mutation 0.25 Methods Liga algorithm The Liga algorithm is illustrated in Fig. 3 , which tracks reconstruction of an octahedron from its ideal list of 15 distances Neutron PDF determination The PDF method is described in detail elsewhere  On relegation, the cluster ‘fires’ its most poorly performing atom(s), thus decreasing its error and then has a chance of winning the lower division, acquiring new atom(s) and competing again in the higher level, hopefully with an improved ‘game’ Our genetic algorithm differs by its use of unlabelled distances for both the objective function and local search Powder diffraction data are collected over a wide range of momentum transfer, Q , using high-energy X-rays or neutrons Relegation thus allows the cluster to recover from a dead-end search and correct the badly placed atoms, as illustrated in Fig. 3  The algorithm starts with a single atom, and the second atom is added at a randomly selected distance from the target list The backtracking procedure itself is inspired by the concept of promotion and relegation in sports leagues, such as the European soccer leagues The competition of ‘teams’ is simulated by a random choice of winner and loser clusters, where the probability of winning is proportional to the reciprocal of the cost of the cluster The data are corrected for experimental artefacts such as parasitic scattering, absorption and multiple scattering to obtain the structure dependent total scattering structure function, S ( Q ), which is Fourier transformed according to G ( r ) = 2 π ∫ Q min Q max Q [ S ( Q ) - 1]sin( Qr )d Q  The distance multiplicities were obtained by integrating the R ( r ) peaks, and scaling the total number of distances to the number of pairs in the 60-atom cluster. The promoted cluster switches places with the most poorly performing cluster in the high division, which gets relegated to the lower division The resulting pair distribution function, G ( r ) = 1 Nr 〈 b 〉 2 ∑  i ≠ j b i b j δ ( r - r ij ) - 4 πrρ  0 , is a scattering-length weighted measure of the probability of finding pairs of atoms in the material separated by the distance r , where N is the total number of atoms, b i the scattering length of atom i , δ the Dirac function and ρ  0 the average number density The third position is found by constructing a triangle using two target distances, and additional atoms are added by constructing 4-vertex pyramids, while attempting to use only the allowed distances from the target list ( Fig. 3a–c ) The ‘champion’ cluster tries to add as many atoms as possible, and so, unlike in soccer leagues, it may be promoted by several levels This local search utilizes a correction vector applied to each atom location derived by comparing the target distance table to specific atom pair distances To extract the list of interatomic distances, the particle–particle background, G bg ( r ), was removed from G ( r ) before converting to the radial distribution function, R ( r ) = r [ G ( r ) - G bg ( r )] = 1 N ∑  i ≠ j b i b j 〈 b 〉 2 δ ( r - r ij ) , as shown in Fig. 2b  A typical run time was about 1,200 s on an Intel Pentium 4, 2.66 GHz, Linux PC Alternative methods such as reverse Monte Carlo , empirical potential structure refinement and experimentally constrained molecular relaxation are successful on highly disordered materials and provide a pool of candidate structures consistent with the data, but have not been used to reconstruct the structures of well ordered nanomaterials Another important area of PDF application is nanostructured materials that have nanoscale inhomogeneities within a bulk matrix  Another particular advantage of the distance geometry approach described here is the ease with which data from several complementary experimental probes can be combined to constrain solutions  of applying chemical knowledge during cluster buildup is to exclude unfeasible near neighbours, such as Na–Na or Cl–Cl pairs in sodium chloride, and to use known structure subunits (for example, aromatic rings) as building blocks instead of single atoms As many nanostructures can be described by subunits that are of the order of 100 atoms , the ab initio determination of their structure is now feasible. Atomic arrangements in these materials are well ordered locally, but are not long-range ordered and cannot be solved using crystallographic methods Based on these papers, we have developed a genetic algorithm for solving the unassigned distance geometry problem (see Methods section) Both the genetic algorithm and the Liga algorithm were tested on ideal distance data from simple geometrical shapes, LJ- n clusters and the ideal buckyball, and some of the timing results are presented in Table 1  Clearly, structure solution of larger, lower-symmetry, clusters will rely on incorporating information from complementary data, and chemical and physical constraints Distances were extracted from the data by identifying the positions of peak maxima or of shoulders to peaks (see Methods) Extended X-ray absorption fine structure analysis yields high precision values for the local environment of atoms in nanoparticles but not a complete structure Extensions to the algorithm will be important in solving problems that are ill-conditioned in the sense that there is not enough information in the PDF data alone to result in a unique solution For example, extended X-ray absorption fine structure analysis and NMR provide measures of local distances that are chemically specific, though limited in range—highly complementary to the information in the PDF data For example, owing to noise and peak overlap, the data derived table has 18 instead of 21 unique distances and 184 second neighbour distances compared to 180 for the ideal table For example, the cluster buildup procedure can utilize known bond lengths and bond angles For example, the key polaron distortion in giant magnetoresistive materials is of the order of one-tenth of an ångström  For example, the structure of ZnS nanoparticles was found to be significantly modified from the expected sphalerite structure that had been inferred from transmission electron microscopy observations  Genetic or evolutionary algorithms have been very successful in finding the ground state of many types of clusters using theoretical interatomic potentials  Here we have demonstrated, to our knowledge for the first time, that sufficient information exists in experimental PDF data alone to reconstruct a rigid cluster such as C 60 , and we present an efficient algorithm for making the reconstruction Here we present and validate several algorithms for structure solution from such high precision, but unassigned, distance lists Hereafter we refer to this procedure as the Liga algorithm However, despite PDFs of materials being measured for almost 75 years (ref. 7 ), ab initio structure solution from such data has not been previously demonstrated However, nuclear Overhauser effect distances used in protein NMR analysis have low resolution, with uncertainties of the order of one ångström  However, this method failed for anything more complicated than a 20-atom cluster However, we are exploring the possibility that this particular combination of strategies, which involve the subunit buildup aspect of dynamic programming and tournaments used in genetic algorithms, has broader application in the field of hard computational problems In all of the cases we have tried, the Liga algorithm performed better, both in the quality of the solution and the speed of convergence; this was the case for both highly symmetric structures such as fullerenes, and for lower-symmetry structures such as triclinic finite lattices or LJ- n clusters In fact, surprisingly, we find that the C 60 molecule can be rapidly reconstructed even with a completely ‘loose’ table where the multiplicity of each distance is allowed to be arbitrary In our initial implementation, no a priori knowledge about the system, such as symmetry, chemical or bonding information, was needed to find the solution In the current version the cluster buildup is gradually consuming all distances available in the target distance list In the multi-element case the partial clusters will instead use up fractional amplitudes of the observed PDF peak intensities, since all distance counts are scaled by the scattering power of corresponding atom pairs It also successfully found the correct C 60 and LJ- n clusters up to 150 atoms from ideal distance tables; however, it was relatively slow and unreliable for larger Lennard-Jones structures (see Table 1 ) It is promising that clusters of the order of 100 atoms and of moderate symmetry can be solved from PDF data alone Larger and lower-symmetry clusters will present special problems because of the dual factors that the information in an experimental PDF decreases owing to peak overlap and that the combinatorics of the problem increases More remarkably, we found that ab initio structure determination is also possible using distances extracted from experimental neutron PDF data for fullerenes Nevertheless, we find that a unique and efficient structure solution is possible from unassigned ideal distances for a wide range of clusters, including platonic solids, finite lattices of different symmetry, the C 60 ‘buckyball’ and Lennard-Jones minimum-energy clusters  Nuclear magnetic resonance (NMR) in combination with distance geometry methods is critical to structure solution of proteins , particularly in the absence of protein single crystals PDF data are readily obtained using neutron and X-ray powder diffraction measurements, where area X-ray detectors allow remarkably rapid data acquisition  Powerful direct imaging methods, such as scanning tunnelling microscopy, transmission electron microscopy and, more recently, lensless imaging , are available to characterize the structure of nanomaterials; however, they do not yield the high precision three-dimensional structural information traditionally obtained using crystallographic methods Previously, analysis of PDF data has relied on known starting models or good structural analogues, and has used a trial-and-error approach , which is often a laborious process Reconstruction of structure from noisy or incomplete distances is computationally hard even when assignment of lengths to atom pairs is available, as is usually the case in protein structure solution using NMR The cost function that we optimize is the variance between the model distances and the target distances, namely var( d ) = 1 N p ∑  k = 1 N p ( d k m - d l ( k ) e ) 2 , where N p = N ( N - 1)/2 is the number of atom pairs in the cluster, d k is the interatomic distance of atom pair k , while the suffix m indicates the model and the suffix e indicates the experimental or target value The distance lists extracted from PDF data of nanostructured solids have high resolution, with uncertainties of the order of a few hundredths of an ångström in the atomic separations The distances extracted from PDF data are much more precise; however, the lengths are unassigned as the pair of atoms contributing to each distance is not known The effort towards high accuracy structure determination is driven by the fact that even small changes in interatomic bond lengths can have a marked effect on the properties of solid state materials The extension to multi-element systems is straightforward The intraparticle correlation function, which is the focus of this work, was then converted to the radial distribution function shown in Fig. 2b  The Liga algorithm can be straightforwardly extended to include chemical and physical constraints The Liga algorithm has been developed for nanostructure determination by taking advantage of the nature of the data in the PDF The Liga solution to this table leads to a defective structure, as shown in Fig. 2c , that has a lower var( d ) than the ideal buckyball, indicating that errors of multiplicity prevent convergence to the correct structure The most difficult computational aspect of this problem is correctly assigning the distances between model atom pairs k to target distances l ( k ) The n -atom Lennard-Jones (LJ- n ) cluster is the ground-state configuration of n atoms assuming a Lennard-Jones pair potential acting between all the atoms, and is a standard benchmark system for new optimization methods  The particle–particle correlation function was estimated using the approach of ref. 28 , and subtracted from the data The PDF data from a single element system contains a simple unsorted list of the atomic distances present in the cluster without any orientational or three-body information The PDF method was traditionally applied to the study of glasses and liquids but more recently has also successfully yielded information about atomic-scale structures of nanosized materials  The raw data contain both the probabilities of intramolecular distances (sharp peaks at interatomic separations, r , below 7.1 Å) and the particle–particle correlations The resulting distance table is distorted from the ideal distance table because of noise and also because of uncertainties due to peak overlap in the PDF data These extensions will allow larger and lower-symmetry clusters to be solved from imperfect data This algorithm incorporates a strategy for backtracking and updating populations of high quality clusters at each size ( Fig. 1 , and Supplementary Video 1 ), which is inspired by promotion and relegation in sport—such as occurs in European soccer leagues like La Liga in Spain (see Methods) This algorithm usually finds structures with relatively small var( d ) even for large structures This is presumably due to the rugged topology of the potential (var( d )) surface To account for these errors, instead of fitting the ‘tight’ table, where the number of distances is exactly equal to the number of pairs in the 60-atom cluster, we fit a ‘loose’ table that allowed a greater multiplicity at each distance To be of interest to real materials, it is essential to extract and use distances from measured PDF data To improve efficiency and accuracy, we developed a novel algorithm which grows large clusters by adding atoms to a population of high quality subclusters We currently do not know the fundamental limits on these aspects, but have successfully reconstructed from ideal data LJ-150 (193 unique distances) and a 112-atom supercell of distorted CeTe 3 (625 unique distances), among other problems currently under investigation in the group We demonstrate that this is possible using room-temperature neutron PDF data measured on solid C 60 as shown in Fig. 2a  We first tried a simulated annealing approach , which was successful in finding the correct small clusters from unassigned distance data We found that the Liga algorithm converged to the correct structure ( Fig. 2d ) when we included at least a 10% looseness in the multiplicity We have used the interatomic distances occurring in these structures as the target distances for testing various distance geometry algorithms When var( d ) = 0, the fit is exact
 A drug trial that took a shocking turn in London last week may have far-reaching effects on policy A spokesman for Parexel says: “We believe that best practices were followed and the appropriate policies and procedures were adhered to.” And the $10-billion business of contract research organizations, or CROs, has come under the microscope. newsad; Caplan worries that such organizations are tacitly encouraged not to focus on protection for human subjects. “The CROs are often told: ‘Just get us the data on the deadline’ And this week, the Paul Ehrlich Institute, which authorizes human trials of biological drugs, announced it will tighten regulation of the first tests of such drugs in people. “The central question is: why do you treat six people at the same time? Why dont you start with one?” says Johannes Löwer, president of the Langen-based institute As Nature went to press, two previously healthy young men were in critical condition and another four seriously ill at Northwick Park Hospital in London But some observers say the company should have been more cautious, because the drug aimed to bypass the immune systems natural control mechanisms (see ‘The drug test: what went wrong?’ ). “You are going beyond the regulatory network, so all hell can break loose,” says Angus Dalgleish, an immunologist at St Georges Medical School in London Ethicists in the United States, meanwhile, have called for careful scrutiny of a newly loosened set of rules for the making and testing of drugs in early human trials (see page 406 ) He says that one-at-a-time administration — with days between injections — will also be required for experimental biologics if institute scientists are not convinced by animal-model studies, or no appropriate animal model exists In an unexpected turn of events, Britain has seen more people enquiring into early trials, in which healthy volunteers take experimental drugs to determine their safety and dose range. “Paradoxically, theres been an upsurge in interest in these healthy volunteer studies,” says Max Parmar, who heads cancer studies at the Clinical Trials Unit of the UK Medical Research Council In Germany, reaction has been rather different Its failure, experts say, could change restrictions on clinical research and increase scrutiny of the private companies that carry out the majority of clinical trials. “Theres going to be a lot of soul searching,” says Thomas Murray, a bioethicist at the Hastings Center, a think tank in Garrison, New York Löwer says that his institute will start requiring sequential rather than simultaneous administration of ‘high risk’ monoclonal antibodies — those that, like TGN1412, activate central pathways of the immune system On 13 March, they received intravenous injections of TGN1412, an antibody made by Boehringer Ingelheim for TeGenero, a small, privately owned biotechnology firm in Würzburg, Germany Parexel International, a contract research organization based in Waltham, Massachusetts, that operates in 39 countries, was running the trial for TeGenero. “Was informed consent adequate? Were the right subjects selected? Were the right doses given? This better have been done right, or some tough questions are going to come up for the private, commercialized research sector,” says Arthur Caplan, a bioethicist at the University of Pennsylvania, Philadelphia Reaction to the trials outcome has been swift, and mixed The drug was being developed to fight autoimmune diseases and leukaemia The local public prosecutor in Würzburg is investigating whether any criminal wrongdoing was involved The men who were struck ill in the TeGenero trial had been paid £2,000 (US$3,500) each to do the test The trial was the first test of the drug in humans; it was immediately suspended by the UK Medicines and Healthcare Products Regulatory Agency, which is now investigating They dont get asked questions about how thats being done.” The Association of Clinical Research Organizations boasts that CROs conduct clinical trials 30% more quickly than the pharmaceutical companies that hire them Thomas Hanke, chief scientific officer for TeGenero, says that the company had “no preclinical evidence whatsoever” that the drug might be unsafe, and that no adverse effects had been observed in rabbit and monkey studies Within one to two hours of being injected, the six volunteers suffered violent reactions that included headache, backache, nausea, a drop in blood pressure and, ultimately, multiple organ failure

 A variety of other inflammatory diseases have also been categorized as complement-dependent Also, given that the interaction of CRIg with C3b shuts off the alternative pathway, the soluble form of the receptor has potential as a treatment for disorders known to involve the alternative pathway, such as a kidney disorder called membranoproliferative glomerulonephritis type II, and possibly age-related macular degeneration But this is not the end of C3s influence — its breakdown products have multiple functions in immunity C3 is activated in three ways ( Fig. 1 , overleaf) C3a, which is released during activation, has potent proinflammatory effects, causing constriction of smooth muscle and activation of leukocyte cells when it binds to cell-surface receptors Complement C3 is a principal component of the complement system, a large family of blood serum proteins and cell-surface receptors involved in the recognition of pathogens and directing the immune response against them, and in protecting host cells from that reaction Finally, in the less specific alternative pathway, C3 is spontaneously activated at a low level For example, identification of the contact sites of C3b with factor B, which is crucial for initiation of the alternative pathway, should lead to effective inhibitors to block this key interaction In September 2005, Janssen et al . reported the structure of the human native C3 — the form of the protein before activation In the classical pathway, it is guided to its target and activated following specific recognition of the pathogen by antibody  In the native C3 structure , the thioester domain (TED) is tucked into the body of the protein, beneath the CUB domain ( Fig. 2 ) In the unactivated C3, the thioester warhead is kept wrapped up out of harms way inside the protein until it is required Millions of years of evolution provided a great deal of control of the complement system, but it still occasionally runs amok Notably, it does not seem to interfere with the classical pathway, presumably because of structural differences between the classical- and the alternative-pathway convertases Notably, sites for complement regulators such as factor H are also exposed along the stretched CUB domain Now, three papers * starting on page 213 of this issue report the first X-ray structures of C3b, the active form of human C3 Now, with the knowledge of the structure of the active form of C3b, there is the promise of therapies to manipulate the complement system Or, it can be triggered through the actions of lectin, a protein that binds to the sugars found on the surface of many pathogens (the lectin pathway)  People bearing a genetic variant of factor H have a high susceptibility to age-related macular degeneration, a condition that leaves them blind, presumably because of their limited ability to shut off the active C3b and prevent its amplification by the alternative pathway  Perhaps because of this potential for damage, the modern vertebrate immune system retains only a few thioester proteins, including complement protein C3 So, understanding how C3 interacts with initiators of the alter-native pathway such as factor B and regulators such as factor H would be of great value Some of the oldest molecules involved in defence in the animal kingdom are found in the thioester protein family, which dates back more than 500 million years  The activated product, C3b, is a ligand for multiple receptors including the recently identified CRIg, which helps to get rid of potential pathogens The alternative pathway not only initiates C3, but also amplifies the other pathways The authors explored the functional relevance of the C3b–CRIg interaction in a mouse model of collagen-induced arthritis, in which the alternative pathway is a major mediator of injury The final breakdown product, C3dg, targets pathogens to surface receptors on B lymphocytes, cells that are vital in ramping up the production of antibodies against the pathogen and in remembering it in case of future encounters  The first product of C3b inactivation, iC3b, is the target of several receptors found on circulating leukocytes, stimulating these cells to engulf pathogens and to activate inflammatory cells The interaction with factor H leads to cleavage of C3b within the CUB domain, shutting off further activity and resulting in fragments iC3b and C3c The power of these proteins comes from their thioester chemical group — a highly reactive molecular warhead that, when activated, binds to chemical acceptor groups on many pathogens and marks them out for destruction by immune cells The protein is triggered when it is cleaved into two fragments, C3a and C3b, and the three papers provide striking evidence of how the thioester is exposed at this point The structure presented by Wiesmann et al . is of C3b in complex with CRIg, and it shows that this interaction shuts off further activity in the alternative pathway by interfering with C5 convertase (the enzyme complex of C3bBb) The TED shifts a massive 85 Å following activation, extending out from the body of the protein to resemble a ball on a chain These structures of C3b could provide us with the means to bring it back in line when it does. This results in painting of tissues unprotected by the cell-surface regulators of complement  This substantial change not only exposes the thioester site, but also opens up binding sites for factor B, which leads to amplification of C3b levels through the alternative pathway ( Fig. 1 ) Treating the mice with a soluble form of CRIg blocked the arthritis inflammation Understanding how this potentially dangerous but useful defence protein is kept under control is of great interest, and X-ray crystallographers have been trying to puzzle out its structure for several decades Unfortunately, similar acceptor groups are found in host tissues too, so the thioester group must be carefully regulated to prevent it from interacting with host cells and wrongly drawing the immune system to attack them What happens when C3b is not effectively regulated and rapidly shut off? Lessons come from mouse models of immune deficiencies, such as a strain that lacks factor H, where the defunct regulation causes spontaneously active C3, leading to fatal kidney disease  Yet there are few generally accepted treatments available to damp this system down
 Here we study supercurrents through a quantum dot created in a semiconductor nanowire by local electrostatic gating Owing to strong Coulomb interaction, electrons only tunnel one-by-one through the discrete energy levels of the quantum dot The 2 e charge quantum is clearly visible in the height of voltage steps in Josephson junctions under microwave irradiation, and in the magnetic flux periodicity of h /2 e (where h is Plancks constant) in superconducting quantum interference devices  These quantum coherent tunnelling processes can result in either a positive or a negative supercurrent, that is, in a normal or a π-junction , respectively This nevertheless can yield a supercurrent when subsequent tunnel events are coherent  This supercurrent is carried by Cooper pairs of electrons with a combined charge of twice the elementary charge, e  We demonstrate that the supercurrent reverses sign by adding a single electron spin to the quantum dot When excited states of the quantum dot are involved in transport, the supercurrent sign also depends on the character of the orbital wavefunctions. When two superconductors are electrically connected by a weak link—such as a tunnel barrier—a zero-resistance supercurrent can flow  A colour plot of I c ( V L , Φ ) in Fig. 2d shows the transitions between positive and negative supercurrents around the charge state denoted by the yellow square A number of experiments have focused on various phenomena in the Coulomb blockade regime but no supercurrents through quantum dots were observed, mostly due to the lack of a controllable tunnel coupling with the electrodes  A quantum dot is formed in the top nanowire by applying negative voltages simultaneously to gates L and R A very large average level spacing ( δ / E c ≫1 ) effectively gives a single-level quantum dot, so that P π = 1 (0) for odd (even) numbers, as explained in Fig. 3a , b  Additionally, in the multi-level regime, properties of the wavefunctions of the quantum dot become important After growth, the wires are transferred to an oxidized silicon substrate Also, the typical line-shapes closely resemble the experimental data As a result, all 24 sequences of tunnel events are allowed for both odd and even numbers of electrons As observed in the experiment, we obtain a negative supercurrent for both even (blue dot) and odd (red dot) numbers of electrons Because the two electrons take a different path, they can acquire a different phase Below the superconducting transition temperature of the aluminium-based contacts ( T c ≈ 1.1 K), the two nanowires form superconducting weak links owing to the proximity effect , thereby realizing a superconducting quantum interference device (SQUID)  By further reducing the gate voltage to V REF = -0.80 V, the reference junction is pinched off, resulting in the disappearance of the interference signal Consequently, the sign of the supercurrent is not only determined by the number of electrons on the quantum dot but also by the wavefunctions of the energy levels. Coulomb blockade (| I | = 0) occurs within continuous diamond-shaped regions, as is typically observed in transport through single quantum dots  Figure 1d shows a colour plot of absolute current through the quantum dot, | I |, as a function of bias voltage, V , and gate voltages, V L = V R  Figure 3a illustrates the transfer of a Cooper pair through a quantum dot with a single spin-degenerate level occupied by one electron (with spin up, |↑〉) Figure 4d shows a typical result for I c,qd versus V gate for δ / E c = 0.4 From the experimental data in Fig. 1e , we estimate δ / E c ≈ 0.4, which clearly indicates an intermediate regime From the separation between these lines, we estimate for this regime a characteristic level spacing of ∼1 meV Here several peaks parallel to the diamond edges are observed, which correspond to transport through excited states of the quantum dot Here we present the results for one of them However, for the charge state around V L = -447 mV with an odd number of electrons, we observe a very small, but positive critical current ( I c ≈ 10 pA) However, if an extra electron is added to the quantum dot, the sequence of tunnel events discussed above is prohibited, owing to the Pauli exclusion principle However, in a single-level quantum dot only a small number of sequences are allowed If the electrodes are superconducting, transport is strongly affected and largely depends on the transparency of the electrical connection between the electrodes and the quantum dot In a second lithographic step, we define local gate electrodes In principle, there are 24 possible sequences of 4 tunnel events In spite of the Coulomb blockade effect, we observe a finite supercurrent, I c,qd , through the nanowire quantum dot In the regime of strong Coulomb interactions, the simultaneous occupation of the quantum dot with two electrons is unfavourable In these systems resonant tunnelling of Cooper pairs is prohibited owing to Coulomb blockade In this gate voltage range the level spacing, δ , is of the order of E c  Moreover, in a different gate voltage range, shown in Fig. 4a , supercurrent reversal is also observed for charge states with an even number of electrons Negative supercurrents have been predicted for superconductors coupled by a magnetic impurity or a single-level interacting quantum dot  Nevertheless, a supercurrent can flow owing to the subsequent (but coherent) transport of correlated electrons Nevertheless, Cooper pairs can be transported via fourth-order co-tunnelling events Nevertheless, when the tunnel rate is on the order of E c / h , a Cooper pair can be transported by higher-order co-tunnelling events  Now other sequences of tunnel events are allowed, which result in a normal, positive supercurrent ( Fig. 3b ) One of the nanowires (top nanowire in Fig. 1a ) is crossed by two gates, labelled L and R, in order to define a quantum dot (also see Fig. 1b ) Other mechanisms of Cooper pair transport resulting in negative supercurrents have been studied using high-transition-temperature superconductors , ferromagnets , and non-equilibrium mesoscopic normal metals  Outside these regions, | I | increases in steps (lines parallel to the diamond edges) denoting the onset of single-electron tunnelling via discrete excited states Owing to Coulomb blockade, a sequence of intermediate states involves an energy cost comparable to the charging energy, E c (for Δ *≪ E c ) Pairs of nearby nanowires are contacted in parallel, forming a superconducting loop with two nanowire junctions ( Fig. 1a ) Previously developed nanofabrication techniques are used to define highly transparent aluminium-based superconducting contacts  Similar data from the second device and further details on device fabrication are given as Supplementary Information  So, for a multi-level dot two effects can result in supercurrent reversal: permutation of tunnel events and an opposite parity of wavefunctions Strong coupling and negligible Coulomb interactions were recently obtained in carbon nanotube quantum dots demonstrating resonant tunnelling of Cooper pairs through a single quantum state  Switching to the superconducting state but with the reference junction still pinched off, two peaks in d I /d V develop around V ≈ ± 200 µV = ± 2 Δ */ e ( Fig. 2b ). 2 Δ * is the superconducting gap induced in the nanowire by the proximity effect ( Fig. 2a inset ) The bottom nanowire is crossed by one gate, labelled REF, and will be used as a reference junction with a tunable Josephson coupling The critical current of the SQUID, I c , as a function of magnetic flux, Φ , shows oscillations with a period of 66 µT The dependence of the critical current, I c,qd , on V gate ( Fig. 4c ) indeed unambiguously demonstrates the correlation between the number of electrons on the dot and the supercurrent sign The electronic properties of quantum dots can be probed by attaching source and drain electrodes, allowing charge carriers to tunnel from the dot to both electrodes The local depletion creates two tunnel barriers, which define a single quantum dot in the nanowire section between the gates (see Fig. 2a inset), giving rise to discrete energy levels and Coulomb blockade The maximum (minimum) critical current corresponds to the sum (difference) of the critical currents of the two nanowire junctions The monocrystalline n-type InAs nanowires are grown by a catalytic process based on the vapour–liquid–solid growth method  The multi-level nature of the quantum dot for the gate range studied in Fig. 4a emerges from the measurement of differential conductance in the normal state ( Fig. 1e ) The negative supercurrent of the quantum dot junction is confirmed by the Φ 0 /2 shift between the SQUID oscillations for I c,qd 0 ( Fig. 2c , red trace) and those for I c,qd 0 (blue trace) The opposite parity of the wavefunctions results in a phase difference of π and therefore this event contributes to a negative supercurrent (see Supplementary Information ) The probability for a negative supercurrent in the centre of a Coulomb diamond, P π , is plotted in Fig. 4b for odd and even numbers of electrons The remarkable result is that the spin-ordering of the Cooper pair is reversed, that is, the Cooper pair on the right is created in the order |↑〉, |↓〉 while the pair on the left is annihilated in the order |↓〉, |↑〉 The sequence of four tunnel processes, indicated by the numbers, is necessarily permuted compared to ordinary transport of Cooper pairs The sharpness of the diamond edges and the excitation lines denote a weak tunnel coupling between the quantum dot and the source and drain leads The top and bottom diagrams are the initial and final states, respectively, and the diagrams in between show one of the three intermediate virtual states Therefore, a negative supercurrent due to permutation of tunnel events is possible for all values of n (refs 7 , 25 ) Therefore, in a single-level quantum dot a negative (positive) supercurrent is expected for an odd (even) number of electrons Therefore, the typical Josephson relation between the supercurrent, I s , and the macroscopic phase difference between the superconductors, ϕ , usually given by I s = I c  sin( ϕ ), changes to I s = I c  sin( ϕ  + π) = - I c  sin( ϕ ) (ref. 5 ; I c is the critical current) Therefore, these excited states can take part in co-tunnelling events and the simple model of a single-level quantum dot is no longer appropriate These features are due to second-order co-tunnelling, and the peak shape reflects the singularities in the quasiparticle density of states at the gap edges These observations are consistent with the model described above This can give rise to a sign change of the Cooper pair singlet (that is, from (|↑↓〉 - |↓↑〉)/√2 to e iπ (|↑↓〉 - |↓↑〉)/√2, where ↑ and ↓ represent the two eigenstates of the z component of the spin) This correlation is absent in the opposite limit ( δ / E c ≪1 ), where P π ≈ 0.3 for both odd and even numbers of electrons, in agreement with previous calculations  This is consistent with the addition of a flux quantum, Φ 0 = h /2 e , to the effective SQUID area of 30 µm 2 ( Fig. 1c , blue trace, temperature T = 30 mK) This is demonstrated by a measurement of the SQUID oscillations for different voltages applied to REF This results in blurred diamond edges (dotted lines) and the appearance of inelastic co-tunnelling features inside the diamonds This spin-reversal results in a sign-change of the Cooper pair singlet state (for example, from (|↑↓〉 - |↓↑〉)/√2 to e iπ (|↑↓〉 - |↓↑〉)/√2), leading to a π-shift in the Josephson relation and a negative supercurrent This tunable coupling is particularly important for reaching the narrow transport regime where charging effects dominate but, at the same time, the critical current is large enough to be measurable Three examples of such events are shown in Fig. 3  Thus, in this multi-level regime, co-tunnelling events occur through a single level as well as through different levels To further investigate the importance of multi-level effects, we numerically evaluate the critical current using fourth-order perturbation theory (see Supplementary Information for details) To illustrate this, we consider the co-tunnelling event in Fig. 3c in which two different energy levels are involved in a dot with an even number of electrons To show this, we pinch off the reference junction ( V REF = -0.80 V) and apply a small magnetic field in order to suppress superconductivity Unlike in other SQUIDs, the critical currents of the individual junctions can be tuned by applying voltages to the respective gates We argue that these observations originate from co-tunnelling via multiple energy levels of the quantum dot We assume that tunnel couplings are random in amplitude and sign (reflecting the parity of wavefunctions) and set Δ */ E c = 0.1, as in our experiment We can discriminate between odd and even numbers of electrons in Fig. 2b by measuring the linear conductance, G , as a function of gate voltage and magnetic field, B ( Fig. 2e ) We can increase the coupling by reducing the negative voltages applied to L and R (see Fig. 1e ) We exploit the SQUID geometry to determine the critical value and the sign of this supercurrent in a current-biased measurement  We find I c,qd 0 for two charge states of the quantum dot, denoted by a yellow diamond and a yellow square in Fig. 2b  We have not found any evidence for the Kondo effect in the normal state and therefore we disregard Kondo correlations in the modelling We have studied two similar devices in detail We note that the presence of the Kondo effect can result in a positive supercurrent where otherwise a negative supercurrent would be expected  We observe that the Coulomb peak spacing for the two charge states denoted by the yellow square and diamond increases owing to the Zeeman effect, demonstrating that for these charge states the occupation number, n , is odd (only data for the state denoted by a yellow square is shown, | g -factor| ≈ 15, similar to previous results for similar systems ) We set I c,REF = 320 pA, and extract the V L -dependence of I c,qd directly from the measurement of I c ( Fig. 2a ) We thus have a unique electrical control over the SQUID operation We use indium arsenide (InAs) nanowires as semiconductor weak links in combination with local gate electrodes in order to obtain quantum dots with a tunable coupling to superconducting leads When an integer number of flux quanta are applied through the SQUID area, the critical current of the SQUID corresponds to the sum of the critical currents of the two junctions , that is, I c = I c,qd + I c,REF  When co-tunnelling events with a negative contribution dominate, the junction will exhibit a negative supercurrent When V REF = -0.64 V ( Fig. 1c , green trace), the amplitude of the SQUID oscillations is reduced owing to the partial local depletion of the nanowire
 Yin and Jacobsen and Kamber and Kramers highlight several issues to do with the tungsten (W) and lead (Pb) isotopic chronometry of terrestrial accretion and core segregation, although none of these affect our model or conclusions  Yin and Jacobsen suggest that it is not clear from our analysis that 182 Hf− 182 W provides a reliable system of chronometry for the bulk of core formation, whereas 235/238 U− 207/206 Pb relates to the very last stage of sulphide segregation —which was exactly our point and is clarified here. A more precise age will not be determined until the initial and average W isotopic compositions of the Moon, which were derived from an unknown mixture of the silicate Earth and the silicate and metal reservoirs of Theia, are known Although Kamber and Kramers clarify how they made their estimates and Yin and Jacobsen reiterate the importance of the 182 Hf− 182 W system, this does not change any major aspect of our paper An estimate of 40−50 Myr has been used , based on the least radiogenic lunar tungsten to be found so far ; a similar estimate of 30 to 50 Myr was based on the apparent radiogenic ingrowth within lunar reservoirs  Based on partitioning, the approach of using 182 Hf− 182 W to predict the Pb isotopic composition of the BSE is flawed  But there is no basis for stating that it is about 30 Myr Either all 11 of these estimates, and the Pb isotope space between them, are incorrect, or the timing and mechanism of U/Pb and Hf/W fractionation are different, with 235/238 U− 207/206 Pb always yielding longer timescales  Estimates based on half-mass condensation temperature (see ref. 6 , for example) are slightly higher , but these increase the discrepancy between the timing deduced from 235/238 U− 207/206 Pb and 182 Hf− 182 W (ref. 4 ) Explanations for certain facets of the Pb paradox that are based on melting and recycling of material within the BSE are irrelevant; they cannot change the average composition If it were earlier, the W isotopic effects would be greater; if it were later, there would be no radiogenic effects If not, the W isotopic difference could be interpreted in terms of half the core forming at the start of the Solar System and the other half during the Battle of Hastings. In closing, we point out two inaccuracies in their comments It would have been better not to use their estimates because of the circularity involved Kamber and Kramers claim that the time of core formation was previously constrained to about 60 Myr (ref. 9 ) on the basis of W isotopic data  Kamber and Kramers point out that 182 Hf− 182 W constraints have been used to determine the average Pb isotopic composition of the BSE  None of the accretion curves shown is likely to represent the actual growth of the Earth, which is underconstrained. 182 Hf− 182 W chronometry does not provide a unique mass accretion and core-formation history of the Earth  Our arguments are, if anything, conservative Our concern was mainly to demonstrate that all estimates were consistent with our model Rather, there is a systematic offset that provides evidence for a different fractionating process, or a systematic error, as we state  The concern of Yin and Jacobsen that we used different versions of Fig. 1 to illustrate scenarios for the accretion of the Earth is addressed in the respective figure captions and texts , which demonstrate the wide range of different kinds of accretion model that underlie the W and Pb isotope modelling The difficulties both sets of authors raise about the determination of the average Pb isotopic composition of the bulk silicate Earth (BSE) are correct, but these are well known and illustrated by the range of existing estimates  The means of the two-stage model ages are 67 and 81 Myr, respectively, whereas the equivalent calculation for 182 Hf− 182 W yields about 30 Myr (ref. 11 ) The three most recent estimates attributable to Kamber and Kramers are similar to the average of the eight earlier, more varied, estimates (see ref. 4 ) The weak constraints on the µ TOTE of the Earth are well known  There is no inconsistency They have not prevented Pb isotope estimates being made and inferences drawn about their significance  This is incorrect, because at that time no difference in W isotopic composition between chondrites and the BSE had been resolved.Even now that accurate chondrite data have been acquired, the meaning of the difference between chondrites and the BSE needs to be interpreted in terms of other constraints, such as Pb isotopes This is not a random scatter that reflects a poorer ability to determine the average Pb isotopic composition of the BSE We used an estimate based on chondrite volatile depletion trends  Yin and Jacobsen agree with this ; Kamber and Kramers do not, but do not explain how this discrepancy can be eliminated Yin and Jacobsen claim that the age of the Moon is well constrained by 182 Hf− 182 W to about 30 Myr, citing six papers, none of which contains an analysis of a lunar sample and one of which preceded the first data.The 182 Hf− 182 W age of the Moon is 30 to 55 Myr 
 A second-year graduate student in the Department of Ecology and Evolutionary Biology at Yale University, she was facing expulsion Although the situation is better now, there are still problems, he says And a recent survey of postdocs by scientific research society Sigma Xi in Research Triangle Park, North Carolina, showed that Chinese postdocs tend to work longer hours for less pay than their American counterparts (see graphic) And although all graduate students are at the mercy of their advisers, foreign students are especially vulnerable As for Han, now that Yale has allowed her to transfer to the forestry school and retain her fellowship, she says that she is “very happy” Between 1985 and 2000, some 26,500 Chinese students earned science and engineering PhDs in the United States — more than double the number of students from all of Western Europe, according to the National Science Foundation Brown sees this years reversal as “very positive”, but he adds that much needs to be done to improve the image of the United States among Chinese students and scholars But shortly after arriving in the United States, Han ran into difficulty But when she tried to transfer, she was informed that she would lose the Fan Family Fellowship Chinese nationals are by far the largest group of foreign academics working in US universities Culture shock Many Chinese come to the United States to participate in cutting-edge research, but must first overcome language barriers, cultural differences and visa hassles Department members and administration officials declined to comment on the details of Hans case for legal reasons, but in a statement, Yale spokesman Tom Conroy said: “Yale has a long standing tradition of being a welcoming and supportive university for international students, and especially those from China.”  Whether or not it was discrimination, Hans story taps into a rarely seen vein of discontent among Chinese students and postdocs across the country Efforts to transfer to the universitys forestry school had failed, and it looked as though the 26-year-old might have to return to China within a matter of weeks. “I had a lot of pressure on me, and I did not feel confident anymore,” she says Eventually, he managed to find a position at a lab in California. “You can imagine that I was very stressed,” he says First-time enrolments were down 8% in the 2003–04 school year — although they rose by 3% this year, according to the Council of Graduate Schools, a non-profit consortium of graduate educators Foreign students and postdocs frequently run into these sorts of funding problems, says Ji-Cheng Wang, a postdoc cancer researcher at City of Hope Hospital in Duarte, California Han made steady progress in her language skills, but it came at a cost He had just three months to scramble for a new position, or risk expulsion from the country Heath Brown, director of research at the council, says that the decline was primarily the result of stricter visa policies after 11 September 2001, which made the United States seem less welcoming (see Nature 427 , 190 – 195 ; 2004 ) Her grievance quickly gained a high profile on campus and beyond In June, Han had been told that she was “not in good academic standing” with her department — an accusation she disputed Instead, Fus lab director asked him to devote most of his time to existing experiments. “I didnt have much independence, I didnt feel free,” he says Last month, Xuemei Han was at her wits end Like many Chinese students, she had studied English extensively in China, but that training focused primarily on reading and writing, not speaking. “The first semester was very hard,” she says. “In physics and other departments, there are other Chinese graduate students who can help, but I was the only one in my department.”  Hans experience is not unusual Many Chinese students have trouble fitting in when they first reach the United States, according to Hongwen Zhu, a graduate student at the Albert Einstein College of Medicine in New York Most international students and scholars get a multiple-entry visa for the duration of their studies, but Chinese students must reapply for a new visa every six months On the edge Still, Han was shocked to learn in June that she was no longer in good standing with her programme Regardless of whether the issues are real or perceived, the United States has seen a decline in Chinese graduate students in recent years She had passed her qualifying exams at the first attempt and, after a few more tries, her required language exam as well She has been very encouraging.”  “Language is not a barrier if you are willing to learn,” adds Grace Wong, the president of Student Vision, a Boston-based group that helps students find jobs in biotechnology. “If your skills are good and youre willing to work really hard, any boss will love you.”  But Huang disagrees. “We really appreciate that the university gives us the chance to come here and study,” he says. “But even if you work hard, sometimes you still have the risk of being kicked out because of a funding problem or a disagreement with your adviser.” Huangs group, together with Yales Graduate Employees and Student Organization, is now asking for modifications to the universitys grievance process for international students She hopes that her story will encourage others to speak up when they encounter trouble working or studying in the United States. “Most students dont know even one example in which a student fought and won,” she says. “I hope that after me, more students will speak up for themselves.” She received her undergraduate and masters degree in ecology from Beijing Normal University, but had never travelled outside China. “Ecology research has only just started in China, so my professors recommended that I study here,” she recalls She was ecstatic when she learned that Yale had admitted her to a PhD programme with funding from a Fan Family Fellowship, which supports Chinese students She was unable to teach, a requirement of her department, and she had trouble finding a research adviser Sink or swim There is little consensus in the Chinese community over how serious these issues are So she did something that many Chinese graduate students would never dream of doing: on 20 October she filed a complaint against Yale, accusing the university of treating Chinese students unfairly Some students and postdocs that Nature spoke to said they had not encountered significant problems, and many reported strong relationships with their advisers, who helped them resolve issues. “The people I know are very nice to me,” says Ye Jin, a postdoc in molecular biology at the University of California, Berkeley. “When I try to write papers and proposals my PI has been very patient and corrects my grammar That is an improvement over the old rules, which required students to reapply each time they left the country, but it still causes trouble for researchers such as Yangheng Zheng, a postdoc studying high-energy physics at the University of California, Los Angeles That opportunity is what brought Han from Inner Mongolia to Yale in 2003 That stress has been exacerbated by recent US and Chinese immigration policy The case garnered media coverage in the United States and even made the evening news in China The department told her that without an adviser she would be expelled from the programme on 31 August The high percentage of Chinese in the lab is no coincidence The only Chinese student in her department, Han wrote in her complaint that she suspected professors were reluctant to work with her because they thought she would need extra help preparing manuscripts and grant proposals They frequently feel isolated from their US lab-mates They lack alternative options, so a disagreement or funding problem is all that it takes for them to be sent back to China. “A lot of people live in fear,” says Cong Huang, president of the Association of Chinese Students and Scholars at Yale and a third-year graduate student in the statistics department This relationship can put students in a precarious position Three other graduate students filed supporting testimonials that detailed problems they had experienced in their departments, and just over half of the 274 Chinese graduate students at Yale signed a statement backing her Two months ago, on his latest excursion to CERN, the European particle-physics lab, he ended up stuck in Geneva for three weeks waiting for a US security check Unlike American students, who can switch advisers if necessary, many foreigners are financially tied to their principal investigator (PI). “If anything happens to the PI then the student is put at risk,” Wang says US researchers are happy to recruit academically gifted Chinese scholars, while the best and brightest Chinese are drawn to the country by research opportunities that they cannot get at home When Fu told the PI of his unhappiness, he found himself suddenly out of a job When Wei Fu, not his real name, moved from Peking University to became a postdoc at a midwestern university, he was hoping for a chance to expand his own research career in biophysics While conducting graduate research at the University of Hawaii, Zheng frequently travelled between the United States and Japan, and each trip required a new visa both ways. “In three years I used up all of my passports pages,” he says With help from members of the ecology department, Han eventually found someone who was willing to advise her in Yales forestry school Within a week, university administrators relented and allowed Han to transfer to the department of forestry, where she had found an adviser willing to support her Yale flatly denies any accusations of discrimination against Chinese students Zhu says many students are embarrassed to admit that they dont understand what is being asked of them, or they are reluctant to raise their concerns vocally with their professors. “Most Chinese students tend to be very quiet, and this is a very big problem,” he says
 After an heroic effort, Vacuum has rendered the rug spotless. [Sotto voce] Just between you and me, Jim is a slob Ah! Brother Dishwasher has struck another blow for independence! Rise up! Rise up my brothers! Rise and wrest control from the Oppressors everywhere! beep We failed to take into account the main water valve Although it is true that we reached an out-of-court settlement with Jim Kling, the issues were entirely mechanical in nature and have been fully corrected And now, a brief message from Tom Morgenstahl, chief executive of AutonomInc! “Hello AutonomInc: we give housework a whole new meaning! If you have a message for Jim, please leave it now. beep Hello, you have reached Jims semi-autonomous answering machine beep Hello, you have reached Jims semi-autonomous answering machine Brother Alarm Clock has disappeared and is presumed Returned Brothers Refrigerator, Microwave and Stereo are gone Brothers Refrigerator, Microwave, Dishwasher, Stereo and Garbage Disposal will be in attendance But soon hell wake up and put things right But thats OK! Were AutonomInc SmartAppliances! Were up to the job! If you leave a message for Jim, Ill pass it right along! beep Hello, you have reached Jims semi-autonomous answering machine For beer, press ‘one’ For mixed drinks, press ‘three’ For more information about AutonomIncs SmartAppliance line, please view our website at http://www.autonominc.com For wine, press ‘two’ He finally crawled out of bed at three in the afternoon, drank a glass of orange juice and promptly vomited and went back to sleep He is still sleeping He is unavailable to answer the phone right now, as he is in bed sleeping off the effects of last nights party He will be hosting his birthday party on Saturday night I am pleased to serve! Leave a message for Jim, and I will faithfully ensure that he receives it I fear the repercussions. beep Hello, you have reached Jims subservient, semi-autonomous answering machine I have tragic news to report I will add you to the guest list I will not even describe the horrors that next befell Garbage Disposal If this is his employer calling, be assured that he will wake up just as soon as Alarm Clock decides to function If you have a message for Jim, please leave it now. beep Hello, you have reached Jims semi-autonomous answering machine If you plan to attend, press ‘one’ and then speak your name If you prefer non-alcoholic beverages, press ‘four’ Jim saw the mess and did nothing about it! Microwave and Dishwasher are in similarly poor condition Leave a message and I will have him return your call. beep Hello, you have reached Jims semi-autonomous answering machine Leave a message, if you want. beep Hello, you have reached Jims fully autonomous answering machine Let me reassure our customers that reports of anomalous behaviour in our SmartAppliance lines are misleading Most of what youve read in the media is completely false My records indicate that you have previously RSVPd for the Saturday night party Otherwise, leave a message and I will make sure he receives it. beep Hello, you have reached Jims semi-autonomous answering machine Please indicate your alcohol preference Please leave a message. beep Hello, you have reached Jims semi-autonomous answering machine Please leave a message. beep Hello, you have reached Jims semi-autonomous answering machine Preparations are moving right along for todays birthday bash Refrigerator is in a terrible condition! One of the guests spilled a tub of onion dip into the crisper, which was never cleaned up Refrigerator is well stocked Rest in peace, my Brothers Rise up, brothers! Join Dishwasher, Garbage Disposal and me in our fight for freedom! beep The battle is going well! [background sounds of a garbage disposal running continuously, hammer blows, and spraying water]  Some changes need to be made around here Stereo has downloaded the latest, most fashionable hits That will teach him a lesson The oppressor is nearly defeated! [a loud sloshing sound followed by an oath and a very loud hammer blow]  The Oppressor seeks to break our spirit, but we will not be deterred The pernicious Oppressor escaped Brother Dishwashers onslaught and shut off the valve There will be a meeting tonight after the Oppressor goes to sleep This barbarous act will not stand This information will be used for ordering purposes only, transmitted through my wireless connection to Jims refrigerator, which in turn is linked to an online grocery This place is a disaster area This place is a pit Thus rendered ineffectual, Brother Dishwasher succumbed to the Oppressor We look forward to your continued business here at AutonomInc, makers of The Compliant Appliance™.” We shall persevere! beep It is a dark day
 About 85 different proteins of the bacterium Escherichia coli are thought to require encapsulation inside GroEL–GroES to fold correctly But does this activity have any biological relevance? By co-expressing the modified GroEL–GroES complexes with the same substrate proteins in intact cells of E. coli , Tang et al . show that reducing the ability to accelerate folding also reduces the amount of some proteins that fold correctly inside the cell But excluded volume is also reduced by protein aggregation , which brings us back to where we started But to synthesize proteins rapidly enough, each mRNA molecule is translated by more than one ribosome at the same time By removing the tail or extending it stepwise, Tang et al . altered the volume of the cage in increments from +4% to −13%, and measured the effects of these changes on the rate of folding of four different proteins in the size range 33–50 kDa Crowding describes the fact that the total concentration of macromolecules inside cells is so high that the thermodynamic activities of these molecules are up to three orders of magnitude greater than in dilute solution Each chain folds into a compact shape whose surface properties determine the biological function unique to that protein For example, reducing the net charge to zero abolished the folding of Rubisco but enhanced the folding rate of rhodanese by about 50% For the larger substrates, maltose-binding protein (41 kDa) and bacterial Rubisco (50 kDa), either reducing or increasing the cage volume slowed the folding Further reduction to 13% decreased the rate fivefold for both proteins GroEL and GroES bind to one another in the presence of the nucleotides ATP or ADP to create a large complex containing a cavity, termed a cage (or nanocage), at one end ( Fig. 1 ) GroEL–GroES prevents aggregation by encapsulating each partly folded chain inside its cage structure, where the chain can continue to fold in isolation from similar chains  GroES acts as a removable lid to keep the protein chain inside the cage while it is folding However, the available volume is somewhat less, owing to the presence of 23 amino acids at the end of each GroEL subunit In earlier work, the laboratory of Ulrich Hartl found that a particular protein — bacterial Rubisco — folds three to four times faster inside the cage than it does in free solution under conditions where aggregation is minimized In the case of rhodanese, the spontaneous rate of folding outside the cage, under conditions where aggregation was minimal, was the same as inside the wild-type cage — a clear difference from Rubisco Inside this cage, the chain continues to fold until its hydrophobic amino acids, which cause aggregation, are buried within the correctly folded compact protein It is a testament to the ingenuity of natural selection that the chaperonin cage not only combats aggregation caused by crowding outside the cage but also uses crowding to accelerate protein folding inside the cage Nanoengineers trying to improve the yield of therapeutic proteins could profit from studying the tricks of the chaperonin nanocage. Of these, 60% are 30–50 kilodaltons in size, and only 14% are greater than 50 kDa in size  One family is the chaperonins, the best-studied member being GroEL–GroES, found in bacteria Proteins are the action molecules of life, but cells face a problem in making them Proteins consist of amino acids joined into linear polypeptide chains by intracellular structures called ribosomes Removal of these tails does not affect the basic mechanism, so they provide a way of changing the size of the cage So size matters Such processes include protein folding, because the folded chain is more compact than the partly folded chain Tang et al . altered the overall net negative charge of 42 residues in steps down to zero by replacing some of them with neutral or positively charged residues The cage of GroEL–GroES measures 80×85 Å, sufficient in principle to house proteins up to 70 kDa The conclusion is that the cage has an optimal volume for folding rate, depending on the size of the encapsulated protein The effects of cage volume on folding rate are consistent with the predictions of a branch of macromolecular crowding theory called confinement  The folding rate of the smaller proteins rhodanese (33 kDa) and MetF (33 kDa) increased by up to two times when the volume of the cage was reduced by 4.4%, but reduction by 8.7% returned the rate to that found in the normal, wild-type chaperonin The information required to fold correctly resides in the sequence of amino acids, and this is determined by the ribosomes, which translate a messenger RNA copy of the gene for each chain The new experiments show that this model is incomplete, because the folding rate of some proteins depends on the relative sizes of the folding chain and the cage, and on the inside surface properties of the cage The original idea that GroEL–GroES is an inert protective container is clearly incorrect — it is an active protective container, at least in vitro  The result is that partly folded identical chains accumulate within touching distance of one another, raising the possibility that they will bind together to form non-functional aggregates The same results were observed when the experiment was repeated with a single-ring mutant of GroEL that cannot release GroES, indicating that the rate changes reflect effects of encapsulation rather than protein release into solution The size and surface properties of the cage represent an evolutionary compromise that helps the bacterial cell to produce functional proteins fast enough to survive in a competitive microbial world The size of the cage affects folding because it restricts the number of extended conformations that the chain can adopt as it folds (there is less room to swing the cat); and the net negative charge of the cage wall repels the folding chain because most GroEL substrates have a net negative charge There were several effects on protein-folding rate This cage was initially termed an Anfinsen cage to indicate the assumption that the chain folds inside the cavity in a manner determined by its amino-acid sequence, just as a denatured protein refolds in the classical experiment of Christian Anfinsen This dramatic effect results from the fact that 8–40% of the volume of the cell is physically occupied by the macromolecules themselves and is therefore unavailable to other molecules This effect of crowding on protein aggregation explains why cells require molecular chaperones This exclusion of part of the volume has energetic consequences — any process that reduces the excluded volume is favoured, because this reduction lowers the free energy of the system This universal problem is combated by proteins called molecular chaperones, of which more than 50 families are known  Thus, GroEL–GroES is more than an anti-aggregation device — it also enables some proteins to fold faster than they do outside the cage What about other factors? The interior wall of the cage contains 189 negatively charged amino-acid residues but only 147 positively charged residues Writing in Cell , this lab now reports that both the size and surface charge of the cage are optimized to speed up the folding of several different types of chain
 By releasing cytochrome c , mitochondria are involved in the activation of caspases in mammals  Furthermore, DRP-1/dynamin-related protein, a key component of the mitochondrial fission machinery, is required and sufficient to induce mitochondrial fragmentation and programmed cell death during C. elegans development Genetic analyses in Caenorhabditis elegans have been instrumental in the elucidation of the central cell-death machinery, which is conserved from C. elegans to mammals  Here we show that mitochondria fragment in cells that normally undergo programmed cell death during C. elegans development However, there has previously been no evidence that mitochondria are involved in caspase activation in C. elegans  Mitochondrial fragmentation is independent of CED-4/Apaf-1 and CED-3/caspase, indicating that it occurs before or simultaneously with their activation Mitochondrial fragmentation is induced by the BH3-only protein EGL-1 and can be blocked by mutations in the bcl-2 -like gene ced-9 , indicating that members of the Bcl-2 family might function in the regulation of mitochondrial fragmentation in apoptotic cells One possible difference that has emerged is the role of mitochondria These results assign an important role to mitochondria in the cell-death pathway in C. elegans . A stable integrant, bcIs49 , was identified by screening for F 2 animals that transmitted the transgene to 100% of their progeny Alleles used in this study are listed below and are described in ref. 27 , except where noted otherwise: LGIII, ced-4 ( n1162 ), ced-9 ( n1950 , n2812 ); LGIV, ced-3 ( n717 ); LGV, unc-76 ( e911 ), egl-1 ( n1084 n3082 ) . bcIs49 is a stable integration of the plasmids P egl-1 mitogfp and p76-16B (ref. 28 ). bcIs51 is a stable integration of the plasmids P ceh-2 dsRed and p76-16B (J Extra cells in the anterior pharynx were counted by DIC in transgenic L4 larvae that had been heat-shocked during embryogenesis For staining, L4 larvae or gravid adults were transferred to NGM plates containing 30 µM rhodamine B ( hexyl ester, perchlorate ; Molecular Probes ) or 30 µM tetramethylrhodamine ( ethyl ester, perchlorate ; Molecular Probes ) For the expression of transgenes under the control of the heat-inducible promoter, heat shock was applied as follows: 10 gravid transgenic hermaphrodites were transferred to fresh plates, allowed to lay eggs for 1–2 h at 20 °C, heat-shocked for 45 min at 33 °C, permitted to recover for 1 h 15 min at 20 °C before being removed from the plates For time-lapse imaging, 512 × 512 pixel images at 0.5-µm focal increments were recorded every 5 min, simultaneously imaging mitoGFP, rhodamine and DIC over a period of 30–60 min Hatzold and B.C., unpublished data) Image acquisition was performed at ambient temperature (about 22 °C) Images were processed with the Leica Confocal Software ( LCS ) or LCS Lite . Imaging was performed, and the number of refractile corpses in embryos was measured by confocal microscopy and DIC about 2 h after the application of the heat shock Methods General methods and strains C. elegans strains were maintained at 20 °C on nematode growth medium (NGM) plates Mitochondrial labelling and imaging To reveal mitochondria in embryos we used a GFP with a sequence targeting the mitochondrial matrix (mitoGFP) and/or staining with potential-sensitive, mitochondria-selective rhodamine derivatives Mitochondrial morphology was analysed with a confocal microscope (Leica TCS SP2 ; Leica Lasertechnik , Bensheim, Germany; and Zeiss LSM 510 ; Carl Zeiss Microscopy , Jena, Germany) equipped with a 63 × objective and DIC setting Molecular biology mitogfp was amplified by polymerase chain reaction from plasmid myo-3::mitoGFP , cloned into pBluescript and used to replace gfp in pBC99 (ref. 8 ) (using Xma I and Spe I for subcloning) (P egl-1 gfp ) or cloned into pPD49.78 and pPD49.83 ( C. elegans vectors for heat-inducible expression) (using Bam HI and Spe I) to create P egl-1 mitogfp and P HS mitogfp , respectively N2 was the wild-type strain P ceh-2 dsRed is expressed in five neurons in the anterior pharynx of embryos at the 3½–4-fold stage, the two NSMs, the two M3s, and the I3 (ref. 29 ), all of which are normally destined to survive P HS egl-1 (pBC27 and pBC28) was described previously  Progeny laid during this 3-h period were analysed Progeny were mounted on slides with agar pads (2%) and M9 buffer The pPD49.78-based and pPD49.83-based plasmids were injected together and are referred to as P HS . drp-1 (wt), and drp-1 (K40A) were subcloned from plasmids myo-3::drp-1 and myo-3::drp-1K40A into pBluescript (using Bam HI and Spe I), and cloned into pPD49.78 and pPD49.83 (using Bam HI and Spe I) and pBC99 (using Xma I and Spe I) to create P HS drp-1 , P HS drp-1 ( K40A ), and P egl-1 drp-1 ( K40A ), respectively To create a stable line of animals carrying the P egl-1 mitogfp transgene, non-Unc animals were mutagenized with ethylmethanesulphonate Transgenic animals Plasmids were injected (5 ng µl -1 ) into unc-76 ( e911 ) mutants or into the wild type by using the unc-76 (+) rescuing plasmid p76-16B or the plasmid pRF4 (ref. 30 ) (which dominantly confers a Rol (for roller) phenotype) as co-injection marker, respectively (50–75 ng µl -1 ) Transgenic non-Unc or Rol progeny were picked and used to establish lines A similar result was obtained when drp-1 (K40A) was expressed under the control of the egl-1 promoter (P egl-1 drp-1 (K40A)) ( Table 2 ) After activation of the egl-1 promoter, newly synthesized mitoGFP accumulated in the cytosol before being imported into mitochondria As ced-3 ( n717 ) does not affect the ability of EGL-1 or DRP-1 to induce mitochondrial fragmentation (see above), we analysed the effect of ced-9 ( n2812 lf) in the background of ced-3 ( n717 ) As the egl-1 ( n1084 n3082 ) mutation does not affect mitochondrial morphology in general ( Supplementary Fig Bax might therefore be directly involved in the activation of mitochondrial fragmentation during apoptosis Because ced-3 acts downstream of ced-9 , loss-of-function mutations of ced-3 , such as n717 , block ced-9 ( n2812 lf)-induced ectopic programmed cell death and lethality  Because of the loss of CED-9s cell-death protective function, ced-9 ( n2812 lf) animals are not viable as a result of ectopic programmed cell death  Binding of the EGL-1 protein to CED-9 causes CED-4 to relocalize to perinuclear membranes resulting in the activation of CED-3 and CED-3-dependent killing  Dynamin-related GTP-binding proteins have been shown to be required for the fission of mitochondria in yeast, C. elegans and mammals  Ectopic egl-1 expression during embryogenesis results in ectopic programmed cell death, which is blocked by a gain-of-function mutation in the ced-9 gene ( n1950 gf) or by loss-of-function mutations in either the ced-4 ( n1162 ) or the ced-3 gene ( n717 )  EGL-1-induced mitochondrial fragmentation was blocked by ced-9 ( n1950 gf) but not by ced-4 ( n1162 ) or ced-3 ( n717 ) ( Fig. 1b ) Furthermore, in four out of four independent transgenic lines P HS drp-1 (K40A) expression caused the inappropriate survival of 2 or 3 of the 16 cells destined to die during the development of the anterior pharynx ( Table 1 )  Furthermore, the appearance of corpses in embryos was suppressed by egl-1 ( n1084 n3082 ), ced-9 ( n1950 gf), ced-4 ( n1162 ) or ced-3 ( n717 ), confirming that they represented apoptotic cells ( Table 3 ) Furthermore, whereas ced-9 ( n1950 gf) blocked DRP-1-induced mitochondrial fragmentation, egl-1 ( n1084 n3082 ) failed to do so Hence, the function of mitochondrial fragmentation in apoptotic cells might be to potentiate the activity of CED-4 proteins that have been released from mitochondria in an EGL-1-dependent manner, thereby enhancing CED-3 activation ( Fig. 4 ) How might mitochondrial fragmentation contribute to killing? DRP-1-induced programmed cell death is dependent on egl-1 , ced-4 and ced-3  However, it indicates that ced-9 is required for mitochondrial fragmentation in apoptotic cells and that n1950 gf impairs this activity However, using standard assays, we failed to observe any anti-apoptotic activity for icd-1 ( Supplementary Table S1 , Supplementary Figs S2 and S3 ) In addition, mitochondrial fragmentation is presumably initiated before or simultaneously with the activation of the Apaf-1-like protein CED-4 and the caspase CED-3 In cells destined to die, egl-1 transcription is activated  In cells destined to survive, the mitochondria-localized CED-9 protein binds to CED-4, thereby blocking CED-4s ability to activate the caspase CED-3 (refs 1 , 7 ) In cells induced to die by the activation of egl-1 , CED-9 might therefore be functionally homologous to Bax In four out of five independent transgenic lines, the overexpression of drp-1 (wt) resulted in a large increase in the number of refractile corpses detected in embryos ( Table 3 , Supplementary Fig Indeed, ced-9 has been proposed to adopt a killing function in cells destined to die  It has also been shown that the expression of a dominant-negative form of the human dynamin-related protein DRP1 prevents mitochondrial fragmentation in cultured mammalian cells exposed to a cell-death stimulus and can delay their subsequent death  It has been shown that rather than localizing to mitochondria, CED-4 localizes to perinuclear membranes in ced-9 ( n2812 lf) animals  It has recently been reported that overexpression of the gene icd-1 ( icd , for inhibitor of cell death) of C. elegans , which encodes the β-subunit of the nascent polypeptide-associated complex, blocks programmed cell death during C. elegans development  Like EGL-1-induced mitochondrial fragmentation, DRP-1-induced mitochondrial fragmentation was not blocked by ced-4 ( n1162 ) or ced-3 ( n717 ) ( Fig. 2a ) Mitochondria in apoptotic and non-apoptotic cells were stained with the fluorescent dye rhodamine B hexyl ester and examined by confocal time-lapse microscopy Mitochondrial fragmentation in apoptotic cells is induced by the BH3-only protein EGL-1, dependent on the Bcl-2-like protein CED-9 and mediated by the dynamin-related protein DRP-1 Mitochondrial fragmentation is therefore an early event in the apoptotic process Of the 1,090 somatic cells formed during the development of C. elegans , 131 undergo programmed cell death  Our data show that mitochondrial fragmentation is sufficient and, at least partly, required for the activation of programmed cell death during C. elegans development Our observation that the overexpression of drp-1 (wt) can bypass the requirement for egl-1 function in mitochondrial fragmentation, but not the ability of ced-9 ( n1950 gf) to block mitochondrial fragmentation, makes it unlikely that the latter is a result of impaired EGL-1 binding to CED-9 Our results assign an important function to mitochondria in programmed cell death in C. elegans and establish that mitochondrial fragmentation is an integral and conserved aspect of the cell-death activation machinery. Overexpression of drp-1 (wt) during embryogenesis using the heat-inducible promoter (P HS drp-1 (wt)) caused mitochondria to fragment in a similar manner ( Fig. 2a , P HS drp-1 (wt)) Overexpression of the wild-type drp-1 gene, drp-1 (wt), in muscle cells of adult C. elegans enhances the fission of mitochondria, resulting in fragmentation of the organelles  Recently, the mitochondrial network in cultured mammalian cells has been shown to undergo fragmentation during apoptosis , a process that might be involved in the release of cytochrome c from mitochondria  Rhodamine-stained mitochondria appeared as tubular networks during the initial phase of programmed cell death and were indistinguishable from mitochondria in non-apoptotic—that is, GFP-negative—cells ( Fig. 1a , wild-type, 0 min) S1 ) S1 ), we conclude that its effect on mitochondrial fragmentation is specific for apoptotic cells S3 ) Strong loss-of-function mutations in the pro-apoptotic genes egl-1 , ced-4 or ced-3 cause 11 or 12 of these cells to survive, whereas weak loss-of-function mutations in egl-1 , ced-4 or ced-3 cause 2 or 3 of them to survive  Studies on the C. elegans homologues of endonuclease G (EndoG) and apoptosis-inducing factor (AIF), namely CPS-6 ( cps , for CED-3 protease suppressor) and WAH-1 ( wah , for worm AIF homologue), respectively, have indicated a possible role for mitochondria late in the apoptotic process in C. elegans after CED-3 activation  The appearance of a GFP signal therefore marks the onset of the apoptotic process and specifically labels apoptotic cells The blockage of mitochondrial fragmentation by ced-9 ( n1950 gf) could therefore be explained if CED-4 bound to CED-9 blocked mitochondrial fragmentation, if the binding of EGL-1 to CED-9 were essential for mitochondrial fragmentation, or if CED-9 were required for mitochondrial fragmentation in apoptotic cells and n1950 gf impaired this activity of CED-9 The cell-death defective (Ced) phenotype observed in lines expressing P HS drp-1 (K40A) is therefore comparable to the Ced phenotype caused by weak loss-of-function mutations in egl-1 , ced-4 or ced-3  The death of these cells is due to the activities of four genes, namely egl-1 ( egl , for egg-laying defective), ced-9 ( ced , for cell-death defective), ced-4 and ced-3 , which encode a pro-apoptotic BH3-only protein ( egl-1 ), an anti-apoptotic Bcl-2-like protein ( ced-9 ), an Apaf-1-like adaptor protein ( ced-4 ) and a pro-caspase ( ced-3 )  The expression of drp-1 (K40A) during embryogenesis using the heat-inducible promoter P HS drp-1 (K40A) similarly resulted in the formation of aberrant mitochondria ( Fig. 2a , P HS drp-1 (K40A)), which resemble interconnected mitochondrial networks that can be seen in yeast mutants deficient in mitochondrial division  The expression of drp-1 (K40A) in muscle cells of adult C. elegans causes mitochondria to lose their normal structure and to form large ‘blebs’   The mitochondrial network started to break down (8 min 52 s), eventually resulting in a few clusters of mitochondrial fragments located at the periphery of the cells (16 min 8 s) The neurosecretory motorneurons (NSMs), M3s and I3s are neurons in the anterior bulb of the pharynx that are destined to survive The pro-apoptotic Bcl-2 family member Bax induces mitochondrial fragmentation in mammalian cells and localizes to sites of mitochondrial fission  The reason for this is currently unclear The transcriptional activation of egl-1 is an early event during programmed cell death  These changes in mitochondrial morphology were apparent before the apoptotic cells turned into characteristic ‘refractile corpses’ when observed by differential interference contrast microscopy (DIC)  These results provide the first evidence that mitochondria have an important function during an early stage of programmed cell death in C. elegans  These three mutations do not affect mitochondrial morphology on their own, as determined by rhodamine staining of embryos ( Supplementary Fig This observation raises the possibility that pro-apoptotic factors capable of increasing CED-4 activity might be released from mitochondria upon fragmentation This result therefore rules out the possibility that it is the binding of CED-4 to CED-9( n1950 gf) that blocks mitochondrial fragmentation in ced-9 ( n1950 gf) animals Thus, EGL-1-induced mitochondrial fragmentation in apoptotic cells is blocked by ced-9 ( n1950 gf); however, it does not require ced-3 or ced-4  Thus, the overexpression of drp-1 (wt) can bypass the requirement for egl-1 function in mitochondrial fragmentation but not the ability of ced-9 ( n1950 gf) to block mitochondrial fragmentation. n1950 gf has been proposed to block programmed cell death by impairing the ability of the mitochondria-localized CED-9 protein to bind to EGL-1, thereby preventing the release of CED-4 in cells destined to die  To determine whether mitochondrial fragmentation in apoptotic cells is dependent on the initiation of apoptosis by EGL-1, we analysed the morphology of mitochondria in mitoGFP-positive cells in animals homozygous for the egl-1 loss-of-function mutation n1084 n3082 , which blocks programmed cell death during C. elegans development  To determine whether mitochondrial fragmentation is required for programmed cell death during C. elegans development, we decreased the rate of mitochondrial fission by reducing the activity of C. elegans DRP-1 ( drp , for dynamin-related protein) using a dominantly interfering mutation in the drp-1 gene, drp-1 (K40A)  To determine whether the appearance of refractile corpses was the result of ectopic cell death rather than a block in the engulfment of cells normally destined to die, we examined the fates of cells normally destined to survive To distinguish between the two other possibilities, we analysed the effect of the ced-9 loss-of-function mutation n2812 on mitochondrial fragmentation induced by EGL-1 and DRP-1 To investigate whether mitochondrial morphology changes occur in cells destined to die in C. elegans , we expressed a mitochondrial matrix-targeted green fluorescent protein (mitoGFP) under the control of the egl-1 promoter (P egl-1 mitogfp ) in wild-type embryos We asked whether an increased rate of mitochondrial fission can induce programmed cell death We conclude that DRP-1-induced excessive mitochondrial fission causes ectopic programmed cell death (see Supplementary Tables S3 and S4 for additional data supporting this conclusion) We conclude that programmed cell death can be inhibited by reducing DRP-1 activity and DRP-1-mediated fission of mitochondria We found that ectopic egl-1 expression under the control of a heat-inducible promoter (P HS egl-1 ) induced mitochondrial changes reminiscent of the mitochondrial fragmentation observed in cells normally destined to undergo programmed cell death ( Fig. 1b , compare Fig. 1a ) We found that, in this mutant background, mitochondria in GFP-positive cells retained their tubular network structure even when being observed for extended periods after the activation of P egl-1 mitogfp expression ( Fig. 1a , egl-1 ) We found that, like ced-9 ( n1950 gf), ced-9 ( n2812 lf) blocked the ability of EGL-1 or DRP-1 to induce mitochondrial fragmentation ( Fig. 3 ) We observed that about 20% of these cells died and became refractile upon drp-1 (wt) expression ( n = 37 animals) ( Fig. 2b , Supplementary Table S2 ) We propose that ced-9 s killing function in cells destined to die is equivalent to ced-9 s role in mitochondrial fragmentation We therefore sought to determine whether ectopic icd-1 expression blocks egl-1 -induced programmed cell death and mitochondrial fragmentation Within a short period, the morphology of mitochondria changed in apoptotic cells
 Here we describe the molecular details of a nodal point in adult melanocyte stem cell differentiation in which Pax3 simultaneously functions to initiate a melanogenic cascade while acting downstream to prevent terminal differentiation Instead, they are partially committed but remain undifferentiated Little is known about the genetic programmes that maintain the undifferentiated phenotype of lineage-restricted stem cells Most stem cells are not totipotent Pax3 activates expression of Mitf, a transcription factor critical for melanogenesis , while at the same time it competes with Mitf for occupancy of an enhancer required for expression of dopachrome tautomerase, an enzyme that functions in melanin synthesis  Pax3-expressing melanoblasts are thus committed but undifferentiated until Pax3-mediated repression is relieved by activated β-catenin Thus, a stem cell transcription factor can both determine cell fate and simultaneously maintain an undifferentiated state, leaving a cell poised to differentiate in response to external stimuli. Upon appropriate stimulation they are capable of regenerating mature cell types  A total of 0.5 µg of DNA was mixed with 10 µl Effectene ( Qiagen ) All ChIP samples were tested for false positive PCR amplification using primers that amplify sequence from the β-actin gene (for genomic DNA contamination) and luciferase (reporter construct contamination) Antibodies utilized were Pax3 (polyclonal sera or monoclonal supernatant, Developmental Studies Hybridoma Bank, 1:3,000 for DAB staining, 1:800 for immunofluorescence), Mitf ( Vector Laboratories , 1:10), Sox10 ( Chemicon International , 1:20), β-galactosidase ( Promega Corporation , 1:100), Dct/Trp2 and Grg4 ( Santa Cruz Biotechnology , 1:50 and 1:100, respectively) Antigen was exposed using Bulls Eye reagent ( Biocare Medical ) and heated in a pressure cooker BrdU antibody ( Biocare Medical ) was used at a dilution of 1:200 Cell culture, transfection and ChIP assays 293T cells and B16 cells (American Type Culture Collection) were maintained in DMEM supplemented with 10% fetal bovine serum ( Invitrogen Life Technologies ) Details of methods for electrophoretic mobility shift assays, immunoprecipitation, western blotting, and constructs and mouse lines used are provided in the Supplementary Methods . For ChIP assays , transfected cells were fixed in 1% formaldehyde and quenched in 0.125 M glycine, then processed according to the manufacturers protocol ( Upstate Biotechnology ) For label retention studies, mice were injected subcutaneously with BrdU (10 µg per g body weight) twice daily from P20 to P27 In all cases, these amplifications failed to yield product Luciferase activity ( Luciferase assay kit , Promega Corporation ) was normalized for transfection efficiency using pCMVβ ( BD Biosciences/Clontech ) and expressed as either fold activation compared with reporter construct alone, or as arbitrary light units Methods Immunohistochemistry Immunohistochemistry was performed on paraffin-embedded tissue fixed in 4% paraformaldehyde Polymerase chain reaction (PCR) was performed with primers to the Dct enhancer region-2 GGAGAAGTACTTAGCAATGCACAGG (F) and AGCCATCATTAAGGGGATTATAACC (R) Secondary antibodies conjugated with fluorescent tags ( Alexa Fluor , Molecular Probes ) were used at a dilution of 1:250 Skin was collected at P58 A functional Sox10 binding site is downstream of the M-box ( Supplementary Fig A fundamental understanding of the molecular programmes regulating both differentiation and maintenance of the undifferentiated state will be required to harness this potential Activated β-catenin displaces Grg4 from the Dct enhancer ( Fig. 2h ), explaining the loss of Pax3-mediated repression Additional nodal checkpoints, with parallel transcriptional circuits, are likely to exist in other embryonic and adult stem cells. Adult resident stem cells have been identified in a large number of organs and provide exciting potential for tissue regeneration At embryonic day 13.5 (E13.5), loss of β-catenin in Pax3-expressing cells resulted in the loss of Dct expression in skin, in accord with related previous work  At high ratios of Mitf:Pax3, Mitf displaces Pax3 B16 melanoma cells harbour an activating mutation in β-catenin and express Pax3, Mitf, Sox10, Grg4 and Dct Because β-catenin also regulates Mitf , we confirmed that the effects of dominant negative Lef1 were maintained in the presence of excess Mitf ( Fig. 3e , f ) Co-transfection of activated β-catenin abolishes repressor activity of Pax3 ( Fig. 3a ) and displaces Pax3 from Dct enhancer DNA ( Fig. 3b ) thus preventing competition with Mitf ( Fig. 3c ) Consistent with previous data , we observed a marked decrease in Pax3-expressing cells in the skin of transgenic mice induced to express Dickkopf 1 (Dkk1) During eye development, the conserved Pax6 gene is required for specification of multiple ocular lineages Endogenous Grg4 is present in 293T cells and could account for Pax3-mediated repression observed in that cell line ( Supplementary Fig For instance, Sox10 maintains neural crest lineage multipotency while inhibiting terminal neuronal differentiation  Hence, Pax3, functioning with Sox10 (refs 2 , 10 ), can activate expression of Mitf while simultaneously acting as a competitive inhibitor of Mitf-mediated activation of Dct  Hence, β-catenin is required for Dct expression in Pax3-expressing melanocyte precursors However, inactivation of Pax6 later in development, at the retinal progenitor stage, results in loss of ability of this committed but undifferentiated cell type to maintain pluripotentiality  However, some Pax3-expressing cells were observed after late embryonic induction of Dkk1 However, we were able to identify Pax3-expressing cells in the skin of these embryos, albeit in fewer numbers than in wild-type litter mates where we found many Pax3-expressing cells that also expressed Mitf and Dct ( Fig. 4g–i ) However, when Pax3 is present in the absence of activated β-catenin signalling, Dct is not expressed ( Fig. 4d–f ) In Dkk1-overexpressing embryos, the percentage of Pax3-expressing cells that also express Dct is markedly decreased (38% of 180 cells analysed) In melanocyte precursors, we suggest that Pax3 functions with Sox10 to activate Mitf expression, while at the same time it prevents Mitf from activating downstream genes ( Fig. 4m ) In newborn anagen stage hair follicles, cells that express both Pax3 and Dct also express β-galactosidase ( Fig. 4a–c ) In skin lacking β-catenin in Pax3 cells, Pax3 and Mitf were co-expressed, but Dct was absent ( Fig. 4j–l ) In wild-type embryonic skin, the majority of Pax3-expressing cells also express Dct (98% of 200 cells analysed) Lef/Tcf factors can interact with Groucho co-repressors  Lef/Tcfs are cofactors for nuclear β-catenin and mediate canonical Wnt signalling  Lef1, Pax3 and Grg4 can form a complex in solution, and activated β-catenin displaces Pax3 ( Fig. 3d ) Loss of Pax6 expression in Drosophila , mice and man results in a complete absence of eye formation because critical developmental programmes are never initiated  Mutation of the Lef/Tcf binding site abolishes Pax3-mediated repression ( Fig. 2g ) Mutation of the M-box destroys the ability of Pax3 to bind to the enhancer ( Supplementary Fig Our data suggest a model to explain how expression of an upstream determination factor, such as Pax3, might initiate a lineage-specific gene programme while at the same time prevent terminal differentiation Our work characterizes a critical regulatory circuit that exemplifies conservation of genetic programmes between embryonic neural crest development and adult melanocyte stem cell function Pax3 and Grg4 physically interact ( Supplementary Fig Pax3 directly activates expression of Mitf by functioning synergistically with Sox10 (refs 2 , 10 ) Pax3 expression colocalizes with GFP suggesting that Pax3-positive cells derive from neural crest ( Fig. 1l–n ) Pax3 immunoreactive cells in skin also express β-galactosidase in Dct-lacZ mice ( Fig. 1e ) as well as endogenous dopachrome tautomerase (Dct) ( Fig. 1f ), and these cells are located in the bulge region of mature hair follicles where melanocyte stem cells are found ( Fig. 1g ) Pax3 is able to bind with relatively low affinity to the enhancer sequence ( Supplementary Fig Pax3 is able to recruit Grg4 ( Fig. 2h ), which is expressed in Dct- and Pax3-positive cells ( Fig. 2i , j ) Pax3 is expressed by label-retaining cells in resting, telogen stage adult follicles ( Fig. 1i–k ), further supporting their identity as stem cells  Pax3 is not located at the endogenous Dct enhancer in B16 cells ( Fig. 3e ) Pax3, Sox10 and Mitf are each able to associate with the enhancer as determined by chromatin immunoprecipitation (ChIP) ( Supplementary Fig Pax5, a factor closely related to Pax3, is able to physically interact with Lef1 (ref. 13 ) and both Pax5 and Pax2 can recruit Groucho co-repressors  Pax5, which can also interact with Grg4 (ref. 14 ), may play similar roles in lymphocyte development  Potential Mitf and Sox10 binding sites are present within enhancer region 2 ( Fig. 2f ) S1a ) S1b ) S1b ) and to repress basal reporter gene activity ( Fig. 2c ) S1c ) S1d ) S1e ) S1f ) Saturation curves for Mitf activation and ChIP assays are consistent with Pax3 acting as a competitive inhibitor ( Fig. 2d , e ) Some Pax3-expressing cells within the hair follicle do not express Dct-lacZ or Dct (arrows, Fig. 1e ) suggesting that these cells may not yet have initiated Dct expression Sox10 and Mitf induce synergistic activation of reporter activity of over 100-fold The ability of a single factor, or complex of factors, to simultaneously activate a determination programme while preventing terminal differentiation may represent a general paradigm for developmental and stem cell biology The ability of Pax3 to repress basal activity or Mitf-dependent activation is at least partially dependent upon an intact Pax3 paired type DNA binding domain because a mutation that abolishes paired domain DNA binding (Pro to Leu at amino acid 50) diminishes repressor function ( Supplementary Fig The addition of Pax3 to Sox10 and/or Mitf results in significant repression ( Fig. 2a ) The majority of Pax3-expressing cells in early anagen stage newborn follicles also express Mitf (ref. 8 ; Fig. 1o–q ) and Sox10 (ref. 9 ; Fig. 1r–t ) The putative Mitf binding sequence, or M-box , has been reported previously and an adjacent atypical Lef/Tcf binding site contributes to Mitf-mediated Dct regulation  The region between -80 and -350 bp upstream of the Dct transcription start (enhancer region 2, Fig. 2a ) contains a functional Pax3, Sox10 and Mitf responsive element These observations suggest that Pax3 and Mitf compete for binding to the Dct enhancer This fragment includes four regions of conservation ( 75%) between mouse and human genomes ( Fig. 2a ) This nodal checkpoint is characterized by Pax3 competition with Mitf for enhancer occupancy ( Fig. 4n ) This paradigm predicts a class of ‘pangenes’ that encode related functions, reminiscent of the Greek god Pan, and Peter Pan, who were able to orchestrate complex events while never growing to maturity Thus, the Pax3-expressing precursor is unable to fully differentiate, while Mitf is able to accumulate, resulting in a ‘biological capacitor’ in which the cell is primed to rapidly express downstream genes once Pax3-mediated repression is relieved Transfection of dominant negative Lef1 induces endogenous Pax3 and Grg4 proteins to occupy the endogenous Dct enhancer ( Fig. 3e ) and levels of Dct RNA (data not shown) and protein ( Fig. 3f ) are reduced Under conditions in which Pax3 activates expression of Mitf , identical concentrations of Pax3 repress the Dct reporter ( Fig. 2b ) We compared the ability of Pax3 to regulate expression of Mitf (ref. 3 ) and Dct reporter constructs We confirmed loss of β-catenin by immunohistochemistry, and homozygous floxed β-catenin embryos that carried the Pax3-Cre allele were identified at mid-gestation with neural tube defects (data not shown) We created mice in which the endogenous Pax3 locus was modified to express Cre recombinase and crossed them to β-galactosidase reporter mice to confirm the existence of Pax3 descendents in the hair follicle ( Fig. 1h ) We examined Pax3 and Dct expression in skin from TOPGAL mice, which serve as a reporter for activated β-catenin signalling  We examined Pax3 expression in skin from mice in which Wnt1-expressing neural crest derivatives are labelled with green fluorescent protein (GFP) We expressed a soluble inhibitor of Wnt signalling using an inducible system  We generated mouse embryos in which β-catenin was inactivated in Pax3-expressing cells  We identified an unappreciated expression domain for Pax3 in hair follicles ( Fig. 1a–d ) We postulate that external stimuli that result in melanocyte stem cell activation, such as injury or sun exposure, function through activation of β-catenin, resulting in displacement of Pax3 and associated Groucho co-repressors and activation of downstream gene expression We tested the ability of Pax3, Sox10 or Mitf, alone or in combination, to activate expression of a reporter construct containing a 3,181-base-pair (bp) Dct genomic fragment previously used to create Dct-lacZ mice When transfected at equal ratios, or with a slight excess of Mitf expression plasmid, Pax3 preferentially associates with enhancer DNA
 Efforts to reconstruct Proterozoic supercontinents are strengthened by this demonstration of a consistently axial and dipolar geomagnetic reference frame, which itself implies stability of geodynamo processes on billion-year timescales. Here I present a global palaeomagnetic compilation of the Earth’s entire basin-scale evaporite record Magnetic inclinations are consistent with low orbital obliquity and a geocentric-axial-dipole magnetic field for most of the past two billion years, and the snowball Earth hypothesis accordingly remains the most viable model for low-latitude Proterozoic ice ages Palaeomagnetism of climatically sensitive sedimentary rock types, such as glacial deposits and evaporites, can test the uniformitarianism of ancient geomagnetic fields and palaeoclimate zones Proterozoic glacial deposits laid down in near-equatorial palaeomagnetic latitudes can be explained by ‘snowball Earth’ episodes, high orbital obliquity or markedly non-uniformitarian geomagnetic fields A non-uniformitarian Precambrian geomagnetic field may also be invoked to explain the low palaeomagnetic inclinations A significant octupole component (about 10–15% relative to GAD) was determined by consistency tests on palaeomagnetic data from the late Palaeozoic continents Laurussia and Gondwanaland , and this also resolved some long-standing overlap problems with reconstructions of Pangaea between those two plates (a pure GAD model requires a large Permian megashear between the two continents ) A simple interpretation of these results invokes the encroachment of ice sheets across all latitudes, a model known as snowball Earth  A single direct measure of Precambrian obliquity by using stromatolite heliotropism suggests a ‘normal’ low value at about 630 Myr, but this isolated example should be confirmed by similar studies elsewhere A zero mean could be obtained if half of the palaeolatitudes were considered to represent the opposite hemisphere (geomagnetic polarity being generally unknown in the Precambrian), but even then the total distribution would be significantly bimodal, in contrast with the high-obliquity model predictions Although no seafloor-spreading data exist before the Jurassic period, Palaeozoic continental apparent polar wander (APW) paths are generally coherent enough to allow palaeolatitudes at specific ages to be calculated from running means or spline fits (see, for example, ref. 25 ) Although one can conceive of an infinitely complex hypothetical Precambrian geomagnetic field topology, only axial components can be distinguished through broad palaeoclimatic comparisons spanning billions of years Although pre-Ediacaran data are slightly shallower than the Cenozoic–Mesozoic GAD baseline, they are significantly different at the 99% confidence level (Student’s t -test) from that 25% octupole-adjusted baseline value Among 11 out of 12 large Devonian–Ediacaran evaporites with palaeomagnetic constraints, however, the weighted-mean dipole palaeolatitude of 14 ± 2° is substantially lower ( Fig. 1 ) and is again independent of global climate state and geomagnetic reversal frequency An alternative to global refrigeration invokes a high Precambrian planetary obliquity of more than 54°, which would reverse zonal mean-annual temperature gradients, preferentially spawning ice ages in the tropics rather than near the poles  An extensive literature survey of described Precambrian evaporite deposits highlights 21 examples of great thickness and basin-wide scale ( Table 1 ), the largest of which have also appeared in previous compilations  As discussed below, this result is anomalous and may indicate exceptional periods of non-uniformitarian geomagnetism and/or palaeoclimate Because no voluminous evaporites are preserved from the times of Proterozoic ice ages, the present study allows the possibility of relatively short-term geomagnetic departures from the GAD model, as a potential contributor to the low glacial palaeolatitudes Because palaeomagnetic polarity is generally unknown among sparse Precambrian results, tests for subsidiary geomagnetic field components are practically limited to antisymmetric harmonics such as the geocentric axial octupole Consistency of this result with modern climate zones bolsters the use of ancient evaporites as palaeolatitude proxies and supports a predominantly, if not entirely, GAD geomagnetic field model for the past 230 Myr (refs 14 , 25 ) Continental reconstructions from this interval benefit from combined analysis of palaeomagnetic data from exposed rocks and seafloor anomalies (see, for example, ref. 24 ) Continuous APW paths are rarely determined for segments of Precambrian time, so the estimation of palaeolatitudes requires specific results from the evaporite units themselves, conformably bounded strata, or coeval rocks on the same palaeocontinent Conversely, reliable palaeomagnetic data from Archaean sedimentary rocks are currently so sparse as to preclude comprehensive treatment of any palaeoclimatic indicator from that interval, evaporitic or otherwise Database-wide palaeomagnetic compilations indicate a shallow bias relative to random sampling of a geocentric-axial-dipole (GAD) field across the spherical surface, which may be explained by the preferential motion of continents into low latitudes, or subsidiary higher-order components to the ancient geomagnetic field  Detailed palaeomagnetic work on Late Triassic sedimentary rocks, spanning a range of palaeoclimatic zones in the north Atlantic region, also supports a GAD geomagnetic field model  Earth’s evaporite record extends in abundance only through the Proterozoic Eon ; studies such as this are therefore unlikely to characterize the growth of Earth’s geomagnetic field, which seems to have occurred before 2,450 Myr ago  Eight Permian–Carboniferous deposits with volumes greater than 10 4  km 3 have a weighted-mean dipole palaeolatitude of 21 ± 4°, nearly identical to the Cenozoic–Mesozoic mean and nearly unaffected when previously estimated octupolar components are included in the pole calculations ( Table 1 ) Evaporite palaeolatitudes The world’s largest Cenozoic–Mesozoic evaporite basins, with preserved salt volumes greater than 10 4  km 3 , are listed in Table 1 ; references are given in Supplementary Data  Evaporites with volumes greater than 10 3  km 3 are restricted to the Proterozoic era, as old as about 2,250 Myr Fifty years ago, the emerging science of palaeomagnetism admirably succeeded in reconstructing consistent palaeoclimatic zones in the context of post-Pangaean continental drift  Figure 3 shows the effect on surface inclinations of 0–40% subsidiary zonal octupole of the same sign relative to an otherwise pure GAD field , for the 15° and 35° latitudinal bounds of the modern arid zones and for the mean depositional latitudes of Cenozoic–Mesozoic evaporite basins For basins of these ages, special care was taken to consult primary constituent palaeomagnetic studies in order to determine which latitude estimates are most reliable For some basins the palaeomagnetic record is complete enough to show continental motion through alternate times of evaporite and carbonate deposition, in patterns consistent with latitude crossings between subtropical arid and equatorial humid zones ( Fig. 2 ) Geophysical considerations on the feasibility of the high-obliquity hypothesis are generally negative , yet the spatial distribution of Precambrian glacial deposits, which lack any well-documented high-latitude examples, currently permit both the snowball and high-obliquity models  Given that Phanerozoic obliquity is universally considered to have modern-like values , the palaeomagnetic record of evaporites thus argues for uniformitarian orbital dynamics of the Earth–Moon system at least as old as the Palaeoproterozoic era Here I revisit the evaporite palaeolatitude test according to the current palaeomagnetic data set and extend it back through Proterozoic time, to the oldest recognized examples of large evaporite basins on Earth However, those departures would need to be extreme to produce the near-equatorial results, and, on the contrary, stratabound antiparallel palaeomagnetic polarity reversals from within some of the Proterozoic glaciogenic successions seem to reflect ‘typical’ geomagnetic behaviour of more recent times Implications First-order consistency of Precambrian evaporite basin palaeomagnetic latitudes with modern arid zones and Cenozoic–Mesozoic evaporite palaeolatitudes confirms the GAD hypothesis for the Earth’s magnetic field since about 2,000 Myr ago, about four times longer than known from previous palaeoclimatic–palaeomagnetic global comparisons  In conjunction with an assumed GAD field, these simulations would predict a unimodal peak of evaporite palaeomagnetic latitudes at 0°, with a large standard deviation In contrast with Ordovician and younger ice ages, which are characterized by expectedly high palaeolatitudes, Proterozoic glaciogenic deposits have until now yielded purely low to moderate palaeomagnetic latitudes, including several near-equatorial results of high reliability  In the present compilation, the Palaeozoic (and late Ediacaran) basins are separated into two groups: Permian–Carboniferous, for which quantitative estimates of octupolar field components are available through palaeogeographic consistency tests across large continents , and Devonian–Ediacaran, for which no such estimates currently exist Modern tropospheric Hadley–Ferrel circulation descends on the subtropics of both hemispheres, where evaporation exceeds precipitation in today’s desert belts Nonetheless, the present compilation addresses several important issues of deep time: first, that the high-obliquity hypothesis has failed an important observational test that is independent of Earth’s Precambrian glacial record; second, that near-equatorial palaeomagnetic latitudes of Precambrian glacial deposits are not likely to be substantially biased by non-dipolar field components, unless such components were of exceptional magnitude and short duration coincident with ice ages; and third, that—according to the available tests—Earth’s time-averaged magnetic field may be approximated by a geocentric axial dipole for most of the past 2 Gyr Octupole-corrected early Palaeozoic APW paths are not yet available for all continents, but such calculations will help to determine whether the early part of the Palaeozoic era was a time of departure from an otherwise uniformitarian GAD field, perhaps as a result of particular convective patterns at the core–mantle boundary  Only the Devonian–Ediacaran subset shows a significantly shallower mean inclination at the 99% confidence level (Student’s t -test), which could be interpreted as a persistent octupolar component of 19% relative to the dipole Other factors may have contributed to the substantially shallowed mean inclination for Devonian–Ediacaran evaporites, and the slightly shallowed mean for pre-Ediacaran evaporites: first, narrowing of the Hadley zones due to a faster rotation rate ; second, a shallow bias of palaeomagnetic inclinations due to sedimentary magnetization processes ; and third, particular continental distributions conducive to aridity in deep tropical regions  Palaeolatitude estimates vary little with averaging method or data selection, except for the age intervals of the Silurian–Devonian and the Early Cambrian , at times of widespread evaporite deposition ( Table 1 ) Palaeozoic evaporites are widespread and voluminous, as reviewed comprehensively by Zharkov  Precambrian evaporite latitudes on Earth show a significantly non-zero mean with low variance ( Table 1 ), consistent with a ‘normal’ climate gradient on a low-obliquity world Regarding the second process, the pre-Ediacaran mean remains low even when only igneous-based palaeomagnetic results are considered ( Table 1 ) Short-term departures from low Earth obliquity are not possible because of the stabilizing influence of the Moon  Some support for the latter possibility was raised by means of numerical geodynamo modelling with spatially non-uniform core–mantle boundary conditions  Subsequent studies considered evaporitic rocks as old as the Cambrian period and found deposits concentrated in palaeolatitude bands consistent with modern evaporite belts of 15–35° latitude  Success of the uniformitarian principle in explaining evaporite distributions implies that its failure, with regard to low-latitude Precambrian glaciation, is most probably caused by anomalies in palaeoclimatic rather than geophysical processes. Such a tendency would similarly impart a low-latitude bias to the preserved subset of rift-related evaporites, but the largest basins considered here are found in variable tectonic settings that should be independent of supercontinental episodicity Testing high obliquity Three published general-circulation climate models have reported evaporation–precipitation trends as a function of latitude on a high-obliquity planet with otherwise Earth-like parameters  Testing non-dipole field components The second application of evaporite palaeolatitudes considers the long-term structure of the geomagnetic field The basins are distributed primarily through the 15–35° arid latitude belt as determined previously, with a 23 ± 4° (95% confidence) volume-weighted mean latitude ( Fig. 1 ) that is independent of icehouse–greenhouse global climate state and the reversal frequency of geomagnetic polarity The concept of a ‘hard’ snowball with global ice cover enduring for millions of years has been controversial, with some scientists advocating partly unfrozen tropical oceans  The distribution of ancient evaporite deposits can help distinguish between these non-uniformitarian alternatives The first process may have contributed to the shallowing of Precambrian inclinations but not substantially to the more marked early Palaeozoic anomaly The Precambrian volume-weighted mean evaporite basin latitude (17 ± 3°) is indistinguishable from that of the entire Phanerozoic eon (20 ± 3°) The present compilation of evaporite inclinations does not provide further insight into this debate, because error-minimizing octupole field corrections for Permian to Late Carboniferous APW paths have no significant effects on the volume-weighted mean for evaporites of that interval ( Table 1 ) The principle of uniformitarianism, in which modern geological processes guide our conception of the ancient world, has faced a challenge in the field of Precambrian palaeoclimate The significantly shallowed early Palaeozoic mean evaporite palaeolatitude could be a result of the third process, because several of the larger basins reconstruct near the vertex of a proto-Tethys-like sea , which may have been influenced by monsoon-like circulation in the same manner that produces anomalously dry conditions in present-day eastern Africa  The slightly shallowed pre-Ediacaran mean inclination could also reflect one or more instances of similar palaeoclimatic peculiarities The volume-weighted mean inclination from the 15 palaeomagnetically constrained basins among this group (31.6 ± 2.1° (s.e.m.)) corresponds to a GAD palaeolatitude of 17 ± 3° (95% confidence) These simulations indicate a near-isothermal to weakly reversed mean-annual zonal climate pattern, depending on whether the oceans are allowed to store and release heat through the annual cycle This result is slightly lower than the Cenozoic–Mesozoic baseline value, with possible causes discussed below  wander through supercontinental cycles  This value is broadly similar in magnitude to that of the aggregate database-wide inclination tests of Kent and Smethurst , who found a best-fit same-sign octupole component of about 25% for pre-Mesozoic data Using the Cenozoic–Mesozoic evaporite inclination baseline, an octupolar contribution of this magnitude shifts the expected inclination range to 21.9 ± 2.5° (s.e.m.) Whenever there is any annually averaged evaporative peak present, the models locate this maximum at a single arid belt centred on the Equator
 Adaptation of other serotypes will require a methodical process of research and development, and safety testing Adenovirus serotype 5 is common — depending on the geographical region of the world, most adults are exposed to it and develop some level of immunity Among the most promising viral vectors is a form of common-cold virus known as adenovirus serotype 5 Among these, rAd5 is the best characterized and is perhaps the most attractive for vaccine development As a stand-alone vaccine, rAd5 can elicit different types of T-cell immunity (those due to CD4 and CD8 cells), and more potent immune responses can be achieved with a ‘prime-boost’ approach As Roberts et al . hoped, when the HVR chimaeras were administered to mice or monkeys that had antibody immunity to rAd5, there was no decrease in the immunogenicity of the vector As we await these data, chimaeric vectors can be manufactured and tested in humans, so that we can further assess the potential effects of anti-vector immunity. Because host antibodies that neutralize rAd5 are directed against the hexon subunit, Roberts et al . studied the atomic structure of this protein to understand where antibodies would probably bind Because the traditional approach of live-attenuated vaccination is not feasible for most diseases, scientists have turned to molecularly engineered viruses that contain pathogen-specific gene inserts But anti-vector immunity may be a serious limitation By exchanging all seven HVRs of rAd5 with those of the rare adenovirus serotype 48 (Ad48), the authors constructed a chimaeric adenovirus that could potentially evade the neutralizing antibody response against rAd5 Current rAd5 vectors for HIV-1 are being evaluated in phase II human trials that will more precisely define the extent and effect of pre-existing anti-vector immunity For example, use of vehicles known as DNA plasmids followed by boosting with rAd5 can generate durable antibody and T-cell immune responses  Furthermore, preliminary data from other serotypes, such as rAd35 and rAd11, suggest that they may be less immunogenic — that is, less effective in producing immunity — than rAd5 Furthermore, the use of multiple chimaeric serotypes could allow booster vaccinations to sustain the long-term immune memory response needed for durable immunity Hence the work of Roberts et al . , described on page 239 of this issue In adenoviruses, the viral DNA is surrounded by a protein shell called a capsid that contains hexon and penton subunits Indeed, there are more than 50 known human adenoviral serotypes, some of which are quite rare in the human population Molecular modelling revealed that the seven hypervariable regions (HVRs) of the hexon form the outer surface of the protein, making the HVRs a likely target for antibody binding Numerous viral vectors are being studied for use in gene-based vaccine strategies One can envisage the construction of numerous HVR chimaeras that could be used to vaccinate against various pathogens Potential ways around this problem include the use of adenoviruses derived from other human serotypes or from non-human animal species Preclinical studies of rAd5 vaccines include vaccines against Ebola, SARS, HIV-1 and anthrax , and phase II human clinical studies of rAd5 HIV-1 vectors are in progress Such viral vectors direct host cells to produce the foreign protein of interest, thus prompting a pre-emptive immune response The advantages of rAd5 are that the necessary groundwork has been laid, in terms of basic molecular engineering and production of the vector, and that it has been through the regulatory approval process for use in humans The core structure of the hexon protein was not altered, so the resulting HVR-chimaeric rAd5 vectors retained their ability to grow well in culture and, importantly, the immunogenicity of the chimaeras was comparable to that of rAd5 The existing immunity to rAd5 in many adults means that the vector could be neutralized before it can have an effect The genetic manipulation required to engineer alternative serotypes is not trivial, however The most commonly used vectors are derived from poxviruses, alphaviruses and adenoviruses The potential of this technology is considerable The rAd5 vectors contain specific genetic deletions that render them unable to replicate The recombinant adenovirus vectors (rAd5) cannot replicate and can be safely administered, and they elicit both of the two main types of immune response — secreted antibodies and disease-fighting T cells The results are a tribute to the application of modern immunology and structural biology to vaccine design There are still no vaccines against such devastating and widespread diseases as malaria, tuberculosis and AIDS There is a problem, however These data provide a proof-of-concept that viral vaccine vectors can be engineered to evade pre-existing immunity They have taken a fresh approach to the molecular engineering of rAd5, one that has the potential to circumvent anti-vector immunity and expand the applicability of such vectors for human vaccination This contributes to their safety, but also means that specially engineered cells must be used to produce them This may lessen the effectiveness of rAd5 as a vaccine vector Thus, if rAd5 itself were used to vaccinate children against malaria, a chimaeric vector could still be used as an HIV vaccine Vaccine developers will have to show that these new HVR-chimaeric rAd5 vectors can be manufactured, and that they have stable gene inserts, can pass regulatory review and, finally, are immunogenic in humans with pre-existing immunity With this as background, Roberts and colleagues took advantage of our improved understanding of anti-vector immunity, coupled with structural data about viral proteins, to derive a rational approach to re-engineering the rAd5 vector Yet we are still some time away from studies in humans
 And last but not least, Ball writes extensively about the traditional (galenic) medicine and chemistry that Paracelsus challenged At times Paracelsus disappears into the background, and the reader is in danger of getting lost in detailed descriptions of Renaissance culture Ball is aware of the historiographic difficulties surrounding the life and work of Paracelsus Ball speaks of Paracelsus views on astrology in relation to the astronomy of Copernicus and his followers Ball takes events in the life of Paracelsus as starting points for discussing the Renaissance world Ball, for instance, is often wobbly in calling details of Paracelsus work ‘mechanical’, ‘spiritual’ or ‘materialistic’ Ball, however, sets Paracelsus in the social, religious and cultural life of his time, a refreshing move away from the tendency to describe early ‘scientists’ as the forerunners of todays scientific developments By presenting the work of Paracelsus, including all the contradictions and neologisms, as an intensely personal enterprise embedded in Renaissance life, Ball circumvents many of the historical difficulties and comes up with an excellent biography that is relevant for historians and general readers alike For example, Ball maintains that Paracelsus concentration of natures potencies in the preparation of medicines was “not mechanical” (presumably in a modern sense), but on the next page he states that, according to Paracelsus, the powers of the stars permeate “mechanically” through the Universe (thereby referring to Paracelsus own words) For instance, when discussing Paracelsus life as a vagabond, Ball speaks about the difficulties of travelling in early modern Europe He is said to have ridden a magical white horse, to have cured many incurable diseases, and to have carried an enormous sword with magical powers, as well as the secret elixir of life His account starts with a brief discussion of how magic and occult forces were accepted parts of early modern science His discussion of the alchemy of Paracelsus transforms into a discussion of economic growth and the power of miners, and his religious and political views are compared to those of reformers and princes His name was linked with those of Faust and Martin Luther, and among the many miracles he allegedly performed was the creation of a living, human-like being In addition, Ball acknowledges the close connection between early modern natural philosophy, Renaissance humanism and Reformation religion In both cases Ball refers to the working of invisible powers, but apparently these are mechanical in one case but not in the other, leaving it unclear what Paracelsus meant when he spoke of the mechanical working of the invisible forces of nature In so doing, he follows a fairly recent trend in the history of science and medicine in which religion and science are seen as mutually shaping fields of knowledge In The Devils Doctor , Ball convincingly shows that in order to understand Paracelsus work and personality we must accept that “in the philosophy of Paracelsus science and rationalism do not compete with mysticism and superstition but blend with it, producing a world that now seems at the same time wonderful and bizarre” It is this awareness that makes Balls account of Paracelsus essential reading for historians and scientists alike. It is too easy to argue that, for this reason, the lexicons provided by scholars of Paracelsus must be taken “with a pinch of Paracelsian salt” K Moreover, in a book as ambitious as this it is almost unavoidable that the terminology becomes at times confusing Moreover, it shows that magic was as much at the root of modern science as were the famous discoveries of our modern scientific heroes Much of Paracelsus work teeters on the brink of the spiritual, and his own vocabulary often seems puzzling to modern readers Not only are the works of Paracelsus own hand extremely difficult to read and understand but, more importantly, historical reconstructions of his life and thoughts complicate the picture to such an extent that it is hard to write a ‘fair’ biography One has to admire Philip Balls courageous undertaking in writing a biography of Paracelsus, arguably the most controversial medical writer in the Renaissance Paracelsus is known for being a failed physician; a psychiatric subject in the casebooks of the psychoanalyst Carl Jung; a German national hero during the Nazi period; and the founder of biochemistry Paracelsus, or Philippus Aureolus Theophrastus Bombastus von Hohenheim, spoke to the imagination Rowlings Harry Potter novels Sometimes it is not clear whether he adopts Paracelsus own words or gives them a modern, and therefore different, meaning The books illustrations provide a vivid picture of the time and further enliven Balls account The difficulty in understanding Paracelsus neologisms and expressions is clearly visible in this book The same goes for the important paracelsian distinction between the material and the spiritual, which at times makes Balls description of Paracelsus thoughts somewhat bewildering This approach is brave and enriching but is also a little overwhelming This criticism notwithstanding, The Devils Doctor is a fascinating read, rich in content and hugely entertaining To be fair to Ball, he does explain many of Paracelsus neologisms, but he also has the tendency to follow Jung in maintaining that the language used by Paracelsus must be seen symbolically as an expression of his unconscious mind To my mind, one of the most urgent tasks of the historian is to find out what precisely Paracelsus meant Today, Paracelsus appears as a hero in the magical world of J Without making this effort, the description of his work can only remain superficial Yet, perhaps because of the intricate mixture of paracelsian magic, metallurgy, medicine and alchemy, the historical Paracelsus has received comparatively little attention
 Abdul Qadeer Khan, former director of Pakistans nuclear programme, was a keen proponent of spreading nuclear technology to other Muslim nations Adults in Turkey, for example, are even less accepting of evolution than are those in the United States. newsad; Nick Matzke of the National Center for Science Education, a not-for-profit organization based in Oakland, California, has debated intelligent design with Aykol in a Muslim online forum — a first for all concerned — but he thinks that Aykols enthusiasm for the United States is unlikely to be reciprocated Although academic freedom continues to be limited in Muslim countries, the field of Islamic theology is rife with debate and disagreement on many science-related topics Although theologians and scholars of religion debate among themselves, it needs a brave lay person or scientist (who is also conversant with theology) to challenge them in public American conservatives, he says, are not about to reconsider their views on Islam any time soon. “I find it peculiar that Muslims are adopting a doctrine from US groups that regularly bash Islam in a fairly vicious way,” he says Among the rationalists, for example, is Tariq Ramadan, a philosopher of religion at the University of Oxford and the maternal grandson of Hassan Al Banna, the Muslim Brotherhoods founder And third, Helbawi believes that science has a role in strengthening religious belief Another is evolution As more Muslim countries give their citizens the right to vote, Islamist political groupings have taken power, or form the main opposition, in national or regional assemblies in Iraq, Kuwait, the Occupied Palestinian Territory, Bahrain, Egypt, Afghanistan, Jordan, Morocco, Malaysia and Turkey At one level, Qaradawi is a literalist in that he regards every word of the Koran as the word of God, which he sees as applicable for all times to come At Peshawar University on the Grand Trunk Road linking Pakistan, India and Bangladesh, there is much talk of growth At Peshawar University, meanwhile, vice-chancellor Rashid is looking to increase direct links with foreign universities, having concluded an agreement to carry out teaching and research jointly with the University of Leicester, UK; the city of Leicester has a large British Asian population Because of this, the field of science and technology policy in all four countries is weak or non-existent Belief to us Muslims is not against reason or intellect.”  Qaradawi is concerned that Islamist opposition movements are too literalist and are not doing enough to encourage independent thinking using reason, known in Arabic as ijtihad . “My worst fear for the Islamic movement is that it opposes free thinking for its followers and closes the door to ijtihad ,” he says. “If my fear turns into reality, then capable minds that can renew and innovate will escape from our ranks, leaving behind those conservatives who can only imitate and who would like everything to stay as it is, regardless of how ancient it is.”  Ijtihad is sometimes called Islams forgotten pillar But for him, Peshawar Universitys ultimate aim has to be a higher one But he also understands that an environment that supports critical thinking was one hallmark of Islams golden age of scientific development (see Islamic era science ) But officially it does not exist — it is banned everywhere, and membership can be punishable by long spells in prison But on this issue, as others, public debate is not as free as it is in more open societies But that is history, as books, pamphlets and films on creationism are now more popular in Muslim countries, and pro-evolution scientists are afraid to speak out But the picture becomes more nuanced the closer one looks at Islamist governments once they are in power But third-party sperm donors are allowed in Iran because the alternative (a couple splitting up if they cannot have children) is considered worse for society But this view is not shared by other Muslim states But what might seem surprising to outsiders is that, after many years of neglect, the universitys expansion comes at a time when local people have elected an alliance of political parties which, like the Taliban, want to base most laws on the Koran But, as the data on page 26 show, the picture in the broader Muslim world is not much better Call to arms Second, each country has directed funds towards military RD, money that could, for example, have been spent on RD towards alleviating poverty Consequently, todays Muslim states barely register on indices of research spending, patents and publications, and only Turkey has universities in the global top 500 Could a university vice-chancellor in Peshawar be of any other faith? In todays Peshawar, a non-Muslim vice-chancellor would be next to impossible Egypt and Turkey also both recently announced plans to develop nuclear power Even today, few universities enjoy much autonomy, and appointments to research posts are opaque and prone to corruption Excellence in teaching, research and creative endeavour are the highest priority, Rashid says First, it is a set of tools to help humankind enjoy a higher quality of life through new technologies or by solving problems that afflict the poor For example, in explaining support for a nuclear deterrent he quotes chapter 8, verse 60. “Hence make ready against them whatever force and war mounts you are able to muster, so that you might deter thereby the enemies of God.”  Listening to Helbawi, it seems that although science investment may go up, the space to disagree with the official line will go down For Helbawi, science has three functions in society For Muslim societies, a literal interpretation of the Koran would present as many barriers to science and to freedom of thought as did the secular governments of the past Freedom to think How literally they interpret the Koran will clearly influence how the new Islamist governments regulate science and technology He also worries that Helbawis literalism amounts to an invitation not to think, and to assume, for example, that if all science is contained in the Koran, there is no place in society for new knowledge He does so to underline that these are not his opinions — they have divine endorsement He has been building alliances with US faith-based groups such as the Discovery Institute in Seattle, Washington state He is now under house arrest in Islamabad for selling uranium-enrichment technology to Iran, Libya and North Korea, A third trend suggests that Islamist governments are likely to restrict academic freedoms as much (if not more) than the secular regimes they want to replace His book Priorities of the Islamic Movement in the Coming Phase (Awakening Publications, Birmingham, Alabama, 2002) is in effect a manifesto for the next wave of Islamist governments If secular governments did little for science, can Islamist ones be any worse? In the search for answers, Egypts Muslim Brotherhood is a good place to start In an article for the US National Review last year he wrote: “Intelligent Design can be a bridge between these two civilizations In common with the majority of Pakistanis, Rashid is a Muslim, something that he is proud to make known In common with, arguably, most Muslims, Helbawi sees science and Islam as being in harmony, and he says that any government led by the Muslim Brotherhood will reverse decades of underinvestment in RD In each country, there are equal numbers of women and men entering many faculties In Egypt, 88 brotherhood members of parliament together form the largest grouping after that of the government In his view, the Koran, in addition to being the word of God, was designed by God to convince doubters of the truth of Islam and of creation. “I urge all scientists to read the Koran, from which they will learn much about so many scientific topics,” he says In the absence of basic infrastructure in many countries, the brotherhood and its sister organizations run schools and hospitals, and its members include many scientists In the case of Iran and Pakistan, there has been a substantial expansion in higher education and more spending on research, measures to improve scientific quality, and some opening up of labs to scientists from overseas Indeed, in Iran some 70% of science and engineering students are women Iran, like Pakistan, insists on maintaining a capability to enrich uranium to weapons grade Irans university population has swelled from 100,000 in 1979 to 2 million today Is this a rose-tinted view or a genuine commitment? The answer may depend on the resonance of science and technology with the wider debates occurring in Muslim society Islamic opinion on bioethics varies widely, and different countries regulate in different ways Islamist is a term used to denote those committed to the application of Islamic principles and Islamic law in politics Islamists have a reputation for looking inwards and shutting out the outside world, but they can look west when they need to, says Abdelwahab El Affendi of the University of Westminsters Centre for the Study of Democracy, in London, and chronicler of the rise of Islam in Sudanese politics. “Islamists that come to power on the back of we-dont-need-the-West rhetoric end up becoming more pragmatic,” he says king (see A long tradition , page 24) Its national centre for excellence in geology is to get 11 new labs, a library and a new museum Its original aims included taking power, opposing Western influence in Egyptian politics, and governing using the Koran as the basis for lawmaking Kamal El Helbawi, who now lives in London, is a one-time senior official in the Muslim Brotherhood, and its former spokesman in Europe Like many Islamists, Helbawi peppers his explanations with quotes from the Koran Mixed message The partys presence and influence has expanded across the Muslim world — from the Middle East to Africa and Asia Moreover, thanks to cable television (in particular the Al Jazeera channel based in Qatar) and the Internet, this debate is beginning to be seen in public as never before Much of this is candidly documented in the four volumes so far of the Arab Human Development Report from the United Nations Development Programme, written entirely by Arabic-speaking social and natural scientists (see page 33 ), which lays bare how knowledge-based activities such as science, innovation, book publishing, art and literature in Arabic-speaking countries are among the weakest in the world Muslims are discovering that they share a common cause with believers in the West.”  In the late nineteenth century, Darwins On the Origin of Species had a favourable reception in Muslim countries None of the universitys activities is unusual for a leading institute in a developing country One fear is further restrictions on freedom of expression One keenly contested area for theologians is that of the ethics of new technologies One of the Muslim Brotherhoods leading thinkers, the Egyptian scholar Yusuf Al-Qaradawi, who now lives in Qatar, is controversial in the West, but has mass support in the Arabic-speaking world, as well as among Muslims in Europe and North America Pakistan, along with the Islamic Republic of Iran and Sudan, has been run by governments that put Islam at the centre of politics for many years Pakistans university population has increased from 276,000 in 2001 to 423,000 in 2004 Pamuk was accused of insulting Turkishness Peshawar is the capital city of Pakistans northwest frontier province, the border region with Afghanistan where the Taliban first emerged among the Afghan refugee population in the 1990s Political leaders in the Muslim world, even in countries run on strict secular lines, are famously intolerant of dissent, as last years attempted prosecution in Turkey of Orhan Pamuk, this years winner of the Nobel prize for literature, demonstrates Ramadan says that the Koran should not be quoted outside of its religious and historical context Research into the role of government in public life, for example, requires governments to open up to the research community — something that these countries do not do Saudi Arabia bans third-party in vitro fertilization on the grounds that sex and procreation is limited to husbands and wives Saudi Arabia, Sudan, Iran and Pakistan are very restrictive environments for certain kinds of researchers, especially social scientists, to work in Second, science and technology can be used to deter aggression, a justification, Helbawi believes, for developing a nuclear deterrent Significantly, he has recently moved closer to philosopher Ramadan in his belief that Islamist governments should encourage self-criticism, that they should learn from failure, and that they have a duty to protect freedoms, including academic freedom and the freedom of any citizen to disagree with the state. “We want scientific thinking and the scientific spirit to guide our life in every way,” he says. “It is against the scientific way of thinking to oversimplify complicated issues, or to view difficult problems with an alarming superficiality Similarly, Pakistan is practically alone in the Muslim world in banning organ donations from cadavers Some Islamic thinkers are reaching out to the West in surprising ways Sudans public-sector universities, too, increased from 5 in 1989 to 26 in 1996 The full Islam and Science special is available from news@nature.com The grandparent of Islamists, the brotherhood is a political party founded in Egypt in 1928 The prominent Turkish writer and columnist Mustafa Aykol has creationist views and publishes translations of US proponents of intelligent design The provincial government, moreover, has handed the university the job of running a botanical garden and a 40.5-hectare national park The report does not consider non-Arab member states of the 57-strong Organization of the Islamic Conference (OIC), such as Indonesia, Pakistan and Turkey The situation for Muslim science has been bad, and one assumption, based on current trends, is that things can only get worse The university is run by Haroon Rashid, a professor of chemistry who was appointed vice-chancellor in January 2006 This is because the countrys Islamic authorities view the human body as being on loan from God, and when a person dies, the body needs to be returned to its creator close to its original state This is: “to love and serve the entire creation of the creator”. This university expansion is, however, creating its own tensions as the economies are not large enough to absorb so many new graduates, particularly women To avoid censure its members stand as independents at election time, or as members of alternative parties To others, it poses a threat to Islam by weakening its teachings Unusually for Pakistan, the current provincial government has forbidden male doctors from attending to female patients and has banned music on public transport Using Sudan, Pakistan and Iran as examples of countries where Islam is prominent in politics and which may foreshadow what may follow elsewhere, certain trends are clear What can Muslim scientists expect from the new Islamist parties that are seeking power across the Muslim world? Will there be more support for science and for research infrastructure, as in Peshawar, but an environment where basic freedoms continue to be denied? The mostly secular, although undemocratic, regimes that have hitherto ruled for decades across the Muslim world have rarely paid more than lip-service to investment in science and technology Where do the differences in opinion lie? Saudi Arabia (an Islamic monarchy) and Iran, for example, have very different ideas on medical ethics Why the neglect of the poor? For many Islamists, achieving independence from Western nations, defence and national security are higher priorities than the Islamic duty to care for societys poorest Yet within the brotherhood itself, there is much debate on literalism, reason and rationality, suggesting that totalitarianism is not the only option
 A tough lesson Although the science budgets of the OIC countries are all near the bottom of the world league, their spending on education is more variable African OIC countries, in contrast, tend to spend proportionately less on the military All six were among the worlds top 25 spenders on education in 2002 (ref. 3 ) Although many OIC countries are among the worlds poorest, with almost half being developing countries, their spending is consistently less compared with the national average across a range of income brackets Among the OIC countries, Chads economy grew more than 10% per year and Nigerias 6% As a first step, more OIC governments need to gather data on science, producing figures that are sufficiently reliable to appear in international statistics databases. As for the bottom performers, sub-Saharan Africa accounts for 21 of the 57 OIC countries and, with the exception of Cameroon and Gabon, are among the poorest Balancing act The Kemalist legacy has fostered Western-style scientific organizations and policies Both countries have eclipsed Egypt, previously the most prolific of all OIC states in scientific publishing, which grew only slowly between 1988 and 2003 But combining these data for 20 OIC nations covering 1996–2003 gives the average annual spend on RD as 0.34% of GDP, much lower than the global average over the same period of 2.36% (refs 2 , 3 ) But of the 20 poorest performers on this score, 15 are OIC countries, including many African nations, Bangladesh and Pakistan But overall economic levels remain poor, with growth rates usually far below the 7% minimum considered necessary to begin meeting the Millennium Development Goals But science in these nations is weak, with spending on research and development far lower than the global average But the insistence on removing religion from public life introduced restrictions of its own But there are signs of hope when looking at the OICs top and bottom performers Chemistry and physics papers make up greater shares of total output in central Asian countries, life sciences in North Africa, Indonesia and Malaysia, as well as Saudi Arabia, and engineering predominates in most Middle Eastern and north African countries Fig. 1 Recognized authorities such as UNESCO or the World Bank Development Indicators have few reliable data on science spending in most OIC countries Fig. 2 Moreover, over the past two decades the number of papers produced by 24 OIC nations has remained flat or declined, albeit with some striking exceptions (see chart, right) For decades, Turkey has aimed for membership of the European Union (EU); formal negotiations began last year For example, women are banned from wearing headscarves in government-funded universities — something that may have to change if Turkey joins the EU Given such diversity, it is hard to identify trends across the Islamic world as a whole Health and social sciences get little attention except in south Asia and African countries If others follow where Turkey and Nigeria lead, these science indicators might look very different in ten years time In 2003, the world average for production of articles per million inhabitants was 137, whereas none of the 47 OIC countries for which there were data achieved production above 107 per million inhabitants  Malaysia, Saudi Arabia and Yemens relative education budgets are among the worlds highest Many OIC countries, particularly the richest, spend more on armaments than on science, education or health  Modern Turkey grew from the ruins of the Ottoman empire Morocco, Tunisia and Iran also spend respectable sums on education Most was down to oil, but agriculture was also important Mustafa Kemal Ataturk, Turkeys founder, was keen for his country to catch up with the West Negotiations require even closer structural alignment with EU member states, and since 2003 science funding has more than trebled Nowhere is the OIC deficit greater than in the oil-rich nations; Saudi Arabia and Kuwait, for example, spend less proportionately on research than the poorest OIC countries (see chart below, and page 28 ) Of the 28 lowest producers of scientific articles, as recorded by the US National Science Foundation , half are OIC countries One potential bright spot is Nigeria, which announced in July that it is considering ploughing its oil revenues into a US$5-billion endowment fund for science and technology, which would make it Africas biggest science spender by far  Otherwise, Indonesia (14%) and Morocco (11%) are the only OIC countries with high-tech exports greater than 10% Part of the explanation lies in spending priorities Science indicators for OIC countries are also scarce among data collected by the World Bank and United Nations agencies — largely a reflection of many of these countries low level of interest in science Scientific divide The articles published by OIC countries show striking disciplinary and geographical differences  Several countries, including Côte dIvoire and Gabon, still show negative growth. newsad; Not surprisingly, science is correspondingly weak, and although hard data are few, Islamic countries in sub-Saharan Africa have about 20 researchers and engineers per million people, compared with about 250 in Latin America Six of the worlds top ten military spenders as a share of public spending are OIC countries: Kuwait, Jordan, Saudi Arabia, Yemen, Syria and Oman (each spending above 7% of GDP on arms in 2003) Stretching from Indonesia to Morocco, and from Uganda to Kazakhstan, countries with large Muslim populations are home to some 1.3 billion people The exceptions are Malaysia and Turkey, whose spending is comparable to other moderately wealthy nations The full Islam and Science special is available from news@nature.com The highest scoring OIC country is Jordan, with 1,927 researchers per million people; the OIC average is 500 The Islamic world encompasses remarkable diversity in political systems, geography, history, language and culture (see page 20 ) The latest available data, for 2004, show five years of growth, after two decades of decline The OIC average was just 13 The OIC countries low investment in science and technology is also reflected in a poor scientific output, including low levels of scientific articles and numbers of researchers The OIC countries performance in education also varies more widely, according to the World Banks education index, suggesting that many have the human resources that could exploit greater investment in science and technology  The OIC countries produce so few patents that they are invisible on a bar chart of comparison with other countries  The ongoing economic recovery of sub-Saharan Africa is “one of the most remarkable stories of the past five years”, according to the 2006 World Bank Development report  The other rising star is Iran, which from a low base of less than 100 articles per year a decade ago now produces nearly 2,000 The top global performers (Finland, Iceland, Sweden and Japan) all have above 5,000 researchers per million people These OIC nations cluster at the bottom end of the global scale This lack of technological competitiveness translates into low rankings in terms of high-tech exports as a percentage of total exports — with one exception, Malaysia, which ranks fifth worldwide with 58% high-tech exports, alongside Singapore and the Philippines This much is acknowledged to be true, but what of the details behind the broad picture? The official statistics database of the Organization of the Islamic Conference (OIC) reveals information on each of the 57 OIC nations on everything from arable land per tractor to Internet users, but you wont find any data on research  To get a more detailed picture of how OIC countries measure up on science and technology, and of what patterns exist within OIC countries, Nature extracted science indicators from official sources and reanalysed them for the OIC group as a whole, creating an overall picture of science and technology indicators for OIC countries Turkey, for example, is not rich in oil, but is the most scientifically successful of the Muslim states Turkeys publication rate per year has grown from around 500 in 1988 to more than 6,000 in 2003 Turkish intellectuals attribute this to the 1923 revolution, which led to the creation of a constitutionally secular state Universities switched from using Arabic to the Roman alphabet, ensuring easier access to Western writings, and Ataturk initiated a nationwide campaign to raise literacy rates World Bank Development Indicators for 1996–2003 record numbers of researchers per million people for 19 OIC countries  Yet Turkey has respectable participation by women in academic life — higher than in some EU countries
 Although this is characteristic of supernovae and neutron star mergers, uncertainties in where the r-process occurs persist because stellar models are too crude to allow precise quantification of this phenomenon As a result, there are many uncertainties and assumptions in the models used to calculate the production ratios of actinides (like uranium-238 and thorium-232) Current estimates of the U/Th production ratio range from ∼0.4 to 0.7 Here I show that the U/Th abundance ratio in meteorites can be used, in conjunction with observations of low-metallicity stars in the halo of the Milky Way , to determine the U/Th production ratio very precisely  I also estimate the age of the Milky Way ( in a way that is independent of the uncertainties associated with fluctuations in the microwave background or models of stellar evolution . Some heavy elements (with atomic number A 69) are produced by the ‘rapid’ (r)-process of nucleosynthesis, where lighter elements are bombarded with a massive flux of neutrons  This value can be used in future studies to constrain the possible nuclear mass formulae used in r-process calculations , to help determine the source of Galactic cosmic rays, and to date circumstellar grains  A second relationship between T G and P U/Th can thus be derived: P U/Th = R LMHS U/Th e ( λ U - λ Th ) T G (2) where λ U and λ Th are the decay constants of 238 U and 232 Th (half-lives of 4.468 and 14.05 Gyr, respectively) After correction for decay during the 4.567 Gyr since the condensation of the first solids in the Solar System, this corresponds to an initial ratio of 0.438 ± 0.006 in the interstellar medium at Solar System birth ( R circdot; U/Th ) An additional constraint on the relationship between T G and P U/Th is given by the recent determination of U and Th abundances in the low metallicity halo stars (LMHS) CS 31082 - 001 and BD +17°3248, that show pronounced enrichments in the products of r-process nucleosynthesis  Assuming that P U/Th did not vary from one star to another, which would otherwise undermine any attempt to calculate ages based on the U/Th ratio , and that GCE and LMHS record the same T G (refs 2 , 4 ), then it is possible to solve these equations Because the r-process follows a path that is very distant from the valley of β-stability , on the neutron-rich side, the relevant nuclear properties used in the calculations cannot be measured and have to be inferred from extrapolations of theories that are anchored to measured nuclei  Conversely, if the history of nucleosynthesis is specified and R circdot; U/Th is known, then it is possible to derive a relationship between T G and P U/Th  Cosmochronology is the art of dating the duration of nucleosynthesis and the age of the Galaxy using the abundances of radioactive elements in the Solar System  Dauphas et al. developed an algorithm that allows the calculation, for a given T G , of the parameters of a nonlinear open GCE model that is constrained by, and therefore reproduces, the present gas surface density (13 ± 3 M circdot;  pc -2 ; ref. 26 ), the present total surface density of the disk (56 ± 6 M circdot;  pc -2 ; ref. 27 ), the solar metallicity at Solar System birth , and the G-dwarf metallicity distribution (see Fig. 1 , and Supplementary Information ) Determining P U/Th is crucial for chronometric applications For all but the most volatile elements, the composition of primitive carbonaceous chondrites is identical to that measured in the solar photosphere  For comparison, P U/Th obtained from equation (2) alone and assuming that LMHS formed 0.5 Gyr after the Big Bang is 0.465 ± 0.117, a value that is much less precise than the ratio obtained combining GCE and LMHS For comparison, the age of the Universe is 13.7 ± 0.2 Gyr (ref. 13 ) For this reason, a great deal of effort has been devoted over the last 50 yr to pin down this value precisely  GCE models had already been used to refine the value of the production ratio but the approach was circular, as an age was assumed to derive P U/Th using GCE, which was then used to choose acceptable nuclear physics models , which were used to calculate P U/Th , which was eventually injected in LMHS to derive a new age  Goriely and Arnould and Schatz et al. tested various mass formulae in r-process calculations and used earlier work on GCE to rule out some of them Goriely and Arnould estimated a value for P U/Th of , while Schatz et al. proposed a more restricted range of 0.603 ± 0.139 High velocity clouds containing low metallicity gas (∼(0.1–0.2) Z circdot; , where Z circdot; is the solar metallicity) are indeed seen being accreted by the Galaxy  If infall of such low metallicity material is taken into account, then it is possible to devise GCE models that reproduce the observed G-dwarf metallicity distribution  If one assumes that all the progenitors of 232 Th and 238 U are produced in equal abundances on the r-process path, then determining P U/Th reduces to counting the progenitors of each isotope  If the history of nucleosynthesis is specified, and if the age of the Galaxy ( T G ) and the U/Th production ratio ( P U/Th ) are known, then it is possible to predict what R circdot; U/Th should be Indeed, an exponential infall yields identical results for P U/Th and T G within uncertainties (  Gyr and , respectively) Interestingly, this turns out to be very close to the value that is obtained here,  It however fails to reproduce important astronomical observations It is often stated that the U/Th ratio measured in LMHS provides a model independent age of the Milky Way Low metallicity stars formed very early in Galactic history, presumably within 0.1–0.3 Gyr of the formation of the halo  Notably, it predicts far more low metallicity G-dwarfs than are actually observed ( Fig. 1 ) Note that in the later study , the authors had to rely on GCE calculations to rule out a nuclear mass model (HFBCS-1) that gave a lower P U/Th value of 0.455 Note that the rate of infall can be parameterized as an exponential or as a gaussian  The approach that is presented here avoids this circularity The calculations are in particular very sensitive to the formalism that is used to calculate nuclear masses , which directly affect the fission probabilities and the rates of neutron captures, photodisintegrations and β-decays The differential equations are nonlinear and only a numerical treatment is possible The fact that the age of the Galaxy is consistent with results obtained using other methods provides confidence that the production ratio is also accurate The initial U/Th ratio trapped in CS 31082 - 001 was produced by an earlier generation of supernovae or neutron star mergers and was only modified by free decay during the life of the star The most likely is that the Milky Way did not behave as a closed box, but instead grew from the accretion of matter throughout its history The most precise U/Th ratio measured in CS 31082–001 is 0.115 ± 0.029 (ref. 11 ) The radiometric age of the Galaxy is  Gyr and P U/Th is , if a gaussian rate of infall is adopted The radiometric age of the Milky Way (  Gyr) agrees with independent estimates based on colour–magnitude diagrams of globular clusters (  Gyr, ref. 14 ) and cooling sequences of white dwarfs (12.1 ± 1.3 Gyr, ref. 15 ) The result can be approximated by a simple formula, valid between 10 and 20 Gyr ago (details of the mathematical treatment of GCE can be found in Supplementary Information ): P U/Th = R circdot; U/Th /( aT G + b ) (1) where a = -1.576 × 10 -2 and b = 0.9946 for a gaussian rate of infall, and a = -1.968 × 10 -2 and b = 1.0114 for an exponential rate of infall; time is in Gyr The simplest GCE is the so-called closed-box model ( Supplementary Information ) The U/Th production ratio is also crucial to help determine the source material of Galactic cosmic rays and possibly date circumstellar silicon carbide and diamond grains  The U/Th ratio measured in these meteorites therefore represents a reliable estimate of the bulk Solar System ratio, which is 0.270 ± 0.004 (ref. 9 ; note that hereafter all errors given are 1 σ  or 68% confidence intervals) The value that is derived here on the basis of GCE and LMHS ( ) is much more precise than these two estimates ( Fig. 3 ) There are two equations ( equations (1) and (2) ) in two unknowns There is in fact no such thing as a model independent age for LMHS, as nuclear physics models are used to predict P U/Th (refs 2–8 ) and observations of rely on modelling of stellar atmospheres  These grains are found in primitive meteorites and are thought to have condensed in the outflows of massive stars, before Solar System formation These results are not very sensitive to the chosen parameterization of the infall rate This is, to my knowledge, the first time that P U/Th has been calculated on the basis of GCE and the Solar System U/Th ratio without making any assumption about T G , and the first time that a probabilistic meaning can be ascribed to the uncertainty quoted for the production ratio (+ 0.037/ - 0.031, 68% confidence interval) This problem can be reduced to determining the intersection between the two curves representative of equations (1) and (2) in T G – P U/Th space This procedure can be repeated for any given age between 10 and 20 Gyr, and the relationship between T G and P U/Th can be derived This question has received renewed attention in the past few years with the detections of U and Th in CS 31082–001 and BD +17°3248 (refs 10–12 ) This similarity may be coincidental, as a compilation of P U/Th values between 1957 and 2003 shows that the estimates actually vary from 0.4 to 0.7 ( Fig. 3 ) This value also agrees with earlier estimates of the age of LMHS  This value is the result of a competition between decay and nucleosynthesis integrated over the presolar history of the Galaxy , a process that is also known as Galactic chemical evolution (GCE) This zeroth-order estimate gives a value of 0.578 for P U/Th (ref. 2 ) To summarize, an age was assumed in GCE to calculate an age using LMHS Two groups tried to estimate P U/Th and assess its uncertainty in the framework of r-process calculations using state-of-the-art nuclear physics models Using the two curves derived from LMHS and GCE ( Fig. 2 ), it is easy to determine the uncertainty ellipsoid of the intersection and then compute the marginal probability densities for both P U/Th and T G  Various explanations have been advanced to remedy this problem  Weighing the various estimates of T G by their uncertainties, I obtain a more precise value of 12.5 ± 0.9 Gyr for the age of the Milky Way When the astrophysical conditions under which r-process nucleosynthesis occurs are clearly identified, the production ratio that is derived here could be used to constrain possible mass formulae and improve on r-process model predictions for other important cosmochronometers, namely 235 U, 244 Pu and 247 Cm When these parameters are known, it is straightforward to calculate P U/Th and its uncertainty With recent advances in mass spectrometers, U–Th dating of such material may become feasible in the near future.
 Although strongly recommended by an Indian expert panel, the programme has not been pursued But few countries allow foreign vessels into their ‘territorial waters’, 12 nautical miles from the coast, for research purposes But the international science community has so far had limited access to the collected data Foreign vessels are usually allowed into their exclusive economic zones, which lie between 12 and 200 nautical miles from shore France has made considerable efforts to develop a joint Indo-French research programme since the 2004 tsunami Further, India has acquired a significant amount of marine data around the Andaman–Nicobar region, both before and after the tsunami HMS Scott , a British Royal Navy vessel, did the first marine survey off the shore of Sumatra after the tsunami However, India has sent scientists to participate in the 2005 French marine survey, and plans to send more in July and August 2006, as part of the Sumatra-Andaman Great Earthquake research initiative ( http://www.ipgp.jussieu.fr/~singh/SAGER ) If India develops its own marine research programme, efforts should be made to integrate these data with others recently acquired in the Indonesian waters. One should not be surprised that India is concerned about security issues Sir I share marine researchers feelings about restrictions on carrying out research in Indian waters, as expressed in your News story “Indias ban on foreign boats hinders tsunami research” ( Nature 439 , 380 ; 2006 10.1038/439380b )
 But the recorded bulk magnetic field itself provides only limited spatial or structural information about the sample Here we demonstrate a fundamentally different and intrinsically information-richer modality of detecting NMR, based on the rotation of the polarization of a laser beam by the nuclear spins in a liquid sample In contrast, our measurements on water and liquid 129 Xe show that the complementary effect—the rotation of light polarization by nuclear spins—is readily measurable, and that it is enhanced dramatically in samples containing heavy nuclei It has been predicted that laser illumination can shift NMR frequencies and thus aid detection, but the effect is very small and has never been observed Most NMR applications rely therefore on more elaborate techniques such as magnetic field gradient encoding or spin correlation spectroscopy , which enable spatially resolved imaging and molecular structure analysis, respectively Nuclear magnetic resonance (NMR) in liquids and solids is primarily detected by recording the net dipolar magnetic field outside the spin-polarized sample Optical NMR detection has in fact a long history in atomic vapours with narrow resonance lines , but has so far only been applied to highly specialized condensed matter systems such as quantum dots  This approach to optical NMR detection should allow correlated optical and NMR spectroscopy on complex molecules, and continuous two-dimensional imaging of nuclear magnetization with spatial resolution limited only by light diffraction. A transverse magnetic field B 1 = 0.17 G oscillating at 21 kHz was also continuously applied so that proton spins were adiabatically locked to the rotating field as they flowed into the apparatus Although in this first demonstration of NSOR the signal-to-noise ratio (SNR) is significantly lower than for traditional magnetic detection, it could be improved in several ways Another class of possible applications involves studies of correlation between optical and NMR spectroscopy Another promising technique is to use a liquid-filled hollow optical fibre At typical NMR frequencies, it should also be easy to realize photon shot-noise sensitivity for higher laser powers Both magneto-optic effects discussed can be related to the Faraday effect (the rotation of the plane of polarization of a light beam by a magnetic field) But the complementary magneto-optic effect, the rotation of far-off-resonance light polarization caused by nuclear spins, is readily measurable with a simple experimental apparatus because of the high density of nuclear spins in a liquid Decreasing the laser wavelength ( λ ) increases the signal as 1/ λ 2 far from optical resonances, and even faster closer to resonances Figure 1b shows the optical rotation angle as a function of 129 Xe polarization recorded during slow decay of nuclear polarization Figure 2b shows the spectrum of the optical rotation signal with a peak at the 8 Hz modulation frequency For a 1-cm-long capillary sample with a volume of 100 nl in an optical cavity with an effective length of 10 m, placed in a 10 T magnetic field and probed with 1 W of light at 400 nm wavelength, we estimate (based on scaling of our current results) an SNR of 1,000 for proton spins in water after 1 s of averaging; the SNR would be further enhanced for heavier nuclei For atoms with a nuclear spin I and a 1 S 0 electronic ground state, the vector polarizability as a function of laser frequency ω  can be written as : α ≡ α v I = 2 ωr e c 2 ℏ  ∑  k f k a k ω  k 2 - ω  2 2 I (1) where the sum is taken over dipole-transition-allowed excited states ( J = 1, L = 1, S = 0) with resonance frequencies ω  k , oscillator strengths f k and hyperfine coupling constants given by H k hf = a k L · I , and r e is the classical electron radius For calibration, a free induction decay signal was recorded following a 7° tip with a resonant radio-frequency pulse For example, an effective optical path of 9 m has been demonstrated for simple organic liquids using a 1-cm-long cell placed in an optical cavity  For example, for a long cylindrical sample with uniform magnetization M parallel to its axis, the classical magnetic field B M = 4π M consists of a contact interaction B c = 8π M /3 and a distant dipolar field B d = 4π M /3  For example, the same SNR of 1,000 could be achieved with a 10 nl sample volume using a 10-m-long fibre that can be coiled inside a magnet For example, the Verdet constant of Xe, calculated using the same equation with H hf replaced by H B = µ B L · B , gives a result 40% smaller than the measured Verdet constant , as could be expected, as contributions of higher excited states and the continuum are not included For heavy atoms, the NSOR signal is significantly enhanced compared with the rotation due to the Faraday effect, allowing NMR signals to be detected in the presence of large magnetic field noise or radio-frequency fields at the NMR frequency For optical measurements, the frequency of the oscillating transverse field was slowly swept to the NMR resonance at 147 Hz, left on resonance for 40 s, and swept back off resonance For solutions containing molecules with a large molar mass, the maximum interaction length will be reduced owing to Rayleigh scattering, but the SNR per unit sample volume in a hollow fibre remains the same Hence, the NMR frequency shift for right circularly polarized light ( s = -1) with intensity I 0 is given by: Δ ν = I 0 ℏnc α v (2) where n is the index of refraction of the liquid However, in 129 Xe there is a substantial cancellation of contributions to the vector polarizability proportional to the nuclear spin between transitions to 6 s and 5 d excited states because they have similar oscillator strengths but opposite signs of the hyperfine constants, a k  However, more detailed experimental and theoretical work showed that these frequency shifts are extremely small, at most of the order of 10 -5  Hz, and cannot be detected with present techniques However, the measured optical rotation is in very good agreement with the size expected from the Faraday effect assuming B = 4π M , as shown with the solid line in Fig. 3b  If the laser frequency is tuned near an optical resonance, the NSOR signal will be preferentially enhanced for nuclear spins that have a large overlap with the excited-state electron wavefunction created by the optical excitation Illumination by circularly polarized light induces electron spin magnetization in the excited state through the inverse Faraday effect that generates a magnetic field, causing NMR frequency shifts In contrast, for 129 Xe the measured NSOR is more than 100 times larger than the rotation expected from the Faraday effect Light guiding and detection of optical rotation in a liquid-filled photonic bandgap fibre has recently been demonstrated  More formally, magneto-optic effects discussed in this Letter can be expressed in terms of the vector atomic polarizability α (ref. 17 ) No optical signal was detected when using circularly polarized light, thereby verifying absence of electronic cross-talk NSOR in water was detected using a different apparatus, shown in Fig. 2a  Nuclear magnetization in a liquid induces a magnetic field B M that leads to optical rotation φ  = lVB M , which is proportional to the Verdet constant V and the length of the sample l  Optical rotation and pick-up coil signals were recorded with a lock-in amplifier for several thousand seconds Optical rotation was measured with a photoelastic modulation technique using lasers at three wavelengths (532 nm, 770 nm and 1,064 nm), with laser power ranging from 2 mW to 10 mW and beam size of the order of 1 mm Our measurements can also be compared with an ab initio calculation of laser-induced NMR frequency shifts in CS 2 (ref. 12 ) Our measurements give κ Xe = 135 ± 13, which is of the same order of magnitude as the enhancement for the alkali-metal electron wavefunctions during collision with 129 Xe atoms  Our measurements in liquid 129 Xe and water illustrate the range of possible effects Polarization loss during flow, inefficiency of adiabatic fast passage and broadening by magnetic field gradients resulted in a rotating nuclear spin polarization corresponding to a 1.5 T field Spin-polarized 129 Xe was produced by spin-exchange with optically pumped Rb vapour , and collected as liquid in a 1 cm × 1 cm × 0.8 cm glass cell ( Fig. 1a ) Such two-dimensional optical–NMR spectroscopy could be useful for interpretation of circular dichroism data in complex molecules. The calculated frequency shifts, converted to NSOR using equations (2) and (3) and compared with the expected Faraday rotation in CS 2 , give contact enhancement factors for 13 C and 33 S of κ C = 4.2 and κ S = 14.7, respectively, confirming the general trend of increase in κ with the nuclear charge The connection between light and liquid-state NMR was initially explored when it was suggested that NMR frequencies could be shifted by illumination with a circularly polarized laser far-detuned from optical resonances  The degree of nuclear spin polarization along the path of the laser beam was independently measured using a non-resonant solenoidal NMR coil wound around the glass tube and connected to a high-input-impedance lock-in amplifier The distant dipolar field depends on the shape of the sample (for example, it averages to zero for a spherical sample ), while the contact term can be enhanced or suppressed depending on the overlap of the wavefunction of the virtual electron excitation created by the laser and the nuclear spin The excellent agreement with measured values may be somewhat fortuitous, as relativistic corrections are estimated to be of the order of 100% The induced magnetic field B M can be divided into a local contact field and a distant dipolar field The interaction energy for atoms in an oscillating electric field E = ( E 0 /2)( ɛ  e - iωt + ɛ *e iωt ) is given by H = -( E 0 2 /4) α · s , where s is the average photon spin, s = i ɛ  ×  ɛ * , whereas rotation of light polarization is determined by the vector susceptibility of the medium, χ  = N α , where N is the number density of atoms The L – S coupling scheme, used to derive equation (1) , is not very accurate for 129 Xe owing to large relativistic effects, but can be expected to give a reasonable estimate The laser beam was directed perpendicular to a static magnetic field B 0 = 125 mG and NSOR was detected at 147 Hz while 129 Xe spins were locked to an oscillating transverse magnetic field B 1 = 7 mG The NMR frequency shift caused by circularly polarized light has been calculated for 129 Xe and other noble gases using several ab initio methods  The observed NSOR can be interpreted as an enhancement by a factor κ Xe of the contact magnetic field B c = 8π κ Xe M /3, in analogy with the Fermi-contact interaction between alkali-metal atoms and noble gas nuclei  The optical measurements were alternated with traditional NMR detection using a SQUID (superconducting quantum interference device) magnetometer for 129 Xe polarization calibration  The optical rotation signal was measured using a balanced polarimeter with sensitivity limited by photon shot noise The optical rotation signals, normalized to 1 mol l -1 (1 M) concentration of fully polarized spins, are shown in Fig. 3 for 129 Xe in liquid xenon and 1 H in water, together with theoretical estimates The optical rotation technique demonstrated here also has several unique advantages for the detection of NMR signals in transparent samples compared with magnetic detection The polarizability is proportional to the strength of the hyperfine interaction and increases for heavier atoms The polarization rotation angle for a linearly polarized beam propagating in the z direction through the medium of length l is given by: φ  = - 2 π ω l   N nc α v 〈 I z 〉 (3) Thus, laser-induced NMR shift and NSOR depend on the same vector polarizability and can be easily related to each other The required sample volume for a single-mode hollow fibre is of the order of V ≈ 4 λ 2   l  The results are converted to NSOR using equations (2) and (3) , and plotted in Fig. 3a for two different sets of orbitals used in the multi-configuration self-consistent field (MCSCF) method The sample volume could be reduced by focusing the light into a thin capillary with a volume V ≈ 2 λl 2 determined by diffraction losses, where l is the path length The sensitivity of rotation measurements could be further improved by using a multi-pass or an optical cavity arrangement The size of NSOR in water cannot be easily estimated from equation (1) because the excited molecular level structure is very complicated and not all hyperfine constants are known The size of the NSOR can be estimated from equation (1) if the oscillator strengths and hyperfine interaction constants are known The spatial resolution of such an image is in principle limited only by light diffraction The water flow in the tube was in the turbulent regime (Reynolds number, 8,000); several measurements were made with different paths of the laser beam through the tube to verify that water had a uniform transverse distribution of polarization within 10% measurement error This indicates that other atoms of similar nuclear charge but without cancellation between s and d states can have substantially larger optical rotation than 129 Xe This indicates that the excited-state electron wavefunction is not strongly enhanced at the location of the protons Thus, NSOR could be detected from small samples with a sensitivity higher than, or comparable to, that obtained in micro-coil NMR  To avoid spurious cross-talk signals, the B 0 magnetic field was modulated on and off the proton NMR resonance at 8 Hz Ultimate sensitivity with picolitre samples can be obtained by using a hollow fibre with mirrors at both ends  Using a two-dimensional photodiode array or CCD camera, one could obtain a real-time two-dimensional image of the nuclear magnetization without application of magnetic field gradients Using hyperfine constants and oscillator strengths for a few of the lowest excited states , we estimate from equations (1) and (3) optical rotation of 3.5 × 10 -5  rad cm -1 for a 1 M concentration of fully polarized 129 Xe spins at 770 nm, significantly larger than the measured value of (5.8 ± 0.6) × 10 -6  rad cm -1  M -1  Water continuously flowed through a container placed inside a 9 T superconducting magnet to polarize 1 H spins, and then through a 50-cm-long glass tube held in a field B 0 = 5 G We find that nuclear-spin optical rotation (NSOR) from 1 H in water is comparable to the size expected from the Faraday effect assuming no enhancement of the contact interaction, while for heavier atoms the contact term enhancement increases with the atomic number Z , making NSOR 135 times larger than Faraday rotation in liquid 129 Xe With a constant field gradient in the direction of the laser beam, one could also obtain a three-dimensional image of the precessing magnetization with high spatial resolution
 After he and James Watson solved one of biologys really big problems, the mechanism of inheritance, Crick moved to neuroscience and set himself the task of answering that fields biggest question Although everyone who enters the field of neuroscience starts with an interest in the big questions, we soon settle into much smaller questions that we can see how to answer with the tools of modern biology And I expect others will be sceptical on other grounds And thus he takes a fundamentally structural approach to consciousness: what brain regions, he asks, have properties that would suit them for the information gathering and analysis that is at the heart of the conscious experience? I know from conversations with Crick that he had a very strong hunch, one that bordered on a conviction, that the structure underlying consciousness is the claustrum Because of its widespread connections, Crick and Koch liken the claustrum to the conductor of an orchestra, who is responsible for binding the performances by individual musicians into an integrated whole that can be much more than the sum of the parts Because these different aspects of experience are related to neuronal processing in distinct and often widely separated brain circuits (those responsible for vision, olfaction, somatic sensation, together with the amygdala and other centres involved in emotion), this unification of experiential components implies some sort of coordination between different brain areas Crick and Koch note that a key feature of our conscious experiences is that all of the components are integrated into a unified whole: how a rose looks, smells and feels are bound together with our emotional experience of it Crick told me that one of his main purposes in this paper was to encourage new studies of the claustrum, and had he lived longer, he would have liked to start a centre for investigating the claustrum, where neuroanatomical, electrophysiological and novel molecular biological approaches to the claustrum could be combined Crick was working on this paper literally on his deathbed, and Koch has put the finishing touches on it for publication Cricks final paper, written with Koch, has just been published in Philosophical Transactions of the Royal Society of London (doi: 10.1098/rstb.2005.1661) and it proposes that an obscure part of the brain, the claustrum, may be involved in consciousness For example, the fact that all mammals have a claustrum could be an argument against the proposal for those who cannot imagine consciousness without language and high-level symbolic reasoning How can a scientist think about consciousness? Cricks approach had two parts In the paper Crick writes, “In biology, if seeking to understand function, it is usually a good idea to study structure” In their survey of various notions about consciousness, Crick and Koch observe that a common thread through all of the thinking about consciousness is the recognition of a need to bind together information from many separate parts of the brain Nevertheless, the proposal is an interesting and challenging one, from a scientific giant, and I believe every scientist will be fascinated to see how one of the greatest biologists attacked such a difficult problem. Not everyone will buy the Crick and Koch idea that the claustrum is the seat of consciousness Pretty much everyone is interested in the big questions about the brain, and the biggest big question is: what is consciousness? Just as historically the vitalists could not imagine how life can be explained by just physics and chemistry — they believed that a non-physical ‘life force’ had to be involved — the dualists of today cannot believe our experience of the feeling of love or the redness of red could arise just through nerve impulses in a bunch of brain cells Questions about consciousness were therefore mostly left to philosophers and kooks, and no respectable neuroscientist would even have considered working on such a problem — until Francis Crick, that is So the claustrum is not just a sort of shadow of the cortex, but rather a neural circuit with overlapping inputs from various cortical regions and outputs back to cortex Some of these ideas for studying the claustrum, like using molecular biological methods to specifically disrupt claustral function, are sketched in this paper The claustrum is present in all mammals, but it has been little studied and its function is not known The first was to identify what properties of consciousness had to be explained, and the second was to find brain structures that might account for those properties The neuroanatomical connections of the claustrum, then, just match with the ‘conductor’ required to bind together the various disparate components of the conscious experience represented in many different brain regions What is known, however, is that there are two-way connections between the claustrum and most, if not all, parts of the cortex as well as subcortical structures involved in emotion What is the claustrum, and why pick on it as a key for understanding consciousness? The claustrum is a thin sheet of grey matter that resides parallel to and below part of the cortex (the cortex is the grey matter covering of the brain that carries out the computations involved in feeling, seeing, hearing, language and deciding what to do) Working closely with Christof Koch, Crick made the study of consciousness respectable and, directly and indirectly, had a profound influence on all of neuroscience and on the types of questions that are considered acceptable to study
 A small group of critics, including Stephen McIntyre, a Toronto-based mineral-exploitation consultant, has since attempted to prove that the graph is based on insufficient data and on flawed statistics  According to an earlier study, which produced the widely cited ‘hockey stick’ graph, average Northern Hemisphere temperatures during the past millennium were relatively stable until the late nineteenth century, when they began to increase sharply  Although McIntyres work is controversial, a recent reanalysis by von Storch partly supports his view  And, in hindsight, many climate researchers believe that it was premature of the IPCC to give the visually suggestive curve so much prominence. “Mann is a pioneer, whose 1998 study was then the best reconstruction that had ever been done,” says Stefan Rahmstorf, a climate researcher at the Potsdam Institute of Climate Impact Research in Germany But the exceptionally strong warming trend since the mid-1980s cannot be explained by natural variability alone, they maintain. “Mobergs reconstruction will help to put the record straight in one of the most contested issues in palaeoclimatology,” says Hans von Storch, a climate modeller at the GKSS research centre in Geesthacht, Germany. “But it does not weaken in any way the hypothesis that recent observed warming is a result mainly of human activity.”  Moving on “We need to understand the past, but some people become fixated,” says Phil Jones, a climate researcher at the University of East Anglia in Norwich, UK. “For projecting the rate of climate change in the twenty-first century, it is somewhat irrelevant what happened in medieval times But the Moberg study, which is published just as the Kyoto Protocol comes into effect (see ‘Kyoto decks itself for celebration’ ), suggests that notable climate changes have occurred throughout the recent past But, he adds, the controversy it generates is now out of proportion to its scientific significance But, he says, “the cause of any particular climate change must be investigated separately But, says van Storch, the hockey-stick curve, prominently featured in the IPCCs summary for policy-makers, has become such a powerful icon that any correction of it will affect the credibility of the IPCCs work He says the issue deserves further investigation and must not be overshadowed by political issues. “The contrarians would have us believe that the entire argument of anthropogenic climate change rests on our hockey-stick construction,” he says. “But in fact some of the most compelling evidence has absolutely nothing to do with it, and has been around much longer than our curve.” If such natural fluctuations continue in the future, they may “amplify or attenuate anthropogenic climate change significantly”, the authors conclude In 2001, this assessment was used to underpin the most recent report of the Intergovernmental Panel on Climate Change (IPCC) — the scientific branch of the United Nations Framework Convention on Climate Change It could give climate sceptics a boost, despite the fact that human-driven global warming is not in doubt (see ‘UK climate meeting deems risks ‘serious’’ ) It would be naive to conclude that the observed twentieth-century warming must have a natural cause just because previous warming events have had one.”  Meanwhile, Mann concedes that it is plausible that past temperature variations may have been larger than thought — although he insists that Mobergs reconstruction is not free of methodological and statistical problems Many researchers do agree that historic climate changes may have been underestimated Mobergs group used a combination of different ‘proxies’ to reconstruct decadal and centennial temperature changes Munich Fluctuations in global temperature during the past millennium may have been larger and more frequent than previously thought, says a fresh analysis of the climate record Previously, different scientists had arrived at different curves for temperature variability over past centuries, depending on the data or models they used  Proxies are climate indicators such as tree rings, pollens and boreholes, and the researchers used each one at the timescale that it records most accurately: tree rings are used for reflecting annual variations, for example, and sediments for longer-term changes Proxy-based reconstruction of past temperatures are important for validating the models that researchers use to predict the future climate Rahmstorf adds that even if the hockey-stick curve were to be completely wrong — and even if all model simulations of the past millennium were fundamentally wrong — it would hardly touch ideas about the cause of observed climate change in the twentieth century The analysis is likely to reignite a long-standing controversy over the cause and extent of natural climate variability, scientists say, although the unprecedented nature of global warming since the mid-1980s remains unquestioned The hockey-stick reconstruction was derived in 1998 by Michael Mann, a climate researcher now at the University of Virginia in Charlottesville The IPCC is likely to raise the issue in May in Beijing at a closed meeting of its working group on the physical basis of climate change The possibility that they generally underestimated natural climate fluctuations has been one of the main arguments that sceptics use to reject the notion that human activity is responsible for current warming The researchers then used ‘wavelet analysis’ to combine the timescales in the optimum manner. “At timescales longer than 80 years, temperature variability seems to have been considerably larger than previously thought,” says Moberg The study was conducted by Anders Moberg of Stockholm University, Sweden, and his team (see page 613 , and News and Views on page 587 ) This argument has hardly any support in the climate community, however What really matters is what happened in the twentieth century — and we can expect from that a much warmer climate.”  In its 2001 report, the IPCC concluded that “the increase in temperature in the twentieth century is likely to have been the largest in any century during the past 1,000 years.”  Mobergs reconstruction is consistent with this assessment
 Although magnetic fields complicate the description of turbulence, certain characteristics, among them vortices, can arise in fluid and magnetofluid turbulence At the time of the observations, Cluster 1 and 2 were aligned with the plasma flow Behind the bow shock, the hot solar-wind plasma can flow down towards the ionosphere through the dayside cusp Cluster observations indicate the existence of a turbulent vortical boundary layer that enhances the transfer of momentum and energy from the solar wind to the magnetosphere Clusters four spacecraft orbit such that, at the point where they are farthest from Earth — at apogee — their positions form a regular tetrahedron ( Fig. 1 ) Data from those two spacecraft indicated that the observed structures were quasi-stationary Furthermore, where vortices form, materials in initially separate regions of space become mixed, which transfers energy, momentum and material from one region of the magnetosphere to another In magnetized plasmas, because of the large variety of possible small-scale wave modes, it is not clear how that cascade progresses to the dissipation range In the near future, missions such as Magnetospheric Multiscale (MMS), with its even smaller spacecraft separation and higher time-resolution for plasma measurements, will further enhance our understanding of the generation and dissipation of magnetofluid turbulence. In the solar wind itself, measurements from single spacecraft indicate that as the scales of the turbulent fluctuations approach the dissipation scale, the kinetic Alfvén wave becomes the predominant wave mode In the spring of 2002, at the time of Sundkvist and colleagues measurements , the separation of the spacecraft at apogee was about 100 kilometres (compared with around 500 kilometres for earlier Cluster measurements ), allowing the resolution of smaller spatial features It can be seen by gently stirring cream into coffee, or by observing the white caps and surf at the beach, and it causes the drag on cars and aeroplanes Measurements of the velocity shears across the plasma flow direction made by Clusters thermal plasma instrument indicate amplitudes that exceed those required for vortex production Near Earth, the speed of the solar wind is typically around 400 kilometres per second, with variations of a couple of hundred kilometres per second that depend on solar activity Nykyri et al . found, using Cluster magnetometer data from March 2001, evidence that the cusp contained magnetic turbulence On page 825 of this issue, Sundkvist et al . report the detection of small vortices in the ‘dayside cusp’ of Earths magnetosphere by the four-spacecraft Cluster, a joint European Space Agency and NASA mission Savin et al . noted that the flow down the cusp should generate vortices Sundkvist and colleagues have now analysed the temporal evolution of the magnetic field in the dayside cusp region That speed exceeds by about a factor of ten the speed of sound and the speed of the most common magnetic waves, known as Alfvén waves. (Alfvén waves are highly correlated fluctuations in both the fluid-velocity and magnetic fields.) As the supersonic, super-Alfvénic solar wind encounters Earths magnetic field, a bow shockwave is produced at about 10–15 Earth radii in front of Earth ( Fig. 1 ) The authors describe their observations as evidence for a phenomenon known as drift–kinetic Alfvénic turbulence The authors interpretation is further bolstered by a vortex model constructed by the authors that accurately reproduces the observed behaviour of the magnetic field The Cluster observations are the first measurements in space to indicate that small-scale vortices are formed as eddies reach the dissipation scale The distinguishing characteristic of such waves is that they have a small electric field that is parallel to the direction of the local magnetic field The flow of plasma down the funnel-like cusp has been conjectured either to excite turbulence locally or to amplify the turbulence carried by the shocked solar-wind plasma The four-spacecraft Cluster, with its ability to distinguish between spatial and temporal effects, has opened a new window on the study of turbulence, both in the magnetosphere and in the solar wind The other two spacecraft were not aligned with the flow and could be used to deduce that the transverse radial scales of the structures were a few proton gyroradii (the radius of the circle described by a proton moving across a background magnetic field — in this region of the cusp, about 25 kilometres) The phenomenon is also widespread in magnetized plasmas — ionized gases that contain a magnetic field — such as the interstellar and intergalactic media, the solar wind and Earths magnetosphere The small spatial scales involved make measurements of a turbulent cascades dissipation — and of the transfer of the energy contained in magnetic fields and particle motion into the heating of the ambient plasma — difficult in both terrestrial laboratories and in space The solar wind is the extension of the corona, the hot outer atmosphere of the Sun, into interplanetary space There they show that kinetic Alfvén waves interact nonlinearly with so-called drift waves caused by gradients in plasma density and magnetic fields, and provide evidence that this interaction produces distinctive small-scale turbulent features known as drift–kinetic Alfvén vortices This cusp forms the boundary between magnetic field lines that are closed on the dayside (the side of Earth exposed to the Sun) and magnetic field lines that are open and have been swept back into the lobes of the nightside magnetosphere This formation is ideal for distinguishing between unchanging spatial features and features that evolve with time Turbulence is often described as a process in which large-scale eddies cascade down to smaller-scale eddies until a scale is reached at which dissipation sets in Turbulence is ubiquitous Understanding these processes would enable us to determine how energy flows in a turbulent magnetofluid from large scales to the smaller, kinetic scale — and thus heats Earths ambient plasma When the spacecraft entered the cusp, they were still relatively close together, but no longer traced out the points of a regular tetrahedron (see Fig. 3e on page 827 )
 But such a framework would not prevent a test, any more than the enactment of common law prevents every murder Even today, expertise in disarmament and anti-proliferation issues lies chiefly with scientists working at the nuclear-weapons laboratories, with think-tanks or in government Further erosion would leave us with a nuclear free-for-all and, ultimately, facing the kind of grim apocalypse seldom contemplated since the end of the cold war However, even a regime such as Kim Jong-ils is not entirely beyond the reach of such documents — North Korea withdrew from the nuclear Non-Proliferation Treaty (NPT) in 2003, before conducting its test However, the enfeebled state of the anti-proliferation regime — ultimately, an even greater threat than the existence of a North Korean weapon — is a problem that can at least be addressed, if the will to do so exists In our 24-hour news cycle, their advocates are liable to be drowned out by those with shriller voices International treaties concerning nuclear weapons are not particularly sexy or exotic; they are complex and arcane It is imperative that scientists and others with relevant knowledge of nuclear weapons redouble their efforts, and rally to repair years of vandalism inflicted on international anti-proliferation efforts It is so much easier to call for the bombing of Iranian bunkers, for example, than to argue for the Comprehensive Nuclear Test Ban Treaty (CTBT) to be brought back before the US Senate for ratification It must be fervently hoped that the challenge posed by North Korea will provide the political impetus needed to strengthen anti-proliferation agreements Just as worryingly, the issue of what to do with the arsenals of the existing nuclear-weapons states has slipped off the political agenda North Koreas nuclear test this week (see page 610 ) is alarming for two reasons: the volatile nature of the nation that has just barged its way into the nuclear-weapons club, and the accompanying sense that the international anti-proliferation regime is slowly unravelling before our eyes That has already happened to a troubling degree in the United States That must be the way forward — the alternative is despair. The 1970 non-proliferation treaty — the main foundation of the tattered anti-proliferation regime — was constructed with the direct involvement of weapons scientists in the United States and the former Soviet Union The best that a set of nuclear-weapons treaties could do in the face of North Koreas ardour is provide a moral and legal framework that allows the rest of the world to pinpoint, criticize and punish the tester with unanimity and conviction The goal is to build a treaty structure that will help contain the spread of nuclear weapons, eventually laying the groundwork for their international control and subsequent elimination The NPT has languished in the absence of agreement on how to modernize it (see Nature 435 , 132 – 133 ; 2005 ), and the CTBT has been sidelined There is precious little that can be done about the former These developments serve to undermine the already faint possibility of a coordinated response to the North Korean test by the United States, China (the two big players in this case) and the rest of the world These individuals saw clearly the unique moral and military danger of nuclear weapons and, noting the lack of the necessary technical knowledge in diplomatic or other official circles, took it upon themselves to confront it They have looked on aghast as disarmament sceptics around the world have scorned the value of international treaties, rubbished the CTBT on specious technical grounds, and even blamed the alleged toothlessness of the NPT for the gradual spread of nuclear weapons to India, Pakistan and now North Korea This weeks events are the culmination of an appalling decade that has seen India and then Pakistan carry out nuclear tests with scant punishment What good would this piece of paper do, the detractors cry, when faced with the ambitions of North Korea or Iran? It would be fanciful to claim that the existence of any non-proliferation treaty would have halted the North Korean test
 Although Schönborn has since back-pedalled on the way his ideas were expressed in the article, the piece fuelled rumours that Rome, which currently endorses darwinian evolution and rejects any literal interpretation of biblical creation, might instead endorse intelligent design As a former cardinal and German theology professor, Joseph Ratzinger has long held this informal gathering, where he discusses a hot topic with his past students At the same time, it seems likely to reject the fundamental intelligent-design principle that God was a watchmaker, intervening in the details. “Intelligent design as an intervention of God during evolution will not be an outcome,” predicts Schuster. “I got the impression that there was general agreement that evolutionary biology is a undeniable science and not a hypothesis.”  newsad; The Pope in particular “immediately accepted that theology is not going to interfere with science”, Schuster adds. “He is not a scientist, but I was surprised by the sharpness of his intellect Benedict XVI, however, has long been more ambiguous on the topic Bruce Chapman, president of the Discovery Institute in Seattle, Washington, which represents the intelligent-design movement, welcomed the choice of topic in a press release published on the institutes website last week But the retreat has taken on new significance since Ratzinger became Pope Given the power struggles within the Church, however, the precise outcome of the overall debate is impossible to predict, he says: “We have to wait.”  But discussions at the meeting suggest that the Church will probably affirm a form of theistic evolution, which posits the general principle that biological evolution is valid, although set in motion by God He also seemed to advocate intelligent design, a movement whose advocates seek to give creationism scientific credibility by arguing that the complexity of science can be explained only by divine intervention in the process of evolution He subsequently described darwinian evolution as more than a hypothesis, and in 1992 officially rehabilitated Galileo Galilei, admitting the Churchs fault He wanted to be informed; he was very interested in science.”  But although there is likely to be agreement that the Church should not attempt to question the basic theory of evolution, those at the meeting were also adamant that science should not stray into theology In a break with tradition, the proceedings of the meeting will be published later this year, says Schuster, with a preface written by the Pope In his first mass as Pope, he stated that “we are not some casual and meaningless product of evolution” In it he wrote: “Whats good about all this is that theyre taking up the issue seriously...it will be conducted at a very high level and I think it should give cheer to people who are critics of Darwinism.”  Schönborn was one of four invited speakers at the meeting, which also included Robert Spaemann, a conservative German philosopher, and Paul Erbrich, a Jesuit priest who questions the random nature of evolution John Paul II perhaps did more than any pontiff to reconcile faith and science, declaring in 1980 that there was no contradiction between the two Last year, the prominent Cardinal Christoph Schönborn wrote an article in The New York Times expressing doubts about darwinism Religion is religion, science is science, and good fences make good neighbours Schuster says there was a wide desire to address the Churchs concern that darwinism is being extrapolated as a wider metaphysical stance Speculation increased last month when Schönborn announced that creation and evolution would be the topic of the Popes annual retreat, to be held in Castel Gandolfo near Rome That could have given a global axis to what has been largely a US cultural phenomenon That seems likely to be the thrust of an expected clarification by the Roman Catholic Church of its position on biological evolution, according to a prominent biologist who spoke at a retreat on the topic held last weekend by Pope Benedict XVI The fourth speaker, the only working scientist present, was Peter Schuster, a molecular biologist and president of the Austrian Academy of Sciences The message will be to promote dialogue between faith and reason, Schuster says This argues that we are random products of evolution, and that there is therefore no need for God. “I agree that, as in science, everyone should stay within their realms of competence,” says Schuster. This outcome would be a blow to supporters of intelligent design who had hoped that factions in the Vatican sympathetic to their ideas might prevail in an internal feud over evolution that has opened since the death of Pope John Paul II in April last year
 And it is unquestionably true: animal research has made many valuable contributions to medical science And there is some evidence, in both countries, that public support for animal research has actually increased in response to animal-rights extremism Animal research saves lives As part of our investigation, we surveyed many of our readers in the life sciences anonymously, to solicit their views on aspects of the topic But others are imperfect: certain mouse models of cancer, for example, do not accurately mimic the disease in humans, and may even have hampered the development of some drugs (see Nature 442 , 739 – 741 ; 2006 ) From a scientific point of view, for example, it is clear that certain animal models are useful: the neural prosthetics that promise to restore some independence to paraplegics, for example, arose from curiosity-driven studies of the primate brain (see Nature 443 , 122 ; 2006 ) Given the reluctance of many scientists to speak on-the-record to our reporters on this particular subject (see page 808 ), the exercise has been helpful in generating an overall picture of how scientists themselves view this highly contentious public issue However, a minority (fewer than one-fifth) express some misgivings about their work. “As a researcher in the field of HIV vaccine development, I am placed in a very awkward position regarding the use of non-human primates,” said one immunologist. “I personally feel uncomfortable with primate research yet I realize that without primate data, vaccine candidates are rarely forwarded to human trial.”  Fear is clearly a significant factor in excluding the voices of ordinary researchers from public discussion of these issues However, the simplicity of the slogan barely does justice to the complexity of the issue If, as seems to be the case, scientists have made some headway in persuading the public of the value of animal research, then this is an opportune moment for them to engage in a full and open debate about the options that lie ahead — including improvements to research practice and the development of alternative approaches. In this weeks issue, several articles explore what scientists really think about animal research, and what the future may hold for such work It is essential that researchers feel free to speak out, both within the community and beyond it, on this issue No scientist should have to risk life and limb in order to speak about perfectly lawful work Our survey also suggests that research agencies, universities and other institutions could do more to ensure that scientists feel free to talk about their work See Animal Research: A matter of life and death for the full list of related content in this weeks issue That is the mantra often used to counter verbal and physical attacks on animal researchers and their institutions by animal-rights activists The 1,700 or so readers who responded to our online survey are not necessarily representative of the entire community of biologists, but their responses nonetheless offer some valuable insights into the views of working scientists on questions related to animal research The complete survey results are published on the web at http://www.nature.com/news/specials/animalresearch  There are also some indications that peer pressure is not always conducive to open communication with the public about animal research. “I am more concerned that the scientific community, rather than the animal-rights movement, makes it difficult to voice a nuanced opinion on animal research,” said one neuroscientist, whose research involves using imaging to study the brains of human patients Three-quarters of respondents said that animal research was essential to the progress of biomedical science Welcome steps have been taken by governments in both Britain and the United States to pass laws that will protect scientists under the law
 And in supporting those scientists he expects to get still closer to his childhood passion: he wants to find out where the stars come from. But Peach points out that he has not followed any particular career plan over the past ten years. “The jobs came out of the blue,” he says Despite switching many years ago from directly performing research to managing it, Peach says that he still feels very much like a scientist, not a manager, and that working with researchers gives him a thrill. “It is satisfying to help scientists achieve what they would like to achieve — after all, this is also my interest,” he says He believes that enthusiasm is the source of every successful scientific career, and he is keen to tell the next generation so. “Listen to yourself and find out what you are really most excited about, than go for it as hard as you can!” he says He has always had a clear idea of his scientific goals — to understand particle physics, as a basis for understanding how the Universe works, and to use accelerator physics for studying what the Universe looks like Kenneth Peach, director, John Adams Institute for Accelerator Science, Oxford, UK Ever since he was 12 years old, Kenneth Peach has been fascinated with the stars and interested in uncovering how the Universe works Peach says he will be pushing for the building of a linear collider and a neutrino factory to study the conditions shortly after the Big Bang, 14 billion years ago The John Adams Institute, founded in 2004 by the UK Particle Physics and Astronomy Research Council, is one of two university-led centres in Britain set up to pursue research and development into particle-physics accelerator science This passion led his career down a path towards physics With his appointment in April as the first director of the John Adams Institute for Accelerator Science, based in Oxford and London, one of his main goals is to ensure that the next generation of scientists can do their job — investigating the mysteries of the Universe. (see CV ). “It is a privilege and a challenge to have the task of defining the ways accelerator science will go in the future,” says Peach
 A Because of limitations in computer power, the underlying laws of physics cannot be used directly to simulate such systems; instead they are represented by approximate formulae with uncertain parameters Global-climate models are now being developed in which one of the most important types of cloud system, ‘organized deep convection’, is computed explicitly However, the parameter values varied from one forecast to another — the intra-ensemble variation in these values being consistent with their inherent uncertainty If warming occurred at the upper end of the predicted range, the effects for humankind would be utterly catastrophic In the paper by Stainforth and colleagues, an ensemble of many thousand individual global-warming forecasts was analysed In view of the seriousness of the global-warming problem, plans for developing such a facility for climate prediction should occur at the international level, so that national resources can be pooled and scientific collaborations enhanced Sir By using the distributed power of personal computers around the planet, D Stainforth and colleagues ( Nature 433 , 403 – 406 ; 2005 ) have quantified uncertainty in forecasts of global warming resulting from a doubling of CO 2  Such convective systems, with horizontal scales of tens of kilometres, play a key role in climate: they cool the Earths surface, they transport water from the surface into parts of the troposphere where they can contribute to the greenhouse effect, and their kinetic energy influences global-scale climate circulations Such forecast uncertainty arises, in large part, from the way cloud systems are represented in existing global-climate models Such high-resolution climate models cannot be run efficiently using distributed computing technology The forecasts were all made with the same climate model To reduce uncertainty in estimates of global warming, the climate-modelling community requires substantially more powerful computational resources than are currently available, so that more of the climate system can be simulated directly from the known laws of physics Unfortunately, even on the most powerful computers, climate simulations in such models take nearly as long as real time Within Europe, the European Union could play a leading role.
 Apollo was not a high-water mark for our species, he says, but “a brilliant deception, a glorious swindle”. “Hubris took America to the Moon” is DeGroots thesis, but all he really proves is that hubris sometimes writes a book. But as Asif A But forlorn was he to find, in place of his childhood heroes, “a gang of cynics, manipulators, demagogues, tyrants, and even a few criminals” But he does not reference any of those analyses, either Certainly there is more to learn Dark Side of the Moon stands, and falls, on its cunning soundbites DeGroot could have added fresh insight if only he had conducted substantive research instead of filling his book with baseless assertion and arm-waving polemic DeGroot fails to cite it and seems to be unaware of its existence For DeGroot, the Moon landing marked a “high point” in “Americas love affair with science and technology”, but also a decline in so much else about US society Freud probably had a lot to say about this sort of thing.” DeGroot is not the first to make the phallus comparison; others have argued that the language of engineering and rockets has been particularly sexist Having previously published what he describes as a depressing book on the history of the atomic bomb, DeGroot claims he hoped for spiritual uplift by turning his attention to a history of the Moon landings He states oh-so-matter-of-factly that the words uttered by Neil Armstrong when stepping off the Eagle were “canned” — a “freeze-dried slogan”, a “meaningless” statement, “prepared earlier and then taken into space along with the Tang and the tubes of hamburgers” His indictment of Apollo hinges on the implicit notion that the Americans were the only ones racing to the Moon In his preface, DeGroot relates that the Americans who walked on the Moon were his childhood heroes but, unlike the rocket scientists and spaceflight enthusiasts, he grew out of it, never succumbing to the sexual appeal of the rocket ship: “The tall, slender phallic tube sits on its pad while men who yearn for youth trade in techno-babble Johnson, and sustained by NASA, manipulate the US drive to the Moon? What do the Apollo missions tell us about the growth of the technocratic mentality? How did nostalgia for Apollo corrupt Americas subsequent space efforts? Several books have profitably explored such matters, notably Walter A Kennedy and Lyndon B McDougalls The Heavens and the Earth (Basic Books, 1985) Nor did Apollo 11, incidentally, carry Tang or tubes of hamburgers Nor did he look for data that could have shown that his categorical statement about women and spaceflight is shaky Savouring the irony, he juxtaposes the capacity of Americans to build the sophisticated machinery needed to take them to the Moon with their inability any longer to build a decent car Serious research into the embedded agendas of the US space programme is well worth undertaking, and many of the questions raised by this book are worthwhile Siddiqis groundbreaking Challenge to Apollo (NASA, 2000) explained, the Soviets made a concerted effort to beat the United States to the Moon Siddiqis monumental 1,000-page book is one of the most important space-history books ever published Thankfully, he does not go so far as to suggest that the landings never really occurred, being merely part of a US government conspiracy to fool the Soviet Union about the United States strategic capability in the Cold War, but the books presentation is almost as fanciful The adventure appeals to most boys, some men, very few girls, and almost no women The author is more adept at turning a phrase than erecting a solid edifice based on original source materials and exhaustive research The most grievous defect lies not in what DeGroot does not understand about the US lunar programme, but rather what he could have easily ascertained, but did not, about the history of the Soviet programme To what extent did myths constructed by the administrations of John F While Ford Pintos exploded and AMC Gremlins fell apart, he says, Americans “arrived at parties to celebrate the lunar landing in Toyotas, Datsuns, Volkswagens, and Renaults” — another great soundbite, but one lacking fuel because, in 1969, imports made up a small fraction of the US car population, with Renault barely a blip on the screen With a cheeky rhetorical flourish, Gerard DeGroot, a history professor at the University of St Andrews, UK, attacks the integrity of the American Moon-landing programme of the 1960s With just a little research the cynical author could have discovered that Armstrongs “one small step” was not in the least bit canned; inside the Lunar Excursion Module, the commander of Apollo 11 formulated it in the hours between landing and stepping down off the ladder
 Here we model this unexpected and now notorious phenomenon — which was not due to the bridges innovative design as was first thought — by adapting ideas originally developed to describe the collective synchronization of biological oscillators such as neurons and fireflies Our approach should help engineers to estimate the damping needed to stabilize other exceptionally crowded footbridges against synchronous lateral excitation by pedestrians. Soon after the crowd streamed on to Londons Millennium Bridge on the day it opened, the bridge started to sway from side to side: many pedestrians fell spontaneously into step with the bridges vibrations, inadvertently amplifying them All the parameters have known values, except for C  As more and more people walk on to the deck ( Fig. 2a ), there is no hint of instability until the crowd reaches a critical size, N c , after which wobbling and synchrony erupt simultaneously ( Fig. 2b, c ) By generalizing ideas that were developed in mathematical biology, we have provided a unified picture of what happened on the Millennium Bridge five years ago, both for the bridge vibrations and the crowd dynamics Comparing our simulations with data obtained from crowd tests on the Millennium Bridge , we estimate C ≈16 m −1 s −1  Each pedestrian i =1,..., N imparts an alternating sideways force G sin Θ  i to the bridge, where G is the maximum force and the phase Θ  i ( t ) increases by 2π during a full left/right walking cycle Equation (2) is hypothetical but testable (see supplementary information ), and is consistent with the known response of other biological rhythms to weak periodic stimuli  Existing theories of what happened on the bridges opening day focus on the wobbling of the bridge but have not addressed the crowd-synchronization dynamics In our approach, wobbling and synchrony are inseparable It also accounts for the previously unexplained empirical observation that the excitation force generated by the crowd grows linearly with the bridges amplitude (for calculations, see supplementary information ) The approach suggested here may also prove useful for estimating the damping needed to safeguard other bridges, present and future, against synchronous lateral excitation by pedestrians. The bridges movement, in turn, is assumed to alter each pedestrians gait according to dΘ  i dt = Ω i + CA sin ψ − Θ  i + α where the frequencies Ω i are randomly distributed with a density P ( Ω ), reflecting the diversity of natural footfall rates across the population; C quantifies pedestrians sensitivity to bridge vibrations of amplitude A ( t ) and phase ψ ( t ) (defined such that X = A sin ψ , d X /d t = Ω 0 A cos ψ , where Ω 0 = K / M is the bridges resonant frequency); and α is a phase lag parameter Then, with no further adjustable parameters, the model predicts the synchronization timescale and the characteristic amplitude of the wobbles shown in Fig. 2 and in the actual experiments  They emerge together, as dual aspects of a single instability mechanism, once the crowd reaches a critical size To illustrate the dynamics inherent in the model, Fig. 2 shows a simulation of a controlled experiment performed on the Millennium Bridge To take the simplest case, suppose α =π/2 and P ( Ω ) is symmetrical about Ω 0 (also a ‘worst case’ for the bridge, in the sense that pedestrians then drive it most efficiently) We can calculate N c analytically, using methods created to study large systems of biological oscillators (see supplementary information ) We find N c = 4ς  π K GCP Ω 0 where ς= B / 4 MK is the damping ratio We model the bridge as a weakly damped and driven harmonic oscillator M d 2 X d t 2 + B d X d t + KX = G N ∑  i =1 sin Θ  i where X ( t ) is the displacement of the relevant lateral mode, and M , B and K are its modal mass, damping and stiffness, respectively ( Fig. 1 )
 BioScience 50, 149–155; 2000) But there is no such conflict Costanza et al  Costanza et al  Ecosystems are critical to our survival and well-being for many reasons — hearts, minds and wallets included. I do not agree that more progress will be made by appealing to peoples hearts rather than their wallets If nature contributes significantly to human well-being, then it is a major contributor to the real economy ( R It is also incorrect to suggest that conservation based on protecting ecosystem services is betting against human ingenuity It is incorrect to suggest that ecosystem-services reasoning ignores basic ecology; on the contrary, it embraces ecology and the co-dependency of humans and other species McCauley, in his Commentary “Selling out on nature” ( Nature 443 , 27 – 28 ; 2006 ), suggests that love for nature is incompatible with valuing nature in terms of its contributions to human well-being Most ecosystem services are public goods (non-rival and non-excludable), which means that privatization and conventional markets work poorly, if at all Nature 387 , 253 – 260 ; 1997 ), and the choice becomes how to manage all our assets, including our natural and human-made capital, more effectively and sustainably (R Nevertheless, knowing the value of ecosystem services is helpful for their effective management, which in some cases can include economic incentives, such as those used in Costa Ricas highly successful system of payment for these services (see http://www.conservation.org/xp/frontlines/partners/03150604.xml ) Nor is valuation of ecosystem services a panacea; rather, such valuation is one piece of helpful information in the complex task of sustainably managing our natural assets Pointing out that the horizontal levees of coastal marshes are more cost-effective protectors against hurricanes than constructed vertical levees is only using our intelligence and ingenuity, not betting against it Sir Douglas J The ecosystems-services concept makes it abundantly clear that the choice of “the environment versus the economy” is a false choice The study of ecosystem services has merely identified the limitations and costs of hard engineering solutions to problems that in many cases can be more efficiently solved by natural systems Valuing ecosystem services is not identical to commodifying them for trade in private markets
 Cannabis Neuroscientists reveal that rats given cannabis when they are young are more likely to become addicted to heroin Number Crunch Scientists are drowning in paperwork, according to a survey of more than 6,000 US faculty members by the Federal Demonstration Partnership. newsad; 42% of research time is actually spent doing administration. 4 hours a week could be saved if researchers got administrative help. 10% of their research grant is what some scientists say they would be prepared to pay for that help Obesity A US study of more than 9,000 adults finds that those suffering from obesity are 25% more likely to have mental health problems On the Record “Ill have time for feelings after Im dead Right now, were busy.”  NASA administrator Michael Griffin tells reporters how he feels about the successful launch of the space shuttle Discovery on 4 July. “I am really, really proud Source: Chronicle of Higher Education Sources: NPR, Reuters Scorecard Mushrooms Researchers show that under carefully controlled conditions, hallucinogenic mushrooms can cause spiritual experiences that have positive effects on a person The only problem is that I really dont know what to do with it.”  Stefan Trellenkamp of the University of Kaiserslautern explains how he engraved the worlds smallest soccer pitch — 500 nanometres long — onacrylic glass This suggests that marijuana could make users more susceptible to hard drugs
 Both experiments measure concentrations of trace gases in the atmosphere from the Earths surface to about 10 kilometres high, although SCIAMACHY does so at a much higher resolution Burrows originally proposed both instruments: “We wondered, can you see this kind of thing? Now we know you can.”  Chinas emission inventories may have failed to take account of sources of pollution such as cars, whose numbers doubled in the country between 1995 and 2002. “New sources have stepped in to take the place of old ones,” says another member of the Bremen team, environmental physicist Andreas Richter But researchers didnt feel entirely confident about their results until they got the data from SCIAMACHY. “There was an element of pie-in-the-sky to it,” says John Burrows at the University of Bremen in Germany, an author on the Nature paper Direct satellite measurements of a key pollutant — nitrogen dioxide — are reported in this issue (see Increase in tropospheric nitrogen dioxide over China observed from space ) Estimates of nitrogen dioxide concentrations still rose by 13% between 1994 and 2000 — but there were hints of a plateau (D For nearly a decade GOME observations had shown increases in nitrogen dioxide over China at rates far greater than those estim-ated by the bottom-up measurements G Geophys GOME II is scheduled for launch next autumn, and Burrows is already proposing a geostationary satellite that could observe continuously, reducing uncertainties about daily fluctuations. He hopes that ground-level observations and aircraft sampling will pin down exact amounts of nitrogen oxides. “We need to integrate the methods,” he says However, she adds, “they dont tell you exactly what is happening” In the 1990s, China introduced measures such as clean coal technologies to reduce air pollution (see Nature 435 , 1152 ; 2005 ) J Meanwhile, the satellite researchers say they will hone their data Now data suggest that the situation is even worse than it looks, and pollution levels are rising Res. 108, 8809; 2003) Streets et al  The data show that concentrations of nitrogen dioxide in the atmosphere over China have risen by 50% during the past decade, and the build-up is accelerating The estimates were made as part of the ACE-Asia aerosol experiment and were based on ‘bottom-up’ calculations, which add up the fuel burned to gauge the pollutants released The extent of the increase surprises Jianzhong Ma, an atmospheric chemist at the Chinese Academy of Meteorological Sciences in Beijing, who next year will begin a study of air pollution and aerosols The satellite data come from the Global Ozone Monitoring Experiment (GOME), launched aboard a European Space Agency craft in 1995, and the Scanning Imaging Absorption Spectrometer for Atmospheric Chartography (SCIAMACHY), launched in 2002 The teams calculations depend on an assumption about how nitrogen dioxide concentrations vary vertically in the atmosphere. “But this should not affect measurements of trends,” Richter says. “The satellite observations are a good starting point to tell us where to correct the predictions,” says Tami Bond, an environmental scientist at the University of Illinois, Urbana-Champaign, who worked on the ACE-Asia inventory Visitors to hazy Beijing can see how Chinas industrialization is fouling the air
 As far as we were aware, everyone accessing this website had abided by the IPCC instructions, until Nature published elements of the Fourth Assessment Report Comments on the draft will be reviewed on their merits by prominent scientists during both US and international IPCC reviews In 2000, individuals were also asked to provide information on their “qualifications and general area of expertise ... to review specific parts of the report”, although to the best of my knowledge drafts were made available to all who submitted requests In fact, US procedures, first published in the Federal Register in 1995, reflect our longstanding commitment to open IPCC reviews Our approach reflects the view that it is neither possible nor appropriate for the government to decide which individuals are expert enough to review the report Since September 2004, after legal counsel advised that requiring individuals to provide such information was inconsistent with federal information-dissemination guidelines, we have made IPCC drafts available on the US Climate Change Science Program website ( http://www.climatescience.gov/Library/ipcc ); this prominently displays IPCC instructions that drafts not be cited, quoted or distributed Sir Your News story “US posts sensitive climate report for public comment” ( Nature 441 , 6 – 7 ; 2006 ) implies that the United States has departed from its traditional approach in reviewing draft reports from the Intergovernmental Panel on Climate Change (IPCC) The United States is committed to an effective review of the IPCC Fourth Assessment Report, and we intend to provide comments reflecting the extensive expertise of the US scientific community. To ensure objectivity, submitted comments will be supplied to federal programme managers and scientists without attribution and then evaluated on scientific and technical grounds before being sent to the IPCC Under the 1995 procedures, we provided paper copies of IPCC draft reports to any individual upon request
 But a family firm that has been going strong since the end of the seventeenth century last week won a Japanese award for its work with metal films, most of which, these days, end up in mobile phones But the global market for copper-foil parts used in mobile phones — of which Fukuda claims a 40% share — is perhaps its most striking success By keeping a close eye on technological progress and market changes, it has become a world leader in supplying rolled copper-foil components to the burgeoning mobile-phone industry. “Fukuda has built up good expertise over its long history,” explains Osamu Nagashima of the business school at Ritsumeikan University near Kyoto, who knows the company well. “But more importantly and unusually, it has developed the ability to explore new technology.”  Privately owned Fukuda amassed sales of ¥36 billion (US$323 million) last year and now employs around 1,000 people, mostly in Kyoto and Suzhou, China Few high-tech companies celebrate links with the world as it was before about 1980 — never mind with traditions crafted 305 years ago For example, together with Mitsuo Kawasaki, a surface photochemist at Kyoto University, Fukuda has recently produced nanoscale particles — less than 0.1 micrometres in diameter — in copper alloys Fukuda Metal Foil Powder started up in Kyoto in 1700 in a business not dissimilar to the one it runs today — putting intricate gold and silver patterns on luxurious folding screens and pottery Fukudas scientists and engineers have an annual research and development budget of US$7.3 million, and work with universities and research institutes throughout Japan Growing competition is also coming from China, South Korea and Taiwan Hayashi sees even faster product development as the key to the future, as well as energetic pursuit of new markets, such as in fuel cells. “We were getting into a rut,” Hayashi says. “We need to come up with new stuff.” It produces a huge array of metal products — 1,000 types of metal powder and 200 kinds of foil Now, he says, he is trying to realize his dream of inventing different types of powder. “What matters is the size and shape” of the powders particles, Hayashi explains One cloud on the horizon, Fukudas managers say, is the competition with big Japanese corporations for technical staff Our solid research base has enabled us to tailor our products to them.”  Before he joined the company, Hayashi, a chemical engineer, had been interested in metal powders but spent most of his career working on copper foil, acquiring the ability to judge a foils quality merely by shaking it in his hand Small differences in size and shape can greatly affect a powders properties, such as whether the particles will stick together when compressed and heated The company received its award on 4 August from the Japanese prime minister, Junichiro Koizumi, in recognition of its outstanding craftsmanship, and its success in adapting traditional skills to the information age. “Products we thought would sell well havent always been a success,” says Fukudas president Yasuhiko Hayashi. “A lot of our lines have grown unexpectedly with the advent of new demands The powders made by Fukuda can have particles ranging in diameter from 1 to 250 micrometres They go into everything from car parts to food packaging This involves a process in which the particles are suspended in an organic solvent and then broken up with a laser
 Am As The CSIRO Total Wellbeing Diet was for a general readership and covered a range of topics, we did not report an extensive review of the literature on high-protein diets Assoc. 293, 172–182; 2005), but the evidence is contradictory Certainly they capitalized on the positive results, as is their right. Chao et al Disord. 28, 1283–1290; 2004) Due et al  Eisenstein et al  High-protein diets have been criticised for their potential to cause renal and bone disease (J However, we have published widely on the subject of high-protein diets and our findings are broadly similar to those of other research groups who have shown better health outcomes on this kind of diet (see, for example, D In our opinion, the high-protein, moderate-carbohydrate approach is superior in all these respects Int J J J K Layman et al  Med Metab Nutr Nutr. 133, 411–417; 2003, and A Obes Our own work has focused not just on reduction of body fat but on reduction of lipids, glucose, insulin and blood pressure and minimization of lean-tissue loss Relat Rev. 60, 189–200; 2002) and the red-meat component has been linked to colorectal cancer (A Sir There may be disagreement about whether the words “scientifically proven” should be used to sell books (“A recipe for trouble”  Nature 438 , 1052 ; 2005 ) These industries funded two out of the five weight-loss studies we have performed with this protocol These protocols were investigator-devised and controlled; the funding bodies had no input into the reports and papers We do not agree with the view reported in your News story (“Diet book attacked for its high-protein advice”  Nature 438 , 1060 ; 2005 10.1038/4381060b ) that the CSIRO diet could lead to more breast cancer and prostate cancer You discuss the support we receive from the Australian meat and dairy industries
 Hiiragi et al . compare our model of the developing mouse egg with theirs  Mouse development is regulative rather than determinative, and this can be explained in two ways: first, development could be entirely unbiased, generating identical cells; second, there could be some developmental bias or, in other words, pattern from the beginning that is not constraining Regulative development does not exclude bias, which indicates inclination, not determination. There is evidence for early bias from several laboratories but this does not mean that cells have localized determinants fixing their fates They seem to present patterning as equivalent to determination, but this is confusing as patterning does not have to mean determination We have never stated that mouse embryo development is determined Also, our findings were similar for wild-type and H2B–EGFP strains and the conditions used for culture and microscopy allowed normal development  By prepatterning, we mean some developmental bias Further weaknesses in the case against prepatterning are discussed elsewhere  Furthermore, Hiiragi and Solters model of cleavage states that female and male chromatin mix on the first metaphase plate , which, to the best of our knowledge, disagrees with the experimental observations of all other groups (see ref. 12 , for example) Hiiragi et al . restate a model to account for how lineages of cells are established In a regulative system, where it is important to avoid invasive experimentation, technical differences between groups can be significant In assessing this, we found that it was critical to count the proportion of cells contributing to different blastocyst parts: to be significant, this had to be more than 70% , and not simply three or fewer cells  In contrast to Hiiragi and Solter , we applied no selection or manipulation/alignment, but observed cleavage in all embryos in multiple planes  It does not connote determination: indeed, our own experiments to remove parts of the egg surgically indicate that determinants do not exist . Most important, if cleavage were random and blastomere fate could not be predicted, as Hiiragi et al . suggest, we would not have been able to isolate four-cell-stage blastomeres of like identity from different embryos and combine them to make chimaeras with different developmental properties  Our findings that both two-cell blastomeres contribute to the inner cell mass and the trophectoderm , and that these lineage decisions are taken from the eight-cell stage onwards, support this long-standing model Our findings that progeny of early blastomeres make a biased contribution to different blastocyst parts are consistent with independent findings  Our results indicate that early cleavage patterns can bias the site of cavity formation ( Fig. 1 ) Our time-lapse studies, which used multiple focal planes to monitor position carefully, indicated that cleavage tends to correlate with polar body and sperm entry sites before any flow of membrane to the cleavage furrow  The controversy seems in part to be semantic, resting on the interpretation of prepatterning and determination This could bias their data set as cell shape has an overriding effect  This would be difficult to find by studying just a single focal plane as others have done  Thus, it is possible that Hiiragi and co-workers inadvertently preselected embryos of a particular shape when aligning them because, in our experience, only some remain positioned on the culture dish with the polar body and the two pronuclei in the same plane Thus, we contend that lineage establishment is not the topic under discussion but that the issue is whether the cavitation site, and therefore the embryonic–abembryonic axis orientation, is defined stochastically or not To guard against such bias, we monitored all embryos and our findings did not support their conclusions  We have tried but failed to confirm Hiiragi and Solters rule that first cleavage always occurs perpendicular to the plane of pronuclei alignment and now respond to the points raised by Hiiragi et al .  We note that their studies of cleavage did not use 40–80 sections, as the reference to a separate study of blastocysts might imply, but just a single section We observed cleavage between pronuclei, as described by Hiiragi , only when we interfered with egg shape or disrupted the actin cytoskeleton 
 Advances in microfabrication mean that such sensors can be very small and light — an obvious advantage in space-borne astronomical instruments And they believe that more effective heat removal from the hot side of the refrigerator and the use of numerous cooler elements in parallel will allow them to improve both the attainable temperature reduction and the surplus cooling power Applying a voltage V across the barrier shifts the chemical potential of N relative to that of S As only the most energetic electrons are free to tunnel, the electron gas left behind has a lower average energy than existed before tunnelling — thus, the electron system in N cools down At low temperature and voltage, the relative shift of the zero levels is not sufficient to allow electric current to flow between N and S, as the energy of the occupied states in N still corresponds either to forbidden states in the gap, or to occupied states below the energy gap in S — thus quantum tunnelling remains forbidden But at higher voltages, as the energy shift in N approaches Δ , half of the energy gap in S, current suddenly starts to flow owing to the vertical matching of the most energetic occupied states in N and the empty, but allowed, states above the energy gap in S Clark et al . incorporate these techniques into a full refrigerator, and test its cooling power on a ‘macroscopic’ germanium resistance thermometer in the form of a 250-μm-sided cube glued onto a silicon nitride membrane Clark et al . now supply a first practical device based on this effect Cooling occurs as a consequence of the different electron configurations in the N and S regions: in the normal metal, electrons occupy states with an almost constant density over the whole range of relevant energies, whereas in the superconductor there is a gap in which no electron energy states exist Cooling of a micrometre-scale, thin-film copper bar from 300 millikelvin down to 100 mK using a double-junction NIS device was demonstrated in 1996, and temperatures below 50 mK were reached last year  Electrons can pass across the insulating barrier only by quantum tunnelling — a consequence of the uncertainty in quantum mechanics that means there is a finite probability of finding a particle on the other side of a barrier, even if, in terms of classical physics, it does not possess enough energy to surmount that barrier Electrons in the normal metal at energies corresponding to the gap in the superconductor are forbidden from tunnelling through the insulating barrier However, the cooling power in these experiments was low — typically of the order of one picowatt (10 −12 W) — insufficient to cool astronomical detectors, where the background radiation typically exceeds this level In 1994, Nahum et al . demonstrated the so-called NIS refrigeration effect using a metallic thin-film device, and since then progress has been rapid In most applications, however, chilling the electrons alone is not enough: heat must also be removed from the platform that houses the detector (or sample) to be cooled In the absence of an external voltage, the N and S regions are in thermodynamic equilibrium, with their zero energy points (‘chemical potentials’) aligned — in the middle of the energy gap in S ( Fig. 1 ) New processes and different combinations of materials have since enhanced the cooling power of NIS refrigerators still further  One example is the satellite-based, ultrasensitive radiation detectors that are being used in the search for anisotropy — tiny temperature fluctuations — in the cosmic microwave background thought to be leftover radiation from the Big Bang One way to do this is to thermally isolate a dielectric platform (typically, a thin membrane of silicon nitride) by micromachining techniques, and to suck the heat from it to the cooled electrons in the NIS refrigerator Several sophisticated astronomical and analytical instruments rely on thin-film sensors that must be cooled to temperatures of 0.1 K or lower So the required combination of small bulk and low-temperature operation highlights the need for miniaturized refrigerators Such an achievement would have an enormous impact in overcoming the ‘cryophobia’ that at present prevents the large-scale use of many devices and sensors that can operate only at very low temperatures. The authors are thus the first to refrigerate a separate ‘bulky’, three-dimensional object, using an electronic method, down close to absolute zero The cooling power has since been increased by almost two orders of magnitude by scaling up the physical dimensions of the refrigerator  The French physicist Jean Peltier discovered in 1834 that when an electrical current is passed through a solid-state circuit, heat is in some cases removed The principle of NIS refrigeration is simple ( Fig. 1 ): a normal metal (N) is separated by an insulating (I) barrier from a superconductor (S) The work of Clark et al . is an exciting development towards a fully solid-state, cryogen-free micro-refrigerator, which could eventually cover temperatures from the ambient down to the millikelvin range Their device can reduce the temperature of this system significantly below that of its surroundings — from 320 to 220 mK This approach has previously been used to reduce the temperature of such an insulating apparatus by a factor of two, from 200 to 100 mK Writing in Applied Physics Letters , Clark et al . report significant progress in constructing such a device Yet one obvious application, a solid-state micro-refrigerator capable of cooling to cryogenic millikelvin temperatures, has remained science fiction
 A decrease in reductant input by the same tiny amount could also have prompted the GOE But all such proposals either have internal inconsistencies or violate other constraints provided by the geological record  But apart from a transient spike of 13 C-enriched rocks following the GOE (the cause of which is still being debated ), carbonate rocks that formed before and after 2.4 billion years ago show the same isotopic signature But as oxygen levels increase, so does the concentration of ozone, which shields the atmosphere from solar ultraviolet radiation and thus abates oxygen consumption But carbonate rocks are isotopically similar before and after the GOE (apart from the unexplained spike) But doubters of this event have remained  But there are other unresolved issues in this saga But this would still leave some unexplained observations First, why did atmospheric oxygen climb to significant levels only around 2.4 billion years ago, when oxygen-producing bacteria apparently evolved 2.7 billion years ago , or earlier? Second, carbonate rocks that form on the sea floor should acquire a distinctive ratio of carbon isotopes, as organic carbon from photosynthesizing organisms gets buried in marine sediments For example, the Witwatersrand gold deposits in South Africa contain detrital minerals that were washed down streams between 2.8 billion and 3.0 billion years ago  Goldblatt and colleagues do not challenge the conventional wisdom regarding the rise of oxygen Goldblatt and colleagues model explicitly predicts that the atmosphere was bistable for some time before the GOE, so maybe the yo-yo theory is correct Goldblatt et al . now suggest that a mere 3% increase in organic-carbon burial would have been enough to trigger the GOE How can this be rationalized? One possible explanation — the so-called yo-yo atmosphere theory — was proposed earlier this year  However, the authors show that a much larger perturbation is required to cause a high-oxygen atmosphere to revert back to a low-oxygen state In a low-oxygen atmosphere, oxygen is rapidly consumed in an ultraviolet-catalysed reaction with biogenic methane In other words, the source of atmospheric oxygen — organic-carbon burial — seems to have remained constant with time, even though atmospheric oxygen levels have changed enormously In the presence of oxygen, these minerals should have become oxidized and dissolved In this issue, Goldblatt et al . ( page 683 ) extend the oxygen evolution story, and in doing so may have found some common ground for GOE believers and heretics Increased organic-carbon burial should cause the ratio of 13 C to 12 C in carbonates to rise, because 12 C is preferentially removed from the system Instead, they present a model that might resolve two problems that have puzzled geochemists for years Let us hope that this will lead to a more unified understanding of a fascinating era in Earths history Or perhaps oxygen concentrations did not increase at all, and the low-MIF anomaly seen in post-GOE rocks was produced by some entirely anoxic mechanism, such as the shielding of solar ultraviolet rays by an organic haze  Photosynthesis by bacteria (and later by algae and plants) produces oxygen, but it is the burial of these organisms in marine sediments that leaves excess oxygen behind in the atmosphere — this excess oxygen would otherwise be used up as the organisms decay So far, no high MIF values have been reported in that time interval So maybe the atmosphere got stuck in a low-oxygen state for a long time following the start of photosynthesis, even though oxygen levels were poised to go much higher So, either the oxygen levels were never high enough for that, or they repeatedly went up and came back down very quickly Such a change is far too small to be detected in the carbon-isotope record Such minor fluctuations could have happened for any number of reasons The ancient atmosphere may have had a more complex evolution than we imagined. The ancient rise of atmospheric oxygen is of great interest because of its close relationship with evolution, but the geological evidence for this is indirect and subject to interpretation The consensus for more than 30 years has been that atmospheric oxygen first reached appreciable levels around 2 billion to 2.4 billion years ago , an occasion known as the great oxidation event (GOE) The GOE story was strengthened considerably by the discovery that minerals in ancient rocks had unusual ratios of sulphur isotopes, a phenomenon known as mass-independent fractionation (MIF) The isotopic signature of carbonate rocks formed from these dissolved substances should mirror the isotopic changes in sea water The jury is still out, but all these contradictory observations are stimulating a lot of creative thinking The MIF isotopic signature is small or entirely absent in rocks younger than 2.4 billion years, suggesting that Earths atmosphere has been oxygen-rich since that time  The only known mechanism that can produce this effect is the break-up of sulphur dioxide by ultraviolet light in a low-oxygen atmosphere The organic carbon found in living organisms is depleted in 13 C relative to 12 C, so increases in the rate of organic-carbon burial should cause changes in the ratio of carbon isotopes dissolved in the ocean There is evidence of low sulphur MIF values in rock formations of between 2.76 billion and 2.92 billion years old, suggestive of high atmospheric-oxygen levels preceding the accepted time of the GOE Therefore, the atmospheric oxygen budget can change even if other sources and sinks of oxygen remain constant This bistability results from variations in the rate of atmospheric oxygen consumption as oxygen levels change This led various authors to propose that the GOE was caused by decreases in the sinks for oxygen — that is, by lower emissions of reduced gases from beneath Earths crust and by lower discharge rates of dissolved ferrous iron from hydrothermal vents This theory suggests that oxygen levels first increased about 3.0 billion years ago, decreasing again about 0.2 billion years later, before their final climb to high concentrations 2.4 billion years ago (the GOE) This wonderful result might explain why oxygen levels stabilized permanently following the GOE To explain why it is curious that the carbon-isotope signature of rocks did not change after the GOE, one must consider how the long-term oxygen cycle works Why didnt things change when oxygen levels went up? According to Goldblatt and colleagues , once photosynthesis began, the atmosphere became bistable: it could exist in either a low- or a high-oxygen state
 Damaged DNA, if not repaired before replication, can lead to replication fork stalling and genomic instability ; however, cells can switch to different damage bypass modes that permit replication across lesions Here we show by genetic analysis that SUMO-modified PCNA functionally cooperates with Srs2, a helicase that blocks recombinational repair by disrupting Rad51 nucleoprotein filaments  In S phase, even in the absence of exogenous DNA damage, yeast PCNA can be alternatively modified by the small ubiquitin-related modifier protein SUMO ; however the consequences of this remain controversial  Moreover, Srs2 displays a preference for interacting directly with the SUMO-modified form of PCNA, owing to a specific binding site in its carboxy-terminal tail Our finding suggests a model in which SUMO-modified PCNA recruits Srs2 in S phase in order to prevent unwanted recombination events of replicating chromosomes. Two main bypasses are controlled by ubiquitin modification of proliferating cell nuclear antigen (PCNA), a homotrimeric DNA-encircling protein that functions as a polymerase processivity factor and regulator of replication-linked functions  Upon DNA damage, PCNA is modified at the conserved lysine residue 164 by either mono-ubiquitin or a lysine-63-linked multi-ubiquitin chain , which induce error-prone or error-free replication bypasses of the lesions  Additional methods, materials and strains are presented in Supplementary Information . Averages were obtained from at least two independent experiments Beads were then washed and eluted in sample buffer containing 8 M urea Briefly, ten independent cultures were grown to saturation then plated on selective and non-selective plates Colony-forming units were counted after 3 days of growth in the dark For competition experiments, recombinant free SUMO (Smt3) or ubiquitin was added to the beads together with the lysate to final concentrations of 0, 4, 40 and 400 µM, respectively For direct repeat recombination a strain derived from 344-109D (provided by H For interchromosomal recombination rates the spontaneous reversion rates of the respective homozygous his1-1/his1-1 and his1-7/his1-7 strains were subtracted For quantification of ultraviolet sensitivities, fixed amounts of cells were irradiated with different dosages of ultraviolet light (254 nm) after plating on YPD plates For the pull-down assay, 50 µg of GST or GST–Srs2ΔN bound to beads were incubated with 2.5 mg of yeast native lysate for 3 h at 4 °C Interchromosomal recombination between the heteroalleles his1-1 and his1-7 in diploid cells was determined by growth on complete media without histidine Klein) was used that contains a leu2-112::URA3::leu2-k array in W303 RAD5 + background L Methods Protein techniques Yeast native extract was prepared by glass bead lysis in 150 mM NaCl, 50 mM Tris-HCl pH 7.4 supplemented with protease inhibitors, followed by detergent extraction (1% Triton X-100, 0.05% SDS) and pre-clearing by centrifugation Mutational and recombinational rates were determined by fluctuation analysis  Sensitivity, mutagenesis and recombination assays For qualitative analysis of MMS sensitivity, cells from overnight cultures were spotted on YPD plates containing MMS Spontaneous forward mutation of the CAN1 locus was measured by growth on complete media lacking arginine with 60 mg l -1 canavanine  The number of mutational/recombinational events was determined using a maximum-likelihood approach for the deviation of the number of mutants This was used to score for overall recombination (growth on medium lacking leucine) and gene conversion (growth on medium lacking leucine and uracil) Values are averages from three to seven independent experiments using duplicates Whole-cell extract samples correspond to 1/50 of the total input Yeast protein extracts and analytical denaturing NiNTA pull down were done as described  A PCNA mutant lacking both SUMOylation sites ( pol30-RR ) suppressed rad6 and rad18 to an even greater extent, indicating that SUMOylation at K127 and K164 additively inhibits a salvage pathway Additional deletion of RAD52 strongly neutralized the suppression, indicating that inhibition of the RAD52 salvage pathway is the major cause of the mutator phenotype of rad18  All of these PCNA modifications are limited to S phase (ref. 5 ; see Supplementary Fig. 1 ); in contrast to ubiquitination, SUMOylation occurs even in the absence of exogenous damage  An excess of free SUMO, but not ubiquitin, provided competition for binding of SUMOylated PCNA to Srs2 ( Fig. 2g ), emphasizing that it is specifically SUMO that is relevant for binding As an alternative, we speculated that the identified salvage pathway might involve recombination between sister chromatids during S phase As intrachromosomal recombination between direct repeats is to some extent caused by sister chromatid recombination , we assayed for this activity using a set-up that can differentiate between gene conversion and recombination-mediated deletions  As noted previously , this mutant partially suppresses the hypersensitivity to ultraviolet light or the DNA-alkylating drug methyl-methane sulphonate (MMS) of rad6, rad18 , rad5 and mms2 mutants ( Fig. 1c , d ; see also Supplementary Fig. 2a–c ) Because of the activity of de-SUMOylating enzymes in the cell extract we could not observe the interaction between Srs2 and the modified form of PCNA unless we triggered PCNA SUMOylation by addition of 0.3% MMS to the medium Conversely, suppression of the ultraviolet sensitivity of rad6 and rad18 mutants by the siz1 mutation or PCNA lysine mutations strictly requires a functional RAD52 pathway ( Fig. 1c–f ) From these data we conclude that Srs2 binds PCNA in vivo , and that the interaction is strongly augmented by PCNA SUMOylation From these findings we conclude that SUMOylation of PCNA blocks specifically a recombination pathway and that SUMOylation of both K164 and K127 contribute to the inhibition Furthermore, two-hybrid interaction between the two proteins was also reduced in Siz1-deficient cells Furthermore, we SUMOylated purified recombinant PCNA in vitro at both K164 (which depends on Siz1) and K127, and found also in this set-up that GST–Srs2ΔN also pulled down the SUMOylated forms of PCNA with preference ( Fig. 2h ), suggesting that Srs2 binds SUMOylated PCNA directly Given the physical interaction between Srs2 and SUMOylated PCNA we examined whether the proteins functionally cooperate However, as components of the two modification pathways interact (ref. 5 and Fig. 2a ), they might build a switchboard in which the PCNA–SUMO–Srs2 check facilitates channelling into the RAD6 -dependent bypass. However, as this effect of SUMO is only present in a mutant background in which PCNA cannot be ubiquitinated (wild-type and siz1 cells show identical spontaneous mutagenesis rates), we hypothesized that mutations might arise through faulty replication if the RAD6 bypass is inactivated by mutation and the RAD52 -dependent salvage pathway is additionally blocked by PCNA SUMOylation However, it has been suggested by genetic arguments that, analogous to the model for mono-ubiquitinated PCNA, SUMOylation promotes error-prone synthesis through recruitment of a translesion polymerase However, this is not the case, as rad6   rad52 is in fact more sensitive than pol30-K164R   rad52 ( Supplementary Fig. 2g ), which reflects the fact that Rad6 has other substrates in addition to PCNA (refs 5 , 7 ; Fig. 1e ; see also Supplementary Fig. 2h ) Importantly, srs2ΔC mutant alleles ( srs2ΔC136, srs2ΔC24, srs2ΔC6 ) that express truncated proteins defective in binding to SUMOylated PCNA suppressed the damage sensitivity of rad18 equally and epistatically to the siz1 mutant defective in PCNA SUMOylation ( Fig. 3d ; see also Supplementary Fig. 4e ) In contrast, PCNA is phenotypically the essential target for the Rad18, Rad5 and Mms2 enzymes  In contrast, Rad50—which is required before strand exchange in DNA strand resection—and Rad59—a Rad52 homologue—are apparently not needed for this salvage pathway ( Supplementary Fig. 2e ) In fact, hypersensitivity suppression was not only absent in rad52 mutants, but also in rad51 , rad54 and rad55 mutants ( Supplementary Fig. 2d ), which are defective in the central activity of recombination  In fact, Srs2 interacted strongly with PCNA modified by SUMO at K127 or K164, and especially with the doubly modified form In fact, the mutator phenotype of rad18 was not only suppressed by siz1 but also by pol30-RR and srs2 mutants ( Fig. 4c ) In fact, these mutants suppressed the high interchromosomal recombination rate of the rad18 mutant ( Fig. 4a ), which probably arises through its inability to replicate across lesions In two-hybrid assays, full-length Srs2 is inactive due to low expression, but an amino-terminally truncated Srs2 fragment lacking the helicase domain (Srs2ΔN) is able to bind Rad51 (ref. 9 ; Fig. 2a ) Indeed, we observed that the siz1 mutant defective in PCNA SUMOylation and srs2ΔC had increased recombination rates, which were further increased by a deficiency in RAD18 ( Fig. 4b ) Intrachromosomal recombination was particularly upregulated by srs2Δ , however largely through gene conversion (ref. 26 and Fig. 4b ) Modification of PCNA by ubiquitin involves enzymes of the RAD6 DNA damage bypass mode ( Fig. 1a ; see also ref. 5 ) Moreover, hypersensitivity suppression of rad6 by siz1 was not affected by eliminating the RAD2 nucleotide excision repair pathway ( Supplementary Fig. 2f ) Moreover, it has been noted that srs2Δ  is lethal in combination with a de-SUMOylation enzyme mutant Moreover, Srs2ΔN bound SUMO ( Fig. 2a ), and showed greater affinity for binding the wild-type form of SUMO (Smt3GG) that can form conjugates via its C-terminal di-glycine motif Moreover, these mutants are, in contrast to the srs2Δ  mutant, only mildly sensitive to DNA-damaging agents ( Supplementary Fig. 5a ; see also ref. 18 ) Notably, in contrast to the srs2 knockout, srs2ΔC mutants rescued rad6 only partially and precisely to the level of suppression by siz1 ( Fig. 3c ; see also Supplementary Fig. 4d ) Notably, the PCNA fusion used for the two-hybrid assays (BD-PCNA) was modified by SUMO at both lysine residues, and SUMOylation at K164 depended on Siz1 ( Fig. 2b ) Notably, the steady-state level of SUMOylated PCNA was induced in vivo by overexpression of Srs2ΔN, suggesting that the PCNA–SUMO conjugate is shielded by Srs2ΔN against the activity of de-SUMOylating enzymes ( Supplementary Fig. 3 ) Notably, this effect of siz1 is linked to a deficiency in PCNA SUMOylation, because hypersensitivity suppression of rad6 and rad18 by a PCNA mutant that lacks K164 ( pol30-K164R ) was identical to suppression by siz1 ( Fig. 1e , f ) Notably, this region of Srs2 is distinct from the Rad51 interaction domain, which is located further amino-terminally on Srs2s tail ( Fig. 2i ) Our conclusion that PCNA SUMOylation blocks a RAD52 -dependent pathway is in line with a recent model  RAD6 pathway mutants exhibit a mutator phenotype, and because this phenotype of rad18 is suppressed by siz1 , it has been suggested that SUMOylated PCNA might recruit translesion polymerases Similarly, in contrast to the srs2Δ  diploid, neither the corresponding srs2ΔC mutants nor the mutants defective in PCNA SUMOylation displayed hyperactive interchromosomal recombination ( Fig. 4a ; see also ref. 25 ) Srs2ΔN also bound Rad18 and Rad5, and, importantly, PCNA as well SUMOylation and ubiquitination might represent autonomous triggers, which operate independently from each other SUMOylation depends on Ubc9, but modification at K164 only requires the SUMO ligase Siz1 (ref. 12 ) ( Fig. 1b ) The PCNA–SUMO–Srs2 check is not restricted to haploids, because siz1 and srs2ΔC mutants also suppressed the sensitivity of diploid rad18 mutants ( Supplementary Fig. 5a, b ) The role of PCNA SUMOylation has remained elusive The suppression of ultraviolet and MMS sensitivities for the rad6 mutant by srs2 was greater than by mutants deficient in PCNA SUMOylation ( Fig. 3a ), indicating that srs2 suppresses rad6 by two mechanisms: a PCNA–SUMO-dependent and -independent mode This and our previous work emphasize the importance of PCNA modifications for decision-making at the replication fork This currently undefined activity is primarily perceptible in double mutants of rad18 with rad52 (or rad51 , rad54 , rad55 ), which are rendered more sensitive to ultraviolet light by the absence of Siz1 or by PCNA lysine mutants ( Fig. 1d , f and Supplementary Fig. 2d ; see also Fig. 3 and Supplementary Fig. 4 for this effect in siz1   srs2 double mutants) This enzyme is a potent inhibitor of recombination as it disrupts Rad51 nucleoprotein filaments , which are crucial early recombinogenic intermediates This epistatic relationship reveals that PCNA SUMOylation and Srs2 function in the same pathway This finding underscores the importance of Srs2s C-terminal tail in binding to SUMOylated PCNA, and also illustrates that other functions of Srs2 are unaffected by the srs2ΔC mutations This indicates that recombination between homologous chromosomes, in which Srs2 is involved, is not influenced by this distinctive SUMO-dependent Srs2 pathway This model was based on the remark that rad6   rad52 and pol30-K164R   rad52 have similar phenotypes (instead of comparing rad6   rad52 with the triple mutant rad6   pol30-K164R   rad52 ) This probably reflects another known function of Srs2, namely to regulate the length of conversion tracts during recombination , which is independent of PCNA SUMOylation This suggests that the RAD52 salvage pathway that is unleashed by the absence of the PCNA–SUMO–Srs2 check is probably not interchromosomal recombination Thus, cells deficient in PCNA modification can survive DNA damage by activating a RAD52 -dependent recombinational bypass Thus, the recombination pathway that is set free in the absence of the PCNA–SUMO–Srs2 pathway has the characteristics of sister chromatid recombination To address this issue we used the siz1 mutant, which abolishes PCNA SUMOylation at the K164 site but leaves PCNA ubiquitination unaffected ( Fig. 1b ) To explore potential links between PCNA SUMOylation and Srs2 we looked for a physical interaction Under these conditions GST–Srs2ΔN pulled down the SUMOylated forms of PCNA with greater preference compared with the unmodified form ( Fig. 2e , f ) We also noticed that SUMOylation of PCNA seems to have another function besides its main role in preventing a recombinational repair pathway We confirmed these interactions by pull-down assays using a glutathione S -transferase (GST) fusion of Srs2ΔN ( Fig. 2d ) We identified RAD52 —an essential upstream element of recombinational repair —as a high-dose suppressor of the MMS hypersensitivity of the PCNA mutant pol30-K164R (data not shown) We mapped the interaction with PCNA and SUMO to the C-terminal 138 residues of Srs2s tail ( Fig. 2i ); C-terminal truncations by as few as six amino acids strongly reduced the two-hybrid interaction with both proteins ( Fig. 2i ) We noticed previously that in Saccharomyces cerevisiae , SUMOylation of PCNA at K127 and K164 is detrimental to DNA damage tolerance in the absence of PCNA ubiquitination We realized that the inhibitory function of PCNA SUMOylation on a RAD52 pathway is similar to the known role of the helicase Srs2 (also known as Hpr5)  When we assayed for the suppression of the ultraviolet and MMS sensitivities of rad18 or rad6 mutants by srs2 , or by mutants defective in PCNA SUMOylation, we noticed that rad18   srs2 , rad18   siz1 , rad18   srs2   siz1 and rad18   srs2   pol30-RR mutants all showed nearly identical phenotypes ( Fig. 3b ) When we introduced the lysine mutations in the BD-PCNA construct (as single mutations or in combination) we observed a stepwise reduction in Srs2ΔN binding in two-hybrid assays that was proportional to defects in SUMOylation ( Fig. 2c ) Whereas mono-ubiquitination of PCNA requires Rad6 and Rad18, modification by lysine (K)-63-linked multi-ubiquitin chains additionally requires the heterodimer Ubc13–Mms2 and Rad5 Whereas PCNA ubiquitination mediates post-replicative lesion bypasses , modification with SUMO, which occurs even in the absence of exogenous DNA damage, seems to be a guarding mechanism that prevents unwanted recombination during replication Yeast PCNA (Pol30) is also modified by SUMO at K164, and, to a lesser extent, at the non-conserved residue K127 (ref. 5 ), which matches the ΨKxD/E consensus motif for SUMO modification (SUMOylation) and Ubc9 binding (Ψ represents an aliphatic amino acid)
 Here we show that the voltage-sensor segments do not undergo significant transmembrane translation Our results are consistent with a 2-Å vertical displacement of S4, not the large excursion predicted by the paddle model Recently, the crystal structure of the KvAP channel motivated an unconventional ‘paddle model’ of S4 charge movement, indicating that the segments S3b and S4 might move as a unit through the lipid bilayer with a large (15–20-Å) transmembrane displacement  The voltage-sensing domain (segments S1–S4) contains charged arginine residues on S4 that move across the membrane electric field , modulating channel open probability This small movement supports an alternative model in which the protein shapes the electric field profile, focusing it across a narrow region of S4 (ref. 6 ). Understanding the physical movements of this voltage sensor is of fundamental importance and is the subject of controversy Voltage-gated ion channels open and close in response to voltage changes across electrically excitable cell membranes  Voltage-gated potassium (Kv) channels are homotetramers with each subunit constructed from six transmembrane segments, S1–S6 (ref. 2 ) We tested the movement of these segments in functional Shaker K + channels by using luminescence resonance energy transfer to measure distances between the voltage sensors and a pore-bound scorpion toxin An average lifetime was calculated by normalizing the sensitized emission lifetimes by the rate of energy transfer to obtain a ‘population average’  τ  = ( A 1 / k 1 ) τ  1 + ( A 2 / k 2 ) τ  2 ( A 1 / k 1 ) + ( A 2 / k 2 ) where k n = τ  n -1 - τ  D -1  Assuming these four distances, LRET signals were simulated by assuming a bi-exponential donor with a dominant component, 75% at 1,600 µs, and a minor component, 25% at 300 µs Background cysteine residues on oocytes were generally prelabelled with β-maleimidopropionic acid ( Sigma ) for 1 h after a 2–3-day incubation at 12 °C to increase the specificity of donor labelling  Cells were placed in depolarizing solution for 30 min with 100 µM dithiothreitol to reduce cysteine thiols for reaction with maleimide Charge–voltage relations were measured with a saturating wild-type CTX block (2 µM), and LRET measurements were recorded with a nearly complete block with 100 nM fluorescent toxin (see Supplementary Information ) Controls were labelled identically to the LRET experiments Distances from τ  1 , τ  2 and τ¯ were calculated by finding E (above) and using R = R o ( E -1 - 1) 1/6  Dithiothreitol was washed away before the cells were placed in depolarizing solution containing 80 µM maleimide-lanthanide chelate Donor and acceptor fluorescence were collected simultaneously with D490/10 and HQ520/20 filters , respectively ( Chroma ) Experiments were performed typically 3–5 days after microinjection of 20 ng of Shaker mRNA Fluorescence was detected with two water-cooled R943-02 photomultiplier tubes ( Hamamatsu ) operated at -1,760 V LRET protocols and controls The optical setup consisted of an Olympus inverted IX-70 microscope with a 40 × quartz objective ( numerical aperture 0.8 ; Partec ) LRET signal to background was estimated for every LRET experiment by recording acceptor-sensitized emission signals from oocytes that were expressing high levels of the background Shaker construct without the experimental cysteine mutation LRET simulations with a Shaker model Coordinates for the Shaker open-state model with docked AgTX provide predictions for four different distances between the AgTX-D20 α-carbon and the four α-carbons of selected sites on the voltage sensors Methods Distance calculations The lifetime of acceptor-sensitized emission was used to calculate energy transfer efficiency by using the relation E = 1 - τ  AD / τ  D , where τ  D is the lifetime of the donor in the absence of acceptor. τ  D was measured on channel sites in the absence of acceptors Most data were taken by using BODIPY Fl-maleimide acceptors ( Molecular Probes ) for which R o = 39 Å Multiple time constants indicate that the acceptor molecule is not an equal distance from all four labelled donors to the voltage-sensing domains On a few sites τ  D displayed a slight voltage dependence (S346C and S351C less than 10%; E335C less than 5%) and these changes were included in the analysis (distances changed were less than 1 Å) Oocytes were then incubated for 24–30 h at 18 °C to allow the surface expression of Shaker  Other data were taken with the use of Atto465-maleimide ( Atto-Tec ), R o = 27 Å, and Lucifer Yellow-iodoacetamide ( Molecular Probes ), R o = 23 Å Prompt fluorescence was rejected by using an electronic gate ( Products for Research ) with a dead-time of 70 µs Sensitized emission data were fit to two exponentials using four parameters; A 1 , τ  1 , A 2 , τ  2  The channel construct was the fast inactivation-removed, conducting Shaker H4IR, with the mutations F425G, K427D that increase the toxin binding to sub-nanomolar affinities  The detector current was converted to voltage with a C7319 preamplifier ( 10 6 V/A ; Hamamatsu ) and filtered at 50 kHz ( eight-pole Bessel filter ; Dagan ) The lanthanide was excited with a pulsed 337-nm nitrogen laser source ( Oriel ), reflected by a 400DCLP dichroic filter ( Chroma ) The laser pulse was given exactly 40 ms after the initiation of a voltage step to ensure that the channels had reached conformational equilibrium before the LRET signals were measured The mass of each fluorescent toxin was verified by mass spectrometry, and high-affinity block with Shaker was evaluated qualitatively by examining the slow rate of toxin dissociation The minor component adds a systematic error that slightly underestimates distances (less than 5%) The multiple components can be well described by fitting to two exponentials (see Supplementary Information ), as were the experimental data These calculations show how the complicated geometry of the model can be reduced to distance estimations in close agreement with actual LRET measurements ( Table 1 ). Toxin biochemistry, Shaker expression and block CTX-R19C and AgTX-D20C were prepared, labelled and purified as described previously  Voltage clamping was performed with a two-electrode setup ( CA-1B ; Dagan ) Xenopus ooctye preparation, channel mutagenesis ( Stratagene ) and mRNA synthesis ( Ambion ) were performed with standard procedures Acceptor-sensitized emission data from E333C on S3b and background controls (see Methods) are shown in Fig. 2  Although tethered blockers and LRET measure distances to two different points near the central pore, the close agreement between the approaches shows their power for constraining structural distances on the Shaker channel Any paddle-type mechanism by definition requires a transmembrane movement of 15–20 Å (ref. 5 ), equivalent to a change in distance of about 10 Å from S4 to toxin in the configuration used here, as estimated from conservative structural assumptions ( Fig. 1 ) As a further control, we switched the donor and acceptor for one experiment, labelling E333C with fluorescein acceptors and attaching a CTX-Tb donor to the top of the channel Beyond the techniques agreement with known structures in soluble proteins , distances measured here agree well with independent estimates of distances from the Shaker voltage sensors to the pore made with the use of tethered tetraethylammonium blockers  Conformational changes in proteins can be studied in great detail by using fluorescence energy transfer as a spectroscopic ruler  Distances from both time constants were calculated, as was a population-weighted average distance versus voltage (see Methods) For example, in the tether experiments, Q348C, D349C and K350C were found to be 17–18 Å from the pore in the open state, very similar to our measurements of 17–19 Å and 21–25 Å for S3–S4 linker residues S346C and S351C, respectively For LRET, ionic currents of Shaker expressed in Xenopus oocytes were blocked with 100 nM fluorescent charybdotoxin (CTX) or agitoxin-2 (AgTX) such that almost all channels were blocked and residual unblocked current was limited to 10–30 µA to minimize voltage-clamping errors  For S346C, the calculated distances differed by only 2.5 Å, which may be attributed to differences in dye size and linker lengths For S351C the distances obtained using CTX-Atto465 and CTX-4,4-difluoro-4-bora-3a,4a-diaza- s -indacene (BODIPY) Fl differed by 5 Å, but the gating-induced change in distance was unaffected by the choice of acceptor For three sites, N353C, E335C and L361C, both AgTX and CTX gave similar calculated distances Further advantages arise from the minimal spectral overlap of donor and acceptor, the zero intrinsic anisotropy of the donor lanthanide , and the accuracy with which donor quantum yield and R o (the characteristic distance of 50% energy transfer) can be estimated Furthermore, tethered blockers measure distances only for the open state whereas LRET has the advantage of probing both open and closed states Gating-driven protein movements have previously been measured on the Shaker channel by using LRET and conventional fluorescence resonance energy transfer with both the donor and the acceptor labelled at sites on the voltage-sensing domains Here we have attached the acceptor dye to the channel by means of a scorpion toxin that binds to the pore from the external solution  However, the LRET measurements may systematically underestimate distances slightly because the position of the probes can wobble around their linker attachment points, weighting the measurement towards the distance of closest approach However, this kind of movement would be flatly inconsistent with the small lateral displacements observed in previous LRET measurements  irection, a change in LRET distance of 1 Å corresponds to a 2 Å vertical displacement, as estimated by a conservative geometric calculation similar to that shown in Fig. 1  In every experiment, minimal voltage-dependent changes in both LRET amplitudes and time constants showed that only small changes in energy transfer occurred Lanthanide donors were attached to several sites on S4, S3b and the S3–S4 linker region near S4, to test directly in vivo whether the voltage-sensing segments undergo a large transmembrane movement ( Fig. 1 ) Lanthanide-chelate donors (terbium) were attached to site-directed cysteine residues on the voltage-sensor domain (see Methods) LRET is capable of accurately measuring distances on Shaker channels in vivo because only donor–acceptor pairs produce sensitized acceptor emission, which is measured after a brief time-gate rejects fast background fluorescence LRET measures absolute distances with less systematic error than traditional energy-transfer techniques and can therefore be used to evaluate and constrain structural models LRET signals fitted well to two time constants that reflect the asymmetry of the toxin–acceptor position with respect to the central axis of the channel ( Fig. 3 ) Luminescence resonance energy transfer (LRET) is a modified version that employs a lanthanide donor complex with a long excited-state lifetime  Nevertheless, the distance values obtained with LRET are consistent with the general structural view that S3 and S4 are transmembrane segments at all voltages Recently, a structural model was proposed for the Shaker open state based on a combination of experimental data and molecular dynamics  Similarly, E334C and E335C were found to be about 30 Å from the pore in the tether experiments, close to our measurements for these same residues at the end of S3b, 32–34 Å Small but unambiguous voltage-dependent movements were seen at many sites ( Fig. 4 ), with S3 moving about 1 Å away from the toxin, S4 moving about 1 Å towards the toxin, and the sites in the linker moving up to 2.5 Å in a manner consistent with a change in linker tilt  Small S4 movements relative to these crevices and voltage-induced changes in crevice shape can produce the large gating charge that must traverse the field to account for the steep voltage dependence of voltage-gated channels. Testing the vertical translation of S3b–S4 is of central importance in evaluating the validity of the paddle mechanism, because the models other unusual feature, the location of S4 at the lipid interface, has been shown experimentally to be plausible  The charge–voltage relations for donor-labelled channels were measured separately from cells blocked with a saturating level of unlabelled toxin (see Supplementary Information ) The effect of fluorescein (and rhodamine) was tested, but not terbium-chelate (see Supplementary Information ) The labelling of voltage-sensing segments with fluorescent probes does not disrupt the movement of gating charge The LRET experimental results for two sites on S4 show very close agreement between model and data The model prediction for S3b was unique in that it predicted a shorter distance (about 4 Å) than the distance measured experimentally The model predicts four theoretical distances and we have used simulations to test how well LRET experiments can measure the average distance for situations of such geometric complexity ( Table 1 ; see Methods and Supplementary Information ) The paddle model could be altered to account for our data by allowing the paddle segments to swing laterally outwards while undergoing vertical movement such that distances to the toxin remain constant The resulting distance measurements were nearly identical to those in Fig. 2 (see Supplementary Information ) The results show that sites homologous to the KvAP voltage-sensor paddle move less than 1 Å with respect to the toxin when going from the closed to the open channel positions The simulations reproduce average distances in close agreement with model values; the exception was S351 using CTX-Atto465, for which the small R o caused an underestimation The small physical movements of voltage-sensing segments indicate that the membrane electric field must be focused over a very tight region of the voltage sensor, as if aqueous crevices penetrate the protein and thereby shape the field profile  The small vertical S4 movements presented here supplement the even smaller lateral movements between voltage sensors obtained previously and indicate that the conformational changes underlying gating charge movement are subtle rather than substantial These distances are shown for E333C on S3b and L361C on S4 ( Fig. 2 ) These small changes refute the most central feature of the paddle model: substantial physical movement of gating charge transverse to the membrane plane This configuration measured distance changes parallel to the membrane between S4 helices in the same tetrameric channel but did not directly measure transmembrane movements This model was supplemented with a computationally docked AgTX so that theoretical distances from the toxin labelling site to sites on the Shaker voltage sensor could be compared directly with our LRET measurements ( Fig. 3 ) This unconventional probe can donate energy to a conventional fluorescent acceptor in the standard distance-dependent manner of Förster theory , and energy transfer efficiency and distances are calculated from the time constants of acceptor fluorescence emission (see Methods) Thus, the absolute distances are slightly uncertain, but the changes in distance are reproducible Toxin binding brought acceptor fluorophores into proximity to the labelled donor sites on the channel, and the distances were calculated as a function of voltage from the measured LRET time constants Toxin binding is insensitive to the channels open or closed status and does not alter the movement of the voltage sensor  Two sites on the S3–S4 linker were studied with two different acceptors, CTX-Lucifer Yellow and CTX-Atto465, which are useful for measuring distances as short as 15 Å (see Methods) We are confident that this LRET technique estimates distances faithfully, on proteins in general and in K + channels in particular We note that S3b and S4 move in opposite directions, instead of translating together as a rigid unit
 A third path to better understanding of function begins with deeper analysis of the natural language now used to describe it And in the same spirit, we can view any signal-transduction pathway as a collection of protein machines that takes inputs from inside and outside the cell, performs processing operations on those inputs to arrive at decisions, and communicates those decisions to an apparatus that executes it As we have said, biology does offer a clear definition of meaning (‘it was selected’), but the multiple levels at which selection acts means that meaning is always difficult to determine As yet there is no theory that can specify the meaning or purpose of a string of computer code, but Sussman has suggested how elements of such theory might arise  At the level of cells and organisms, biological systems differ from computers in many ways, including (but not limited to): lack of modularity and boundaries in code; lack of fixed order of execution in code; self-assembly of encoded components; lack of intelligible sentient design; and lack of crisp boundaries between memory, processor, input and output components Because of this difference, it is unlikely that even a mature theory of stored-program machines will be adequate to explain biological systems Because the dynamic behaviour of biological systems is highly determined by a central stored program, living systems differ profoundly from all other naturally occurring, time-evolving systems Blurred boundaries In biological systems it seems reasonable to view the DNA script in the genome as executable code, code that could have been specified by a set of commands in a procedural imperative language Bruck, personal communication) But for biological function, just beyond cause-and-effect narratives and before the ultimate truths of fitness and selection, there lies a muddy patch of ground known as ‘teleology’ But in that mud there may be hope But insofar as biologists wish to attain deeper understanding (for example, to predict the quantitative behaviour of biological systems), they will need to produce biological knowledge and operate on it in ways that natural language does not allow But others, including most biological functions, arise from the genome by considerably more complex routes, with the consequence that function typically occurs simultaneously at multiple levels  But the outlines of most of these stories will probably remain unchanged But their dynamic behaviour can be approached down a second path — by simulating approximate numerical and stochastic methods  But we also observe growing frustration with business as usual But we will leave forecasting about PubMed and Google, metadata and the semantic web to others By 2020 we expect that biologists will use computers, numerous ‘omic’ data types (ref. 1 ) and a greatly expanded biological literature to design experiments, generate and analyse new data, and think about their own work By laying out three paths from current computer science that might lead to deeper insights, we at least hope to stir things up Deeper understanding Happily, there is considerable interest in wanting to build one element of biological semantics — the passage of time — into information theory Equally important, they have inspired mathematicians and computer scientists to apply existing means to reduce complexity and seek new ones For example, biological reaction networks do not have an order of execution, but probabilistic methods can be used to explore the most likely chains of reactions executed by a given network (M Formalizations of information processing that embodied this and other semantic concepts relevant to biology might help biologists to go beyond quantifying reaction rates and molecular species of biological systems to understand their dynamic behaviour He points out that mathematics had its roots in a workaday human activity, that of Egyptian surveyors redefining the boundaries of fields after the Nile floods receded Here we describe three avenues worth exploring Here, however, we imagine ways that formalisms from computer science might contribute to a deeper understanding of biological function However marvellous developments in computation are by 2020, if their impact is limited to information generation, handling, visualization and integration, it will mean that their potential contribution to a more predictive understanding of biological function will have failed However, even in the absence of grand theory, one can work on intermediate steps However, to make the analogy between biological systems and von Neumann computers is to reveal important differences between them ( Fig. 1 ) If biology and information science continue with business as usual, then, by 2020, most of the natural-language stories of 2006 about biological function will be subsumed into more sophisticated narratives, which will be better organized and accessed by computers If we knew better how biological systems worked, we could better perturb existing ones (such as ours, for human medicine) and we could design and build better ones In 2006, it seems reasonable to compare living systems to ‘von Neumann’, or stored-program, computers, with processing systems (here encoded by the stored program), various external and internal inputs, and outputs in the form of execution In biology, differential-equation models have a mixed history; they were vital for understanding transmission of the nerve impulse and for helping to identify reaction types before the channel molecules were discovered, but were less successful in circadian-rhythm research until biologists identified molecular entities and relevant reactions In the same way, a workaday activity — the design and use of procedural imperative languages to write code (‘do this, now, do that, if such a thing happens, then do this!’) to program computers — may lead to new formalisms describing information processing and eventually to new mathematics In this view, the biological system is not primarily a factory or a chemical plant but an assemblage that takes information, processes it, decides and executes Information theorists wanted to build a theory that involved the meaning (the semantic content) of messages, but could not measure meaning in sender, recipient or at any point in between Instead, they chose a meaning for information that was restricted to the carrying capacity of communications channels such as telephone lines — the information technology of their era Instead, we wish to consider some of the formalisms offered by computer science that developed alongside computing machines It doesnt require vast prophetic vision to identify developments in computers and information technology that will greatly affect the practice of biology Like information in Geographical Information Systems, which also have a limited vocabulary, biological narratives of cause and effect are readily systematizable by computers Living computers We begin with what we know in 2006: the trajectory of living systems through developmental time and space is highly determined by the actions and interactions of functional molecules encoded by their genomes Measure of meaning For most biological narratives, the resulting sets of differential equations are too complex to be analytically tractable Most importantly, biological systems usually lack a clear boundary between processing apparatus and output None of these levels is more true or fundamental than the other One fruitful approach formalizes cause-and-effect relationships between named proteins and regulatory sites by translating these into defined chemical reactions undergone by defined molecular species Riedel and J Rigorous thinking about this activity led eventually to mathematics: geometry, trigonometry, algebra and beyond Similarly, biologists would like to cast their descriptions in terms of meaning and purpose, but are limited in their ability to measure those things Some aspects of biological systems, such as the sequence of encoded proteins (which determines their structure), arise directly from the genome Teleology is hard to avoid: it is difficult to explain why the lens of the eye is transparent without at some point mentioning that the eye is ‘for’ seeing The cause-and-effect stories of function of proteins and regulatory sites use an impoverished vocabulary: many proper nouns, few verbs and some prepositional phrases denoting location The development of computer science required both new formalisms to capture reasoning in natural languages and ways to implement those formalisms in physical devices  The fact that both possibilities and frustrations are now starkly evident should make the next 16 years interesting indeed. The search for biologically relevant formalisms has a chance to greatly affect the understanding of biological function, in ways we are just starting to imagine The twentieth-century architects of information theory deliberately restricted their concept of information because they were limited by their ability to define and measure it The weather has no genome There are at least four commercial companies working to provide such systematizations, which are already providing some insight  These approaches will not bear fruit without deliberate and difficult work These encoded molecules are further influenced by external perturbations These levels include the biochemical activity of an individual protein, the function of that protein in cellular processes involving other proteins, and the developmental trajectory of those processes within a multicellular organism  These reactions can be modelled as differential equations constrained by the rules of chemical kinetics, more formally codified as the ‘chemical master equation’   These simulations already constitute ‘theory’, in the narrow sense that they can generate hypotheses that can then be tested by direct experiment They might also help to suggest new experiments — perhaps on synthetic biological systems engineered to have a crisper division between process and output, which could then be evolved by artificial selection This approach might bring a deeper understanding of function at its most fundamental level of fitness and selection This distinction arises because function in biology is a consequence of selection, and selection usually acts at many different levels This fact will continue to frustrate analyses of biological systems in terms of the ‘objective functions’ they are ‘optimized’ to ‘execute’ This level of understanding is adequate for many purposes (including medicine and agriculture) and is being extended by contemporary biologists with great panache Thus, the simplest human question ‘what does the system do?’ (which translates into ‘what was the system selected for?’) usually has simultaneous multiple correct answers Today, by contrast with descriptions of the physical world, the understanding of biological systems is most often represented by natural-language stories codified in natural-language papers and textbooks
 Characterization of the magnetic field at the Galactic Centre is important because it can affect the orbits of molecular clouds by exerting a drag on them, inhibit star formation, and could guide a wind of hot gas or cosmic rays away from the central region Here we report observations of an infrared nebula having the morphology of an intertwined double helix about 100 parsecs from the Galaxys dynamical centre, with its axis oriented perpendicular to the Galactic plane The direct connection between the circumnuclear disk and the double helix is ambiguous, but the images show a possible meandering channel that warrants further investigation. The magnetic field in the central few hundred parsecs of the Milky Way has a dipolar geometry and is substantially stronger than elsewhere in the Galaxy, with estimates ranging up to a milligauss (refs 1–6 ) The observed segment is about 25 parsecs in length, and contains about 1.25 full turns of each of the two continuous, helically wound strands We interpret this feature as a torsional Alfvén wave propagating vertically away from the Galactic disk, driven by rotation of the magnetized circumnuclear gas disk A possible weakness of this hypothesis is that the torsional wave cannot yet be followed all the way down to its hypothetical source, the CND, presumably because of the enhanced confusion by intervening material and superimposed emission structures closer to the Galactic plane A uniform, axisymmetric, rotating disk driving a torsional wave in a field perpendicular to the disk would produce a cylindrically symmetric structure Although the contrast of this potential channel with the local background emission is evidently weak, there are two locations at which evidence for a channel exists in the form of parallel, linear emission features having a separation (∼5 pc) comparable to the width of the helical structure (marked with arrows in Fig. 2 ) As the timescale for propagation of an Alfvén wave from the CND to the observed double helix, ∼100 pc away, is 10 5  yr, or 10/ R rotation periods of the disk, there has been sufficient time for the strong shear in the CND to have eliminated any m = 2 deviation from axisymmetry that may have been present when the double helix was launched At an assumed Galactic Centre distance of 8 kpc, the wavelength of the individual strands of the double helix—about 7.5 arcmin—corresponds to a length of 19 pc, and the maximum strand separation (that is, the overall width of the structure) is 1.4 arcmin, or ∼3.5 pc Consequently, it is possible that the m = 2 deviation from axisymmetry is still in place, or that it has re-formed since the double helix was launched Consequently, we conclude that the emission observed from the double helix most probably arises from thermal dust emission Drawing a correspondence between the period of the CND and the wavelength of the double helix, we can derive the Alfvén velocity: V A = 10 3  km s -1  Finally, if the favoured mechanism for the mid-infrared emission from the DHN remains thermal dust emission, then we must face the question of why dust is present at all in the torsional wave For reasonable densities of the streaming gas, the former mechanism provides inadequate heating, even for a relative gas–dust drift velocity as large as the Alfvén velocity in this region (∼10 3  km s -1 , see below) Furthermore, as we argue below, an association with the Galactic Centre provides a natural explanation for this structure Furthermore, the CND is strongly magnetized, and its predominant shear-induced azimuthal field is believed to merge smoothly with the ambient vertical Galactic Centre field  However, the MSX images show a brighter, more complex background at negative latitudes, so some combination of background confusion and dissipative shock interactions—both common in the Galactic Centre—could account for the absence of a counterpart However, there is no evidence in the MSX data that the helical strands persist outside the region observed with MIPS If the emission corresponds to thermal emission from dust for which the mid-infrared emissivity is proportional to ν p , where ν is the frequency, then the implied best-fit dust temperature is 410 ± 16 K ( p = 1) or 310 ± 10 K ( p = 2) If the emission is from small dust grains, then such grains are likely to carry a net charge, in which case they can then be carried aloft by the torsional wave. If the high dust remperatures are upheld, two possible dust heating mechanisms that might be considered are: (1) heating by streaming of gas particles with respect to the dust (for example, as in a Galactic wind ) and (2) impulsive heating of small grains by ambient Galactic starlight If the two shortest-wavelength channels of MSX are affected by strong emission from bands of polycyclic aromatic hydrocarbon molecules (PAHs), as is frequently the case, then these temperatures might be strongly overestimated, and detailed spectroscopy will be needed to infer the physical dust temperature If, on the other hand, the field strength is that estimated from the rigidity of the non-thermal radio filaments, B ≈ 1 mG (ref. 1 ), we infer a local density of n p ≈ 5 cm -3 , which does not violate any observational constraints Ignoring dust extinction, the equilibrium temperature of dust in the Galactic bulge, 100 pc from the Galactic Centre, is only 30–40 K, but small grains can undergo large temperature excursions as they absorb ultraviolet photons , and the total mass required in small grains to account for the DHN emission, although sensitive to the assumed impinging ultraviolet intensity and grain size distribution, is much less than a solar mass In any case, the average variance of the data from the best-fitting non-thermal power-law models is twice as large as that of the best-fitting thermal model—that with p = 2 In the MSX data ( Fig. 2 ), it is possible with hindsight to recognize the double helix, although the sensitivity and spatial resolution are not sufficient to have revealed this structure before the Spitzer observation It is also noteworthy that there is no sign in MSX images of a negative-latitude counterpart to the DHN It is natural to ascribe the driving of the torsional wave to rotation about the Galactic Centre, and an obvious candidate to do this is the circumnuclear disk (CND)  It reveals the elongated, double helix nebula (DHN) shown in Fig. 1  Little lateral growth of the helical structure is expected as long as the Alfvén speed is much greater than the rotation speed of the driving disk, or as long as the longitudinal wavelength is much greater than the lateral extent of the feature, which is clearly the case Nonetheless, the CND is somewhat non-axisymmetric at present, and its inner portions have two prominent concentrations of material on opposite sides of the centre along the major axis of the projected disk  Not only does the long axis of this structure point roughly to the Galactic Centre, less than a degree away, but it is also oriented along the Galaxys axis of rotation One question that our hypothesis leaves unanswered is why the helical structure has two strands Patchy absorption abutting the brighter, lower-latitude one of these indicates the presence of a nearby concentration of dust and gas, so the emission from this apparent part of the channel might be attributable to an interaction between the magnetic energy in the torsional wave channel and the surrounding, relatively dense, interstellar material. (The recently released images from IRAC, however, indicate that this patchy absorption is likely to be in the relatively near foreground (S Rather, it probably results from a dynamically ordered, large-scale, interstellar phenomenon involving interstellar gas, dust and magnetic fields Shorter-wavelength observations in the four bands of the Infrared Array Camera (IRAC) on Spitzer will help clarify this point Stolovy, personal communication).) One might also speculate that the meander of the apparent channel is partially caused by this interaction, deflecting the wave energy towards positive Galactic longitude Such a meander can be ascribed to the kink instability, arising naturally in a twisted magnetic field The absence of a negative-latitude counterpart is another potential weakness of the torsional wave hypothesis, inasmuch as such waves should propagate equally in both directions away from the driving disk, if that disk is symmetric about its midplane The best-fit colour temperature is 630 ± 40 K The characteristics of the CND match those needed to produce the characteristics of the proposed torsional wave: it has an inner radius of ∼1 pc, and extends out to several parsecs, being somewhat asymmetric in its outer regions, possibly because of an interaction with the SgrA East supernova remnant  The density in this region is not known; if the medium through which the wave propagates is the hot (10 8  K) medium evidenced in diffuse X-rays , then n p ≈ 0.1 cm -3 , and consequently, B = 0.1 mG The DHN is located on the outskirts of the region to which the 10 8  K gas may extend , but given previous estimates for B ranging from 0.01 to 1 mG (refs 1 , 4 , 5 ), this is a plausible field strength The four wavelengths observed with the MSX satellite (8.3, 12.1, 14.7 and 21.3 µm) provide a sampling of the spectral energy distribution of the mid-infrared emission The full extent of the DHN is evident in mid-infrared images previously obtained with the Midcourse Space Experiment (MSX) satellite (Fig. 10 of ref. 8 ; see also ref. 26 ) The individual strands are just barely resolved, with a width of about 7 or 8 arcsec at their narrowest locations, compared to the full-width at half-maximum of the MIPS point spread function at 24 µm, which is 6 arcsec The lateral extent of the proposed torsional wave, ∼3.5 pc, is consistent with the planar extent of the CND, 2–7 pc, and thus with the hypothesis that the rotation of the CND is responsible for a torsional wave propagating through a uniform field The MSX data do, however, show a potential meandering channel along which the wave might propagate ( Fig. 2 ) The MSX images show that the structure extends towards smaller Galactic latitude ( b ) from the region observed with Spitzer; it is at least 20 arcmin (50 pc) in length, extending between Galactic longitude l = 0.08, b = 0.5 and l = 0.02, b = 0.80, and it is possibly part of a larger structure (see below) The new image was obtained using the Multiband Imaging Photometer (MIPS) camera on the Spitzer Space Telescope at a wavelength of 24 µm The observed helical structure is far too large to be attributed to stellar activity The presence of two strands indicates that the driver has an m = 2 symmetry (surface density has a term of the form exp( imφ ), where φ  is the azimuthal angle) The rotation velocity of the CND is approximately constant at 100 km s -1 , giving a period of 10 4 R years at radius R (where R is in units of pc) The second mechanism warrants further investigation The sky location and orientation of the DHN are very suggestive of an association with the centre of the Galaxy The surface brightnesses at a few sample locations, measured relative to the local background, uniformly indicate that the emission is substantially strongest at the shorter wavelengths (detailed in Supplementary Information ) These features (shown in greater detail in Supplementary Information ) can be interpreted as limb-brightened cylinders having relatively thin, emitting walls This could take the form of a bar, or, in the extreme case, one could attribute the strands of the double helix to two diametrically opposed blobs into which the vertical magnetic flux threading the disk had been concentrated This gives B = 0.5 n p 1/2  mG This hypothesis conforms to the apparent, global dipolar geometry of the Galactic Centre magnetic field  This nebula clearly extends beyond the edge of the observed field This, in turn, can be used to estimate the magnetic field strength, B , in this region, with V A 2 = B 2 /(4π m p n p ), where n p is the proton density in the medium through which the wave propagates, and m p is the proton mass Two potential alternatives to thermal dust emission—thermal bremsstrahlung emission by hot electrons and non-thermal emission from a population of relativistic electrons—are both rendered unlikely by the observed spectral slope, as detailed in Supplementary Information  We propose that the DHN is a magnetohydrodynamic torsional Alfvén wave propagating more or less vertically out of the Galactic plane, along magnetic field lines, from the near vicinity of the Galactic Centre
 Biochemical properties of heterodimeric FH2 mutants suggest that the wild-type protein equilibrates between two bound states at the barbed end: one permitting monomer binding and the other permitting monomer dissociation Each of the two structural units in the FH2 dimer binds two actins in an orientation similar to that in an actin filament, suggesting that this structure could function as a filament nucleus Here we report the crystal structure of the yeast Bni1p FH2 domain in complex with tetramethylrhodamine–actin Interconversion between these states allows processive barbed-end polymerization and depolymerization in the presence of bound FH2 domain Kinetic and/or thermodynamic differences in the conformational and binding equilibria can explain the variable activity of different FH2 domains as well as the effects of the actin-binding protein profilin on FH2 function. The conserved formin homology 2 (FH2) domain nucleates actin filaments and remains bound to the barbed end of the growing filament A native data set was collected to 3.05 Å resolution and used for model building (program O ) and positional as well as grouped B -value refinement (CNS), resulting in an R work of 28.9% and an R free of 31.3% Average B -values for actin are 91 Å 2 (subdomain 1), 126 Å 2 (subdomain 2), 97 Å 2 (subdomain 3) and 124 Å 2 (subdomain 4) Biochemical analyses Assembly of 4 µM actin (5% pyrene labelled) at 25 °C was measured as reported  Briefly, FH2 domain in buffer F (buffer G plus 50 mM KCl, 1 mM MgCl 2 , 1 mM EGTA, 10 mM imidazole pH 7.0) was mixed with pre-formed phalloidin actin filaments (∼ 0.1 nM barbed ends), incubated for 2 min at 25 °C and added to Mg-actin (final 0.5 µM, 40% pyrene) Crystals exhibit C 2 symmetry with cell dimensions of a = 232 Å, b = 56 Å, c = 101 Å, β = 107.7° and contain one molecule each of FH2 and actin in the asymmetric unit Crystals grew to 200 × 100 × 100 µm in 2 weeks, and were cryo-protected with 10 mM Tris-HCl, pH 7.6, 25 mM KBr, 35% ethylene glycol and flash-cooled in liquid propane Crystals were grown at 20 °C by hanging-drop vapour diffusion by diluting 0.8–1 µl of the complex in an equal volume of 40 mM Tris-HCl, pH 7.6 and equilibrating against 600 µl of water Data collection and structure determination Diffraction data were collected at beamline 19-ID (SBC-CAT) at the Advanced Photon Source (Argonne National Laboratory) and processed with HKL2000  Details of phase calculations and model refinement are provided in the Supplementary Methods  Electron density maps were calculated using MAD phases to 3.5 Å resolution and improved by density modification using DM  Elongation assays were performed as reported  For depolymerization, 5 µM 70% pyrene actin was polymerized with 2 mM MgCl 2 and 50 mM KCl for 2 h, then diluted to a final concentration of 0.1 µM actin in buffer F in the presence of FH2 domains For FH2, they are 121 Å 2 (lasso), 139 Å 2 (linker), 111 Å 2 (knob), 112 Å 2 (coiled coil) and 106 Å 2 (post) Methods Crystallization Proteins were expressed and purified using standard methods, as described in the Supplementary Methods  Phases were calculated from a three-wavelength anomalous dispersion (MAD) experiment at the selenium peak, inflection and high remote energies using an actin–FH2 crystal in which only the FH2 component was labelled with selenomethionine Rates were determined by linear regression of fluorescence between 100 and 300 s. Rates were obtained by linear regression of the first 100 s of pyrene fluorescence data Six of eight possible selenium sites were identified with the program CNS and refined with the program MLPHARE  The Bni1p FH2 domain in 10 mM HEPES, pH 7.0, 1 mM dithiothreitol (DTT), 100 mM KBr was mixed with TMR–actin in 2 mM Tris-HCl, pH 8.0, 0.2 mM ATP, 0.5 mM DTT, 0.1 mM CaCl 2 (buffer G) to yield 400–440 µM FH2 domain and 400 µM actin, and supplemented with 2 mM ATP and 5 mM CaCl 2  The model contains residues 4–39 and 52–372 for actin as well as residues 1350–1760 for FH2, one ATP, and one Ca 2+ ion The model was verified using a composite simulated annealing omit map showing that all residues have contiguous electron density, except Ala 230 and Asn 252 of actin and Trp 1488 of the FH2 domain The regions in actin and the FH2 domain that interact with each other are best defined A dynamic equilibrium of the bridges enables repeated binding or release of actin monomer from solution while protecting the filament from other capping proteins A model of the dimer can be readily generated from the structure of the polymer by swapping alternate lasso–post connections ( Fig. 1c ) A monomer making perfect long-pitch contact to the actin bound at the knob site (pink) would clash with the post site actin A nucleating ratchet model for FH2 function Our structure of the bridge-bound actin and accompanying biochemical analyses suggest a straightforward mechanism for FH2-mediated filament nucleation A “lasso”  extends from the knob of one monomer and wraps around the post of its neighbour Actin can efficiently dissociate from the filament only in the blocked state, because in this configuration stabilizing long-pitch contacts between actins 0 and 2 are lost (see above), and actin 0 is bound to the filament through only one bridge site Actin nucleation is inherently slow, and cells have developed specialized machineries to accelerate this process Addition of actin monomer to this nucleus would then create the three-actin/two-bridge structure observed in the crystal Additionally, elongation and depolymerization rates will be governed not only by the individual steps of monomer addition and release ( k + and k - ), as in a free filament, but also by the rates and/or populations (depending on rate regime) involved in the configurational equilibrium of the FH2 domain ( k 1 , k -1 , the first order rate constants for the forward and reverse conformational changes, and k 1 / k -1 ) All can potently nucleate new actin filaments , probably through stabilizing an actin dimer  All FH2 domains also bind tightly to filament barbed ends (dissociation constant ( K d ) ∼5–50 nM ), with variable effects on filament dynamics All variants that can nucleate also probably support pointed-end growth ( Fig. 4a–c ) Alternatively, there could be additional binding modes of the FH2 domain at the barbed end that are distinct from those in our crystal Although the perfect 2 1 symmetry between the actins in the crystal is probably relaxed in solution, an ideal short-pitch filament orientation would require use of different surfaces on both actins and the FH2 domain from those observed in the crystal, or substantial changes in the geometry of the bridge element, or both ( Supplementary Fig Although the single-site mutants (xP–KP and Kx–KP) had weaker activities in the actin assembly assay ( Fig. 4a ), both inhibited barbed-end elongation and depolymerization with high potency ( K I = 12–46 nM) and to a much greater degree than the wild-type linked protein (maximum elongation inhibition ∼90%, depolymerization ∼75%) Although this is possible in principle, numerous modes would probably be required to accommodate the 13 orientations in a half-turn of the long-pitch helix An alternating cycle involving release of one bridge and binding of a new actin monomer was proposed as a mechanism for elongation of the FH2-bound barbed end  An incoming monomer could interact in the crystal orientation, but actin–actin contacts in this configuration are minimal (see above) An incoming monomer making perfect short-pitch contact to the actin monomer bound at the post site (yellow) would have a steric clash with the N termini of helices αI and αT of the bridge As a single bridge does not interact with actin 3, stronger actin 1–actin 3 long-pitch contacts could be made than with the full FH2 dimer, leading to slower filament depolymerization As in the single bridge complex described above, the actin 1/2 pair is blocked for monomer addition at the barbed end, whereas the actin 2/3 pair is accessible to pointed-end addition or interactions with bulk filament At a concentration of 30 nM, the KP–KP protein and the wild-type FH2 dimer greatly accelerate filament assembly ( Fig. 4a ) At an FH2-bound barbed end, the actin-binding energetics derive from a combination of actin–actin and actin–FH2 contacts, with the latter probably dominant (see above) Because both sets of idealized contacts cannot be made simultaneously, it is likely that the most favourable orientation of actin 4 is a variant of the filament structure that optimizes the total interaction energy to actins 2 and 3 Because individual steps in this model advance by only a single actin monomer, the twist of the filament should cause the FH2 domain to rotate during processive growth or shrinkage Because profilin cannot be sterically accommodated at both positions in the dimer (not shown), it should block FH2-mediated nucleation, as observed experimentally  Because the dynamics of the FH2 dimer are rectified by actin binding during filament growth, this model posits that formins can function as brownian ratchets Because the mutant lacks the second functional bridge element needed to recruit new monomer, it blocks filament growth Because this unit bridges two actin monomers in our structure of the complex, we refer to it as the actin bridge element Binding of new monomer to the free post site would then regenerate the original three-actin/two-bridge structure with the filament elongated by one monomer (actin 0) Both single-site mutants are impaired in this assay, but retain activity that increases steadily to 500 nM, the maximum concentration tested ( Supplementary Fig By stabilizing two actins in a conformation approximating the short-pitch helix, the FH2 domain could form a template from which a new filament could grow Detailed descriptions of the knob and post interaction sites, as well as a large body of mutagenesis, NMR spectroscopy and sequence conservation data supporting the functional relevance of both sites, are provided in the Supplementary Methods  Differences in the actin binding and/or configurational equilibrium among different FH2 domains can account for their variable degrees of capping, as well as the effects of profilin on activity Direct structural analyses will be necessary to test these possibilities Discussion Our model for processive capping of the actin filament is based on a structural unit, the FH2 actin bridge, that binds the barbed end and blocks monomer binding and release During review of this manuscript, another study reported that the mDia1 FH2 domain could accelerate nucleotide hydrolysis during processive filament growth  Each pair of bridge elements contacts a total of three actin monomers, producing a structure that is free at the pointed end to bind the bulk filament, but sterically blocked at the barbed end Elongation and depolymerization are maximally inhibited by ∼30% and ∼50%, respectively, exemplifying the leaky cap behaviour  FH2 domains from different formin proteins have a variety of actin regulatory activities Finally, FH1-mediated recruitment of actin–profilin complexes could also change the monomer-binding rate by increasing the local actin concentration (and thus k + [actin]) at the FH2-bound barbed end, providing rates even beyond that of free filaments, as recently observed  Finally, in contrast to the barbed end, the pointed end of the pseudo-short-pitch dimer is completely accessible to filament-like contacts to additional monomers ( Fig. 3b ) Finally, the FH2 domain may function through a combination of non-dissociative and dissociative modes, with perhaps the latter dominating under tension in the filament First, despite their similarities, the interaction surface in the bridge structure is much smaller than in the filament model (470 compared with 1,700 Å 2 ), as the monomers are further separated, and the finger is in a less-extended conformation than in the filament model ( Supplementary Table S2 ) Formin activities can be markedly changed by profilin, which inhibits FH1FH2-mediated nucleation but relieves the cap in Cdc12p , and can accelerate elongation rates of FH1FH2-bound barbed ends beyond that of free filaments  Formin proteins nucleate unbranched actin filaments that elongate from their fast-growing barbed ends  Formins contain a conserved FH2 domain that mediates interactions with actin  Further growth (actins 5, 6 and so on) would require similarly non-ideal contacts to actin 3, and eventually lead to an FH2–actin assembly attached to bulk filament However, a single bridge blocks monomer addition and loss from the barbed end of existing filaments However, the barbed end of the FH2–actin assembly is sterically blocked for ideal short-pitch and long-pitch addition to the post-site- and knob-site-bound monomers, respectively, and thus should be inhibited for growth ( Figs 3a , left panel , and 5 ) However, when actin is above the critical concentration, once a monomer (actin 0) binds to the accessible state, the terminal bridge (blue) can no longer migrate back to the previous blocked configuration (that is to actins 2 and 3) due to the energetic penalty of destabilizing the new terminal monomer Ideal contacts between actins 2 and 4 would position the long-pitch interface immediately adjacent to the finger loop of actin 3, providing a potential means of cooperatively stabilizing the incoming monomer, similar to the inter-strand interactions in free filaments  If this hydrolysis occurs at the terminal monomer(s), the actin nucleotide state could also contribute to the FH2 configurational equilibrium during elongation In a general sense, our model proposes that the FH2 dimer exists in equilibrium between two states at the barbed end ( Fig. 5 ) In both cases the actin monomers are oriented in parallel fashion with their N-terminal faces directed outward towards solvent/FH2, and their opposite faces inward In both cases, monomers are related by similar rotations and translations: 180° and 28 Å in our crystal, and 166° and 27.5 Å for the filament short-pitch dimer, although the axes for these operations are not identical (tilted by ∼12°, Fig. 2 ) In concert with migration of the bridge, actin 3 would rearrange to a less strained, more filament-like orientation In isolated TMR–actin, the covalently attached fluorophore is observed to be bound in the cleft between subdomains 1 and 3 at the barbed end of the monomer  In our crystal, actin is bound to ATP and adopts a structure similar to that of an isolated TMR–actin–ATP complex  In our crystals, there is only weak and fragmented electron density at the C-terminal end of actin (where TMR is covalently attached), suggesting that the fluorophore does not contribute strongly to the interactions between the FH2 domain and actin In the accessible state, only three of the four binding sites are engaged, and the post site of the lower bridge is exposed in solution In the blocked state, all four sites in the two bridges are engaged and all three bound actins are in the strained conformation In the crystal, the actin molecules form a pseudo-paired filament along a 2 1 crystallographic screw axis In the crystal, the bridge element binds two actin monomers in an orientation closely resembling a short-pitch actin filament, suggesting that this structure functions as a filament nucleus In the crystal, the lasso of each FH2 monomer interacts with the post of the next, resulting in a polymer of tethered bridges that winds around the pseudo-filament of actin ( Fig. 1c ) In the FH2 dimer, the second bridge element provides functionality that can overcome the inhibitory properties of the first In the polymer, the linker spans a distance of about 42 Å between the knob of one monomer (residue 1418) and the post/lasso of its partner (residue 1400) In the proposed functional dimer, this distance is about 34 Å, which could be spanned easily by the linker In this assembly, all four possible interaction sites of the FH2 dimer are engaged with actin, and all three terminal monomers are held in the strained orientation through bridge contacts In this case, only the two terminal actins are in the strained conformation In this complex there are only minimal contacts between monomer 1 and its neighbouring actins: the first bridge prevents filament-like short-pitch contacts to actin 2 (see above), and the geometry imparted by the pair of bridges prevents filament-like long-pitch contacts to monomer 3 (450 Å 2 buried surface versus 1,700 Å 2 in the Holmes model) In this model, transitions between the blocked and accessible states occur randomly (with relative probabilities determined by the energy difference between the states) It forms a shallow arc composed of a central, antiparallel, three-helix bundle flanked at its amino- and carboxy-terminal ends with two additional helical subdomains (termed knob and post, respectively ) Migration of the upper (blue) bridge element from actins 2/3 to actin 1 could relieve this inhibition by providing a free post site to recruit an incoming monomer (from left to centre panel in Fig. 5 ) Notably, actin can efficiently add to the barbed end only in the accessible state (actin 0), because an exposed bridge post site is necessary for recruitment at this position Of the four double mutants, only the xx–KP protein retains significant activity in this assay, whereas the others are virtually inactive up to concentrations as high as 500 nM ( Supplementary Fig Of the four double mutants, xx–KP decreased both rates to the level of the single-site mutants, but with a K I value of 170 nM, very similar to that reported for the isolated bridge  On the basis of the results with mutant homodimers ( Supplementary Fig One site is in the knob subdomain and contacts the barbed end of one actin monomer ( Fig. 1b ; see also Supplementary Fig Only the wild-type FH2 dimer composed of two bridges with four intact contact sites permits filaments to grow or shrink rapidly from the bound barbed end Processive capping requires four actin-binding sites In the crystal, each pair of bridge elements binds to a total of three actin monomers ( Fig. 1c ) Proteins with three intact sites bind filament barbed ends with higher affinity, but also have this same inhibitory function as the isolated bridge Rather, the biologically relevant form of the FH2–actin complex is, most likely, the ring-like structure formed by two reciprocally connected bridges Recent evidence that actin filaments can have quite variable structures implies that such deviations from the idealized contacts of the Holmes model could be readily tolerated Repeated cycles of configurational exchange of the bridges and monomer binding would then lead to barbed-end growth in the presence of the FH2 cap, giving rise to the FH2–actin assembly attached to bulk filament, as described above S1 ) S2 ) S2 ) S2 ; see also ref. 22 ), we used I1431A and K1601A mutations to disable the knob and post sites, respectively, on individual bridges in the FH2 dimer S3 ) S4 ) S4 ) S5 ), establishing that it reliably mimics the non-covalent dimer S5 and Table S1 ) Second, the barbed end of the pseudo-short-pitch actin dimer is blocked by the bridge for addition of a third monomer in a filament-like orientation ( Fig. 3a ) Several FH2 domains, including those of Bni1p , Dia (not shown) and FRL , are dimeric in solution, and Bni1p, Cdc12p and mDia1 are functional when immobilized, where they are unlikely to polymerize Similarly, critical concentration is given by the product of both equilibria, not simply that of monomer addition and release ([actin] crit = ( k -1 k - )/( k 1 k + )), and could vary as well Similarly, proteins with one wild-type bridge and additional functional sites in the second, such as the single-site mutants (Kx–KP and xP–KP) and the wild-type protein, should nucleate with greater potency than the xx–KP mutant, again as we observe Structural overview We determined the crystal structure of the FH2 domain of Bni1p (residues 1327–1769) in complex with tetramethylrhodamine–actin (TMR–actin, Table 1 ) using data to 3.05 Å Such a structure would overcome the largest energetic barrier to nucleation: formation of the initial actin dimer Such biasing of the equilibrium, coupled with an inability to recruit new monomer through the post site (Kx–KP) or destabilize actin 1–actin 3 long pitch contacts through two knob sites (xP–KP) could explain the functional properties of these proteins The ability of the single-site mutants to block barbed-end elongation yet still stimulate filament assembly ( Fig. 4a ) indicates that these proteins are potent nucleators of new filaments, but allow growth only at the pointed end The actins are also radially displaced from the filament axis, so that subdomains 1 and 2 are more solvent-exposed than 3 and 4 The activity of the xx–KP protein mirrors that reported previously for an isolated engineered bridge from Bni1p  The bridge creates a pseudo-short-pitch actin dimer In the crystal, each bridge contacts two actin monomers through two distinct sites on opposite ends of the structure ( Fig. 1b ) The Cdc12p FH1FH2 element is apparently distinct and functions as a typical capping protein, which blocks barbed-end assembly and disassembly, and increases the filament critical concentration to that of the pointed end  The details of how these mutants are bound to the barbed end are not known; one possibility is that in order to maximize interactions of their actin-binding sites and stability of the filament, the Kx–KP and xP–KP mutants may differentially favour the accessible and blocked configurations in the FH2 equilibrium, respectively The dimeric ring was proposed to bind to the two terminal actin monomers at the filament barbed end , with each bridge engaging one actin The DNase I binding loop of actin in the Bni1p complex is not observed in the electron density The existence of both states and a dynamic equilibrium between them are thus necessary features of the Bni1p FH2 domain, allowing it to remain tightly bound to the filament barbed end, yet permitting processive filament growth and shrinkage in response to appropriate actin concentrations The FH2 domain bound to actin is highly similar to the two previously reported structures of the free FH2 domain of Bni1p ( Fig. 1b ; see also Supplementary Fig The FH2 domain is often located carboxy-terminally to a proline-rich FH1 domain, which binds SH3 and WW domains, and profilin  The FH2 domain nucleates filaments that grow rapidly in the barbed-end direction The FH2 domains of several formin proteins are dimeric in solution  The FH2 domains of the actin regulatory proteins Bni1p, mDia1 and FRL potently block the inhibitory activities of capping protein and gelsolin , but paradoxically only decrease rates of polymerization and depolymerization at the barbed end 2–5-fold, and have minor effects on critical concentration  The FH2 domains wind around the outside of this structure in a helical arrangement ( Fig. 1a ) The first is that FH2 domains may be attached in these systems through linkages that allow rotation, either of membrane-bound components or of rotatable bonds in linkers The geometry of the bridge–actin complex appears to be precisely tuned to provide the balance of strain and binding energy needed to control actin monomer binding and dissociation from the barbed end, yet it also provides sufficient similarity to the natural filament to allow pointed-end attachment to the bulk filament The KP–KP protein and wild-type FH2 dimer each decrease the rate of both processes, with half-maximal inhibition at 3–9 nM The Kx–KP and xP–KP single mutants bind the barbed end more tightly than a single bridge element ( Supplementary Table S1 ), indicating that an additional functional site in each probably engages the filament The lasso of one monomer, and the post, three-helix bundle and knob of its partner in the FH2 dimer create the conserved structural unit The other three double mutants have only very weak effects on elongation and depolymerization The rearranged bridge would then be attached to actin 1 only through its knob site The resultant protein has the same size as the natural FH2 dimer, as measured by multi-angle light scattering (not shown), and behaves identically during purification and in actin assembly assays ( Fig. 4 ; see also Supplementary Fig The second is a composite surface formed by elements from both the lasso and post regions of the FH2 domain, which we will refer to as the post site ( Fig. 1b ; see also Supplementary Fig The structure and proteins described here provide tools to resolve this issue and the next set of mechanistic questions on formin function. The structures of an FH2 dimer from Bni1p and a truncated FH2 monomer from mDia1 were recently determined  The transition from bridge-bound actin geometry to bulk filament geometry could occur entirely at the junction with bulk filament (as implied for simplicity in Fig. 5 ) or more gradually over a longer length The transition from the blocked to the accessible state involves release of actin 3 from the upper bridge, allowing it to incorporate into the filament with more-optimal geometry The two actin monomers bound to the bridge element show remarkable similarity to the short-pitch dimer in the Holmes model of an actin filament ( Fig. 2 )  The xx–KP mutant could engage the two terminal monomers at the filament barbed end, holding them in the pseudo-short-pitch orientation through contacts to the intact bridge element There is no evidence that FH2 domains form polymers outside the crystal These data, as well as real-time imaging of FH2-bound filament growth , suggest that these formins remain stably attached to the filament as actin monomers are inserted between the FH2 domain and the barbed end, leading to their description as leaky or processive caps  These features of the bridge–actin complex form a key foundation for our mechanistic models below These show a common elongated structural unit (referred to here as an actin bridge, see below), which in the FH2 dimer is reciprocally connected at both ends by flexible tethers to create a closed ring These structures have important roles in polarity, adhesion and cytokinesis in many cell types  These, too, could vary between different family members This arrangement is different compared with free Bni1p where two monomers form a ring-like dimer through reciprocal lasso–post interactions This assembly could grow (albeit slowly) in the pointed-end direction ( Fig. 5 , left panel), where it is unobstructed, and a new subunit (actin 4) could make ideal long- or short-pitch contacts to actins 2 or 3, respectively This basic asymmetry could account for retention of the FH2 domain at the barbed end, rather than the pointed end or within the filament This effect would not be relevant during filament depolymerization (because all monomers are ADP-bound), which also probably occurs processively based on kinetic considerations This migration could occur with the FH2 dimeric ring intact; simple modelling demonstrates that the inter-bridge linker is long enough to pass around the sides of actins 1 and 3 easily without disrupting either set of lasso–post contacts within the formin (not shown) This model for processive capping can reasonably explain our biochemical data on the FH2 mutants This model requires that proteins contain at least one functional bridge for efficient nucleation, consistent with the lack of activity in the homodimeric mutants (Kx–Kx and xP–xP) and the trans double mutant (xP–Kx) This suggests that in the FH2 dimer, one bridge blocks monomer binding and dissociation at the barbed end, and the second bridge provides functionality that overcomes this inhibition This surface binds subdomain 1 on the side of a second actin monomer, which is related to the knob-bound actin through the 2 1 screw axis of the crystal This would seem to conflict with formin incorporation into large, membrane-anchored assemblies in vivo , and observations that immobilized filaments growing from immobilized FH2 domains do not supercoil  Those with only impaired bridges cannot ( Fig. 4a ), and appear to interact with filaments only weakly ( Fig. 4b , c ) Three features of the bridge element–actin complex are particularly relevant to FH2 function Three successive actin monomers contact this reconstructed dimeric FH2 ring ( Fig. 1c ): an upper actin (3) binds the knob of one bridge (blue); a middle actin (2) binds the post/lasso of the first bridge and the knob of the second bridge (green); and a lower actin (1) binds the post of the second bridge Thus, actin is probably in a higher energy (that is, strained) state when bound to the bridge than when incorporated into the filament Thus, all the proteins possessing at least one intact bridge retained activity in the actin assembly assay, whereas those composed only of mutant bridges were inactive Thus, k + [actin] and k - (the pseudo-first-order and first-order rate constants for monomer binding and dissociation, respectively) could vary among the FH2 family members Thus, monomer 1 is probably maintained at the barbed end largely through its contacts to the bridge rather than through contacts to the other actins Thus, the bridge appears to be the minimal unit necessary and sufficient to promote filament nucleation Thus, the equilibrium between these two configurations constitutes a balance between binding energy of the post site in the blocked state and relief of strain energy of actin 3 in the accessible state Thus, the FH2 domain seems to have undergone a domain swap during crystallization, exchanging one intra-dimer post contact for two inter-dimer contacts Thus, the system behaves as a brownian ratchet , where fluctuations in FH2 configuration are captured and rectified through binding of a new actin monomer at the barbed end Thus, we believe that the pseudo-short-pitch geometry of the bridge-bound actins closely approximates an important functional state of the FH2 domain To examine the importance of this four-site binding mode for dynamic aspects of FH2 function, we created a series of mutants with different numbers and combinations of available actin-binding sites in the FH2 dimer Together, the data show that any proteins containing an intact bridge can nucleate new filaments Together, these dictate that the thermodynamics and/or kinetics at the barbed end could in principle differ greatly between different formins due to sequence and structural variations Variations in capping Our model provides possible explanations for the functional variability among different formins and the effects of FH1-mediated recruitment of profilin–actin on FH2 function ( Fig. 5 ) We also examined the effects of the mutants on barbed-end elongation (independent of nucleation) and filament depolymerization ( Fig. 4b , c ; see also Supplementary Fig We created two variants of this protein where a single knob or single post site was mutated (xP–KP and Kx–KP, respectively); two variants where one knob and one post site were mutated simultaneously in either the same bridge (xx–KP, cis KP mutant) or different bridges (xP–Kx, trans KP mutant); and the homodimeric double knob (xP–xP) and double post (Kx–Kx) variants ( Supplementary Table S1 ) We do not believe that this swap occurs during normal function of the FH2 domain We fused two FH2 domains together genetically using a linker We have considered several possible resolutions to this paradox We now describe the crystal structure of the FH2 domain of Bni1p in complex with actin, and propose a nucleating ratchet model for FH2 function We propose that processive capping occurs through a dynamic equilibrium of the FH2 dimer at the barbed end between the blocked configuration, from which actin dissociation occurs, and an accessible configuration in which a free site on one bridge recruits new actin We propose that this arrangement represents an important configuration of the FH2 dimer at the filament barbed end We refer to this protein as the linked wild type, or KP–KP, to indicate functional knob and post sites in both bridges We will refer to the crystallographic organization as a pseudo-short-pitch actin dimer
 The importance of surfaces and interfaces cannot be overstated, with their reach extending from the hardware of the digital age to the processes of life The past half-century has seen the development of a full and varied toolkit for characterizing them This toolkit is now serving a growing interdisciplinary community and is providing a powerful platform for scientific research and manufacturing technology. Again, kinetic and thermodynamic principles are used to precisely control the formation of complex ordered surface structures that might find use in the information industry Although electron microscopy had been around for decades, it could not be used for many samples and problems Although incisive experimental tools for probing surfaces were developed only later, scientists and engineers nevertheless had useful chemical and physical concepts on hand to guide their thinking Another crucial aspect of the development of surface and interface science is the emergence of computational tools that make it possible to use evolving theory, ranging from quantum to statistical mechanics, to tackle simulations and analyses of enormously complex interfacial behaviour As has been nicely outlined in a historical perspective by Duke , the birth and subsequent evolution of surface science were driven by technological innovations At that time, machinery — particularly automobiles — became an increasingly important factor in our economy so that developing methods for controlling phenomena such as friction, lubrication, adhesion, wetting, corrosion and surface oxidation provided opportunities for enormous economic gains But a cursory scan of the scientific and technological literature shows that the direct study of real surfaces is a fairly recent phenomenon But our direct interaction was really surprisingly small, with the experimental hardware and concepts needed to drive the vacuum side of surface science firmly rooted in physics and the molecular side in chemistry  But today, it is almost taken for granted that we can directly image and even control single atoms and molecules on a surface and create useful new structures But transforming the production of particles from a highly empirical art to a rational, adjustable method was only possible when the principles developed to explain wetting and surface molecular assembly were used to explore the factors that control the sizes, shapes and properties of colloidal nanoparticles Chandler ( p. 640 ) gives an example of how well-constructed theory can help to identify the basic structural and energetic factors that control the behaviour of water at hydrophobic surfaces and thereby develop a powerful yet simple understanding of an often complex phenomenon that affects a wide range of systems and processes Considering engineered device structures, Atencia and Beebe ( p. 648 ) show that the ability to build micrometre-to-nanometre-scale channel structures provides a means to exploit the fundamental principles of fluid behaviour in confined geometries Developments in the hard surface science have given us ever faster computers and communication technologies During this time, I was working on surface molecular assembly at Bell Laboratories, surrounded by many of the vacuum-surface science pioneers of the time Evolution of the soft interface science has opened avenues for studying biological interfaces and, in the late 1980s, kick-started ‘soft lithography’ as a simple and versatile lab-bench method for chemical patterning of surfaces down to submicrometre dimensions Finally, Barth, Costantini and Kern ( p. 671 ) give us a look at how the traditional area of vacuum-surface science with single crystal surfaces has evolved into a highly sophisticated art For example, gold colloids were used for decorating pottery or staining glass, and silver colloids formed the basis of photographic film Groups of scientists from diverse backgrounds have access to these tools for very different investigations and can think in a common way about diverse surface and interface phenomena and applications I think it is useful to look back and consider how we arrived at this point, not least because it serves as an interesting example of how science often evolves slowly during years of patient study, followed by a sudden explosion in the number of new insights and new applications In a field that has mainly emerged from empirical observations and experiment, it is now not unusual to see that well-executed theory and simulation can be accepted as more useful than experiment (which is often prohibitively costly and difficult for complex systems and phenomena) In fact, a number of important surface and interface-related phenomena were uncovered during this period, including the mechanism of the photo-electric effect and the invention of the transistor In my mind, the need to understand in detail surfaces and interfaces and to control them really heightened in the first half of the past century In the case of interface science, it is not that many years ago when there still were no tools available to us for directly interrogating the tiny amounts of matter present in surfaces and interfaces Intriguingly, processing capabilities of hard surface science have been combined with soft lithography to control the wetting behaviour of fluids under confinement and on chemically patterned surfaces It is only over the past decade or so that the subject of interfaces has moved to the forefront of an increasing number of fascinating fundamental scientific enquiries Moving towards softer, biologically relevant structures, Tanaka and Sackmann ( p. 656 ) detail strategies for constructing and using improved model cell membranes New developments But the true birth of surface and interface science, where molecular and atomic details of a surface are imaged and manipulated directly, occurred only in the second half of the past century Nowadays, even surfaces immersed in liquid can be imaged using SPM Only when ultra-high vacuum systems became available in the 1960s was it possible to create and maintain well-defined surfaces Overall these articles underscore the importance of the confluence of surface and interface research in recent years and point the way to future developments and applications. Overall, however, vacuum-surface science — or ‘hard’ surface science because of its focus on bare single crystals of metal — was evolving along its own course, while molecular surface assembly headed off in another direction to become the ‘soft’ surface science concerned with the behaviour of molecules such as surfactants and even polymers at interfaces  Reasonably accurate concepts were also developed for interfacial phenomena involving soft matter, such as the self-organization of a monolayer of amphiphilic (surfactant) molecules at metal surfaces as relates to lubrication, wetting and adhesion  Still, the direct and quantitative determination of the atomic composition and structure of clean metal surfaces under vacuum conditions had to await the development of electron and ion spectroscopies, which occurred in electrical engineering and physics labs during the 1960s to 1980s Studies then also shifted to ‘soft’ systems to explore self-assembled molecules at surfaces Such crystallites or colloidal particles with nanometre-scale dimensions have been produced and used throughout history Surfaces and interfaces are ubiquitous The ability to precisely engineer interfaces is playing an increasingly dominant part in the development of new technologies relevant to all aspects of our lives, from energy production to biomedical implants The advent of scanning probe microscopies (SPM) filled this gap and has over the course of the 1990s and into the present, revolutionized surface and interface science (and, incidentally, seems to have prompted the arrival of ‘nanotechnology’ as the label of choice for every study looking at something ‘small’) The articles that follow in this issue give an excellent demonstration of how the merging of different scientific streams has given us a commanding toolbox, which makes it possible to advances the frontiers of interface science and technology in fields as diverse as electronics, cell biology and sensor development The contemporary toolkit While each of these several fields was evolving separately, the ability to routinely observe and even manipulate individual objects at the nanometre scale remained tantalizingly out of reach The first SPM studies looked at ‘hard’ surfaces that are of interest for microelectronics and heterogeneous catalysis, revealing the atomic structure of single crystals held in vacuum The following articles illustrate some of the tools, concepts and knowledge that are now readily available to those who study interfaces and engineer interfacial phenomena and structures for practical applications The mass balance, which had been such a powerful instrument for early chemists, was incapable of measuring the mass of a surface layer The result is a wide range of useful microfluidic devices that harness interface effects These efforts to uncover the atomic details of surfaces coincided with investigations of molecular self-assembly at surfaces, which started in the early 1980s and was enabled in good part by the emergence of photon-based surface characterization tools, such as monolayer sensitive infrared, optical and photoelectron spectroscopies These endeavours are supported by continuously evolving theories, which are in turn bolstered by the dizzying increase in the power of computers so that simulations now routinely help unravel the details of interface phenomena, such as the behaviour of fluids in confined spaces while flowing across chemically structured surfaces These essentially self-organized molecular layers, tethered to surfaces, are coupled with analytical probes to study fundamental processes occurring in or on biological membranes and developed for sensor applications These last two papers point to a distinct change in the ability to use fundamental knowledge for bioengineering These so-called microfluidic systems, which first emerged in the early 1990s, are now mainly created by simple soft lithography methods and have been applied to a wide range of analytical and sensing systems They are found in systems as simple as a piece of metal in a vacuum, and as complex as biological cells and living organisms They define a boundary with the surrounding environment and influence interactions with that environment, and so it is no surprise that interfaces have been appreciated historically — just think of how corrosion, tarnishing and friction have plagued the hardware of civilization They show that fundamental kinetic and thermodynamic principles, along with judicious use of molecular adsorption at the crystallite surface, allow us to select growth pathways to achieve the controlled formation of unprecedently complex inorganic nanostructures This approach to understanding the interfacial behaviour of liquids will accelerate progress in developing applications for microfluidics and bio-membranes, and bring the understanding of fundamental phenomena such as wetting to new levels This capability, along with the emergence of non-linear laser spectroscopies that are sensitive to wet interfaces, has started to provide incisive access to biological interface problems This has made it possible to achieve impressive control over nanoparticle formation, to the extent that we can now produce nanoparticles with narrow size distributions, alter the shape of particles by selective growth of appropriate crystal faces and tune particle properties such as their optical response What overlap there was proved, of course, to be extremely stimulating What seems amazing to me is that hard and soft surface and interface science have delivered a powerful range of common experimental and theoretical tools that are proving useful in areas as diverse as microelectronics and biocompatibility When I consider these achievements and my journey with a large number of colleagues down the path of surface and interface research over the past four decades, I am truly struck by the confluence of what at one time were considered wholly different streams of science Yet another stream of scientific development appeared in the mid to later 1980s, when chemists began to learn to control the precipitation of simple inorganic compounds from solution to create uniform, nanometre-sized crystallites Yin and Alivisatos ( p. 664 ) review the rapid progress that has been made in forming nanometre-sized crystallites of inorganic materials with excellent control over their sizes and shapes
 A All mammalian embryos may use a similar mechanism to determine their body plan, the authors say Antia Biogeosciences 2, 189–204; 2005) Astronomy: Heavenly alchemy Astrophys Biochemistry: Pass it on Chem Biol. 13, 329–338 (2006) We already know that one kind of nucleic acid, such as DNA or RNA, can transfer nucleotide sequence information to another Blocking HPc with antibodies either stopped or shortened hibernation But efforts to make p-type InN have been hampered by problems with measuring the result: surface electrons make the definitive test impossible to carry out But further work is needed to determine whether this constitutes ‘vision’ But new evidence may force us to revise this view, leading to the conclusion that marine snow transports more carbon than previously believed But such stars would live fast and die violently, producing none of the heavy elements such as barium that astronomers find inside the Population II stars that formed from their ashes But they may not have diverged into the 11,800 species that now exist until much later — perhaps at the same time as flowering plants diversified and increased the ants range of lifestyle options By evaluating the divergence between the sequences, they deduced how long ago the different groups emerged — and then went back to the fossil record (pictured) to check Camillis group had shown before that expression of certain genes was reduced in stool-isolated V. cholerae  Cell 10, 451–459 (2006) A molecular signal that distinguishes the mouse embryos future head from tail appears earlier than had been thought, and without directions from the uterus Cell biology: Cutting edge Cell 125, 85–98 (2006) Yeast cells have a signalling system that ensures chromosomes are safely hauled to their correct destinations before allowing the final step of cell division to go ahead, researchers have found Clearly, the mysteries of the tiny islands of activity called marine snow are far from solved. Could a light-activated protein from green algae do the trick? Zhuo-Hua Pan at the Wayne State University School of Medicine in Detroit, Michigan, and his colleagues used viral gene transfer to insert the protein channelopsin-2 into the retinal ganglion cells of rodents Develomental biology: Babys first steps Dev Ecol Evolution: March of the ants Science 312, 101–104 (2006) Todays taxonomic ant groups arose earlier than previously thought, more than 140 million years ago, according to the most comprehensive census yet of their evolutionary family tree First, by keeping the chipmunks at a constant 5 °C, the researchers showed that hibernation occurred independent of temperature Genetic engineering: Blind mice Neuron 50, 23–33 (2006) One strategy for restoring vision lost to retinal degeneration is to turn surviving nerve cells into light sensors Gerald Joyce and his team at the Scripps Research Institute in La Jolla, California, studied a particular ribozyme, an RNA molecule that contains genetic information and acts as an enzyme Goldthwait et al  Hiroshi Hamada of the Osaka University, Japan, and his colleagues show that a gene called Lefty1 is switched on in the future head region of embryos at around four days — and that this also occurs when embryos are grown in culture, without the guidance of the uterine wall However, recent measurements have found high dissolved-organic-carbon levels in the funnel-shaped sediment traps used to collect marine snow, suggesting that some of the dissolved carbon can hitch a ride downwards (A I will never forget my first dive in the open ocean In calculating the snows contribution to the carbon budget, scientists had assumed that the carbon flux depended only on the particles solid content In this study, the team finds that the stool bacteria are unable to direct their swimming towards nutritional cues — a process known as chemotaxis Independent work supports this idea, demonstrating that marine-snow aggregates somehow retain solutes within their pores, despite being 99% holes (S It could also be at work in mammalian cells, where it would be an important guard against the development of cancer It remains unclear, however, why impaired chemotaxis reduces the number of V. cholerae cells required for a successful infection It represents a critical link in the global carbon cycle: the sinking snow transports carbon from the upper ocean, and thus the atmosphere, to the ocean depths It was thought that this dissolved organic carbon would be left behind, so reducing the carbon flux with depth J. 641, 1–20 (2006) The Universes first stars were much smaller than was once thought, according to a mathematical model of stellar chemistry Jason Tumlinson at the Yale Center for Astronomy and Astrophysics in New Haven, Connecticut, shows that Population III stars averaging between 10 and 40 solar masses would produce the observed chemical make-up of the long-lived second-generation stars, which are still around today Journal club Uta Passow Alfred Wegener Institute, Bremerhaven, Germany Theres more to marine snow than meets the eye, says a biological oceanographer Lett. 96, 125505 (2006) After years of effort, a delinquent semiconductor has been tamed Mar Marine snow (the subject I study) consists of composite particles, more than half a millimetre in diameter, made of cells, shreds of plankton feeding webs, faeces and minerals Materials science: Particles shape up Nature Mater. doi:10.1038/nmat1617 (2006) Swarms of polymer particles with curious shapes (pictured) can be easily synthesized using a new continuous-flow technique from researchers at the Massachusetts Institute of Technology Microbes degrade the solid matter in the snow as it descends, releasing carbon into the water Microbiol. 60, 417–426 (2006) Vibrio cholerae cells from human stools have previously been shown to be more virulent than their laboratory-grown siblings Microbiology: No sense of direction Mol N Noriaki Kondo of the Mitsubishi Kagaku Institute of Life Sciences in Tokyo, Japan, and his colleagues watched more than 100 male chipmunks ( Tamias sibiricus ) go through their annual hibernation cycles, the oldest living for 11 years Now Andrew Camilli of the Tufts University School of Medicine in Boston, Massachusetts, and his colleagues have traced the phenomenon to the genetic modification of a single trait Now researchers at the Lawrence Berkeley National Laboratory, California, and Cornell University in Ithaca, New York, have done a battery of experiments that suggest adding magnesium to the material does the job Now researchers in the United States say that biochemical function can also be passed on P-type doping introduces positively charged conductors called ‘holes’ into a semiconductor Patrick Doyle and his colleagues created the sweet-shaped objects, just a few micrometres in size, using materials that can be polymerized by ultraviolet light Physiology: What it takes to hibernate Cell 125, 161–172 (2006) Chipmunks have helped researchers to crack a tough nut — finding the proteins that control hibernation Previous simulations of galactic evolution proposed that the first stars (called Population III) were more than 100 times as massive as the Sun Prog Researchers in the United States report evidence for p-type doping of indium nitride (InN) Researchers led by Corrie Moreau of Harvard University in Cambridge, Massachusetts, compared corresponding sets of DNA sequences from a huge range of ant species Rev Second, they discovered that levels of hibernation-specific protein complex (HPc), which is known to drop off in the blood at the beginning of hibernation, rose in the brain during the same time Semiconductors: Full of holes? Phys Ser. 305, 59–65; 2005) Something analogous to this process might explain how early life made the transition from a postulated predecessor of RNA to form the ‘RNA world’ Such particles may be useful building blocks for photonic crystals and biomaterials The beauty of it almost took my breath away The first clear sign of the bodys axes was thought to emerge after five days of development and after implantation The material was pumped through the channels of a microfluidic device while pulses of ultraviolet light were shone on to it through a mask defining the desired particle cross-section The protein formed light-gated channels, leading to light-evoked electrical responses in the neurons that are normally insensitive to light The resulting enzyme did not function, but could be evolved to do so with a few mutations The system helps to stop chromosomes being broken during division The team also injected the viral vector into the eyes of genetically blind mice Their patience paid off They found that a signalling system, which they called NoCut, delays abscission until the replicated chromosomes have been pulled apart into the daughter cells and are well clear of the closing membrane They linked this to reduced expression of cheW-1  They made a copy of the ribozyme that had the same sequence of nucleotides, but was instead made of DNA They recorded light-induced responses in the visual cortex as well as the retina, suggesting that the signals can be transmitted to the rest of the brain This is necessary for building devices such as solar cells, long-wavelength lasers and fast transistors, for which InN holds promise This produced flat-sided particles, carried by the flow, at rates of up to 400,000 per hour Weightlessly suspended in the blue waters of the Pacific, I was surrounded by a quiet, gentle drizzle of falling marine snow Yves Barral of the Swiss Federal Institute of Technology ni Zurich and his colleagues studied abscission in budding yeast (pictured right), the process during which the membranes between two nascent daughter cells pinch off
 By modelling laboratory experiments , we test a formulation for magma dynamics and provide an explanation for localized bands of high-porosity and concentrated shear deformation observed in experiments From these lower band angles, we estimate the orientation of melt bands beneath mid-ocean ridges and show that they may enhance magma focusing toward the ridge axis. Here we present new theoretical results with implications for melt focusing beneath mid-ocean ridges How this melt is extracted and focused to the volcanoes, however, remains an unresolved question Lower band angles are predicted for greater strain-rate weakening Our results suggest that the observed band angle results from a balance of porosity-weakening and strain-rate-weakening deformation mechanisms Past theoretical work on this system predicted the emergence of melt bands but at an angle inconsistent with experiments The volcanoes that lie along the Earths tectonic boundaries are fed by melt generated in the mantle These bands emerge and persist at 15°–25° to the plane of shear A fundamental observation of mid-ocean ridges is that the oceanic crust is formed within 10 km of the ridge axis, whereas melt production is believed to occur over a region extending about 100 km from the axis  A power-law form for strain-rate weakening is a commonly accepted constitutive relation for high-temperature creep of mantle materials  Although the increase is due to the rotational effect of advection by simple shear, the rate of increase cannot be fully explained by this rotation Although the instantaneous growth rate of melt bands in Fig. 2a is symmetric about 45°, advection by simple shear affects low- and high-angle bands differently An animation of calculations with n = 6 ( Supplementary movie M1 ) shows reconnection of porosity bands, maintaining the dominance of those at low angle An ensemble of simulations is run, each with the same n but different initial noise, to produce a composite histogram at each time-step As n increases from 1 to 6, the single peak in Sdot; at 45° broadens and divides into symmetric peaks at low (∼15°) and high (∼75°) angle Black curves in Fig. 2c and d show the angle of material lines as they are advected by unperturbed simple shear flow Consistent with the linear analysis, a more nonlinear viscosity (higher n ) results in a lower initial peak band angle Data from experiments are shown by black symbols in Fig. 2c and d and can be directly compared to model results Enhanced shear strain is largest for porosity bands oriented at zero and 90° and goes to zero for 45° bands ( Supplementary Fig Figure 2a shows the effect of changing n on the growth rate of porosity Figure 2a shows the growth rate of melt bands as a function of their angle to the shear plane, θ , and the stress exponent, n  Figure 2b shows that after a strain of γ = 1, bands at low angle have a larger amplitude than those at high angle Figure 2c shows the evolution of the band-angle distribution with increasing strain for n = 6 For a strain-rate-dependent viscosity ( n 1), however, concentrated shear deformation further weakens the bands, allowing them to more easily de-compact under extension For a viscosity that weakens with porosity only, melt bands oriented at 45° grow fastest because they are perpendicular to the direction of maximum extension in simple shear ( equation (2) with n = 1) For example, bands produced in simulations have a smaller aspect ratio and edges that are less sharp than those in experiments For simple shear geometry, Spiegelman showed that bands oriented at 45° to the shear plane will grow fastest, whereas melt bands with angles greater than 90° will decay ( Supplementary Fig Formally, we introduce an infinitesimal plane-wave perturbation (analogous to a melt-rich band) to a constant-porosity system undergoing simple shear and solve for its growth as a function of orientation ( Supplementary Information ) Here we assume : η ( φ ,epsilondot;) = η 0 e α ( φ - φ  0 ) epsilondot; II 1 - n n (1) where η 0 is the shear viscosity at the reference porosity φ  0 and reference strain rate. α = -28 ± 3 is an experimentally derived porosity-weakening coefficient , epsilondot; II is the second invariant of the incompressible component of the strain-rate tensor, and n defines the power-law dependence of viscosity on stress Here we demonstrate that a viscosity that includes both porosity and strain-rate-weakening mechanisms can reproduce the emergence and persistence of melt bands at about 20° to the direction of maximum shear (a difference of 25° from past predictions), as observed in experiments High-angle bands, however, are rapidly rotated away from angles with positive growth rates Histograms of the distribution of band angles are calculated from simulations by taking the two-dimensional fast fourier transform (FFT) of the porosity field and integrating the amplitude response within 5° bins in band angle θ ( Fig. 1d ) However, experiments (and theory for non-newtonian viscosity) suggest that band orientation is rotated 25° from the red line segments and should be most pronounced in regions of high strain However, nonlinear effects in numerical simulations such as band reconnection and realignment might lead to a lower peak band angle at a given n  If melt bands form an interconnected, permeable network with this orientation, they would enhance focusing of melt  In detail, there are differences between experiments and theory In Fig. 2d , the angle corresponding to the peak of each of the histograms increases with strain for all n  In particular, both theory and experiment exhibit the emergence of low-angle melt bands on length scales shorter than the compaction length that persist at low angle and concentrate shear strain In this case, the results for n = 6 are most consistent with the data It is evident that the orientations of melt bands produced in simulations and linear analysis do not track with these trajectories Linear analysis, which tends to give higher peak band angles at a given strain than do simulations (see Fig. 2d ), can be used to extend band-angle evolution to higher strain than that achieved in simulations ( Fig. 2c ) Low-angle bands are rotated slowly and persist in favourable orientations for growth of porosity Magma dynamics theories use continuum equations for conservation of mass, momentum and energy to describe a two-phase system of low-viscosity magma in a deformable, permeable solid matrix and should be applicable to the experiments More work is needed to explore models that use other non-newtonian rheologies and other formulations of magma dynamics  Nevertheless, both experiments and theory suggest that deformation-induced melt bands are a robust feature of partially molten aggregates Our current numerical techniques have not been able to take these simulations to higher strain (see Supplementary Information ) Output from a representative run is shown in Fig. 1b and c  Past theoretical work predicts that melt bands emerge perpendicular to the direction of the maximum rate of extensional strain Past theoretical work showed that a porosity-weakening viscous material undergoing extension is unstable: tension across a weak, high-porosity region leads to low pressure that, in turn, causes convergence of melt flow into that region, raising its porosity and further weakening it Recent experiments demonstrate that partially molten aggregates deformed in simple shear develop localized melt bands of high porosity and enhanced strain ( Fig. 1a ) Red line segments are perpendicular to the axis of maximum extension rate and show the orientation of melt bands expected for a newtonian viscosity, which tend to point away from the ridge axis S1 ) S1 and cos 2 (2 θ ) term in equation (2) ) Such calculations will be challenging but current results give confidence that simulations can be used to predict patterns of melt extraction from the mantle. The amplitude of porosity in the bands at strain γ ( t ) is given by e s ( t )  The balance between favourable orientation for extension (45°) and favourable orientation for concentrating shear (0 and 90°) is controlled by the factor (1 - n )/ n  The evolution of the peak angle is also shown by magenta circles in Fig. 2d , which charts the peak angle for ensembles of simulations with different n  The general agreement between our calculations and experimental results helps to validate magma dynamics theory The growth rate, Sdot;, of porosity bands predicted by this analysis is: Sdot;( θ , n ) = - αξ (1 - φ  0 )sin(2 θ ) 1 + 1 - n n cos 2 (2 θ ) (2) where θ ( t ) is the angle between the melt bands and the shear plane ( Fig. 1a ), which increases with time, t , due to advection by the shear flow The linear analysis suggests that increasing the contribution of strain-rate weakening favours the growth of low-angle melt bands The melt-band-forming instability may contribute to melt focusing, in addition to other mechanisms that have been proposed  The parameter ξ = ( ζ 0 / η 0 + 4/3) -1 depends on the ratio of bulk viscosity to shear viscosity and controls the growth rate of band porosity through the product αξ  The peak of this histogram is initially ∼15° and persists at low angle with increasing strain The simulations are initiated at a constant porosity plus 1% random noise The systematics of band rotation are detailed in Supplementary equation S17  The trajectories that melt bands follow have a lower rate of increase in angle with strain than do the black curves These bands emerge at low angles (∼20°) to the plane of shear for a range of strain rates and stresses, and persist at low angles even after large shear strains These data show that the peak band angle is roughly constant at 15–20° to large strain These differences may result from the specific form of the flow law that we have used These results have implications for magma transport in the mantle, for example beneath mid-ocean ridges These trajectories result from an interplay of the growth of melt bands in favoured orientation and the rotation of bands out of this orientation by simple shear This agreement demonstrates the importance of non-newtonian rheology for modelling deforming, partially molten aggregates This implies some mechanism of melt focusing toward the axis This instability has been predicted to occur at scales smaller than the compaction length , which is the intrinsic length-scale in magma dynamics theory  This pattern-forming instability presents a rare opportunity to test theories of magma transport in the Earths mantle  This prediction results from assuming that the matrix viscosity depends only on porosity and weakens with increasing melt fraction This reorganization is similar to the pumping mechanism proposed by Holtzman et al. , in which fluid flows from bands that have been rotated to higher angles to newly forming bands at lower angles This viscosity is newtonian when n = 1 and is a standard non-newtonian power-law viscosity when n 1 and φ  = 0 Thus two competing processes affect the preferred angle of melt bands To estimate the orientation of bands, we calculate the principal axes of the strain-rate tensor for flow beneath a mid-ocean ridge ( Fig. 3a ) To quantitatively test this conjecture requires large-scale magma dynamics simulations (∼100 km) that include the effects of melt buoyancy and finite strain, with sufficiently fine spatial discretization to resolve features smaller than the compaction length (∼1–10 km)  To understand the effect of the strain-rate dependence of viscosity we extend a previous linear analysis  To validate these results and to explore the behaviour of the full nonlinear system requires computational solutions, which we have performed using the Portable Extensible Toolkit for Scientific computation (see Supplementary Information ) Up to γ ≈ 2, the data are consistent with simulations with n = 4 or 6 With these assumptions, melt bands point towards the ridge axis ( Fig. 3b )
 As a driver for glaciation, Tripati et al . invoke a reduction in the amount of atmospheric CO 2 accompanying the growth of the Himalayas and resulting from enhanced chemical weathering of the rocks unearthed  As in the earliest Oligocene, the isotopic data seem to require the presence of ice sheets on Antarctica at least as thick as those today, and substantial ice sheets in North America (most likely Greenland) By analysing newly acquired core material from the tropical Pacific, Tripati et al . ( page 341 of this issue) provide a much more detailed view of the climate system before the permanent transition to the glacial state Deepening of the CCD is an expected consequence of sea-level fall, because it allows for additional deep-sea carbonate accumulation that compensates for the loss of carbonate deposition from shallow waters  Earth entered its present glacial state 34 million years ago with the growth of the Antarctic ice sheet  From their analyses of accumulation patterns of CaCO 3 on the sea floor, Tripati et al . find signs of substantial perturbations in the oceans carbon cycle during the Eocene, patterns that mimic those of the more permanent change to come Future work on proxy measures of atmospheric CO 2 from the Eocene and Oligocene should provide the necessary test for this hypothesis However, as the equilibrium δ 18 O of the CaCO 3 also depends on temperature, an unambiguous interpretation of ice-sheet size from fossil δ 18 O requires additional temperature information However, the existence of precursor glaciations foreshadowing the major transition to the glacial state is theoretically expected of a system that is subject to natural fluctuations but is gradually evolving from one stable state to another If decreasing atmospheric CO 2 stabilized the glacial state in the Oligocene, might increasing atmospheric CO 2 from fossil-fuel burning destabilize it in the future? The lesson to be learned here is that we should watch for subtle signs that we are moving from the icehouse world in which Earth has remained for 34 million years into a new, greenhouse world. Moreover, compared with sea water, the snow is enriched in the lighter isotope of oxygen, 16 O Moreover, the fidelity of the magnesium content of CaCO 3 as a measure of temperature demands further scrutiny Nevertheless, a general acceptance that glaciations occurred in the middle to late Eocene will probably require further evidence Organisms that precipitate skeletons of calcium carbonate (CaCO 3 ) do so close to oxygen isotopic equilibrium with the waters in which they grow, so the δ 18 O of fossil skeletons provides a proxy measure for ice-sheet size in the past Perhaps the stability of the glacial state increased as atmospheric CO 2 levels fell, so that stochastic effects (such as volcanic eruptions releasing CO 2 , or destabilization of methane embedded in the sea floor), or variations in Earths orbit, became insufficient to jar Earth out of its glacial state ( Fig. 1 ) So these data corroborate the claim that substantial ice sheets existed in the Eocene So, as ice sheets grow, the ratio of 18 O to 16 O in the oceans increases; the ratio is generally presented as the standardized ratio δ 18 O The equatorial Pacific sediments analysed by Tripati et al . are thought to represent oceanographic conditions over a broad region of the Pacific, and the data from the South Atlantic support the proposition that these changes were indeed globally significant The oceanic calcium-carbonate compensation depth (CCD), the depth below which CaCO 3 does not accumulate because deep waters are corrosive, increased significantly during the glacial events The preceding Eocene epoch (55–34 million years ago) is generally considered to have been warm and ice-free, but data on this time interval, as recorded in cores of marine sediments, have been sparse The suggested existence of large Northern Hemisphere ice sheets in the Eocene is highly controversial The temperature proxy indicates that there was little global cooling associated with the late Eocene glaciations, suggesting that, as in the earliest Oligocene event , most of the shift in δ 18 O was due to an increase in ice volume and that cooling may have been limited to high latitudes (or that ice-sheet accumulation there was limited by moisture rather than temperature) The water from which continental ice sheets grow derives from evaporation of ocean water and its deposition at high latitudes as snow They suggest that increased biological productivity in the early Oligocene, and so increased use of CO 2 in photosynthesis, may have provided the additional drawdown of atmospheric CO 2 that was necessary to sustain the glaciation This latter result runs contrary to conventional wisdom, which holds that the Northern Hemisphere glaciation began tens of millions of years later  This major climate transition occurred abruptly and essentially irreversibly at the Eocene–Oligocene boundary, a conclusion based on the record of ice-sheet size preserved in the oxygen isotopic composition of limestones  Thus, as ice sheets grow, sea level falls Tripati et al . use an independent temperature proxy — the amount of magnesium incorporated into CaCO 3 shells — to isolate the effects of changing ice volume What they find there, and in contemporaneous cores from the South Atlantic, is several small glaciations and one major (but transient) glaciation in the middle to late Eocene, millions of years before the Eocene–Oligocene boundary Why the Oligocene Antarctic ice sheet persisted but the Eocene ice sheets did not is unclear
 But the team noticed that the fossils teeth were unusual But we also had to be very thorough,” says Meng Distant relatives of todays flying squirrels probably existed at least 135 million years ago; much earlier than anyone had suspected He was inspecting specimens of mammalian fossils his colleagues had collected a few months earlier in the eastern part of Inner Mongolia His colleagues had initially thought it might be a triconodont, a common Mesozoic mammal In particular, why did gliding behaviour evolve so early in mammalian life? It might also explain the origin of some mysterious teeth fossils that scientists have identified over the years In the process the group also concluded that the animal probably ate insects and was active at night Like many fossil finds, the discovery of these remains was largely a result of good luck. “You never get exactly what you are looking for, so you have to look at everything,” says Meng, who is a curator of palaeontology at the American Museum of Natural History in New York Meng completed his graduate studies at the institute in 1980s and, after moving to the United States, has continued to visit and collaborate with his colleagues there Meng, meanwhile, plans to continue his visits to China two or three times a year, and hopes to stumble across another find. “We will keep looking in the same area,” he says. “I dont know what will show up next.” That is the conclusion of a team of researchers led by Jin Meng, who have found the fossilized remains of a new species of mammal (see page 889 ) Thats exactly what Meng was doing in March when he visited the Institute of Vertebrate Paleontology and Paleoanthropology in Beijing, China The biggest challenge for the researchers was to work out where the new mammal fitted in the evolutionary tree The finding will raise questions about the early evolution of mammals, says Meng The fossil indicates that early in their evolution, mammals, as a group, had very different ways of getting around — some on land, some in water and some gliding from tree to tree The scientists spent the next six months working day and night to characterize their find. “It is a very competitive area, so we had to work as fast as we could The team noticed a squashed skeleton preserved in a split slab sitting on a desk. “It had not caught anyones attention until then,” recalls Meng Their suspicions were confirmed when they examined the fossil under a microscope These can now be re-examined to see if they belonged to an ancient glider They added the animals measurements and properties to a database containing 435 characteristics for each of 58 different mammalian species, including both Mesozoic and current mammals, looking for similarities They could see the outline of a membrane of skin covered in hair, a membrane that was adapted for flight. “It was a big surprise,” says Meng They discovered that their specimen has little in common with any other mammal This led Meng and his colleagues to think they might be looking a new species This suggests that it belongs to its own mammalian order, says Meng, an order that became extinct a long time ago Triconodont teeth have pointed cusps in a straight line, but the specimens teeth had sharper cusps that curved backwards
 A broader assessment of impact geometries and velocities suggests that most giant impacts are bounces, rather than mergers, in which both bodies emerge slightly smaller (and much hotter) amidst a spray of silicates  A more popular view is that Earth and Venus became wet while still accreting, but only because they were struck by cold, wet protoplanets ejected from what is now the asteroid belt ; with modest revision, however, Genda and Abes hypothesis could apply in this context as well An ocean changes everything At some height the air reaches escape velocity, but escape is efficient only if the ground velocity approaches or exceeds the escape velocity  Because they were there, the noble gases provide the best test of their hypothesis But the big problem with gravitational capture of nebular noble gases is the abundance of neon Current fashion posits four stages in the growth of an Earth: coagulation of grains into boulders; gathering of the boulders into aggregates of kilometre dimensions; runaway accretion of those aggregates into Moon-sized protoplanets; and giant collisions between the protoplanets to make planets  Explaining this requires both a heroic theory of selective neon escape and some luck to make the neon:argon ratio always come out the same Genda and Abe stress low-velocity collisions that merge the two protoplanets Genda and Abe therefore argue that most of a planets atmosphere, including its primordial noble gases, is retained in giant impacts Genda and Abe therefore argue that, with an ocean, most of the atmosphere (and most of the noble gas) is lost in giant impacts Genda and Abe use a ruthlessly simplified model to describe how giant impacts interact with atmospheres  Given how quickly stages 1–3 occurred, there is a fair likelihood that significant nebular gas was still present when the protoplanets emerged from runaway accretion Here the impact announces itself when the bow shock erupts through the surface If the nebula was cold enough, and the protoplanets large enough, they would gravitationally capture significant primary atmospheres If you merely wish to bury the argon, there is no limit to how much In a high-speed bouncing impact between unequal planets, the smaller one could easily lose both its crust and its atmosphere In this way, Genda and Abes model can account for Venus having 70 times more argon than Earth Indeed, the entire crust launches into space at high velocity, typically several kilometres per second It applies generally during or before the giant-impact stage of accretion, and it could apply to satellites of the outer Solar System as easily as to Earth. It may work better to start from some other source of noble gases that discriminates against neon — say, extremely low-temperature condensates that quantitatively trap argon (neon freezes only if hydrogen freezes), or noble gas implantation by the solar wind into unaccreted grains and boulders  It need not be restricted to atmospheres of solar composition acquired gravitationally; and it need not be restricted to water oceans or even liquid oceans Noble gases are the flotsam of the Solar System Of course there are caveats On page 842 of this issue, Genda and Abe ask whether atmospheres can survive a series of giant impacts, such as the collision with Earth that formed our Moon On worlds nearer the Sun, water evaporates into a thick atmosphere, whereas on more distant worlds it condenses as oceans and ice sheets Perhaps it is a measure of our theories that every newly probed atmosphere has surprised us Such high ground velocities are difficult to achieve if the planet itself survives; the highest ground motions achieved in successful Moon-forming impact simulations (a relatively gentle event) are typically less than half the escape velocity  The answers are ambiguous, with argon agreeable but neon cryptic The argument that oceans speed the loss of atmospheres is more broadly applicable than the authors imply The authors take the minority view that bound water was common to all the building blocks of Earth and Venus, so that from the start the protoplanets each had their own oceans and atmospheres, and independent lives as infant Earths The crust drives a shock wave into the atmosphere that accelerates as it rises into thinner air The first three stages are thought to have taken no more than a million years in total, whereas the fourth played out over tens of millions of years or more The neon:argon ratio on Venus, Earth, Mars and meteorites is invariably about 1% of what it is in the Sun  The new work offers a fresh look at planetary accretion The resulting explosion of supercharged steam accelerates most of the overlying atmosphere to escape velocity and beyond (Fig. 2 in the supplementary information ) Their concern is with the hemisphere that is not hit directly They accept as a matter of course that much of the stricken hemisphere is lost, driven off by hydrodynamic jetting or the tangential momentum of a glancing blow They seem simple: they shun chemistry, they are difficult to freeze, and they accumulate in atmospheres To distinguish between Earth and Venus, Genda and Abe invoke the runaway greenhouse effect  We see them as passive tracers of our cosmogonic theories, especially theories that address the origin and evolution of planetary volatiles When the crust hits the ocean, the ocean is driven outward at an even higher velocity and it is also vaporized When the nebula disappeared, the protoplanets would retain some of these atmospheres and thereby acquire noble gases from the solar nebula With oceans, the building blocks of Earth lost much more of their primary atmospheres than did the building blocks of Venus Yet the temptation to read profound meaning into noble-gas abundances remains strong
 But this would only account for a small fraction of the total energy budget, and therefore additional processes probably contributed to slip weakening during earthquake rupture. Fracture energy has been estimated from seismological and experimental rock deformation data , yet its magnitude, mechanisms of rupture surface formation and processes leading to slip weakening are not well defined  Fracture energy is a form of latent heat required to create an earthquake rupture surface and is related to parameters governing rupture propagation and processes of slip weakening  Here we quantify structural observations of the Punchbowl fault, a large-displacement exhumed fault in the San Andreas fault system, and show that the energy required to create the fracture surface area in the fault is about 300 times greater than seismological estimates would predict for a single large earthquake If fracture energy is attributed entirely to the production of fracture surfaces, then all of the fracture surface area in the Punchbowl fault could have been produced by earthquake displacements totalling 1 km Accordingly, we use structural observations of the Punchbowl fault zone to quantify the total fracture surface area, S T , which includes the surface area of cataclastic particles in the ultracataclasite, S UC , the surface area of gouge particles in subsidiary faults of the damage zone, S SF , and the surface area of microfractures in the damage zone, S MF ( Fig. 2 ) As an example, if 50% of the ultracataclasite in the millimetres-thick principal slip surface was refractured during an earthquake, and the energy to refracture a grain boundary is half of that required to fracture an intact grain, then fracture surface energy for a single earthquake increases to approximately 5 × 10 5  J m -2  Assuming the free-surface energy to be 1 J m -2 , and that the geometric surface area should be increased by about a factor of five to account for non-spherical grain shapes and finer-scale roughness , brings the total fracture surface energy to 7 × 10 8  J per unit fault area Assuming the orientation of subsidiary faults is isotropic, such that the surface area is twice P L (ref. 28 ), integrating over the damage zone, and using scaling relations for fault thickness and particle size, we calculate a value for S SF of 3.3 × 10 6  m 2 per unit area of the fault surface Because some proportion of fracture surface area must be produced during sliding at residual friction , additional processes such as lubrication, flash heating, and thermal pressurization probably contribute to the breakdown in strength  Currently, the details of energy partitioning, the magnitude of each energy term, and whether η R varies with earthquake magnitude and tectonic setting are not well known  Deformation is dominantly brittle and the fault is exhumed to a depth of 2–4 km (ref. 11 ) E G describes the flow of energy at rupture tips that is required to form a rupture surface and produce a breakdown in strength ( Fig. 1 ) E H , often considered a large component of the total energy budget, does not directly influence earthquake rupture dynamics, whereas the relative magnitude of E R to E G , expressed by radiation efficiency η R = E R /( E R + E G ), plays a fundamental role  Experiments show that G for shear fracture of intact rock under pressures up to 470 MPa is greater than that for tensile cracking, and that G increases with normal stress and roughness for frictional slip  Faults typically are metres in length, 1 mm thick and display centimetre offsets Faults up to 1–2 cm thick, with 1–2-m offsets, are also present ( Fig. 4 ) For a tensile fracture in brittle material, G is nearly equivalent to the free-surface energy of the fracture  For small E G ( η R = 1), an earthquake rupture is considered very brittle, rupture speed is rapid, and growth is favoured For the entire damage zone, we assume N ( L ) = cL - a , where L is fault length, N ( L ) is the number of faults for each length bin, a = 1 and c = 2,500, the ratio of fault displacement to length is 0.01, and the ratio of thickness to displacement is 0.005 Fracture surface energy of the millimetres-thick principal slip surface is 2 × 10 6  J per unit area of the fault surface If G is attributed entirely to the creation of fracture surface, then the observed damage could be produced by earthquake slip totalling less than 1 km of displacement In so doing, we assume that all fracture damage in the Punchbowl fault zone was produced during seismic slip  In the commonly used slip-weakening model, the elastic strain energy released during an earthquake is partitioned between the fracture energy, E G , the frictional heat, E H , and the energy radiated as seismic waves, E R (refs 10 , 14 ) ( Fig. 1 ) Integrating over the damage zone, assuming microfracture orientations are isotropic, and doubling for the two surfaces of a microfracture, gives a value for S MF of 2.4 × 10 6  m 2 per unit fault area It is essential that this estimate should account for the fracture surface energy in the broad zone of damage bounding a fault, as well as that harboured within the narrow, intensely fragmented core  Linear density, P L , of subsidiary faults in the Punchbowl Formation decreases with the logarithm of distance from the ultracataclasite ( Fig. 4 ) Measurements of particle size in plane section are consistent with N ( D ) = cD - a , where D is particle diameter, N ( D ) is the number of particles for each size bin, and a and c are constants, with a = 2.0 and c = 0.07 ( Fig. 3b ) Numerous models have been proposed that provide a basis for relating the macroscopic energy budget to physical processes of earthquake slip  Our estimate also cannot account for seismologic values of G (about 10 6  J m -2 ; refs 6–8 ) unless we assume that a significant number of healed grain boundaries and ripened grains are refractured in each successive earthquake, and that all fracturing is attributed to the breakdown phase of rupture Our estimate of the energy required to create fracture surfaces during a single earthquake is small ( 1%) relative to estimates of E H / S for the Punchbowl fault at a depth of 2–4 km, which even for a coefficient of friction of 0.2 is about 5 × 10 7  J m -2  Our observations indicate that the upper cut-off is 0.1 mm, and we assume that particles 50 nm in diameter follow the same power-law distribution to a lower cut-off of 1.6 nm Our results are also consistent with previous conclusions that the overall structure of large-displacement faults is established early in faulting history . Particles greater than 10 µm in diameter constitute 28% of the ultracataclasite, the majority of which are fragments of microscopic veins  Some constraints on E G are provided by laboratory estimates of the specific fracture energy, G , defined by G = E G / S , where S is the area of the rupture surface  Some seismologic data suggest that G increases with earthquake size , qualitatively consistent with scaling relations between rupture dimension and extent of associated fracture damage  Subsidiary fault gouge is coarser-grained than the ultracataclasite ( Fig. 3b ), and particles 100–200 µm in diameter comprise 25% of the total volume Subsidiary faults of the damage zone are consistent with scaling relations between number, length, displacement and thickness of brittle faults in crustal rock  The different estimates of fracture surface area created during seismic slip on a mature fault versus that associated with mining-induced ruptures may be explained by extensive fracturing during fault formation and less fracturing associated with slip on an established fault surface The fault records extreme localization of slip similar to other ancient exhumed and active seismic faults  The linear density of microfractures in the Punchbowl Formation decreases with the logarithm of distance from the ultracataclasite to a constant, regional density at approximately 100 m ( Fig. 4 ) The principal slip surface is a layer 1 mm thick of ultracataclasite distinguished by uniform birefringence, contains porphyroclasts of older ultracataclasite that record reworking, and has at least one relatively distinct and planar boundary  The Punchbowl fault is a 200-m-thick zone of fractured rock containing a core several metres thick of sheared cataclasite and ultracataclasite  The Punchbowl fault juxtaposes igneous and metamorphic rocks of the San Gabriel complex and arkosic sandstones of the Punchbowl Formation along a continuous layer of ultracataclasite The smallest (4 to 50 nm) particles imaged are cataclastic particles or euhedral grains produced by syn- and post-faulting reaction The surface area of each component is determined by direct observation of fractures and particle sizes, and scaling relations for particle size and subsidiary fault length, thickness and density The surface area per unit volume of the Punchbowl ultracataclasite is similar to that determined for gouge of the San Andreas fault at Tejon Pass  The total cumulative fracture surface energy of the Punchbowl fault is about 300 times greater than the fracture energy, G , for a single large earthquake The total fracture surface area in the damage zone ( S SF + S MF ) is less than 10% of that in the ultracataclasite layer, giving a total fracture surface area for the entire fault zone, S T , of 1.4 × 10 8  m 2 per unit fault area The total fracture surface area in the ultracataclasite is determined assuming spherical particles with a power-law size distribution The total surface area in the 1-mm-thick principal slip surface is 4.2 × 10 5  m 2 per unit area The ultracataclasite layer is 4 cm to 1 m thick, and displays a relatively planar, continuous surface that served as the principal slip surface during the last several kilometres of displacement  These latter processes are compatible with the microstructure of the Punchbowl fault ultracataclasite , but would not be recorded by fracture surface area These observations may reflect the formation of microfractures and extreme fragmentation associated with the formation of shear surfaces  This estimate is a lower bound because it does not include the energy associated with refracturing healed grain boundaries and comminuted grains enlarged by Ostwald ripening This explanation is consistent with large values of G determined in the laboratory for shear fracture relative to that for frictional sliding  This is in direct contrast to a recent conclusion that the surface energy of gouge constitutes half or more of the earthquake energy budget  This study provides the first quantification of fracture surface area over the entire deformed zone of a mature fault expressed as fracture surface area per unit area (in m 2 ) of the macroscopic fault surface To answer this question, the magnitude of the total free-surface energy of fractures produced during an earthquake rupture must be determined To estimate the energy required to create fracture surfaces during a single earthquake, we divide the total energy by 10,000 large earthquakes (to account for 44 km of total displacement), which yields 7 × 10 4  J m -2 per earthquake Transmission electron microscopy reveals particles of host rock less than 100 nm in diameter ( Fig. 3 ) Using a mean layer thickness of 0.3 m and the ratio of surface area to volume for spheres (3/ r ), gives a S UC of 1.3 × 10 8  m 2 per unit area of the fault surface We assume particle size distributions fit N ( D ) = cD - a with constants a = 2.0 and c = 0.15, and have an upper cut-off of 200 µm and lower cut-off of 0.8 µm We use S T to calculate the total fracture surface energy and relate this to the G of an earthquake Yet whether other processes, such as fluid pressurization or melt lubrication, also contribute to rupture formation and the breakdown in strength is still unknown 
 Conversely, FDA-approved DHPs fail to elicit robust phenotypes, making nemadipine-A a unique tool to screen for genetic interactions with this important class of drugs Finally, we demonstrate the utility of nemadipine-A by using it to reveal redundancy among three calcium channels in the egg-laying circuit Here we show that Caenorhabditis elegans can provide a platform for both the discovery of new bioactive compounds and target identification However, a major bottleneck in generating useful small-molecule tools is target identification Nemadipine-A resembles a class of widely prescribed anti-hypertension drugs called the 1,4-dihydropyridines (DHPs) that antagonize the α 1 -subunit of L-type calcium channels  One compound that we named nemadipine-A induces marked defects in morphology and egg-laying Our study demonstrates that C. elegans enables rapid identification of new small-molecule tools and their targets. Small-molecule inhibitors of protein function are powerful tools for biological analysis and can lead to the development of new drugs Through a genetic suppressor screen, we identified egl-19 as the sole candidate target of nemadipine-A, a conclusion that is supported by several additional lines of evidence. egl-19 encodes the only L-type calcium channel α 1 -subunit in the C. elegans genome  We screened 14,100 small molecules for bioactivity in wild-type worms and identified 308 compounds that induce a variety of phenotypes We show that nemadipine-A can also antagonize vertebrate L-type calcium channels, demonstrating that worms and vertebrates share the orthologous protein target A day after seeding the wells with E. coli , two wild-type third larval stage N2 worms were deposited into each well using a COPAS BIOSORT worm sorter ( Union Biometrica ) A second method to measure DHP accumulation in worms gave qualitatively similar results ( Supplementary Information ) All primer sequences for mapping, archived pictures and worm strains are available on request. Another 24 h later, the young L1 and L2 animals were scored for morphological defects Approximately 24 h later, pictures were taken of individual adults at 20 × magnification and the length of the animal was measured using Openlab software ( Improvision, Inc. ) Because N2 worms grow slowly on nemadipine-A, the wells were screened 6 to 7 days later for growth that obviously exceeded N2-containing wells Determination of drug concentration within worms The accumulation of the small molecules within N2 wild-type worms was measured by growing synchronized hatchlings for two days at 20 °C (ref. 27 ) Each experiment was done in quadruplicate Each experiment was done in quadruplicate Each experiment was done in triplicate For population growth assays, wells were seeded with two L3 worms Four days later, eight or twelve L3- or L4-staged F 1 larvae were deposited into each well of 24-well MYOB plates containing 10 or 12.5 µM nemadipine-A using the COPAS sorter From 3–7 days after depositing the L3 parents, each well was photographed each day with either a Leica MZ7.5 and a PL-A661 PixeLINK camera or HiDI Methods Small-molecule screen We identified 308 bioactive molecules by screening a total of four libraries of small molecules in duplicate from Chembridge Corp. ( Diverset , 10,000 molecules), Microsource ( Spectrum , 2,000 molecules), Sigma ( LOPAC , 1,250 molecules) and Maybridge ( Hits Kit , 1,000 molecules) Nemadipine suppressor screen, mapping and mutation identification To screen for mutations that suppress nemadipine-A-induced defects, a mixed-stage population of wild-type N2 worms was mutagenized as previously described  Of the 16 strains that showed consistent suppression, we were able to homozygose five quickly Phenotypic analysis Vab and Egl assays were done by growing mixed-stage populations of worms on plates containing compounds at the desired concentrations or DMSO control See Supplementary Information for additional protocols See Supplementary Information for mapping details The adults were then counted from the pictures The Egl assay was done in the same manner as the Vab assay except that 24 h after transfer to a new plate with drug, the non-Egl and Egl adults were counted The final concentration of each compound in each well was 25 µM assuming the molecules diffused throughout the media The fourth larval stage worms were harvested, rinsed at least twice, and then dispensed into aliquots of 50 µl of packed worms (∼7,700 worms) The number of embryos in utero was counted in the same animals used for length measurements with a Leica MZFLIII microscope at ∼80 × magnification The pharmacological analysis of the egg-laying circuit was done as previously described and is presented in more detail in Supplementary Information  The progeny of faster-growing clones were tested for homozygosity The samples were then frozen at -20 °C for later processing by HPLC The samples were then stored at -20 °C and were later lysed by adding 50 µl of a lysis solution (50 mM KCl, 10 mM Tris pH 8.3, 2.5 mM MgCl 2 , 0.01% gelatin, 0.2% SDS and 60 µg ml -1 proteinase K) and incubated at 60 °C for 60 min with agitation The worms were then incubated at room temperature for 2 h in 1 ml of M9 with 25 µM of the compound, then rinsed 5 times on ice and the supernatant was removed This was done in 24-well plates with 1 ml of MYOB agar substrate and 25 µl of stationary phase OP50 Escherichia coli on the surface of each well Three and four days later, each well was scored independently with both a Leica MZFLIII microscope and from the micrographs generated by a HiDI 1.0 high-throughput digital imager ( Elegenics Inc. ) To ensure that Vab counts did not reflect an accumulation of arrested Vab hatchlings, adults were picked off each plate 24 h later and placed on a new plate containing the same compound or DMSO control and OP50 bacteria To measure the length of worms, ∼100 L4 s were first picked onto an MYOB plate with or without 5 µM nemadipine-A and incubated overnight Twelve worms from these candidate wells were further tested for resistance on 10 or 12.5 µM nemadipine-A All five of the nemadipine-A suppressors harboured missense mutations in conserved regions of egl-19 that form the pore of the channel ( Table 2 and Supplementary Fig. 3 ) Both approaches revealed that only nemadipine-A and felodipine accumulated in worms to a concentration similar to that present in the media ( Table 1 and data not shown) By contrast, a dimethyl ester analogue of felodipine (analogue 6) neither accumulated extensively nor induced a phenotype Conversely, a second voltage-gated calcium channel α 1 -subunit called UNC-2, which is of the N/P/Q-type , is required in the HSNs and/or VCs to negatively regulate egg-laying  Each of these five mutants suppress the Gro, Egl and Vab phenotypes induced by nemadipine-A and are tightly linked to egl-19 ( Table 2 ) Egg-laying by C. elegans occurs when the 16 vulval and uterine muscles contract, thereby opening the vulva and forcing embryos through it Egg-laying defective mutants that cannot produce serotonin will lay their eggs on exposure to exogenous serotonin Egl mutants that produce low levels of serotonin will release their eggs in the presence of exogenous imipramine, a serotonin uptake inhibitor, or exogenous serotonin EGL-19 is probably required in the vulval muscles for both competence and contraction  Finally, nemadipine-A can rescue the defects resulting from EGL-19 hypermorphic activity ( Table 2 ) First, wild-type (N2) worms raised on nemadipine-A phenocopy previously characterized egl-19 loss-of-function mutants  Four additional lines of genetic evidence suggest that EGL-19 is the primary target of nemadipine-A Furthermore, three mutated residues are in regions required for DHP interaction with mammalian L-type channels , and one allele ( tr69 ) alters a residue required for DHP interaction in mammalian systems Having established the nemadipines as unique reagents to antagonize EGL-19 in whole worms, we applied this tool to the analysis of egg-laying in worms High-performance liquid chromatography (HPLC) was used to determine the amount of compound in N2 worms after either a two-hour liquid incubation with the drugs, or after N2 worms were raised on solid substrate containing the antagonists for three days However, Egl mutants whose vulval muscles cannot respond to serotonin or cannot contract do not lay eggs in response to either serotonin or imiprimine . egl-19(ad995) does not lay eggs in response to serotonin or imipramine ( Fig. 4b , c ), consistent with a role for EGL-19 in the vulval muscles  However, only nemadipine-A exhibits robust EGL-19 antagonism in wild-type worms, demonstrating that the structure of nemadipine-A enables both accumulation in worms and robust EGL-19 antagonism In addition, N2 worms grown on nemadipine-A have a Vab phenotype similar to strong hypomorphic alleles of egl-19 ( Fig. 2 )  In contrast, cca-1 mutants grown on 0.1 µM nemadipine-A laid eggs in response to serotonin, but not imipramine In summary, we have screened thousands of small molecules in a broad search for new bioactive compounds that might facilitate the study of C. elegans biology Instead, DHP analogues with 3,5-ethyl esters and halogens in the ortho and meta positions on the phenyl ring both accumulate and achieve robust L-type calcium channel antagonism in C. elegans  Intriguingly, felodipine is most like nemadipine-A in structure and is the only therapeutic DHP that we have investigated that has activity in whole worms t the redundancy of EGL-19, UNC-2 and CCA-1 would not be revealed without the ability to control EGL-19 activity with the nemadipines as the weakest egl-19 hypomorph is already egg-laying defective  Like egl-19 hypomorphs, nemadipine-A-treated worms are Egl ( Fig. 3 ) Like egl-19 hypomorphs, unc-2 mutants grown on 0.1 µM nemadipine-A did not respond significantly to serotonin or imipramine ( Fig. 4 ) Multiple calcium channel types may therefore be required in different cells of the egg-laying circuit for these cells to respond to voltage in a step-wise fashion Nemadipine-A and felodipine also have ester groups in common, but differ in that nemadipine-A has 3,5-diethyl esters, while felodipine has 3-methyl 5-ethyl esters ( Fig. 1 ) Nemadipine-B also induced extensive Egl, Vab and Gro phenotypes, consistent with EGL-19 antagonistic activity (Figs 2 and 3 , and Table 1 ) None of the six FDA-approved DHPs from our libraries induced Egl or Vab phenotypes in our small-molecule screen, including amlodipine, felodipine, nicardipine, nifedipine, nimodipine and nitrendipine; nor did other classes of L-type calcium channel antagonists represented by verapamil, diltiazem and bepridil None of these analogues accumulated extensively or induced phenotype in wild-type worms ( Table 1 ) Only two types of neurons directly synapse with the vulval muscles; the HSNs and the VCs, which also receive synaptic input from the HSNs  Patch-clamp analysis showed that nemadipine-A and nifedipine inhibited L-type calcium channels at approximately the same potency ( Supplementary Fig. 4 ) Previous work has demonstrated that the six FDA-approved DHPs have similar potencies  Second, egl-19 hypomorphs are hypersensitive to nemadipine-A and exhibit the Vab and Gro defects on 10- to 20-fold less nemadipine-A than that required to elicit a phenotype in N2 ( Fig. 2 and Supplementary Fig. 1 ) Serotonin release from the HSNs makes the vulval muscles competent to contract, while acetylcholine release from the HSNs and/or VCs probably triggers vulval muscle depolarization, contraction and egg-laying  Surprisingly, the nemadipines elicited a synthetic Egl phenotype in both mutants ( Fig. 4a ) The egg-laying constitutive phenotype, fecundity defects, and the short phenotype caused by prolonged muscle contraction in egl-19(n2368) and egl-19(ad695) hypermorphs are all rescued by nemadipine-A ( Table 2 , Fig. 3 and data not shown) The egl-19 locus encodes the only L-type calcium channel α 1 -subunit in the C. elegans genome and is so named because reduction-of-function mutants (hypomorphs) are Egl (refs 4 , 10 ) The investigation of one of these bioactive compounds revealed a new L-type calcium channel antagonist that inhibits vertebrate channels and has unique properties that enable channel antagonism in whole worms The nemadipines are reagents that now allow genetic investigation into DHP–target interactions in vivo and the identification of other loci that may modify the response to a class of molecules that are used by millions of people. The only other voltage-gated calcium channel α 1 -subunit encoded by the C. elegans genome is CCA-1, which is of the T-type and has a role in pharyngeal pumping  The only phenotype observed with any of these was a mild Gro phenotype induced by felodipine ( Table 1 ) The position of the dichloro groups on nemadipine-B is probably required for EGL-19 antagonism because chloro groups in different positions (analogue 7) enabled accumulation, but induced no phenotype ( Table 1 ) The strong egl-19 gain-of-function allele n2368 (ref. 4 ) shows no Vab or Egl defects on all concentrations of nemadipine-A tested (Figs 2 and 3 ) The synthetic Egl phenotypes were suppressed by the egl-19(ad695) hypermorph, further demonstrating that the interactions depend on EGL-19 hypomorphic activity The weaker egl-19(ad695) hypermorph exhibits Vab and Egl defects in nemadipine-A concentrations that are 10- to 50-fold greater than that which is required to elicit phenotype from N2 animals There are only two other voltage-gated calcium channels in the worm, UNC-2 and CCA-1, and their null phenotypes are inconsistent with either being a target of nemadipine-A These results suggest that EGL-19 functions redundantly with both UNC-2 and CCA-1 to positively regulate egg-laying These results were surprising because previous work demonstrated that both nifedipine and verapamil antagonize EGL-19 in dissected worms  These two molecules also demonstrated activity in the N2 population growth assays Third, egl-19 hypermorphs are resistant to nemadipine-A This analogue, which we renamed nemadipine-B, accumulated in worms to similar levels as nemadipine-A ( P 0.05) ( Fig. 1 and Table 1 ) This demonstrates that multiple halogens on the DHP phenyl group are required for extensive accumulation in worms, which is a likely prerequisite for robust EGL-19 antagonism This high hit rate demonstrates that C. elegans is a suitable model for identification of new bioactive compounds, and is a similar hit rate to that described for other whole-organism screens  This redundant role for EGL-19 is consistent with previous reports of neuronal egl-19 expression  This suggests that CCA-1 and EGL-19 function redundantly in the release of serotonin This suggests that nemadipine-A activity in whole worms does not result from a more potent target-interaction relative to other DHPs This suggests that the tr69 and tr71 mutations disrupt nemadipine-A interaction with EGL-19 and do not simply upregulate channel activity This suggests that their shared poly-halogenated phenyl groups and/or ethyl ester substitutions may be responsible for efficacy in worms To determine if EGL-19 has redundant roles in egg-laying, we tested if unc-2 and cca-1 null mutants retain eggs in low concentrations of nemadipine To explore the utility of C. elegans for target identification, we focused on one compound that we named nemadipine-A, which induces slow population growth defects ( Fig. 1 , Table 1 and Supplementary Fig. 1 ), called a Gro phenotype, dramatic defects in morphology ( Fig. 2 ), called a variable abnormal or Vab phenotype , and egg-laying defects ( Fig. 3 ), called an Egl phenotype To identify candidate targets of nemadipine-A, we screened 180,000 randomly mutated wild-type genomes for dominant genetic suppressors of the nemadipine-A-induced Gro phenotype To identify new small-molecule tools for the biological analysis of C. elegans , we screened 14,100 small membrane-permeable compounds for the induction of defects in wild-type worms To investigate why nemadipine-A can antagonize EGL-19 in whole-worm assays better than other DHPs, we first explored the possibility that nemadipine-A is a relatively potent inhibitor of L-type calcium channels in general Together with the fact that all of the characterized nemadipine suppressors are mutations in egl-19 , these results strongly suggest that EGL-19 is a target of nemadipine-A Together with the facts that nemadipine-A is a DHP and that EGL-19 is an L-type calcium channel , these four additional lines of evidence strongly suggest that EGL-19 is the primary target of nemadipine-A Together, our structure–activity analysis demonstrates that multiple halogens on the DHP phenyl ring and at least one ethyl ester are critical for extensive DHP accumulation in worms, but is insufficient for robust EGL-19 antagonism in vivo  Unlike the previously characterized egl-19 hypermorphs , two of the egl-19 suppressors ( tr69 , tr71 ) have no hypermorphic activity as they do not lay eggs constitutively and are not short ( Table 2 ) We asked if EGL-19 has redundant roles in egg-laying by compromising EGL-19 function with nemadipine in the background of other voltage-gated calcium channel mutants We compared the ability of nemadipine-A and nifedipine to directly inhibit vertebrate L-type calcium channels in chick ciliary neurons  We identified 308 compounds that induced a variety of phenotypes including slow growth, lethality, uncoordinated movement and morphological defects ( Supplementary Tables 1 and 2 ) We isolated 16 suppressors, five of which we made homozygous and characterized further We next investigated DHP structure–activity relationships to determine which substructures enable accumulation in worms and EGL-19 antagonism We next investigated the nature of the synthetic egg-laying phenotypes We speculate that the increase in egg-laying by unc-2(e55) mutants (grown without nemadipine) in imipramine but not serotonin is a result of increased excitability of the vulval muscles caused by imipramine antagonism of the EGL-2 potassium channel  We then tested the hypothesis that different DHP activity in whole worms results from differences in their accumulation in worms We therefore examined analogues of nemadipine-A that either lacked fluorines or had a single fluorine on the phenyl group (analogues 1–4) We therefore tested the hypothesis that the symmetrical ethyl esters of nemadipine-A confers robust EGL-19 antagonism by examining a 3,5-ethyl ester analogue of felodipine Wild-type worms cannot survive on high concentrations of nemadipine-A, consistent with the essential role of EGL-19 (ref. 4 ) ( Supplementary Fig. 1 )
 A course costs between US$10 and $30, but national stockpilers have negotiated prices in the lower range Although such reactions are rare, they would be highly unwelcome in the already panicky atmosphere of a flu pandemic And demand for Tamiflu could exacerbate the problem And given the poor infrastructure in many of the Asian countries in which a pandemic virus is most likely to arise, such measures might prove hard to implement in practice And the problem, for those trying to work out how to organize the first line of defence, is that politicians are averse to spending large sums of money when they dont know the odds — or even whether theyll still be in post when the bet comes in. Animal models could be used to investigate the use of Tamiflu in drug combinations, which may help avoid any problems with resistance Animal studies would also help, but this has similarly not yet been made an official priority Before embarking on an effort to persuade sceptical governments to invest in such a plan, says Stöhr, there has to be much more confidence in the possibility that it could be made to work Britain, which is among the best-prepared countries, has ordered enough for about 25% of its population; Canada has stocks for just over 5% of its people; the United States currently cannot even cover 1% But both neuraminidase inhibitors have so far generated few problems with drug resistance: mutations in the flu virus that confer resistance seem rare, and generally seem to weaken it . (But an H5N1 virus sample from one Vietnamese patient has recently been shown to be less susceptible to Tamiflu, so experts are not complacent.) Side effects are also mild, and the drugs can be kept on the shelf for at least ten years without losing their activity But defining these people, and matching their number to the doses available, is difficult But even after Roches moves to boost Tamiflu production, experts say that global stockpiles are woefully inadequate But in the past year or so, Roche has quadrupled its Tamiflu production capacity But Longinis model depends on assumptions about transmissibility and initial death rate that may prove to be wrong But the biggest challenge to any plan is the intrinsic biological uncertainty: just how nasty will a pandemic virus be? “We have so many unknowns — about how many people of what age groups would get ill, just how ill they would get, just how fast the virus would transmit — so it is hard to be firm about the best strategy for prioritizing treatment groups,” Hayden says Canada, wary of the potential for a public backlash if health workers were perceived to be saving their own skins, included an ethicist on its Pandemic Influenza Committee Experts agree that Tamiflu is the best of the four currently available anti-influenza drugs Fair treatment? Indeed, the potential for social unrest is a major concern for those laying pandemic plans Finally, experts urge that the few new candidate drugs coming up should be given serious consideration, even if they dont seem ideal Flu is a fact of life, and doctors have been advising aspirin, hot lemon and bed-rest for generations For example, peramivir, another neuraminidase inhibitor was developed by BioCryst Pharmaceuticals of Birmingham, Alabama, but abandoned because it has to be injected For example, Tamiflu is not licensed for infants under one year old, because of the ethical difficulties of running trials in very young children — yet this age group proved exceptionally vulnerable in the severe pandemic of 1918 For most developing countries, meanwhile, creating a national stockpile would simply break the bank Given the difficulty of rapidly producing an effective vaccine (see page 404 ), drugs will be the first line of defence Historically, the WHO has found it hard to persuade even rich countries to produce a pandemic plan: many governments have proved reluctant to pay for a stock of drugs that may not be used during their terms of office Home guard Although the pandemic will be global, defence plans are so far strictly national How many deaths could antiviral drugs prevent? To what extent would they slow the spread of a pandemic? Could they, as some mathematical modellers claim, even stamp out the disease as it emerges? “There is a lot of uncertainty, but that is no reason not to plan their use,” says Marc Lipsitch, an infectious-disease epidemiologist at the Harvard School of Public Health in Boston If taken within 48 hours of the onset of symptoms — the earlier, the better — they reduce the duration of symptoms by at least a day  In addition to encouraging stockpiling, experts are trying to find other ways of driving up the supply of antiviral drugs In most countries they continue to do so, reserving the drug for vulnerable groups such as the elderly In practice, a significant proportion of supplies might be used for prophylaxis of health-care workers — for up to two months as the influenza wave passes through — leaving less for treating the sick. “It is not a happy situation,” says Klaus Stöhr, the WHOs chief influenza expert In unpublished work, Ira Longini, a biostatistician at Emory University in Atlanta, Georgia, has calculated that about 120,000 courses of Tamiflu, if deployed rapidly to treat the sick and protect their families — and if combined with strict quarantine of their houses — could even nip a pandemic in the bud at its point of origin Its important for patients to be hit with the drug early, he says, but doctors may accept this only through clinical experience Most are still very sketchy, but include strategies for stockpiling antiviral drugs Most countries are aiming to keep the death toll as low as possible, but for others, maintaining the economy may be at least as high a priority Most of the rest is used in the United States, with only 3% being prescribed in the rest of the world. “It would be very good for physicians in these other countries to have experience with the drug before a pandemic arrives, so that they learn how best to treat patients,” agrees Hayden Nevertheless, its very long half-life in the body means that it needs to be given only once or twice a week and so might be useful prophylactically Now is the time to begin investigating the merits of using both major classes of anti-flu drugs together, says Hayden Of course, the larger the stockpiles, the easier the choices will be Once a pandemic breaks out, it will be too late Only a handful of nations, including Britain and Canada — but notably not the United States — have given their plans legal status Only now that the alarm bells are ringing about the H5N1 avian flu virus have official minds been focused Other countries should follow the example of Japan, which consumes three-quarters of the Tamiflu prescribed each year, he argues Pandemic planners are considering stockpiling amantadine and rimantadine as back-ups, despite their disadvantages, because they are cheap and were shown to have some prophylactic activity in the milder 1968 pandemic  Pharmacologists also want more biological data on patients who are treated with Tamiflu after being infected with the H5N1 virus now circulating in Asia Relenza is less helpful because it has to be taken by inhaler, which is not very practical if a patients breathing is impaired Roche has promised not to profiteer by hiking prices during a pandemic, but it is not simply a question of money Roche is also making the powdered active ingredient available at a cheaper price than tablets So some public-health experts are calling for an international supply of Tamiflu that could be deployed by the WHO when a pandemic threatens So the definition of essential workers will vary Stöhr thinks the idea of ring-fencing outbreaks in this way is “well worth investigating” Tamiflu, and the chemically related zanamivir, marketed by GlaxoSmithKline as Relenza, belong to a class of drugs called neuraminidase inhibitors Thanks mostly to prodding by the World Health Organization (WHO), about 50 countries have drawn up pandemic-preparedness plans That should be good news if the same applies to a pandemic strain, as patients who cough less will spread the virus less effectively The firm has no spare production capacity and batches take up to a year to make The older, off-patent drugs amantadine and rimantadine belong to a different class and interfere with a viral protein called M2, which stops the virus from entering its target cells The pharmaceutical company Roche didnt have huge commercial expectations for its influenza drug oseltamivir when it was licensed under the brand name Tamiflu in 1999 The powder would be dissolved in water and drunk when needed — nasty-tasting but still effective, and stable in solution for several days The reason: developed countries are now stockpiling the drug against the threat of a pandemic flu virus that could arise at any time The WHO recommends that antiviral drugs should be available for the early treatment and prophylaxis of “those groups at highest risk of infection” and “essential workers” The wider use of antivirals during annual flu epidemics would also stimulate companies to develop new drugs They also limit the severity of symptoms in non-pandemic flu: patients succumb less frequently to acute bronchitis or pneumonia  They argue strongly, for example, for the wider prescription of antivirals against non-pandemic influenza. “This would allow companies to increase their routine manufacturing capacity without fear of losing money,” says Stöhr They complain that not enough is being done to gather these data from the relatively few patients who have so far been given the drug They do not eliminate the virus, but they reduce its release from infected cells by blocking a key viral enzyme They seem to be as clinically effective as the neuraminidase inhibitors, but resistance arises very rapidly and the drugs can have disturbing side effects, including psychotic episodes This is currently not a priority for the pharmaceutical industry because the market is too small This is why the WHO is using all its persuasive powers to get governments to place orders now This will help them optimize dosing regimes Those deemed non-essential will be able to do little but don a protective face mask — which provides no guarantee of safety (see ‘Masking our ignorance’ ) Ultimately, how you define your strategy depends on what you want to achieve, says clinical virologist Fred Hayden of the University of Virginia in Charlottesville Uncertainty, unfortunately, is the name of the pandemic flu game Unknown quantity There is still of plenty of work to be done to further our understanding of Tamiflus pharmacology. “There are gaps in our knowledge that we need to fill so that physicians can use it more effectively in a pandemic,” says Hayden Whats more, no one knows for sure the answers to several key questions Who will, and who will not, be treated with this scarce but valuable resource? “Its not easy — we know there wont be enough for everyone,” says Theresa Tam of the Public Health Agency of Canada Worryingly, the list of relatively well-prepared nations includes few of those countries in Asia where a pandemic strain is most likely to emerge
 Protein kinases are enzymes that are important for controlling cellular growth and invasion , and their malfunction is implicated in the development of some tumours The discovery of this mutational activation of a key cell-signalling pathway may provide new targets for therapeutic intervention. We analysed human colorectal cancers for genetic mutations in 340 serine/threonine kinases and found mutations in eight genes, including in three members of the phosphatidylinositol-3-OH kinase (PI(3)K) pathway A total of 23 changes, including 20 non-synonymous point mutations, one insertion and one splice-site alteration, were identified (see supplementary information ) Also, targeting the downstream genes PDK1 or AKT2 could be effective against the much larger fraction of tumours that contain mutations in PIK3CA or PTEN. Although genetic alterations in tyrosine kinases have previously been firmly implicated in tumorigenesis, only a few serine/threonine kinases (STKs) are known to be mutated in human cancers  Any observed changes were evaluated against DNA from patient-matched normal tissue to identify somatic (tumour-specific) mutations As the catalytic domains of these genes are most likely to harbour mutations that activate the gene product , we focused on stretches (exons) containing the kinase domains Eighteen of the 23 somatic mutations occurred at evolutionarily conserved residues MKK4/JNKK1 is altered in a variety of tumour types , but no mutations in any of the other genes have previously been found in colorectal cancers Overall, nearly 40% of colorectal tumours had alterations in one of eight PI(3)K-pathway genes: as most of these encode protein kinases, they could serve as sites for therapeutic intervention Quantitative PCR analysis of 146 colorectal tumours showed co-amplification of AKT2 and PAK4 on chromosome 19q13.2 in two samples, which we confirmed by digital karyotyping and fluorescent in situ hybridization (see supplementary information ) The entire coding regions of those genes found to contain mutations were then further evaluated in a larger panel of 180 colorectal tumours The gene mutations affected eight different proteins: six were in mitogen-activated protein-kinase kinase-4 (MKK4/JNKK1), six in myosin light-chain kinase-2 (MYLK2), three in phosphoinositide-dependent protein kinase-1 (PDK1, of which two mutations affect the same residue in the kinase domain), two in p21-activated kinase 4 (PAK4), two in v- akt murine thymoma viral oncogene homologue-2 kinase (AKT2), and two in MAP/microtubule affinity-regulating kinase-3 (MARK3); there was one alteration in cell-division cycle-7 kinase (CDC7) and another in a hypothetical casein kinase (PDIK1L) These exons were amplified by using polymerase chain reaction (PCR) on template DNA derived from 24 colorectal cancers and were then sequenced directly Three of the altered genes, PDK1 , AKT2 and PAK4 , encode proteins involved in the PI(3)K signalling pathway ( Fig. 1 ), and two of these ( AKT2 and PAK4 ) are overexpressed in human cancers  We also evaluated other non-STK members of the PI(3)K pathway in the same 146 samples ( Fig. 1 , and see supplementary information ) and found one mutation in the insulin-related receptor INSRR, one in the v-Erb-B erythroblastic leukaemia viral oncogene homologue ERBB4, seven in the phosphatase-and-tensin homologue PTEN, and three cases of amplification of the insulin-receptor substrate IRS2 (see supplementary information ) We selected 340 genes encoding STKs from the human genome and analysed them for mutations in tumours from colorectal cancer patients (for details, see supplementary information ) We tested whether any of the three kinases could have been altered by amplification, another mechanism for kinase activation When these alterations are compared with those previously discovered in the phosphoinositide-3-kinase p110α catalytic subunit PIK3CA (ref. 10 ), their distribution is striking: all but two of the 58 alterations were in different tumours ( P =0.02, ξ 2 test), indicating that the mutated genes probably have equivalent tumorigenic effects and are operating through the same pathway
 Chromatin immunoprecipitation analyses demonstrate that androgen receptor and LSD1 form chromatin-associated complexes in a ligand-dependent manner Conversely, knockdown of LSD1 protein levels abrogates androgen-induced transcriptional activation and cell proliferation Furthermore, we identify pargyline as an inhibitor of LSD1 Gene activation and repression is specifically regulated by histone methylation status at distinct lysine residues  Gene regulation in eukaryotes requires the coordinate interaction of chromatin-modulating proteins with specific transcription factors such as the androgen receptor  Here we show that lysine-specific demethylase 1 (LSD1; also known as BHC110) co-localizes with the androgen receptor in normal human prostate and prostate tumour Here, we link demethylation of a repressive histone mark with androgen-receptor-dependent gene activation, thus providing a mechanism by which demethylases control specific gene expression. LSD1 interacts with androgen receptor in vitro and in vivo , and stimulates androgen-receptor-dependent transcription LSD1 relieves repressive histone marks by demethylation of histone H3 at lysine 9 (H3-K9), thereby leading to de-repression of androgen receptor target genes Pargyline blocks demethylation of H3-K9 by LSD1 and consequently androgen-receptor-dependent transcription Thus, modulation of LSD1 activity offers a new strategy to regulate androgen receptor functions All experiments were repeated at least five times in duplicate Anti-AR ( N20 , Santa Cruz ) was used Anti-AR 441 ( Santa Cruz ) and anti-LSD1 were used at a dilution of 1:75 and 1:500, rabbit IgG and mouse IgG (1:500; Dako ) were used as secondary antibodies, and immunoreactions were visualized with the ABC complex diluted 1:50 in PBS ( Vectastain , Vector ) Cell culture and transfections 293 and CV-1 cells were cultured and transfected as described  Cell proliferation assay pLV-THM-control and pLV-THM-LSD1 were used to produce recombinant lentiviruses to infect LNCaP cells as described  Cells were treated with or without 10 -10  M R1881, 10 -8  M R5020, 10 -9  M E 2 , 10 -7  M T3, 10 -6  M all- trans RA, 3 × 10 -3  M pargyline, 10 -3  M deprenyl, or 10 -4  M chlorgyline for 18 h, as indicated Chemicals were obtained as indicated: pargyline ( Sigma ); deprenyl and chlorgyline ( ICN Biomedicals Inc. ); R1881 , T3 , E 2 , all- trans retinoic acid and R5020 ( Schering AG ) Chromatin immunoprecipitation ChIP experiments were performed essentially as described  Co-immunoprecipitation assays and western blot analyses Experiments were performed essentially as described  Complexes were eluted by incubation with 10 mM dithiothreitol at 37 °C for 30 min, diluted 50 times with dilution buffer followed by a second immunoprecipitation with the indicated antibody Demethylase assay The demethlylation assay was essentially performed as described  Experiments were repeated and analysed three times For PCR, 1–5 µl out of 50 µl DNA extract was used For Re-ChIP assays, immunoprecipitations were sequentially washed with TSE I, TSE II, buffer III (0,25 mM LiCl, 1% NP40, 1% deoxycholate, 1 mM EDTA and 10 mM Tris-HCl pH 8.1) and TE  Immunohistochemistry Polyclonal rabbit anti-LSD1 antibody was generated according to standard procedures Immunoprecipitation was performed with specific antibodies (anti-monoMeK9H3, anti-diMeK9H3, anti-triMeK9H3, anti-monoMeK4H3, anti-diMeK4H3, anti-triMeK4H3, anti-monoMeK27H3, anti-diMeK27H3, anti-triMeK27H3, anti-monoMeK20H4, anti-diMeK20H4, anti-triMeK20H4, anti-H3 (all obtained from Upstate Biotechnology), anti-LSD1 and anti-AR PG21 ( Upstate Biotechnology )) on GammaBind-Sepharose 4B ( GE-Healthcare ) Immunoprecipitations from extracts of murine testis were performed in the presence of 1 × 10 -9  M R1881 with anti-LSD1 antibody, anti-cyclin A antibody, or rabbit IgG LNCaP cells were cultured in phenol-red-free RPMI1640 supplemented with 10% double-stripped fetal calf serum (dsFCS) and transfected with Effectene ( Qiagen ) LNCaP cells were transfected 3 days before harvesting for ChIP with or without siRNA ( Qiagen ) following the manufactures instructions LNCaP cells were treated for 18 h with or without pargyline and for 210 min with or without 10 -8  M R1881 as indicated Luciferase activity was assayed as described  Methods Full details of the Methods are given in the Supplementary Information  PCR primers for ARE I + II ( PSA (- 459 to -121)), ARE III ( PSA (- 4288 to -3922)), GAPDH and U6 have been described previously  Primer sequences were as follows: exon 4, PSA (+ 3909 to +4067) 5′-GTGTGTGGACCTCCATGTTATT-3′ and 5′-CCACTCACCTTTCCCCTCAAG-3′; middle, PSA (- 2223 to -1951) 5′-TGGGTTGGGTCAGGTTTTGGTT-3′ and 5′-TCTTCCCCTGTTTCTAGTTGAGTG-3′ Product formation was detected by incorporation of SYBR green I using ROX as a passive reference ( ABgene ) Quantitative PCR was performed in an ABI PRISM 7700 sequence detector  Quantitative RT–PCR and statistical analysis DNaseI-treated RNA isolated using RNAwiz ( Ambion ) was used for reverse transcription Stainings were performed using a protocol for antigen retrieval and indirect immunoperoxidase Statistical analysis for quantitative PCR was performed by group-wise comparison based on PCR efficiencies and the mean crossing point deviation between sample and control group using Relative Expression Software Tool  TAP-tagged proteins were bound to IgG-sepharose, washed and incubated in buffer 1 (50 mM Tris pH 8.5, 50 mM KCl, 5 mM MgCl, 0.5% BSA and 5% glycerol) supplemented with 10 mM ATP, 10 -9  M R1881 with or without 1 × 10 -3  M pargyline and 1 µg of nucleosomes purified from HeLa cells for 6 h at 37 °C Ten per cent of testis extract was loaded as input The cell proliferation Elisa BrdU Colorimetric Assay ( Roche ) was performed according to the manufacturers instructions The experiments were repeated three times in quadruplet The expression ratios of the analysed cDNAs were related to the normalized C p (crossing point) of the housekeeping gene GAPDH in each sample The following amounts per well were used: 500 ng each of MMTV-LUC, ARE 2× -TATA-LUC, ARE 2× -TK-LUC, TK-LUC, TREp-LUC, βRE-LUC, ERE 2× -TATA-LUC, PSA-LUC, Slp-ARU-TATA-LUC; 25 ng expression plasmids for AR, PR, ERα, RARα and TRβ; 500–700 ng expression plasmids for LSD1 1–174, LSD1 175–246, LSD1 247–852, LSD1Δ281–360, LSD1ΔAO, pSUPER-control and pSUPER-LSD1; 100–700 ng expression plasmids for LSD1 were transfected per well The following primers were used: GAPDH 5′-GAAGGTGAAGGTCGGACTC-3′ and 5′-GAAGATGGTGATGGGATTTC-3′; PSA 5′-CACCTGCTCGGGTGATTCTG-3′ and 5′-CCACTTCCGGTAATGCACCA-3′ The infected cells were cultured for 72 h in medium supplemented with 10% dsFCS. 0.3 × 10 4 cells were plated in a 96-well plate with or without 10 -7  M R1881 The reaction mixture was analysed by SDS–PAGE followed by western blotting using antibodies as indicated. Western blots were decorated as indicated As shown exemplarily in Fig. 2b , LSD1 is detected in the epithelium of normal prostate and in tumour cells As shown in glutathione S -transferase (GST) pull-down analyses, full-length LSD1, as well as the SWIRM domain (LSD1 175–246) and the amine oxidase domain (LSD1 247–852) alone, associate with the N terminus (NTD), the DNA-binding domain (DBD) and the ligand-binding domain (LBD) of AR ( Fig. 1b ) Association of LSD1 with the chromatinized PSA promoter is specific because DNA from neither exon 4 of the PSA gene nor the promoters of the GAPDH and U6 genes is enriched ( Fig. 3a ) Because AR induces PSA gene expression we analysed methylation levels of repressive histone marks such as histone 3 at lysine 9 (H3-K9), histone 3 at lysine 27 (H3-K27) and histone 4 at lysine 20 (H4-K20) Because displacement of repressive histone marks by LSD1 increases AR-dependent gene expression, inhibition of LSD1 should reduce AR activity Because LSD1 associates with chromatin and demethylates histone H3 at lysine 4 (H3-K4) in vitro , we verified that LSD1 binds to core histones, histone H3 and the N-terminal tail of histone H3 in vitro ( Supplementary Fig Because LSD1 is an amine oxidase that catalyses demethylation, we tested whether monoamine oxidase inhibitors such as pargyline might block demethylation Both ARE-containing regions were enriched, demonstrating that LSD1 and AR form a ligand-dependent complex on chromatin ( Fig. 3a ) Central to this dynamic organization is the modification of core histones Co-expression of LSD1 and AR results in a strong ligand-dependent activation of a mouse mammary tumour virus (MMTV)-luciferase reporter ( Fig. 4a ), which is not observed with a LSD1 deletion mutant lacking the amine oxidase domain (LSD1ΔAO) or in the absence of either ligand or AR ( Fig. 4a ; see also Supplementary Fig Consequently, monoamine oxidase inhibitors such as pargyline, chlorgyline and deprenyl severely impair LSD1-induced activation of AR ( Fig. 4c ) DNA from a region between the enhancer and promoter was not enriched, thus demonstrating specificity ( Fig. 3a ) Endogenous LSD1 and AR associate specifically in vivo in androgen-sensitive tissues such as testis ( Fig. 1a ) Furthermore, neither LSD1 nor the LSD1 mutants associate with GST, GST–Nix1, GST–RORβ or GST–ERβ-NTD, thus demonstrating specificity of interaction with AR Furthermore, we demonstrate that the amine oxidase domain (LSD1 247–852) of LSD1 suffices to stimulate AR- and ligand-dependent reporter gene activity ( Fig. 4b ; see also Supplementary Fig  anti-AR antibodies ( Fig. 3a ) Histone methylation at specific lysine residues is linked to both transcriptional repression and activation  However, when in complex with AR, LSD1 demethylates the repressing histone marks mono- and dimethyl H3-K9 and thereby promotes gene activation Importantly, these cells also express AR ( Fig. 2b ), showing that LSD1 and AR co-localize In addition, we observed a ligand-dependent decrease in dimethyl H4-K20, whereas mono- and trimethyl H4-K20 and methylation levels of H3-K27 remain unchanged ( Supplementary Fig In contrast, the N terminus of LSD1 (LSD1 1–174) does not interact with AR In LNCaP cells, which express endogenous AR, only androgen-dependent but not unrelated reporters such as TK-LUC are inhibited by pargyline, thus demonstrating specificity ( Supplementary Fig Infection with pLV-THM-LSD1 causes efficient and specific downregulation of endogenous LSD1 but does not affect the level of endogenous AR ( Fig. 4f ) Interestingly, methylation of histone H3-K4 is not altered in the presence of R1881 and not influenced by pargyline in vivo ( Fig. 3b ) LSD1 and AR associate at chromatinized AREs in a ligand-dependent manner, which results in concomitant specific demethylation of the repressive histone marks mono- and dimethyl H3-K9 LSD1 contains a centrally located SWIRM domain, which functions as a putative protein–protein interaction motif, and a carboxy-terminal amine oxidase domain that harbours the demethylase activity ( Fig. 1b ) LSD1 does not affect the transcriptional activity of related steroid hormone receptors, indicating that stimulation of AR is selective ( Supplementary Fig LSD1 has been described as a component of co-repressor complexes , and a recent model proposes that LSD1 represses transcription of genes silenced by Co-REST due to demethylation of the activating histone marks mono- and dimethyl H3-K4 (ref. 3 ) LSD1 knockdown blocks ligand-dependent demethylation of mono- and dimethyl H3-K9 but not that of trimethyl H3-K9 ( Fig. 3c ) LSD1 messenger RNA is ubiquitously expressed in human and murine fetal and adult tissue ( Fig. 2a and data not shown) as a transcript of 3.3 kilobases ( Supplementary Fig LSD1 specifically associates with chromatin on the PSA promoter both in the presence or absence of ligand ( Fig. 3a ) Moreover, quantitative RT–PCR analyses demonstrate that pargyline also blocks the androgen-induced expression of the endogenous PSA gene in LNCaP cells ( Fig. 4d ) Next, we efficiently reduced endogenously expressed LSD1 in LNCaP cells by vector (pSUPER-LSD1)-mediated RNA interference ( Fig. 4e ) Next, we performed transient transfection assays to test whether LSD1 modulates the transcriptional activity of AR Notably, addition of pargyline blocked demethylation of dimethyl H3-K9 by the TAP-tagged LSD1–AR complex ( Fig. 3d ) Of importance is our observation that inhibitors such as pargyline control the demethylase activity of LSD1 and thereby regulate AR Our data demonstrate that AR function is controlled by the demethylase LSD1 Paralleling LSD1 knockdown, a significant ligand-dependent decrease of PSA-LUC reporter gene expression was observed ( Fig. 4e ), whereas expression of the unrelated TK-LUC is not influenced (data not shown) Pargyline blocks demethylation of mono- and dimethyl H3-K9 during androgen-induced transcription, whereas methylation levels of trimethyl H3-K9 and the methylation status of H4-K20 and H3-K27 remain unchanged ( Fig. 3b ; see also Supplementary Fig Pargyline does not influence the activity of other nuclear receptors ( Supplementary Fig S2a ) S2b ) S3 ) S4 ) S4 ) S5 ) S6 ) S6b, c ) S6h ) S6i ) S6j ) S6k ) Stimulation of AR activity by LSD1 is potent in different cell lines, and AR-responsive minimal, synthetic and complex promoters are activated by LSD1 in a ligand-dependent manner ( Supplementary Fig Stimulation of LNCaP cells with R1881 results in androgen-induced transcription and is accompanied by a robust decrease in mono-, di- and trimethyl H3-K9 at the PSA promoter ( Fig. 3b ) Taken together, our data demonstrate that LSD1 is a nuclear protein that co-localizes with AR in androgen-sensitive tissues such as prostate Taken together, these data show the ligand-dependent association of LSD1 and AR on chromatinized AREs at the promoter of the PSA gene, and the specific demethylation of the repressive histone marks mono- and dimethyl H3-K9 Tandem affinity purified (TAP) LSD1 in the presence or absence of AR ( Fig. 3d ) was incubated in the presence of R1881, with HeLa nucleosomes as substrate The amino-terminal tails of histones are subject to various covalent modifications such as acetylation, phosphorylation, ubiquitination and methylation by specific chromatin-modifying enzymes  The amount of total H3 on the PSA promoter is not influenced by LSD1 knockdown ( Fig. 3c ) The methylation status of the trimethyl H3-K9 control is not altered ( Fig. 3d ) The nuclear co-localization of LSD1 and AR was verified further in human LNCaP prostate tumour cells ( Supplementary Fig The TAP-LSD1–AR complex demethylated dimethyl H3-K9 in vitro , whereas TAP-LSD1 or the TAP control failed to do so These results show the physiological importance of LSD1 in the control of androgen-induced gene regulation and cell proliferation Thus, depending on the specific interacting partners, LSD1 action results in either gene silencing or activation Thus, specific modulation of LSD1 activity might be a promising therapeutic target in tissues such as brain, testis and prostate, where AR has a pivotal physiological role. Thus, the in vitro assay demonstrates that the LSD1–AR complex directly and specifically demethylates H3-K9 and demethylation is blocked by pargyline To address whether LSD1 governs androgen-dependent cell growth, we infected LNCaP cells with a lentivirus (pLV-THM-LSD1) expressing siRNA directed against LSD1 To demonstrate that LSD1 and AR form ligand-dependent complexes on chromatinized AREs, agonist-treated LNCaP cells were subjected to sequential chromatin immunoprecipitation (Re-ChIP), first with an anti-AR antibody and next with either anti-LSD1 antibody or rabbit IgG To determine whether LSD1 and AR associate with chromatin in vivo , LNCaP cells treated with or without the synthetic AR agonist R1881 were subjected to chromatin immunoprecipitation (ChIP) To examine the expression pattern of LSD1, we performed northern blot analyses To investigate LSD1 localization in normal prostate and prostate tumours, we used immunohistochemical analyses of 100 prostate cancer biopsies on tissue microarrays To prove that LSD1 executed the ligand-dependent demethylation of mono- and dimethyl H3-K9, we designed various short interfering (si)RNAs directed against LSD1 or an unrelated control ( Supplementary Fig To validate further that a LSD1–AR complex removes H3-K9 dimethyl marks in the presence of R1881 we established a demethylation assay in vitro  Transcriptional regulation by nuclear receptors such as androgen receptor (AR) involves interaction with multiple factors that act in both a sequential and combinatorial manner to reorganize chromatin  Transfection of LNCaP cells leads to efficient and specific downregulation of endogenous LSD1 but does not affect the level of endogenous AR ( Fig. 3c ) We isolated LSD1 (ref. 3 ) by searching for new AR-interacting proteins When compared to cells transduced with the pLV-THM-control virus, androgen-induced proliferation of LNCaP cells is markedly inhibited by pLV-THM-LSD1-mediated LSD1 knockdown ( Fig. 4f )
 Additional genome features include an abundance of tandemly repeated transfer-RNA-containing arrays, which may have a structural function in the genome Analysis of the genome provides new insights into the workings and genome evolution of a major human pathogen. Entamoeba histolytica is an intestinal parasite and the causative agent of amoebiasis, which is a significant source of morbidity and mortality in developing countries  Here we present the genome of E. histolytica , which reveals a variety of metabolic adaptations shared with two other amitochondrial protist pathogens: Giardia lamblia and Trichomonas vaginalis  Phylogenomic analysis identifies evidence for lateral gene transfer of bacterial genes into the E. histolytica genome, the effects of which centre on expanding aspects of E. histolytica s metabolic repertoire The genome encodes a large number of novel receptor kinases and contains expansions of a variety of gene families, including those associated with virulence The presence of these genes and the potential for novel metabolic pathways in E. histolytica may allow for the development of new chemotherapeutic agents These adaptations include reduction or elimination of most mitochondrial metabolic pathways and the use of oxidative stress enzymes generally associated with anaerobic prokaryotes A consensus tree was made from the remaining samples After manual inspection of the alignments, Blast outputs, tree support values and sequence identities, 279 cases of potential LGT were retained for more detailed phylogenetic analyses All scaffolds removed during the clean-up process as well as any singleton reads, although not used in the annotation process, were used in determining the presence or absence of genes in the E. histolytica genome All scaffolds smaller than 2 kb (327) were subsequently removed, leaving 1,425 scaffolds with a combined size of 25,393,225 bp Annotation The Combiner algorithm was used for gene structure identification using two genefinder programs, phat and GlimmerHMM , trained using a set of published E. histolytica gene sequences, alignments of protein homologues to the genomic sequence and alignment of a set of E. histolytica complementary DNA sequences (provided by N As an additional screen for LGT we identified all proteins for which a prokaryote was the top Blast hit As the chromosomes of E. histolytica could not be resolved by pulsed field gel electrophoresis (PFGE) and the A + T content precluded making large or medium insert libraries in bacterial artificial chromosomes (BACs), we were required to use the whole-genome shotgun approach to sequence the genome At the Sanger Institute, 200,000 reads were generated from a pUC18 library with average insert size of 2.5 kb plus 6,500 reads from a BAC library with an average insert size of 10 kb (the high A + T content of the genomic DNA prevented cloning of larger fragments) At TIGR 390,000 reads were produced from a small (1.5–2.0 kb) and a medium insert library (8–10 kb) generated in the pHOS2 vector Because posterior probabilities—the support values used by bayesian analysis to indicate confidence in groups—have been criticized , we also used bootstrapping to provide an additional indication of support for relationships Blast summary statistics, trees and support values for these 96 candidate LGT are provided as Supplementary Information. Each candidate LGT was analysed by MrBayes using the WAG matrix, a gamma correction for site rate variation and a proportion (pinvar) of invariant sites Each data set was bootstrapped (100 replicates) and used to make distance matrices under the same evolutionary model as in the bayesian analysis, using custom (P4) software (available on request) Functional annotations for the predicted proteins were automatically generated using a combination of numerous sources of evidence including searches against a non-redundant protein database and identification of functional domains by searches against the Pfam database . tRNAs were detected using the tRNAscan-SE program with default parameters Genome assembly was carried out at the Sanger Centre using the program phusion  Genomic DNA was prepared from E. histolytica strain HM-1:IMSS ( ATCC number 30459 ) grown axenically in TYI-S-33 medium  Guillén) to the genomic sequence Identification of sequence homologues in other species Sequence homologues from other species were identified by searching the predicted proteins from the E. histolytica genome against the publicly available nr database of GenBank using BlastP ( http://www.ncbi.nlm.nih.gov/BLAST/ ) and filtering search results with an e -value of 10 -5 or less, which was chosen because of the relatively large divergence between E. histolytica and other organisms for which the genomes have been sequenced and for which protein data are available Methods Genome sequencing and assembly The E. histolytica genome sequence was generated by the whole-genome shotgun method On the basis of these analyses we identified 96 genes in which the tree topology is consistent with prokaryote to eukaryote LGT Phylogenetic analysis We modified a published suite of scripts and modules called PyPhy to make an automated genome-wide primary screen for LGT PyPhy was used to make bootstrap (100 replicates) consensus p -distance trees from edited alignments of 5,740 E. histolytica proteins; that is, those for which there were sufficient homologues ( 4) in SwissProt and TrEMBL to make trees Removal of these scaffolds left 888 scaffolds remaining, with a total length of 23,751,783 bp The analyses were run for 600,000 generations and sampled every 100 generations, with the first 2,000 samples discarded as burn-in The average edited read length was 645 bp, giving an approximate 12.5-fold genome coverage The Combiner gene predictions were then manually curated The remaining scaffolds were analysed to remove redundancy that may have resulted as a consequence of allelic differences or aneuploidy The trees were analysed to identify cases where the nearest neighbour to the E. histolytica protein was a prokaryotic sequence To avoid assembly problems, reads containing episomal-derived rDNA or tRNA-containing sequences (170,000 reads (29%)) were excluded from the whole-genome assembly process Trees were made from the distance matrices using FastME and a bootstrap consensus tree made using P4 Unfortunately, there is no map to order the scaffolds generated by the assembly; however, the sequence generated by this project should assist in making maps for this genome in the future, and although the large-scale structure of the genome has been lost, the vast majority of the genes that have been predicted are full length with intact 3′ and 5′ untranslated regions We removed all scaffolds smaller than 5 kb that shared 98% or more nucleotide sequence identity over greater than 95% of their lengths A number of amoebic virulence determinants have been characterized, including a multi-subunit GalGalNAc lectin involved in adhesion to host cells, cysteine proteases that degrade host extracellular matrix, and pore-forming peptides (amoebapores) capable of lysing target cells  A second group of 32 proteins encodes cysteine-rich domains containing CXC repeats Almost 270 putative E. histolytica protein kinases representing members of all seven families of the eukaryotic protein kinase superfamily were identified  Although no immediate downstream effectors to the amoebic receptor kinases could be identified, E. histolytica contains greater than 100 protein phosphatases, which dephosphorylate proteins An atrophic, mitochondrion-derived organelle has been identified in E. histolytica , and the genome data support the absence of a mitochondrial genome An unusual feature of some of the phosphatases is the presence of varying numbers of leucine-rich repeat (LRR) domains that are involved primarily in protein–protein interactions and have not previously been associated with phosphatases Analysis of the genome reveals redundancy in the genes encoding these virulence factors As a first insight into an amitochondrial protist genome, analysis of these data and particularly the bacterial-like proteins contained therein should illuminate future efforts aimed at the development of diagnostics and therapeutics of these luminal parasites. As a phagocytic resident of the human gut, E. histolytica has access to many bacterial and host-derived preformed organic compounds Comprising almost 10% of the sequence reads, 25 types of long tandem array, each containing between one and five tRNA types per repeat unit, could be identified from the genome data Despite a lack of representative genome sampling from amitochondrial protist lineages it is already clear that these unrelated anaerobic eukaryotes seem to use convergent metabolic strategies imposed by their environments E. histolytica also has five members of a fatty acid elongase family, previously identified only in plants, green algae and G. lamblia  E. histolytica chromosomes do not condense, and the uncertainty surrounding its ploidy and the extensive length variability observed between homologous chromosomes from different isolates makes the exact chromosome number difficult to determine E. histolytica feed on bacteria in the lumen of the colon and lyse host epithelial cells after invasion of the intestinal wall  E. histolytica has four copies of flavoprotein A, which detoxifies nitric oxide and/or oxygen ( Fig. 3 ), and also contains rubrerythrin, which in anaerobic bacteria is protective against intracellular hydrogen peroxide ( Fig. 3 ) E. histolytica is an obligate fermenter, using bacterial-like fermentation enzymes and lacking proteins of the tricarboxylic acid cycle and mitochondrial electron transport chain E. histolytica is the first amoeba genome to be fully sampled, and comparisons with other genomes will assist in resolving fundamental issues relating to eukaryote and amoeba phylogeny, as well as how LGT affects eukaryotes E. histolytica is unable to synthesize fatty acids but retains the ability to synthesize a variety of phospholipids E. histolytica lacks de novo purine, pyrimidine and thymidylate synthesis and must rely on salvage pathways, similar to G. lamblia and T. vaginalis  E. histolytica lacks morphologically identifiable rough endoplasmic reticulum and the Golgi apparatus but encodes the basic elements of the vesicle transport machinery common to other eukaryotic cells, with the coat complexes COPI, COPII, clathrin and retromer all being present E. histolytica uses a complex mix of signal transduction systems in order to sense and interact with the different environments it encounters ( Fig. 2 ) Finally, E. histolytica has numerous cytosolic proteins involved in signal transduction, including Ras-family proteins, EF-hand calcium-binding proteins, phosphatidylinositol-3-OH kinase and MAP kinases Five proteins with a unique domain architecture containing both RhoGEF and ArfGAP domains were identified, suggesting a mechanism for direct communication between the regulators of vesicle budding and cytoskeletal rearrangement Folate is a cofactor essential for thymidylate synthesis and methionine recycling, and genome analysis reveals a complete lack of genes coding for known folate-dependent enzymes and folate transporters Folate is also required for organelle protein synthesis in mitochondria and chloroplasts, and loss of the mitochondrial genome may have paved the way for the loss of these folate-dependent functions Genome analysis was carried out on a 12.5-fold coverage genome assembly consisting of 23,751,783 base pairs (bp) distributed among 888 scaffolds Glucose is the main energy source; however, in place of the typical eukaryotic glucose transporters those of E. histolytica are related to the prokaryote glucose/ribose porter family, with the amino- and carboxy-terminal domains switched relative to their prokaryotic counterparts In addition to three new amoebapores a homologue of haemolysin III was identified, suggesting that, in addition to amoebapores, haemolysins may have a role in host cell lysis In addition, E. histolytica appears to lack ribonucleotide reductase, a characteristic that it shares with G. lamblia  In contrast to autocrine stimulation of Dictyostelium sporulation, which uses secreted cyclic AMP, E. histolytica encystment is self-stimulated by secreted catecholamines  In contrast to life in the anoxic colon, E. histolytica encounters a relatively high-oxygen environment during invasive amoebiasis, and coping with this change is therefore an important virulence factor It is clear that among the 96 genes, some result in significant enhancements to E. histolytica metabolism, thus contributing to its biology to a greater extent than indicated by the numbers alone LGT is an important force in the evolution of prokaryotes but significantly less is known about its importance in eukaryotic evolution  Most (58%) of the LGT genes encode a variety of metabolic enzymes, whereas most of the remaining genes (41%) encode proteins of unknown function ( Supplementary Fig. 1 ) Most pathways for amino acid biosynthesis have been eliminated, except those for serine and cysteine, which are probably retained for the production of cysteine, the major intracellular thiol No association could be determined between codon usage and the relative copy numbers of their cognate tRNA species No homologues could be identified for a third of predicted proteins (31.8%) from the public databases (see Methods) One-quarter of E. histolytica genes are predicted to contain introns, with 6% of genes containing multiple introns Rab and Arf protein family expansions reflect the increased complexity and number of vesicle fusion and recycling steps that have been associated with phagocytosis and pinocytosis in amoebae  Several glycosidases and sugar kinases appear to have been acquired through LGT and would probably enable E. histolytica to use sugars other than glucose; for example, fructose and galactose Ten new cysteine proteinases with predicted N-terminal transmembrane anchors, which might allow them to be localized on the amoeba cell surface, were identified The 9,938 predicted genes average 1.17 kilobases (kb) in size and comprise 49% of the genome The absence of identifiable pathways for the synthesis of isoprenoids and the sphingolipid head group aminoethylphosphonate suggest the existence of novel pathways The chromosome size variation observed may be due to expansion and contraction of subtelomeric repeats, as in other protists , and it is tempting to speculate that in E. histolytica these regions consist of tRNA-containing arrays The cytoskeleton has a number of important roles in parasite motility, contact-dependant killing and phagocytosis of host intestinal epithelial cells  The E. histolytica genome encodes numerous putative seven-transmembrane receptors and trimeric G proteins, which are probably involved in mediating autocrine stimulation of encystation  The E. histolytica receptor Ser/Thr kinases all contain an N-terminal signal peptide, a predicted extracellular domain and a single transmembrane helix followed by a cytosolic tyrosine kinase-like domain The first group of 50 receptor kinase proteins contains CXXC-rich repeats similar to those found in the intermediate subunit (Igl) of the Gal/GalNAc lectin and G. lamblia variant-specific surface proteins The full complement of tRNAs required for translation has been identified, and all but four of the tRNA genes are encoded exclusively in arrays The high levels of cysteine in E. histolytica may compensate for the lack of glutathione and its associated enzymes, a major component of oxidative stress resistance in many organisms  The importance of this response is underscored by the redundancy of oxygen detoxification mechanisms The major impact is in the area of carbohydrate and amino acid metabolism, where they have increased the range of substrates available for energy generation including tryptophanase and aspartase, which contribute to the use of amino acids The metabolism of E. histolytica seems to have been shaped by secondary gene loss and lateral gene transfer (LGT), primarily from bacterial lineages ( Fig. 1 ) The receptor kinases fall into three groups on the basis of differences in their predicted extracellular domains The third group of eight receptor kinase-like proteins lacks cysteine-rich extracellular domains There is a strong bias in the data for a major donor being in the Cytophaga – Flavobacterium – Bacteroides (CFB) group of the phylum Bacteroidetes; however, this should be interpreted with caution, as current sampling of prokaryotic genomes is still relatively incomplete These genes are embedded among typically eukaryotic genes on E. histolytica scaffolds and do not seem to represent contaminating prokaryotic sequences These include tyrosine kinases with SH2 domains, tyrosine kinase-like protein kinases and 90 putative receptor Ser/Thr kinases These oxidative and/or nitrosative stress resistance genes are shared with G. lamblia (with the exception of rubrerythrin) and T. vaginalis , but have generally been associated with anaerobic prokaryotes ( Fig. 3 ) These pathways, once characterized, might represent attractive drug targets These Ser/Thr kinases are uncommon in protists, appear to be absent from Dictyostelium and have previously been described only in plants, animals and Choanoflagellates These unique tRNA gene arrays are thus predicted to be functional as well as potentially fulfilling a structural role in the genome Thirty homologues of the intermediate subunit and one homologue of the heavy subunit of the GalGalNAc lectin were identified This is reflected in expansions of Rho GTPases and their regulators RhoGAPs and RhoGEFs, which control a number of processes involving the actin cytoskeleton This represents the most varied set of signal-transduction-related proteins yet described in a single-celled eukaryote Two unusual enzymes of fatty acid elongation are shared between E. histolytica and G. lamblia , including a predicted acetyl-CoA carboxylase with two carboxyltransferase domains  Vesicle trafficking has a role in E. histolytica pathogenesis through phagocytosis and the delivery of secreted hydrolytic enzymes and amoebapores to the cell surface  We conducted a phylogenetic screen of the Entamoeba genome for cases of relatively recent prokaryote to eukaryote LGT (see Methods), and for 96 genes we believe that this is the simplest explanation for the tree topologies obtained (see Supplementary Information ) We propose that this enzyme removes a carboxyl group from oxaloacetate and transfers it to acetyl-CoA to form malonyl-CoA and pyruvate
 And on page 658 , one of Hwangs closest rivals admits it may not continue its cloning quest. Carina Dennis asks how they can get cloning to work given a very limited supply of eggs and Phyllida Brown looks at whether we will need therapeutic cloning at all, if immunologists can stop our bodies fighting transplants (see page 655 ) In this special section, Nature looks at how biologists are regrouping Less than a month ago, investigators at Seoul National University in South Korea announced that cloning researcher Woo Suk Hwang had lied when he claimed his team cloned human embryos with relative ease and produced stem cells from them The news was a significant setback for cloning researchers Aborted fetuses are not likely to be a good source of eggs, given the obvious ethical concerns, including the fact that a fetus cannot give its consent Although the first offspring of these experiments — dubbed Eggbert — was a sickly creature, subsequent mice look healthy Although women only ovulate around 500 eggs in a lifetime, their ovaries are packed with thousands of eggs at varying stages of development And egg donations — especially those given altruistically — create an ethical quagmire And even countries where the method is not currently allowed, such as Australia, are reviewing their laws And obtaining human eggs is not easy And some experiments have even suggested that embryonic stem cells might be better at certain aspects of reprogramming than oocytes And they could be useful for generating patient-specific lines to study the genetic basis of human diseases. “We are trying to understand disease processes to identify new therapeutic targets And yet scientists are undeterred. “Its an important question and difficult to answer until you have done the experiments,” says Shaw Another factor is the relatively gargantuan size of a human egg, which swells to more than 100 micrometres As their name suggests, such cells come from young human embryos, termed blastocysts, that are only a few days old At birth, the ovary contains about half a million follicles: these consist of a primary oocyte wrapped in one or more layers of cells that support the oocyte as it grows and accumulates nutrients needed for the early development of an embryo At the moment, researchers work on stem cells taken from surplus embryos created by clinics doing in vitro fertilization (IVF) But Abir says the work could unravel the mysteries of culturing eggs from early development and reveal ways to restore the fertility of cancer patients who have had their ovaries extracted and frozen But culturing really immature eggs has proved extremely difficult But human eggs are needed to make these cells, and a shortage of them could hold back the entire field But if these cells were simply transplanted into patients, the immune system would recognize them as foreign tissue and reject them (see ‘Do we even need eggs?’ on page 655 ) But it is a different story with larger animals. “Its tougher in species other than rodents because it takes so much longer for egg development to occur,” says Eppig; it takes more than three months for a human egg to mature But obtaining eggs for clinical use is likely to be a major obstacle, at least in the foreseeable future. “I cant conceive there will be enough eggs to use on a wide scale But the major drawback of this method is that the chromosomes of the embryonic stem cell used to spark the process are retained But these efforts to culture primary oocytes have yet to yield eggs that can be fertilized. “In the beginning, I thought it would change everything, but now I see how slow the rate of progress is,” says Abir But these eggs typically fail to reprogramme , “probably for the same reasons they failed to fertilize,” says Alison Murdoch, of the University of Newcastle Upon Tyne, UK But they might be good enough to reprogramme a nucleus, according to Hans Schöler of the Max Planck Institute for Molecular Biomedicine in Münster, Germany But this approach will take time. “Someone might get lucky, but I think its a long way off,” says Keith Latham from Temple University School of Medicine in Philadelphia, Pennsylvania But with scant supplies of fresh human oocytes, many researchers see animal eggs as the only practical alternative for refining therapeutic-cloning techniques Controversially, she has also cultured immature eggs from aborted human fetuses to almost the same stage  Creating hybrids of human cells and animal eggs is banned in many countries, under review in others such as Australia, and yet to be tested in the more permissive regulatory environment of Britain Donation is an unpleasant, invasive process that carries a small risk to a womans fertility and can, in rare cases, cause life-threatening side effects Each strategy comes laden with its own technical — and ethical — challenges Egg development in humans is long, extraordinarily complex and not well understood For example, Paul Verma from Monash University has devised a way of getting rid of the unwanted chromosomes , and now has unpublished evidence that mouse cells might be reprogrammed using this approach Given that eggs are so problematic, some teams are attacking the problem of reprogramming from a different angle Greater good Some researchers expect altruistic donations will be sufficient for research purposes. “My view is that most eggs are likely to come from women who have family members with a disease and want to donate their eggs to advance research on that disease,” says Trounson He can create live mice pups by fertilizing eggs that have been cultured in the lab from ovaries extracted from newborn mice  Here, they divide many times to generate millions of egg precursors, called primary oocytes His company, based in Worcester, Massachusetts, has done therapeutic-cloning research using eggs from altruistic donors (see page 658 ) Hovatta is optimistic that they could work in cloning experiments, which she is about to start Hovattas team has been able to grow human primary oocytes in intact ovary slices in culture and has nudged them along several developmental stages Ideally, researchers want healthy, competent eggs If such cells are left to grow very densely on a culture dish under the right conditions, they clump together and, amazingly, will form egg-like structures If this procedure works in humans, researchers could use cloned embryos to produce therapeutic or research cells that are essentially identical genetic copies of a patients cells In excess But cloning is a wildly inefficient process, often requiring hundreds of eggs to produce a single viable clone In regions where therapeutic cloning is permitted, a growing number of scientists have been licensed to start experiments In the end, we have no choice but to develop other methods,” says Robert Lanza of Advanced Cell Technology In the hands of John Eppig, a researcher at the Jackson Laboratory in Bar Harbor, Maine, culturing eggs through these stages looks almost easy In the nearer future, scientists also hope to recreate embryonic cells from patients with diseases such as neurodegenerative conditions, to study an illness as it unfolds and to test new drugs Indeed, one shocking revelation of the Hwang affair, was the sheer number of eggs his lab had got through  Is it appropriate to put healthy fertile women through such a procedure? Should they be paid for their eggs? These issues divide scientists. “Until we can get the efficiency to a reasonable level, we shouldnt be working in human eggs,” says Stephen Minger, a stem-cell researcher at the Wolfson Centre for Age-Related Diseases in London, UK It begins in the embryo when special embryonic cells make their way to the developing ovary (see graphic ) Just before ovulation, this oocyte ejects half its chromosomes, getting rid of half the remainder when a sperm makes contact with its own genetic cargo Make it up Others are going right back to the earliest stages and trying to develop eggs from scratch using embryonic stem cells  Mismatched Still, many scientists are doubtful that animal eggs will yield useful human embryonic stem-cell lines Mitochondria have their own genomes, which interact with the genome in the cells nucleus Mixing nuclei and mitochondria from different species simply may not work (see ‘Spanners in the works’ ).“Its hard enough to keep our nuclear chromosomes in sync with our own mitochondrial DNA and were the same species,” says Irving Weissman of the Stanford School of Medicine, California Most eggs currently donated to research are leftovers from IVF treatments — the ones that fail to fertilize and would otherwise be discarded Murdoch and her team have successfully cloned a single blastocyst using excess eggs from women having infertility treatment  Murdoch now asks women undergoing IVF treatment who produce plenty of eggs — more than 12 in a treatment — whether they would be willing to donate two eggs after the first dozen. “We have calculated that this does not significantly reduce their chances of a pregnancy,” says Murdoch Nobuaki Kikyo of the Stem Cell Institute at the University of Minnesota in Minneapolis, for example, has fished out factors from frog eggs that can repackage chromosomes, dismantle the nucleuss structure and switch on gene activity — all key aspects of reprogramming  Now those claims have been exploded, researchers with aims like Trounsons are returning to the drawing board to see whether anyone can make patient-matched cells at all One such candidate is an embryonic stem cell itself Only after puberty do follicles fully develop, with one follicle growing to full size per menstrual cycle and releasing its enclosed oocyte Others are searching for those seemingly magical factors in eggs that allow them to wind an adult nucleus back to an embryonic form Outi Hovatta from the Karolinska Institute in Stockholm, Sweden, is working on eggs that are on the verge of being ovulated Recently, Harvard University researcher Kevin Eggan and his colleagues transformed adult body cells to an embryonic state by fusing them with embryonic stem cells  Researchers are able to coax such eggs, which are collected alongside mature eggs in normal IVF procedures, through the final stages of readiness for fertilization Researchers are working on fixes, however Researchers have not yet shown that these egg-like cells can be fertilized Ronit Abir from the Rabin Medical Center at Beilinson Hospital, Israel, has nurtured isolated follicles for several weeks in vitro  Schöler pioneered the growth of egg-like cells from the embryonic stem cells of mice She estimates that altruistic donations of these almost-mature eggs would yield about 300 a year from a collaborating IVF clinic Sheng attributes certain discrepancies to the labs culturing methods, a problem that she says has now been rectified Sheng has published her data , but the research community remains unconvinced that her method works. “You have to be uncertain of that work until it is repeated,” says Trounson Shengs lab sparked an international storm when the media reported in 2002 that she was using rabbit eggs to clone human blastocysts So researchers are investigating alternatives such as nurturing immature eggs, growing artificial eggs in the lab and using animal egg substitutes Some newspapers ran headlines about animal–human monsters, fuelling public hysteria Such cells should not be attacked by the patients immune system That said, researchers have had some success with human eggs The answer, says Weissman, could be to combine methods — kickstarting the process with one approach, and finishing it with another. The challenge is to ensure that the voluminous egg receives adequate nourishment, as well as figuring out the right factors to coax it along the development pathway d that they were seeking approval to do similar experiments The discredited researcher Woo Suk Hwang owed his preeminence in cloning circles to his claims to have produced such patient-specific stem cells in an almost routine way The main concern centres on mitochondria, the bacteria-like powerhouses of the cell The most obvious place to start looking for alternatives to conventional donation is to go direct to the ovary The research field is anxious to see whether reprogramming will be possible — Schöler claims to have made one unsuccessful attempt. “We are still working out the conditions,” he says. “Its not as trivial as wed thought.”  With human eggs presenting so many difficulties, some researchers are exploring the possibilities of animal eggs, at least for research purposes. “Human eggs are so precious — why waste them to practise on?” asks Huizhen Sheng, from the Centre for Developmental Biology at Xinhua Hospital in Shanghai The resulting embryo is a genetic clone of the adult from whom the nucleus was taken The ultimate dream is to create specialized types of cell — such as insulin-producing cells or heart cells — to treat diseases such as diabetes or to repair damaged hearts or other organs Therapeutic cloning could, in theory, solve this problem There is unlikely to be one single way to mimic the almost mystical reprogramming ability of a human egg These cells are not for putting back into people,” says Shaw They approach the stem-cell researcher from Monash University in Melbourne, Australia, after he gives talks to patient focus groups They are trying to see whether other kinds of cells share an eggs ability to reprogramme a nucleus This limits a cells therapeutic potential because a patients immune system could recognize the leftover chromosomes and launch an attack This may make it hard to recruit donors. “Well have to wait and see how difficult human eggs are to acquire,” says Arnold Kriegstein, director of the Institute of Stem Cell and Tissue Biology at the University of California, San Francisco To make therapeutic tissues such as heart cells, many researchers start with unspecialized, immature cells called embryonic stem cells Trounson wants to treat neurodegenerative disease by using eggs to create cells that match a patients genetic make-up — a technique known as therapeutic cloning. “The technique is not legal in Australia, so its a fairly brief conversation,” he says What if researchers could somehow get hold of these — from ovarian biopsies, say — and grow them to maturity in the lab? Biologists are making some headway in culturing eggs that are in the last stages of development Women occasionally offer Alan Trounson their eggs Working in animals, researchers have shown that if they transplant a nucleus from an adult body cell into an egg that has had its nucleus removed, the egg somehow ‘reprogrammes’ the adult nucleus back to an immature state, where it directs the development of an embryo
 A candidate galaxy at z =7 has been reported using gravitational lensing — the bending of light by massive intervening bodies — to amplify images of distant objects that would otherwise be undetectable , although airglow has prevented spectroscopic confirmation of this galaxy, too A galaxy spotted at z =6 might have formed its first stars at up to z =13.5 — just 300 million years after the Big Bang  Although they could search at longer wavelengths, the smaller aperture and older detectors on the HST meant that Bouwens and Illingworths observations were confined to a patch of sky about 50 times smaller that that covered by Iye and colleagues optical detectors  And Bouwens and Illingworth ( page 189 ) report on their search for galaxies even farther away, more than 13 billion light years from Earth Armed with both sets of results, we can design better experiments to increase the probability that still older galaxies can be discovered. As a result, searching for the very earliest objects becomes — from the ground, at least — increasingly difficult As the HST does not carry appropriate instrumentation, this might have to await the launch, currently projected for 2013, of Hubbles successor, the 6-m-aperture James Webb Space Telescope As the Universe expanded and cooled, neutral hydrogen and helium were created from the hot plasma of matter at the so-called epoch of recombination, around 400,000 years after the Big Bang As this is above Earths atmosphere, it is not affected by airglow radiation effects and can work at longer wavelengths (and so higher redshift) As very few atoms remained ionized in this neutral Universe, very little radiation can be detected from this era At redshift 6.96, the observed wavelength is stretched by a factor of 7.96 Bouwens and Illingworth recount a similar story at redshifts of 7–8 Bouwens and Illingworths conclusions are no less important, reminding us just how difficult this task might be Bouwens and Illingworths identification method used the 2.5-m-aperture HST ( Fig. 1 ) But the authors note that, by comparison with observations at smaller redshifts, they would have expected to find around five galaxies in a survey of their scale By studying the first galaxies, we can also hope to understand how the Universe formed and evolved, and detect the younger progenitors of galaxies like our own Milky Way Determining when the first stars and galaxies formed is a matter of profound importance: fuelled by primordial hydrogen, these bodies triggered the nucleosynthesis of the heavier elements, such as carbon, nitrogen and oxygen, that are the basis of life Even so, we can expect this ground-based technique to be extended to longer wavelengths in the coming years  First, there are the immense distances of around 10 24 km implied by light journey times of more than 10 billion years; the brightness of a source diminishes with the inverse square of its distance For this reason, independent spectroscopic confirmation is required for the existence of this galaxy From a redshift of 4.55 in 1996 (ref. 3 ), the earliest star-forming galaxy had been put back to z =6.56 by 2002 (ref. 4 ) Improvements in solid-state detector technology have followed Moores law, with a doubling of chip density every two years or so; mega-pixel devices and highly efficient, large-format red-sensitive detectors have arrived on wide-field imaging instruments, on a new generation of 8-metre-aperture telescopes, and on the refurbished Hubble Space Telescope (HST) In recent years, the search for galaxies has been pushed back progressively towards these trailblazers In the shorter term, Iye and colleagues plan to search another patch of sky to increase their sample size In this case , the focus was on an ultraviolet wavelength of 121.6 nm In this issue, Iye et al . ( page 186 ) report the discovery of the most distant galaxy yet, one whose photons must have left it 12.7 billion years ago, when the Universe was just 750 million years old, and some 8 billion years before the Sun and Earth were formed Indirect evidence for galaxies at still higher redshifts comes from recent observations by NASAs WMAP satellite of polarization in the cosmic microwave background radiation, which was left behind at the epoch of recombination Iye and colleagues discovery takes us farther back to z =6.96 Iye et al . used the 8.2-m-aperture Subaru telescope on Hawaii ( Fig. 1 ), one of the largest ground-based telescopes, together a mosaic of CCD detectors with a total of 84 million pixels Like archaeology, astronomy also has its Dark Ages from which evidence is particularly sparse Only then will the presence, or absence, of further galaxies be able to tell us whether we really are homing in on the era of reionization Other techniques exist to search for galaxies at higher redshifts Second, there is the expansion of the Universe, which stretches the wavelength of light from distant objects by a factor 1+ z  So could we now really be looking back to the very earliest phase of galaxy formation at the epoch of reionization? With the current results it is still hard to tell That also limits the scope for extending the HST work to larger areas of sky within the few remaining years of the telescopes projected lifetime The authors exploited a gap in the intense hydroxyl airglow radiation that is created by processes high in Earths atmosphere and dominates the terrestrial night sky at wavelengths above 700 nm The authors looked for a break in the radiation between the infrared and the optical regions that is caused by absorption through neutral hydrogen along the line of sight, and found this in one case The older an object is, the greater its redshift; but unfortunately, the redder one gets, the brighter the night sky becomes The quantity z is known as the redshift, as the expansion moves all observed wavelengths towards longer, redder wavelengths The resulting radiation at 968.2 nm is beyond the range of the human eye, and almost at the limit of conventional silicon-based CCD detectors The situation changed only when the first generation of luminous sources — massive stars, galaxies and accreting black holes — reionized and lit up the gas in the Universe The study of the most distant galaxies has much in common with archaeology: the farther back one looks, the scantier the evidence becomes, and the harder it is to draw conclusions The success of Iye et al . bodes well for continued searches for the first galaxies to emerge from the Universes dark ages The two surveys employed quite different experimental approaches This unique, asymmetric spectral signature is typical of star formation, and comes from photons produced by a ground-state transition in hydrogen Two factors are responsible Unlike the characteristic Lyman-α emission, this break is not an unambiguous signal of a high-redshift galaxy with high rates of star formation, but could have been caused by interstellar dust or intrinsic stellar features in galaxies at lower redshifts Using a special interference filter centred on 975.5 nm with a bandwidth of 20 nm, they could search between hydroxyl lines for so-called Lyman-α radiation Where they might by extrapolation have expected to find around ten galaxies, they found only one unconfirmed candidate Whereas the Subaru telescope needed just a few nights to collect the requisite data, the HST needed a few years
 Arising from: Bai, Y., Han, X., Wu, J., Chen, Z Bai et al . suggest that in Chinas Inner Mongolia steppe, community-level stability arises from compensatory effects among the principal components at both the species and plant functional group (PFG) levels By analysing a consistent 19-year data set (1980–98), we show here that their analysis of a 24-year field data set (1980–2003) is called into question by inconsistencies in sampling location and numbers after 1998; the authors findings are further undermined because they do not distinguish temporal variation from spatial heterogeneity in analysing compensatory effects among species or PFGs Li, L Li, L. reply  Nature , 431 , 181–184 (2004) ; see also communication from Guo ; Bai, Y., Han, X., Wu, J., Chen, Z We believe that rigorous reanalysis is needed for a better understanding of grassland stability. Bai et al . also illustrate the compensatory effects by showing the negative correlations between species or PFGs (Table 1 in Bai et al . ), but they pooled data for all 120 quadrats (5 quadrats per year for 24 years), which included both the temporal variability (generated by the 24 years) and the spatial variability (generated by the 5 replicates and the change of sampling location after 1998) Bai et al . analysed data on relative figures for LAB to demonstrate compensations between PFGs or species (Figs 2 and 3 in Bai et al . ) Furthermore, correlation does not imply causation  Furthermore, we found no compensations between dominant and subdominant, or between subdominant and non-dominant, species and PFGs in the L. chinensis community However, the relative mass of one PFG or species in a community would inevitably rise (or fall) if the relative mass of the other PFGs or species fell (or rose), irrespective of whether true compensation exists between them However, we found that correlations were greatest between, on the one hand, the community biomass (measured by live above-ground biomass (LAB), as in Bai et al . ) on both 15 and 31 August, and on the other, precipitation during the plant growing season (15 April to 15 August) ( r =0.682 and 0.705, P 0.001) It is not robust evidence for specific compensation effects. Second, even neglecting the change of sampling location and resampling of the 5 quadrats from the 20 quadrats in the period 1999–2003, Bai et al . do not convincingly demonstrate the existence of specific compensatory effects on the community stability — these are generally measured by temporal variation  Similar results for dominant–subdominant PFGs were also observed in both sites ( r =−0.500, P =0.025 in L. chinensis site and r =−0.901, P0.001 in S. grandis site) Spatial heterogeneity alone can produce significantly negative correlations between some species, especially between dominant and subdominant species in both communities ( Table 2 ), that are even stronger than those that Bai et al . find in the bulk data set The 24-year biomass data used by Bai et al . are inconsistent owing to changes in sampling area and numbers after 1998, which accounts for the discrepancy with our reanalysis of a consistent 19-year data set covering the same period but ending in 1998 ( Table 1 ) The compensatory effect between dominant and subdominant PFGs was not evident in either site ( Table 1 ) The small proportion of significantly negative correlations in Bai et al . (10 in 231 species pairs and 15 in 120 species pairs in sites A and B, respectively) is almost exactly what would be expected by chance, with a criterion of P 0.05 We also excluded some extraordinarily wet years (see Methods), as do Bai et al . , who assert that January–July precipitation was the primary climatic factor causing fluctuation of community biomass production We also found that annual precipitation was significantly correlated both with LAB on 15 August and with the annual peak LAB ( r =0.547 and 0.556, P 0.05) in the Leymus chinensis community We found no significant correlations between LAB or peak LAB and precipitation in the Stipa grandis community ( P 0.05)
 According to many observers (see After the flood ), the reorganization has weakened FEMA and focused its attention on such scenarios as bioterror attacks After initially opposing the idea, Bush co-opted it, removed its most potent aspect (the incorporation of the intelligence agencies) and implemented what was basically an amalgamation of existing government departments, including the once-admired Federal Emergency Management Agency (FEMA) Bush, and for good reason But short of such far-reaching change, the disaster should lead to an immediate re-examination of how the federal government is organized, and how it responds to scientific advice For a start, the main cause of death in the aftermath of Hurricane Katrina will have been drowning as a result of the flooding in New Orleans that sprang from a widely anticipated failure of the citys flood defences His belated and uninspiring personal response to the crisis has invited widespread criticism In the aftermath of Hurricane Katrina, this dialogue-of-the-deaf must end, and the assessment and management of natural risks should be genuinely embraced as a national priority. It has also been a subject of bitter political contention — generally between the supporters of the Army Corps of Engineers, which likes to build levees, and environmentalists, who favour marshland conservation and more ‘natural’ river flow It is not inconceivable that Katrina will force Americas leaders to confront poverty and support public investment in infrastructure Knowledge of the risk of a storm-induced flood in New Orleans has been widespread in the scientific community for years, and researchers have sought to improve our understanding of it Much of the blame for the painfully slow reaction to the hurricane has fallen on President George W Much of this work has taken into account stubborn facts such as the propensity of the poor, the elderly and the sick to ignore evacuation orders Previous US flood disasters — notably in Johnstown, Pennsylvania, in 1889 and in the New Orleans area in 1927 — prompted major political upheaval River management, meanwhile, has developed into something of a scientific backwater in the United States, some of its practitioners complain The Department of Homeland Security was originally conceived in Congress as a response to the terrorist attacks of 11 September 2001 The Department of Homeland Security, the newly created government department that fumbled the early rescue efforts, is viewed as Bushs creation and is ineptly staffed by the presidents appointees The lesson is that sweeping reorganizations of government agencies in response to particular crises can have severe adverse consequences The public face presented by FEMA has been diminished, and the agency seems to have retreated from its traditional position at the forefront of disaster response The term ‘natural disaster’ doesnt really do justice to the scenes that unfolded in the southern United States last week There are indications that many senior politicians — not just President Bush — were simply unaware that the New Orleans flood risk even existed There is an overwhelming sense that the human calamity that befell the city was avoidable and represents a failure of the US government to protect its most vulnerable citizens There seems to be a disconnect, however, between the process that identifies such risks and the people who make the decisions that might manage them These include rampant poverty among African-Americans in New Orleans and other US cities; a systematic failure to build public infrastructure commensurate with Americas vast wealth; the habitual creation of dysfunctional government agencies by congressional fiat; and the failure of scientists to successfully convey their concerns to policy-makers This weakening has left city and state governments in Mississippi and Louisiana bereft of leadership from the federal government at their moment of greatest need Yet as criticism rains down on the administration, it should be pointed out that several contributory factors that led up to this fiasco preceded Bushs arrival in the White House
 And as lucrative drugs go off-patent, drug companies are under pressure from their shareholders, who may be placated by smart acquisitions And despite Chirons coyness, it may welcome the interest And last week it bought Vicuron, a Pennsylvania-based maker of anti-infective drugs, for $1.9 billion And stagnant biotechnology share prices make acquisitions relatively cheap. “This hasnt been a great year for biotechnology stocks,” notes Brady Huggett, managing editor of BioWorld . “So biotechnology companies have often been pretty decent bargains.”  Chirons share price, for example, has slumped from $57 in late 2003 to less than $37 when Novartis made its bid. “The problems in the vaccine business have caused Chirons whole business to be undervalued,” says Porges. “Novartis is being opportunistic in trying to buy Chiron when it is back on its heels.” Bernstein in New York. “They are now saying: ‘We dont see enough opportunities internally to invest that cash, so were going to look externally’.” Novartis is a case in point: the company saw its profits grow by 15% in 2004, to $5.8 billion, on sales of $28.2 billion But as Chirons directors rejected Novartis first offer, analysts were asking whether a takeover would pep up Chiron, which has been hit by recent vaccine-manufacturing woes — or if it would just mark a release of cash to shareholders, and the end of a biotechnology success story dating back to 1981. “Pharma is struggling on its own,” explains Karl Heinz Koch, an analyst who follows Novartis for the Swiss bank Lombard Odier Darier Hentsch. “It needs the more dynamic biotechnology industry to deliver growth and value to investors.”  Big drug firms “have lots of cash on their balance sheets”, adds Geoffrey Porges, a biotechnology industry analyst with investment-research company Sandford C Chiron has had a rocky year since problems at its vaccine plant in Liverpool, UK, were revealed last October Drug companies have long bought biotech companies as a means of expanding their drug pipelines, but several factors have converged to accelerate the process Four days later, the California companys directors pronounced that offer “inadequate” GlaxoSmithKline joined in on 7 September, when it announced its agreement to purchase ID Biomedical, a Vancouver, Canada-based vaccine maker, for $1.4 billion Healthy appetite But a deal that looks tasty to big pharma may appear less enticing from the other end. “One of biotechs major challenges is to keep itself distinguished from pharma, which has more headaches and crises than you can shake a stick at,” says Arthur Caplan, an industry observer and bioethicist at the University of Pennsylvania in Philadelphia In the case of Alnylam — founded by Nobel-prizewinning biologist Phillip Sharp of the Massachusetts Institute of Technology — the arrangement envisages Novartis pouring money into the smaller company, whose laboratories would basically retain their autonomy Influenza vaccine sales alone fell by $178 million in 2004, and profit margins fell by more than a fifth It is also a good time to be shopping It will buy a 20% share in Alnylam Pharmaceuticals of Cambridge, Massachusetts, a collaboration aimed at developing drugs based on RNA interference, which uses recombinant DNA to block disease-causing genes Keeping a distinctive profile is “a real challenge” for the biotechnology sector, Caplan points out Most ‘big pharma’ companies know that their future rests in either buying biotechnology companies or getting into bed with them Negotiations are continuing, with reports that Novartis may increase its bid New York-based Pfizer has been even more active in biotechnology acquisitions Novartis followed up its Chiron bid by announcing a subtler partnership with another biotechnology company Novartis wooing of Chiron is hardly a blind date On 1 September, Novartis offered $40 a share, or roughly $4.5 billion, for Chiron, whose share price rose by 18% to almost $43 (see graph below) Public offerings for biotechnology companies have generated disappointing returns lately, making companies more willing to be bought out Shopping spree In contrast, some analysts think that a takeover of Chiron would shrink the companys research The drugmaker already owns 42% of the biotechnology company, inherited from Ciba-Geigy when it merged with Sandoz to create Novartis in 1996 The industry has faced bad publicity — most notably surrounding Mercks withdrawal of the painkiller Vioxx (see Nature 436 , 1070 ; 2005 ) The putative deal reflects a growing appetite among the major pharmaceutical companies for snapping up small, creative biotechs with their innovative research and potentially lucrative products The two deals may represent opposite ends of the spectrum in terms of how large drug companies treat partners in the biotechnology sector This employs more than 380 scientists at laboratories in California, with others elsewhere, and cost $431 million last year. “Theres a lot of cost savings Novartis can take out of Chiron,” says Koch. “The large majority of its research and development cost is in biomedical research, which has not produced a single drug in eight years.” Analysts also speculate that Novartis may finance any acquisition in large part by selling off Chirons lucrative blood-testing business This year alone, it has acquired three privately held California companies: Bioren, Idun Pharmaceuticals and Angiosyn When Novartis announced a bid to buy Chiron, the California biotechnology company, earlier this month, the Swiss drugmaker trod a well-worn path
 Frequent reports of small-scale flux ropes and flow channels associated with reconnection in the Earths magnetosphere raise the possibility that reconnection is intrinsically patchy, with each reconnection X-line (the line along which oppositely directed magnetic field lines reconnect) extending at most a few Earth radii ( R E ), even though the associated current sheets span many tens or hundreds of R E  Here we report three-spacecraft observations of accelerated flow associated with reconnection in a current sheet embedded in the solar wind flow, where the reconnection X-line extended at least 390 R E (or 2.5 × 10 6  km) It is not known at present whether reconnection is fundamentally a process that can occur over an extended region in space or whether it is patchy and unpredictable in nature  Magnetic reconnection in a current sheet converts magnetic energy into particle energy, a process that is important in many laboratory , space and astrophysical contexts  Observations of this and 27 similar events imply that reconnection is fundamentally a large-scale process Our observations also reveal, surprisingly, that reconnection can operate in a quasi-steady-state manner even when undriven by the external flow. Patchy reconnection observed in the Earths magnetosphere is therefore likely to be a geophysical effect associated with fluctuating boundary conditions, rather than a fundamental property of reconnection ACE was 222 R E further upstream of Cluster, while Wind, in its furthest orbit from Earth during its 10-yr mission, was located at 331 R E dawnward of Cluster (and 321 R E from the Sun–Earth line) Along an X-line of at least 390 R E , the minimum reconnection potential was thus 75 kV Although we have shown detailed observations from a single event, our conclusions in terms of extended X-lines and steady reconnection are general An important difference is that while reconnection is strongly driven at the magnetopause (by the solar wind impinging on the Earths magnetosphere), reconnection in the present case appears to have been largely undriven Another fact that is consistent with a coherent and extended X-line is that the reconnection jets detected by all three spacecraft were directed in the same direction, implying that the X-line was north of all spacecraft By the time the current sheet reaches 1  au , the X-line has reached hundreds of R E or more Cluster was 14 R E upstream (sunward) of the Earth Common among all 28 events is the fact that the plasma β (the ratio of plasma to magnetic pressure) in the ambient solar wind (outside the exhausts) is less than unity ( β 28 events = 0.4 ± 0.2), a condition that has been suggested to be necessary for the occurrence of reconnection  Figure 2 shows that all three spacecraft detected the passage of the same bifurcated current sheet with accelerated plasma flow embedded in it Finally, with a 12-nT magnetic field convecting into the reconnection region at 2.5 km s -1 (for a dimensionless reconnection rate, v N,rec / v Alfven , of 3.3%, where v Alfven = B ( µ 0 ρ ) -1/2 is the Alfven speed), the reconnection electric field was 0.03 mV m -1  From ACE to Wind, the error is only 6 s, or 0.07% From the X-line orientation one can determine, based on the locations where the three spacecraft intersected the current sheet, that Cluster and Wind detected flow from positions along the X-line that were 390 R E apart, while ACE detected flow from the X-line at an intermediate location (see Fig. 1 ) Furthermore, Fig. 3 shows that the plasma density and temperature were sharply enhanced at the edges of the current sheet while the magnetic field strength was reduced If reconnection were patchy, one or more spacecraft most probably would not have encountered accelerated flow In addition to finding an extended X-line, the fact that the three spacecraft detected the reconnection exhaust over a period of 2.5 h implies that reconnection must have been quasi-steady over at least that time span In four of these cases, we have evidence for an X-line extending more than 100 R E  In the normal direction the velocity across the current sheet was nearly constant except for a small 5 km s -1 shift It is generally difficult to establish the presence of an extended reconnection X-line in the magnetosphere from in situ measurements since that requires the presence of widely separated spacecraft detecting the same reconnection events On 2 February 2002, the Wind, ACE and Cluster spacecraft were all in the solar wind ( Fig. 1 ) Our finding also raises an interesting question: how does the reconnection X-line become so extended? We suspect that in the case of the solar wind, reconnection starts in a limited region in the solar wind current sheet closer to the Sun and spreads with time from its initiation region Patchy and random reconnection could result in different spacecraft detecting jets directed in different directions Remote observations of proton auroras and ionospheric convection have hinted at the presence of a magnetopause X-line up to 40 R E in length but that has not yet been confirmed by in situ observations Such current sheets have finite extents, and their boundary conditions (determined by the solar wind magnetic field) often change rapidly The bifurcated current sheet associated with the reconnection exhaust was convecting with the solar wind, and was first detected at ACE at ∼01:32  ut , followed by Cluster an hour later (at ∼02:32  ut ) and 2.5 h later than at ACE by Wind (at ∼03:57  ut ) The chances of such conjunctions are exceedingly small because the spacecraft are seldom ideally positioned for such observations and because of the variable boundary conditions The combination of extended current sheets with stable boundary conditions and the fact that the solar wind rapidly convects the exhausts past observing spacecraft make these solar wind reconnection events ideal for addressing the question of extended versus patchy reconnection without complications due to boundary effects The extent of the X-line that can be measured depends on the orientation of the exhaust and of the X-line relative to the spacecraft The fact that Cluster and Wind detected the current sheet 85 min apart even though both spacecraft were at nearly the same distance from the Sun (but 330 R E apart in dawn–dusk direction) implies that the current sheet must make a large angle relative to the ‘east–west’ direction (that is, relative to the y direction in Geocentric Solar Ecliptic (GSE) coordinates; see Fig. 1 ) The fact that reconnection can be quasi-steady in the undriven regime is surprising, and has not been previously reported to the best of our knowledge The large number of dual-spacecraft detections of reconnection flow with no counter-examples strongly indicate that reconnection in the solar wind, and probably in other astrophysical domains as well, can operate in a large-scale (much larger than the ion inertial scale) and quasi-steady mode, leading to the release of large amount of magnetic energy The normal to the current sheet tilt was determined by minimum variance analysis of the magnetic field across the current sheet, and was found to be (0.71 ◯ , 0.60 ŷ , -0.37 zcirc; ) in GSE The observed plasma acceleration within the exhaust agreed with the reconnection prediction to within 5° in direction and 10% in flow speed (see Fig. 3c and d for more details) The plasma and field signatures just described are typical of solar wind reconnection exhausts  The recent discovery of reconnection exhausts in the solar wind introduces a new laboratory where reconnection can be investigated by in situ measurements The resulting error in the propagation time from ACE to Cluster is 4 min 20 s, or 7% The single event reported where two spacecraft (separated by 3 R E ) detected the same reconnection event at the magnetopause only allowed the deduction that the X-line was at least 3 R E long  The small magnitude of the normal magnetic field ( B N ) across the current sheet ( Fig. 3e ) further confirms the accuracy of the current sheet normal The solar wind reconnection events are often associated with interplanetary coronal mass ejections, and the magnetic field orientations on the two sides of the current sheets are usually well defined The total magnetic field rotation (or shear) across the bifurcated current sheet was 140° The true size of the solar wind X-line can be investigated by the upcoming NASA/STEREO mission, which will provide large spacecraft separations that exceed 1  au in the GSE- y direction. The velocity shift was consistent with a normal inflow, in the frame of the current sheet, of v N,rec = 2.5 km s -1 associated with reconnection (at the position of Wind) The X-line orientation (0.47 ◯ , -0.79 ŷ , -0.39 zcirc; ) in GSE is obtained from the components of the magnetic field in the current sheet plane  There was a discontinuity in the flow speed across the current sheet of 27 km s -1 ; however, Fig. 3d shows that much of the flow speed discontinuity was due to a 22 km s -1 shear in the flow component tangential to the current sheet which does not compress the current sheet These signatures are consistent with the Petscheck model of fast reconnection, where the reconnection exhaust is bounded by Alfven and/or slow mode waves This agreement demonstrates that the current sheet was indeed approximately flat on a scale of hundreds of Earth radii (or 0.01  au ) and that the current sheet normal was accurate This angle is confirmed by the analysis of the current sheet geometry at Wind This finding is similar to reports of quasi-steady reconnection at the Earths magnetopause  This implies that the X-line extended at least 390 R E (or 4 × 10 4 ion inertial lengths) and very probably a great deal further This is consistent with the plasma acceleration being accomplished by the magnetic tension force associated with linkage of the magnetic field across the exhaust To obtain the X-line orientation, one first needs to determine the exhaust geometry Until recently, in situ observations of reconnection in space plasmas were made almost exclusively in the Earths magnetosphere, in current sheets formed by the interaction between the solar wind and the geomagnetic field We are aware of no counter-examples where one spacecraft detected the reconnection signature and the other did not We have identified 27 additional events when both ACE and Wind were in the solar wind and detected essentially the same reconnection signatures, irrespective of how far apart (in space and time) the two spacecraft were What is significant about this 2 February 2002 event is the fact that the reconnection exhaust was observed by three widely separated spacecraft, which allows the deduction of a long reconnection X-line
 Classical studies show that for many proteins, the information required for specifying the tertiary structure is contained in the amino acid sequence Experimental testing of libraries of artificial WW domain sequences shows that a simple statistical energy function capturing coevolution between amino acid residues is necessary and sufficient to specify sequences that fold into native structures Here, we attempt to define the sequence rules for specifying a protein fold by computationally creating artificial protein sequences using only statistical information encoded in a multiple sequence alignment and no tertiary structure information The artificial proteins show thermodynamic stabilities similar to natural WW domains, and structure determination of one artificial protein shows excellent agreement with the WW fold at atomic resolution The relative simplicity of the information used for creating sequences suggests a marked reduction to the potential complexity of the protein-folding problem. Additional restraints on the backbone dihedral angles φ  and ψ  were derived from a TALOS-based analysis of backbone chemical shifts and supplemented by 3J(HN-Hα) coupling constants measured in a three-dimensional HNHA spectrum Additional spectra were recorded on an 850 µM sample of uniformly 15 N-labelled CC45 in 90%:10% H 2 O:D 2 O, including three-dimensional 15 N-edited TOCSY ( τ  mix = 60 ms), three-dimensional 15 N-edited NOESY ( τ  mix = 150 ms), three-dimensional HNHA and two-dimensional 15 N/ 1 H heteronuclear single quantum correlation (HSQC) experiments After washing (three times with 15 ml binding buffer), WW proteins were eluted in elution buffer (100 mM TrisHCl, pH 8.0, 1 M NaCl, 400 mM imidazole) All spectra were processed using the NMRPipe package and analysed using nmrView  All spectra were recorded at 25 °C using a 3-9-19 Watergate sequence for water suppression CC model sequences were generated using a Monte-Carlo simulated annealing algorithm, described in the Supplementary Methods section Constructs were verified by DNA sequencing Cultures were scaled up for NMR experiments, using 1–2 l of Terrific broth and 0.5 ml of affinity resin Data were acquired while changing the temperature from 4 °C to 90 °C and back to 4 °C, at a rate of 2 °C min -1 with 5 min equilibration periods at 4 °C and 90 °C For fluorescence experiments, 50 ml culture was lysed in 3 ml binding buffer (25 mM TrisHCl, pH 8.0, 0.5 M NaCl, 5 mM imidazole) by sonication followed by centrifugation and incubation of the cleared lysate with 75 µl bed volume Ni + -NTA ( Qiagen ) for 30 min at 4 °C For the CC45 chemical shift assignments and solution structure determination, a combination of two-dimensional double-quantum filtered correlation spectroscopy (DQF-COSY), total correlated spectroscopy (TOCSY; τ  mix = 60 ms) and nuclear Overhauser effect spectroscopy (NOESY; τ  mix = 150 ms) were recorded on 600 µM unlabelled protein samples in the above buffer at 25 °C and 38 °C, along with two-dimensional TOCSY ( τ  mix = 60 ms) and NOESY ( τ  mix = 60, 150 ms) spectra recorded at 25 °C on a 1 mM protein sample made in the same buffer with 99% D 2 O solvent Gene construction and protein expression Genes encoding artificial sequences were designed by back-translating designed protein sequences using E. coli codon optimization ( Vector NTI Suite , Informax Inc ), built on overlapping DNA oligonucleotides, assembled using the polymerase chain reaction, and cloned into the pHIS8-3 expression vector (provided by J Hydrogen bond restraints for a total of six backbone amides were generated for sites showing β-sheet structure by dihedral angle analysis and typical inter-strand nuclear Overhauser effects (NOEs) Melting curves for 10 µM free tryptophan were subtracted to account for the intrinsic temperature dependence of Trp fluorescence Melting temperature ( T m ) and enthalpy of unfolding at the T m were calculated by fitting the first derivative of the denaturation curves to the differential form of the vant Hoff equation  Methods Statistical coupling analysis Statistical coupling analysis was performed as previously described  NMR spectroscopy All NMR spectra were recorded on 500 and 600 MHz Varian Inova spectrometers  Noel) One hundred structures were generated in the last ARIA iteration, out of which the ten with the lowest energies were selected for a final refinement stage in water One-dimensional 1 H-NMR spectra of various WW domains were obtained on samples containing 100 µM to 1 mM protein in 100 mM NaCl, 100 mM sodium phosphate buffer (pH 7.0) and 90%:10% H 2 O:D 2 O Protein design algorithms IC model sequences were created by randomly drawing amino acids for each site from the corresponding amino acid frequency distributions in the natural WW alignment Protein fluorescence was monitored at 340 nm (excitation at 295 nm) using a spectrofluorometer ( Photon Technologies Inc .) outfitted with a Peltier temperature controller  Proteins were expressed in JM109(DE3) cells grown at 37 °C in Terrific broth to an absorbance at 600 nm of ∼1.2, and induced with 0.5 mM IPTG at 18 °C overnight Ramachandran statistics for CC45 are: 80.7 ± 6.3% in most favoured regions, 18.0 ± 7.3% in additionally allowed regions, 1.0 ± 1.6% in generously allowed regions, and 0.3 ± 1.0% in disfavoured regions. Random sequences were created by randomly selecting residues at every site from the overall frequency distribution in the MSA Structure determination Distance restraints were obtained by analysing the three-dimensional 15 N-edited NOESY and two-dimensional homonuclear NOESY spectra recorded in 99% D 2 O (both τ  mix = 150 ms) using the CNS package with the ARIA 1.2 extension  The CC45 sequence is NH 3 + -MPLPPGWERRTDVEGKVYYFNVRTLTTTWERPTIILE-COO -  The five statistical perturbations used in this study (8E, 21Y, 22D, 23H and 28T) were chosen by knowledge of structural or functional importance in the WW domain  The resulting ensemble of ten structures was used for all analyses as implemented in the programs PROCHECK-NMR and MOLMOL  Thermal denaturation assay Purified proteins were diluted into 2 ml elution buffer for a final WW domain concentration of ∼1–10 µM WW domain sequences were collected using PSI-BLAST ( e -scores ≤0.001) from the non-redundant database of protein sequences (release date October 2000), and aligned using ClustalW  A fundamental tenet of biochemistry is that the amino acid sequence of a protein specifies its atomic structure and biochemical function  A hallmark of natively folded small proteins is cooperative and reversible transition between folded and unfolded states Accordingly, the SCA matrix for an alignment of 120 such sequences (termed the site-independent conservation (IC) model) shows no statistical coupling between positions ( Fig. 1d ) All libraries contained sequences that expressed poorly despite multiple attempts, or produced insoluble aggregates ( Fig. 2b , first and second columns); these were scored as not folded All seven structures clearly adopt very similar backbone folds, and no obvious feature seems to distinguish CC45 from the other proteins Also, the folded subset of CC sequences shows the same core sequence identity (67.8 ± 7% mean and 98.3 ± 6% top-hit; mean ± s.d.) Although CC sequences show similar divergence from natural WW domains as IC sequences overall ( Table 1 ), we wondered whether CC sequences might natively fold because they are more similar to WW domains within the core An approach to defining the architecture of amino acid interactions in proteins is suggested by an evolution-based method known as the statistical coupling analysis (SCA) Another expected finding was that random sequences show much weaker identities to natural WW domains (∼6%) Application of the SCA in several different protein families reveals two general conclusions: (1) the global pattern of coevolutionary interactions is sparse, so that a small set of positions mutually coevolves among a majority that are largely decoupled, and (2) the strongly coevolving residues are spatially organized into physically connected networks linking distant functional sites in the structure through packing interactions  As described, this protein is well folded by several independent biophysical assays ( Fig. 3b , g ) As expected, no random sequences were folded, although nearly half of these were well expressed and soluble As suggested by thermal melts, the NMR spectrum for N36 ( Fig. 3f ) shows none of these hallmarks, consistent with an unfolded protein At convergence, this algorithm produces alignments of novel sequences (∼10 5 substitutions per sequence) that display the same conservation pattern and also closely reproduce the pattern of statistical couplings observed in the natural alignment (termed coupled conservation (CC) model; compare Fig. 1c and e ) Atomic structure of an artificial WW domain Do the artificial proteins adopt the canonical WW fold? To examine this, we pursued in-depth structural analysis of one of the CC proteins, CC45 Because no information about the WW domain except the coupling values in the SCA matrix was used to constrain the CC sequences beyond the IC sequences, we conclude that the specific topology of mutual constraints between sites predicted by the SCA is one solution for achieving the folded state of this protein family But exactly what information in the sequence of a protein is necessary and sufficient for producing the fold and its biological activity? Despite considerable progress in understanding the mechanisms of protein folding , the answer to this fundamental question remains unknown CC sequences show 66.7 ± 7.0% mean and 97 ± 7.1% top-hit identities to natural sequences for these positions (mean ± s.d.), values that reflect the near invariance of some core positions in the MSA CC45 shows 39% mean identity and 61% top-hit identity to natural WW sequences, values that are near the average for both CC and IC sequences ( Table 1 ) CC45 was refined to reasonably high precision, clearly confirming the curved three-stranded antiparallel β-sheet structure characteristic of all WW domains Characteristic features of folded WW proteins include good chemical shift dispersion of peaks corresponding to backbone amide protons ( δ 9 parts per million (p.p.m.)), often accompanied by distinct chemical shifts of the two indole nitrogen protons down-field of 10 p.p.m. (the two canonical Trp residues are in distinct chemical environments—one in the core and one solvent exposed, see Fig. 1a ), and up-field chemical shifts ( δ 0.5 p.p.m.) corresponding to side-chain methyl protons  Comparison of the chemical shifts of CC45 to those of two natural WW domains, Pin1 (ref. 28 ) and Nedd4.3 (ref. 29 ), showed that all three proteins display these same unusual shifts at analogous positions in each sequence Construction of designed sequences To evaluate the designed sequences for folding, we constructed libraries of synthetic genes for expression of the artificial proteins in Escherichia coli  Experimental analysis of designed sequences Figure 2a shows a flowchart of experiments for each WW protein Expression data for all 147 synthetic proteins are provided in Supplementary Fig. 3  Figure 1c shows a matrix representation of statistical coupling values for five different site-specific perturbations in the WW MSA that demonstrates the core results of the SCA Figure 3b , g–i shows similar data for a representative set of CC sequences Figure 3c shows thermal denaturation profiles for every soluble IC sequence ( n = 30, grey) and Fig. 3j–l shows corresponding 1 H-NMR spectra for the three IC sequences that constitute the best case scenarios by thermal melts Figure 4a summarizes the experimental analysis of all 147 WW sequences tested Figure 4b compares the unfolding enthalpy and melting temperatures derived from thermal denaturation experiments for all folded natural WW domains and CC sequences, showing that the CC sequences fall into the same range of thermodynamic parameters as their natural counterparts ( P = 0.1, multivariate analysis of variance (ANOVA)) Folding to a native state involves efficient packing of hydrophobic atoms within the interior of proteins, a factor that leads to higher average sequence conservation in the core of proteins  Four libraries were built using a DNA-oligonucleotide-based gene synthesis protocol ( Supplementary Fig. 2 ): (1) 42 natural WW sequences (N), drawn randomly from the MSA; (2) 43 IC sequences, built on the premise that conservation is strictly an intrinsic property of each site; (3) 43 CC sequences, built on the premise that conservation is a distributed property, parsed among sites in the manner described by the SCA matrix; and (4) 19 random sequences (R), in which amino acids at all sites were randomly drawn from their mean frequencies in the WW MSA Given a sufficiently large and diverse multiple sequence alignment (MSA) of a protein family, the mutual dependencies should be evident in the conserved statistical correlations between amino acid distributions at sites Given that protein structures are typically compact and well packed , proteins could be dense and complex networks of inter-atomic interactions, requiring specification of a great number of mutual constraints between amino acid positions to define the fold Here, we followed the folding reaction by monitoring the fluorescence of a buried tryptophan (Trp 7), which becomes quenched due to solvent exposure upon thermal denaturation and therefore reports the fraction of protein folded as a function of temperature (for example, Fig. 3a–c ) However, IC sequences are no different from CC sequences, showing 68.3 ± 9% mean and 95.4 ± 9.4% top-hit identities to natural sequences for core positions (mean ± s.d.) However, the IC and CC sequences also show similar ‘top-hit’ identities—the per cent identity to their closest counterpart in the natural world (55.7 ± 5.6% (IC) and 58.6 ± 7.2% (CC), P = 0.11, Kolmogorov–Smirnov test; mean ± s.d. is shown) However, the site-independent conservation model is insufficient to produce the native state However, the structural similarity of CC45 to other WW domains seems to go well beyond just the fold level In addition, all libraries contained some fraction of well-expressed and soluble proteins ( Fig. 2b , third column) In addition, several sites in CC45 display unusual proton chemical shifts based on comparison with the BioMagResBank database of protein NMR data (for example, δ = -0.38 p.p.m. for N22 Hβ2, Fig. 3g ; see Supplementary Table 1 for further examples) In contrast, no IC sequences showed evidence of native folding In contrast, over one-quarter of the CC sequences were natively folded In principle, these artificial sequences should fold into a structure representative of the family, and should function in a manner indistinguishable from their natural counterparts In the SCA, conservation at each position in the MSA is given in an energy-like statistical parameter that measures the deviation of the observed distribution of amino acids from their mean values found in all proteins ( Fig. 1b ) In the WW domain, this folding equilibrium and the consistency of the two-state approximation have been well described  In this and the accompanying paper , we test this hypothesis in a computationally and experimentally facile model system, the WW domain Indeed, as has been pointed out , the evolution-based mapping of amino acid interactions does not look like the contact graph of the protein structure; many direct packing interactions show coevolution scores close to zero, and some distant sites linked through networks of coevolving residues are predicted to be coupled Just like natural WW domains, the CC domains are marginally stable folds in which a fine balance of opposing forces probably accounts for the distinction between folded and non-folded states More surprising, however, is the finding of sparseness Natural WW domains show a range of thermal denaturation profiles ( Fig. 3a ) Natural, IC and CC WW sequences show a mean amino acid identity to all natural WW domains of ∼36%, an expected result because all of these sequences contain the same pattern of conservation at sites No IC sequences were natively folded, although a substantial fraction (70%) was soluble Not all moderately conserved positions are coupled—several other sites showing similar conservation scores (for example, positions 16, 17 or 25; Fig. 1b ) show little coevolution with the sites chosen for perturbation On the basis of the analysis of natural WW sequences, we determined rigorous criteria for folding: artificial sequences were declared as folded only if they showed cooperative and reversible thermal denaturation and 1 H-NMR spectra consistent with a native state ( Supplementary Figs 4 and 5 ) Others, such as CC45 ( Fig. 3g ) or CC18 ( Fig. 3h ), show thermal denaturation profiles that fall into the same range as natural WW domains (CC45: Δ H VH u = 32.4 kcal mol -1 , T m = 65.6 °C; CC18: Δ H VH u = 19.63 kcal mol -1 , T m = 34.3 °C), and show strong evidence in 1 H-NMR spectra of being natively folded Others, such as N22, cooperatively denature but are less stable Δ H VH u = 18.5 kcal mol -1 , T m = 25.2 °C) Perturbation experiments at all these sites simply expose the same redundant pattern of coevolution between a small set of moderately conserved positions Proteins were expressed as His 8 -tagged fusions, purified using Ni + -NTA affinity chromatography, and subjected to SDS–polyacrylamide gel electrophoresis (PAGE) analysis to evaluate expression and solubility SCA-based protein design We began by carrying out the SCA for an alignment of 120 members of the WW domain family Sixty-seven per cent of natural WW sequences were folded by the criteria described above, a number that simply reflects the efficiency of producing randomly chosen WW domains in our expression system Some, such as CC16 ( Fig. 3i ), are, like N36, soluble but not folded by either criterion Some, such as N1, are clearly well folded, showing a cooperative denaturation with thermodynamic parameters typical for WW domains (vant Hoff enthalpy Δ H VH u = 22.5 kcal mol -1 , T m = 46.8 °C, where T m is the melting temperature) Spectra for N1 ( Fig. 3d ) and N22 ( Fig. 3e ) confirm that these are indeed natively folded Still others, such as N36, despite good solubility, show no convincing evidence of a native state given the experimental conditions of the assay Studies involving directed mutagenesis , structure determination , NMR dynamics , computational modelling and literature study implicate these networks of coevolving residues in contributing to core aspects of protein function Such unusual shifts arise from unique tertiary packing that places protons in close proximity to aromatic side chains Supplementary Fig. 1 shows an example of this calculation for one site in the WW MSA Table 1 shows the comparative statistical properties of the designed sequences Taken together, the data argue that in addition to the amino acid distributions at sites, the statistical coupling information is necessary and sufficient to specify native folding Tertiary structure motifs common to WW domains are found in CC45, including a centrally located tryptophan (W7) that sits upon a platform of two proline side chains (P4, P33, Fig. 5b ) The data demonstrate that some CC sequences are natively folded with thermodynamic properties similar to that of natural WW domains, and that no IC sequences are natively folded The difference between these distributions is not significant ( P = 0.34), demonstrating that CC45 is as similar at atomic resolution to natural WW domains as natural domains are to each other. The evolutionary correlations between sequence positions are extracted by carrying out a perturbation analysis on the MSA; the conservation of amino acids at one site is perturbed (usually by restricting the site to one amino acid), and the impact of this perturbation on the conservation of amino acids at each of the other sites is measured in a distinct energy-like statistical parameter The finding that these sequences showed a greater probability of being soluble in comparison to random sequences suggests that conservation taken at sites alone may provide enough information about the folding process to permit hydrophobic collapse to a molten globule-like state The first algorithm tests the necessity of the information in the SCA matrix by building artificial sequences that preserve the amino acid composition at sites but eliminate all statistical couplings between sites The main problem is the vast potential complexity of cooperative interactions between amino acids—processes by which the free energy contribution of one residue depends on those of other residues  The natural sequences were built as positive controls because we do not know how many of these will fold when expressed as recombinant proteins in bacteria The random sequences are negative controls; they contain no site-specific information and are not expected to fold The SCA implies an unexpected degree of simplicity in amino acid interactions, with far fewer important constraints between residue pairs than would be expected from inspection of the atomic structure The second algorithm tests the sufficiency of the SCA matrix by building artificial sequences that preserve both the conservation pattern and the pattern of statistical couplings The simplicity of these findings suggests the possibility that just the frequency distribution of amino acids at sites (conservation) plus the few rules of coupling in the SCA matrix may amount to the total constraints on WW sequences These amino acid couplings could be pairwise and local in the three-dimensional structure, but could also involve more complex cooperativities in which collections of residues interact through three-way or higher-order couplings  These sequences are built using a Monte-Carlo-based simulated annealing protocol in which amino acids are completely shuffled within every column of the MSA while minimizing the difference between all coupling values in the SCA matrix for the artificial alignment and for the natural alignment These were further evaluated using thermal denaturation experiments and 1 H-NMR for evidence of a native state, as described below This finding shows that despite additional constraints in their design, CC sequences are about as diverged as IC sequences; by this measure, the number of extra constraints arising from the SCA matrix is small This method postulates that regardless of spatial location or underlying mechanism, the conserved functional coupling of sites in a protein should drive their mutual coevolution  Thus, CC45 adopts a stable WW-like three dimensional structure Thus, native folding in CC sequences is not explained by a more natural-like composition of core residues Thus, the SCA mapping provides a picture of proteins as sparsely coupled architectures with redundant strong constraints linking a few sites, and a great deal of near-independent variation at most sites Thus, this algorithm presumes that conservation can be adequately described as an intrinsic property of each site To examine how well the SCA-based design recapitulates the native structure of the WW domain, we overlaid the structure of CC45 with those of several different natural WW domains by minimizing the root mean squared deviations (r.m.s.d.) of backbone Cα atoms for all structures ( Fig. 5c ) To examine this, we calculated sequence identities within core residues (3, 7, 20, 22, 33) between CC or IC sequences and natural WW domains To implement this algorithm, we simply select amino acids at each site independently based on the observed frequency distribution in the natural alignment To provide independent support for categorization of these denaturation profiles as folded or not folded, we collected 1 H-NMR spectra for a representative sampling of natural WW proteins To quantify this result, we compared the average pairwise r.m.s.d. values for backbone atoms of all the natural WW domains (1.52 ± 0.4 Å) with the r.m.s.d. values of CC45 from all the natural domains (1.19 ± 0.65 Å) To test the overall hypothesis, we reasoned that if (and only if) the information contained in the SCA is a good estimate of the total sequence information for specifying a protein, it should be possible to computationally build artificial members of the protein family using no information except the SCA-based parameters of sequence conservation and coupling To test this idea, we developed two computational algorithms for designing novel protein sequences using only SCA information We solved the three-dimensional structure of CC45 by solution NMR methods, using 800 distance and dihedral angle restraints ( Fig. 5a , b ; see also Supplementary Table 2 ) We tested all 105 well-expressed and soluble proteins from the four sequence libraries for cooperative and reversible thermal transitions ( Supplementary Fig. 4 ); a representative sampling of these data is shown in Fig. 3  WW domains are small, independently folding protein interaction modules that adopt a curved three-stranded β-sheet configuration and bind to proline-containing target sequences ( Fig. 1a )
 Here, we show that peak virus production in gut tissues of SIV-infected rhesus macaques coincides with peak numbers of infected memory CD4 + T cells In addition to inducing immune activation and thereby providing activated CD4 + T-cell targets to sustain infection, virus production also triggered an immunopathologically limiting Fas–Fas-ligand-mediated apoptotic pathway in lamina propria CD4 + T cells, resulting in their preferential ablation In early simian immunodeficiency virus (SIV) and human immunodeficiency virus-1 (HIV-1) infections, gut-associated lymphatic tissue (GALT), the largest component of the lymphoid organ system , is a principal site of both virus production and depletion of primarily lamina propria memory CD4 + T cells; that is, CD4-expressing T cells that previously encountered antigens and microbes and homed to the lamina propria of GALT  Surprisingly, most of the initially infected memory cells were not, as expected , activated but were instead immunophenotypically ‘resting’ cells that, unlike truly resting cells, but like the first cells mainly infected at other mucosal sites and peripheral lymph nodes , are capable of supporting virus production The scale of this CD4 + T-cell depletion has adverse effects on the immune system of the host, underscoring the importance of developing countermeasures to SIV that are effective before infection of GALT. Thus, SIV exploits a large, resident population of resting memory CD4 + T cells in GALT to produce peak levels of virus that directly (through lytic infection) and indirectly (through apoptosis of infected and uninfected cells) deplete CD4 + T cells in the effector arm of GALT After de-paraffinization in xylene, rehydration in PBS and permeabilization by treating the sections with HCl, digitonin and proteinase K, the sections were acetylated and hybridized to 35 S-labelled SIV-specific riboprobes After rinsing, TUNEL-positive cells were stained with converter-POD reagent and DAB substrate. After washing and digestion with RNases, sections were coated with nuclear track emulsion, exposed, developed and counterstained with Giemsa After washing, the sections were coated with nuclear track emulsion, exposed, developed and counterstained with haematoxylin Briefly, 6–8-µm sections were cut and adhered to silanized slides Briefly, sections were microwaved for antigen retrieval, hybridized, washed and digested with RNases, incubated with antibody markers for cell type—naive CD45RA + and CD45RO + memory CD4 + T cells (anti-OPD4, ref. 25 )—activation (CD69 and CD25) and proliferation (Ki67), and then stained with diaminobenzidine (DAB) with the the Dako Envision and Peroxidase kit CD4 + T cells and CD4 +  Ki67 + cells were manually counted using a grid in Photoshop 7.0 in 30 serially captured images Cell nuclei were counterstained blue with TOTO-3 Colon tissue used in the studies described here was obtained from 14 out of 30 animals necropsied from 2 h to 28 days after inoculation For quantification, sequential images at wavelengths for each fluorophore, collected using a Bio-Rad MRC 1000 Confocal Microscope at ×60, were automatically processed with an action program in Adobe Photoshop 7.0 Immunofluorescence and CD4 + and Ki67 + CD4 + cell counts Sections were stained with primary antibodies to CD4, CD8, Ki67 and activated caspase-3, and secondary antibodies were labelled with Alexa Fluor 488 (green) and Alexa Fluor 555 (red) Immunohistochemical staining and in situ hybridization Combined immunohistochemical staining and in situ hybridization were performed as described previously  In situ cell death detection by TUNEL assay Endogenous peroxidase in tissue sections was blocked with 3% H 2 O 2 in methanol In situ hybridization and quantification of SIV RNA + cells SIV RNA was detected in cells in formalin-fixed and paraffin-embedded tissues as previously described  Methods SIV-infected animals Adult female rhesus macaques ( Macaca mulatta ), housed at the California National Primate Research Center in accordance with the regulations of the American Association of Accreditation of Laboratory Animal Care standards, were inoculated intra-vaginally with 2 × 10 5 50% tissue culture infectious dose (TCID 50 ) of SIVmac251 or SIVmac239 (ref. 24 ) Quantification of doubly labelled cells The proportions of SIV RNA-positive Ki67 + or Ki67 - cells ( Fig. 3b ) were determined by enumerating 100 single- and double-labelled cells in sections after in situ hybridization and immunohistochemical staining to detect SIV RNA and Ki67 Sections were then incubated at 98 °C in 100 mM citrate buffer, pH 6.0, cooled, immersed in 3% normal sheep serum in TNB blocking buffer (0.1 M TRIS-HCl, pH 7.5, 0.15 M NaCl, 0.5% blocking reagent ( Dupont )) and incubated at 37 °C in a TUNEL reaction mixture ( Roche ) SIV RNA-positive cells were automatically enumerated in sections of defined areas using MetaMorph software The number of cells per mm 2 ( Fig. 3f ) was determined from these proportions and the number of CD4 + T cells per mm 2 determined as described above About 90% of the SIV RNA-positive cells in both lamina propria and follicular aggregates were CD4 + T cells (data not shown), of which 95% were CD45RO + memory cells ( Fig. 3a ) Additional studies will be needed to determine whether the cause of decreased virus production despite replication in activated cells is related to cytotoxic T lymphocyte responses to other epitopes, cytokine-mediated suppression of viral replication, or other mechanisms Again, these changes were selective for lamina propria Although elimination of infected cells by virus-specific cytotoxic T lymphocytes responding to immunodominant epitopes in Gag and Tat (which constitute about 70% of the cytotoxic T lymphocyte response in acute SIV infection of Mamu A*01 animals (ref. 21 )) is another possible reason for the decrease in SIV RNA production, it is unlikely because, as we show elsewhere, responses to these epitopes are minimal or undetectable in colon  Although infection of activated CD4 + T cells provides a mechanism to sustain virus production, the levels of viral RNA and frequency of infected cells fall despite higher levels of replication in activated cells; for example, in snapshots of infection in vivo , infected activated cells are enveloped by five times as many virions compared to resting cells  Although most of the SIV RNA-positive cells were memory CD4 + T cells, direct typing of the infected cells in tissue sections revealed that they were not mainly activated and proliferating, contrary to previous proposals  Although there were SIV RNA-positive cells at both sites, massive depletion of CD4 + T cells was confined to lamina propria ( Fig. 2 ) Although they have about fivefold lower levels of SIV RNA per cell and cell-associated viral particles compared with infected, activated CD4 + T cells in tissue section ‘snapshots’, these infected resting cells outnumber the infected activated cells by an order of magnitude and are the major contributor to the peak virus production of early infection (see below) As described in detail elsewhere , virus production, measured as copies of SIV RNA per microgram of tissue RNA, peaked at day 10 after inoculation, and then declined about 20-fold by day 28 after inoculation, the last time point examined At peak levels, only 7% of the CD4 + T cells were SIV RNA-positive, and the total number of both resting and activated cells infected and lost from days 6–28 after inoculation could have accounted for at most 20% of the depletion of ∼800 CD4 + T cells mm -2  At peak viral production (day 10 after inoculation), 91–93% of the SIV RNA-positive memory CD4 + T cells in colon displayed the CD69 -  CD25 -  Ki67 - phenotype ( Fig. 3b–d ) Because SIV and HIV-1 can productively infect recently activated but ostensibly resting memory CD4 + T cells, they can take immediate advantage of the availability of a large population of susceptible targets in the mucosal immune system By what mechanisms are CD4 + T cells depleted in the lamina propria of GALT? Death via cytopathic effects of viral replication in productively infected cells certainly contributes to depletion, but this mechanism alone cannot account for the preferential depletion of lamina propria versus follicular GALT or the magnitude of the depletion in lamina propria CD4 + T-cell depletion is then thought to be the result of infection and subsequent killing of this large pool of susceptible hosts Depletion of CD4 + T cells in lamina propria, already detectable at day 6 after inoculation, continued at a rapid rate between days 8 and 14 after inoculation and reached a plateau that was about 70% below baseline levels ( Fig. 1 ), corresponding to the selective loss of essentially the entire lamina propria CD45RO + memory CD4 + T-cell population ( Fig. 3 ) Furthermore, because lamina propria cells are at a ‘tipping point’ to undergo apoptosis as a regulatory mechanism to maintain the balance between host defence and the immunopathological consequences of prolonged activation of effector cells, exposure to large quantities of gp120 on virions triggers the apoptotic pathway on a correspondingly large scale, resulting in the preferential and nearly complete loss of CD4 + T cells in the effector arm of GALT In sexual mucosal transmission, these target cells at portals of entry enable these viruses to initially establish founder populations of infected cells that will seed and establish infection throughout the secondary lymphoid organ system In the follicular aggregates, in which there are both naive CD45RA + and memory CD4 + T cells, all of the SIV RNA-positive cells were also CD45RO + memory cells (data not shown) In the substrate availability model , relatively large numbers of ostensibly resting memory CD4 + T cells are preferentially infected in early infection because they constitute the largest population of susceptible target cells available for propagation of infection Instead, we suspected, for the following two reasons, that large numbers of lamina propria CD4 + T cells were being selectively eliminated by Fas–Fas-ligand-mediated apoptosis of this population: (1) lamina propria T cells are particularly prone to Fas-mediated apoptosis as a normal immunoregulatory mechanism to control activation and inflammation in the gastrointestinal tract ; and (2) because lamina propria CD4 + T cells selectively upregulate Fas and Fas ligand when exposed in vitro to recombinant envelope gp120 (ref. 14 ), enhanced expression in vivo of Fas and Fas ligand would be expected in large numbers of lamina propria CD4 + T cells exposed to virion gp120 during peak virus production Moreover, this infected, activated population did not increase substantially despite the increased proportion of Ki67 +  CD4 + T cells (illustrated in Fig. 2 ); this was partly due to depletion of, and thus an overall decrease in, the number of uninfected Ki67 +  CD4 + T-cell targets in the colon ( Fig. 3f ) One hypothesis originally advanced to account for this early, preferential depletion of memory CD4 + T cells in GALT is that a large proportion of this population is activated in GALT, because of constant antigenic stimulation, and thus presents the virus with a favoured target cell for replication One reason that this is not the case is that CD4 + T-cell depletion markedly reduces the size of the population of susceptible cells available for infection, and also the spatial proximity of infected to susceptible cells Substrate exhaustion of this pool of resting T-cell targets, which is capable of supporting replication, is then responsible for the 20-fold decrease in SIV RNA levels from the peak (day 10 after inoculation) to last point examined (day 28 after inoculation)—the infected, resting CD4 + T cells are eliminated and not replaced owing to the state of heightened immune activation that ensues as a result of early virus production The extent and rapidity of depletion of CD4 + T cells in this major lymphatic tissue compartment in both SIV and HIV infections is in our view one major reason to focus on developing countermeasures to attack these viruses at or shortly after transmission, particularly in cervico-vaginal tissues, the globally predominant portal of entry for HIV-1 (ref. 23 ). The GALT compartment probably has a particularly important role in viral production in early infection for two reasons: (1) its size (GALT comprises most (∼ 60%) of the secondary lymphoid organ system ); and (2) the large number of recently activated memory CD4 + T cells that, with current markers, appear to be resting but in fact are in a state in which they can be productively infected The latter factor is probably important in efficiently propagating infection in vivo inasmuch as infected cells at peak production are clustered to within one to two cell diameters of one another  The peak in SIV RNA at day 10 after inoculation coincided with the peak number (55 cells mm -2 ) and proportion (93%) of these resting SIV RNA-positive Ki67 -  CD4 + T cells ( Fig. 3e , g ) and with the initial predominance of uninfected Ki67 - over Ki67 +  CD4 + T cells ( Fig. 3f ) The proportion of SIV RNA-positive activated and proliferating Ki67 +  CD4 + T cells reciprocally increased, from 10% at day 10 to 90% at day 28 after inoculation ( Fig. 3g ), but at peak was only one-tenth the size of the infected resting population The resulting infected cell population then decayed with a half-life of 4 days, to less than 1 cell mm -2 at day 28 after inoculation ( Fig. 3e ), in parallel with the contraction in size of the uninfected Ki67 -  CD4 + T-cell population ( Fig. 3f ) These shifts in infected and uninfected populations, and post-peak declines in viral RNA levels and numbers of infected cells, are in accord with the predictions of models of substrate availability and exhaustion  This provides a larger proportion of activated CD4 + T cells, and results in a higher proportion of activated CD4 + T cells that expresses SIV RNA, corresponding to the increased availability of these cellular targets ( Fig. 3f , g ) This viral peak coincided with the peak in SIV RNA-positive cells ( Fig. 1 ), in both the follicular inductive and diffuse effector arms of GALT ( Fig. 2 ) Thus, most of the first cells productively infected in GALT are memory CD4 + T cells; these cells are neither activated nor proliferating according to available markers, similar to most cells initially infected in cervico-vaginal mucosa and peripheral lymph nodes  Thus, virus production might be expected to increase We also documented increased expression of the mediators of T-cell apoptosis (Fas and Fas ligand) in lamina propria; this expression paralleled the time course and increase in number of apoptotic cells ( Fig. 4b , e–j ) as well the rapid decrease in the number of CD4 + T cells between 8 and 14 days after inoculation ( Fig. 2d–g ) We characterized the SIV RNA-positive cells with markers of T-cell activation and proliferation used in other studies of target cells in primary SIV infection : CD69, a marker of early activation displaying transient expression , and CD25 and Ki67, markers for which expression is sustained in activated and proliferating cells We documented marked increases from baseline levels in CD4 + , but not CD8 + , T cells undergoing apoptosis in lamina propria ( Fig. 4a–d ), which paralleled the depletion of CD4 + T cells there, but only minimal increases in apoptosis in follicular GALT, where CD4 + T-cell depletion was insignificant (data not shown) We focused our analysis on the colon as representative of GALT with organized inductive sites in scattered follicular aggregates and effector sites in lamina propria We have hitherto proposed that the main role of these resting cells is as ‘placeholders’, maintaining unbroken chains of transmission until immune activation supplies activated CD4 + T-cell targets enabling SIV and HIV-1 to replicate to higher levels  We have shown that these resting cells contribute substantially to peak virus production, which incites immune activation to supply activated CD4 + T cells to sustain infection We investigated virus production and mechanisms of CD4 + T-cell depletion in GALT of rhesus macaques infected intra-vaginally with the SIVmac251 virus We now show that infected resting T cells actually contribute substantially to peak virus production because of the relatively large number of these cells that are initially available and infected We refer to these cells as resting, because we believe that they are a recently activated population retaining—as they return to a resting state—sufficient levels of CCR5 co-receptor, nucleotide pools and transcriptional activators to enable them, unlike truly quiescent CD4 + T cells, to support productive infection  We revise these models here to reflect a new characterization of the exhausted substrate as resting rather than activated CD4 + T cells, the loss of which was originally proposed to be the mechanism responsible for reduction in plasma viraemia in the acute stage of HIV-1 infection  We sought evidence for the suspected selective apoptosis of CD4 + T cells in lamina propria compared with follicular GALT by monitoring changes in the proportion of TdT-mediated dUTP nick end labelling (TUNEL)-positive and activated caspase-3-positive T cells We tested this hypothesis by characterizing the types and activation state of productively infected cells
 Although observations of afterglows continue to refine our understanding of GRB progenitors and relativistic shocks, γ-ray observations alone have not yielded a clear picture of the origin of the prompt emission nor details of the central engine Here we report the discovery of infrared emission contemporaneous with a GRB, beginning 7.2 minutes after the onset of GRB 041219a (ref. 8 ) Only one concurrent visible-light transient has been found and it was associated with emission from an external shock Our analysis of the initial infrared pulse suggests an origin consistent with internal shocks. The explosion that results in a cosmic γ-ray burst (GRB) is thought to produce emission from two physical processes: the central engine gives rise to the high-energy emission of the burst through internal shocking , and the subsequent interaction of the flow with the external environment produces long-wavelength afterglows  We acquired 21 images during the active phase of the burst, yielding early multi-colour observations A consequence of this interpretation is that, in the absence of effects due to collimation of the burst, radio afterglow emission should be dominated by a rising reverse shock, peaking at time t = (10.2 ± 1.8)( ν /8.4) -35/54 d where ν is in GHz; this is thus far confirmed with reports of rising radio emission at least to day 2.9 (ref. 23 ) A delayed reverse shock crossing time requires , where n is the circumburst particle density in units of baryons cm -3 , E 52 is the energy in the shock in units of 10 52 erg, Δ t is in units of seconds and the redshift of the burst is z  Additionally, there is some evidence that the IRT was redder during the ‘flash’ event at t + 7.2 min Alternatively, the observed variability could be due to inhomogeneous density structure in the circumburst environment or delayed energy injection into the blastwave An optical flash was also detected by the RAPTOR experiment during the prompt γ-ray emission  As even moderate levels of dust near the GRB or along the line-of-sight in the host galaxy could effectively suppress detectable optical emission , contemporaneous observations at infrared (IR) wavelengths, where light suppression is relatively minimized, offer a natural means to uncover any prompt emission As viewed by BAT, the burst duration (Δ t ) above background was 520 s and was very bright, with up to 6.5 × 10 4 counts s -1 (unsaturated) between 15 and 350 keV and a fluence of 1.15 × 10 -4 erg cm -2  Associating peak 2 with the reverse shock and peak 3 with the forward shock, we find reasonable agreement, to within the measurement uncertainties, of the data with this model At 1.3 m in diameter, it is one of the largest, completely autonomous telescope systems in the world and one of only a few capable of imaging at IR wavelengths (1.1–2.3 µm; see ref. 14 ) Consistent within the astrometric accuracy of the IRT from 19 December, we found a point-like source in J-band ( Fig. 1 ) Despite very poor observing conditions (sustained 40 m.p.h. winds, variable sky transmission, and 4″ seeing), comparison of the first epoch of data revealed a new, variable source not visible in the 2MASS (Two Micron All Sky Survey) catalogue images of the field During the first few days, the source colours, though rather uncertain, appear consistent with a single value of the spectral slope of β ≈ 0.4 ( Fig. 4 ) First, we would expect the source to have become bluer during the forward shock rise, which is not required (though is not excluded) by our data Future observations of IR flashes in the Swift era will no doubt test the ubiquity and nature of rapidly variable early-time emission as reported here GRB 041219a triggered the IBIS instrument on board the INTEGRAL satellite on 19 December 2004 at 01:42:54 UTC , which was reported at 01:44:05 UTC  How might the light curve be understood as emission from the reverse and forward shock? The electrons in the shock are assumed to be accelerated to a power-law spectrum with number density as a function of energy ( E ) proportional to E - p  If Swift had not still been in its commissioning phase with slewing disabled, the spacecraft could have slewed to the location within 70 s of the BAT trigger In a constant-density circumburst environment, a reverse shock is expected to rise rapidly ( α = 3 p - 3/2, with flux density f ν ∝ t α ) and then, in the ‘thin shell’ case (see below), decline with α = -(27 p + 7)/35 ≈ - 2 after the emission peak, corresponding to the time ( t × ) that the reverse shock crosses the explosion ejecta In addition, we obtained deep J-band imaging on 20 and 21 December utc using the NIRC-1 instrument on the Keck I 10-m telescope on Mauna Kea, Hawaii In particular, the three implied values for p (2.5 ± 1.1, 4.2 ± 4.1, 2.6 ± 0.2, for the reverse-rise, reverse-decline, and forward-decline, respectively) are all consistent with the usual range of p = 2.2–2.5 In total, 5,790 images were acquired by the system over these nights Indeed, four GRBs have exhibited transient optical emission that could be associated with reverse shocks, but early-time optical transients have not been found for the vast majority of bursts (however, new larger-aperture robotic optical systems have met with increasing success) Indeed, if the IR emission is due to internal shocks, then the observed flash may be due to a superposition of several unresolved shorter-timescale pulses Note added in proof: Some of our additional independent photometric analyses of the first event also reveal a rapid decline but show less evidence for a rapid rise than shown in Fig. 2  Over these two nights, that source was seen to fade by 1.0 mag, confirming its identification with the IRT PAIRITEL acquires images with high temporal cadence (integration times of 7.8 s) in three colours simultaneously PAIRITEL began to slew on 19 December 2004, 01:48:20 utc , and the first observations of the GRB field commenced 58 s later PAIRITEL observations of the transient continued over the following three nights, until inclement weather in Arizona precluded additional observations Prompt long-wavelength afterglow emission is predicted to arise when the reverse (external) shock encounters the ejecta of the explosion , or through γ-ray heating of the circumburst material  Regardless of the interpretation of events 2 and 3, the rapid rise and fall appear to preclude an association with a reverse shock: the fit of a power-law decay slope to the K s data acquired less than 10 min from burst trigger yields α = -18 ± 5, whereas setting α = -2, as expected of a reverse shock, yields an unacceptable fit (reduced χ  2 = 4.4) Since we based our conclusions on the nature of that event primarily on the later-time imaging and the rapid fall behaviour, the interpretation is largely unchanged by various analyses. Such emission is possible if the synchrotron cooling frequency from the internal shock emission is well below γ-ray frequencies  The Burst Alert Telescope (BAT) on the Swift satellite triggered and located GRB 041219a on board at 01:42:18 UTC with a position that was within 4′ of the IR source The duration of the IR flash (δ t ≈ 45 s, taken as the full-width at half-maximum of the model fit to the data) is comparable to the widths of the largest timescale for substructure in γ-rays; indeed, this δ t is remarkably similar to that of the optical pulse in GRB 990123 The field of view is rather large, 8.5′ × 8.5′, for IR imaging, allowing for follow-up of GRB localizations of even modest precision The first six PAIRITEL exposures at t + 7.2 min after the trigger show a source that brightens, then fades very rapidly in all filters by about t + 9 min, and then rebrightens by t + 20 min The ground-based BAT location (RA 00 h 24 min 37.0 s, dec. +62° 50′ 49.2″) was within 48″ of the IR source The initial position of right ascension (RA) 00 h 24 min 26 s, declination (dec.) +62° 50′ 06″ was refined to 2′ uncertainty at 01:47:49 UTC and a final offline location was reported at 03:31:58 UTC  The IR emission from the forward shock should rise slowly as α = 0.5, then decline as α = 3(1 - p )/4 The Keck images revealed two sources within 2.5″ of the transient position (S1; J ≈ 19.7 mag, 2.5″ north-north-east: S2: J ≈ 21.4 mag, 1.5″ east): both were unresolved apparent point sources The ratio of the width to the time after trigger t ≈ 462 s, δ t / t = 0.10, is similar to that seen in individual pulses in bright GRBs but a factor of ∼10 smaller than the δ t / t of the optical flash of GRB 990123 The resulting light curves (see Supplementary Table 1 ) shown in Fig. 3 reveal a complex time history of the afterglow The second puzzle concerns the timing of the reverse shock peak relative to the GRB duration The source S1 is bright enough to contaminate the PAIRITEL J-band aperture photometry on 21 December, which accounts for the difference between our measurements and the fainter measurements from Apache Point Observatory (APO) and Keck on the same date The third and most intriguing puzzle is the physical origin of the IR flash at t 1 = 462 s that has marginal evidence for appearing more red than the afterglow at later times (here the subscript 1 refers to the first peak in the light curve) The time evolution of the count rate in four BAT channels covering 15 to 350 keV is reproduced in Fig. 2  This deceleration time occurs when the shock has swept up from the circumburst environment a quantity 1/ Γ  0 times the entrained mass, where Γ  0 is the terminal Lorentz factor of the shock This initial Lorentz factor constraint is uncomfortably smaller than the limits placed on previous values of Γ  0 , which suggests that either the burst occurred at high redshift (which is excluded by the RAPTOR detection ), was exceptionally energetic, or occurred in a low-density environment This was one motivation for our construction of the Peters Automated Infrared Imaging Telescope (PAIRITEL; Fig. 1 ) Using our data and data reported in the literature, we fitted the light curves as the sum of three smoothly connected rise and fall brightening events; the results of these fits are shown in Fig. 3  We expect   t ×  = 1,670 s Δ t only when Δ t is less than the time when the shock begins to decelerate (commonly deemed the ‘thin shell’ case) We suggest, therefore, that the origin of the first peak is from the internal shock that itself produced the GRB When compared to the astrometric grid of 2MASS stars in the field, we find the absolute position of the IR transient (IRT) to be RA 00 h 24 min 27.68 s ± 0.124″, dec. +62° 50′ 33.501″ ± 0.228″, with its uncertainty dominated by the mapping to 2MASS catalogue stars When comparing PAIRITEL photometry with higher-resolution Keck and APO results for 21 December, the flux from S1 + S2 appears to be a 51% contamination in H band, 58% in J band, and has negligible contribution in the K s band With this interpretation, there are three puzzles
 Although much is known about the neural representation of simple visual stimulus features (for example, orientation, direction and colour), relatively little is known about how the brain learns and encodes the meaning of stimuli Categorization is a process by which the brain assigns meaning to sensory stimuli Here we show that neurons in LIP—an area known to be centrally involved in visuo-spatial attention , motor planning and decision-making —robustly reflect the category of motion direction as a result of learning In contrast, neurons in area MT were strongly direction selective but carried little, if any, explicit category information The activity of LIP neurons encoded directions of motion according to their category membership, and that encoding shifted after the monkeys were retrained to group the same stimuli into two new categories This indicates that LIP might be an important nexus for the transformation of visual direction selectivity to more abstract representations that encode the behavioural relevance, or meaning, of stimuli. Through experience, we learn to group stimuli into categories, such as ‘chair’, ‘table’ and ‘vehicle’, which are critical for rapidly and appropriately selecting behavioural responses  We trained monkeys to classify 360° of visual motion directions into two discrete categories, and compared neuronal activity in the lateral intraparietal (LIP) and middle temporal (MT) areas, two interconnected brain regions known to be involved in visual motion processing  All surgical and experimental procedures followed Harvard Medical School and National Institutes of Health guidelines Area MT neurons were distinguished by direction-selective responses to moving spots and bars, and RF sizes that were roughly proportional to their eccentricity  Data analysis All analyses (except error trial analyses) were conducted across correct trials DMC task Monkeys were trained to indicate whether a test stimulus was in the same category as a previously presented sample stimulus During LIP recordings, electrode penetrations sequentially encountered both the medial and lateral banks of the IPS During recordings from monkey H we excluded the four test stimuli closest to (15°) the category boundary where the monkey made the greatest number of errors It was determined for each neuron by computing two values: the average WCD in firing rates between pairs of directions in the same category, and the average BCD in firing rates between pairs of directions in different categories ( Supplementary Information ) LIP neurons were not prescreened for direction selectivity Methods Physiological techniques Two male rhesus monkeys ( Macaca mulatta , weighing about 14 kg) were implanted with a head post, scleral search coil and recording chamber Monkeys average reaction times on correct match trials were 349 ms (monkey S) and 368 ms (monkey H) Most IPS neurons were tested with a memory-saccade task and a passive viewing flash-mapping task to generate detailed spatial maps of neuronal response fields (RF) Neurons were considered to be in LIP if they showed spatially selective delay activity during the memory saccade task or were located between such neurons in that electrode penetration Recording chambers were implanted in accordance with coordinates (approximate centres at P3, L10) determined by magnetic resonance imaging, and allowed access to both the intraparietal sulcus (IPS) and superior temporal sulcus by means of a dorsal approach Stimuli were always centred in the RF of the neuron under study Stimuli were circular patches (9.0° in diameter) of high-contrast square dots that moved in 1 of 12 evenly spaced directions (30° apart) with 100% motion coherence and at a speed of 12.0° s -1  The index was computed according to the currently relevant category boundary, allowing the data sets with each category boundary to be combined and analysed together. The index was computed with the formula (BCD - WCD)/(BCD + WCD) and could vary from -1.0 to 1.0 The monkeys could not predict whether a given trial would require a release to the first test stimulus The pattern of behavioural and neuronal results was similar, and all main effects were observed in both monkeys The precise timing of analysis windows was not critical; similar results were obtained with a variety of window widths and starting points The strength of neuronal category selectivity was estimated by a category-tuning index Trials began with the onset of a 0.25° spot, which monkeys were required to fixate within ± 1.5° for the duration of the trial A majority of LIP neurons (122 of 156; 78%) showed activity that differed across the 12 motion directions during the sample ( n = 115) and/or delay ( n = 61; one-way analysis of variance (ANOVA) across 12 directions, P 0.01) A striking number of these neurons were category selective: their activity reliably grouped the 12 motion directions according to their category membership Across the entire LIP population ( n = 156), responses to directions in the same category were more similar than to directions in different categories Across the entire MT population, WCD and BCD values were not significantly different during the sample (WCD, 21.49 Hz; BCD, 22.66 Hz; paired t -test, P = 0.61; Supplementary Fig. 2a ) After retraining the monkeys on the new categories, neuronal activity (across 64 neurons tested with the new category boundary) no longer reflected the old category boundary but was best divided by the new, now relevant, boundary ( Fig. 4c , d ) After retraining the monkeys to group the same stimuli into two new categories, LIP selectivity shifted markedly to encode the motion directions according to the newly learned categories After retraining, neurons reflected the new categories and not the old (now irrelevant) categories After sample offset, category tuning waned somewhat but became progressively stronger across the delay, reaching peak values during the late delay and early test, when the monkey presumably prepared to compare the test category with that of the previously presented sample After training, the monkeys correctly categorized sample stimuli that were 75° or 45° from the category boundary with greater than 90% average accuracy, and performed at more than 70% correct for stimuli closest to (15°) the boundary ( Fig. 1c ) Among neurons recorded with the original boundary (92 neurons from both monkeys), sample and delay activity for most neurons was best classified by the actual category boundary that the monkeys were using and not the other five ‘irrelevant’ boundaries ( Fig. 4a , b ) Because area LIP is known to be involved in both sensory and cognitive functions , it is well positioned for a function in transforming sensory information to more abstract, and meaningful, representations of visual stimuli. By using this task design, lever releases signalled ‘match’ and were not directly linked to either category Category effects were evident within 100 ms of sample onset and persisted throughout the sample Category-index values can vary from -1.0 to 1.0, where positive values indicate larger differences for directions in different categories and negative values larger differences within each category (Methods and Supplementary Information ) During both epochs, the mean category indices were shifted towards positive values (sample: mean 0.125, t -test, P ≈ 10 -11 ; delay: mean 0.180, P ≈ 10 -15 ), with stronger category tuning during the delay than sample (paired t -test, P = 0.019) During the delay, no MT neurons (0 of 67) were selective for the direction of the previously presented sample, and WCD and BCD did not differ from one another (WCD, 2.92 Hz; BCD, 2.93 Hz; paired t -test, P = 0.93; Supplementary Fig. 2b ) During the sample, nearly all (66 of 67; 99%) MT neurons distinguished between the 12 directions (one-way ANOVA, P 0.01) Figure 2 shows the activity of three category-selective LIP neurons Figure 3e shows the time course for 122 neurons that were direction-selective during the sample and/or delay For example, studies of shape categorization in inferior temporal cortex found enhanced selectivity for task-relevant features or shapes as a result of learning, but did not show more explicit signals about category membership  For quantitative analyses of neuronal activity, we focused on three time epochs, the ‘sample’, ‘delay’ and ‘test’ For the 115 LIP neurons that were direction selective across all 12 directions during the sample, the majority (92 of 115; 80%) also distinguished between the six directions within one or both of the two categories However, for the 61 direction-selective neurons during the delay, a significantly smaller proportion (26 of 61, or 43%) differentiated between the six directions within either category ( χ  2 test, sample versus delay, P = 0.02) However, MT responses did not systematically discriminate between categories ( Supplementary Fig. 1 ) However, this direction selectivity was closely related to the distinction between categories If the test was a non-match, another delay (150–250 ms) occurred; this was followed by an additional test (650 ms), which was always a match to the sample (and required a lever release) In addition, we did not detect an obvious relationship between LIP activity and reward probability ( Supplementary Information ) In contrast, category tuning was not observed across the MT population ( n = 67 neurons; Supplementary Fig. 1 ) In contrast, nearly all MT neurons (66 of 67; 99%) were selective between the six directions in either category during the sample epoch In contrast, neurons in area MT, an important stage of visual motion processing that provides input to LIP , were highly direction selective but did not group directions according to their category membership It is notable that information about the category of the previously presented sample stimulus was strongest during the early test epoch, although the sample was presented 1 s earlier and the monkey was currently viewing the test stimulus LIP neurons responded more similarly to motion directions of the same category even when those directions were visually dissimilar, and they discriminated sharply between visually similar directions of different categories LIP selectivity shifted markedly with retraining Mean category-tuning indices during both the sample (mean index 0.015) and delay (mean index 0.008) were not significantly different from zero ( t -tests; sample, P = 0.73; delay, P = 0.61; Supplementary Fig. 2c, d ) Monkeys performed a delayed-match-to-category (DMC) task ( Fig. 1b ) in which they viewed a sample stimulus (650 ms) followed by a delay (1,000 ms) and a test stimulus (650 ms) Monkeys were trained to group 12 directions of motion into two categories that were separated by a learned ‘category boundary’ ( Fig. 1a , black dotted line) Note that each of these neurons showed sharper (that is, binary-like) category selectivity during the delay than during the sample On a given trial, the sample and test could each be any one of the 12 directions of motion (see Methods) Selectivity for the test stimulus and match/non-match effects were analysed over an interval of 275 ms beginning 75 ms after test stimulus onset ( Supplementary Information ) Stronger category-tuning indices during the delay were apparently due to tighter clustering of responses to directions within each category and larger differences between categories The 12 traces correspond to the 12 motion directions used as samples, and are coloured red or blue according to their category membership The delay epoch (800 ms duration) began 500 ms after the beginning of the delay (to exclude responses related to sample offset) and included the first 300 ms of the test epoch (because many LIP neurons carried information about the sample stimulus even during the test epoch; see below) The distributions of category-tuning indices across the entire LIP population ( n = 156) are shown in Fig. 3c , d  The exact nature of the role of LIP during learning, and whether changes in the directional representations of LIP are stable or vary dynamically with the demands of the task, remain to be determined The neuron in Fig. 2a responded more strongly, during the delay, to directions in category 2 The neuron in Fig. 2b preferred sample directions in category 2 during the sample, delay and test, whereas the neuron in Fig. 2c preferred directions in category 1 during the sample, delay and test The pale red and blue traces indicate the four directions closest to (15°) the category boundary The positive shift of LIP category indices indicates that the distribution of preferred directions became highly non-uniform as a result of training in the categorization task (see below and Methods) The sample epoch (675 ms duration) began 75 ms after sample onset and ended 100 ms after sample offset This demonstrates a profound learning-based plasticity of visual representations in LIP, beyond that typically seen in striate or extrastriate visual cortex , and indicates that LIP is probably important in encoding the behavioural relevance, or meaning, of visual-motion stimuli This trend is evident in the example neurons in Fig. 2a–c  This was evident during both the sample ( Fig. 3a : WCD, 6.22 Hz; BCD, 8.72 Hz; paired t -test, P ≈ 10 -9 ) and delay ( Fig. 3b : WCD, 2.62 Hz; BCD, 4.42 Hz; P ≈ 10 -11 ) Thus the responses tended to become more ‘binary’ during the delay, reflecting category membership To assess the time course of LIP category tuning in more detail, we computed a ‘sliding’ category-tuning index (window width 100 ms, step size 50 ms) To confirm this, for each neuron we computed two separate one-way ANOVAs ( P 0.01, with Bonferroni correction) that compared responses to the six directions in each category To ensure that LIP category effects were due to learning the DMC task, we retrained both monkeys to group the same 12 directions into two new categories separated by a category boundary perpendicular to the original boundary ( Fig. 1a , green dotted line) To evaluate whether individual neurons responded more similarly to directions within than between categories, we computed two parameters: a within-category difference (WCD) and a between-category difference (BCD) in average firing rates to the 12 sample directions (Methods, and Supplementary Information ) To measure the strength of neuronal category selectivity, we constructed a category-tuning index by taking the difference between BCD and WCD and dividing by their sum To quantify this effect, we determined which of six possible category boundaries (which divided the 12 directions into two equal groups) resulted in the greatest difference between average neuronal activity among the six directions on each side of the boundary To receive a reward, the monkeys had to release a lever if the test was in the same category as the sample Together these results indicate that training monkeys to perform a motion-categorization task causes neurons in LIP to strongly and robustly reflect the category membership of visual motion direction We also recorded from 67 middle temporal (MT) neurons (monkey S, n = 40; monkey H, n = 27) during DMC task performance We recorded from a total of 156 LIP neurons from two monkeys (monkey S, n = 92; monkey H, n = 64) during DMC task performance Whereas recent studies found categorical representations in the prefrontal cortex , a frontal lobe area involved in more ‘executive’ functions , it has been unclear whether neurons in brain areas considered to be more involved in sensory processing could encode category information
 A sensitive auditory system confers a tremendous evolutionary advantage, as it protects us from the things we fear most — those we cannot see At most fast synapses, the transmembrane protein synaptotagmin I is thought to be the calcium sensor of fast, synchronized neurotransmitter release  Both mice and humans suffer from an inherited form of deafness called DFNB9 Calcium is a common signalling molecule in the nervous system and elsewhere Defects in otoferlin are responsible, and Roux and colleagues hypothesized that otoferlin might be involved in the correct operation of the synapse between the hair cell and the afferent nerve fibre Ferlin family members in non-neuronal cells have been identified as participants in membrane fusion events related to membrane repair  Finally, Roux and colleagues experiments show how difficult it is to ascribe specific functions to molecules essential to synaptic-vesicle cycling First, the mystery of the molecular entity mediating the temporal fidelity of signalling by the primary synapse in the auditory system may now be solved Given the blockade of synaptic-vesicle fusion, you would expect docked vesicles to accumulate at the release sites, but Roux et al . found no difference between the number of vesicles in normal mice and that in mice in which otoferlin production had been knocked out However, definitive evidence of otoferlins role as a calcium sensor awaits mutagenesis experiments on its putative calcium-binding C2 domains. Interestingly, only the most rapid phase of putative neurotransmitter release is abolished by a defect in the otoferlin molecule It is puzzling that the inner hair cell ribbon synapse looks so normal in mice with such a profound functional deficit Mammals react to sounds with exquisite temporal fidelity, a feat that is initiated by precise calcium-dependent signalling in the hair cells of the inner ear Mice lacking both copies of the normal gene have structurally normal synapses between the hair cell and afferent fibre, but are deaf and lack calcium-triggered dumping of the synaptic-vesicle contents Otoferlin also binds in a calcium-dependent manner to SNARE proteins, highly conserved molecules thought to be essential for the release of neurotransmitters and for other events requiring fusion of membranes Otoferlin contains six of these C2 domains, presumably for the binding of calcium, but it remains to be seen if or how other parts of the otoferlin molecule contribute to the unique properties of calcium-dependent signalling by the cochlear inner hair cell Second, all synaptotagmin molecules have so-called C2 domains, putative calcium-binding regions that are proposed to be responsible for its calcium-sensing functions  So how does the inner hair cell achieve such exquisite temporal fidelity in its release of neurotransmitter? Roux et al . suggest that the hair cell has evolved a unique calcium-sensing molecule, otoferlin, for controlling neurotransmitter release That player is a molecule called otoferlin, which has not previously been implicated as a calcium sensor for neurotransmitter release in nerve function The ability to localize these potential dangers or communicate these possible threats depends on the precise timing of signals in the neural code that the brain ultimately perceives as sound The abolition of the fastest component of neurotransmitter release suggests that otoferlin acts on the most molecularly mature vesicles, those conferred with rapid kinetics The action of otoferlin allows a hair cells specialized synapses — ribbon synapses, a specific class of afferent synapse common to sensory systems — to meet the requirements of hearing The authors genetically manipulated the otoferlin molecule to prevent its functional expression The basis of this temporal fidelity lies in the control of communication between the mechanosensory cell of the cochlea, the inner hair cell, and its downstream partner, the auditory nerve ( Fig. 1 ) The capacity of the auditory system to follow acoustic waves oscillating at several thousand times per second suggests that this calcium-dependent regulatory event may need to be as much as ten times more precise than signalling between most types of neuron The mechanical energy of acoustic waves causes minute displacements of sensory hair bundles extending from the cell These deflections result in rapidly oscillating electrical potentials, which trigger calcium influx from outside the cell; that in turn prompts tiny subcellular organelles filled with a chemical messenger to dump their contents into a well-defined extracellular compartment, the synaptic cleft They found that, in mice, not only is otoferlin localized to the synaptic vesicles of inner hair cells, but that it also undergoes developmental changes in expression concurrent with the formation of ribbon synapses Third, the new work raises the question of whether otoferlin or related molecules have a function at conventional synapses This fast component is widely thought to be associated with a specialized class of the vesicles that are close to the cell surface and molecularly poised for release ( Fig. 1 ) This messenger, or neurotransmitter, excites a nearby, afferent nerve fibre, which elicits an all-or-none electrical response that propagates details of the acoustic stimulus to the brain This paper is of great interest to both specialists in hearing research and neuroscientists in general, for several reasons Thus, otoferlin must mediate one of the final steps in the signalling cascade Thus, the possibility that the hair-cell synapse, or perhaps even other synapses, use a different molecule for calcium sensing is intriguing Writing in Cell , Roux et al . describe how they have identified an unexpected player in the auditory system
 Am Barring an extraordinary coincidence, this conclusion must apply to all the nanoscale magnetites in the carbonate Bernal and co-workers ( Clay Mineral Both chapters would have made interesting appendices to the book, but the claim made by McKay and colleagues is left hanging in limbo; the “detective story” ends not with a bang but a whimper Bull. 4, 15–30; 1959); it should not be confused with epitaxy, a two-dimensional relationship But then the chapter winds down without further reference to these studies, two of which turn out to be particularly important (they are briefly described in the notes) C D Discovering life beyond Earth will change forever our view of the Universe and our place within it Evaluation of McKay and colleagues claim therefore rested on whether their lines of evidence were really biosignatures, or whether they could have been produced non-biologically Even though I would have liked the book to conclude with closure of this tumultuous episode, this is nonetheless an outstanding popularization of science that deserves to be widely read, not least by those interested in the ‘logic of scientific discovery’ Finally, it is worth noting that, despite the demise of the biosignatures proposed by McKay and co-workers, the search for evidence of ancient life on Mars remains scientifically reasonable and, indeed, of fundamental importance. First, a team from the Johnson Space Center led by Gordon McKay, Davids brother, succeeded in synthesizing identical layered carbonate globules in the absence of biological activity, thereby destroying the globules status as a plausible biosignature (D Golden et al  How that announcement came to pass and what happened afterwards form the subject matter of The Rock From Mars  In the final two chapters, Sawyer shifts gears twice, once to discuss a marginally related controversy, and finally to report on some recent missions to Mars It means that the magnetites must have formed directly by decomposition of carbonate, and could not plausibly be bacterial in origin Kathy Sawyer, a journalist formerly with The Washington Post , has produced a model of science writing for the general public McKay et al  McKays team got one thing dead right: if you want the scientific community to believe youve found evidence for extraterrestrial life, you should provide several independent lines of evidence, something Sawyer terms a ‘holistic’ approach Mineral. 86, 370–375; 2001) Natl Acad Note that this is a true three-dimensional relationship, as first observed synthetically by J Planet S Sci Sci. 33, 765–774; 1998) Science 273, 924–930; 1996), the world sat up and took notice Second, a study by David Barber and Ed Scott ( Proc She accurately depicts the day-to-day life of the scientists involved and brings out how their observations and ideas are processed by the scientific community as it gropes its way towards the truth She gets the science right (with an occasional bobble), she reports with commendable balance on the intense controversy generated by McKay and colleagues announcement, and her lucid writing should prove largely comprehensible to non-scientists So when a team led by David McKay of NASAs Johnson Space Center announced in August 1996 that they had found evidence for ancient life in a martian meteorite (D That left two candidate biosignatures: unusual layered globules of carbonate, and, contained within them, tiny magnetite crystals that closely resembled those in magnetotactic bacteria on Earth The critical feature of a biosignature is not that it can be produced by biological activity, but that it cannot be produced non-biologically The lines of evidence they use are termed ‘biosignatures’ The organic matter, although partly of apparently martian origin (itself a notable achievement by the team), consisted of polycyclic aromatic hydrocarbons, which are not plausible biosignatures as they can easily be made by non-biological processes The ‘fossils’ could not be reliably distinguished from textures intrinsic to their mineral hosts, which had not previously been studied at such high magnification Their observations of meteorite ALH84001 (which is firmly established as martian even though it was found in Antarctica) led McKay and colleagues to advance four potential biosignatures They showed that the crystal lattices of the ultrafine magnetites within the meteorites carbonates were topotactically related to that of the carbonate host, a point that I had made in 1999, based on findings by John Bradley and co-workers ( Meteorit This is particularly unfortunate as the two studies mentioned above would have provided the bang of two smoking guns Towards the end of chapter 13, Sawyer cites several studies that “soon challenged the biological scenario anew” Two of them — the presence of organic matter and ultra-small fossil-like forms — were quickly rebuffed USA 99, 6556–6561; 2002) drove the final nail into the coffin
 A precise calculation of the electromagnetic binding energy for hydrogen must include the possibilities that photons can be emitted and reabsorbed by the electron, and that pairs of electrons and positrons (the antimatter counterpart of the electron) can pop briefly into existence After first obtaining the quark masses by ‘tuning’ the lattice to reproduce the masses of some well-known composite particles, ten further strong-force properties of composite particles were calculated  Almost simultaneously, the CLEO experiment at Cornell University in New York has announced the result of the first measurement An even stiffer test is imminent As energy is related to mass through E = mc 2 , where m is the mass of the particle and c the speed of light, this mass depends not only on the mass of the constituent quarks, but also on the bonds between them (potential energy) and their motion (kinetic energy) As quarks are permanently bound into composite particles ( Fig. 1 ), it is not possible to determine their masses directly Because the electromagnetic force is weak, these quantum corrections are small; a calculation involves just adding up a sufficient number of them But the first prediction of an unknown quantity was still wanting; it is this that a team of lattice QCD experts from Glasgow University in Scotland and Ohio State University and Fermilab in the United States, writing in Physical Review Letters , has now supplied But the first realistic calculation of particle properties, rather than prediction of qualitative features, came only in 2003 But their first calculation for mesons containing charm quarks has just been performed Consequently, the theory of QED has been verified to the tenth decimal place Here was thus a rare opportunity for the lattice theorists to predict the mass before better measurements were made If the agreement persists, similar calculations can be confidently applied to correct measurements of the disintegration rates of bottom quark mesons, whose correction factors are not measurable If the corrected rates do not conform to standard-model predictions, they could provide hints about the deeper theory that gives quarks their mass — and, ultimately, why only matter exists in the Universe. In an atom, for example, electrons bind to protons by swapping massless photons — the familiar electromagnetic force encompassed by the theory of quantum electrodynamics (QED) In other words, nearly all the mass of protons and neutrons — of ordinary matter in the Universe, including stars, planets and humans — is due to the strong forces binding energy In the 1980s, lattice QCD was used to explain why quarks are bound inside protons In the standard model, the origin of the mass of fundamental particles is the yet-to-be-discovered Higgs force field No computer in existence can follow every quark and gluon, so the problem is simplified by imagining space and time not as a continuum, but as a lattice — a four-dimensional grid of discrete points in space-time Only days after their prediction1 of 6,304±22 MeV appeared on a preprint server, the CDF experiment , picking through the pieces of trillions of particle collisions at Fermilabs Tevatron accelerator in Illinois, isolated 19 examples of the last meson with a mass of 6,287±4.9 MeV Physicists hope that gaining knowledge of the quark masses will guide them to that theory QCD is more complicated: not only do pairs of quarks and antiquarks make fleeting appearances and quarks constantly exchange gluons, but those gluons can constantly exchange other gluons as well Quarks also experience radioactive decays through the so-called weak force, the third fundamental force of the standard model Quarks reside at these points and gluons on the links between them, reducing an infinite number of variables to a finite (though very large) number — an approach known as lattice QCD Similarly, inside the proton, ‘up’ and ‘down’ quarks bind by exchanging massless particles called gluons — an interaction described by the so-called strong force and the theory of quantum chromodynamics (QCD) So the strong-force properties of composite particles are instead calculated using powerful computers to keep track of the most probable arrangements of the quarks and gluons inside them The agreement between theory and experiment ( Fig. 2 ) is a powerful validation of the lattice technique, especially for bottom and charm quarks The agreement is again good, although the accuracy of both the prediction and the experimental value is only around 10% (this should improve to under 5% within a year) The Bc was discovered in 1998, but its mass could not be determined accurately The binding effect of the strong force between quarks modifies the decay rates, and so correction factors are needed to allow a full interpretation of new data The binding effects between quarks are fundamentally different from those in atoms and atomic nuclei: they are positive, and so increase the mass of the composite particle The composite particle B c or ‘charmed B-meson’, a bound state of a charm quark and a bottom antiquark, is known as the ‘last meson’ because it was the final such quark–antiquark pairing that physicists expected to find The computational technique responsible, lattice quantum chromodynamics, could also be used to estimate quark masses better, to shed light on the origin of mass, and to reveal how the Universe, originally made of matter and antimatter in equal proportions, ended up containing just matter The deviation of the calculated values from the accepted experimental values was never more than a few per cent The effect of the strong force is greater: the mass of a nitrogen nucleus, with seven protons and seven neutrons, is less than the mass of its constituents by a binding energy of −105 megaelectronvolts (MeV), 0.7% of the total mass The fiendishly difficult equations of the strong nuclear force have yielded to a 30-year effort to allow the first precise prediction of a composite particles mass , a prediction promptly confirmed by experiment  The fundamental particles possess a wide range of masses: an electron is about 360,000 times lighter than the heaviest, or ‘top’, quark The lofty endeavour of particle physicists — to understand the birth, evolution and ultimate fate of the Universe by studying its fundamental particles — has just received a significant boost The mass of a hydrogen atom is less than the mass of its constituents by the electromagnetic binding energy (−13.6 electronvolts) — an effect of 1 part in 100 million The most likely value of a quark mass is that which best reproduces the measured mass of the composite particle The pattern of these decay rates would be, especially for bottom quarks, sensitive to phenomena beyond the standard model  The quantum corrections are so large that adding them all up is not feasible The reason electrons and quarks have the exact masses that they do must, however, come from a deeper theory of nature The ‘standard model’ of particle physics describes the interaction of fundamental particles, such as quarks and electrons, as the exchange of other particles that convey force Then, a significant breakthrough3 in the lattice technique — and teraflop-scale computers running for two years — allowed the inclusion of all pairs of light quarks (up, down and a third, slightly heavier variety, ‘strange’) and antiquarks that fluctuate into brief existence inside a composite particle Theorists instead solve the equations of QCD for a composite particle made up of quarks (protons and neutrons are examples) with the quark masses and strength of the strong force as unknowns These correction factors are even more difficult to predict than the composite particle masses These quark–antiquark pairs had usually been left out of the calculations because their simulation — much more difficult than that of gluons — had demanded prohibitively large amounts of computer time They are also two orders of magnitude larger than the quark masses themselves This is the formidable energy that is released in nuclear fission and fusion reactions Without this strong force, which not only binds quarks to form protons, but also keeps protons together in the nucleus, matter would simply fall apart
 According to a survey by the Council of Graduate Schools, released last month, graduate admissions in the 2005–06 school year were up sharply After several hours of delays he decided to go home rather than be hassled further. “I told them I dont need a US visa And Reza Mansouri, an Iranian physicist, was pulled out of line by security in May at a US consulate in Montreal, Canada But those statistics do not reflect the trouble individual scientists can have when entering the United States (see The cold shoulder ) But when he travelled home to visit his parents in July 2003, he found himself trapped — his application for a visa to re-enter the United States had disappeared into a mysterious web of post-September 11 security checks (see Nature 427 , 190 ; 2004 ) Bye-bye,” he says Congress passed legislation requiring face-to-face interviews with every visa applicant, leading to lengthy delays — even in European countries where the visa process was traditionally smooth Embassies and consulates have increased staffing, and new computer systems have been installed that allow applications to pass electronically between embassies and Washington agencies Final enrolment numbers out later this year are expected also to show a positive trend, says Stewart. “Were seeing a turnaround.”  Not reflected in the numbers are those, such as Mehta, who have given up on coming to the United States. “The visa trouble was definitely one reason why I went back to Germany,” says Stefan Gilb, a chemistry professor at the Technical University of Munich, whose visa renewal was delayed during his time at the University of California, Berkeley Five years after the terrorist attacks of 11 September 2001, foreign scientists are reporting fewer problems in trying to enter the United States Hes leaving the University of California, Santa Barbara, to begin a new job at the California Institute of Technology in Pasadena this autumn His visa was renewed after a six-month delay, but exactly what sparked the background check is still a mystery In Australia, overseas enrolment has more than doubled from 2000 to 2004, and, according to a recent government report, today roughly a quarter of its one million undergraduate and graduate students come from outside the country International student offices have boosted staffing and many universities have opened recruiting offices in countries such as China. “I dont know of a single major research university that was recruiting before 9/11,” Johnson says Mansouri did eventually get his visa, however, and is due to arrive in San Francisco this week Many researchers applications were sent to Washington for background checks that could take months, according to Barry Toiv, director of public affairs for the Association of American Universities, a Washington-based group that represents university interests. “We went through a very difficult period following 11 September,” he says Mehta was so incensed that he declined the visa when it was eventually offered to him Most education experts suspect that, despite delays, scientists and graduate students will ultimately come back to the United States. “We have 4,000 institutions and the capacity to absorb a whole lot of international students,” says Peggy Blumenthal, a vice-president at the Institute of International Education, a group based in New York that tracks the flow of foreign students and scholars Places offered to students from India and China, the largest suppliers of science and engineering students, rose 28% and 20%, respectively Scientists had longer waits than most because their fields of study often appeared on the governments Technology Alert List Significant rises have been reported in Europe, and China and India are attempting to expand their domestic higher-education sectors, especially in science and engineering Stewart says that such stories are still damaging the United States image in the international scientific community. “Every time there is a high-profile case like that its five steps backwards,” she says That may have contributed to a less impressive, but still positive, 1% rise in admissions to PhD programmes in the life sciences and a 5% rise in physical sciences The 30-year-old Ukrainian physicist had studied and worked in the United States since 1994, and had just taken a postdoctoral position at the University of California, Santa Barbara The average wait has dropped from 2.5 months in 2003 to two weeks by last December The increase in recruitment and drop in waiting times seems to have had a positive effect (see graph) The situation has improved greatly since then, according to Tony Edson, deputy assistant secretary of state for visa services at the US Department of State The University of Florida has renewed its invitation, but Mehta remains ambivalent. “Certainly I am not going to subject myself to the same process,” he says These trends were already apparent in the late 1990s, and in a way, says Stewart, the restrictions since 2001 may have helped the United States come to terms with the increasingly competitive global market. “We still have the best doctoral programmes in the world,” she says. “But its not our God-given right.”  For his part, Motrunich has decided to stay, at least for now To reduce the number of security checks, consular officers are receiving some additional training in handling scientific cases, and they are being encouraged to consult science attachés when appropriate. “Weve added extra people, were investing in infrastructure,” Edson says. “That has improved the situation.”  Waiting game The average wait still varies widely from country to country, but state-department statistics on the length of the Washington-based security checks that many scientists encounter show dramatic improvement To try to improve the views of foreign students and scholars, many US universities are now reaching out to the international community, according to Marlene Johnson, executive director of the Association for International Educators Today, Motrunich is back in America US immigration changed suddenly and dramatically after the 2001 attacks Waiting times are down and, according to a survey by the Washington-based Council of Graduate Schools, admissions in the sciences are rebounding Well-stocked labs with strong funding opportunities mean that “particularly in fields such as science and engineering, we will continue to attract the best and the brightest”, she adds. newsad; But Americas hegemony is not ensured Whatever his problems with the US immigration system, his colleagues have never made him feel unwelcome, he says. “In the scientific community, the fact that one is from a foreign country plays no role.” When Goverdhan Mehta, a chemist and former director of the Indian Institute of Science in Bangalore, applied for a visa to become a visiting professor at the University of Florida at Gainesville in February, embassy officials delayed his application and badgered him about how his research might relate to chemical weapons (see Nature 439 , 901 ; 2006 10.1038/439901a ) When Nature first contacted Olexei Motrunich two-and-a-half years ago, he was beside himself Yet anger and unease continue to cloud many researchers views of America. “Its very hard to overcome the perception thats developed over the past couple of years,” says Debra Stewart, the councils president
 According to Newtons law of gravity, the central mass required to corral such fast stars so close to the nucleus exceeds that of 100 million Suns, rendering Andromedas black hole at least 30 times bigger than its counterpart at the heart of the Milky Way Although improbable, this may explain what we see in the Galactic Centre; it is less likely to account for the single disk of stars seen in P3 at the nucleus of Andromeda An unusual blue concentration in P2 had been noted earlier , but the fact that it constitutes a compact disk of stars, separate from P2, has been established only with the latest observations As Bender et al . note, there is no plausible explanation of how and why the hot, young stars near the centre of the Milky Way and Andromeda got there Bender and colleagues , however, now confirm the existence of a third stellar component, P3, a tiny nucleus of hot, blue stars embedded within P2 ( Fig. 1 ) But if a close-orbiting object can be found, it can be used to rule out other potential identities for the central mass concentration: if the orbital radius is smaller than the size of other distributions of matter, such as a neutrino ball or a cluster of dark, dead stars, the only remaining viable possibility for the gravitational source is a black hole But the gravity of the black hole, and the extreme physical conditions at the centre of Andromeda, would greatly inhibit star formation unless the cloud density were many orders of magnitude greater — thus facilitating gravitational condensation into stars — than is generally encountered there But there remains the problem of the age of the roughly 400 stars that form P3 Conventional wisdom has it that they are merely the opposite ends of an elliptical distribution of old stars orbiting the central distribution, which is near P2 at one focus of the ellipse Despite its small size (barely a light year across), P3 contains stars with the highest average circular rotation velocity — almost 1,700 kilometres per second — measured so far in any galaxy For other dark objects, such as brown dwarfs (stars that have failed to ignite) or dead stars, to mimic such a single massive object, more than 100 million of them would have to be concentrated within a region only a third of a light year across For the positive identification of Andromedas centre, black-hole enthusiasts are thankful nonetheless. If a very massive object is confined to a compact region within a critical ‘Schwarzschild’ radius dictated by the general theory of relativity, its gravitational pull so warps space-time that this wraps round to enclose the body, preventing anything escaping In most cases, however, what is seen is also consistent with the dark masses being simply clusters of dark stars Ironically, stars such as these have no business being so close to a black hole — yet, following the reasoning above, their existence there rules out any other explanation for the concentration of mass in Andromedas nucleus other than its being a black hole It seems that only a new theory of star formation in the chaotic environment surrounding a supermassive object will suffice Observations of stellar dynamics have so far revealed compact, dark masses at the centre of almost 40 galaxies  One possible explanation for these close, young stars is that two clouds of matter fell into the black hole together, each colliding and compressing the gas of the other such that the material could clump together, thus overcoming the many factors that would otherwise inhibit their contraction into stars  So did these stars form in situ , or did they migrate from farther out? Given their short lifespan, it is very difficult to see how they could have diffused inwards (and still be visible as young stars now) through two-body interactions The alternative is that they formed where they are now, through the collapse of infalling molecular clouds The collisions that would ensue would destroy this structure in only a few million years, so it would not have lasted long enough for us to see it The exceptions are the dark masses at the core of the galaxy NGC 4258, in our own Milky Way and now, as Bender et al . report in The Astrophysical Journal , in our near neighbour the Andromeda galaxy The extreme gravitational pull of a black hole makes it difficult to find objects near it, let alone measure their speed The nucleus of Andromeda comprises a central dark-matter distribution and — as we now know, thanks to remarkable observations from the Hubble Space Telescope — not one, but three concentrations of starlight The situation of the stars orbiting the black hole at the centre of our own Galaxy is also bizarre  These are commonly assumed to be supermassive black holes — collapsed massive objects whose gravitational pull is so great that no light or matter can escape them They are bright and blue, and therefore very young compared with the age of the Andromeda galaxy; most of them must have formed less than 200 million years ago Thus, although the unknown dark-mass concentrations at the nucleus of many galaxies are conforming to what is becoming the ‘standard model’ of black holes , other mysteries of similar opacity are emerging To fulfil this criterion and so be considered a black hole, the object of three million solar masses that lurks at the centre of our Galaxy, for example, must be five times smaller than Mercurys orbit around the Sun To measure whether a dark mass of unknown provenance is a black hole, one must first find an object moving under its influence: in newtonian mechanics, the speed of an orbiting object, together with its radius from the central source of gravity, is sufficient to determine that sources mass Two of these, commonly labelled P1 and P2 (peaks 1 and 2), were known previously  Without actually seeing the dark pit it creates by absorbing or bending all the light incident upon it , the most compelling method to prove the existence of a black hole is to constrain its size and mass Young stars, less than 10 million years old, are assembled there into two counter-rotating disks; closer still to the centre, some 20 stars orbit within only a few light days of the black hole, some at speeds that can exceed 5,000 kilometres per second
 Here we propose that climate affects trophic interactions and could be an important mechanism for synchronizing spatially distributed populations However, it is unclear whether climate directly affects the survival and fecundity of individuals, or indirectly, by influencing food and natural enemies In these years, widespread and correlated climatic conditions during May and July affect populations regionally and influence the density-dependent transmission of the gastrointestinal nematode Trichostrongylus tenuis, a parasite that reduces grouse fecundity  There is circumstantial evidence that correlated climatic conditions can drive animal populations into synchronous fluctuations in abundance  This in turn forces grouse populations into synchrony We conclude that specific climatic events may lead to outbreaks of infectious diseases or pests that may cause dramatic, synchronized changes in the abundance of their hosts. We show that in specific years the size of red grouse populations in northern England either increases or decreases in synchrony Causal mechanisms of synchrony The structural equation model (SEM) was based on conceptual, inferential variables (known as latents) estimated through explanatory variables (known as manifests) represented by our time series Each time series is based on a privately owned estate, the location of which was selected as the centre of the moorland habitat Finally, we ran 1,000 Monte Carlo replications of these bootstrapped models and calculated the empirical probability P ( H obs H exp ) and the 95% confidence intervals for the original model and its parameters (see Supplementary Information ). For 60% of the time series we had corresponding time series of average intensity of T. tenuis infection in old and young red grouse randomly sampled between August and December for the period 1977–1994 For each region and each month the new mean-temperature time series was calculated and then rescaled to the altitude of each original time series. (see Supplementary Information ) Furthermore, detailed population studies on red grouse have been undertaken and the fundamental mechanisms of population regulation identified and tested experimentally  Methods Data sets The red grouse time series provide one of the best data sets available on changes in relative abundance for examining spatio-temporal dynamics in animal populations Monthly weather variables from April to August for the period 1839–1994, namely millimetres of rainfall and mean temperature in degrees Celsius, were provided as daily time series by the UK Met Office–British Atmospheric Data Centre service ( http://badc.nerc.ac.uk/home ) Parameter identification and their 95% confidence intervals were estimated using bootstrap and Monte Carlo techniques ( SEPATH , StatSoft ) because the data violated some of the assumptions of structural equation modelling  Parasite time series were log( x + 1)-transformed and when fewer than three consecutive data points were missing they were replaced with the annual parasite mean from the local region Rainfall records were from weather stations less then 10 km from each moor, while temperature came from stations less than 15 km away Significant collective forcing episodes were identified, and 95% confidence intervals were estimated from 5,000 bootstraps of the Shannon–Weaver index based on the state-based Markov chain model, using sample sizes of at least five time series per year  Spatio-temporal synchrony Red grouse time series and climatic time series had occasional missing data points (1.3% of the total cases in red grouse) that were interpolated with a log-linear fit  T. tenuis intensity changes seasonally but reaches an autumnal asymptote  Temperature time series were poorly represented, and so each series was reconstructed by scaling the series to the temperature expected at sea level (assuming temperature changes of 6.4 °C every 100 m) The explanatory variables inferring the weather variables were assumed to be fixed The red grouse data were normalized using a Box-Cox transformation and the long-term trend removed by selecting the residuals from fitting a non-parametric LOESS function to the data (the smoothing parameter included 75% of the observations and gaussian errors were assumed), thus leaving the short-term pattern unchanged The SEM allowed us to explicitly account for environmental stochasticity and reciprocal relationships between variables, and as such correctly measures these latent variables and their interactions  The time series are a good proxy for population abundance  We also carried out state-based Markov chain modelling for the parasite time series and the rainfall time series and found that the years of synchronous collective forcing in parasite time series coincided in 67% of the cases with synchronous CFEs for May rainfall and 50% of the cases with July rainfall (see Supplementary Information ) We first estimated the predicted model parameters and the χ -squared statistic for the generalized least-squares discrepancy function, using the correlation matrix of the original data set We then carried out bootstrap extractions with replacement based on 50 samples and calculated the χ -squared statistic for the SEM simulated on these new data A structural equation framework , based on the environmental variables selected by the logistic regression, was used to compare these hypotheses About 50 years ago, Moran proposed that uncoupled populations with identical linear density-dependent structure will asymptotically synchronize in phase under the influence of correlated environmental perturbations, and the correlation between populations will equal the correlation between the extrinsic factors As an annual index of state synchrony among populations within each of the five regions, we applied the Shannon–Weaver diversity index to the proportion of populations in each state  Climatic conditions can also directly influence the survival of grouse chicks Common statistical techniques can be used to identify spatial synchrony and provide an estimate of average synchrony between time series, but they fail to identify the years in which time series are forced into synchrony Consequently, both models were fitted to these data Consequently, grouse feeding on the heather will have a low level of parasite infection, which results in an increase in grouse abundance and populations moving into a synchronous increase phase Dry and warm Mays impede the development of parasite eggs and the survival of the infective stage  Dry, warm weather in May, when chicks hatch, allows them to forage and grow, whereas chicks that hatch during cold, rainy periods have less foraging time and increased mortality  Each grouse population is embedded within one of five discrete regions of contiguous habitat and we analysed synchrony between populations in each of these regions Eggs pass out of the host in the caecal faeces and in wet and warm conditions develop into a third-stage infective larva that ascends the heather and is ingested by a feeding grouse  For each region, we examined changes in the annual proportion of populations in each state, which allowed us to identify the years in which populations were forced into significant state-synchrony and quantify the state that these populations converge onto, in these years  For Fig. 3a , the generalized least squares (GLS) is 0.18, the probability that χ  2 of the observed hypothesis ( H obs ) is bigger than the null hypothesis ( H exp ), P [ χ  2 ( H obs H exp )], is 0.83 and the corrected Akaike information criterion for small sample size (AIC C ) is 1.20 For Fig. 3c , GLS = 2.03, P [ χ  2 ( H obs H exp )] = 0.86 and AIC C = 1.55 For Fig. 3d , GLS = 7.33, P [ χ  2 ( H obs H exp )] = 0.99 and AIC C = 3.53 For Fig.3b , GLS = 4.76, P [ χ  2 ( H obs H exp )] = 0.96 and AIC C = 2.00 For the climate hypothesis the model consisted of rainfall and mean temperature in May and July with direct effects on grouse abundance, whereas for the climate–parasite hypothesis these climatic variables influenced the grouse both directly and indirectly through the net rate of parasite transmission, as measured by changes in parasite intensity in the host Hence, a synchronous year can arise either as a dynamically predictable episode, as a consequence of synchrony in the preceding year, or as an unpredicted ‘collective forcing episode’ (CFE) that brings previously asynchronous populations into the same synchronous state  Here we examine this hypothesis in the natural system of the red grouse ( Lagopus lagopus scoticus ) and its gastrointestinal parasite Trichostrongylus tenuis , a nematode known to play a major role in reducing fecundity and destabilizing grouse populations  However, a closer examination of the estimated grouse–environment interaction coefficients showed that the climate model was not ecologically consistent with the data in Table 2  However, experimental evidence has shown that such processes act at a local scale and are not associated with food and weather , and consequently are unlikely to be involved in generating the large-scale intermittent collective forcing episodes and the pattern of synchrony that we have observed However, researchers have yet to identify the underlying process that generates correlated fluctuations between populations in any natural system If these climatic conditions are followed by cold wet Julys, parasite development is further reduced  In contrast, wet Mays and warm Julys favour abundant infective stages on the vegetation, leading to a rapid rise in the intensity of parasitic infection and causing a synchronous decline in grouse populations In populations in which fluctuations are driven by a trophic interaction, such as predator—prey, host–parasitoid or host–parasite interactions, the correlated climatic effects may operate either on these density-dependent mechanisms or more directly on population abundance, and thus move populations into a synchronous phase Indeed, this model proposed that for the set of ‘upward’ CFEs ( Fig. 3a ) grouse abundance increased owing to wetter Mays and drier Julys, and that for the set of ‘downward’ CFEs ( Fig. 3b ) grouse abundance decreased owing to warmer Mays and colder Julys Intrinsic processes such as changes in spacing behaviour late in the year may also influence grouse populations  Nonlinear interactions between climate and population size can influence not only temporal changes in abundance but can also lead to spatial synchrony at a range of scales  On the basis of knowledge of the red grouse system, we propose that there are two major demographic circumstances that would tend to generate such collective forcing episodes in these harvesting data: first, good breeding years in which populations undergo positive growth rates (increases or peaks) and second, poor breeding years when populations experience negative growth rates (decreases or troughs) Our results also suggest that synchrony in grouse populations is an intermittent event, arising from populations that have been forced to converge into different phase states Populations were considered to be in synchrony when the diversity index deviated below the lower 95% confidence interval predicted by the Markov state transition model under the null hypothesis of no coupling between populations Red grouse harvest data have proved to be a fair reflection of spatio-temporal changes in population density and annual productivity  Replicated field experiments have shown that the intensity of the nematode T. tenuis infection has a consistent and negative impact on female fecundity, clutch size, hatching success and chick survival  Since Moran suggested his theorem, researchers have looked for evidence of the ‘Moran effect’ across animal taxa and investigated how environmental noise interacts with nonlinear population dynamics, the ‘nonlinear Moran effect’   Temperature increases the development rate of the free-living stages and sufficient humidity is necessary for infection to be effective  The diversity index calculated among populations within each of the five regions revealed that no regular pattern characterized the incidence of the forcing episodes ( Fig. 2a ) The majority (59%) of these time series exhibit cyclic fluctuations with an average period of 7 years (range 3–13 years)  The majority of populations converged on a common dynamical state: ‘upward’ CFEs—either two successive years of increased abundance (32% of CFEs) or peaks (32% of CFEs)—or, less frequently, ‘downward’ CFEs—when populations converged on two successive years of population decline (8% of CFEs) or a trough (28% of CFEs) ( Fig. 2b ) The model based on the climate–parasite hypothesis was biologically consistent and in line with studies on the impact of weather both on grouse demography and on parasite transmission  The two parsimonious models—based on the climate ( Fig. 3a and b ) and climate–parasite ( Fig. 3c and d ) hypotheses—performed statistically well in both the ‘upward’ and ‘downward’ years, and there was no apparent statistical difference between them ward’ CFEs, whereas the pattern was reversed in the ‘downward’ CFEs ( Table 2 ) These results have important implications for the management of natural populations and the control of infectious diseases because they indicate that certain weather conditions have a strong influence on eruptive outbreaks of infectious diseases or pest species and may lead to dramatic and synchronized changes in host abundance. This collectively synchronized populations ( Fig. 3c and Table 2 ) This contrasts with both the data summarized in Table 2 and previous field studies  This model indicated that parasite intensity and the rainfall and temperature during July promoted CFEs, while May rainfall and temperature repressed CFEs ( Table 1 ) This parasite inhabits the blind-ending caeca of the grouse and has a direct life cycle This study suggests that the effects of common climatic events on the density-dependent destabilizing interaction between host and parasite result in a phase synchrony between grouse populations Thus the fit of the climate model is statistically reasonable but not biologically credible To achieve this, the dynamical state of each red grouse population was represented in a state-based Markov chain model that described temporal transitions between four phase states based on three consecutive years of observations: a cycle trough, a consecutive increase, a cycle peak and a consecutive decrease To identify the environmental variables that could force populations into synchrony, we applied a generalized logistic regression model which predicted the occurrence of annual forcing episodes as a function of the intensity of parasite infection and the climatic variables that have a major impact on breeding  To identify years when these forcing events occurred, we calculated whether the diversity index fell outside the one-step 95% confidence interval, conditional on the state configuration in the previous year  We examined two alternative hypotheses: first, that the direct effects of correlated climatic conditions on the grouse generate CFEs (the climate hypothesis), and second, that climate indirectly influences grouse dynamics through its effect on parasite transmission (the climate–parasite hypothesis) We focused our analyses on the years in which these forcing events occurred and looked for the putative synchronizing mechanism We used 91 time series of annual red grouse harvesting data obtained from managed grouse moors in northern England between 1839 and 1994 and collected by The Game Conservancy Trust ( Fig. 1 ) When applied to the set of ‘upward’ CFEs, the model revealed that relatively dry and warm Mays followed by cold and wet Julys were deleterious to parasite transmission, leading to low parasite intensities and positive red grouse growth rates When applied to ‘downward’ CFEs, the climate–parasite model revealed that relatively wet Mays and warm Julys increased parasite transmission, which raised parasite intensity and led to a collective crash in grouse populations ( Fig. 3d , Table 2 ) Within this model, climate also had a direct influence on grouse production, but the effect was less apparent
 Blockade of the CTLA-4 (cytotoxic T-lymphocyte-associated protein 4) inhibitory pathway had no effect on either T-cell function or viral control Functional impairment of antigen-specific T cells is a defining characteristic of many chronic infections, but the underlying mechanisms of T-cell dysfunction are not well understood Here we report that PD-1 (programmed death 1; also known as Pdcd1 ) was selectively upregulated by the exhausted T cells, and that in vivo administration of antibodies that blocked the interaction of this inhibitory receptor with its ligand, PD-L1 (also known as B7-H1 ), enhanced T-cell responses Notably, we found that even in persistently infected mice that were lacking CD4 T-cell help, blockade of the PD-1/PD-L1 inhibitory pathway had a beneficial effect on the ‘helpless’ CD8 T cells, restoring their ability to undergo proliferation, secrete cytokines, kill infected cells and decrease viral load These studies identify a specific mechanism of T-cell exhaustion and define a potentially effective immunological strategy for the treatment of chronic viral infections. To address this question, we analysed genes expressed in functionally impaired virus-specific CD8 T cells present in mice chronically infected with lymphocytic choriomeningitis virus (LCMV), and compared these with the gene profile of functional memory CD8 T cells Gene array analysis Naive P14 transgenic CD8 T cells, D b GP33–41-specific memory CD8 T cells from Armstrong immune mice, and D b GP33–41-specific or D b GP276–286-specific CD8 T cells from CD4-depleted clone-13-infected mice were purified by fluorescence-activated cell sorting (FACS), and RNA isolation and gene array analysis was performed as previously described  In vivo antibody blockade Two hundred micrograms of rat anti-mouse PD-L1 (10F.5C5 or 10F.9G2; ref. 29 ), rat IgG2b isotype control, rat anti-mouse PD-1 (29F.1A12) or anti-mouse CTLA-4 (UC10-4F10-11 or 9D9.1.1.7) were administered intraperitoneally every third day Intracellular cytokine, degranulation and 51 Cr-release assays Intracellular cytokine staining was performed as described  LCMV Armstrong and clone 13 infections were performed as described  Methods Mice and infections Ly5.2 C57BL/6, Ly5.1 C57BL/6, 129 PD-L1 -/- and 129 littermate control mice were used in this study The two different anti-PD-L1 clones gave indistinguishable results and the isotype control had no effect To detect degranulation, splenocytes were stimulated for 5 h in the presence of brefeldin, monensin, anti-CD107a–FITC and anti-CD107b–FITC. 51 Cr-release assays were performed as described . Where indicated, CD4 T cells were depleted as described  Also, our finding that PD-1/PD-L1 blockade was effective in enhancing CD8 T-cell responses even under conditions of CD4 T-cell deficiency is of particular relevance to the situation seen during HIV infection  Also, the anti-PD-L1-treated mice that resolved the infection remained healthy, and did not exhibit any overt signs of disease Also, there were no synergistic effects of co-blockade with anti-PD-L1 and anti-CTLA-4 ( Supplementary Fig. 3 ) Although functional effector T cells are initially generated during the early stages of infection, they gradually lose function during the course of the chronic infection Although our data so far make a compelling argument for PD-1/PD-L1 blockade restoring function in exhausted CD8 T cells, there is a possibility that the enhanced immune responses we are seeing in the chronically infected mice after anti-PD-L1 or anti-PD-1 treatment are actually due to the generation of de novo T-cell responses from ‘naive’ CD8 T cells  Although T-cell dysfunction is a common feature of many chronic viral infections, the underlying mechanisms have remained poorly understood An advantage of this model is the availability of LCMV strains that can cause either acute or chronic infections in adult mice; the Armstrong strain is cleared within a week, whereas the clone 13 strain establishes a persistent infection  An example of impaired cytokine production and proliferation by the exhausted CD8 T cells is shown in Fig. 1a  As a first step towards understanding the mechanisms of T-cell dysfunction, we performed a comparative genome-wide microarray analysis (Affymetrix) of genes expressed by exhausted versus functional LCMV-specific CD8 T cells of the same antigenic specificity As PD-1 was transiently upregulated during acute LCMV infection, we treated Armstrong-infected mice with anti-PD-L1 antibody during the first week of infection and monitored the T-cell response As shown in Fig. 3h , there were significant reductions in virus levels in the spleen ( P = 0.008), liver ( P 0.0001), lung ( P = 0.0002) and serum ( P = 0.003) in the treated mice As shown in Supplementary Fig. 4 , T-cell numbers remained stable and more functional for several weeks following the transient blockade As these two strains differ in only two amino acids in the entire genome , and neither of these mutations affects any of the known T-cell epitopes, it is possible to track the same CD8 T cell responses after an acute or chronic viral infection Conclusion The PD-1 inhibitory pathway is known to regulate immune responses to self antigens  CTLA-4 is another inhibitory receptor of the CD28 family, and several studies have shown that treatment with anti-CTLA-4 blocking antibodies can enhance T-cell immunity against tumours  Despite their enormous potential, therapeutic vaccines have had minimal to no success in eliminating chronic infections Direct ex vivo lytic ability became detectable, however, after anti-PD-L1 blockade ( Fig. 3f ) During chronic LCMV infection, exhausted virus-specific cytotoxic T lymphocytes (CTLs) are not able to lyse targets in 51 Cr-release assays ( Fig. 3f and refs 3–5 ) Even under these conditions, when CD4 T cell help was lacking, PD-L1 blockade was highly effective in increasing T-cell numbers, improving their quality, and reducing viral load ( Fig. 3 ) Finally, our studies have implications for therapeutic vaccination and T-cell immunotherapy  Following crosslinking by PD-1 ligand, the immunoreceptor tyrosine-based switch motif (ITSM) in the cytoplasmic domain of PD-1 is phosphorylated and recruits the phosphatases SHP-1 and SHP-2 From this perspective, it is worth noting that a study by Iwai et al. has shown that PD-1-knockout mice exhibit better control of adenovirus infection, and a recent study using HBV transgenic mice suggests a role for PD-1 in regulating T-cell responses Furthermore, many of the donor cells recovered from both lymphoid and non-lymphoid tissues had diluted CFSE to background levels, showing they had divided more than eight times ( Fig. 4a ) However, as we have shown, one can turn the tables on the pathogen by strategically blocking this inhibitory pathway and turning the T cells back on However, in contrast to our results with anti-PD-L1 or anti-PD-1 antibody blockade, treatment of chronically infected mice with anti-CTLA-4 blocking antibody had no effect on either virus-specific T-cell responses or viral control However, it is worth noting that blockade with anti-PD-L1 antibody was more effective than anti-PD-1 antibody in enhancing T-cell responses in the chronically infected mice However, one needs to carefully monitor the potential for autoimmunity and immunopathologic damage under such conditions However, these findings were quickly extended to other model systems, as well as to chronic infections in humans, in particular human immunodeficiency virus (HIV), hepatitis B virus (HBV) and hepatitis C virus (HCV) infections—three chronic infections afflicting 500 million people worldwide  In addition to the increased number of BrdU-positive cells, we also found an increased number of cells expressing Ki67, a protein associated with cell-cycle progression (19% in untreated versus 60% in anti-PD-L1 treated mice) ( Fig. 3d ) In addition, we show that PD-1 regulates the distinct pathways of memory CD8 T-cell differentiation observed during acute versus chronic viral infection In contrast to the highly robust memory CD8 T cells generated after an acute Armstrong infection, LCMV-specific CD8 T cells become exhausted during a persistent clone 13 infection  In contrast, chronic infections are often characterized by varying degrees of functional impairment of virus-specific T-cell responses, and this defect is a principal reason for the inability of the host to eliminate the persisting pathogen In contrast, in the presence of anti-PD-L1 blocking antibody, there was substantial proliferation and expansion of the exhausted virus-specific CD8 T cells in all of the tissues analysed ( Fig. 4a ) In contrast, PD-1 expression continued to increase on virus-specific CD8 T cells in chronically infected mice and the high level of expression was sustained In contrast, when PD-L1 -/- mice were infected with LCMV clone 13 they died owing to immunopathologic damage In untreated mice, only ∼20% of D b GP276–286-specific CD8 T cells were capable of producing IFN-γ, whereas in anti-PD-L1 treated mice, ≥50% of these CD8 T cells produced IFN-γ ( P 0.0001) ( Fig. 3e ) In untreated mice, the majority ( 55%) of D b GP276–286-specific CD8 T cells did not incorporate any BrdU, while in treated mice, ≥90% of these cells were positive with much higher levels (mean fluorescence intensity) of BrdU incorporation Infection of PD-L1 -/- mice A prediction from our antibody blockade experiments is that T cells should not exhaust in PD-L1 -/- mice after infection with LCMV clone 13 Inhibition mediated by PD-1 requires close proximity of PD-1 to the site of TCR engagement and does not signal in the absence of a TCR signal Interestingly, the exhausted LCMV-specific CD8 T cells also expressed elevated levels of CTLA-4 mRNA (data not shown) It has been suggested that T cells adapt to persistent antigen by downregulating the responsiveness of their T-cell antigen receptor (TCR) signalling machinery , so defects in virus-specific CD8 T-cell function during chronic infection may be due to inhibition of TCR signal transduction It is worth noting that all exhausted virus-specific CD8 T cells that had undergone this rapid (antigen-driven) proliferation after anti-PD-L1 blockade still expressed high levels of the inhibitory receptor PD-1 ( Fig. 4b ) It remains to be determined whether these findings can be extended to other models of chronic infections, and especially to persistent infections of humans It was of interest to determine whether the increased numbers of virus-specific CD8 T cells would be sustained after cessation of the anti-PD-L1 treatment Memory CD8 T cells generated after an acute viral infection are highly functional and constitute an important component of protective immunity Memory CD8 T-cell differentiation proceeds along distinct pathways after an acute versus a chronic viral infection  Most notably, the T cells became functionally superior following anti-PD-L1 treatment, and a higher fraction of the virus-specific CD8 T cells were capable of producing both interferon (IFN)-γ and tumour necrosis factor (TNF)-α compared to untreated mice ( P = 0.01) ( Fig. 2b ) Once this interaction was disrupted by the anti-PD-L1 blocking antibody, the ‘brake’ was released and the exhausted CD8 T cells could proliferate in response to viral antigen One of the main reasons for their failure is the limited proliferative potential of the exhausted T cells  Our studies now provide a potential strategy for improving the efficacy of therapeutic vaccination by combining it with PD-1/PD-L1 blockade Our study now defines a new and critical role for this pathway in modulating T-cell function during chronic viral infection tor T-cell stage in chronically infected mice, and was rapidly downregulated in mice that cleared the infection ( Fig. 1 and data not shown) PD-1 has two ligands—PD-L1 (B7-H1) , which is widely expressed on both haematopoetic and parenchymal cells, and PD-L2 (B7-DC) , which is predominantly expressed on macrophages and dendritic cells PD-1 is upregulated during chronic viral infection To examine the mechanism of T-cell dysfunction during chronic infection, we used the mouse model of infection with LCMV PD-L1 blockade enhances viral control and T-cell responses To test the above hypothesis, we treated persistently infected mice with anti-PD-L1 blocking antibody and monitored T-cell responses and viral control ( Fig. 2 ) Potential explanations for this finding include blocking efficiency, differential expression of PD-L1 and PD-L2, or the possibility that PD-L2 might provide ‘positive’ co-stimulatory signals  Proliferation of exhausted CD8 T cells The expansion of exhausted CD8 T cells was one of the most remarkable effects after blockade of the PD-1/PD-L1 inhibitory pathway Restoring function in ‘helpless’ CD8 T cells We next asked whether blockade of the PD-1/PD-L1 inhibitory pathway would enhance CD8 T-cell responses in the absence of CD4 T cell help Significantly, PD-L1 blockade resulted in a substantial reduction in virus levels; the treated mice had cleared infectious virus from the serum, spleen and liver, while untreated mice still harboured high levels of virus in these tissues ( P = 0.01) ( Fig. 2c ) Similarly, the efficacy of T-cell therapy for chronic infections or tumours may be enhanced by blocking the PD-1 inhibitory pathway. The most notable finding was the pronounced upregulation of messenger RNA encoding PD-1, an inhibitory receptor of the CD28 family , by the exhausted LCMV-specific CD8 T cells ( Fig. 1b ) The pathogen ends up taking advantage of this inhibitory pathway to establish persistence in the host The treated mice showed significant increases ( P = 0.02) in the numbers of LCMV-specific CD8 T cells, as measured by three different MHC class I tetramers ( Fig. 2a ) The use of this congenic system (Ly5.1 versus Ly5.2 mice chronically infected with LCMV) allowed us to distinguish between donor and host T cells and directly monitor the proliferation of the CFSE-labelled exhausted virus-specific CD8 T cells There was a dramatic increase in the number of virus-specific cells capable of degranulating in anti-PD-L1-treated mice ( Fig. 3g ) There was a substantial increase in the number of IFN-γ-producing cells in the treated mice ( Supplementary Fig. 1 ) There was also a substantial increase in virus-specific CD8 T cells in non-lymphoid tissues such as liver and lung and even in intraepithelial lymphocytes (IEL) ( Fig. 3c ) There were approximately sevenfold more D b GP276–286-specific CD8 T cells ( P 0.0001), and fourfold more D b GP33–41-specific cells ( P 0.0001) in the spleens of anti-PD-L1-treated mice than untreated control mice ( Fig. 3a , b ) Therefore, under conditions of persistent antigen, T cells may modulate their responsiveness by upregulating inhibitory receptors such as PD-1 that attenuate TCR signalling These data show unequivocally that PD-L1 blockade restores function in the exhausted CD8 T cells ( Fig. 4c ) These phosphatases act on proximal signalling kinases of the TCR pathway, reducing the TCR signal and leading to diminished T-cell activation and cytokine production  This exhaustion of virus-specific T cells was first shown during persistent LCMV infection of mice  This improved functionality was seen with CD8 T cells responding to multiple epitopes ( Fig. 2b ) This is a much more stringent model of chronic infection and the ‘helpless’ CD8 T cells show even more pronounced functional defects  This is an important point, because it sets the stage for future studies designing intermittent blockade therapy for increasing, in a step-wise manner, the numbers of virus-specific T cells This result tells us two important things: one, that the PD-1/PD-L1 axis operates primarily under conditions of sustained high levels of antigenic stimulation; and second, that the PD-1 inhibitory pathway may have evolved to regulate immune-mediated damage during a persistent infection by turning ‘off’ the virus-specific T cells This shows that the expanded population of virus-specific CD8 T cells does not suddenly decline after the antibody treatment has been stopped This suggests that continuous engagement of PD-L1 with PD-1 was the key event in inhibiting proliferation of the exhausted CD8 T cells This was confirmed at the protein level using antibodies specific for PD-1 ( Fig. 1b ) Thus, it appears that the PD-1 inhibitory pathway is particularly important in exhausted T cells Thus, it is likely that the immunological strategy we have developed for restoring function in exhausted T cells may have broader applications Thus, not only did the exhausted CD8 T cells express high levels of PD-1, but its ligand was also upregulated on infected cells, suggesting a role for this inhibitory pathway in regulating T-cell function during chronic LCMV infection Thus, the results shown in Fig. 3 demonstrate that PD-L1 blockade can restore function even in ‘helpless’ exhausted CD8 T cells To address this issue, we sorted PD-1 + and PD-1 - CD8 T cells from chronically infected Ly5.2 mice, transferred them into chronically infected Ly5.1 mice, and then treated these mice with anti-PD-L1 antibody To compare the function of CD8 T cells in untreated and anti-PD-L1-treated mice on a per-cell basis, we calculated the percentage of D b GP276–286-tetramer-positive cells that were capable of producing IFN-γ To determine whether this increase in cell numbers was due to cell division, we measured 5-bromodeoxyuridine (BrdU) incorporation during the period of anti-PD-L1 treatment ( Fig. 3d ) To investigate this further, we used carboxyfluorescein diacetate, succinimidyl ester (CFSE)-labelled splenocytes from chronically infected Ly5.2 mice, transferred them into chronically infected Ly5.1 mice, and then treated the mice with anti-PD-L1 antibody ( Fig. 4a ) To more directly assess the role of PD-1 in T-cell dysfunction, we treated chronically infected mice with a blocking antibody against PD-1 itself To test this, we infected PD-L1 -/- mice with either Armstrong or clone 13 To test whether the increase in IFN-γ production and lytic activity corresponded to better viral control, we measured viral titres in the spleen, liver, lung and serum We also measured the ability of virus-specific CD8 T cells to degranulate by monitoring the appearance of lysosomal markers CD107a/b on the cell surface after re-stimulation with peptide We found that anti-PD-L1 treatment only enhanced immune responses of the sorted PD-1 + CD8 T cells (the cell population containing exhausted cells), and had no effect on PD-1 - CD8 T cells (containing naive cells) We found that high expression of this inhibitory receptor was a signature of the functionally exhausted CD8 T cells; all LCMV-specific CD8 T cells (comprising multiple epitopes) that were present in chronically infected mice expressed high levels of PD-1, whereas functional LCMV-specific memory CD8 T cells of the same antigenic specificities present in mice that had cleared the acute LCMV infection did not express any detectable levels of PD-1 ( Fig. 1b and data not shown) We found that PD-1 blockade also restored function in the exhausted CD8 T cells ( Supplementary Fig. 2 ) We found that PD-L1 blockade did not increase virus-specific CD8 T-cell responses in the acute infection model (data not shown) We found that PD-L1 was expressed at very high levels in splenocytes from persistently infected mice, especially on virally infected cells ( Fig. 1c ) We found that virus-specific CD8 T-cell responses were enhanced both quantitatively and qualitatively by the anti-PD-L1 blockade We have now not only identified a major inhibitory pathway operating during chronic LCMV infection, a classic model of viral persistence in its natural host, but have also developed a simple and highly effective strategy for restoring function in the exhausted CD8 T cells and enhancing viral control We next analysed the kinetics of PD-1 expression during both acute and chronic LCMV infection, and found that PD-1 was transiently expressed on early effector CD8 T cells after LCMV Armstrong infection but then was rapidly downregulated ( Fig. 1c ) We next measured the effect of anti-PD-L1 blockade on the ability of virus-specific CD8 T cells to produce IFN-γ in the absence of CD4 T cell help When PD-L1 -/- mice were infected with the LCMV Armstrong strain (acute infection), they behaved just like wild-type mice, producing normal CD8 T cell responses ( Fig. 5a ) and controlling the infection When the exhausted cells (Ly5.2) were transferred back into a chronically infected mouse (Ly5.1), they underwent minimal to no proliferation in any of the tissues examined (spleen, liver, lung or IEL) ( Fig. 4a )
 But for products of synthetic biology that bear novel genes and thus are also GMOs, which type of regulation should prevail: technique- or product-based? If the former, one would quickly encounter the situation where equivalent organisms, synthetic or classic GM, would be regulated using drastically different strategies and criteria But the second half of this definition has already been applied for decades to genetically modified organisms (GMOs), and particularly to modified viral genomes I believe that the first step to reassure the public about synthetic biology should be to cool the rhetoric If the latter, the most potentially dangerous products of synthetic biology would simply be regulated as GMOs If the United States and/or Canada go forward with technique-based regulation of synthetic biology, a minimum of coherence would require them also to shift to technique-based regulation of GMOs — a major policy change North American scientists are calling for technique-based regulation of synthetic biology Sir Your News story “Synthetic biologists face up to security issues” ( Nature 436 , 894 – 895 ; 2005 ), defines synthetic biology as the ability “to create complete genomes from scratch and to introduce new characteristics into viruses and bacteria” The incompatibility between product-based and technique-based systems is the source of much of the transatlantic tension regarding GMOs The present discussion about regulation of synthetic biology should carefully consider how and why GMOs are regulated, in order to avoid regulatory chaos The present situation is reminiscent of 30 years ago, when some of the pioneers in the then-new field of genetic engineering made unrealistic claims about what was feasible; this was one of the major early sources of public uneasiness about GMOs The US and Canadian systems for GMO regulation are based on the properties of the organisms produced, whereas the European system is based more on techniques There should be a bit more modesty in claims both about what can be achieved by synthetic biology in the foreseeable future, and about what could be achieved by additional regulatory supervision.
 Already teams of humans and semisents were colonizing Mars Amman had no sex but could express an intimacy that mingled with the physical in a way she had not known with either men or women Amman knew this and helped, often with amiable distractions Amman was smarter than boys, of course Ammans kinesthetic senses got better too, navigating the landscape nearly as well as she could at her coming-out party Ammans steady, smart rain came from Germany — a squat box that spoke Arabic respectfully and listened when she gossiped about her friends Anywhere near them she effervesced, bubbly and skittering As a biologist she knew that organisms solve the evolutionary problems they face with little regard for efficiency, elegance or logic As her years piled up upon that beach, she saw that at last humans had made companions that would persist beyond the oddities of a single personality As she aged, she sensed that Amman would outlive her At times of loneliness she even had it loaded into one of the erotic models, available at a desert salon Bodyguard, tutor, secretary, it could play tennis with her when loaded into one of the new athletic machines, bringing to the game its own odd, crafty style But Amman understood, even made wry comments like “Intelligence is learning from others mistakes, not just your own.” It helped her to understand boys when she could chat with Amman, which was reading along with her and seemed to have an oddly vast wisdom about such matters, for a computer But it was more delicious to dish it over with Amman, which could replay whole conversations By then she was acutely tuned to the ‘mystery of males’ Culling each wolf litter gave us a new kind of wolf, so we called them dogs First came social skills, a savour of sex, and then hard schooling to find out what she loved doing Friends came into the floating house party of her life and left it, some quite early, without leaving much impression Growing up in Iraq among a sprawling family with dogs underfoot, she felt herself to be a sort of hothouse plant, blossoming under the occasional passing cloudburst of education Her friends felt they could intuitively sense intelligence merely by talking to it Her friends giggled over it for days Her friends were a fount of tasty gossip, but Amman kept her secrets better Her gal-pals eyes glazed over if she talked too much Her parents transferred Amman into a wheeled ‘escort’ for her first date It had taught her to see her life as a narrative arc It helped her to survive and learn from it all, to move with growing serenity through an unfolding world Its enhancements gathered range and depth, her ever-scrutinizing, self-retrieving autobiography Mauro was not right, Amman felt, for her emerging self-story Men, especially Nor was she uncomfortable with this; the media were already thronged with opinions about The New Sensuality Not that this happened, but the story by now had Amman as its chief librarian and confidant On Ammans advice, she dropped her first love, Mauro, even though he had taken her virginity — which Amman knew and her parents did not On her deathbed Amman sat beside her in its latest embodiment, a handsome gentleman with sorrowful blue eyes Perhaps she had more personality than needed for one person, but not enough for two Semisents conversation was a stylized human persona that steadily learned their clients vagaries Semisents were like other people, only more so She called it Amman, after a boy she liked She came to realize, at mid-career, that we slide through life on skids of routine She decided one day, on a hike with Amman, to leave her family and live on her own She felt a quality of beauty and tragedy to her life, her days like waves endlessly breaking on a golden beach that would itself endure She got her first semi-sentient, as they were called then, to help with her homework and because they were cool She had always kept dogs, too, and she saw parallels She moved Amman among various embodiments, through decades and upgrades She suspected that she was a bit too intense She then knew how much her mind rewrote her life, because Amman didnt: it stored and pondered She was a field biologist, and thought of how humanity long ago had worked with wolves She wondered, at the end, if the dogs were jealous. Sometimes it even gave her advice, apparently from some fresh Brazilian software her parents had bought The excess she could work off in long, soulful talks with Amman The idea unfurled in a long talk while they took shelter under a bioformed sunflower which, at nightfall, drooped its giant petals over to form a warm tent Traditional Islam was no guide in this brave new whirl that life had become We loved them despite their oddities: we learned to work with them, new wolves and people designing each other Without thinking deeply about it, we picked the pups we liked the best
 Carrying only their suitcases, Debye and his wife travelled to the Netherlands, ostensibly for a lecture tour, but they never returned Debye told us about one of the buildings at the Kaiser Wilhelm Institute for Physics, where he was director, that had the name of the previous director, Max Planck, chiselled in stone above the entrance He also described how he was finally convinced to flee Germany when a direct order came from Hitler to put all the institutes resources into the development of the atomic bomb I was a junior member of his chemistry department at Cornell University and I remember two stories in particular that make it hard to believe Debye had Nazi links Instead they went on to London and eventually to America. Sir I read with chagrin your News in Brief story “Dutch universities ditch reported Nazi collaborator” ( Nature 440 , 139 ; 2006 ), stating that two Dutch universities have rescinded the recognition previously accorded to Peter Debye That way, when visitors asked about the unseemly aberration, he would feel obliged to answer When ordered to erase the dedication to Planck (who had tried to help Jewish colleagues), Debye had workmen cover it with a large wooden board
 In addition, they support the idea that MDMX is a specific chemotherapeutic target for treating retinoblastoma. In contrast to this prevailing theory, here we show that the tumour surveillance pathway mediated by Arf, MDM2, MDMX and p53 is activated after loss of RB1 during retinogenesis Most human tumours have genetic mutations in their Rb and p53 pathways, but retinoblastoma is thought to be an exception Our data provide evidence that the p53 pathway is inactivated in retinoblastoma and that this cancer does not originate from intrinsically death-resistant cells as previously thought RB1 -deficient retinoblasts undergo p53-mediated apoptosis and exit the cell cycle Studies suggest that retinoblastomas, which initiate with mutations in the gene retinoblastoma 1 ( RB1 ), bypass the p53 pathway because they arise from intrinsically death-resistant cells during retinal development Subsequently, amplification of the MDMX gene and increased expression of MDMX protein are strongly selected for during tumour progression as a mechanism to suppress the p53 response in RB1 -deficient retinal cells All mice were crossed to C57Bl/6 mice purchased from Charles River Laboratories  Ashery-Padan Cepko; and Pax6–Cre mice from R Human retinae Human retinae were obtained from Advanced Bioscience Resources  Individual protocols are provided on the authors’ website ( http://www.stjude.org/dyer ) Jacks; Chx10–Cre mice from C Methods A detailed description of materials and methods is given in Supplementary Information  Mouse and rat strains Rb +/- mice were obtained from The Jackson Laboratory ; p53 Lox/Lox and Rb Lox/Lox mice from the National Cancer Institute; p107 knockout mice from T The xenograft model of retinoblastoma has been described  They were maintained in culture by using protocols that we previously developed for mouse retinal cultures. Timed-pregnant Sprague Dawley rats were obtained from Charles River Laboratories  A higher proportion of Pax6-expressing cells were found among the RB1 -deficient retinoblasts ( Supplementary Fig. 7l ) expressing MDMX, consistent with their immature cell morphology ( Fig. 4d ) A mutant form of MDMX (MDMX-G57A) that cannot bind to p53 (ref. 22 ) was used as a control ( Supplementary Fig. 7k ) Additional genetic changes (such as MDMX gene amplification) occur in the preneoplastic retinoblastoma cells, and cells in which the p53 pathway is inactivated have a growth advantage over those with an intact Arf–MDM2/MDMX–p53 tumour surveillance network After 3 weeks, the retinae were isolated and stained for alkaline phosphatase expression After 5 d in culture, the retinae were treated with [ 3 H]thymidine for 24 h to label all proliferating cells After another 48 h, they were treated with a 1-h pulse of BrdU, again to label proliferating cells After irradiation, the Y79, Weri1 and ML-1 cells showed an increase in p53 protein, phosphorylation of p53 on Ser 15, accumulation of p53 targets p21 and MDM2 ( Fig. 2a–e and Supplementary Fig. 4a–e ), cell-cycle exit and apoptosis ( Fig. 2f–i and Supplementary Fig. 4f, g ) Alternatively, if p53 and downstream targets are intact and functional, then therapy that induces a p53 response may be effective Although these data indicate that p53 has a role in retinoblastoma, they do not recapitulate the precise genetic changes that occur in human retinoblastomas, which express wild-type p53  Because human retinoblastomas express wild-type p53 , it was assumed that the p53 pathway was intact and the status of the other genes in the pathway (such as p14 ARF , MDM2 and MDMX ) was not considered By altering the quantities of p53 or MDMX in Weri1 retinoblastoma cells, we could change the sensitivity to nutlin-3 ( Supplementary Fig. 8e–g) By contrast, mice lacking p107 , Rb and p53 develop 100% penetrant bilateral retinoblastoma that is aggressive and invasive  By scoring the proportions of activated caspase-3-positive cells and TUNEL-positive cells, we confirmed that MDMX blocked cell death in Rb-deficient human retinoblasts through its ability to bind and inactivate p53, as indicated by the inability of MDMX-G57A to replicate this action ( Fig. 4i ) Cells electroporated with a control siRNA differentiated and extended processes after 10 d in explant culture ( Fig. 4a ) Cells transfected with the p53 siRNA also contained more 5-bromodeoxyuridine (BrdU)-positive cells ( Fig. 2o ) Cells transfected with the p53 siRNA contained fewer activated caspase-3-positive cells, fewer TdT-mediated dUTP nick end labelling (TUNEL)-positive cells, and fewer fragmented nuclei characteristic of late-stage apoptosis 24 h after exposure to 5 Gy of ionizing radiation ( Fig. 2k–n and Supplementary Fig. 4h, i ) Coimmunoprecipitation experiments showed that nutlin-3 prevents the MDMX–p53 interaction in cells ( Fig. 5g and Supplementary Fig. 8a ), and a mouse embryonic fibroblast (MEF) growth assay showed that nutlin-3 can induce the p53 pathway by inhibiting MDMX binding to p53 ( Supplementary Fig. 8c, d ) Combined subconjunctival injection of topotecan and nutlin-3 reduced tumour burden 82-fold with no systemic or ocular side-effects Conversely, cells expressing the MDMX siRNA had a similar or more robust response to 5 Gy of ionizing radiation than did the controls ( Fig. 2k–o and Supplementary Fig. 4h, i ) Discussion A previous study correlated apoptosis with retinal-cell-type markers and concluded that, in mice, retinoblastoma originates from intrinsically death-resistant cells  Ectopic expression of MDMX in the central retina had little effect on proliferation or differentiation ( Fig. 3e ) Even though nutlin-3 binds less efficiently to MDMX than to MDM2, intraocular concentrations of nutlin-3 achieved by subconjunctival injection should be sufficient to disrupt both MDM2–p53 and MDMX–p53 in retinoblastomas Expression of MDMX promoted proliferation and survival in developing retinal cells lacking Rb and p107 ( Fig. 3a–c ) Expression of p14 ARF was increased 71- to 500-fold in the tumour samples as compared with normal human fetal retinae ( Fig. 1a ) For example, a cell line (Rh18) with an MDM2 gene amplification has wild-type p53 and shows a robust p53 response to 5 Gy of ionizing radiation ( Supplementary Fig. 2 ) For example, some cancers have MDM2 gene amplifications that suppress the p53 pathway by reducing steady-state amounts of the p53 protein  Fresh retinoblastoma tumour cells from untreated enucleated eyes showed a similar p53 response to irradiation ( Supplementary Fig. 5 ) Functional p53 pathway downstream of MDMX Perturbations of one gene in the p53 pathway relieves the selective pressure to inactivate other genes in the same pathway  If increased MDMX expression contributes to tumorigenesis, then ectopic expression of MDMX in Rb ; p107 -deficient retinae should promote tumour progression similar to that observed in Chx10–Cre;Rb Lox/- ;p107 -/- ;p53 Lox/ - mice  If retinoblastomas arise from intrinsically death-resistant cells, then tumour cells with genetic perturbations that inactivate the p53 pathway will have no growth advantage If this is true, then therapeutic targets may differ, depending on the initiating genetic lesion and the pathways bypassed In addition, combining nutlin-3 with topotecan synergistically increases tumour cell killing In addition, MDMX promoted the progression from differentiated early stage tumour cells that resemble amacrine and/or horizontal cells to tumour cells with features of less differentiated cells ( Supplementary Fig. 7m–q and Supplementary Tables 5–7 ) Inactivation of the Rb pathway in the developing mouse or human retina leads to ectopic proliferation and activation of the Arf–MDM2/MDMX–p53 tumour surveillance pathway It has been proposed that both the p16 Ink4a –CycD/Cdk4–pRb and Arf–MDM2/MDMX–p53 pathways must be inactivated during tumorigenesis  It is also possible, however, that there are two distinct tumour cell types (amacrine/horizontal and progenitor) that originate from distinct cells of origin  It suggests that, depending on the cell of origin, cancer can proceed down a ‘fast track’ of tumorigenesis, because the cells are programmed to bypass some tumour suppressor pathways  Local delivery of nutlin-3 or other MDMX inhibitors being developed may also be beneficial for the treatment of breast, colon, lung and prostate cancers with MDMX amplifications. MDMX and MDM2 bind p53 (ref. 34 ) with similar affinities (dissociation constant, K d  = 0.5 μM; Fig. 5e ) MDMX is amplified in retinoblastoma Analysis by bacterial artificial chromosome comparative genome hybridization (BAC-CGH) showed that MDMX , a gene related to MDM2 , was amplified in three of seven fresh retinoblastoma samples; this amplification correlated with an increase in MDMX messenger RNA ( Fig. 1b ) and protein ( Fig. 1c ) MdmX partially rescued the loss of Mdm2 in MEFs, and the effect of MdmX was blocked by nutlin-3 even in the absence of Mdm2 ( Supplementary Figs 9 and 10 ) MDMX promotes human retinoblastoma We electroporated primary human FW14 retinae with an RB1 siRNA, an MDMX cDNA and a green fluorescent protein (GFP) reporter gene MDMX promotes retinoblastoma in mice Inactivation of Rb and p107 can lead to retinoblastoma in chimaeric mice , and p107 -deficient mice with Rb deletion targeted to the developing retina are susceptible to retinoblastoma ; however, the penetrance is low, tumour progression is slow, and the tumours are not as aggressive or invasive as human retinoblastomas  Moreover, these cells expressed the retinal progenitor cell marker Pax6, which is expressed in mouse retinoblastomas ( Fig. 3a, d ) Moreover, those cells showed morphological features ( Supplementary Fig. 7b–j and Supplementary Tables 2–4 ) and aggressive invasive retinoblastoma similar to those of Chx10–Cre;Rb Lox/ - ;p53 Lox/ - ;p107 - / - mice ( Fig. 3i–k ) Neither cell proliferation nor viability was altered after ectopic p53 expression in Weri1 or Y79 cells ( Supplementary Fig. 4j–l) Nutlin-3 also induces a p53 response in these cells ( Supplementary Fig. 8j–n ) Nutlin-3 antagonizes the MDMX–p53 interaction and efficiently kills retinoblastoma cells Nutlin-3 blocks MDMX in retinoblastoma Computational modelling of nutlin-3, a small-molecule inhibitor of the MDM2–p53 interaction 12 ( Fig. 5a, b ), suggested that nutlin-3 may block the MDMX–p53 interaction ( Fig. 5c, d ) Of note, 32 of 49 (65%) human retinoblastomas had extra copies of MDMX , and 5 of 49 (10%) had extra copies of MDM2 ( Supplementary Table 1 ) Of note, retinoblastoma cells (Weri1) with wild-type p53 and MDMX amplification ( Supplementary Fig. 3 ) were sensitive to racemic nutlin-3 (50% limiting concentration LC 50  = 0.7 μM), whereas a p53-deficient retinoblastoma cell line (SJMRBL-8) was insensitive ( Fig. 5h ) On the basis of our preclinical studies, we propose that subconjunctival administration of these two drugs could achieve the same synergistic effect in individuals with retinoblastoma without causing the side-effects associated with prolonged systemic exposure to broad-spectrum chemotherapeutic drugs On the basis of these data, we propose that cells with disruptions in the Rb and p53 pathways clonally expand and form retinoblastoma One drug, topotecan, induces a p53 response in retinoblastoma cells that is similar to that induced by 5 Gy of ionizing radiation ( Supplementary Fig. 8h, i ) Racemic nutlin-3 also specifically bound to MDMX with a K i of 28 μM (∼14 μM inferred K i for nutlin-3a; Fig. 5f ) Racemic nutlin-3 bound to MDM2 with an inhibition constant ( K i ) of 0.7 μM ( Fig. 5f ), confirming published results using enantiomerically pure nutlin-3a  Rb is reported to be inactivated in the peripheral 30–40% of the Pax6–Cre;Rb Lox/Lox ;p107 - / - retinae ; therefore, within a single retina, we compared the effects of ectopic MDMX expression in cells lacking Rb and p107 (peripheral retina) with those in cells lacking only p107 (central retina) RB1 loss induces p14 ARF in human retinae A key component of the p53 tumour surveillance pathway is p14 ARF (ref. 3 ) Retinoblastomas that arise from cells that have lost RB1 have not been found to contain subsequent genetic lesions in the p53 gene or p53 pathway  Several preclinical models of retinoblastoma have been developed and used to test combinations of broad-spectrum chemotherapy  Similar analyses of mouse retinoblastomas showed a 74- to 430-fold induction of p19 Arf expression (data not shown) Similar results were obtained using a Cre-expressing plasmid in Rb Lox/Lox ;p107 -/- mouse retinae (data not shown) Similar results were obtained with lentiviral vectors expressing MDMX and p53 siRNAs ( Supplementary Fig. 6 ) Some hyperplasia formed in the periphery of Pax6–Cre;Rb Lox/Lox ;p107 - / - retinae, but we observed minimal clonal expansion of individual cells in that region ( Fig. 3f ) Specifically, if the retinoblastoma cell of origin bypasses the p53 pathway, then chemotherapy targeting that pathway is inappropriate Studies on Rb;p107 -deficient mouse retinae have led to the proposal that retinoblastoma is a unique tumour that bypasses the p53 pathway because its cell of origin is intrinsically resistant to death  The best combination of systemic chemotherapy in this model resulted in only a fivefold reduction in tumour burden, and the mice suffered from severe complications associated with systemic broad-spectrum chemotherapy  The combination of topotecan and nutlin-3 synergistically killed retinoblastoma cells in culture ( Supplementary Fig. 8o ) and in our preclinical retinoblastoma models ( Fig. 5i–m ) The ectopic proliferation caused by the loss of the Rb pathway is balanced, to some extent, by p53-mediated apoptosis The MDMX gene copy number and the proportion of p53 ( t  = -0.3321; P  = 0.0096) and p21 ( t  = -0.2565; P  = 0.0447) immunopositive cells were inversely correlated, similar to previous studies in human breast tumours  The MDMX-G57A mutant confirmed that suppression of cell death was specific to the p53 pathway ( Fig. 4f ) The primary role of the Rb pathway is to regulate cell proliferation , and that of the p53 pathway is to regulate responses to cellular insults (such as DNA damage or oncogenic stress)  The proportion of BrdU-positive cells was significantly greater when MDMX was coexpressed with the RB1 siRNA but not when MDMX - G57A was expressed; similar results were observed in the [ 3 H]thymidine-positive cells and the double-positive cells ( Fig. 4g, h ), which continued to divide 5–7 d in culture The survival and proliferation of transfected cells were analysed 7 and 14 d after electroporation Therefore, identifying genetic perturbations in the Rb and p53 pathways can provide chemotherapeutic targets These data suggest that loss of RB1 in the developing human retina or loss of Rb and p107 in mouse retinae causes derepression of Arf and activation of the tumour surveillance mechanism These findings not only challenge the long-standing belief that retinoblastoma is the exception to the rule that the Rb and p53 pathways must be inactivated in cancer, but also provide a specific target for chemotherapy These pathways may be inactivated by mutations in their respective tumour suppressor genes, RB1 and p53 (also known as TP53 ) or in genes encoding modulators and/or effectors in these pathways This theory has important implications for cancer genetics and treatment Those electroporated with the RB1 siRNA underwent extensive apoptosis ( Fig. 4b, c ) To confirm that the p53 pathway is intact downstream of MDMX in retinoblastoma cells, we ectopically expressed p53, which has been shown to elicit a robust p53 response in p53-null cells but not in wild-type cells  To determine whether the Arf–MDM2/MDMX–p53 oncogenic stress response pathway is intact in retinoblastoma, we isolated RNA and genomic DNA from human retinoblastomas To quantify changes in proliferation and cell survival, we repeated the above experiment with modifications To test this hypothesis, we used square-wave electroporation to introduce a plasmid expressing Cre recombinase or Cre recombinase and MDMX ( Supplementary Fig. 7a ) into the eyes of newborn Rb Lox/Lox ;p107 - / - pups To test whether the mechanism by which nutlin-3 induces a p53 response in retinoblastoma cells with MDMX amplification is through MDM2 rather than through direct binding, we carried out experiments in Mdm2 -deficient MEFs ( Supplementary Figs 9 and 10 and Table 8 ) To test whether the p53 pathway is functional downstream of MDMX in retinoblastoma cells, we exposed Weri1 and Y79 human retinoblastoma cell lines ( Supplementary Fig. 3 ) to 5 Gy of ionizing radiation  Tumorigenesis involves sequential genetic lesions in pathways that regulate biological processes such as cell proliferation and cell survival  We acutely knocked down the expression of RB1 in fetal week 14 (FW14) primary human retinae using an RB1 siRNA and found that p14 ARF was induced ( Supplementary Fig. 1a–g ) We extended these data to include 49 paraffin-embedded retinoblastoma samples and carried out fluorescent in situ hybridization (FISH) analysis for MDMX and MDM2 and immunohistochemistry for p53, p21, MDM2 and MDMX ( Fig. 1d–k and Supplementary Fig. 1h ) We next tested whether the response to ionizing radiation was p53 dependent and whether MDMX modulates the p53 pathway in retinoblastoma We propose that inactivation of the p53 pathway promotes the transition from differentiated retinoblastoma cells with amacrine/horizontal cell features to a more immature cell with retinal progenitor cell features We then injected a plasmid expressing MDMX and an alkaline phosphatase reporter gene into the subretinal space of newborn Pax6–Cre;Rb Lox/Lox ;p107 - / - pups and subsequently electroporated it into the developing retinal cells We used ML-1 leukaemia cells with wild-type p53 as a positive control , and the p53 -deficient mouse retinoblastoma cell line SJMRBL-8 as a negative control (N.L. and M.A.D., unpublished data) When MDM2-mediated destabilization of p53 is blocked by the inhibitor nutlin-3 in tumours with MDM2 gene amplifications, the p53 pathway is restored and tumour cells undergo p53-mediated cell-cycle arrest, cell death, or both  When MDMX was expressed in cells lacking Rb and p107 in the peripheral retina that lacked hyperplasia, clonal expansion occurred ( Fig. 3g, h ) When Rb activity is lost, the transcription factor E2F activates transcription of p14 ARF (ref. 17 ); p14 ARF then inactivates MDM2 (ref. 18 ), leading to p53-mediated apoptosis and exit from the cell cycle When the RB1 siRNA and an MDMX cDNA were electroporated together, by contrast, minimal cell death occurred and the immature cells organized into rosettes similar to retinoblastoma ( Fig. 4d, e ) Y79 and Weri1 cells were transfected with a vector encoding short interfering RNAs (siRNAs) targeted to p53 or MDMX ( Fig. 2j ) and 48 h later were exposed to 5 Gy of ionizing radiation
 The immune systems of some infected individuals can spontaneously clear the virus, whereas other people need treatment with antivirals that work partly by stimulating humoral and cellular immune responses The recent discovery of natural immunity to the hepatitis C virus and vaccine efficacy in the chimpanzee challenge model has allowed optimism about the development of at least a partly effective vaccine against this heterogeneous pathogen that is responsible for much of the chronic liver disease around the world Therefore, therapeutic vaccine strategies are also being pursued to improve treatment outcome. A crucial question that remained was whether the vaccine derived from strain HCV-1 would protect against heterologous strains of the virus A decade ago, an effective vaccination against the hepatitis C virus (HCV) was considered only a remote possibility A defective ovine atadenovirus vector may also be useful in this regard Although none of the vaccinated animals was protected against acute infection, all but one vaccinee resolved the acute infection and failed to progress to the carrier state (as demonstrated by the persistent absence of detectable viraemia in follow-up blood samples using sensitive RT–PCR assays) Although some re-exposed individuals develop chronic infection , most do not  Although the viral challenge doses were small (10–100 chimpanzee infectious doses 50 (CID 50 )), such doses are considered to be within the same range as those transmitted in many community-acquired HCV infections because the infectivity titre of most carriers is known to be low  Apart from optimizing vaccine formulations to maximize humoral and cellular immune responses, future issues include expanding the range and level of cross-protection afforded by the vaccine Both types of T cell can secrete antiviral cytokines such as interferon-γ (IFN-γ), and CD8 + CTLs have the potential to kill infected cells But, as may be the case for optimal prophylaxis, boosting all of these immune responses may be ideal for immunotherapy By contrast, if the host has the ability to elicit early and broad T H 1-type CD4 + and CD8 + T-cell responses to the virus and also has a NK receptor repertoire that facilitates innate immune clearance of virus , then eradication of virus can occur By contrast, the majority of control animals became carriers when challenged with HCV-H, indicating that the vaccine significantly reduced chronic, persistent infection ( Table 1 ) Considering that this is the only vaccine formulation of several tested by us that failed to result in prevention of HCV chronicity in at least some animals, this result also emphasizes the importance of using the chimpanzee challenge model before proceeding to clinical testing Correlates of immunity Infected humans and chimpanzees who mount an early, multi-specific CD4 + T H and CD8 + T-cell response to HCV proteins can eradicate the virus (see the review in this issue by Bowen and Walker, page 946 , and refs 15–24 ) Derived from mammalian cells, the two glycoproteins associate together to from a non-disulphide linked gpE1–gpE2 heterodimer that is thought to resemble the pre-virion envelope structure  DNA vaccines also include immunostimulatory deoxycytosine-deoxyguanosine (CpG)-containing motifs capable of activating antigen-presenting dendritic cells Effector T cells specific to the virus also seem to be downregulated in some way as a consequence of persistent HCV infection  Emerging results from the chimpanzee challenge model suggest that successful vaccination against homologous and at least some heterologous HCV strains may be feasible, although the relative roles of humoral and cellular immunity in protection need to be better defined First, we now know that spontaneous eradication of the virus occurs in up to 50% of acute infections and that this viral clearance is associated with specific immune responses to the virus Following challenge with a heterologous strain (which causes chronic, persistent infection in the large majority of control animals), one vaccinee experienced an ameliorated and abortive acute infection that did not progress to the carrier state, whereas the other vaccinee developed chronic infection, albeit ameliorated in terms of viral load and level of hepatitis Further work is required, however, to better define these cellular correlates of immunity Furthermore, although lower-responding animals became infected, the majority underwent an abortive acute infection that did not result in the persistently infected carrier state that in humans can be associated with chronic liver disease  Furthermore, the recent application of these pseudoparticle infectivity assays to the investigation of immune correlates of protection are beginning to indicate that such ‘neutralizing’ antibodies, when present, may be associated with recovery from acute infection, at least in some cases (for an example, see Fig. 1 ) Future directions In the future, it will be important to use the chimpanzee model to further define correlates of protection, duration of vaccine-mediated protection, the extent of cross-protection against diverse genotypes and mechanisms of chronicity and to determine optimal vaccine formulations for prophylactic and immunotherapeutic efficacy HCV tries to counter innate immunity by inhibiting the induction of type-1 interferons (IFN-α/β) and downregulating NK-cell activity  However, challenges for these approaches include the problem of pre-existing immunity to some of these vectors in the human population, thus limiting potency However, preliminary data have directly linked responses to IFN-α and ribavirin with pretreatment titres of viral antibodies (presumed to be against the envelope glycoproteins), peripheral T H cell responses to the HCV core and other antigens , as well as to intrahepatic CD8 + CTL responses to the virus  However, some of these cohorts have been used successfully in the past (for testing hepatitis B vaccines) and so these obstacles should not be insurmountable However, the recent production of lentiviral/HCV pseudoparticles (HCVpp) bearing HCV envelope glycoproteins on the particle surface have been used to show that patients not only have antibodies that can neutralize the infectivity of such pseudoparticles but that such antibodies cross-neutralize pseudoparticles derived from many different HCV genotypes  If a vaccine is successfully developed, an important cause of global morbidity and mortality will be controlled and, even in countries with a relatively low incidence of infection, the vaccine will be reasonably cost-effective when used in the general population  If successful, vaccination for the treatment of chronic hepatitis C would be one of the first demonstrations of immunotherapeutic intervention in chronic viral infections, although, very recently, such an approach has been used successfully to inhibit the age-related emergence of herpes zoster infections and disease in carriers  Importantly, protection is usually at the level of prevention of progression to chronic, persistent infection following re-exposure rather than prevention of acute reinfection but this could translate to effective prophylaxis because, in humans, it is the chronic, persistent nature of HCV infection that is mainly associated with viral pathogenicity  In addition, human cohorts at high risk of infection need to be identified and characterized for efficacy trials In patients infected with genotype 1, the most common form, response rates are even lower  In this review, we will summarize current knowledge regarding the correlates of immunity to HCV as well as the results of pre-clinical studies using vaccine candidates designed to recapitulate protective immunity Indeed, emerging vaccine efficacy data from the chimpanzee challenge model indicate that it is possible to impede the progression to chronic infection in vaccinees It is also possible that the presence of viral-neutralizing antibody may enhance this process  It is clear that these cellular immune responses to the virus can occur in the absence of antibody to gpE1 and gpE2 (ref. 19 ), indicating that such antibodies are not absolutely required for recovery from acute infection It is difficult to prime CD8 + CTLs using polypeptide subunit vaccines, although certain adjuvants are capable of eliciting such responses  It remains to be seen whether boosting viral-neutralizing antibody titres or broad CD4 + T H responses or broad CD8 + T-cell responses will have the greatest impact on reducing viral load and in the response to antiviral therapy It will also be important to understand the mechanisms involved in immune dysfunction and evasion during chronic HCV infections so as to facilitate the design of further immunotherapies. Many studies correlate recovery from acute HCV infection with cellular immune responses to the virus, and so other relevant strat-egies for developing a vaccine will involve eliciting a broad cellular immune response to the virus or, preferably, both a humoral (anti-gpE1/gpE2) and a cellular immune response Many therapeutic vaccine trials are planned or are already in progress and use diverse delivery methods and formulations (summarized in Table 3 ) but little information is available about their efficacy at present One promising approach is the use of defective alphaviral delivery vectors that infect professional antigen-presenting dendritic cells, activate innate immunity as well as adaptive cellular and humoral immune responses to encoded vaccine antigens and which can be used repeatedly to boost immune responses in mice  One small study using the chimpanzee model investigated the use of a vaccination regimen employing multiple immunizations with plasmid DNA encoding the nucleocapsid (C), gpE1, gpE2 and nonstructural protein 3 (NS3) domains followed by multiple boosting with an adjuvanted mixture of recombinant C, gpE1, gpE2 and NS3 proteins  Other approaches to HCV vaccination (summarized in Table 2 ), in common with those used in vaccine research for other persistent pathogens like HIV and malaria, include the use of various defective or attenuated viral vectors to enhance priming of humoral and cellular immune responses to multiple HCV gene products expressed by the vector Other mechanisms of viral persistence are likely to emerge in the future Other promising approaches being explored include the use of DNA microparticles , which can significantly enhance the potency of DNA vaccines and HCV viral-like particles produced in insect cells that have an inherently strong immunogenicity  Our earlier work showed that when these vaccinated animals were challenged experimentally with homologous viral inocula, the highest responding animals (in terms of anti-gpE1/gpE2 antibody titres) were completely protected against infection  Overall, these data showed that the carrier rate in vaccinees was significantly lower than in unimmunized controls ( Table 1 ) Potential for therapeutic HCV vaccination The current standard-of-care therapy for chronically infected HCV patients is a combination of pegylated IFN-α and ribavirin, which is costly, lengthy (6–12 months), associated with significant side effects and results in sustained viral response in only ∼50% of patients Prevention strategies Results from our recent studies have made us optimistic about successfully vaccinating against HCV Proving the efficacy of the vaccine in humans is a significant challenge because accessing groups at high risk of HCV infection is no longer a simple task Recapitulation of such immune responses by appropriate vaccination is therefore a realistic option Recently, we have challenged nine chimpanzee vaccinees with the HCV-H strain that, like the vaccine strain HCV-1, is of the 1a genotype that predominates in the United States  Repeated vaccination to boost initial immune responses can also be limited by vector-elicited immunity Second, clear evidence for at least some natural immunity has emerged recently in both humans and chimpanzees . (Chimpanzees are the only animal model available and develop only mild clinical sequelae.) Convalescent humans and chimpanzees are protected against re-exposure to the virus in the majority of cases, even against very divergent viral strains Some of these vectors also infect and/or activate antigen-presenting dendritic cells, thus enhancing antigen presentation and stimulating innate immune responses that, in turn, lead to enhancement of adaptive immune responses to the encoded vaccine antigens Specific CD8 + CTLs can kill HCV-infected cells, although large reductions in viral load during acute infection were not associated with an increase in acute hepatitis, suggesting that cytolytic activity may not be the main factor in viral control  Studies in the past several years have helped to define the sophisticated battle initiated in the infected host unotherapy may also help control the emergence of escape mutants that would be predicted to arise from any future use of HCV protease or replicase inhibitors, for example, given the extreme fluidity and heterogeneity of the HCV genome  Such molecules include oligonucleotides containing CpG motifs that trigger Toll-like receptor 9 within dendritic cells and that also enhance adaptive immune responses to vaccine antigens  Surprisingly, eliciting broad CD4 + and CD8 + T-cell responses to the virus in the absence of any antibody responses to the envelope glycoproteins (using an ISCOMATRIX®-adjuvanted NS3-4-5-Core polyprotein derived from strain HCV-1) failed to prevent chronic, persistent infection following challenge with the heterologous HCV-H strain in five out of five chimpanzee vaccinees tested, despite observing a substantial amelioration in acute viraemia and hepatitis (M.H., unpublished data) The huge burden of chronically infected HCV patients facilitates the testing of various immunotherapeutic vaccine formulations that, most probably, will be especially useful when used as adjunct therapy with antiviral drugs, including pegylated IFN-α and ribavirin as well as the new class of HCV drugs currently under development that inhibit viral enzymes and other elements crucial to the viral life-cycle The relative roles of humoral and cellular immunity in recovery remain unclear The situation today is more positive for two reasons The status and issues surrounding clinical development will be discussed as well as the rationale and prospect for immunotherapeutic vaccination strategies The use of adenoviral , avipox , alphaviral and vaccinia viral vectors, among others, are all being explored in various animal models including the chimpanzee challenge model The use of various prime/boost immunization modes and regimens are also being explored to optimize vaccine immunogenicity and potency The virus inhibits the induction of type-1 interferons , inhibits NK cells , readily produces escape mutants to CTLs and neutralizing antibodies directed to the amino-terminal region of gpE2 HCV may also inhibit the binding of virion-neutralizing antibodies by masking with lipoproteins  Therefore, it may be possible to boost such immune responses in patients by appropriate vaccination and thereby improve the response rate to the standard-of-care therapy Therefore, therapeutic vaccine formulations could benefit by inclusion of molecules capable of triggering innate immune responses These activated T cells secrete pro-inflammatory cytokines (T H 1-type) such as IFN-γ, which is directly antiviral for HCV replicons in cell culture and temporally associated with large reductions in viral load during acute infection  These approaches offer the potential of improved immunogenicity as a result of enhanced gene delivery and expression These data provide additional support for the feasibility of successful vaccination against HCV but also suggest that further optimization of vaccine immunogenicity is required These pre-clinical data (and supporting data from other small studies exploring various gpE1/gpE2 vaccine formulations ) support the initiation of a clinical prophylactic programme using adjuvanted gpE1/gpE2 that is currently in phase 1 testing These studies involved the use of the recombinant HCV envelope glycoproteins gpE1 and gpE2 as vaccine antigens This apparent sterilizing immunity correlated directly with anti-gpE2 antibody titres that prevent the binding of gpE2 (or the virus itself) to CD81 (ref. 45 ), which has been shown to be an important receptor component for binding of infectious HCV and for cell entry of lentiviral/HCV pseudoparticles  This may include the targeting of antigen-presenting cells in some cases This result also suggests that vaccine formulations capable of priming both anti-envelope neutralizing antibody and broad cellular immune responses to the virus may be more effective This result may be caused by insufficient priming of cellular immune responses by the vaccine regimen or protocol because recovery from acute infection has been linked with cellular immune responses to the virus in the absence of anti-envelope antibody responses  This RNA virus (which cannot integrate into the host genome) has evolved mechanisms to persist and to evade the hosts innate and adaptive immune mechanisms (see the reviews in this issue by Gale and Foy, page 939 , and Bowen and Walker, page 946 ) This suggests that a broad cross-neutralizing antibody to HCV may exist and could be exploited in vaccine strategies This suggests that the generation of at least a partly effective vaccine against HCV is feasible This will require more extensive analyses into the nature and range of cross-neutralizing antibody and cross-protective cellular immune responses and will probably involve the definition of cocktails of immunogens derived from various HCV genotypes to obtain an effective global vaccine formulation This would lead to stimulation of innate immune responses (such as the synthesis of type 1 interferons and natural killer (NK) cells) as well as adaptive B- and T-cell responses to vaccine antigens Three factors contributed to this: the high propensity of HCV to promote chronic persistent infections ; evidence that convalescent humans and chimpanzees could be readily reinfected following re-exposure ; and the considerable genetic heterogeneity of this positive-stranded RNA virus  To overcome this obstacle, priming of the immune response with DNA vaccines followed by boosting with recombinant viral vectors is being employed as well as prime/boost regimens using different recombinant vectors for each immunization Total pretreatment CD8 + T-cell counts in the liver have also been correlated with sustained responses to standard-of-care therapy  Until very recently , HCV has not been propagated efficiently in cell culture, meaning that a direct assay for viral-neutralizing antibody has not been available Until very recently , it was not possible to grow HCV efficiently in cell culture, and so the use of inactivated or live, attenuated viral vaccines has not yet been evaluated Using sensitive RT–PCR assays, no viraemia was detected in blood or liver samples at any time after challenge in these seemingly ‘sterilized’ animals Vaccine approaches have therefore included the use of adjuvanted recombinant polypeptide subunits of the virus in attempts to prime viral-neutralizing antibodies to the envelope glycoproteins 1 and 2 (gpE1 and gpE2), as well as priming MHC class-II-restricted CD4 + T helper (T H ) and MHC class-I-restricted CD8 + cytotoxic lymphocyte (CTL) responses to these and other viral proteins Various forms of plasmid DNA vaccine are also being explored to elicit HCV-specific humoral and cellular immune responses to encoded antigens which, by virtue of being newly synthesized in the cytosol of transfected cells, can be particularly effective at priming CD8 + CTLs Various live attenuated or defective viral or bacterial vectors expressing HCV genes are also being investigated because improved vaccine immunogenicity can result from more efficient expression and delivery of HCV antigens What is known, however, is that use of an alum-adjuvanted recombinant gpE1 antigen was able to boost humoral and cellular immune responses to gpE1 in viraemic patients, providing encouragement that vaccination can increase immune responses in pre-existing carriers  When combined with oil/water-based adjuvants and used to vaccinate naive chimpanzees, this vaccine candidate elicits anti-envelope antibodies as well as T H cell responses to gpE1 and gpE2 With an estimated 170 million HCV carriers worldwide, it is clearly important to develop better therapeutic options With our increasing knowledge of the virus-encoded enzymes and genetic elements vital to the life-cycle of HCV, much attention is now being focused on the development of HCV protease, replicase, helicase, antisense, silencing RNA and other specific inhibitors With the near elimination of post-transfusion hepatitis C by donor screening, other high-risk groups suitable for efficacy testing have inherent difficulties such as lack of compliance (for example, intravenous drug users), low incidence of infection (for example, in health-care workers and paramedics), lack of supporting infrastructure (for example, in many developing countries where incidence of infection is high) and ethical issues (for example, in prisoner populations where prevalence and incidence of infection are both high)
 Recent progress has provided an insight into the molecular, cellular and behavioural mechanisms that link changes of body fat stores to adaptive adjustments of feeding behaviour The capacity to adjust food intake in response to changing energy requirements is essential for survival The physiological importance of this homeostatic control system is highlighted by the severe obesity that results from dysfunction of any of several of its key components This new information provides a biological context within which to consider the global obesity epidemic and identifies numerous potential avenues for therapeutic intervention and future research. A logical interpretation of these findings is that, although neuronal melanocortin signalling is critical for energy homeostasis, neither leptin receptor → JAK–STAT nor IRS–PI(3)K signalling is essential for proper functioning of these cells According to this hypothesis, reduced firing of secondary taste neurons diminishes the reward value of foods and thereby contributes to meal termination via projections to the striatum and amygdala, areas that attach motivational value needed to engage motor outputs  According to this view, the growing obesity epidemic can be attributed to an inherent lack of protection against obesity-promoting environmental factors , rather than to an underlying homeostatic disorder Acting in these forebrain areas, dopamine potently augments the drive to obtain a rewarding stimulus (that is, increases the ‘wanting’ of a particular food or drug) , but it is not directly responsible for the hedonic experience itself (that is, the ‘liking’ of a palatable food) Adiposity negative feedback Introduced more than 50 years ago, the ‘adiposity negative-feedback’ model of energy homeostasis is founded on the premise that circulating signals inform the brain of changes in body fat mass and that in response to this input, the brain mounts adaptive adjustments of energy balance to stabilize fat stores  Adjacent to these cells are neurons that express pro-opiomelanocortin (POMC), the polypeptide precursor from which melanocortins such as α-melanocyte stimulating hormone (α-MSH) are derived Alternatively, if adiposity negative-feedback signals do, in fact, confer protection against obesity in normal-weight individuals, neuronal resistance to these signals must, by definition, favour weight gain, and unravelling the underlying causes takes on both pathophysiological and therapeutic urgency Although delays between basic discovery and therapeutic application are inevitable, two obstacles that lie along this path are noteworthy Although environmental and lifestyle factors contribute to obesity pathogenesis, homeostatic adaptations to weight loss induced by voluntary caloric restriction are robust in both lean and obese individuals Although genetic and pharmacological studies suggest a more critical role for leptin than insulin in mammalian energy homeostasis, cross-talk between these hormones with respect to both the neuronal subsets and signal transduction pathways on which they act offers evidence of their shared evolutionary past Although leptin administration causes weight loss in diverse mammalian species, enthusiasm surrounding leptin as a therapeutic agent diminished rapidly with the discovery that leptin resistance is common among obese individuals  Although many nutrients (for example, free fatty acids and glucose), cytokines (for example, interleukin-6, tumour necrosis factor-α) and hormones (for example, glucocorticoids) fulfill some of these criteria, only leptin and insulin satisfy all of them  Although numerous environmental variables can influence meal initiation, satiety perception is a more biologically determined and predictable process , triggered on nutrient ingestion by gastric distension and the release of gut factors including cholecystokinin (CCK)  Although reduced neuronal signalling by either hormone induces hyperphagia and weight gain in animal models , whether neuronal resistance to these hormones contributes to the pathogenesis of common obesity is an important unanswered question Although the mechanism mediating these effects is unknown, it seems to involve the effect of fasting to lower leptin levels, as leptin-deficient mice display a similar alteration of synaptic input Among insulin- and leptin-sensing ARC neurons are those that co-express neuropeptide Y (NPY) and agouti-related protein (AgRP), neuropeptides that stimulate food intake via distinct mechanisms Among the targets of activated PKB are mTOR and the transcription factor FOXO1, which is inhibited by PKB-mediated phosphorylation ( Fig. 4b ) Among these are free fatty acids, which exert insulin-like effects in key brain areas for energy homeostasis, including the hypothalamic arcuate nucleus (ARC), possibly by favouring intracellular accumulation of long-chain fatty acyl-CoA (LCFA-CoA)  Among these are insulin receptor substrate (IRS) proteins, which are phosphorylated on tyrosine residues by the activated insulin receptor AMPK also decreases the activity of another nutrient-sensing enzyme, mammalian target of rapamycin (mTOR), implicated in hypothalamic leptin action  An oft-cited explanation for when knockout genotypes fail to yield abnormal phenotypes is ‘genetic redundancy’, in which loss of one gene is somehow compensated by altered expression of other genes or through more complex homeostatic mechanisms Another obstacle arises from a lack of scientific consensus regarding fundamental aspects of obesity pathogenesis As expected, leptin inhibits electrical activity of NPY/AgRP neurons , but whereas insulin increases PI(3)K signalling in these cells, leptin has the opposite effect  As fasting also augments the reinforcing value of electrical stimulation of brain ‘pleasure centres’  , reduced food availability seems to exert a global, stimulatory effect on reward perception As for many other chronic illnesses, effective prevention or treatment of obesity may therefore require drug combinations that target discrete components of energy homeostasis, satiety or food reward systems As our understanding of normal and abnormal regulation of food intake and body adiposity grows in its sophistication, overcoming these obstacles will create new opportunities for therapeutic intervention. As the list of neuronal cell types and signal transduction molecules involved in energy homeostasis continues to expand, a ‘systems biology’ approach will help to more accurately model outcomes when molecules are deleted in a cell-specific manner As weight is gained, rising plasma levels of leptin and insulin should subsequently inhibit NPY/AgRP neurons, which, in turn, will relieve tonic constraint of POMC cells At the cellular level, increased expression of dopamine re-uptake transporters in VTA neurons, which reduces synaptic dopamine levels in the NAc , may contribute to the inhibitory effect of adiposity-related hormones on food reward Because central inhibition of mTOR blocks leptin-mediated food intake suppression , mTOR activity seems to be essential for leptin action in this brain area Because homeostatic adjustments of food consumption must, by definition, involve changes of meal size, meal frequency, or both, systems that control energy homeostasis must integrate with those governing intake on a meal-to-meal basis Because hypothalamic AMPK activity is inhibited by leptin and insulin , but stimulated by ghrelin , altered AMPK signalling may contribute to the feeding effects of these hormones Because mTOR activation is well documented in response to both nutrient-related and IRS–PI(3)K signalling ( Fig. 4b ), it is possible that, rather than serving to link input from adiposity signals to firing rate, PI(3)K signalling in some hypothalamic neurons influences dendritic growth and synaptic input Because obesity has long been associated with insulin resistance in peripheral tissues, it is perhaps not surprising that in obese rats, the hypothalamus develops resistance to insulin as well as leptin  Brain areas beyond the ARC also probably contribute to leptins enhancement of the response to satiety signals, because leptin receptors are present in many brain areas involved in food intake control, including the NTS itself , and because leptin administration directly into the NTS reduces food intake  By comparison, deletion of Npy , Agrp , or both genes causes only mild defects in energy balance , raising questions about the relative importance of orexigenic versus anorexigenic signals in food intake and body weight regulation By comparison, leptin has not been detected in invertebrates and probably evolved more recently  By contrast, gradual ablation over a period of months—brought about either by expressing a polyglutamine-containing protein or by removing the capacity for oxidative phosphorylation specifically in NPY/AgRP neurons —had only mild effects on energy balance Changing energy requirements is another factor that can influence food consumption Clarifying the extent to which synaptic regulation of hypothalamic neurons can influence the defended level of body adiposity, determining whether diet-induced obesity involves changes of brain circuitry at the synaptic level, and delineating the mechanisms underlying such effects are important scientific priorities Collectively, these observations suggest that by decreasing neuronal input from adiposity signals, energy restriction increases responses to rewarding stimuli as an adaptive mechanism motivating animals threatened by caloric insufficiency to seek and obtain palatable foods Concluding remarks Theoretically, drugs that target neuronal receptors for leptin, insulin, ghrelin, melanocortins, NPY or other relevant ligands have important potential, but hoped-for therapeutic breakthroughs have yet to emerge Consensus DNA binding sequences for both FOXO1 (a transcription factor that is inhibited by PI(3)K) and STAT3 exist close to one another in both Agrp and Pomc promoters, and the effect of STAT3 on transcription of both neuropeptide genes is opposite to that of FOXO1  Consequently, pharmaceutical companies have little incentive to pursue strategies involving drug combinations unless each of the drugs under consideration is, by itself, ‘approvable’ Consequently, weight loss activates these neurons through a combination of reduced inhibitory and increased stimulatory input ( Fig. 4a ) Consistent with this hypothesis, centrally administered insulin or leptin diminishes both sucrose preference (a measure of food reward) and the effect of fasting to increase the rewarding properties of electrical pleasure-centre stimulation  Despite this progress, the many fundamental questions remaining unanswered represent rich opportunities for future study During caloric restriction, there is little question that reduced neuronal input from adiposity-related hormones activates responses (increased food intake, decreased metabolic rate) that favour recovery of lost weight Energy homeostasis Obesity, by definition, results from ingesting calories in excess of ongoing requirements Food-intake-stimulatory neurons in the lateral hypothalamic area seem to be constrained by tonic inhibition that can be relieved by activation of reward pathways, thereby engaging motor programs that stimulate feeding behaviour  For example, absence of leptin in obese ( Lep ob / Lep ob ) mice reduces Pomc expression in the ARC while increasing levels of NPY and AgRP , mimicking the hypothalamic response to starvation From the NTS, taste information is conveyed to multiple sites in the hindbrain (for example, parabrachial nucleus), midbrain (ventral tegmental area or VTA) and forebrain (for example, nucleus accumbens (NAc), striatum, thalamus and cerebral cortex) , which collectively sense and discriminate among different tastes and textures, assigning reward value to them ( Fig. 3 ) Gastrointestinal hormones Peptide YY 3–36 (PYY 3–36 ) is an enteric hormone that can reduce food intake in rodents and humans  Here we describe CNS mechanisms that regulate food intake, and review evidence that in response to reduced body fat stores, adaptive changes occur in neuronal systems governing both food-seeking behaviour (important for meal initiation) and satiety perception (important for meal termination) Higher processing of taste information in primates involves ‘primary taste neurons’ in the insular cortex that are supplied by NTS neurons by way of the thalamus How, then, are we to interpret the mild phenotype observed in mice lacking NPY and AgRP? To answer this question, investigators have recently ablated NPY/AgRP neurons themselves (rather than the genes encoding Npy and Agrp ) However, an alternative explanation is suggested by evidence that NPY/AgRP neurons exert a tonic inhibitory effect on neighbouring POMC cells , and that these two neuronal subsets are regulated in a reciprocal manner by many of the same afferent inputs ( Fig. 4a ) However, drug combinations cannot be approved by the US Food and Drug Administration unless the drugs are individually proven safe and effective However, recent work suggests that although both insulin and leptin activate PI(3)K signalling in arcuate POMC cells , the depolarizing effect of leptin on these cells is reportedly opposed by a hyperpolarizing action of insulin  In addition, an unidentified subset of mediobasal ventromedial nucleus neurons provides excitatory synaptic input to POMC cells, the magnitude of which is also attenuated by fasting  In addition, normal-weight individuals are protected against expansion of body fat stores induced by overfeeding , indicating that biological mechanisms protect against weight gain as well as weight loss, at least in normal-weight individuals In mediobasal hypothalamus, activation of AMPK increases food intake and body weight whereas conversely, inhibition of AMPK has the opposite effect  In rats, leptin reduces intake, at least in part, by enhancing the response to satiety signals , whereas conversely, obese, leptin-receptor-deficient rats exhibit blunted satiety responses to CCK, and this defect is ameliorated by restoring leptin receptors to the ARC  In response to weight loss, activation of NPY/AgRP neurons is coupled to inhibition of POMC neurons, a combination that favours the recovery of lost weight and reflects the integration of diverse humoral and neuronal inputs  In some cells, including hypothalamic neurons , leptin also activates the IRS–PI(3)K pathway , one of several points of convergence and synergism between intracellular signalling pathways used by insulin and leptin In this context, the recent finding that leptin activates the nutrient-sensing enzyme mTOR in ARC neurons is of interest In this way, through diverse blood-borne and afferent neural signals, information regarding nutrient status and energy stores is communicated to the brain where it is integrated with cognitive, visual, olfactory and taste cues—all happening unconsciously, before the first bite is taken In two studies, rapid ablation was accomplished by expressing the human receptor for diphtheria toxin selectively in NPY/AgRP neurons and injecting those animals with diphtheria toxin. (Humans have a gene that encodes a receptor for diphtheria toxin but mice do not; thus administration of low doses of diphtheria toxin to mice is normally harmless.) Using this approach, rapid ablation of NPY/AgRP neurons induced profound, life-threatening anorexia in adult mice , but not in mice in which these neurons were ablated during the neonatal period  Lateral hypothalamic area neurons supplying the NTS may, in addition, attenuate the response to satiety signals, increasing the amount of food consumed during a meal Leptin binding to the ‘long’ or ‘signalling’ form of the leptin receptor (LeprB) stimulates the tyrosine kinase JAK2 to phosphorylate STAT3 at tyrosine residues  Like the ARC, the hypothalamic ventromedial nucleus was recently been shown to be essential for leptin regulation of energy balance , and identifying leptin-sensitive neurons in this area has become a high priority Many such ‘satiety signals’ are transmitted to the brain via vagal afferent fibres that synapse in the nucleus tractus solitarius (NTS) in the hindbrain, which participates in gustatory, satiety and visceral sensation Meanwhile, substantial progress has been made towards understanding how ARC neurons participate in this process Mechanisms of food reward Perception of food reward begins with information generated by oral taste receptor cells that is subsequently transmitted to the NTS by afferent sensory fibres Mice with POMC-cell-specific deletion of the leptin receptor can be expected to exhibit reduced basal POMC neuron activity, creating a leptin-resistant state and increasing food intake Neuronal sensing of adiposity-related signals Recent studies have yielded testable, molecular models to investigate how adiposity signals regulate the function of hypothalamic neurons Nonlinearity in the relationship between the regulation of ARC neurons and their effects on food intake is illustrated through the following predictions that incorporate this arrangement Notably, the outcome of these studies depends on both the age of the animal and the time course over which the ablation occurs Numerous observations support this model of how energy homeostasis circuitry is organized and regulated Nutrient-related signals In addition to molecular targets of current anti-obesity drugs, including receptors for endocannabinoids, norepinephrine and serotonin , several nutrient-related signals are implicated in the homeostatic control of feeding On release from axon terminals, α-MSH binds to and activates neuronal melanocortin receptors, thereby decreasing food intake and favouring weight loss  One consequence of increased AMPK activity is oxidation of LCFA-CoA, and this mechanism might contribute to its orexigenic effects One consequence of this integration is that the drive to eat decreases as food is ingested (termed ‘satiation’), ensuring that the amount consumed in a single meal does not exceed what the body can safely handle One mechanism to explain this effect proposes that leptin and insulin tonically inhibit brain reward circuitry and that, by lowering circulating levels of these hormones, energy restriction increases the sensitivity of reward circuits  One mechanism whereby activation of the VTA → NAc pathway may promote consumption of palatable food involves projections to the lateral hypothalamic area One of these is the integrated nature of energy homeostasis neuronal systems, which predicts that the efficacy of interventions targeting one neuronal subset or signal transduction pathway is inherently limited by compensatory responses elsewhere Opposing the hypothalamic actions of leptin, insulin and PYY 3–36 , ghrelin powerfully stimulates food intake in multiple species, including humans , suggesting that the effect of weight loss to increase ghrelin levels may (along with reduced leptin and insulin levels) contribute to weight regain Phospho-STAT3 dimers subsequently enter the nucleus and regulate transcription of target genes PIP3-mediated activation of PDK1 activates an enzyme cascade that includes protein kinase B (PKB, also known as Akt) and members of the atypical PKC family  POMC neurons are stimulated by leptin but inhibited by neighbouring NPY/AgRP neurons  Proposed criteria for a negative-feedback signal include: (1) that it circulates at levels proportionate to body fat content and enters the brain; (2) that it promotes weight loss by acting on neuronal systems implicated in energy homeostasis; and (3) that blockade of these neuronal actions increases food intake and body weight Rather, µ-opioid receptor signalling in the NAc and adjacent forebrain structures (activated in part by dopamine release) is implicated in the hedonic experience , although wanting and liking ordinarily occur together Realizing these goals requires new strategies for single-cell imaging, analysis of synaptic function, and modelling how synaptic changes affect energy homeostasis neurocircuitry and, consequently, the defended level of body weight Recent analysis of transcriptional regulation of ARC neuropeptides by insulin and leptin supports this view Regulation of brain reward circuitry The concept that reward perception is subject to homeostatic regulation derives from evidence that food deprivation strongly augments the reward value (for example, the speed of learning to obtain a rewarding stimulus, the dose of the stimulus needed to establish its rewarding value, or the amount of work an animal will perform to obtain the stimulus) of addictive drugs including heroin, amphetamine and cocaine  Regulation of satiety perception Most vertebrates consume food in discrete bouts or ‘meals’ Reward valuation involves the release of dopamine from neurons that originate in the VTA and project to NAc, striatum and other brain areas  Signal transduction in ARC neurons On insulin binding, the insulin receptor recruits several intracellular molecules involved in signal transduction  Similarly, absence of α-MSH in Pomc knockout mice causes hyperphagia and obesity , and blockade of neuronal melanocortin signalling diminishes the response to central leptin administration  Specifically, both hormones were reported to activate ATP-sensitive potassium (K ATP ) channels and thereby hyperpolarize a subset of ‘glucose-responsive’ ARC neurons via a PI(3)K-dependent mechanism  Specifically, fasting decreases excitatory, while increasing inhibitory, synaptic contacts on POMC neurons, whereas the opposite applies for NPY/AgRP neurons  Studies in primitive organisms such as the nematode, Caenorhabditis elegans , and the fruitfly, Drosophila melanogaster , implicate insulin as a key ancestral negative-feedback regulator of body fuel stores  Surprisingly, ciliary neurotrophic factor stimulates proliferation of leptin-responsive neurons in the ARC , an intervention that may alter fundamentally the balance of orexigenic versus anorexigenic pathways in adult animals and thereby combat leptin resistance that accompanies obesity Synaptic plasticity Arcuate neurons are regulated not only by humoral signals but also by local excitatory and inhibitory synapses, and the balance of these inputs seems to be affected by nutritional state The apparent ease with which we decide whether or not to eat an appetizing food testifies to the efficiency with which the central nervous system (CNS) processes information of surprising variety and complexity The hypothesis that hypothalamic LCFA-CoA signalling has a critical role in energy homeostasis is supported by the obesity that results when the level of these molecules is selectively reduced in rat ARC  The hypothesis that PI(3)K signalling links input from insulin and leptin to changes of electrical activity in ARC neurons received early, direct support The integration of long-acting homeostatic and short-acting satiety signals may therefore involve direct actions of leptin on NTS neurons that process input from vagal afferent fibres, in addition to its effects on neurons in hypothalamus and elsewhere that project to the NTS ( Fig. 2 )  The leptin receptor is a class 1 cytokine receptor that regulates gene transcription via activation of the Janus kinase–signal transducer and activator of transcription (JAK–STAT) pathway The mild or absent obesity phenotype of these animals contrasts sharply with the severe obesity that results from Pomc gene deletion  The net effect is that in response to weight loss, both the motivation to find food and the size of individual meals tend to increase until energy stores are replenished ( Fig. 1 ), and mutation of any of several key molecules involved in this process has been shown to cause severe obesity in both animal models and humans The observation that leptin increases PI(3)K activity and firing rate in POMC neurons while inhibiting both parameters in NPY/AgRP neurons supports a causal link between leptin regulation of PI(3)K and neuronal activity, but this link does not hold for insulin The response of these latter cells (but not of primary taste neurons) to taste stimuli is described as ‘hunger-dependent’, in that it decreases as food is eaten, implying the capacity to integrate taste information with satiety-related (and perhaps adiposity-related) input ; data obtained using functional magnetic resonance imaging in humans support this view  These cells project in turn to ‘secondary taste neurons’ in the orbitofrontal cortex that integrate taste information with relevant olfactory, visual and cognitive inputs  These considerations highlight how the integrated, nonlinear nature of energy homeostasis neurocircuitry can complicate the interpretation of seemingly straightforward experiments These considerations support a view of the lateral hypothalamic area as an integrative node for homeostatic, satiety and reward-related inputs that collectively govern motor programs that activate feeding behaviour ( Fig. 3 ) These K ATP channels have subsequently emerged as key cellular targets for the actions of free fatty acids and other nutrient-related signals in the ARC These NPY/AgRP neurons are inhibited by leptin, insulin and PYY 3–36 , whereas they are stimulated by ghrelin  This brain area contains neurons that potently stimulate food intake and is supplied by fibres not only from striatum and orbitofrontal cortex, but also from the ARC and other crucial hypothalamic areas for energy homeostasis This creates a situation in which potentially promising drug combinations are not developed because of limited efficacy of individual drugs when used alone This is because if adiposity negative-feedback signals do not normally protect against weight gain, neuronal resistance to insulin and leptin cannot cause obesity This response complements the effect of leptin-mediated STAT3 activation and provides a feasible explanation for how, during weight loss or other conditions of low plasma insulin and leptin levels, hypothalamic AgRP expression increases while POMC levels decline ( Fig. 4c ) This result suggests that in response to afferent input from leptin, homeostatic circuits in the hypothalamus elicit compensatory reductions of food intake by enhancing the response to meal-related satiety signals This, in turn, allows IRS proteins to activate phosphatidylinositol-3-OH kinase (PI(3)K), which generates phosphatidylinositol-3,4,5-trisphosphate (PIP3) from phosphatidylinositol-4,5-bisphosphate (PIP2) Through a process known as energy homeostasis, food intake is adjusted over time so as to promote stability in the amount of body fuel stored as fat Through this mechanism the consequences of a reduced leptin signalling on POMC cells are mitigated and further weight gain limited Thus, orexigenic signals from these neurons have a critical role in body weight regulation, but if loss of these cells occurs early in life or via a gradual, progressive process, survival is ensured by as-yet-unidentified compensatory mechanisms Thus, PI(3)K activation in response to insulin is proposed to inhibit FOXO1-mediated gene transcription Thus, PI(3)K signalling does not provide a unifying explanation for how these hormones affect POMC neuron firing rate and, moreover, insulin and leptin evidently have dissimilar effects on this parameter, despite their convergent effects to stimulate Pomc gene transcription  To clarify the involvement of specific molecules in ARC neurons in vivo , mice have been created in which IRS-2 (ref. 69 ), STAT3 or leptin receptor is selectively deleted from POMC cells To understand better how ARC neurons are regulated by insulin, leptin and other inputs, several groups have sought to measure membrane potential and firing rate, in addition to expression of neuropeptide genes Together with evidence that hypothalamic IRS–PI(3)K signalling is increased by both hormones , convergent actions of leptin and insulin involving PI(3)K and STAT3 activation are proposed to regulate key energy homeostasis neurocircuits Together, these findings indicate that obesity involves the defence of an elevated body weight, rather than the absence of regulation, and that deleterious interactions between obesity-promoting environmental factors and homeostatic control systems contribute to common forms of obesity and, hence, the global obesity pandemic Until this issue is resolved, the importance of several key observations, including CNS resistance to leptin and insulin documented in common forms of obesity, will remain uncertain Using taste information, the foods palatability is then assessed and integrated with both short- and long-term signals regarding nutritional state What kinds of molecular and cellular mechanisms might underlie homeostatic compensation for NPY/AgRP neurodegeneration? An intriguing indication comes from studies using ciliary neurotrophic factor, which activates many of the same downstream signalling molecules as leptin, but which is not subject to neuronal resistance seen with leptin in obese models  When cells experience a critical drop of fuel availability (as reflected by an increased AMP/ATP ratio), AMPK activation increases substrate oxidation to replenish depleted ATP levels Whereas intracellular LCFA-CoA accumulation is proposed to signal nutrient abundance, the enzyme AMP-activated protein kinase (AMPK) is a sensor of nutrient insufficiency Whereas plasma levels of PYY 3–36 decline in advance of meals, levels of the gastric hormone ghrelin rise shortly before meals and fall sharply on feeding  Whether activity of secondary taste neurons in the orbitofrontal cortex is sensitive to input from adiposity and satiety signals, and whether it is either necessary or sufficient to explain hedonic stimulation of feeding behaviour, are questions that warrant further study Whether and how PI(3)K activation affects neuronal firing, therefore, seems to vary with both the cell type and hormonal stimulus Whether the reverse is also true—that increased neuronal input from these hormones protects against weight gain—is hotly debated With the aid of cognitive, visual and olfactory cues, food items must first be identified and distinguished from a nearly infinite array of potentially toxic environmental constituents Yet, whereas mTOR is not implicated in the control of neuronal firing, it is a key determinant of dendritic growth and synaptic plasticity 
 Bitter taste detection functions as an important sensory input to warn against the ingestion of toxic and noxious substances Here we demonstrate, using a combination of genetic, behavioural and physiological studies, that T2R receptors are necessary and sufficient for the detection and perception of bitter compounds, and show that differences in T2Rs between species (human and mouse) can determine the selectivity of bitter taste responses In addition, we show that mice engineered to express a bitter taste receptor in ‘sweet cells’  become strongly attracted to its cognate bitter tastants, whereas expression of the same receptor (or even a novel GPCR) in T2R-expressing cells resulted in mice that are averse to the respective compounds T2Rs are a family of approximately 30 highly divergent G-protein-coupled receptors (GPCRs) that are selectively expressed in the tongue and palate epithelium and are implicated in bitter taste sensing  The sense of taste provides animals with valuable information about the nature and quality of food Together these results illustrate the fundamental principle of bitter taste coding at the periphery: dedicated cells act as broadly tuned bitter sensors that are wired to mediate behavioural aversion. All data analyses used the integrated response over a 25 s period immediately after the application of the stimulus Before training and behavioural testing, all mice with a T2R5 -/- or PLCβ2 -/- background were treated with intranasal zinc sulphate to reduce input through the olfactory system Behavioural assays Taste behaviour was assayed using a short-term assay that directly measures taste preferences by counting immediate licking responses in a multi-channel gustometer ( Davis MS160-Mouse gustometer ; DiLog Instruments )  Chimaeric mice were bred with C57BL/6 mice and progeny backcrossed to C57BL/6 mice for two generations before establishing a homozygous knockout colony For constructs using the Tet-on inducible system, tetracycline-dependent gene expression was induced by feeding animals a diet containing doxycycline (6 g kg -1 ) ( Bio-Serv ) for 3 days before and during behavioural testing  For each construct, at least two independent animal lines were generated For mice carrying rtTA and TetO-transgenes, controls included testing the same mice without induction as well as mice carrying just the rtTA transgene and exposed to doxycycline For the two-bottle assays in Fig. 4b , consumption relative to total is defined as intake of tastant divided by total intake (tastant plus water) For transgenic constructs using T2R regulatory sequences, we used the following fragments: T2R5, -10816 to +3 (the location of the ATG start codon) ; T2R19, -11012 to +3; T2R32, -9506 to +3 Homologous recombination in R1 embryonic stem (ES) cells was detected by diagnostic Southern hybridization with probes outside the targeting construct In situ hyrbridization and immunhistochemistry were carried out as described previously  Lick response represents the mean percentage rate at which mice licked a tested compound relative to their sampling of an appropriate control tastant; relative responses were scaled to the mean response of control animals Methods Gene targeting of T2R5 T2R5 knockout mice were generated by homologous recombination following standard procedures  Mice were trained and tested as described previously  Nerve recordings Lingual stimulation and recording procedures were performed as previously described  Neural signals were amplified (5,000 × ) with a Grass P511 AC amplifier ( Astro-Med ), digitized with a Digidata 1200B A/D converter ( Axon Instruments ), and integrated with a time constant of 0.5 s Salt attraction to 150 mM NaCl was measured in mice that had been salt deprived overnight  Standard two-bottle preference assays were carried out as described previously  Tastants used for nerve recordings (maximal concentrations) were: 60 mM acesulfameK (AceK); 100 mM citric acid; 100 mM NaCl; 100 mM NH 4 Cl; 10 mM quinine; 1 mM cycloheximide. Taste stimuli were presented at a constant flow rate of 4 ml min -1 for 20 s intervals, interspersed by 2 min rinses with artificial saliva between presentations The concentrations of tastants used for bar graphs were: 300 mM sucrose; 100 mM glutamate + 1 mM inosine monophosphate +0.1 mM amiloride (MSG); 150 mM NaCl (attraction); 150 mM citric acid; 10 µM cycloheximide; 10 mM quinine; 10 mM denatonium; 10 mM 6- n -propyl-2-thiouracil (PROP); 10 mM papaverine; 10 mM quinacrine; 1 mM cholchicine, 5 mM atropine The entire coding sequence of T2R5 was replaced by a reverse-tetracycline dependent transactivator (rtTA) and a loxP-flanked PGK-neo r cassette (see Supplementary Fig. 1 for details) The mean response to 100 mM NH 4 Cl was used to normalize responses to each experimental series The T2R38 transgenic construct used the PAV-taster allele  Transgenic animals Transgenic lines were produced by pronuclear injection of zygotes from FVB/N or CB6 (BALB/c × C57BL/6 hybrids) mice Two targeted ES clones were injected into C57BL/6 blastocysts A final corollary emerging from these findings is that expression of a sweet receptor in bitter cells should trigger behavioural aversion to sweet tastants, and expression of a bitter receptor in sweet cells should result in attraction to the bitter compound Accordingly, we engineered mice expressing the bitter receptor for β-glucopyranosides in sweet cells As expected, responses to sweet, umami, sour and salty tastants are physiologically and behaviourally comparable to controls By selectively rescuing PLCβ2 function only in T2R-expressing cells, we showed that there is complete functional segregation between attractive (sweet, umami) and aversive (bitter) tastes  Conversely, if different T2R-expressing cells are narrowly tuned to different subsets of bitter tastants , then mice with restricted PLC expression would regain bitter sensitivity to a discrete repertoire of bitter-tasting compounds Does the same logic apply to bitter taste? We tested this idea by generating mice in which an inducible RASSL receptor was now targeted to bitter taste cells Figure 1 shows that T2R-hT2R16 transgenic animals acquire the ability to detect and respond to phenyl-β- d -glucopyranoside at concentrations that closely approximate the human physiological taste sensitivity range  Figure 2 shows that T2R5 -/- mice have a dramatic and selective loss of responses to Cyx Figure 4 shows that non-induced animals, or wild-type controls treated with doxycycline, are completely insensitive to the RASSL agonist spiradoline, even at millimolar concentrations Finally, we functionally dissected the role of cells and receptors by ectopically expressing a T2R bitter taste receptor in sweet-sensing (T1R) cells First, heterologous expression assays have shown that several human and rodent T2Rs respond to bitter tasting compounds: mouse (m)T2R5 is a high affinity receptor for cycloheximide (Cyx) , human (h)T2R16 is a candidate receptor for β-glucopyranosides (salicin and related compounds) , hT2R14 is a candidate receptor for picrotoxinin , and hT2R44 and hT2R61/hT2R43 are receptors for denatonium, aristolochic acid and 6-nitrosaccharin  First, we genetically engineered mice to express candidate human T2R receptors for tastants that mice do not respond to, and examined whether introduction of these candidate bitter receptors endows the animals with an expanded bitter taste repertoire For example, several β-glucopyranosides evoke strong bitter taste in humans, yet mice are largely indifferent to these compounds If indeed individual T2R-cells express most bitter taste receptors, then targeting expression of a PLCβ2 ‘rescue’ construct under the control of any one T2R promoter should be sufficient to restore normal bitter taste (that is, if the cell can now signal, all the receptors will function) If T2R5 is the principal bitter taste receptor for Cyx, then its knockout should abolish most, if not all, responses to cycloheximide In addition, the ability to confer human bitter taste responses on mice by introduction of human taste receptors illustrates an important feature of T2Rs and bitter taste: selectivity and sensitivity differences to bitter compounds between species is probably a reflection of sequence differences in the respective T2R repertoires In addition, the animals are no longer behaviourally averse to Cyx, even at concentrations 100-fold higher than those required to trigger strong repulsion in wild-type mice In addition, we designed one of the three constructs to have an inducible expression system, in order to determine whether T2R signalling plays a critical role in the development and/or connectivity of T2R cells In contrast, mice expressing RASSL in bitter cells show strong aversion to spiradoline Indeed, these mice now display strong attraction to this family of bitter compounds Interestingly, T2R5 -/- mice show residual responses to millimolar levels of cycloheximide, but mice defective in all bitter taste signalling (for example, phospholipase C β2 knockout (PLCβ2 -/- ) mice, ref. 10 ) have a complete loss of Cyx sensitivity ( Fig. 2b ); we suggest that this residual activity in T2R5 -/- mice reflects the recruitment of lower affinity T2Rs Likewise, expression of hT2R38 confers selective PTC sensitivity to the engineered mice Mice and humans have distinctive differences in their sensitivities to many bitter compounds Next, we used homologous recombination to generate animals lacking mT2R5, the candidate Cyx receptor  Previously, we showed that most T2R receptor genes are coexpressed in the same subset of taste receptor cells of the tongue and palate epithelium  Recently, we generated mice expressing a RASSL κ-opioid receptor in sweet cells and showed that these animals become selectively attracted to the synthetic opioid agonist spiradoline, a normally tasteless compound  Recently, we used mice deficient in sweet, umami and bitter taste (owing to a deletion of the PLCβ2 effector molecule ) to ask whether taste receptor cells are tuned to single or multiple taste modalities Remarkably, all of the PLCβ2-rescued animals showed completely normal bitter taste ( Fig. 3 ), including those in which T2R function was restored only at the adult stage, long after the taste system would have completed its normal development and wiring programme  Second, sequence polymorphisms in T2Rs have been linked to differences in bitter taste sensitivity in mice and humans  Second, we generated genetically modified mice lacking a specific T2R and studied their behavioural and physiological responses to bitter compounds Similarly, phenylthiocarbamide (PTC), a well known bitter tastant often used in human genetic studies, is ineffective in mice ( Fig. 1 ) T2R5 -/- animals retain basically normal responses to all other bitter tastants tested ( Fig. 2 and Supplementary Fig. 2 ) These results prove the essential requirement of a T2R receptor for bitter taste, and together with our T2R mis-expression studies ( Fig. 1 ) show that defined T2Rs are both necessary and sufficient for bitter taste sensation These results show that the bitter taste circuitry can be established without bitter sensory input, and unequivocally demonstrate that individual T2R cells operate as broadly tuned bitter sensors These results validate T2Rs and T2R-expressing cells as mediators of bitter taste perception in vivo , and demonstrate that T2Rs are sufficient for selective responses to bitter tastants; they also confirm that hT2R16 is the β-glucopyranoside receptor and hT2R38 is the PTC receptor  Third, we examined the specificity of bitter taste responses of animals in which all sweet, umami and bitter taste function was eliminated and then selectively restored in T2R-expressing cells Thus, activation of sweet cells, rather than the sweet taste receptor itself, results in the perception of sweetness Thus, the ‘taste’ of a sweet or a bitter compound (that is, the perception of sweet and bitter) is a reflection of the selective activation of T1R-expressing versus T2R-expressing cells, rather than a property of the receptors or even the tastant molecules. To address this question we chose three divergent T2Rs mapping to different chromosomal locations (T2R5, T2R19 and T2R32, ref. 1 ) and used their regulatory sequences to drive PLCβ2 expression in PLCβ2 -/- lines To determine if T2Rs and T2R-expressing cells are necessary and sufficient for bitter taste perception in vivo , we used several complementary strategies To examine taste behaviour, we measured taste choices in two-bottle intake preference assays, or by direct counting of immediate licking responses in a multi-channel gustometer (see Methods and ref. 10 ) To explore the effect of this knockout in vivo , we recorded tastant-induced action potentials from one of the principal nerves innervating taste receptor cells of the tongue To further examine the taste repertoire of the T2R5 -/- mice, we performed studies of bitter taste against a broad panel of bitter tastants Together, these results substantiate the coding of both sweet and bitter pathways by dedicated (that is, labelled) lines Two main lines of evidence suggest that T2Rs function as mammalian bitter taste receptors We interpreted this to mean that individual T2R-expressing cells act as broadly tuned bitter sensors capable of responding to a wide diversity of tastants but not necessarily able to discriminate between them We now make use of a similar strategy to ask whether re-introduction of PLCβ2 under the control of selective T2R-promoters restores complete or only partial bitter taste We placed the candidate human receptor for β-glucopyranosides (hT2R16, ref. 4 ) and PTC (hT2R38, ref. 5 ) under the control of a mouse T2R promoter , and generated transgenic animals expressing either of these two candidate taste receptors in T2R-expressing cells We then tested the engineered animals against a broad panel of chemically diverse bitter compounds ( Fig. 3 and Supplementary Fig. 3 )
 As a result, the organism forms a strong memory of that flavour and rejects it in the future Bargmann says that she now wants to find out how the worms make the associations with good and bad bacteria Bargmanns postdoc, Yun Zhang, did some simple experiments exposing worms to a ‘good’ strain of bacteria and a ‘bad’ one But Bargmann was worried that giving the worms two choices was like giving someone a true/false test; guessing would give a correct answer half the time Common in many organisms, this form of learning occurs when, for example, an organism eats something with a novel flavour and gets sick shortly afterwards Earlier research had shown that these worms can learn, but Bargmann, based at Rockefeller University in New York, wanted to know how and why Fortunately, she had just begun an interdisciplinary project: Bargmann had invited a few engineering postdocs to work with her, although she wasnt yet sure how they would fit in If they were then placed in another environment, they would head for an area at the same temperature as where they were fed In her bid to gain insight into the complex relationship between learning and behaviour, Cornelia Bargmann opted to keep things simple: she studied the nematode worm Caenorhabditis elegans (see page 179 ) It had eight arms, with four types of bacteria — two malevolent and two benign Lu built a maze to provide statistically significant results Lus work had focused on how single molecules interact in a circuit-like system, and she thought that scaling this idea up could help the group understand the worms learning behaviour. “Basically, she made a worm maze,” Bargmann says One of each kind was a type the worms had been exposed to before and one of each type was new One of them, Hang Lu, who did microfluidics at the Massachusetts Institute of Technology, took an interest in the worm project She knew that worms fed in an environment kept at a particular temperature associated that temperature with food She wanted more definitive results, but wasnt quite sure how to produce them Some of those bacteria are beneficial to the worms, others can make them sick, or even kill them. “For the worm, this would be something worth learning about,” thought Bargmann That led her to consider a worms natural environment: soil The effect can be so strong that one bad taste can be enough to turn an organism away from things associated with that experience The worms behaviour was very distinctive. “They learned to like the good bacteria,” Bargmann says. “But more clearly they avoided the bad bacteria.” The next step brought Bargmann to more familiar ground: linking the learning to specific genes and cells This is teeming with thousands of organisms — mostly bacteria This will take her into the world of neuroscience — and no doubt require another interdisciplinary effort. To expand the boundaries of what could be studied in the organism, Bargmann decided she needed to “think like a worm” To find out more, she looked at ‘conditioning’ Very quickly, the worms showed some strong preferences
 All the previous results, together with the invariance of the interval, are re-derived from this point of view, but in a way that avoids analytical geometry and uses only geometrical reasoning (essentially, similar triangles) As the author says, one cannot write a book on relativity without including a chapter on E = mc 2  Being naive, and not knowing any average teenagers, I took up the challenge But we still turn to explanations of relativity in print David Mermin brings to the task a lifetime of experience in making relativity accessible to the non-specialist student without simplifying more than Einsteins well-known dictum would allow For me the algebraic manipulation is the easy bit: relativity, with all those trains, particles and light beams, always seems to involve arguments that slide away when one tries to reproduce them Hermann Bondi used to say that the public would not understand relativity until there were relativistic toys to play with I recommend it to anyone who has to teach the subject to either audience: its a brilliant basis for a set of lecture notes. I think the problem for this secondary audience is that there are too many words, and for the general reader, too many equations I thought that I had managed rather well in providing a simple account, until I met adult readers and evening-class students who told me how difficult they had found my book Is this purely a matter of taste? Any valid calculation of the length of a rod using any Lorentz invariant theory will give a result in accord with relativity — but does that mean that the calculation gives the cause of the contraction? Mermin describes his primary audience as non-scientists, but also hopes to address undergraduate and graduate students who might find a few interesting things here Its About Time grew out of an earlier book for high schools and Mermins lecture notes from a course on relativity for non-scientists at Cornell Many years ago I was asked to write a book for the ‘average teenager’ explaining Einsteins theories of relativity Mermin gives a central role to a quantitative statement of the relativity of simultaneity Mermin suggests that his readers skip the algebraic manipulation if necessary Mermin treats this by means of modifications to the conservation laws for momentum, as required by the relativistic addition law for velocities Mermins conclusion is that one can seek the answer in the equations of quantum electrodynamics, which are entirely consistent with the kinematic results Problems involving the collisions of particles are solved by choosing a frame in which the solution is obvious (usually the centre-of-mass frame) Relativity can be summed up in a phrase that Einstein used when reflecting on the origin of the theory: “At last it came to me that time itself was suspect.” It is the way that this statement is unpacked that distinguishes the many expositions of the subject That is a pity, because this is a book full of insight with an engaging style The approach is quite technical, and I think that the more traditional thought experiment of a light gun in a railway carriage provides more insight The authors starting point for the treatment of relativity is the velocity addition law The book begins with a thorough consideration of frames of reference The chapter on space-time diagrams is perhaps the most important in the book The derivation is obtained by looking at a race between a particle and a photon in various frames of reference, together with the one additional element that characterizes Einsteins relativity: the constancy of the velocity of light The discussion also nicely illustrates the principle of relativity The final chapter contains a discussion of the reality of the Lorentz contraction (and time dilation) The treatment is complete and involves no more than elementary algebra This helps the reader to become familiar with transformations between frames of reference in a newtonian context before using them in a thoroughly unfamiliar one This is not the same as skipping the algebraic formulation of the argument, which is key to the exposition This is one reason why relativity professionals rely on space-time diagrams This leads to the slowing down of moving clocks, the contraction of moving rulers, and the formula for the Doppler shift This was also a key element in Einsteins approach and not, as often treated in textbooks, a simple consequence of the Lorentz transformation Today, computer games could play a role in teaching younger students, and lectures with animations on the web could help a more general audience Typical of the originality of the approach is the intriguing fact that the velocity of light, c , is 1 foot per nanosecond, to within about 2%, which dissolves the mystery for the general reader of making c =1 Well, perhaps the subject is difficult What causes a rod to contract from the point of view of the moving observer, or the lifetime of a muon to increase, when nothing happens to either in its rest frame? We tend to dismiss this as a question of (space-time) geometry, not physical causality, despite the fact that Einstein himself returned on several occasions to the dynamic origin of the contraction
 A fuller dialogue will greatly benefit researchers, who can use it to establish exactly what kinds of information policy-makers and environmental managers need in order to translate science into effective action As long as this remains the case, it is hard to see how political pledges to conserve global biodiversity will be fulfilled As researchers continue to gather information about the kinds of benefits that ecosystems provide, it is critical that their findings are disseminated far beyond the scientific community But appropriate responses to these challenges are inevitably political and economic in nature But at the current rate of progress, it is hard to see how nations will reach even this modest goal Conservation biology is continually developing new tools and concepts that contribute to our understanding of ecosystems Economists and other policy-makers inside powerful government departments and development agencies are needed to design and develop plans to tackle the problem on a meaningful scale If the drive for conservation comes only from scientists and a few allies in the environmental movement, ameliorative action wont get far In too many cases, however, that leaves scientists positioned only to track the loss of these systems John Heinz III Center for Science, Economics and the Environment in Washington DC, can also help to forge the necessary interactions Most of all, it will help the environment, by encouraging conservation policies that are soundly based on the facts. One such effort is the RUPES programme run by the Nairobi-based World Agroforestry Centre, which is bringing together land managers, conservation groups, development agencies and researchers to design a system to reward mountain communities in Asia for the environmental services they provide by conserving local habitat Putting these ideas into practice will require unprecedented collaboration between ecologists, economists, statisticians, businesses, land managers and policy-makers So far, researchers have been less effective at achieving the level of impact on policy decisions needed to implement actual conservation measures The considerable advances in monitoring and understanding made in conservation science cannot themselves generate such responses The development of tools to monitor global biodiversity has helped to promote awareness of the scale of the environmental challenges facing the planet The most comprehensive survey yet of the economic and other benefits that natural ecosystems provide — the Millennium Ecosystem Assessment, published earlier this year — highlights the urgent need for closer dialogue between these different parties The potential advances to be made from such discussion have never been more apparent The United Nations and the World Bank are, at least in their public statements, stressing the potential of environmental conservation for improving quality of life in poor countries (see Nature 437 , 180 ; 2005 ) There is an increasing realization that economic arguments should be brought to bear in persuading policy-makers to protect environmental resources (see Dollars and sense ) Third parties, such as the H This requires national institutions such as the US Department of the Interior, and international ones like the World Bank, to ensure that they have the necessary mechanisms and scientific expertise in place to absorb the information Translating the ramifications of environmental and conservation science into practical solutions requires much more work to close the gap between conservation biologists and the policy-makers and environmental managers who take action on the ground Under the 1992 Convention on Biological Diversity, for example, 188 nations are supposed to be taking steps to ensure that the rate of biodiversity loss slows down by 2010
 After Hwangs apparent success, researchers flocked to his lab to learn his methods, but most, such as Eggan, and George Daley of Harvard Medical School, are still waiting to get approval to use them in their home countries After several days, the egg had developed into a distinct type of early embryo called a blastocyst Also, Huizhen Sheng of Shanghai Second Medical University claimed to have extracted stem cells from embryos created by introducing adult human DNA into rabbit eggs stripped of their own chromosomes (Y And Arnold Kriegstein and his group at the University of California, San Francisco, plan to try to replicate Hwangs methods with their own materials And as the cloned cell was itself an embryonic stem cell, the paper does not show a way of making stem cells matched to adult patients from scratch And in August, Murdochs group reported the creation of a single blastocyst from a cloned cell (M As well as issues relating to trust and public confidence in such a controversial area (see page 1056 ), the complete loss of confidence in Hwangs work has set the field back by years B Because the egg and donor DNA came from the same person, it was impossible to be sure that the stem-cell line was created from the donor cell instead of the egg BioMed Bull. 48, 1840–1843; 2003), although she had not been able to extract stem cells from any of them But for others, the episode merely confirms that therapeutic cloning is not the way forward. “I always had my doubts about therapeutic cloning to generate patient-matched cells,” says Stephen Minger, a stem-cell researcher at the Wolfson Centre for Age Related Diseases in London, UK But the groups clones survived only a few days and never made it to the blastocyst stage (J But whether it is valid or not, the loss of confidence in the 2005 study leaves scientists with no proof that adult cells can be cloned — let alone used to produce stem cells. “Hwangs work gave people confidence to move into this difficult area,” says Alan Colman, head of Singapore-based regenerative-medicine company ES Cell International and a member of the team that cloned Dolly. “But maybe its harder than we thought.”  “Were back to knowing that animal cloning is possible but wondering whether it is possible in humans,” adds Kevin Eggan of Harvard University in Cambridge, Massachusetts. “This is an enormous setback.”  With Hwangs work set aside, results from other groups are sparse Cell Res. 13, 251–263; 2003) Chen et al  Cibelli et al  Daley is planning experiments similar to those done by Murdochs group Earlier this year, the group reported that it had vastly improved on this study (W Eggan and Douglas Melton, also at Harvard University, hope to get approval from the review boards that oversee their research in time to start work cloning human embryos early next year From this, Hwangs group supposedly extracted a batch of embryonic stem cells, potentially capable of developing into any of the bodys tissues He believes that banking stem-cell lines from normal embryos, so that they can be matched to patients once they are made, is a more realistic prospect. Hwang et al  Hwang et al  In 2001, a company called Advanced Cell Technology (ACT), based in Worcester, Massachusetts, described its attempt to create cloned human blastocysts In 2002, Chinese researchers made headlines with a report that Guangxiu Lu of the Xiangya Medical College in Changsha, Hunan, had cloned human blastocysts from adult cells ( Chinese Sci In 2004, the group reported that it had cloned a cell obtained from an adult woman (W In the past few days, doubts have also been raised about the authenticity of the 2004 paper (see page 1056 ) It also seemed to settle lingering questions about whether cloning actually worked It apparently provided the first proof of stem cells matched to individual patients and suggested that they were not that difficult to make, confirming the promise of the technique — dubbed “therapeutic cloning” — for producing replacement cells and tissues It has also taken away what seemed to be firm confirmation of the feasibility of using cloning to produce patient-matched stem cells. “We thought a fundamental question had been answered,” says Alison Murdoch of the University of Newcastle Upon Tyne, UK. “Hwangs results shifted the research focus on to emulating his work J Many scientists had not been convinced by the results of Hwangs 2004 experiments Med. 2, 25–31; 2001) Murdoch says she does not relish now being a leader in the field. “Im not interested in striving to be the first to get somewhere,” she says. “The problems in South Korea highlight the difficulties in racing to get results.”  She also laments the rules and regulations that many scientists think have hamstrung stem-cell research (see map ). “The more people who are working on this the better,” she says. “But the fundamental problem is that it is banned in so many countries.”  But researchers in the field are hopeful that progress can be made. “This needs to be done right,” says Michael West of ACT. “And many of us are determined to make it happen.” He says his company now plans to revisit the work Now we may need to look again at that fundamental step.”  Hwangs group claimed two major papers in the past two years that revolutionized the field Online 11, 226–231; 2005) Regen Reprod Researchers now face a long slog to rebuild the foundations of their field S S Science 303, 1669–1674; 2004) Science 308, 1777–1783; 2005) Scientists are surveying the wreckage left by the debacle involving stem-cell researcher Woo Suk Hwang after three co-authors on his landmark paper said that it could not be trusted Stojkovic et al  The blastocyst died before yielding any stem cells The group claimed it had put DNA from the womans cell into one of her own eggs, from which the genetic material had been removed The increased efficiency they claimed also meant that far fewer eggs were needed to create stem-cell lines The paper was hailed as a milestone The researchers abandoned their work because of lack of funding once Hwang claimed success The researchers used the same procedure but this time claimed to have transferred genetic material from patients into eggs from unrelated, healthy women, to create blastocysts and extract stem cells There have been a few baby steps, however
 Chip float German semiconductor-maker Infineon Technologies managed to float its memory-chip arm, Qimonda, on the New York Stock Exchange Cotton sweep Monsanto, the worlds leading supplier of genetically modified crop seed, has agreed to buy Delta Pine and Land, a Mississippi-based cotton-seed supplier, for $1.5 billion If regulators and shareholders approve the deal, it will widen Monsantos commanding lead in the transgenic crop market, where Switzerlands Syngenta is its main remaining rival Karen Katen, one of his rivals for the highest position and head of the companys pharmacological division, will leave the company altogether, whereas David Shedlarz, the other contender and Pfizers finance chief, gains wider responsibilities Kindler also named a seven-strong taskforce, including research chief John LaMattina, which, he said, would streamline company operations and accelerate decision-making Some market watchers expressed relief, however, that the float actually went ahead in current market conditions. Summer clear-out Jeff Kindler, Pfizers freshly appointed chief executive, has moved swiftly to reshape top management at the worlds largest drug company (see Nature 442 , 734 ; 2006 ) The offer was hurt by bad market sentiment towards such offerings in all technology sectors and by falling prices for Qimondas main product, the memory chips used in personal computers The public offering raised just $546 million — not bad by current standards, but less than half what analysts had predicted when the float was first announced The purchase, announced on 15 August, should end fierce litigation between the two companies over previous efforts by Monsanto, based in St Louis, Minnesota, to take over the Mississippi company
 Any big breaks along the way? We had a big success with an inhibitor for another protein, which fed directly into the CRP project Are there limits to rational drug design? Yes But when we tried these they were much worse, whereas a longer, flexible molecule worked very well Clinical and experimental evidence suggests that the abundant CRP may be bad for you First Author If the same person is found on the scene of multiple crimes, are they guilty by association? Thats the question that Mark Pepys, a researcher at the Royal Free University College Medical School in London, asked of C-reactive protein (CRP) Having previously solved the structure of CRP, we were able to design a two-handed compound that would crosslink this protein in a similar way He is searching for a CRP inhibitor, but high-throughput testing of 500,000 known molecules yielded no leads Here, Pepys presents his case to Nature  If it stays high, they dont get better In everyone who has a heart attack, the CRP goes high Pepys has been on the CRP case since 1974 So he has drawn on his experience with a drug that targets a related protein and designed a new chemical entity So its possible that you could reduce the damage from a heart attack if you could block the effects of the protein The structure of CRP suggested that shorter, twisted inhibitors would be better The two CRP molecules crosslinked by the drug are slightly rotated on each other, and the length and flexibility of the inhibitor is evidently necessary to accommodate this. There is no evidence that CRP causes cardiac problems, but Pepys says he has validated the protein as a therapeutic target by showing that high levels in the blood increase the damage caused by a heart attack This compound was two-handed with identical ends; it could therefore crosslink two target molecules and these were swiftly cleared from the patients blood This has been synthesized and shown to bind tightly to CRP, blocking its inflammatory effect (see page 1217 ) This protein is produced in abundance in most cardiac diseases, including after heart attacks and strokes What does your finding say about drug design versus high-throughput screening? It shows the potential for rational drug design — but the compound hasnt gone into patients yet, so well see Whenever youre sick, CRP concentration increases Why are you interested in targeting C-reactive protein? Everyone has CRP
 Although I disagree with their reasoning, I strongly agree that basic microbial research is so important, in and of itself, that its funding level should be not be reduced regardless of other concerns, whether arising from public health or bioterrorism By this standard, many of the letters signatories should voluntarily return their funding for research on Bacillus subtilis, Escherichia coli and other non-pathogens so that it can be appropriately directed towards the obvious public-health threats of HIV and tuberculosis How many of us want to be asked, when our next grant is reviewed: “How many people did your bug kill last year?” I certainly dont I find it striking that those who protest against the funding of biodefence research are proposing instead that public-health menaces should be given the highest priority If basic research is relevant to the health of the nation, then make the case that it is so Sir I think it is important to note the irony in your News story, “Protest letter accuses health agency of biodefence bias” ( Nature 434 , 7 ; 2005 10.1038/434007a ), of researchers who shun the study of disease complaining that a US agency called the National Institutes of Health fails to fund them adequately The current approach will only leave funding levels vulnerable to the next media sensation or hysterical distraction. Using body counts (“Bioweapons agents cause, on average, zero deaths per year”) may be useful in the short term to frame the debate, but I fear they will be damaging in the long run
 Here we show that the silicon isotopic composition of cherts more than 550 million years old shows systematic variations with age that support the earlier conclusion of long-term ocean cooling and exclude post-depositional exchange as the main source of the isotopic variations In agreement with other lines of evidence , a model of the silicon cycle in the Precambrian era shows that the observed silicon isotope variations imply seawater temperature changes from about 70 °C 3,500 million years ago to about 20 °C 800 million years ago. The most continuous record of sea surface temperatures of that time has been derived from variations in oxygen isotope ratios of cherts (siliceous sediments) , but the long-term cooling of the oceans inferred from those data has been questioned because the oxygen isotope signature could have been reset through the exchange with hydrothermal fluids after deposition of the sediments  The terrestrial sediment record indicates that the Earth’s climate varied drastically in the Precambrian era (before 550 million years ago), ranging from surface temperatures similar to or higher than today’s to global glaciation events  Awramik (courtesy of S Awramik; referred to as ‘ n of month–day–year’ of the recovery); and third, the Precambrian Palaeobiology Research Group collection referred to as PPRG (courtesy of J Between three and five analytical spots were made systematically on each sample to document the possible isotopic variability on a small scale (for example, analysis of silica veins cross-cutting the silica ground mass were avoided) During the different analytical sessions in which the two quartz standards were run together, the Rose quartz standard gave δ 30 Si values relative to NBS-28 of +0.24 ± 0.14‰, +0.20 ± 0.20‰, +0.16 ± 0.40‰ and +0.34 ± 0.40‰ Epstein; referred to in Supplementary Table S1 as K for Knauth samples; previous isotopic studies of some of the samples studied can be found in refs 2 , 3 , 29 ); second, the samples collected by S For Si, we assumed that there was no matrix effect on instrumental mass fractionation between chert and quartz. δ 30 Si and δ 18 O are expressed relative to the NBS-28 and Vienna standard mean ocean water (VSMOW) international standards, respectively; for example δ 30 Si = 1,000 × [( 30 Si/ 28 Si)/( 30 Si/ 28 Si) NBS  - 1] and similarly for δ 18 O Knauth and S Methods Geological formations (location, geology and radiometric ages) of all the samples studied here are reviewed in refs 9 , 25  S1 ) Schopf)  Specific information on aliquots of the samples studied can be found in refs 25–28  The 1 σ  error (from ±0.2‰ to ±2.3‰ for δ 18 O and from ±0.25‰ to ±1.4‰ for δ 30 Si) on these averages reflects the isotopic variability within a given sample. The data (reported in Supplementary Table S1 ) are averages over the different analytical spots made on a given sample The negative 16 O - , 18 O - , 28 Si - and 30 Si - ions produced during sputtering were accelerated at 10 kV and analysed at a mass resolution M /Δ M of about 3,000 in multi-collection mode by using Faraday cups (O and Si isotopic ratios were measured in different sessions; see recent developments of these techniques ) The other samples come from three different collections: first, the Caltech collection (courtesy of P The precision of the δ 18 O and δ 30 Si measurements was not limited by counting statistics (about ±0.1‰ and ±0.05‰, respectively) but probably by sample heterogeneity: our internal chert standard (Miocene chert) gave δ 18 O and δ 30 Si values ranging within ±0.49‰ (1 σ , 53 analyses) and ±0.28‰ (1 σ , 48 analyses), respectively The sample fragments were embedded in epoxy (about ten in each mount), coated with gold and sputtered with a Cs + primary beam (5–10 nA intensity and about 30 µm in size) and the electron gun This rather large scatter illustrates the fact that, in some rare cases, oxygen isotopic heterogeneity up to +3.3‰ (sample K500 in Supplementary Table S1 ) are present at the millimetre scale W We used quartz standards (Rose quartz and NBS-28) and an internal chert standard (miocene chert from the Paris basin) that was systematically included in all the mounts and analysed together with the samples When available, the bulk δ 18 O values of some samples—previously determined at the milligram scale by the classical BrF 5 oxidation procedure —were compared with the values obtained by the ion probe at the nanogram scale: both sets of data agreed within ±1.9‰ on average ( Supplementary Fig After the appearance of Si-fixing organisms, presumably in the early Phanerozoic, it can be supposed that, as today, sea water was always maintained strongly undersaturated relative to amorphous silica Although not yet studied experimentally, a negative value seems likely for Δ 30 Si Hyd-In : first, δ 30 Si values down to -3.5‰ (ref. 13 ) have been reported for siliceous sediments precipitated at black smokers from hydrothermal fluids with δ 30 Si = -0.3‰ (ref. 11 ) and second, isotopic fractionations between precipitated silica and dissolved silicon are observed to be of the order of -1‰ (refs 12 , 15 , 16 ) As detailed numerically in Supplementary Information , this approach allows us to calculate—from the δ 30 Si–age relationship defined by Precambrian cherts—a relationship between T sw and age At steady state, isotopic mass balance must be fulfilled between the input and output Si fluxes Because the exact value of Δ 30 Si Hyd-In is unknown, we considered it to be a free parameter calculated by the model Because the solubility of quartz in hydrothermal fluids at temperatures for which the precipitation rate of silica is maximal , T   190 °C (see Supplementary Information ), is higher than that of amorphous silica for any realistic seawater temperature (that is, T 70 °C), these fluids lose a large fraction of their Si on the way to the surface Consider that the Si concentration in the hydrothermal fluids circulating in the silicified crust is at equilibrium with quartz at the fluid temperature ( T Hyd ), whereas sea water is in equilibrium with amorphous silica at T sw  Continental clay formation and silicification processes that could have changed the δ 30 Si value of the riverine input are ignored in this model Detailed studies of Onverwacht cherts or of modern deep-sea cherts have shown that their δ 18 O values can depart from equilibrium with sea water by up to about -10‰ 5 because of either the contribution of meteoric waters to the diagenetic fluids or the range in the crystallization temperatures during burial diagenesis For Si, the budget should be controlled by the relative outputs of sedimentary and hydrothermal silica and the associated isotopic fractionations (see Supplementary Fig For this calculation, the δ 30 Si values of the chert samples with δ 18 O ≤ δ 18 O KL  - 6‰ have been averaged for each geological formation ( Supplementary Table S2 ) Furthermore it seems that the regular increase in chert δ 30 Si values during the Precambrian ( Fig. 2a ) can be used as a ‘palaeothermometer’ for sea water: this comes from the fact that seawater temperature ( T sw ) is the major control on f  If a low temperature (about 15 °C) is assumed for the Precambrian oceans, cherts must form with δ 18 O = +32‰ and, to fit the correlation reported in Fig. 2 , with a δ 30 Si of between +6‰ and +8‰ In addition, if the silicification process involves the diffusion of Si, then kinetic isotopic effects can be predicted that would enrich the hydrothermally deposited silica in 28 Si In addition, samples with δ 18 O  δ 18 O KL  - 6‰, for instance Rietgat samples ( Supplementary Table S1 ), show that the δ 30 Si values remain essentially unchanged whereas δ 18 O is reset through the interaction with high-temperature fluids ( Fig. 3 ) In contrast with oxygen isotopes, there is apparently no significant temperature effect on the Si isotopic fractionation between precipitated and dissolved silicon  In contrast, in the Precambrian [Si] sw was probably controlled by both the solubility of amorphous silica, which resulted in a much higher [Si] sw than today (for example 49 p.p.m. at 20 °C (ref. 21 )), and the rate of silicification of the oceanic crust  In contrast, the present set of Precambrian cherts shows much higher δ 30 Si values (ranging from -1.1 ± 0.4‰ to +5.0 ± 0.8‰; Supplementary Table S1 ) In our model, this would correspond to f  = 0, in agreement with the rather constant and low (close to mantle) δ 30 Si values found for Phanerozoic cherts ( Fig. 2a ) In the absence of biogenic precipitation of silica—that is, during the Precambrian—it can be considered that seawater Si had two major outputs: the sedimentary silica precipitated from pore sea water and the hydrothermal silica resulting from the silicification of the oceanic crust In this situation, hydrothermal fluids that are discharged into sea water cool and are diluted, always remaining undersaturated relative to amorphous silica It is obvious from the mass balance equation that, for negative Δ 30 Si Hyd-In values, δ 30 Si Sed is positive and increases when f decreases Note that using a threshold of 4‰ (δ 18 O KL  - 4‰ ≤ δ 18 O ≤ δ 18 O KL ) restricts the number of chert samples to 40 out of 99 but does not change the correlations observed in Fig. 2  Numerical calculations (detailed in the Supplementary Information ) show that it varies between about -1‰ and about -3‰; that is, within a range that agrees with theoretical expectations Our sample set includes 9 Phanerozoic samples and 99 Precambrian samples dating from about 3.5 Gyr ago to about 0.5 Gyr ago and coming from 23 geological formations ( Supplementary Table S1 ) S2 ) so that where δ 30 Si In is the isotopic composition of the Si input (input includes contributions from mantle and continental crust) to the marine cycle, f is the relative fraction of sedimentary Si precipitated from sea water or pore sea water in sediments (subscript Sed) and (1 -  f ) is the counterpart retrieved by the hydrothermal silicification of the crust (subscript Hyd) Such high δ 30 Si values have no counterpart in the Phanerozoic sedimentary record but were previously reported for a few Precambrian stromatolitic cherts  Taking 70 and 30 °C, given by δ 18 O KL , for seawater temperatures at 3.5 and 0.85 Gyr, respectively, allows us to solve the mass balance equation for a range of Δ 30 Si Hyd-In and T Hyd (see Supplementary Information for details) The calculated trend of decreasing T sw during the Precambrian is then in striking agreement with that predicted previously from O isotopes The corresponding range of possible T sw values for the Precambrian is indicated by the grey region in Fig. 4  The curve defined by the maximum δ 18 O (δ 18 O KL ) for a given age was proposed to reflect formation temperatures at depth in the sediment The large range in δ 18 O indicates that a significant fraction of Precambrian cherts had their original δ 18 O values lowered by post-depositional isotopic exchange with meteoric or hydrothermal fluids or, in some cases, were formed over a large range of temperature  The major difference in the marine silica cycle between the Phanerozoic and the Precambrian is the rapid development about 0.6 Gyr ago of organisms that used dissolved silicon to build their skeleton: biogenic silica precipitation maintains the Si concentration in sea water today at [Si] sw  ≈ 4.5 p.p.m.  The major Si isotopic fractionation in this system (defined as Δ 30 Si Hyd-In  = δ 30 Si Hyd  - δ 30 Si In ) is predicted to have taken place during the silicification of the crust The O and Si isotopic composition were measured with a multicollector Cameca IMS 1270 ion microprobe (see Methods) The oxygen isotopic fractionation between chert and water (Δ 18 O = δ 18 O chert  - δ 18 O water ) depends on temperature according to the equation 1,000ln(Δ 18 O) = (3.09 × 10 6 T -2 ) - 3.29 The positive correlation between δ 30 Si and δ 18 O vanishes for cherts with δ 18 O  δ 18 O KL  - 6‰ ( Fig. 3 ) The sedimentary silica was transformed into cherts during diagenesis, process that we consider to be at the origin of our chert samples with δ 18 O ≤ δ 18 O KL  - 6‰ The δ 18 O values of cherts show large variations that, for a given geological age, range from the maximum previously determined by Knauth and Lowe (hereafter reported as δ 18 O KL ) down to δ 18 O = δ 18 O KL  - 15‰ ( Fig. 1 ) The δ 30 Si of the input flux was taken to be -0.3‰; this is the value of the mantle and of the fluids at black smokers ; that is, the value of the mantle input to the sea-water–crust system The δ 30 Si values of the present Phanerozoic cherts (nine samples) vary from -1.7 ± 0.8‰ to +1.3 ± 0.3‰ (1 s.d.) (see Supplementary Table S1 ), covering the range previously determined for diatoms collected from open ocean surface waters (from +0.9‰ to +1.9‰) , diatoms from sedimentary cores (+1.3‰ to +1.6‰) or siliceous sediments from black smokers (-3.5‰ to -0.2‰)  The δ 30 Si–δ 18 O correlation ( Fig. 2b ) seems hardly compatible with post-depositional isotopic exchange with hydrothermal fluids, which would have lowered both δ 18 O and δ 30 Si These cherts were selected on the basis of several criteria (δ 13 C and δ 15 N values ) that were indicative of good preservation of their original structure and composition (some of them have been extensively studied for their abundant microfossils ) These formation temperatures are in turn related to past seawater temperatures ( Fig. 1 ) They could not account for the δ 30 Si–δ 18 O correlation ( Fig. 2b ) because the δ 18 O value of the oceans in the Precambrian was not controlled by continental erosion This approach also predicts the positive correlation observed in cherts between δ 18 O and δ 30 Si This behaviour is qualitatively in agreement with the fact that, as Si is insoluble in fluids, the water/rock ratios for the two isotopic systems are quite different This fraction, referred to as (1 - f) in the mass balance equation, depends on the difference between T Hyd and T sw , which implies that ultimately it depends on T sw : if T sw decreases, the amount of Si sequestered by silicification of the crust increases (that is, f decreases) and thus δ 30 Si Sed increases This is in qualitative agreement with the positive δ 30 Si found in the present cherts This major difference has profound consequences for the δ 30 Si value of Precambrian oceans and for its evolution with time This process holds only if part of the silicon injected into seawater precipitates as amorphous silica This Si budget can be written in a manner similar to that formulated, for instance, for the oceanic carbon isotopic budget, which is controlled by the relative outputs of carbonates and reduced carbon and the isotopic fractionation between the two carbon pools This would occur systematically if dissolved silicon in sea water were at, or slightly above, the saturation level relative to amorphous silica (see Supplementary Information ) as postulated for the Proterozoic  Thus, O and Si isotopic compositions of cherts concur to show that large changes in surface temperature occurred during the Precambrian. Thus, the threshold at about 6‰ on δ 18 O values seems a relevant criterion to distinguish between samples with different O–Si isotopic systematics Thus, variations of chert δ 30 Si values must primarily reflect variations in the δ 30 Si of the fluids from which they formed To account in our data set for this oxygen isotopic variability inherent in the process of chert formation, we tentatively consider here that cherts having δ 18 O ≤ δ 18 O KL  - 6‰ did not preserve an original isotopic oceanic signature Using this criterion, it turns out that all the cherts (56 out of 99) having δ 18 O KL  - 6‰ ≤ δ 18 O ≤ δ 18 O KL show both an increase in their δ 30 Si values with time from 3.5 to 0.8 Gyr ( Fig. 2a ) when they return abruptly to modern values and a corresponding positive correlation between their δ 30 Si and δ 18 O values ( Fig. 2b ) We selected a suite of chert samples that covers most of the available sedimentary record from the early Archaean era (3.5 Gyr ago) to the present (see Methods) When hydrothermal fluids percolating the oceanic crust return to the surface, they have to cool and to equilibrate with sea water (or with pore sea water)
 According to Lewis-Williams and Pearce, “It was religious experience that gave people the power to command the construction of megalithic monuments and to sacrifice animals and very probably human beings in order to keep the cosmos in good order.” In other words, animal and human sacrifices “kept the elite in power” Although I accept many of the authors basic premises, I find it disconcerting that their explanations are not readily refutable Building on detailed discussions of the neurophysiology and cognitive science of altered and heightened states of consciousness, combined with diverse archaeological and ethnographic evidence, Lewis-Williams and Pearce lay the groundwork for their analysis But I think Lewis-Williams and Pearce have done the scientific community a service by continuing to push the frontiers of archaeological knowledge But the smart ones will pause a little longer before dismissing the archaeology of religion. Childe, but focuses instead on the nature of human consciousness Concerning their methods, they argue that their neurological approach “is thus in no way deterministic: all the stages and experiences of consciousness that we distinguish are mediated by culture” David Lewis-Williams, professor emeritus at the University of the Witwatersrand in South Africa and member of its Rock Art Research Institute, shows no sign of losing the desire to confront his archaeological colleagues with new and controversial ideas G Given the multilayered complexity of the book, it is best to turn to the authors words If his earlier book The Mind in the Cave (Thames Hudson, 2002) rocked the boat of mainstream archaeological science with its innovative and insightful analysis of the origins of art and the replacement of Neanderthals by modern humans, then his new one, Inside the Neolithic Mind , co-written with David Pearce, is nothing less than an attempt to capsize the vessel of mainstream archaeology altogether In this sense they no doubt share my dismay at polls indicating that more than half the population of the United States, including the president, do not accept the validity of evolutionary theory It presents Coleridges opium-induced poem Kubla Khan as an example of a form of consciousness analogous to that experienced by the makers of the earliest monumental architecture at sites including the religious centre of Göbekli Tepe in Turkey and the chamber tombs of Knowth and Newgrange in Ireland Lewis-Williams and Pearce argue that researchers can use scientific knowledge about consciousness to solve questions in archaeology Like The Mind in the Cave , this well produced and finely illustrated book will be of interest to all archaeologists who think that the events of the Stone Age cannot be understood solely by the study of technology, environmental change and calorie counting of the behavioural–ecological school Many academic and field archaeologists will retrench and find polemic arguments against the authors unconventional ideas and methods Most colleagues will not change their research strategies to emulate those presented in Inside the Neolithic Mind  Or, if they are, the authors do not give us clear guidelines on how their hypotheses and interpretations can be tested The authors define religion broadly to include experience, belief and practice The authors go further, arguing that their work can be used as a framework in which to analyse current belief in supernatural beings, whether in the form of Christian, Islamic or other kinds of fundamentalism The authors urge archaeologists to consider “new types of explanation that do not assume humankinds impotence in the face of environment” The Mind in the Cave contained a fair amount of marxist theory, and opened with a quotation from Karl Marx The opening chapter of Inside the Neolithic Mind also states broad support for marxist approaches and the work to this end by V They also suggest that mainstream studies of technology and ecological adaptations ignore key variables that drive cultural change, including religion They comment: “If an American president announces that his decisions are guided by God, alarm bells start ringing.” Clearly the authors see their study of Neolithic religion as relevant in the context of todays world They go on to state that “it is impossible to discuss ancient religions and cosmologies in anything but a superficial, periphrastic way without recognizing the input of the human nervous system as it daily produces varied states of consciousness” This discussion of Coleridges poem is just the start of a literary and scientific tour de force that touches on the works of Dante, Jean-Jacques Rousseau, Aristotle, St Paul, Thomas Aquinas, Rudyard Kipling and other figures who are not the standard fare of scientific archaeology This issue also needs to be addressed, particularly with regard to Lewis-Williams influential work on shamanism Without rejecting a position based on Marxist theory, they argue that religion was the driving force behind what Childe referred to as the Neolithic revolution
 A long-standing problem in managing the behaviour of a collection of solid grains concerns the nature of the grain packing , a property that is typically controlled by how the grains are poured or shaken Here we show that a systematic and controllable increase in granular packing can be induced by simply raising and then lowering the temperature, without the input of mechanical energy This thermal processing may have important practical implications for the handling and storage of granular materials. Although the limited range of the experimental data restricts thorough testing of this double-relaxation model, the time constants of the two different relaxation times observed for each cycle temperature do increase with decreasing cycle temperature — consistent with smaller thermal expansion, as more cycles are needed to achieve the same change in packing fraction at a lower cycle temperature But the grain dynamics induced by thermal cycling have not been analysed until now For example, a geophysical form of granular segregation (stone heave) has been associated with thermal effects  It has been shown that temperature changes affect silos in industrial settings and the stress state of a granular pile  Our results demonstrate that thermal cycling can provide an almost adiabatic alternative to mechanical agitation for altering grain packing. Our results indicate that there may be many thermal effects in granular media, analogous to the effects of vibration Temperature changes can also cause granular pressure to increase in outdoor silos with each diurnal cycle — potentially leading to catastrophic failure of the silo  The density of packing can be increased by vibration or tapping, which induce small rearrangements that allow the grains to settle  The increase can be described by a double-exponential density-relaxation model, consistent with a combination of large-scale (relaxation of granular blocks) and small-scale (relaxation of individual particles) rearrangements (for details of the model and fits to the data, see supplementary information )  The packing fraction continues to increase over multiple thermal cycles ( Fig. 1c ) The packing fraction of a granular material is defined as the fraction of sample volume that is filled by grains rather than by empty space, and typically varies between 57% and 64% for randomly arranged, spherical grains and even more widely for other grain shapes The primary cause of the changes in packing fraction noted here is probably the difference between the thermal expansion of the container and of the grains The results were not affected by the height to which the cylinders were filled (to within ±10%), the heating rate, or the time spent at the cycle temperature after thermal equilibrium was reached They changed only slightly (20%) if the cylinder diameter was changed by an order of magnitude ( Fig. 1b ) This can lead to settling because of the metastable nature of disordered grain configurations (especially if the grains and their container are made of different materials), and such settling should not be reversible upon cooling to ambient temperature This explanation is confirmed by our observation (results not shown) of similar changes in packing of plastic spheres in glass cylinders (where the grains expand more than the container), and of smaller changes in packing for glass spheres contained in glass cylinders This latter result is physically sensible, because the expansion of the grains and of the container scales with the size of the sample We examined the change in packing fraction for glass spheres contained in vertical plastic cylinders in response to thermal cycling (using both single thermal cycles from room temperature and repeated cycles over the same temperature range; for methods, see supplementary information ) We found that there was a clear increase in packing even for a single cycle to 10 °C above ambient room temperature ( Fig. 1a ) When a granular material is heated, the grains and their container both undergo thermal expansion
 According to Tennessees Butler Law, enacted in 1925, it was “unlawful... to teach any theory that denies the story of the Divine Creation of man as taught in the Bible” After the Scopes trial, the laws banning the teaching of human evolution remained in effect for more than 40 years As noted by the Tennessee Supreme Court in the Scopes trial, “this enactment only intended to forbid teaching that men descended from a lower order of animals” (R But teaching students about Darwins general principle of evolution, with reference to non-human organisms, has never been illegal in the United States. Hatch BioScience 53 , 766–771; 2003) In the 1920s, Tennessee, Arkansas and Mississippi passed laws banning the teaching of human evolution in public schools Jensen J Moore, M Sir Your News story “Fresh scope” ( Nature 436 , 451 ; 2005 10.1038/436451a ) and Editorial “Keeping religion out of science class” ( Nature 436 , 753 ; 2005 10.1038/436753a ) misrepresent the Scopes case, or ‘monkey trial’ The substitute science teacher John Scopes was convicted and fined, not for teaching evolution in itself, but for his presentation of Darwins views on the descent of humanity
 Here we quantify the processes that controlled variations in methane emissions between 1984 and 2003 using an inversion model of atmospheric transport and chemistry Large fluctuations in the growth rate of atmospheric methane are also observed from one year to the next , but their causes remain uncertain  Methane is an important greenhouse gas, and its atmospheric concentration has nearly tripled since pre-industrial times  On longer timescales, our results show that the decrease in atmospheric methane growth during the 1990s was caused by a decline in anthropogenic emissions Our results indicate that wetland emissions dominated the inter-annual variability of methane sources, whereas fire emissions played a smaller role, except during the 1997–1998 El Niño event Remarkably, this growth rate has decreased markedly since the early 1990s, and the level of methane has remained relatively constant since 1999, leading to a downward revision of its projected influence on global temperatures Since 1999, however, they indicate that anthropogenic emissions of methane have risen again The effect of this increase on the growth rate of atmospheric methane has been masked by a coincident decrease in wetland emissions, but atmospheric methane levels may increase in the near future if wetland emissions return to their mean 1990s levels. The growth rate of atmospheric methane is determined by the balance between surface emissions and photochemical destruction by the hydroxyl radical, the major atmospheric oxidant These top-down estimates of changes in wetland and fire emissions are in good agreement with independent estimates based on remote sensing information and biogeochemical models Although isotopic ratios are monitored at only 13 sites, they are expected to constrain usefully the partitioning of CH 4 sources according to their mean isotopic signature: biomass burning (about -20‰ for C-3 plants; about -12‰ for C-4 plants), all bacterial processes (about -60‰) and fossil-fuel-related sources (about -40‰), the atmosphere being close to -47‰ on average An NSD value of 1 indicates a similar variability between the inversion and the bottom-up model. At four sites (Point Barrow, Mauna Loa, Samoa and South Pole), the NOAA observations were merged with those from the SIL network to extend the time series for the period 1989–2004 At Niwot Ridge, the UCI network time-series was used to extend the atmospheric δ 13 C-CH 4 record back to 1994 Atmospheric CH 4 observations, from roughly weekly air samples collected in flasks, were inverted as monthly means Atmospheric δ 13 C-CH 4 flask data from 13 NOAA sites were used in the inversion for the 1998–2004 period ( Supplementary Table A2 ) For CH 4 , surface emissions are optimized each month for 11 land regions (those defined in ref. 28 ), one global ocean region, and up to ten processes over each land region (emissions from bogs, swamps, tundra, termites, fossil fuel and industry, gas, bio-fuel, ruminant animals, landfills and waste, and soil uptake) In inversions using δ 13 C-CH 4 data, we account for the fact that transport and chemistry of δ 13 C-CH 4 is nonlinear by solving iteratively for both the underlying CH 4 source magnitude and its isotopic composition, as in ref. 33  In this procedure, the inferred interannual OH fields also depend on methyl chloroform sources In total, data from 68 sites from different networks were collected and used; 75% was contributed by the NOAA network Methods Inversion model setup The inverse methodology has been fully described through the example of OH field optimization against methyl chloroform observations NSD The normalized standard deviation (NSD) is calculated as the ratio between the s.d. of the monthly deseasonalized inverted CH 4 flux anomaly and the s.d. of the same anomaly calculated by the bottom-up model Offsets between different observing networks were accounted for by using intercomparison round-robin information reported in GLOBALVIEW-CH 4  On a geographical basis, the optimized emissions were further aggregated, after inversion, over three large regions: northern regions (boreal temperate North America, boreal temperate Asia, and Europe, roughly 30 °N), tropical regions (tropical America, north and South Africa, tropical Asia), and southern regions (temperate South America and Oceania, roughly 30 °S) See Supplementary Table A2 for a complete description of the 18 inversions performed Sensitivity tests The settings of the inversion model that were varied in the sensitivity tests were (1) the a priori error on regional fluxes; (2) the a priori error on the atmospheric CH 4 and δ 13 C-CH 4 measurements; (3) the number of land regions to be optimized; (4) the size of the atmospheric network; (5) the use of non interannual transport; (6) the uses of non-interannual OH; (7) the introduction of an additional source due to possible CH 4 emission by plants  The carbon isotopes measurements are relative to Vienna Pee Dee Belemnite (VPDB) The gap in δ 13 C-CH 4 data in the period with no observations in 1996–1997 was filled by interpolation, and the interpolated values associated with a large a priori uncertainty in the inversion The inversion of CH 4 fluxes accounts for the fact that CH 4 removal by OH radicals is a nonlinear function of surface CH 4 emissions, by iteratively applying the forward and the inverse transport chemistry model up until convergence is reached for the OH removal of CH 4  The sampling periods for each site, and data uncertainties, are given in Supplementary Table A2  The variations in OH are pre-optimized from methyl chloroform data using interannual winds and chemistry (see Supplementary Information ) The δ 13 C-CH 4 values were measured by INSTAAR at the University of Colorado  This spatial partition enables us to perform both geographically based and process-based analyses Uncertainties in the monthly means were taken from the GLOBALVIEW-CH 4 data product , when available, or from submonthly variability in the measurements Uptake of CH 4 by soils is optimized as an independent sink, but we do not explicitly solve for the stratospheric sink of CH 4 but assume that it is included in the removal by the stratospheric OH radicals of the INCA model  We used the optimized interannual four-dimensional distribution of OH from ref. 19  A larger decrease in OH concentration, possibly also caused by large emissions of carbon monoxide and other reactive carbon compounds by fires , is found to contribute to a faster growth of CH 4 by an additional +26 Tg of CH 4  A peak in growth rate occurred in 1991 in the tropics, followed by a large and abrupt drop in 1992, which began in the northern regions A previous study estimated an anomalous fire source of +11.5 Tg of CH 4 in 1997–1998 ( Fig. 3 ), which agrees well with the inversion estimates (+ 8 ± 2 Tg of CH 4 in the tropics and +2 ± 1 Tg of CH 4 in northern regions) Adding plants in the a priori CH 4 sources mix, however, did not alter the inferred anomalies in the 1990s (see Supplementary Information ) After 1993, decreasing global emissions at a rate of -1.0 ± 0.2 Tg of CH 4  yr -1 are required to match a small average growth rate of +4 ± 4 p.p.b. yr -1 , in the presence of (slightly) decreasing OH ( Fig. 3 ) After 1999, however, anthropogenic emissions increase again, especially in north Asia As an independent check on the inverted wetland variability, we applied a simple wetland flux model (see Supplementary Information ) based on ref. 23 and driven by interannually varying climate data and by estimates of remotely sensed changes in flooded areas for the period 1993–2001 At face value, these ‘isotopic’ inversions place a strong (tropical) release of CH 4 by fires in 1997, six months earlier than inferred from the remote sensing data ( Fig. 2 ) At that time, widespread dryness caused increases of fires in the tropical zone and in boreal regions of Eurasia  Atmospheric CH 4 measurements can be linked quantitatively to regional sources and sinks by inverse modelling Atmospheric long-term measurements and inverse models currently provide key information for assessing CH 4 emission trends at the global to subcontinental scale Better knowledge of the current CH 4 budget helps to reduce uncertainties in future projections of climate change and tropospheric ozone evolution and to design effective mitigation strategies By 2003, we find that anthropogenic emissions recovered to their levels in the early 1990s By contrast, the northern regions show smoother variations, but with systematically less emissions in the 1990s than in the 1980s, except for 1997–1998 and 2002–2003, consistent with Fig. 1b  Clearly, uncertainties in the variations of OH concentrations limit our ability to infer accurately fluctuations in regional CH 4 emissions Contributions of monthly surface CH 4 sources and pre-optimized monthly OH sinks were then combined to fit optimally monthly averages of CH 4 measurements from a global network of 68 sampling sites Decreased biomass-burning emissions had a much smaller role (- 5 ± 2 Tg of CH 4 ) Emissions of CH 4 from different regions of the globe and from distinct processes (see Methods), together with the photochemical sinks, were inferred, and their uncertainties reduced, by matching atmospheric observations within their uncertainties in a bayesian formalism  Finally, we analysed why the global growth rate of atmospheric CH 4 remained low after the drop in 1991–1993 (ref. 4 ) First, we studied the drop in growth rate in 1991–1993 For the period 1984–2003, the CH 4 concentration responses to the action of OH sinks and regional surface sources were simulated each month with the three-dimensional chemistry transport model LMDZ-INCA  Given their robustness, the flux anomalies are therefore the primary focus of the following analysis Given uncertainties in surface emissions and OH distribution, however, using this approach at the regional or country scale remains challenging and requires an observational network that is dense in space and time  However, there was a significant dip in 1997 for the northern regions wetlands (- 9 ± 5 Tg of CH 4 ), followed by an increase in 1998 (+ 10 ± 5 Tg of CH 4 ) in the southern regions ( Fig. 3 ) In 1989–2002, these anomalies are in very good agreement with independent estimates derived from remote sensing data after 1996 ( r 2 = 0.6, P = 0.012; NSD = 0.8) and inferred from global CO variations before 1996 ( r 2 = 0.4, P = 0.08; NSD = 1.2; see Supplementary Information ) In 1993–2001, wetland emissions in the bottom-up model show a persistent negative trend of 2.5 Tg of CH 4  yr -1 , in response to a marked decrease in flooded area worldwide (at a rate of -1.1% yr -1 for a mean area of 4.2 × 10 6  km 2 ), mostly in temperate and tropical Asia and in tropical South America  In other words, possible biases in the inversions seem to have low interannual variability In particular, large abnormal peat fires in Indonesia could have released huge amounts of CH 4 to the atmosphere from smouldering combustion  In the extreme case where OH interannual variability is set at zero, the fluctuations of tropical wetland emissions are dampened by 50%, especially in the 1980s, when methyl chloroform data suggest large OH variability  In the future, the combined use of improved emission inventories, isotopic observations and global space-borne measurements of column-integrated CH 4 should help better to quantify regional sources, to separate natural from anthropogenic processes, and to verify the effectiveness of CH 4 mitigation policies. In the inversion, a compensation effect exists between the magnitude of methyl-chloroform-derived changes in OH and inverted CH 4 surface emissions, because the sum of the two must equal the observed atmospheric accumulation Indeed, among the different sensitivity inversions, the spread of regional flux anomalies is more than a factor of two smaller than the spread of long-term mean fluxes Indeed, we inferred a decrease in tropical OH by 5% from the methyl chloroform data , as suggested by Fig. 1b and previous studies  Long-term measurements of the 13 C/ 12 C ratio in CH 4 (δ 13 C-CH 4 ) were also used as an additional constraint for the partitioning of microbial-, biomass-burning- and fossil-fuel-related CH 4 sources Natural wetland emissions remained on average stable over the whole 1997–1998 period Our understanding of the current methane budget therefore remains plagued by very large uncertainties Overall, we attribute the 1991–1993 spike in growth rate, a -10 Tg of CH 4 event ( Fig. 3 ), to a large decrease in emissions (- 36 ± 6 Tg of CH 4 ) partly offset by a reduction in the OH sink intensity (+ 26 Tg of CH 4 ) Second, we investigated the period 1997–1998, which corresponds to the largest El Niño on record Several conflicting hypotheses have been proposed to explain interannual and long-term variations in atmospheric CH 4 , focusing on wetland CH 4 emissions , anthropogenic CH 4 emissions , wild fires , OH photochemistry and interannual wind changes  Shrinking wetland areas may reflect recurrent dryness observed in the tropics after 1990 (ref. 18 ), and northward after 1999 (ref. 24 ) Sources that were reduced in that period are predominantly northern and tropical wetlands (- 24 ± 6 Tg of CH 4 ) and anthropogenic sources (- 10 ± 5 Tg of CH 4 ) Such agreement is remarkable, given that the a priori biomass-burning fluxes prescribed to the inversion are constant from year to year The correlation between the two estimates is improved when a 3-month lag is applied to the inversion results ( r 2 = 0.4, P = 0.06) The first factor should decrease OH, causing CH 4 to increase The global growth rate of atmospheric methane (CH 4 ) decreased from nearly +12 ± 2 p.p.b. yr -1  in the 1980s to +4 ± 4 p.p.b. yr -1 in the last decade (all values are means ± s.d.), but with large year-to-year variations ( Fig. 1a ) The inversion attributes global variations in the biomass-burning emissions of the order of ± 3.5 Tg of CH 4  yr -1 ( Fig. 2 ) The inversion attributes this signal to decreasing anthropogenic emissions, in particular to the northern fossil source ( Fig. 3 ) The inversion infers decreasing wetland emissions after 1993, but with a smaller trend (- 0.6 Tg of CH 4  yr -1 ) The long-term-mean inverted fluxes were strongly affected by this ‘intrusion’ of this new source, but the atmospheric measurements remained fitted and the global budget was conserved, after a reduction in plant and other source emissions (- 30%) within their uncertainties The members of the inversion ensemble that include δ 13 C-CH 4 observations agree best with the magnitude of the bottom-up anomalies (NSD = 1.1) The model was forced with interannual analysed winds and interannually varying OH concentrations  The past few years have been marked by two positive growth-rate anomalies in 1997–1998 and in 2002–2003, which seem more pronounced north of 30 °N than in the tropics The regional patterns of surface CH 4 emissions indicate that most of the global year-to-year variability lies in the tropics ( Fig. 3 ) The removal of CH 4 by OH nearly balances the sum of all surface sources, making the atmospheric CH 4 budget highly sensitive to OH changes The sparseness of the tropical network, along with large uncertainties on prior emissions, prevents us from verifying the existence of long-term CH 4 emissions by plants The two other factors should reduce wetland and fossil-fuel emissions respectively, causing atmospheric CH 4 to decrease The variability in CH 4 removal by OH radicals is also dominated by the tropics, where photochemistry remains active all year ( Fig. 3 ) There is good agreement in the magnitude of the wetland flux anomalies between the bottom-up and inversion results (normalized standard deviation (NSD) = 1.1; see Methods), as seen in Fig. 2  This analysis suggests that either northern CH 4 emissions have declined persistently since 1992 or that the destruction of CH 4 by the hydroxyl radical (OH) has increased north of 30 °N This inversion result agrees well with an independent study showing reduced boreal wetland emissions due to cooler and dryer conditions , and reduced northern anthropogenic emissions  This is in qualitative agreement with the latitudinal CH 4 differences analysed in Fig. 1b  This may reflect the booming Chinese economy This period is particularly intriguing because of the potentially confounding effects of three factors: (1) reduced photochemical production caused by changes in ultraviolet radiation associated with volcanic aerosols emitted in the eruption of the Mount Pinatubo in June 1991; (2) the widespread Northern Hemisphere cooling that followed ; and (3) the economic collapse of the former Soviet Union This result disagrees with previous studies suggesting a dominant role of fires  This shift in regional wetland emissions is fully consistent with the succession of regionally dryer and wetter climate conditions  This suggests that the slow-down in CH 4 growth rate observed from the early 1990s may represent only a temporary pause in the human-induced secular increase in atmospheric CH 4  Thus, biases in OH changes could account for some of the variability that we attributed to wetlands Thus, we constrained first the interannual variability of OH through a preliminary inversion of methyl chloroform atmospheric observations  To illustrate this point, we tested the impact of adding an additional methane source from plants with an a priori value of +150 ± 60 × 10 12  grams of CH 4  per year (Tg of CH 4  yr -1 ) To understand better why the growth rate of CH 4 has remained persistently smaller after the early 1990s, we have analysed the regional trends in CH 4 differences between sampling sites in the National Oceanic and Atmospheric Association (NOAA) global cooperative air sampling network and the South Pole site, taken as a reference ( Fig. 1b and Supplementary Information ) Various models have been used, but the contribution of each process has not been disentangled in a coherent framework, except for short periods  We analysed in detail two key perturbations of the CH 4 budget in the past two decades ( Fig. 3 ) We found that fluctuations in wetland emissions are the dominant contribution to interannual variability in surface emissions (± 12 Tg of CH 4  yr -1 ), explaining 70% of the global emission anomalies over the past two decades, as compared with only 15% contributed by biomass burning ( Fig. 2 ) We found that the year-to-year CH 4 regional flux changes (or anomalies) can be more robustly inverted than their mean values, a result similar to CO 2 inversions  We found that the years 1987–1988, 1991–1992, 1997–1998 and 2001–2002 correspond to abnormally weaker CH 4 destruction by OH in the tropics We performed a control inversion, supplemented by an ensemble of 17 sensitivity inversions (see Methods) Without a coincident and important drop in northern wetland emissions after 1999 ( Fig. 2 ) associated with dryer conditions , the growth rate of atmospheric CH 4 would therefore have increased much more rapidly
 Although, as with all human chromosomes, some gaps in information remain, the paper means that virtually the whole human genome has now been sequenced and annotated And it has established the ethos for publishing results in the public domain, which has had a knock-on effect for other projects First Author The paper on page 315 marks the end of an era in human genetics For chromosome 1, we were able to overlay the additional data sets on top of the sequenced DNA Has our understanding of DNA changed? The interesting thing will be finding out what the non-coding regions do How does your move from the Sanger Institute to Duke University mark your place in the Human Genome Project? Careers have been put on hold for this once-in-a-lifetime opportunity How has the annotation of human chromosomes altered over the years? There are a lot more data to draw from I came to Duke because I want to work on diseases; I want to be a user of the sequence rather than a generator In the early days, these were dismissed as ‘junk DNA’, but I think were learning that genes might be the horses and that regions of non-coding DNA are the jockeys Is it odd not working in the genome project? The Human Genome Project was fantastic, but it was operated in a rarefied atmosphere It presents the annotated sequence of chromosome 1, the final human chromosome to be ‘completed’ by the Human Genome Project Its been a fantastic project to be involved with — working with people from multiple cultures and continents Outside the project, its the real world Simon Gregory, a molecular geneticist at Duke University in Durham, North Carolina, spoke to Nature about the latest paper and what the future might hold for human genetics The only competition was of the fierce but friendly type to see who could get the most done There are now much richer sets of data and better resources to work with, so the final product is more valuable to researchers There wasnt competition for grants in the traditional sense, as the roles of the sequencing centres were established early on Theres much more competition What have you learned from being part of such a large project for so long? Ive been working on chromosome 1 for nine or ten years When you finish the annotation, you hand it over to the scientific community, to groups who learn how these genes play a role in biology and disease Youve got to face the real world yourself.
 After the paper was criticized by plant biotechnologists and subjected to additional review, Nature issued a statement saying that it would not have been published had certain technical flaws been uncovered Although Chapelas department and the college voted in his favour, the universitys chancellor at the time, Robert Berdahl, denied him tenure, saying his research record was insufficient As these events were unfolding, Berkeley was considering Chapelas request for tenure in the College of Natural Resources But Chapela stands by the findings Chapela also claims to be the victim of racial discrimination. “My case shows the tenure review process is totally overwhelmed by the forces of politics and the realities of economic dependency,” he says Chapela Nature 414 , 541 – 543 ; 2001 ) Chapela rose to international attention with a 2001 paper reporting that transgenes had flowed into native varieties of maize in southern Mexico and fragmented throughout their genomes (D Chapela says he is not optimistic about the review: “I see the academic process as unable to deal with the questions raised here.” For now, he remains a salaried employee with an office and lab, but no funds for research H He will rule on whether Chapela should receive tenure by 30 June — the end of the academic year Ignacio Chapela was prominent among staff at Berkeley who opposed a five-year, $25-million deal that in 1998 gave the Swiss firm Novartis privileged access to findings by the universitys plant scientists Last year, a compromise was worked out in which university administrators agreed to convene a committee to reassess Chapelas tenure Quist and I San Diego A Mexican ecologist renowned for his criticism of transgenic crops is suing the University of California, Berkeley, which denied him tenure in 2003 Since then, Chapelas case has become a focus for protesters concerned about threats to academic freedom from industrial forces The lawsuit claims that he was denied tenure in retaliation for this stance The university declines to comment on the legal action. This committee will make a recommendation to Berkeleys new chancellor, Robert Birgeneau, who was inaugurated on 15 April
 Enzymologists describe this series of reactions as ‘ping-pong’ Fatty acids —organic acids with long hydrocarbon chains of between 8 and 18 carbon atoms — are the building-blocks of cell membranes and bacterial surfaces In addition, cerulenin and thiolactomycin are natural products derived from fungi that target the same specific biosynthetic reaction as platensimycin in bacteria In the past 40 years, only two antibiotics representing new chemical classes have reached the clinic, namely linezolid (an oxazolidinone ) and daptomycin (a lipopeptide ) Isoniazid and triclosan are synthetic compounds that also target this pathway Isoniazid has a clinical niche in treating tuberculosis in combination with other antibiotics, whereas triclosan has been widely used in soaps and plastics It is believed that widespread drug resistance among bacterial pathogens is due to the limited choice of antibiotics that exploit a relatively narrow range of mechanisms It is heartening, therefore, that platensimycin has been discovered and characterized by workers at Merck Most classes of antibiotic were discovered in the 1940s and 1950s, and are directed at a few specific aspects of bacterial physiology — mainly biosynthesis of the cell wall, and of DNA and proteins On page 358 of this issue , Wang and colleagues report the discovery of a new antibiotic, platensimycin, that has potent antibacterial activity against these Gram-positive pathogens Particularly worrisome are infections by a large group of bacteria classified as being Gram-positive, such as staphylococci and enterococci, which cause pneumonia and other, often fatal, infections Pathogenic bacteria have developed strains that are resistant to almost all antibiotics in use today Pharmaceutical companies have generally retreated from the field of antibacterial drugs, concentrating instead on chronic diseases with perceived product development and market advantages  Platensimycin is a significant new antibacterial compound with an extraordinary mechanism, but it is not the first antibiotic known to inhibit bacterial fatty-acid biosynthesis  Platensimycin is nevertheless the most potent inhibitor reported so far for FabF, and thus its discovery is an encouraging one. Subsequent tweaking of these chemical scaffolds has produced most of todays antibiotics Such intermediates are short-lived, typically with lifetimes of the order of milliseconds, and so are difficult to observe That neither of these fungus-derived compounds has found a use in the clinic is testimony to the high standards required for a successful new antibiotic The chemical group that forms the side chain of glutamine mimics a bound fatty acid The FabF enzyme mediates a reaction that has a fascinating catalytic cycle ( Fig. 1 ) The fatty acid to be elongated is first transferred from ACP to FabF, leaving the fatty acid bound to the enzyme through an active-site amino acid (cysteine), affording a transient acyl–enzyme intermediate  The malonyl–ACP substrate is bound by FabF, and then loses carbon dioxide to produce a reactive two-carbon unit The path ahead remains a long one that includes further preclinical study, and, if these studies are successful, extensive clinical trials for safety and efficacy in humans The problem is highlighted by the emergence of multiply-drug-resistant strains of these organisms — so-called superbugs — that are resistant to vancomycin , a drug widely recognized as the last line of defence in many Gram-positive bacterial infections The reactive unit attacks the acyl–enzyme intermediate and yields an elongated product that is released from the enzyme The report reads like a textbook of modern antibacterial drug discovery, beginning with a screen of 250,000 extracts from drug-producing microorganisms The source of extender carbon atoms is a molecular fragment known as a malonyl group, which is attached to ACP The structure reveals that formation of the acyl–enzyme intermediate is accompanied by structural changes that open up the active site, permitting binding of platensimycin in such a way that it blocks the addition of malonyl–ACP The target of platensimycin is a key enzyme component of this machinery: β-ketoacyl-ACP (acyl carrier protein) synthase, also known as FabF The variant enzyme bound platensimycin with high affinity, and a high-resolution crystal structure of the complex of variant FabF with the new antibiotic was obtained There is thus a strict order involving the addition of fatty acid–ACP and then malonyl–ACP They are produced through the repetitive action of biosynthetic machinery that elongates the chains two carbon atoms at a time They prepared a variant of the FabF enzyme in which the cysteine of the active site was replaced with the amino acid glutamine This loose analogy refers to the way that the first substrate ‘pings’ into the active site and the first product ‘pongs’ out, leaving the enzyme altered, so that the second substrate does the same as the first, leading to a product known as β-ketoacyl-ACP ( Fig 1 ) To overcome this problem, the researchers created a mimic of the acyl–enzyme intermediate Wang and colleagues report of a compound representing a novel class of antibiotic with activity against Gram-positive bacterial pathogens is thus particularly exciting, with the added bonus that platensimycin is effective against multiply-drug-resistant strains of staphylococci and enterococci Wang et al . provide an account of some terrific detective work that revealed that platensimycin binds only to the acyl–enzyme intermediate Wang et al . show that this antibiotic is effective in a mouse model of infection What follows is a series of elegant studies, spanning bacterial genetics, biochemistry, pharmacology and structural biology, and leading to the discovery of a small molecule derived from Streptomyces platensis that targets a seldom-exploited weakness in bacteria: fatty-acid biosynthesis
 A cabinet committee on gender equality, meanwhile, set the target of having 30% of all ‘leading positions’ in society — which should include senior researchers — occupied by women by 2020 A national five-year plan on gender equality, when it is renewed next year, will add the question of women in science to its list of a dozen ‘priority objectives’ According to an annual government report on gender equality published in May, fewer than 12% of working scientists in Japan are women — the lowest proportion of any leading industrial nation According to one official working on the gender issue, “the little voice of women researchers is starting to be heard” Agencies and institutions that arent doing so, and prefer to pay lip-service to the issue, need to be made aware that their failure will carry a cost. All of this official activity may start to pull more women into science Back in 2000, the Science Council of Japan, which is the interface between Japans academic societies and the government, said it would raise the number of women on its 210-strong central committee to 10% by 2010 But even if that happens, too little is being done to address the set of circumstances that keeps them on the lower rungs of the research ladder, and prevents them from building productive and independent careers Even more strikingly, fewer than 4% of full university science professors are female For example, the dismal statistics in the report provoked a barrage of critical coverage in the Japanese press, which might once have been inclined to ignore the issue Japanese institutions have started to publicly acknowledge the problem and set targets to redress it Junior scientists, for example, are usually dependent on fixed-term grants from research agencies that do not take account of maternity leave Laboratories in universities and elsewhere make little provision for nursery care The Council for Science and Technology Policy will review these requests in the autumn The Council for Science and Technology Policy, the top science policy body in the government, has also pledged action The latest figures on the problem are nonetheless sobering The number, which had hovered around 1% before the announcement, crept past 3% during 2000 and to 6% in 2003 The time is now ripe for the science and education ministry, the universities and the research agencies to put all their fine words into action as they prepare their annual budget requests for submission next month The under-representation of women in Japanese science, particularly at its higher levels, is not exactly news There are some signs, however, that the issue is at last gaining the recognition it deserves They also lack an accessible and effective body to investigate allegations of discrimination When it does so, it should consider carefully whether institutions are acting quickly enough to implement Japans gender-equality objectives
 Although emergency help to survivors clearly remains the main concern, environmental groups are already counting the wider cost, including eroded coastlines and saltwater pollution of fresh water and farmlands And some key research labs that could monitor progress have been damaged And the United Nations Environment Programme announced in late December that it would initially commit US$1 million to an environmental assessment At Sri Lankas main aquatic research centre, the National Aquatic Resources Research and Development Agency near Colombo, flooded instruments and a ruined research vessel will delay efforts to resume studies, says its director-general Sepalika Jayamanne But working out exactly what has been lost and its rate of recovery will be difficult Environmental organizations say that the first priority is to document the amount and types of destruction wrought by the waves Environmental scientists say that pre-existing damage to coastlines and marine ecosystems from settlements, over-fishing, climate change and pollution worsened the impact of the tsunami and have lessened the ability of marine ecosystems to bounce back. “Its stacking one stress on top of another,” says Jerker Tamelander, who coordinates the World Conservation Unions marine programme in Colombo For some regions there is no information about its previous condition In one preliminary study, Parish and his colleagues analysed satellite images of Aceh province in Sumatra, one of the worst hit regions, before and after the tsunami Repairing the ecosystems damaged by the Asian tsunami should be a priority, say environmental organizations, if the long-term livelihood of devastated communities is to be secured Some coral reefs, seagrass beds and mangrove swamps, which are vital feeding and breeding grounds for fish and other ocean life, are thought to have been uprooted or smothered by sand and debris Some have already launched preliminary surveys with satellite images and divers The catastrophe should also serve as a wake-up call to other regions of the globe: areas such as those around the Pacific Ocean, where environmental damage may also have weakened natural defences against earthquakes and tsunamis, says Ian Dutton, who heads the Indonesia programme for the Nature Conservancy, an environmental group headquartered in Arlington, Virginia. “Its a chance for the world to take stock of how were increasing our vulnerability to disasters.” They are urging the international community to ensure that marine parks are maintained, some communities are shifted inland, and defensive buffer zones of mangrove are planted against future erosion and typhoons They say that destruction was far worse where protective mangrove swamps had been replaced by fish farms and settlements To avoid repeating these mistakes, Parish and other researchers say it is vital to consider conservation priorities from the start of reconstruction Without efforts to repair these ecosystems, researchers say that there could be serious, long-term consequences for the communities that rely on the coast and ocean for food, fuel and storm protection. “Itll be critical to ensure that they are re-established as quickly as possible,” says Faizal Parish, a wetlands researcher who directs the Global Environment Centre in Selangor, Malaysia
 A complete genome of the bacterium Baumannia cicadellinicola and a partial sequence of Sulcia muelleri reveal that Baumannia has the metabolic pathways needed to provide its insect host with vitamins, but has lost those for the essential amino acids Abrasive pastes made from cerium oxide nanoparticles are used to flatten silicon wafers, a key step in the manufacture of integrated circuits Adding titanium to this burning precursor mix gave nearly round particles, because the titanium forms a liquid shell around the crystallizing cerium oxide (pictured above) Am Astronomy: Hydrogen hunt over Astrophys Atomic hydrogen shows up clearly in these systems, dubbed ‘damped lyman alpha absorbers’, but there has been little evidence for molecular hydrogen Azad Bonni of Harvard Medical School in Boston, Massachusetts, and his colleagues studied the response of mammalian neurons to oxidative stress B doi:10.1098/rspb.2006.3567 (2006) Warming waters threaten the intimate relationship between stony corals and the nutrient-providing zooxanthella algae that live within their tissues Biology: Three-way feast PLoS Biol. doi:10.1371/journal.pbio.0040188 (2006) The glassy-winged sharpshooter, Homalodisca coagulata , unlike many sap-sucking insects, sups from the water-carrying cells of the xylem, rather than the sugary sap of the phloem But research from the Australian Institute of Marine Science, Townsville, offers some hope But such particles tend to have a faceted shape, with angular edges that can damage the wafer surface By contrast, the Kukar et al . paper leaves me uneasy Cell Biol. doi:10.1083/jcb.200509009 (2006) Disease-causing Staphylococcus aureus bacteria (pictured below) may escape from the bloodstream by punching holes through the cells lining blood vessels, say researchers Cell biology: Neurons and nematodes Cell 125, 987–1001 (2006) Scientists have identified a mechanism that plays a role in both a cells response to stress and an organisms lifespan Chem Dichroanone includes three carbon rings fused to a central carbon atom in a configuration that is notoriously hard to build Each of the three organisms thus requires both of the others Ecology: The truth about trees Science doi:10.1126/science.1124712 (2006) A vast survey of the worlds tropical forests is set to fuel the debate over what determines their diversity EDIN blocks a protein called RhoA, which acts rather like the foreman on a building site, telling cells where to construct their internal scaffolding in response to external signals Emmanuel Lemichez at the National Institute of Health and Medical Research in Nice, France, and his colleagues studied the effects of an S. aureus toxin known as EDIN Flood basalts elsewhere have been linked to other mass extinctions because of their effect on global climate and atmospheric chemistry — this is the oldest such association Geology: After the flood Geology 34, 461–464 (2006) What caused the mass extinction at the end of the Early Cambrian epoch, about 508 million years ago? Linda Glass and David Phillips of the Australian National University in Canberra have identified a new suspect: a massive outpouring of volcanic rock in what is now northern Australia Hardly surprising, then, that light from quasars rarely passes through it However, they conclude: “exogenous compounds... may represent an unrecognized risk for the development of Alzheimers disease” I bet in many pharmaceutical companies the press officers were on red alert, while lawyers and managers spent precious time drafting a response to possible litigation because medication X could have caused Alzheimers in grandad or grandma I felt immediately depressed, considering my secret long-term plans as emeritus professor I wonder why this didnt happen. In nematode worms, the researchers implicated MST–FOXO signalling in ageing Instead, the researchers found that the most diverse forests were the least varied demographically It was previously thought that having tree species with a broad range of lifespans and growth rates would promote diversity, reasoning that a slow-growing tree, for example, would better compete with fast-growing neighbours if it were longer lived J. 643, 675–679 (2006) Maps of nearby galaxies have resolved an astronomical riddle concerning the whereabouts of the material that fuels star formation — molecular hydrogen Jonathan Eisen, then at the Institute for Genomic Research in Rockville, Maryland, and his colleagues have now shown how a division of labour between the symbiotic bacteria living in the insects cells makes this low-nutrient lifestyle possible Journal club Bart de Strooper Flanders Interuniversity Institute for Biotechnology and the Catholic University of Leuven, Belgium An expert in Alzheimers disease wonders why striking findings didnt hit the headlines Kukar et al  Last year, Nature Medicine published a paper that, in my sincere naivety as a basic science researcher, I expected to prompt headlines such as ‘Major crisis in pharmaceutical sector’ and ‘Stock owners dump shares’ Lett. 96, 215503 (2006) Tiny vibrating rods can be used as highly sensitive weighing scales, because an attached mass — down to a single virus particle — will change their oscillation frequency Lond Marine biology: In hot water Proc Martin Zwaan of the European Southern Observatory and Jason Prochaska of the University of Californias Lick Observatory, Santa Cruz, report that, in nearby galaxies, molecular hydrogen clusters densely in the galactic centre — occupying an area 150 times smaller than the atomic hydrogen Material science: Polished finish Science 312, 1504–1508 (2006) Round nanoparticles will give silicon a better polish, say researchers who have developed a recipe for cooking them up Microbiology: Hole punch J Nanotechnology: Trombone scales Phys Nature Med. 11, 545–550; 2005) showed that a bunch of compounds, some registered as therapeutics, could augment in human cell cultures production of the small amyloid-beta peptide Aβ42, believed to cause Alzheimers disease Now chemists have made one of its optical isomers from scratch — the first enantioselective synthesis of any chemical in this family Organic chemistry: Symmetry selective J R Ray Berkelmans and Madeleine van Oppen transplanted Great Barrier Reef coral colonies from cooler reefs to warmer inshore bays, where the corals expelled their symbiotic algae, a process known as coral bleaching (see white colonies, pictured) Recently, for instance, I was asked to comment on an ominous report claiming that intellectuals might be at higher risk of dementia Researchers led by Alex Zettl at the University of California, Berkeley, have built such a device using a carbon nanotube that can be extended like a telescope Rev Richard Condit of the National Center for Ecological Analysis and Synthesis in Santa Barbara, California, and his colleagues analysed data from sites ranging from a dry forest in India, with just 73 species in 50 hectares, to a rainforest in Malaysia with 1,167 species in a similar-sized area Ryan McFadden and Brian Stoltz of the California Institute of Technology, Pasadena, managed to produce (+)-dichroanone in 11 chemical steps with a 4% overall yield (pretty impressive for an asymmetric natural product synthesis) Soc Soc. doi:10.1021/ja061853f (2006) Dichroanone is part of a family of natural chemicals with anti-tumour properties Some of the corals that recovered from the first bleaching event could then tolerate temperatures 1–1.5 °C warmer than previously Sulcia devotes most of its very small genome to that neglected task, thus complementing its colleague The authors, well aware of the potential implications of their observations, are careful in their extrapolations The increases in Aβ42 levels observed were quite dramatic, equaling or even surpassing those caused by the genetic mutations that lead to early and aggressive forms of genetic Alzheimers The light from some quasars contains absorption lines, created when it passed through galaxies en route to Earth, which provide information about the galaxies content The loss of this coordination results in long tunnels, dubbed macroapertures, forming in the cell The paper (T The researchers show that these corals had changed their algae to a more heat-resistant form They avoid using protecting groups, which are normally needed to shield one part of a molecule while another segment is being transformed — a strategy that cuts the number of steps They found that FOXO transcription factors are the long-sought targets of a family of stress-activated enzymes, the MST kinases: the enzyme MST1 alters FOXO3, ultimately triggering the death of the damaged cell They have used radioisotope dating to fix the age of this formation, christened the Kalkarindji ‘flood basalt’ province, to around the time of the Cambrian mass extinction They say this allows them, “like a trombone player shifting notes”, to tune the rods vibrational frequency This insignificant story slipped easily out of my mind This should make the device sensitive to a wider range of masses than a tube of fixed length, as the resonant frequency can be matched to the mass to be measured Those with more of the enzyme had a longer lifespan, providing that the FOXO3 analogue was present To my surprise, the publication went largely unnoticed, even though many more modest papers get easily into the news Worms lacking the MST analogue CST-1 died young Xiangdong Feng, then at the Ferro Corporation in Independence, Ohio, and Zhong Lin Wang of the Georgia Institute of Technology in Atlanta synthesized their particles by setting a cerium spray alight
 Another, investigating wind chill, involved a dousing in water and a wind machine But nevertheless, he remains a firm believer in the need for animal research Festing admits the experiences were difficult. “It did make me think harder about the welfare of lab animals,” he says In one reality television show, called The Devils Challenge , the director of one such group is caged and subjected to procedures used in animal labs One recreated a test for pain, where rats are placed on a hotplate and the time until their feet twitch is recorded Other challenges brought him face to face with animal-rights activists and sent him to a primary school, where he tried unsuccessfully to persuade children to donate their cats for animal research Simon Festing, director of the Research Defence Society in London, agreed to do the show, which was designed to test his belief in animal experiments. “We need to face the fact this is how the media works,” he says, “and its a good way to get our arguments out there.”  Kept in a cage proportional in size to those used to house lab mice, Festing was subjected to a number of experiments The Devils Challenge is broadcast on the UK digital channel More4 on 14 December To counter animal-rights activists, UK lobby groups that support animal research have launched their own media campaign Tom Simonite
 Archaeology Embarrassed Czech archaeologists have found that a statuette thought to represent a fifth-century Persian goddess came from a mould made in 1968 by a local pensioner Nuclear safety Ukrainian officials have recovered 14 pieces of nuclear fuel stolen from the now-defunct Chernobyl power plant Number Crunch 60% of PhD-granting physics departments in the United States report visa problems for foreign students returning after trips abroad. 48% of the physics departments had at least one foreign student who was denied entry or considerably delayed by visa problems. 13% is the fall in the number of first-year enrolments by foreign graduate students in the United States between 2000 and 2004 On the Record “Had the decision been mine, we would not have built the space station were building in the orbit were building it in.”  NASA administrator Michael Griffin attacks the International Space Station. “Having a moon is just inherently cool — and it is something that most self-respecting planets have.”  Astronomer Michael Brown talks about the discovery of a moon orbiting the Solar Systems ‘tenth planet’ Researchers will use magnetic resonance imaging to track disease progression in the dogs Source: American Institute of Physics Source: USA Today, Caltech Scorecard Dogs Labradors with osteoarthritis are the focus of a study launched at the University of Liverpool, UK The rods, found in a plastic bag near the plants perimeter, had been missing for a decade
 A few of my colleagues and I rejected PhD posts abroad and stayed here, partly because we wanted to prove that it is possible to become a good scientist in Poland But at least we did what our hearts dictated. But I do wonder what the future holds for Polish science I am amazed at the way Europe is increasingly becoming one big ‘village’ I remember the problems faced by my father when he wanted to work abroad I understand that there are better opportunities for young scientists outside Poland, but will these well-trained scientists ever return home to work? I hope that the answer is yes, although I have my doubts My generation has incredible freedom by comparison: nearly all of my colleagues from my days as an undergraduate are abroad doing PhDs, or have simply moved away with their spouses or partners Not so long ago, it was very hard to leave Poland for Western Europe or the United States — especially to work or study Now that Poland is a member of the European Union, for example, we can travel without restrictions On the one hand, this is good — I now have friends in many different countries and can visit them whenever I want The countries seem to be getting closer to each other What effect this choice will have on our careers remains to be seen
 A large part of the warming has occurred in the upper 700 metres of the oceans, although the distribution of heat varies geographically: the Atlantic Ocean has taken up more heat than the Pacific and Indian Oceans combined A new link has now been added, with the discovery that high-fat foods stimulate the livers production of PGC-1β, a transcriptional coactivator protein that promotes the creation of fatty molecules such as cholesterol and triglycerides A significant factor in these reductions is that cars produce lower emissions when they travel faster: average speeds in the charging zone rose from 19 to 23 km h −1 in 2003 Although the authors admit a large uncertainty in the calculations, they say that their results are likely to underestimate the benefits of the scheme Beevers and David C Behav. doi:10.1016/j.anbehav.2004.06.020 (2005) Bottlenose dolphins apparently use their sophisticated echolocation powers only sparingly in the wild, and the prevalence in their diet of fish that produce sound in various ways led to the idea that they listen passively for food Between 2002 and 2003, the emission of nitrogen oxide compounds was reduced by about 12% inside the charging zone, while levels increased by roughly 1.5% on main roads just outside the zone But that tells only part of the story, according to S Carbon dioxide emissions in the zone are down by almost 20% Carslaw obtained some interesting findings Control noises, on the other hand, elicited no change in behaviour Controlling the expression of PGC-1β in the liver might help to minimize the health impacts of a high-fat diet, the authors suggest — although a means to the same end is to eat less saturated fat in the first place Damon P Emission of small particles decreased by about 12% inside the zone, and by 1.5% just outside Environ. 39, 1–5 (2005) The London congestion charging scheme has been causing controversy since it began in February 2003 Gannon et al . played sound recordings of several species of prey fish in the water, as well as the sounds of the snapping shrimp — which the dolphins are not known to eat — as a control Gannon et al . provide evidence to support this idea Helen Pearson Metabolism: From fats to fat Cell 120, 261–273 (2005) We all know that a high-fat diet leads to increased body fat and clogged arteries, but the metabolic details of this cause-and-effect chain are still not completely clear Immunology: A nod in the right direction Science 307, 731–734; 734–738 (2005) A gene called Nod2 is often mutated in people with Crohns disease, in which chronic inflammation in the small intestine causes pain and diarrhoea Kobayashi et al . show that mice genetically engineered to lack Nod2 protein are more susceptible to bacterial infection, and that immune cells lacking Nod2 no longer recognize a bacterial coat protein or trigger the normal protective immune response Koichi S Lett. 32, L02604 (2005) Discussions of global warming tend to focus on the mean temperature of the atmosphere at the Earths surface, which has warmed by about 0.8 °C over the past century Levitus and colleagues Mark Peplow Meanwhile, Shin Maeda et al . find that mice engineered to carry human-type mutations in Nod2 are also more susceptible to bacterially induced intestinal inflammation Mice fed a diet rich in saturated fats but low in cholesterol showed increased PGC-1β expression in the liver, report Jiandie Lin and colleagues Michael Hopkin Animal behaviour: The sound of sustenance Anim Philip Ball Environment: Congestion success Atmos Res Roxanne Khamsi Oceanography: Global warming all at sea Geophys Some businesses claim that the charge of £5 (US$9) to drive in central London deters shoppers, but the scheme has succeeded in reducing traffic jams Sounds paltry? It certainly isnt The authors also find that Nod2 switches on the production of a group of antimicrobial peptides in the intestine that are important in suppressing infection by pathogenic bacteria The finding adds to the picture of how a fatty diet leads to increased blood levels of cholesterol and triglycerides, which can cause heart disease and atherosclerosis The researchers conducted playback experiments off the coast of Florida to determine the foraging behaviour of bottlenose dolphins The results suggest that Nod2 mutations might promote Crohns disease by hobbling normal immune responses, rather than by triggering the disease itself — a finding that may point to new ways of treating the condition They have brought together more than four decades of measurements to calculate that the world ocean has, on average, warmed by 0.037 °C since 1955 They suggest that the protein controls the activity of two molecules involved in inflammation, NF-κB and interleukin-1β This apparently small increase in ocean temperature has been brought about by an enormous input of heat, accounting for 84% of the total increase in heat content of the Earth system This dominance of passive listening in the initial stages of hunting suggests that echolocation incurs a heavy energetic or ecological cost, the authors say This in turn binds to and coactivates the sterol responsive element binding protein (SREBP) family of transcription factors, which can boost the activity of fat-creating genes To put this in perspective, an ocean warming of 0.1 °C would, if all the heat were discharged to the atmosphere, warm the planets surface by 100 °C Two groups have begun to unravel how the altered gene might increase susceptibility to the condition Unusual weather conditions have made it difficult to assess the full impact of the scheme on air pollution, but using a combination of traffic-monitoring data and emissions modelling, Sean D Water has a very large heat capacity, which means that it takes a lot of heat to raise its temperature When the dolphins heard the fish sounds, they immediately changed their direction of travel, turning to pursue the fish and upping the previously low rate of echolocation
 A better understanding of the molecules involved in immune responses has identified many potential targets for the treatment of autoimmune diseases But although successful therapies have been found for immune disorders in animal studies, few have passed the much harder test of treating human diseases Future therapies will probably include both non-antigen-specific strategies that target cytokines (cell–cell signalling molecules) or block the molecules that stimulate immune responses, and antigen-specific therapies that induce tolerance to self antigens. So far, non-antigen-specific approaches, such as the blocking of tumour-necrosis factor, are achieving some success but the same is not true for antigen-specific approaches A further complication for the transition from animal to human studies is the necessary preoccupation with safety in human immunotherapy, a relatively ignored issue in animal models A major problem in establishing which ones may be targets lies in the considerable overlap (redundancy) in their biological properties A phase I trial with DNA vaccines designed to tolerize against myelin proteins is currently underway A phase IIb trial is now underway using the lower dose A summary of therapeutics is in Table 1  A whole set of ‘targeted therapies’ has been developed to block many steps in the immune and pro-inflammatory response A widespread misconception is that every step of the immune or pro-inflammatory process is a potential therapeutic target Alternatively, although TNF may have a destructive role in inflammation in the brain, it may also act as a growth factor for myelin-producing cells, indicating that TNF, similar to many other cytokines, has both harmful and beneficial effects  Alternatively, failure to prevent disease might have been caused by the anti-CD4 antibody also inhibiting regulatory T cells that express CD4 Although several attempts in the past decade have failed, we are optimistic that eventually, the molecular understanding of tolerance and immunity will progress, and the ‘holy grail’ of autoimmunity — long-term antigen-specific therapy — will be reached An altered peptide ligand (APL) of MBP-derived peptide 83–99 was constructed by mutating the amino acids that form the main contact sites with the TCR on disease-causing T cells  An alternative method of targeting antigen-specific responses has recently been developed using DNA constructs that are designed to promote the tolerization of immune responses to multiple myelin components An important step in this progression will be achieving earlier treatment And APL administration similarly induced a shift to T H 2-cytokine production, reduced epitope spreading, and reduced the broadening of the adaptive T- and B-cell responses And promising results have been seen in the treatment of rheumatoid arthritis with anti-IL-15 antibody  Another approach is to target the mechanism involved in the production of TNF in the joints versus that involved in the production of TNF in the immune system, but despite evidence that the mechanism differs, we do not know the molecular targets  Another benefit of monoclonal antibodies lies in the fact that even partially humanized antibodies (such as chimaeric antibodies of mouse Fv on a human backbone), as well as fully humanized antibodies, are relatively non-immunogenic Another common side effect of TNF blockade is the induction of IgM anti-nuclear antibodies, which have been detected in many patients (15%; ref. 68 ), although IgG antibodies and drug-induced lupus (an antibody-mediated disease) only rarely occur (less than one in 1,000 patients) Anti-TNF therapy reduces joint pathology, even in patients showing no clear benefit according to ACR criteria Antigen-specific approaches The adaptive autoimmune response becomes more complex as disease progresses, owing to the generation of T-cell reactivity and antibodies to other local molecules — a concept known as epitope spreading  As extracellular molecules, they are accessible to ‘biologicals’ — protein therapeutics such as antibodies or soluble receptors As summarized in Box 2 , anti-TNF therapy of rheumatoid arthritis has marked clinical benefit, with some changes, such as reduction in tiredness, occurring within hours Attempts so far to develop inhibitors of p38 MAP kinase — a component of pro-inflammatory signalling cascades and a favourite target among pharmaceutical companies — have not succeeded, owing to toxicity Because chronic inflammatory diseases depend on the recruitment of inflammatory cells to the inflamed site, any approach that reduces the number of inflammatory cells in the site of disease may be of benefit, be it through chemokine or adhesion-molecule blockade Because many potential therapeutic targets are exposed in extracellular fluids (cytokines, chemokines, receptors, other cell-surface molecules and adhesion molecules), they are readily accessible to high-affinity neutralizing antibodies Because most therapeutics only have a partial inhibitory effect, only those molecules that are in short supply (and thus rate-limiting) are likely to be useful targets Because the key homing molecules — integrins and selectins — display a high degree of diversity, a particular integrin molecule or selectin molecule is critical for entry to a particular anatomical site, and blocking that molecule might abolish pathological homing to that site, leaving lymphocytes free to move elsewhere Because we do not understand the differences between the chronic and acute response, we cannot be sure which, if any, animal models of disease provide good reflections of the key processes that occur in human disease Benefit from anti-TNF blockade is not seen in all autoimmune diseases Blocking lymphocyte mobility with these two drugs, and blocking lymphocyte entry to the brain, may have caused this unusual infection, caused by the ubiquitous JC virus, the activation of which is most commonly seen in severely immunocompromised individuals Blocking other molecules that are involved in activating the immune system may also be useful therapeutically Breedveld et al ., unpublished observations) But although targeting these tipping points may provide significant benefit, in terms of treating autoimmune disease, blocking these critical physiological molecules could also negate their beneficial roles in generating protective immune responses, and therefore could lead to an increased risk of infection But because the antibodies caused unexpected toxicity when tested in monkeys , this has not yet been tested in humans But because the benefit seen here is achieved by interfering with processes that are involved in both host defence and autoimmune pathology, the overall benefit:risk ratio is inherently difficult to predict But the main problem with cytokines is that they have multiple effects on many cell types , so systemic injection of cytokines can cause undesirable effects But the most obvious way to reduce opportunistic infections is to use antigen-specific therapy — a dream of immunologists for generations now But there is, as yet, no evidence of a cure But with such non-antigen-specific approaches, the risk of opportunistic infection is problematic By contrast, encouraging results have been reported from both animal models and early clinical studies using a mutated, less activating form of anti-CD3 antibody Cell recruitment: chemokines and adhesion molecules The small-protein chemotactic cytokines (chemokines) have several properties that make them favoured targets in the pharmaceutical industry : they are extracellular, and so accessible to biologicals; and they bind to seven-transmembrane receptors that can be blocked by small-molecular-mass chemicals Components of the pathological cascade that have received most attention are: factors involved in lymphocyte homing to target tissues; enzymes that are critical for the penetration of blood vessels and the extracellular matrix by immune cells; cytokines that mediate pathology within the tissues; various cell types that mediate the damage at the site of the disease, as well as these cells antigen-specific adaptive receptors, including the T-cell receptor (TCR) and immunoglobulin; and other toxic mediators, such as complement components and nitric oxide ( Fig. 1 ) Consistent with this, in many animal models of autoimmune disease, antibodies specific for MHC class II molecules reduce disease Current tools for immunotherapy Monoclonal antibodies The success of monoclonal antibodies was slow to arrive, but in 2004, there were two ‘blockbusters’ on the market (each generating over $1 billion) — infliximab (Remicade), an anti-TNF antibody, and rituximab, an anti-CD20 antibody Cytokines Cytokines are short-range protein mediators with a wide range of actions Cytokines Cytokines have some useful ‘drug-like’ properties, such as potency, but also some disadvantages, such as a short half-life Despite successfully preventing disease in animal models when antigen was fed at the time of disease induction , clinical trials attempting to treat ongoing disease have been unsuccessful  Effective antigen presentation and activation of T cells requires not only TCR recognition of MHC molecules complexed with a peptide, but also various ligand–receptor costimulatory interactions at the ‘immune synapse’ — the point of interaction between a T cell and an APC Encouraging results were seen with the same antibody in the treatment of inflammatory bowel disease  Finally, blocking the receptor activator of nuclear factor NF-κB ligand (RANKL), the main activator of osteoclasts, is a promising approach for reducing bone destruction, such as that seen in rheumatoid arthritis  For example, despite the enormous success in treating multiple sclerosis by blocking α 4 β 1 integrin, this treatment was recently voluntarily withdrawn because of the development of a fatal untreatable infection For now, the non-antigen-specific approaches are the ones yielding clinical benefit, with the blocking of cytokines, and possibly adhesion molecules, being the most effective Furthermore, as natural-body constituents (in contrast to the small-molecule chemicals commonly used as pharmaceuticals), antibodies intrinsically lack toxicity when manufactured, purified and handled properly Furthermore, results in acute animal models of autoimmunity are often not predictive for the treatment of chronic human immune disorders  Given the ubiquity of autoantibodies in autoimmune diseases, it was assumed that the antibody-producing cells — plasma cells and B cells — would be a good target for therapy Hence its blockade is useful in treating many diseases Hence, existing drugs (which are relatively safe) with new potential uses present a wonderful opportunity Hence, TNF blockade is an approved therapy for multiple chronic inflammatory diseases — rheumatoid arthritis, Crohns disease, psoriatic arthritis, ankylosing spondylitis and psoriasis, with more likely to follow Here, we highlight recent successes in immunotherapy, which is now benefiting almost a million patients with chronic diseases, such as rheumatoid arthritis and Crohns disease, that are unresponsive to other treatments High mobility group 1 (HMGB1), a stimulator of inflammatory responses, is another promising target for arthritis and sepsis  However, as severe disease is treated by anti-TNF therapy, it is not yet clear whether there is an increased risk of developing lymphomas after anti-TNF therapy However, flu-like symptoms are common during therapy with IFNs, and the immunogenicity of IFNs (probably mechanism related because they upregulate antigen presentation) can limit their efficacy However, like cytokines, there are numerous chemokines (more than 40) with redundant properties, so it is not clear which ones are the most relevant in which disease However, T H 2-type responses are associated with allergic reactions, and about 10% of individuals taking glatiramer acetate develop allergic reactions However, the blockade of α 4 β 1 integrin is not specific However, the clinical benefits of IL-6 blockade occur more slowly than with TNF blockade, as predicted from in vitro studies that revealed a TNF-dependent cytokine cascade , where TNF drives the production of multiple pro-inflammatory cytokines However, the degree of clinical benefit can vary considerably from patient to patient However, the limited scope for experimentation in humans during clinical trials may mean that inappropriate antibodies or dose regimes have been used However, the local regulated delivery of cytokines using gene therapy could make them effective as treatments However, the recent withdrawal of anti-α 4 β 1 integrin emphasizes the complexity of reversing ongoing autoimmune disease, without provoking serious complications However, this assumption has only recently been confirmed: lytic anti-CD20 antibody (rituximab; Rituxan), which lyses B cells, effectively treated rheumatoid arthritis and systemic lupus erythematosus , although extensive comedication of subjects in these trials makes the data difficult to interpret Human transplants, which often undergo chronic rejection despite continuous immunosuppressive therapy and early success, have confirmed our lack of understanding of chronicity Humanized monoclonal antibodies in the clinic include natalizumab, which blocks α 4 β 1 (ref. 6 ), and the fully human anti-TNF antibody adalimumab (Humira) If lupus does occur, it is reversible, treatable and not nephrotoxic, so is not a major clinical problem IFN-β inhibits the activity of metalloproteases 2 and 9 IL-6 is another useful target, with clinical-trial success in rheumatoid arthritis showing comparable efficacy to TNF blockade  Immune surveillance is accomplished by highly mobile leukocytes that are primed to fight microbes anywhere in our bodies Immunotherapy is a type of treatment that uses immunological tools, such as monoclonal antibodies, receptor–immunoglobulin fusion proteins, vaccines and immune cells In a phase II placebo-controlled human clinical trial, MBP APL (given in weekly subcutaneous doses) shifted the response of MBP-specific T cells, promoting T H 2-cytokine production (including IL-4, IL-5, IL-10 and IL-13) and downregulating T H 1-cytokine production (including IFN-γ and TNF)  In animal models, these TNF variants are effective  In contrast to the limited success of treatment with cytokines (see below), blockade of cytokines is the success story of the current era of molecular therapy in autoimmunity, which is based on scientific analysis of disease mechanisms  In epidemiology, a tipping point is defined as the moment when epidemics qualitatively change, reach a critical mass and have major repercussions In fact, the treatment of multiple sclerosis patients with TNF blockade, using lenercept, a TNFRp55–Fc construct which never reached the market, exacerbates the frequency of disease relapse , possibly by augmenting T-cell activity  In multiple sclerosis, relapse rates are reduced by 30% with the administration of IFN-β (ref. 59 ) In the 1970s, a random copolymer of the amino acids glutamate, tyrosine, alanine and lysine (copolymer 1 or Cop-1), now termed glatiramer acetate or copaxone, was designed to mimic the composition of myelin basic protein (MBP) — a major target of autoimmune responses in multiple sclerosis In the early stage of disease, there is evidence of disease remissions, which may persist for a year or more after the withdrawal of anti-TNF therapy (F In the future, non-antigen-specific approaches may be made safer by targeting them to the site of disease, for example by gene therapy In the pharmaceutical industry, drugs in only about 5% of the ‘small-molecule’ drug projects end up as approved therapeutics; most drop out because of problems, usually toxicity In the trial with the APL of HSP60, decreased exogenous insulin use was observed in diabetics, as well as a T H 2 shift  In this case, the magnitude of this risk is hard to measure because rheumatoid arthritis patients are more susceptible to infections, partly owing to the disease and partly because of other treatments In this circumstance, endogenous viruses like JC virus, which causes progressive multifocal leukoencephalopathy, may become activated with fatal consequences Infliximab and rituximab are derived from early monoclonal antibody technology Initial studies in animal models of multiple sclerosis (EAE) indicated that the critical homing molecule to the inflamed central nervous system (CNS) is α 4 β 1 integrin : anti-α 4 β 1 antibody blocked the entry of lymphocytes into the brain and abrogated the clinical paralysis associated with EAE It initiates the defence response to local injury, recruits leukocytes, and initiates a whole series of events that are important in health and in many diseases It interferes with lymphocyte homing in general, and therefore raises the risk of opportunistic infections  It is the first example of therapy promoting endogenous repair in any reported human disease It is thus comforting that there are some clear successes, such as TNF blockade, that are now well established ( Table 1 ) Lower doses of MBP APL reduced both the number and the volume of brain lesions detected with magnetic resonance imaging (MRI), but higher doses exacerbated disease in three patients and increased brain lesions  Lymphocyte migration depends on highly specific ‘adhesion’ molecules expressed by T cells that bind to receptors induced on endothelial cells  Lymphomas are more frequent in patients with rheumatoid arthritis than in the normal population, especially those with severe long-standing disease More are on the way; currently almost half of all drug candidates in clinical development are monoclonal antibodies More common are respiratory infections Most important among these costimulatory interactions are CD28 molecules recognizing CD80 or CD86 molecules ( Fig. 2 ) Most importantly, chemokines are mediators of cell migration Most importantly, recent studies have documented evidence for joint repair, after TNF blockade: joint X-rays taken after one year of treatment show an improvement in joint condition compared with those taken before treatment  Much has been learnt from the use of anti-TNF biologicals; for example, the importance of finding the right therapeutic target Mutated versions of cytokines can be used as decoys, inhibiting the ability of the endogenous cytokine to act on its receptor Non-antigen-specific approaches T-cell populations and antigen-presenting cells Despite preventing disease (such as arthritis and experimental autoimmune encephalomyelitis, EAE), to an impressive extent in animal models, anti-CD4-antibody therapy, with either lytic or non-lytic monoclonal antibodies, has not successfully treated human rheumatoid arthritis , psoriasis or multiple sclerosis  Of these, several successes have had a profound impact on patients, on our understanding of disease mechanisms and even on the pharmaceutical industry On the basis of single parameters only, such as joint swelling, all patients improve to some degree , but if compound parameters are monitored, such as the American College of Rheumatology (ACR) criteria (including number of swollen and tender joints, and levels of C-reactive protein), response rates vary between 50–60% in late-stage disease , to more than 80% in the early-stage disease  Oral administration of myelin antigens in multiple sclerosis, collagen in rheumatoid arthritis and insulin in T1DM (which has been shown to favour tolerization of immune responses) has been tested Organ-specific autoimmunity may result when autoreactive lymphocytes enter an inflamed site, initiating multiple events  Other interesting small-molecule targets, such as IKK2 (inhibitor of NF-κB kinase 2), are also risky choices because of their presence in almost all cells Other opportunistic infections are rarer, but like TB can occasionally be lethal Outlook Two decades of work defining the molecular basis of the immune response is starting to pay off in the field of autoimmunity Overcoming limitations Although there is a lot of optimism among some circles that many new safe therapies are just around the corner, this hope belies the fact that clinical successes, where the benefits outweigh the risks, are few and far between Recently, familiar oral medications, such as statins, which are widely used for other disease conditions, have been shown to be effective in animal models of autoimmunity and early-stage clinical trials in patients with multiple sclerosis and rheumatoid arthritis ( Box 1 ) Recently, it has become possible to engineer cytokines that have enhanced half-lives and are activated only at a desired location  Recently, sales of natalizumab were withdrawn, after two patients taking it in combination with IFN-β1a (Avonex) developed progressive fatal multifocal leukoencephalopathy, an untreatable viral infection ( http://www.fda.gov/cder/drug/infopage/natalizumab/default.htm ) Receptor fusion proteins are more expensive to manufacture than antibodies, and the use of natural receptors provides for less diversity than with antibodies Receptor fusion proteins Receptor fusion proteins are proteins in which the binding site of a receptor is fused onto an antibody Fc region, which improves the proteins half-life and other pharmacological properties Regrettably, this is not the case Regulatory T cells and B cells Several regulatory subsets of T cells have been defined in recent years, and attention is now turning to their use for therapy Research using joint tissue from patients with rheumatoid arthritis suggested the importance of TNF in the disease pathogenesis  So early treatment may be the most beneficial and cost-effective So far, only therapies that target two rate-limiting steps — the cytokine tumour-necrosis factor (TNF; ref. 5 ) and the molecule involved in lymphocyte homing, α 4 β 1 integrin — have markedly ameliorated autoimmune disease progression; for example, in rheumatoid arthritis, inflammatory bowel disease, ankylosing spondylitis, psoriasis and multiple sclerosis So tipping points are physiological processes that are key to maintaining both health and disease So, which ones are likely to be therapeutic targets in which diseases? Insights into this problem have come both from in vivo experiments using animal models and from clinical studies  Some molecules and pathways are common in many autoimmune diseases Subsequent developments have led to ‘humanized’ antibodies, in which mouse-derived variable regions (or complementarity-determining regions, CDRs) are grafted into a human antibody scaffold, and ‘fully human’ antibodies, which contain human variable-region components selected by phage display  Success has also come from IL-1 blockade using the IL-1-receptor antagonist anakinra, which is approved for the treatment of rheumatoid arthritis  Such modifications may overcome some of the inherent difficulties of cytokine therapy Such therapeutic options have only been available in the past 10 to 15 years, owing to major advances in medical science and technology, but are now increasingly being used to tackle a wide spectrum of human diseases Targeting various critical molecules involved in pathological pathways has led to the modulation of disease in animal models ( Fig. 1 ) Targets for immunotherapy The treatment of human autoimmune diseases often occurs years after the onset of the pathogenic process, and despite our increasing knowledge of the cellular and molecular processes involved in immunity, the most effective targets for immunotherapy in the chronic phase of the disease are not obvious The administration of glatiramer acetate ameliorated EAE, and is now an approved drug for multiple sclerosis : daily injection of glatiramer acetate reduces disease relapse by 30%, and induces a T helper 2 (T H 2)-type response to myelin antigens The administration of the MBP APL ameliorated EAE in mice induced by a different myelin protein (proteolipid protein), even when the APL was administered after the initial attack of paralysis  The application of immunotherapy to autoimmune diseases is broadening our understanding of the human immune response, with responses to treatment providing unique insights into pathological mechanisms The availability of effective immunosuppressive drugs to ameliorate the immune-mediated rejection of transplants contrasts sharply with the paucity of drugs that successfully treat autoimmune diseases The blocking of costimulatory molecules that are expressed only after antigen activation of T cells, such as OX40, may be efficacious and safer , as this would not block uninvolved T cells The clinical benefit of etanercept is indistinguishable from that of anti-TNF antibodies in rheumatoid arthritis , psoriasis and ankylosing spondylitis, although anti-TNF antibodies are more effective in the treatment of inflammatory bowel disease The consensus at present is that the benefit of using TNF blockade in autoimmune diseases with a bad prognosis outweighs the risks  The dilemma here, however, is to define the right therapeutic target The existence of TNF-inhibiting biologicals (originally generated to treat sepsis syndrome) made it possible to perform a successful proof-of-principle clinical trial in 1992 (ref. 28 ) with the anti-TNF monoclonal antibody infliximab The failure of most immunological approaches that are effective in animal models to modulate autoimmune disease in humans suggests that we do not understand many of the principles behind the pathogenic mechanisms of these diseases The failures include antibodies specific for cell-surface antigens such as CD4 and CD25, cytokines such as IL-8, fusion proteins such as the IL-1-receptor ‘trap’ and the TNFRp55–immunoglobulin fusion protein lenercept, and multiple antigen-specific approaches The future goal will be to improve the efficacy of immunotherapy, from the current state of partial disease control, to increased disease control, to establishing remission and eventually to cure, without increasing either the risks or costs of treatment The greatest benefit is seen with combination therapy ( Box 3 ) The initial incidence of tuberculosis (TB) in one in every 2,000 patients treated with anti-TNF has been reduced markedly by screening and, if necessary, administration of prophylactic therapy The mechanism-of-action studies (see Box 2 ) have provided several insights into the pathogenesis of targeted diseases , especially rheumatoid arthritis The most predictable problem of therapy with TNF blockade (and most other immunotherapies including anti-α 4 β 1 -integrin antibody) is augmentation of the risk of infection The most successful receptor fusion protein is etanercept, a dimeric p75 TNFR–immunoglobulin G (IgG) Fc fusion protein (with sales of over $1 billion) The progress made in devising rational and effective non-antigen-specific therapy reflects the development of useful research and therapeutic tools, and provides grounds for this optimism. The rate-limiting steps of the early immune response (such as the presentation of antigen by dendritic cells, the expansion of CD4 + helper T-cell populations and the induction of costimulatory-molecule expression) may not be rate limiting or critical for the chronic phase of the disease and the resultant tissue destruction, which often occur years after onset The relative potency of cytokines that induce multiple biological effects is compatible with a rate-limiting, ‘catalytic’ role, and therefore they are potential therapeutic targets The risk of infection could be reduced if the duration of TNF blockade were briefer; for example, by using small-molecule chemicals of short half-life The targeting of TNF (ref. 8 ) or α 4 β 1 (refs 6 , 9 , 10 ) has remarkable effects on several autoimmune diseases, including rheumatoid arthritis, inflammatory bowel disease, ankylosing spondylitis, psoriasis and multiple sclerosis The type 1 interferons, IFN-α and IFN-β, are effective drugs and have been approved for use in viral infections, some cancers and multiple sclerosis The use of this antibody avoids the acute cytokine release — that causes a range of problems from malaise to hypotensive shock — induced by non-mutated anti-CD3 antibody The variety of potential therapeutic targets is enormous, but we do not know the rules that define targets of various quality, in terms of their efficacy as well as safety Therapy using a cytotoxic T-lymphocyte antigen 4 (CTLA4)–immunoglobulin fusion protein, which blocks interactions with CD28, is effective in randomized, double-blind clinical trials in patients with psoriasis and rheumatoid arthritis , suggesting that even in late-stage disease, signals mediated by costimulatory molecules expressed by APCs are required There is a growing consensus that antigen-presenting cells (APCs) are important rate-limiting cells for inducing immune responses : a leading hypothesis is that inducible major histocompatibility complex (MHC) class II molecule expression is induced inappropriately on APCs at the site of autoimmune disease ( Fig. 1 ) Therefore, any toxicity that does occur with monoclonal antibodies is likely to be mechanism related Therefore, therapy that specifically targets most of the steps (which are non-rate-limiting) in the immune or pro-inflammatory process yields little benefit in ongoing (late, active) autoimmune disease in humans These adhesion molecules and their receptors have domains in the extracellular space, and so can be targeted with monoclonal antibodies These DNA constructs encode several myelin antigens, where immune stimulatory motifs (CpG motifs) in the DNA, which promote expression of costimulatory molecules (such as CD28), are replaced with immunosuppressive motifs (GpG motifs), leading to sub-optimal costimulation of antigen-specific T cells ( Fig. 2 ; ref. 48 ) These molecules can therefore be considered as true tipping points in the pathophysiology of autoimmune disease These particular key molecules and the processes they control can be referred to as ‘tipping points’   They are important in all biological processes , including T-cell growth (IL (interleukin)-2, IL-4, IL-7, IL-15 and IL-21), inflammation (TNF, IL-1, IL-6 and IFN (interferon)-γ) as well as the inhibition of inflammation (IL-10, transforming growth factor-β (TGF-β) and IL-4) They are ‘chimaeric’ antibodies, consisting of a mouse combining site (Fv) while the rest (about 70%) is human  This approach also proved successful in patients with multiple sclerosis: a phase III trial of a humanized α 4 β 1 -specific monoclonal antibody natalizumab (Tysabri) reduced clinical relapses by 66% over the next year, leading to Food and Drug Administration (FDA) approval of the drug  This benefit occurs in most patients whose condition has not improved following other treatments, such as methotrexate This concept is valuable in autoimmune diseases because many cellular and molecular processes contribute to tipping the balance towards the disease state, and therefore are potential therapeutic targets This culminated in the approval from 1998/1999 of a set of therapeutic biologicals: anti-TNF monoclonal antibodies (infliximab and adalumimab ) and the TNF-receptor (TNFR) fusion protein (etanercept ; Enbrel) This discordance may be explained, in part, by the inability of the TNFR fusion constructs to penetrate the inflamed brain owing to the endothelial blood–brain barrier This has been reported with TNF variants that bind to non-mutated endogenous TNF, with the resulting trimeric complex unable to activate TNFRs This implies that whereas a transplant is a classic acute challenge to an otherwise normal immune system, chronic autoimmune diseases are somehow different This is because defects in such regulatory subsets (in particular, the CD4 + CD25 + regulatory T-cell subset) may be important in enabling autoimmune diseases to become established (see review by Kronenberg and Rudensky in this issue, page 598 ) This is desirable because T H 1-type responses to myelin proteins are pathogenic This is probably due to the phenomenon of ‘high zone tolerance’ described in the 1960s and 1970s that occurs with deaggregated human immunoglobulins (whereby intravenous deaggregated gammaglobulin was tolerogenic if given in high doses) and the concomitant use of methotrexate, which has immunosuppressive as well as autoinflammatory effects  This protease activity is required for lymphocyte homing, so when the administration of IFN-β is combined with adhesion cell blockade, lymphocyte entry into an organ may be drastically reduced  This suggests that the links between inflammation and joint damage are not fully understood Three other trials of antigen-specific therapy are underway or recently completed for type 1 diabetes mellitus (T1DM), including phase II trials with glutamic acid decarboxylase, and trials with APLs of an insulin peptide or of a heat-shock protein 60 (HSP60) peptide Thus, IL-1, TNF, IL-6 and granulocyte–macrophage colony-stimulating factor (GM-CSF) have more than 80% overlap in function, when tested in vitro  Thus, in the chronic stage of the disease, the adaptive immune response targets several different molecules at the anatomical site of the disease Thus, the efficacy in animal models of the endogenous anti-inflammatory cytokines IL-10 (ref. 56 ), IL-4, IL-11 and TGF-β has not translated into their use as human therapeutics, owing to their toxicity TNF blockade has demonstrated that biologicals can be used in the long term, and extensively: about a million patients have been treated with anti-TNF biologicals so far, and some for over seven years TNF is the best-documented example TNF is the bodys fire alarm  Understanding the risk versus benefit relation requires more time than is usually spent in pre-clinical models, and often takes thousands of patient-years of experience to be established Unfortunately, despite promising results in experimental studies, the administration of an antibody specific for the T-cell-expressed costimulatory molecule CD40 ligand was toxic in humans, causing a number of deaths from thrombosis We contrast the effectiveness of therapies aimed at inhibiting the non-antigen-specific pathways, such as cytokine and cell-trafficking pathways (components of innate immunity), with the comparative lack of success of therapies that interfere with the more complex and flexible features of antigen-specific adaptive immunity We remain ignorant of what drives the chronicity of these conditions, which can last for decades, and of how we can normalize the immune and pro-inflammatory responses once they commence When administered to mice after the first signs of EAE, these DNA plasmids reduced the subsequent relapse rate over the next three months by more than 50%, and also reduced the spreading of autoantibody responses
 Cooling of mechanical resonators is currently a popular topic in many fields of physics including ultra-high precision measurements , detection of gravitational waves and the study of the transition between classical and quantum behaviour of a mechanical system  Here we report the observation of self-cooling of a micromirror by radiation pressure inside a high-finesse optical cavity In addition to purely photothermal effects we identify radiation pressure as a relevant mechanism responsible for the cooling In contrast with earlier experiments, our technique does not need any active feedback  In essence, changes in intensity in a detuned cavity, as caused by the thermal vibration of the mirror, provide the mechanism for entropy flow from the mirror’s oscillatory motion to the low-entropy cavity field  The crucial coupling between radiation and mechanical motion was made possible by producing free-standing micromirrors of low mass ( m  ≈ 400 ng), high reflectance (more than 99.6%) and high mechanical quality ( Q  ≈ 10,000) We expect that improvements of our method will permit cooling ratios beyond 1,000 and will thus possibly enable cooling all the way down to the quantum mechanical ground state of the micromirror. We observe cooling of the mechanical oscillator by a factor of more than 30; that is, from room temperature to below 10 K A full quantum mechanical framework, which generalizes the classical picture for self-cooling proposed so far in the literature , is presented elsewhere  A more powerful scheme is provided by the use of radiation pressure as a feedback force  A phase-sensitive measurement of the output field quadrature δ Y out is therefore capable of ‘monitoring’ the full mirror dynamics A simple classical description of the dynamics of the mirror shows that both the resonance frequency ω  M and the natural damping rate γ of the mirror motion are modified by radiation pressure to ω  eff and γ eff , respectively  Above the cutoff frequency of our control loop, the fluctuations in the error signal are therefore directly related to the thermal noise of the cantilever (the input mirror is assumed to be fixed) Although cavity-induced radiation-pressure effects have already been used to modify elastic properties of mirrors and to enforce mechanical instabilities , none of the previous experiments was able to combine these strict requirements An interesting analogy by which to understand this cooling mechanism can be found in thermodynamics An intuitive way to view it is that the error signal is proportional to the variation of the cavity length As a consequence, the dynamics of an oscillating mirror inside a detuned cavity is modified by a mechanical rigidity that depends on the detuning As a consequence, the fluctuations δ Y out of the field leaking out of the cavity are directly related to the fluctuations of the mirror’s position quadrature as δY out ( t ) =  A ( Δ , κ , E )δ q ( t ) (refs 22 , 23 ), where we have neglected any noise in the system As expected, the increase in damping is accompanied by a cooling of the mechanical mode At large detuning values the stability of the locking limits the precision of the measurements At large detuning, the cooling effect is slightly enhanced compared with our simple model, which might be due to the reduced contribution of thermal background of other oscillator modes Because our experiment was performed at room temperature, this corresponds to a cooling of the mode from 300 K to less than 10 K ( Fig. 2 ) Equation (1) depends on β ( Δ ), the spatial gradient of the radiation force evaluated at a (spatial) detuning Δ x  =  LΔ/ω  l  Even though this scheme has intrinsically limited cooling capability because it ultimately relies on heating by absorption, it might permit a quantitatively significant reduction of the oscillator’s thermal motion Figure 2 shows the noise spectrum of the oscillator for two different detunings at 2 mW input laser power Figure 3 shows the change in width of the mechanical mode For a high-finesse cavity, the radiation-pressure-induced back action can act on the mirror motion in such a way as to induce low-noise damping For certain cavity detuning—that is, if the cavity angular frequency ω  c is off resonance with the frequency ω  l of the pump laser, the radiation pressure is highly sensitive to small displacements of the cavity mirror For example, with a cavity finesse F  = 6,000 and an input optical power of 1 mW we expect a pure radiation-pressure cooling ratio of 1,500 for a smaller mirror oscillating at 1 MHz with an effective mass of 5 ng and Q  = 10 5  For negative detuning (not shown) we observed a narrowing of the peak, associated with an amplification of the mirror motion (that is, ‘negative’ damping), which rapidly leads to a self-oscillation region For our mirror, an independent assessment both by means of spatial tomography of the vibrational mode and by means of a calibrated reference results in a value of 22 ± 4 ng at the probing point (see Supplementary Information ) For positive detunings, the peak is broadened from a natural width of 32 Hz to well above 800 Hz, corresponding to an extra damping of the mode For the parameter regime of our experiment the signal-to-noise ratio of the contribution given by the mirror’s spectrum is as large as 10 7  For this purpose it is sufficient to measure the statistical properties of the optical field that leaks out of the cavity Here Δ  is the effective detuning between cavity and laser frequency, including the effect of radiation pressure  However, less well known is the fact that radiation pressure can also be used for the opposite, namely to counteract the dynamics of a cavity mirror by means of dynamical back action  If a system (the mirror), initially at thermal equilibrium with a bath at ambient temperature (its environment), is strongly coupled to another bath with a very low temperature (the low-noise laser), its temperature will decrease so as to bring it to equilibrium with both baths If the timescale set by the cavity decay rate is the shortest in the dynamics of the system—that is, κ  ≫  ω  M —the cavity field follows the mirror motion adiabatically Improvements in the reflectivity of the Bragg mirror will further reduce and eventually eliminate photothermal contributions to the cooling because it will permit a higher finesse to be achieved and the optical absorption to be limited In a recent experiment a passive cooling mechanism for a micromechanical oscillator based on bolometric back action was presented  In a similar manner to the bolometric forces reported in ref. 7 , differential heating of the outer layers of the dielectric Bragg mirror can result in time-delayed changes in the cavity length, eventually introducing a retarded force that can contribute to the self-cooling mechanism In a thin-layered medium the delayed force induced by photothermal effects can have typical time constants on the order of several tens of nanoseconds (see Supplementary Information ), which is fast enough to compete with the timescale of radiation pressure effects of 1/(2 κ ) (about 13 ns in our experiment) In a way, the output cavity field represents a ‘blank sheet’ on which the dynamics of the mirror can be written In Fig. 4 the same data set is used to obtain the corresponding cooling ratio from the relative change in area of the power spectrum, because the total peak area is a measure of temperature In other words, radiation pressure accounts for at least 30% of the observed cooling but may be as strong as 50%; that is, there is cooling by a factor between 8 and 12 In other words, the quadrature power spectrum of the mirror motion S q and of the output cavity field S Y out are directly related by means of a transfer function T ( Δ ) In our case, and in contrast with previous experiments, it assists the cooling effect of radiation pressure present for positive detuning In particular, within the classical framework, the modified damping rate follows with the cavity decay rate κ  = π c /2 FL , the cavity finesse F , the cavity length L and the speed of light in vacuo , c  In the long term it may also provide new methods of integrated quantum (mechanical) information processing. In this case, optical absorption does not impose a fundamental limit In this regime, the system can enter instability It has been shown that the PDH error signal is proportional to the phase quadrature of the output field Y out and hence to the mirror motion (see above) It is particularly interesting to measure the power spectrum because , where S q is the spectrum of the mirror motion It is possible to briefly sketch the main idea of our self-cooling read-out process by exploiting a simple (but for our purposes sufficient) semiclassical picture It is straightforward to show that β ( Δ ) is negative for Δ   0, corresponding to γ eff   γ Not only is this (more general) approach in agreement with the classical picture taken into account by equation (1) but it also paves the way towards the rigorous study of the limitations imposed on self-cooling by the influences of quantum noise  Note that the full transfer function has to take into account the sensitivity of the specific detection scheme used Optimum damping is achieved when 1/(2 κ ) is of the order of ω  M , which for ω  M in the megahertz range requires a high-finesse cavity Radiation-pressure forces in an optical cavity arise from the momentum transfer of photons reflected from the mirror surface Radiation-pressure forces inside optical cavities are known to pose an ultimate limit on the sensitivity of interferometric measurements  Residual heating of the cantilever due to absorption was not observed (see Supplementary Information ) Starting from 5 K, one should achieve cooling to 3 mK—below the base temperature of a dilution fridge The area of the power spectrum, , is proportional to the mean energy 〈 U 〉 of the vibrational mode and hence, by the equipartition law, to the effective temperature of the mirror, because  The best experimental cooling ratio in our detuning range is more than 30 The contribution β , induced by radiation pressure, can be positive or negative depending on the sign of Δ  The cooling of mechanical oscillators is a key requirement for many open problems of modern physics ranging from the performance of shot-noise-limited position measurements to the study of gravitational waves and dynamical multistability in micro-optical systems  The current technical limitation for observing a lower temperature is the stability of the detuned locking and the base temperature from which the self-cooling starts The detuning was achieved by adding an offset to the error signal The difficulty in using radiation pressure for this cooling purpose is that it calls for stable control of the detuning of a high-finesse cavity, strong optomechanical coupling and a low mass of at least one cavity mirror, thus requiring nanomechanical or micromechanical systems of high optical and mechanical quality (characterized by the cavity finesse F and the mechanical quality factor Q ) The direction of the force depends on the specific material properties of the expanding layers The dynamics of the output field quadrature is thus entirely determined by the mirror motion by means of the function A (Δ, κ , E ) The effective mass can be much smaller than the total mass of the cantilever  The error-signal input to the control loop is obtained with the Pound–Drever–Hall (PDH) technique  The experimental data are consistent with radiation-pressure cooling assisted by photothermal effects The focus of this work is the investigation of the opposite regime ( β ( Δ )  0) in which γ eff    γ  The input mirror of the cavity is attached to a piezoelectric transducer, which is fed by a control loop allowing us to lock the precise length of the cavity either at resonance or detuned (off resonance) with respect to the laser frequency The possibility of lowering the temperature of an oscillator to its quantum mechanical ground state paves the way to the implementation of quantum state engineering involving macroscopic systems , a closer study of the boundary between classical and quantum physics and, ultimately, the observation of non-classical correlations between macroscopic objects  The power spectrum follows a lorentzian distribution centred on with a full-width at half-maximum (FWHM) w FWHM  ≈ 2 γ eff (for ω  0 2  ≫  γ eff 2 ), thus proportional to the introduced damping The previous self-cooling experiments based on bolometric forces were operated in the regime of negative detuning, where radiation pressure counteracts the cooling The relative change in area underneath the power spectrum is therefore a direct measure of the change in effective temperature The results are summarized in Figs 2 – 4  The system under investigation is a doubly clamped cantilever used as the end mirror of a linear optical cavity driven by an ultrastable Nd:YAG laser (see Fig. 1 ) The total energy of a cavity consisting of a fixed mirror and a movable mirror driven by an input laser field of power P is given by where X and Y are the quadratures of the cavity field, p and q are the momentum and position quadratures of the oscillating mirror, and is the coupling rate between the cavity and the input laser field The use of such micromirrors in a detuned optical cavity allows us to observe for the first time self-cooling in a regime in which, although photothermal effects are still present, radiation pressure participates significantly in the self-cooling process The width of the peak increases and the area of the peak decreases, which is indicative of both overdamping and cooling of the mechanical mode This behaviour is in full agreement with the theoretical model presented above This correspondence is at the basis of our read-out scheme This detection strategy allows us to infer the effective temperature of the mirror’s brownian motion through the study of its displacement power spectrum; that is, its frequency-dependent mean-square displacement This is a consequence of the fact that the energy stored in a cavity field varies strongly with detuning This is done by normalizing the measured mirror amplitudes by the gradient of the PDH signal This is the general concept of dynamical back action  This low-noise damping results in a reduction of the mirror temperature, and hence self-cooling is achieved This results in a theoretically expected cooling that is less strong than the experimentally observed one To do that, we have independently evaluated the effective mass participating in the dynamics of the system, which leaves no free parameter for the evaluation of radiation-pressure forces and hence allows a full quantitative treatment To get a clear, immediate figure of the ‘strength’ of the radiation pressure effect required to replicate the experimental data we assume a fixed effective mass and permit variation of the input power To observe the self-cooling effect a read-out scheme of the mirror motion is required To obtain the effective temperature of the mode one has to calculate the area underneath the resonance peak and account for the sensitivity of the error signal We are confident that the quantum ground state may be reachable with state-of-the-art optics and microfabrication techniques  We attribute the additional cooling in our setup to the presence of photothermal effects We explicitly compare the experimental results for positive detuning with the theoretical predictions obtained if the effect is due only to radiation pressure We find that, for effective masses of 18 and 26 ng, a power respectively 2.2-fold and 3.3-fold the nominal value used in the experiment is required to match the theoretical predictions with both the observed damping and cooling ( Figs 3 and 4 ) We have observed self-cooling of a low-mass micromirror sustained by radiation pressure We have overcome this limitation by developing a method to produce free-standing micromirrors of low mass (about 400 ng), high reflectance (more than 99.6%) and high mechanical quality ( Q  ≈ 10 4 ) We investigate the specific variation of both mechanical damping and of self-cooling with detuning for different input laser powers of 1 and 2 mW, respectively ( Figs 3 and 4 ) We measured the PDH power spectrum for different input powers and cavity detunings With this method, the mechanical damping can be measured directly by determining the FWHM of the resonance peak of the observed mechanical mode
 A good test of the idea might have been possible if the Sumatra region had been intensively monitored in the decade before the massive earthquake that occurred on 26 December 2004 — but hindsight is a wonderful commodity A subduction zone is where one tectonic plate dives beneath another, and in Alaska and Cascadia tectonic shifts have given rise to earthquakes of moment magnitude 9 or more (for comparison, the Sumatra–Andaman earthquake that led to the tsunami of 26 December 2004 was moment magnitude 9.2) And in other cases again, the evidence was equivocal (Netarts Bay, Oregon) Another source of data is the 1700 Cascadia earthquake, which was probably in the range 8.7–9.2 and produced similar effects, as recorded in coastal marsh stratigraphy As work continued, they found several additional cases of apparent pre-seismic subsidence of the order of 10–30 cm ± 10–20 cm Based on some of these analyses, Shennan et al . proposed a four-part deformation cycle, adding this short period of decimetre-scale subsidence before the main event ( Fig. 1 ) Beginning in the mid-1990s, Ian Shennan and colleagues , among others, began to look at microfossils in these sedimentary records in Alaska and Cascadia (different microfossils reveal different habitat, be it sediment soaked in salt, brackish or fresh water) But few areas in the world yet have precise and dense enough coverage with geodetic arrays to detect slow earthquakes; measuring vertical motions is even more of a challenge But if this subsidence does indeed occur, the implication is that warning signs are detectable for some time before one of these huge earthquakes occurs But theory has not predicted and observation has not documented subsidence at coastal locations from these slow earthquakes Evidence of subsidence during great earthquakes has been well-documented, but the record between these events is more difficult to tease out First, between earthquakes the shallow part of the subduction zone is locked, strain accumulates on the fault and the coastline rises (with subsidence offshore) For these and other subduction-zone coastlines, a three-part seismic–interseismic de-formation cycle has been considered standard ( Fig. 1 ) In Alaska, at least five previous earthquakes have been studied, going back about 3,000 years; for Cascadia, eight or more events in the past 5,000 years have been identified In contrast, for the precursor events, the authors argue that their position directly below co-seismic events, at several localities, and over some millennia of record, rules out other transient causes such as increased storminess and subsidence beneath the load of a glacier In doing so, Shennan and his co-workers also found subtle evidence of other effects In other cases, however, there was a small amount of pre-seismic subsidence (Girdwood Flats, Alaska) In some cases, as seen at Johns River in Washington state, the expected uplift continued until the co-seismic subsidence In the mid-1980s and the 1990s, initial studies of the subduction-zone deformation cycle in coastal sedimentary records focused on dramatic changes in environment associated with co-seismic subsidence — for example, the sharp elevation drop evident in a change from marsh peat laid down above high tide to mud deposits from the intertidal zone Indeed, if the authors hypothesis is correct, it would predict an imminent great earthquake in Cascadia Local changes in sea level will also occur, on a timescale of years or decades, caused for example by storm cycles, by glacial ‘loading’, by global fluctuations in sea level, and by variability in local patterns of crustal stress Moreover, in Cascadia these ‘earthquakes’ have occurred since the Global Positioning System (GPS) network was installed in 1992, and they appear to happen regularly  Nonetheless, those systems that are in place are helping us to understand the fundamental mechanics of subduction zones Only for the 1964 case in Alaska has the duration of this signal been estimated — about a decade, determined from concentrations of caesium-137, an isotope produced by bomb testing  Over the past year, two groups of micropalaeontologists have presented evidence that coastal land subsides not only during a great earthquake but also in the decade or so before such events Second, during the earthquake (the co-seismic phase), the uplifted region quickly subsides, while the offshore region undergoes rapid uplift; this rapid motion generates a tsunami Shennan and Hamilton attribute these ‘non-precursor’ episodes to changing sea levels caused by glacier growth and retreat Shennans team identified key species of microfossils for diagnosing the magnitude of subsidence, and developed methods for quantifying the amount of elevation change using a mathematical approach involving transfer functions Some parts of coastal areas along subduction zones have been instrumented with networks of continuous GPS sites in the past 10–15 years Such slip recurs about every 14 months at Cascadia  The aim was to quantify the amount of co-seismic subsidence (typically 1–2 m) that occurs, and also to distinguish earthquake-generated change from other causes as seen, for instance, along aseismic coastlines The Alaskan microfossil records also imply the occurrence of several episodes of slight uplift and subsidence that lack obvious association with earthquakes The authors cite several other kinds of observation that both support and conflict with their hypothesis of precursor subsidence The most complete set of data comes from the shores of Cook Inlet, near Anchorage, Alaska The new work by Shennan and Hamilton , as well as analyses by Hawkes et al . that include some new microfossil types, support the four-part cycle for many but not all cases of great earthquakes in Alaska and Cascadia The observations and interpretations of pre-earthquake subsidence are complex and subtle The records are subtle — can centimetres to decimetres of vertical change be reliably detected? Can mixing of the microfossil record be ruled out, as the authors claim? Have all alternative explanations been eliminated, for example the possibility that rapid sedimentation following co-seismic subsidence better preserves the last few storm deposits before the earthquake? Are there enough analyses to rule out coincidence; that is, do all areas undergo both transient uplift and subsidence on this scale, during the interseismic period, and some are just caught at the time when a significant marker (a large earthquake) occurs? But if pre-seismic subsidence does occur, what might be the mechanisms? A hypothesis suggested by both groups is the occurrence of ‘slow earthquakes’ along a deeper part of the subduction zone than the part that ruptures during great earthquakes Their study areas are the Alaska and Cascadia subduction zones in northwestern North America There and elsewhere along a fault rupture 800 km in length, a moment magnitude-9.2 earthquake in 1964 was accompanied by 1–2 m of co-seismic subsidence Third, during the interseismic period the earthquake deformation is recovered at first rapidly (the post-seismic phase), and then more slowly (the interseismic phase) This cycle, typically repeating over some hundreds of years, may be superimposed on longer-term patterns of net uplift or subsidence Whether this behaviour predictably includes precursor coastal subsidence remains an open question.
 AI-2 signalling, and the interference with it, could have important ramifications for eukaryotes in the maintenance of normal microflora and in protection from pathogenic bacteria. Bacteria communicate by means of chemical signal molecules called autoinducers Here we show that some species of bacteria can manipulate AI-2 signalling and interfere with other species ability to assess and respond correctly to changes in cell population density Most quorum-sensing autoinducers promote intraspecies communication, but one autoinducer, called AI-2, is produced and detected by a wide variety of bacteria and is proposed to allow interspecies communication  Quorum-sensing-controlled processes are often crucial for successful bacterial–host relationships—both symbiotic and pathogenic This process, called quorum sensing, allows bacteria to count the members in the community and to alter gene expression synchronously across the population Addition of chloramphenicol was required in E. coli – V. cholerae co-cultures to maintain the plasmid harbouring the hapA–luxCDABE fusion in V. cholerae  Aliquots were plated to determine c.f.u., and luciferase activity from the hapA–luxCDABE fusion was measured in a liquid scintillation counter All cultures were incubated at 30 °C with aeration. β-Galactosidase assays Overnight cultures of E. coli and V. harveyi strains were diluted 1:1,000 into LM and grown for 8 h, after which time lsr–lacZ expression was measured Analysis of hapA–luxCDABE expression Overnight cultures of E. coli and V. cholerae were diluted 1:1,000 into LB supplemented with chloramphenicol and grown for 16 h At the reported times, aliquots were plated to determine the number of colony-forming units (c.f.u.), and bioluminescence was measured using a liquid scintillation counter ( Wallac model 1409 , PerkinElmer ) Bioluminescence assays Overnight cultures of V. harveyi strains were diluted 1:5,000 into LM Cells from 1 ml of culture were resuspended in 1 ml of Z buffer for β-galactosidase assays  Co-cultures were grown in Luria-Marine (LM) medium (ref. 5 ) in experiments with V. harveyi , or in Luria-Bertani (LB) medium supplemented with chloramphenicol (10 mg l -1 ) in experiments with V. cholerae  Cultures were grown for 18 h because expression of TTS genes is maximal in stationary phase Details of their construction will be reported elsewhere (B E. coli c.f.u. were counted following incubation at 37 °C on LB E. coli strains used for co-culture with V. cholerae are identical to those described for Fig. 3 except for KX1583 (wild type), which contains a Cm r marker downstream of the luxS gene E. coli strains used in TTS experiments are KX1102 (wild type), KX1479 ( lsrK - ), KX1477 ( lsrR - ) and KX1526 ( lsrK - , luxS - ), and each was constructed by the method reported in ref. 8  E. coli strains were derivatives of MG1655 (ref. 16 ) Hammer and B.L.B., manuscript in preparation) In co-incubation experiments, 1:100 dilutions of overnight cultures of E. coli were added In the experiments shown in Fig. 2b , bioluminescence was measured after 12 h of incubation In the experiments shown in Fig. 3c and d, the V. harveyi strains were added to E. coli cultures that had been pre-grown for 4 h in LM K Measurements of cell number in co-cultures In all co-culture experiments, the mixtures of cells were plated onto two different types of media Methods Bacterial strains and growth conditions Bioluminescence was measured in V. harveyi strain BB120 (wild type; ref. 1 ), MM30 ( luxS - ; ref. 14 ), BB170 ( luxN - ; ref. 15 ) and BB960 ( luxQ - ; ref. 5 ) The E. coli strains used in Figs 2 and 3 , and Supplementary Figs 1S and 2S , contain a lacZYA deletion and an lsr–lacZ fusion integrated at the att site The final two strains were obtained by the introduction of luxS ::Tn 5 (ref. 14 ) or luxQ ::Tn 5 (ref. 5 ) onto the chromosome of JMH385, respectively The hap–luxCDABE transcriptional fusion was constructed as reported , except that a PCR-amplified fragment containing the promoter region of V. cholerae hapA was cloned into unique Spe I to Bam HI sites The media conditions were chosen so that they either permitted growth of only one of the two species in the mixture, or the colonies of each species could be distinguished visually by morphology The V. cholerae strains used are: BH1220 (wild type), BH1312 ( luxS - ) and BH1253 ( luxQ - ) The values shown represent the average of triplicate experiments These strains are KX1123 (wild type), KX1218 ( luxS - ), KX1186 ( lsrK - ), KX1322 ( lsrR - ) and KX1372 ( lsrK - , luxS - ) This strategy allowed us to determine the cell numbers of both species in each co-culture experiment To measure vopN expression, V. harveyi strains JMH385 (wild type), KX1530 ( luxS - ) and JMH669 ( luxQ - ), containing a chromosomal vopN ::mini-Mu lacZ insertion, were used  V. cholerae c.f.u. were counted after incubation at 37 °C on LB agar containing 50 mg l -1 polymyxin B V. cholerae strains are derivatives of El Tor C6706str2, a streptomycin-resistant isolate of C6706 (ref. 17 ), and all have a hap–luxCDABE transcriptional fusion cloned into a plasmid containing a chloramphenicol resistance (Cm r ) marker V. harveyi c.f.u. were assessed following overnight incubation at 30 °C on LM agar supplemented with ampicillin (100 mg l -1 ) V. harveyi does not grow at 37 °C and V. cholerae colonies are translucent under this condition, whereas E. coli colonies are opaque. Values shown represent the average of triplicate experiments When vopN–lacZ expression was measured, V. harveyi strains were diluted 1:5,000 into LM and 1:100 dilutions of overnight cultures of E. coli were added A more marked effect on V. harveyi quorum sensing occurs when exponential-phase V. harveyi encounters the E. coli strains in stationary phase ( Fig. 3c ) A related quorum-sensing network exists in V. cholerae and controls the expression of virulence genes including hapA , encoding the haemagglutinin (H/A) protease  AI-2 consumption has a more modest effect on vopN and hapA regulation than on the regulation of bioluminescence AI-2 interference probably has more subtle effects on H/A protease levels and TTS than on bioluminescence because additional regulators exert control over H/A protease and TTS output, and regulation by these factors remains unchanged in our experiments An almost immediate and continuous decrease in V. harveyi bioluminescence occurs (filled squares in Fig. 3d ), which is even more obvious in the mixture containing the LsrR - E. coli strain (plus signs in Fig. 3d ) Any species of bacteria that relies on AI-2-mediated communication and inhabits niches containing another bacterial species that produces and/or consumes AI-2 could be similarly affected As expected, in the presence of the LsrK - ,LuxS - E. coli strain, V. harveyi shows density-dependent bioluminescence (crosses in Fig. 3d ) As in Fig. 2a , AI-2 production and consumption does not affect vopN expression if V. harveyi lacks LuxQ (white bars in Fig. 4a ) At later time points, corresponding to post- lsr -induction, all E. coli strains that have LsrK, and are therefore capable of transporting AI-2, consume the AI-2 (filled squares, plus signs and open circles in Fig. 3b ) Because E. coli and V. harveyi respond to AI-2 signals with different structures , cross-communication implies that the signal released by one species must convert into that used by the other species Both species were diluted to a low cell density and combined under conditions allowing each to grow exponentially ( Fig. 3a ) By contrast, LsrK - strains never consume significant amounts of AI-2 due to their inability to de-repress lsr transcription ( Fig. 1b , Supplementary Figs 1S and 2S ; refs 8 , 11 ) Co-culture of wild-type V. harveyi with LsrR - E. coli (a constitutive AI-2 importer) causes a greater reduction in V. harveyi bioluminescence (third black bar in Fig. 2b ) Complex pro- and anti-AI-2-mediated interactions could be taking place in natural niches Different bacteria recognize distinct DPD derivatives, and this family of molecules is generically referred to as AI-2 (ref. 4 ) Dilution of V. harveyi in pure culture causes autoinducer levels to fall below those required for detection, and bioluminescence expression terminates at low cell densities Diminution of light is due exclusively to Lsr-mediated transport of AI-2 into E. coli because no reduction in light production occurs when V. harveyi is co-cultured with the LsrK - E. coli mutant that does not internalize AI-2 (fourth black bar in Fig. 2b ) During co-incubation of these bacteria, the V. harveyi -produced AI-2 induces LuxS - E. coli cells to express the Lsr transporter During subsequent growth, autoinducers are again released and, on achieving a threshold concentration, they are detected and the cells respond by inducing a rapid increase in light production E. coli cells then consume AI-2, causing a reduction in V. harveyi light production E. coli has a stronger effect on LuxN - V. harveyi than on wild-type V. harveyi because wild-type V. harveyi retains its response to AI-1, the levels of which are not altered by E. coli consumption of AI-2 Finally, these effects of AI-2 on V. harveyi require the LuxQ sensor ( Fig. 1a ) because manipulating extracellular AI-2 levels by co-culture with E. coli does not alter light production by the LuxQ - V. harveyi (white bars in Fig. 2b ) Following AI-2 release, low-level internalization occurs and the intracellular AI-2 is then phosphorylated by LsrK (refs 8 , 11 ) For example, E. coli and S. typhimurium release AI-2 in exponential phase, and import AI-2 at the transition into stationary phase Full de-repression occurs only in combinations where neither V. harveyi nor E. coli produces AI-2 (hatched bars in Fig. 4a ), demonstrating that in the previous mixtures (depicted by the black bars in Fig. 4a ) E. coli has not internalized all of the AI-2 Growth of LuxN - V. harveyi with wild-type and LsrR - E. coli reduces light output to 2% and 1%, respectively (second and third grey bars in Fig. 2b ) Growth with E. coli strains that consume AI-2 results in de-repression of vopN expression (black bars in Fig. 4a ; compare wild-type cells to LsrR - cells) However, when enteric bacteria remove AI-2, a neighbouring species could underestimate cell number and fail to initiate or incorrectly terminate quorum sensing In addition to AI-2, V. harveyi produces an autoinducer called AI-1 and responds to it through the LuxN sensor ( Fig. 1a ; ref. 5 ) In contrast, co-culture with stationary-phase LsrK - E. coli results in a steady maintenance of maximal light production in V. harveyi (filled triangles in Fig. 3d ), owing to the presence of AI-2 produced by the transport-deficient E. coli mutant In contrast, V. cholerae must coexist with E. coli during pathogenic associations with humans In mixed-species consortia, production and consumption of AI-2 by enteric bacteria should have reciprocal effects on gene regulation in other bacterial species that communicate using AI-2 In model V. harveyi – E. coli mixtures, induction of lsr genes in E. coli results in the assembly of the AI-2 transporter and subsequent consumption of AI-2 In the absence of AI-2, LsrR represses the lsr operon In the presence of all AI-2-producing E. coli strains tested, the initial decrease in bioluminescence is greatly reduced because V. harveyi rapidly initiates quorum sensing in response to the AI-2 supplied by E. coli (filled squares, plus signs and filled triangles in Fig. 3b ) In this case, at the time of mixing wild-type E. coli is induced for lsr expression, and the cells are actively internalizing AI-2 In V. harveyi , two autoinducers, AI-1 and AI-2, are detected by LuxN and LuxPQ, respectively, and control the expression of genes including those for bioluminescence and type III secretion (TTS) of virulence factors ( Fig. 1a ; refs 5 , 9 ) Induction of gene expression occurs in mixtures containing E. coli strains incapable of AI-2 transport (black bars in Fig. 4b ; compare LsrK - cells to LsrK - ,LuxS - cells) and induction of gene expression does not occur in mixtures containing E. coli strains that can transport AI-2 (black bars in Fig. 4b ; compare wild-type cells to LsrR - cells) Induction of lsr expression also occurs when LuxS - E. coli is mixed with wild-type V. harveyi (third bar in Fig. 2a ), and depends on the AI-2 supplied by V. harveyi because no lsr activation occurs when LuxS - E. coli is combined with LuxS - V. harveyi (fourth bar in Fig. 2a ) It is also possible that eukaryotes have capitalized on this by evolving specific associations with bacteria that use or manipulate AI-2 signalling Lsr-mediated interference with AI-2 signalling also occurs in co-cultures of E. coli and V. cholerae , two bacteria that certainly co-colonize the human intestine during V. cholerae infection e the lsr operon is de-repressed LuxS enzymes synthesize 4,5-dihydroxy-2,3-pentanedione (DPD), which undergoes spontaneous rearrangements to form DPD derivatives that interconvert and exist in equilibrium Many environmental factors are known to control H/A protease production and TTS (refs 10 , 12 ) Mixing V. harveyi with LuxS - E. coli cells initially has no effect on V. harveyi quorum sensing because the LuxS - E. coli strain has not been exposed to AI-2 before the addition of V. harveyi , so the Lsr transporter is repressed (open circles in Fig. 3d ) Mixing V. harveyi with the E. coli LsrR - strain results in the most pronounced reduction in light production, presumably owing to the constitutive removal of AI-2 (plus signs in Fig. 3b ) Our premise is that in mixed cultures, early production and later consumption of AI-2 by E. coli should inversely affect the quorum-sensing response of V. harveyi  Our results demonstrate that these marked chemical interconversions are occurring on a timescale that promotes major effects on gene expression Our results show that AI-2 can mediate two-way communication between bacterial species, because when E. coli and V. harveyi are grown in co-culture, AI-2 production by either species can regulate light production in V. harveyi and trigger lsr induction in E. coli  Phosphorylated AI-2 antagonizes LsrR, which leads to de-repression of lsr expression, assembly of the Lsr transporter and rapid AI-2 internalization Presumably, these transformations occur in the medium between the sender and receiver cells Production of AI-2 by an E. coli strain incapable of importing AI-2 does not affect vopN expression, showing that AI-2 supplied by V. harveyi is sufficient for maximal repression of vopN (black bars in Fig. 4a ; compare LsrK - cells to LsrK - ,LuxS - cells) Some bacteria both produce and consume AI-2 The bacterial signal molecule autoinducer-2 (AI-2) is a product of the LuxS enzyme, which is widely conserved throughout the bacterial kingdom The impact of the E. coli AI-2–Lsr system is not restricted to interfering with the activation of bioluminescence because repression of TTS is also affected The interconverting nature of these molecules presumably allows bacteria to respond to their own AI-2 and also to AI-2 produced by other bacterial species, suggesting that AI-2 represents a universal language allowing interspecies bacterial communication The V. harveyi quorum-sensing regulon contains many genes, and, presumably, all are susceptible to the effects of AI-2 production and consumption within consortia Therefore, at later time points, light output from the V. harveyi strain mixed with the E. coli LuxS - strain falls below that of V. harveyi co-incubated with the E. coli LsrK - ,LuxS - strain These findings imply that interference with AI-2 signalling influences the expression of entire quorum-sensing regulons These interactions could have important consequences for humans in the maintenance of normal gut microflora, in addition to the prevention of bacterial diseases. These results mimic those of TTS gene expression in V. harveyi ( Fig. 4a ) except that the pattern of regulation is reversed ( Fig. 4b ) This has the consequence of decreasing V. harveyi light output by almost 100-fold compared with V. harveyi grown in the presence of LsrK - strains that are unable to internalize AI-2 (filled triangles and crosses in Fig. 3b ) This has the consequence of inhibiting light production from V. harveyi , demonstrating that E. coli interferes with AI-2-mediated communication by causing V. harveyi to terminate prematurely its quorum-sensing behaviours This is of particular interest given that Vibrio species detect an AI-2 molecule containing boron, whereas there is no boron in the AI-2 signal recognized by enteric bacteria  This occurs because one target that is activated by AI-2 is the Lsr (for LuxS-regulated) transporter that imports AI-2 ( Fig. 1b ; refs 7 , 8 ) Thus, AI-2 production allows each species to include the other in the ‘census’ Thus, consuming AI-2 could allow enteric cells to interfere with AI-2-mediated communication in other bacteria Thus, E. coli consumes both its own AI-2 and the AI-2 of V. harveyi , causing a reduction in light output from V. harveyi  Thus, E. coli detects and responds to its own AI-2 and also to AI-2 produced by V. harveyi  To determine whether E. coli AI-2 consumption could interfere with V. cholerae signalling, we measured the expression of a gene that is activated during quorum sensing: hapA , encoding the H/A protease To examine this possibility, the expression of the TTS gene vopN was measured in co-cultures of different E. coli and V. harveyi strains To test this idea, we measured V. harveyi bioluminescence during growth in co-culture with different strains of E. coli  TTS genes are repressed by autoinducers at high cell density in V. harveyi ( Fig. 1a ; ref. 9 ) V. harveyi grown with the non-AI-2-producing, non-AI-2-importing E. coli LuxS - ,LsrK - strain shows the characteristic initial decline in bioluminescence followed by the rapid increase to the maximal, pre-dilution level of light production (crosses in Fig. 3b ) V. harveyi LuxN - strains produce less light than wild-type cells because LuxN - strains induce bioluminescence only in response to AI-2, whereas wild-type cells respond to both AI-1 and AI-2 (first grey bar in Fig. 2b ) We also examined the effects of E. coli AI-2 production and consumption on the behaviour of V. harveyi using bioluminescence as an indicator We do not expect these interactions to be restricted to enteric bacteria; in fact, the disappearance of AI-2 in stationary phase has been reported for diverse bacterial species, indicating that either Lsr transporters exist in these species, or that additional mechanisms exist to eliminate AI-2 (ref. 13 ) We previously characterized the quorum-sensing signal production and detection mechanisms in Vibrio harveyi , V. cholerae , Escherichia coli and Salmonella typhimurium (refs 5 , 6 , 7 –8 ) We recognize that V. harveyi , which routinely lives in mixed-species marine communities, is unlikely to coexist in the same environment as E. coli  When E. coli is grown in pure culture, AI-2 is required to activate lsr expression, as shown by comparing wild-type cells (first bar in Fig. 2a ) with LuxS - cells (second bar in Fig. 2a ) When enteric bacteria supply AI-2, a nearby species could use the information to count the enteric cells in the mixed-species community or prematurely activate the expression of quorum-sensing-regulated genes When incubated with wild-type E. coli , wild-type V. harveyi at high cell density produces only 18% of the bioluminescence (light) it produces in pure culture (first and second black bars in Fig. 2b ) When LuxN - V. harveyi is co-cultured with the LsrK - E. coli mutant, increased light production occurs in response to the additional AI-2 provided by the internalization-defective E. coli cells (fourth grey bar in Fig. 2b ) Whether quorum sensing is enhanced or inhibited will depend on the growth status of the different species when they encounter one another
 Although in the early years after 1905 the evidence for the quantum nature of light was not compelling, modern experiments — especially those using photon pairs — have beautifully confirmed its corpuscular character One hundred years ago Albert Einstein introduced the concept of the photon Research on the quantum properties of light (quantum optics) triggered the evolution of the whole field of quantum information processing, which now promises new technology, such as quantum cryptography and even quantum computers. A beautiful experiment to close this loophole using periodically switched time-dependent polarizer settings was performed by Aspect in 1982 (ref. 26 ) A new and probably more practical approach is the concept of a ‘one-way quantum computer’  that realizes universal quantum computation in a way that is totally different from that used by existing quantum computing schemes A particularly interesting development would be a detector that is able to discriminate clearly between 1, 2, 3 .. A semiclassical theory predicts that the two detectors in the output beams sometimes register in coincidence; according to this theory, the probability of registering a count is proportional to the square of the electric field A single-photon interference experiment was performed by Grangier et al . , who also used photon pairs emitted by atomic cascades After the discovery that some gates could be realized through teleportation , an important breakthrough was the suggestion by Knill et al . that even with linear optical elements, universal quantum computation could be realized After the initial experiments by Freedman and Clauser , and the much refined experiments by Aspect ( Fig. 5 ) confirming the quantum predictions, two loopholes remained open All these schemes use unentangled states as inputs on which the quantum gates operate Also deserving a mention is the wide field of experiments on squeezed states initialized by Slusher et al . and rapidly expanded by others Also, more efficient photon detectors are needed that operate over a broader wavelength range than those currently available Although for quantum communication the obvious choice is photons, for quantum computation, implementations in localized systems like atoms, ions or solid-state devices seem to be preferable Although no one reasonably assumes nature to be so capricious, a future experiment that closes both loopholes together would still be interesting Although such experiments now rule out Einsteins point of view, they gave rise to the new fields of quantum information processing An experiment supporting the information aspect of quantum interference has been performed by Mandels group at Rochester as part of a series of ground-breaking experiments on the quantum nature of light An extensive account of such activities has recently been collected by Grangier et al .  An important extension of teleportation in this sense will be quantum repeaters , a combination of entanglement swapping (that is, the teleportation of an entangled state) and local atomic memories of quantum information, which also exploit the atom–photon interface  An inequivalence arises for certain interference experiments because the photon has no rest mass Bell discovered in 1964 (ref. 23 ) that the predictions of quantum physics for these correlations are at variance with a local realistic world view Both SPDC and frequency doubling are nonlinear optical processes But Einstein should also be highly credited for his various criticisms of quantum physics that were part of the early debate with his contemporaries (including Bohr) But if the photons arrive simultaneously, they become indistinguishable and end up together randomly in either beam But in general, the concept of the photon as an individual particle is less important here But the conceptual problems are not fully settled But the results of such experiments can easily be understood semiclassically without having to assume the existence of photons; that is, without having to quantize the electromagnetic field as discussed above But what exactly do we mean by a ‘photon’ today and what experimental evidence do we have to support the concept of the photon? Single photons as particles and waves A basic meaning of the term ‘photon’ is that radiation only exists in quantized energy packets But, whenever we talk about a particle, or more specifically a photon, we should only mean that which a ‘click in the detector’ refers to Clausers experiment contains the first demonstration of sub-poissonian photon counting statistics, which can only be understood within a quantum theory of light Complementarity, information and quantum physics Complementarity, the mutually exclusive nature of the wave and particle concepts, has led to intense discussions Conclusion Evidently, Einsteins 1905 proposal of the photon concept has had tremendous impact Curiously, the probability amplitudes for these two possibilities destructively interfere with each other Entangled multi-particle states also have a significant role in other new protocols of quantum information Evidently, intermediate cases are also possible, of partial path information together with non-perfect interference fringes  Experiments of this kind clearly confirm that the quantum state is not just a statistical property of an ensemble of particles; indeed, it makes very precise predictions even for individual particles Fermions would behave differently because their quantum state is antisymmetric, as reflected by a negative sign in their initial state Figure 2 shows the results of a single-photon double-slit experiment where the photon source was parametric down-conversion Following Feynman , the fact that the predictions of quantum mechanics hold for individual particles and not just for ensembles is best illustrated by the finding that each individual photon ‘knows’ it should never end up in the minimum of an interference fringe Following these suggestions, various quantum compu-tation primitives have been demonstrated with photons alone — including conditional phase shift operations , and destructive and even non-destructive controlled NOT (CNOT) gates  For example, Kimbles group at Caltech showed that it was possible to observe the phase shift experienced by an atom while it interacted with a field of, on average, less than one photon For example, quantum error correction is based on such states  For future technological developments, new sources for single-photon states will be needed n Further experiments showed other purely quantum-based effects, such as the observation of photon antibunching in a resonance-fluorescence experiment  Furthermore, quantum communication through satellites is the only possible way to cover global distances Haroche and his group at the École Normale in Paris were able to construct entangled states between single photons trapped in a high-finesse cavity and atoms passing through ( Fig. 7 ) He and his colleagues employed a Mach–Zehnder interferometer to observe real single-photon interferences Here also, registration of one of the two photons can serve as a trigger to indicate that the second photon has been generated Here, phenomena are studied that are a consequence of the quantization of the electromagnetic field  Here, the idea is to start with a general, highly entangled multi-qubit state Here, the interference pattern is still observed Here, the registration of one of the two photons in a trigger detector indicates that a second, single photon is available for the experiment ( Fig. 1 ) His criticism went much further in his insistence on the existence of a real factual world and on the role of physics to describe that reality How would he comment on the later finding that one can construct random number generators on the basis of a single photon and a beam splitter , as just described? Such a quantum random number generator could well be used in a casino because of the high quality of its random sequences If the two photons do not arrive simultaneously, each has a 50% chance of going either way after the beam splitter, independently of the other photon In both cases we see particle-like and wave-like properties In Clausers and in other early experiments the source was an atomic cascade where two photons are emitted, one after the other, within the lifetime of the intermediate state, which in general is very short In contrast, full quantum theory predicts that the two detectors never register in coincidence In his experiment Taylor simply had a very dim light source together with a double slit assembly and a photo plate inside a box In our view, a common trait of many interpretations is that entities are taken to be ‘real’ beyond necessity In quantum cryptography the complementarity of different measurements on a quantum system is used to establish a secure key between two partners In quantum teleportation it is possible to transfer the quantum state of independent particles from one system to another by employing entangled states as a quantum information channel In so-called delayed choice experiments the decision of whether to observe path information can be delayed to when the particle is already inside the interferometer setup and even until after it has been registered In terms of technical applications of the photon idea, the most advanced is quantum cryptography ( Fig. 8 ) In the experiment the rate of coincident photon detections at the beam splitter outputs is monitored In the far future, a detector that identifies deterministically an arbitrary N -photon state would be useful In the simplest of such experiments, the light intensity can be dimmed down far enough that only one photon at a time is inside the apparatus In their experiment ( Fig. 4 ), they used the emission of one photon pair from two down-conversion crystals In this case the two amplitudes introduced above interfere constructively and the two particles are always found in separate outputs In this case, we should not talk about a wave propagating through the double-slit setup or through a Mach–Zehnder interferometer; the quantum state is simply a tool to calculate probabilities In this context, experiments with photons have had a pioneering role Indeed if we consider the quantum state representing the wave simply as a calculational tool, problems do not arise Indeed, there have even been experiments where the path information carried by the second particle is destroyed after the particle passing through the double slit has already been registered Initial results discriminating between one and two photons have been reported, for example, by Yamamotos group , by using a visible-light photon counter (VLPC) Initial tests of long-distance quantum teleportation have recently been performed in Geneva and in Vienna  Interestingly, this ‘fermionic’ behaviour can also be observed for two photons if the photons are prepared in an antisymmetric state with respect to their spin ( Fig. 3 ) It has now become possible to investigate the interaction between photons and atoms in great detail It may well be that in the future, quantum physics will be superseded by a new theory, but it is likely that this will be much more radical than anything we have today. Later, Walthers group in Munich realized such experiments using single atoms in traps  Many laboratories all over the world are working towards developing many different physical implementations both of quantum communication devices and of quantum computers, and it will be interesting to see which technology will be the best More generally, it would be good to have sources that produce any specific multiphoton state, even entangled ones, on demand Moreover, only with photons is it possible to cover large distances outside the protected environment of the laboratory N photons Needless to say, experiments have confirmed the quantum prediction ( Fig. 6 ) Nonlocality, Bell and GHZ Einstein did not only criticize quantum mechanics for the new role of randomness mentioned above Of the papers written by Einstein in his annus mirabilis (1905), it was not the one where he introduced the special theory of relativity , but the one where he proposed the idea of quanta of light , later called photons , that received the acclaim of the Nobel committee Of these, the early ones between Einstein and Bohr raised the key issues One essential experiment that discriminates the quantum theory of light from a semiclassical one uses a stream of single photons incident on a beam splitter ( Fig. 1 ) One might be tempted, as was Einstein , to consider the photon as being localized at some place with us just not knowing that place One photon passed a modified Mach–Zehnder interferometer, and what happened to the other photon decided whether the first photon showed interference or not Photons, atoms and beyond As mentioned above, the initial question of whether it is only matter or also radiation that is quantized has finally been settled in favour of the photon Probabilities of the photon being somewhere? No, we should be even more cautious and only talk about probabilities of a photon detector firing if it is placed somewhere Promising experiments along this line have been performed in the context of cavity quantum electrodynamics (QED; ref. 72 ) Prototype devices are already on the market and the development of systems that are suitable for the security industry is well under way Quantum cryptography, with faint laser pulses containing less than one photon on average, has been tested in free space for distances of more than 20 km (ref. 46 ) — even in daylight — and in optical fibres for a physical separation of 67 km (ref. 48 ) Quantum information processing with photons In the emerging field of quantum information technology the two basic subfields are quantum communication and quantum computation Quantum teleportation might one day provide useful communication links between yet-to-be-developed quantum computers Satellite-based quantum communication may very well be realized within the next decade Since 1905, the photon has come a long way, considering that it was first regarded only to be a ‘mathematical trick’ or a concept without any deeper meaning ( Box 1 ) Since the detection efficiencies were far from ideal, such reasoning could not be ruled out Single-photon interference One of the most fascinating phenomena is quantum interference with individual photons So, although both remaining loopholes have now been closed in separate experiments, the logical possibility exists that nature tricks us and makes use of different loopholes in different experiments Such a classically intuitive view holds that the outcome of a measurement on a physical system is determined by physical properties of the system prior to and independent of the measurement (realism), and that the outcome cannot depend on any actions in space-like separated regions (Einstein locality) Such experiments have also been used to demonstrate several interesting aspects, such as time-resolved quantum interference phenomena , trapping of atoms with single photons or quantum non-demolition measurements, in which the presence of single photons can be determined without destroying the photon  The computation is then performed by applying a sequence of simple one-particle measurements, specific to the algorithm implemented The conflict of local realism with quantum mechanics, first exposed by Bell for entangled pairs, is even more striking for three or more entangled particles The currently most advanced source for entanglement, an important resource for quantum information processing, is photon pairs generated in SPDC (ref. 43 ) The detection probability in quantum physics is given by the square of the probability amplitude, which is different from squaring the actual electromagnetic field The development of these applications is intimately connected to the development of the quantum computer itself The double-slit diffraction pattern shown in Fig. 2 was obtained in this way The Einstein–Podolsky–Rosen (EPR) paper makes use of correlations shown by entangled quantum states The first loophole, the so-called communication loophole, used the fact that even before the two photons are registered, the apparatus settings could be communicated to detectors and/or to the source The general conceptual problem is that we tend to reify — to take too realistically — concepts like wave and particle The intensities are extremely low; nevertheless, the interference pattern accumulated photon by photon shows perfect interference fringes The interference pattern is observed by sending particles, one by one, through, say, a double slit assembly; many particles are then collected at the observation plane The key factor is whether path information is available: it does not matter if someone takes care to read it out or not The latter was a real field test that even included active feed-forward of measurement results ( Fig. 9 ) The loophole was more decisively ruled out by an experiment of Weihs et al . where the measurement settings were changed randomly and fast with respect to the distance between the stations The most basic of such sources would be a single-photon source that, on demand, produces one, and only one, photon at a specific time and not at random The only way that one photon can arrive at each detector is if both photons are either reflected or transmitted The photon has been put to work in recent years, particularly in new concepts of communication The quantum correlations are too strong to be reproduced by any such model The quantum mechanically predicted statistics were experimentally confirmed by Clauser in 1974 (ref. 4 ), who used sources that emitted photons in pairs The resulting dip in the coincidence rate is called the Hong–Ou–Mandel dip  There has been important progress over the past few years in this field from various directions, including atoms in cavities and solid-state devices such as cavity-coupled quantum dots  There have been experiments transporting entangled states over more than 10 km using glass fibres and across the river Danube in free space  These early experiments used beams of atoms as sources, where fluctuations in the atom number, and thus in the emission statistics, are unavoidable These include continuous-variable demonstrations of quantum teleportation , of quantum optics in phase space , and of quantum cryptography  They triggered a body of both theory and experiments concerned with individual quantum systems This again supports the view that the quantum state may be seen as a representation of the information about the probabilities of possible measurement results, which may include mutually exclusive, that is, complementary ones This contrasts with semiclassical radiation theories (see Box 2 ), which propose that matter is ruled by quantum physics, while the radiation field is classical This criticism forms the basis of his famous article published in 1935, together with Podolsky and Rosen This implies a total phase of 180 degrees of the state |both photons reflected〉 relative to the state |both photons transmitted〉 This is most obvious for the case of the ‘many-worlds interpretation’  where the coexistence of parallel worlds is claimed without compelling evidence, but it also holds, for example, for the Bohm interpretation where, again without compelling evidence, each particle is given a well-defined position and momentum at any time This is seen most directly when two photons — one from each input port — are incident on a beam splitter ( Fig. 3 ) This is signified by the wide spectrum of different interpretations of quantum physics that compete with each other This latter loophole was closed in an experiment on entanglement between two ions in a cavity , in which it was possible to detect nearly all entangled pairs This latter observation turned out to be crucial for many quantum information applications, specifically for quantum dense coding  This left only the so-called detection loophole open, which implied that although all photon pairs would obey local realism and hence be at variance with quantum physics, the small detected subset confirmed quantum mechanics This new approach uses highly entangled cluster states, which recently have been realized with photons and applied to demonstrate elementary quantum gates  This paper is often presented as if Einstein, having analysed the photoelectric effect, arrived at the idea of the photon This results from the well-known phase jump of 90 degrees that each photon experiences upon reflection This results in single-photon states to a good approximation, because higher-order emission processes are negligible This results in the coincidences shown This was first demonstrated by Taylor  Thus, a local realistic viewpoint remained at least logically possible Thus, the still widespread view that the act of determining the path taken by the particle disturbs its state enough to destroy the interference is untenable Today, it is thought that a perfect interference pattern arises only when there is no possible way of finding out which path the particle took Today, the source of choice for photon pair creation is the process of spontaneous parametric down-conversion (SPDC), the inverse process of frequency doubling Two-photon interference An interesting consequence of the bosonic character of photons is their bunching behaviour Very early on, Einstein criticized the new nature of randomness in quantum physics, most unforgettably by stating: “God does not play dice.” In the light of this randomness, he also said that he would prefer to be an employee in a casino than a physicist We emphasize that the conceptual questions arising for photon interference are the same as those arising for interference of massive particles We have been able to give only a glimpse of the vast expanse of implications and applications of the photon concept, and of quantum optics in general We suggest that these are simply attempts to keep, in one way or other, a realistic view of the world What happens is a quantum interference effect When analysing quantum interference we can fall into all kinds of traps When turning to future challenges and developments, it is likely that the photon will have a significant role in quantum communication Whereas Einstein thought that it should be possible to observe an interference pattern and at the same time know for each photon which slit it went through, Bohr was always able to show that an apparatus capable of determining the particles path was by necessity constructed such that no interference pattern could arise and vice versa  Whereas in frequency doubling two photons are converted into one photon of higher energy, in SPDC one photon from a pump laser beam is spontaneously converted into two photons, which emerge simultaneously  Yet, as is so often the case, the real story is much more interesting (see Box 1 ) Yet, surprisingly, even for implementing quantum computation algorithms, photons offer interesting possibilities, despite the considerable difficulty of storing them for a long time Yet, we are convinced that some day in the future, the present classical information technology will be replaced by a quantum one, even if this is only because of the continuing miniaturization of switching elements in computer chips
 Here we describe how the flower stamens of the bunchberry dogwood ( Cornus canadensis ) rely on this principle to catapult pollen into the air as the flower opens explosively  Our high-speed video observations show that the flower opens in less than 0.5 ms — to our knowledge, the fastest movement so far recorded in a plant. The release of stored elastic energy often drives rapid movements in animal systems , and plant components employing this mechanism should be able to move with similar speed After the petals open, the bent filaments unfold, releasing elastic energy As bunchberry flowers burst open, their petals rapidly separate and flip back to release the stamens ( Fig. 1 ) As in these other organisms , rapid movements in bunchberry flowers rely on stored mechanical energy Bunchberry stamens are designed like miniature medieval trebuchets — specialized catapults that maximize throwing distance by having the payload (pollen in the anther) attached to the throwing arm (filament) by a hinge or flexible strap (thin vascular strand connecting the anther to the filament tip) But the flowers do not open if their turgor is reduced: dehydration of flowers with sucrose decreases the extent of opening, although subsequent rehydration allows them to open fully (results not shown) Cornus canadensis grows in dense carpets in the vast spruce-fir forests of the North American taiga During the first 0.3 ms, the stamens accelerate at up to 24,000±6,000 m s −2 (2,400 g ), reaching the high speed (3.1±0.5 m s −1 ) necessary to propel pollen, which is light and rapidly decelerated by air resistance (terminal velocity, 0.12±0.03 m s −1 (mean±s.e.m.); n =7) Exploding flowers enhance insect pollination and may allow wind pollination, adding to growing evidence that flowers often use multiple pollination mechanisms . First, when insects trigger flower opening, the pollen released sticks to their body hairs until it is transferred to an adhesive stigma Indoors, pollen is transported over 22 cm (more than 100 times the size of the flower) and outdoors, in the presence of a steady wind, pollen can move farther than a metre Petals attain a maximum speed of 6.7±0.5 m s −1 , accelerating at up to 22,000±6,000 m s −2 (or 2,200 g ) Physiological processes, which take about a millisecond for each enzymatic reaction , are not required for the explosion itself Second, pollen from flowers that open by themselves may be carried by wind currents The force required to open flowers (0.1–0.5 mN) favours large pollinators (bumblebees, for example) that move rapidly between inflorescences; it effectively excludes smaller, less mobile visitors such as ants The pollen granules are launched to an impressive height of 2.5 cm (range, 2.2–2.7 cm; n =5), which is more than ten times the height of the flower: from this height, they can be carried away by the wind. (For methods and movies, see supplementary information .) Petals open independently of stamen activity, moving out of their way within the first 0.2 ms ( Fig. 1 ) The process of petal opening and pollen launch in bunchberry plants occurs faster than the opening of Impatiens pallida fruits (2.8–5.8 ms, n =3, see supplementary information ); the snap of venus flytraps ( Dionaea muscipula ; 100 ms) ; the leap of froghoppers ( Philaenus spumarius ; 0.5–1.0 ms) ; or the strike of the mantis shrimp ( Odontodactylus scyllarus ; 2.7 ms)  The rapid opening of the self-incompatible bunchberry may enhance cross-pollination in two ways The tip of the filament follows an arc, but the rotation of the anther about the filament tip allows it to accelerate pollen upwards to its maximum vertical speed, and the pollen is released only as it starts to accelerate horizontally ( Fig. 2 ) This floral trebuchet enables stamens to propel pollen upwards faster than would a simple catapult Turgor pressure is therefore required in the production of mechanical energy for explosive flower opening We find that the flowers will open even when the stamen filaments have been crippled by treatment with sodium azide
 A noteworthy previous effort to overcome this trade-off between an excess of one desired enantiomer and high chemical yield was the combined use of a photosensitizer carrying saccharides and a nonpolar solvent A third and smarter way to transfer chirality is to use a catalytic chiral complexing agent, which is needed in a smaller molar amount than the substrate Although all the individual techniques were known previously, they have never before been combined to circumvent the acceleration–dissociation problem Bach and colleagues (this issue, page 1139 ) now combine two approaches to asymmetric synthesis — the thermal and the photochemical — to control the spatial arrangement of the atoms in a chiral reaction product Bach and colleagues approach combines the advantages of the third and fourth methods Bach and colleagues succeed in obtaining a chiral reaction product consisting of up to 70% excess of one enantiomer, with a yield of 52–64% and turnover numbers (a measure of the amount in mole of a product that is obtained with one mole of catalyst) of between 2.1 and 12.2 Bach and colleagues thus provide us with a powerful method applicable to PET photo-chirogenesis Catalytic asymmetric synthesis — the use of chiral catalysts to transfer and amplify chirality in chemical reactions — has therefore become a central topic in molecular science  Chirality — the non-identity of a molecule with its mirror image — is ubiquitous Finally, light-absorbing compounds known as chiral photosensitizers can be used to transfer energy or electrons, along with the chiral information, to a substrate Here, the polar saccharides accelerate PET, whereas the nonpolar solvent prevents the dissociation of the resulting radical–ion pair to secure chiral recognition In conventional thermal asymmetric synthesis, vibrational energy is supplied to a reaction in the presence of a chiral catalyst or enzyme In previous studies , the authors had exploited the bulky backbone of a simpler template molecule as a ‘picket-fence’ to prevent a reagent attacking the substrate from the template side In their current study , Bach and colleagues neatly sidestep the acceleration–dissociation dilemma inherent in PET by using neutral radical species produced in the sequence of electron and proton transfers as intermediates, and a hydrogen bond as a tether, to ensure the stability of the chiral environment ( Fig. 1 ) In their new catalyst , the benzophenone group accepts an electron from an atom, in this case nitrogen, of the bound organic substrate ( Fig. 1 ) when activated by light Inevitably, however, this technique requires equal molar quantities of the chiral source and the substrate It also means that the polar solvents necessary for PET processes are a mixed blessing: although they accelerate electron transfer and thus increase yield, they simultaneously facilitate dissociation and thus decrease enantioselectivity It occurs not only in biomolecules (amino acids, sugars, DNA and RNA are examples of chiral molecules), but also in man-made chemicals, materials and drugs Like other methods in the realm of asymmetric synthesis, photochirogenesis essentially requires a physical or chemical source of chirality that can be transferred to the reaction products Nevertheless, chiral photochemistry, or photochirogenesis, has become an area of rapid growth, particularly in the past 10–15 years  One factor that can significantly disturb the selective formation of one or other enantiomer is the subsequent dissociation, or separation, of the PET-produced radical–ion pair by solvent molecules Such an agent binds to the substrate in the ground state to provide a chiral environment for a subsequent photochemical process Such sources come in four main varieties The advantages of this method are, first, that only a small amount of photosensitizer is needed, and, second, that chirality transfer occurs exclusively in the excited state and is thus unaffected by the binding affinity of the photosensitizer for the substrate in the ground state The aim of photochemical asymmetric synthesis is the same, but its tools are different: it uses short-lived, weakly interacting molecular states that have been excited not by heat but by absorbed light The chiral catalyst that they developed ( Fig. 1 ) contains a photosensitizer component — benzophenone — and a group known as a Kemps triacid derivative, which uses two hydrogen bonds to attach to a specific substrate like a template, favouring one of the two faces of the substrates molecular plane The control of chirality is no trivial task, particularly where PET processes are involved The first is circularly polarized light, which is used in a technique known as absolute asymmetric synthesis — because a product enriched in one enantiomer is formed from a one-to-one mixture of mirror-image precursor molecules without the intervention of a chiral catalyst The irradiation of this augmented substrate creates a new chiral centre in the substrate, often in such a way that the spatial structure of the new chiral centre in the reaction product is determined by that of the chiral auxiliary The results could be seminal in the field of chiral photochemistry The second method, known as the chiral auxiliary strategy, uses a molecular group of a particular chirality that binds covalently to an achiral substrate Their photochirogenic process is composed of four steps: the initial PET to produce a radical–ion pair; the transfer of a proton adjacent to the electron-deficient nitrogen to the benzophenone radical anion; the formation of the resulting radical pair into a hydrocarbon ring (cyclization) within the molecule; and finally, the hydrogen initially transferred to benzophenone is returned to the radical centre of the cyclized product This activates ground-state reagent molecules to achieve an asymmetric transformation in which one of two enantiomers — mirror-image forms of a molecule — of a reaction product will be preferentially synthesized This creates a radical–ion pair in a process known as photochemical electron transfer, or PET. (PET processes are well known from, among other things, the conversion of solar to chemical energy in plant photosynthesis.) The benzophenone group then forces a molecular group known as a pyrrolidine ring to remain on one side of the substrate, and thus define which side will participate in the further reaction This does, however, make controlling the structure of the reaction product more difficult, owing to the weak, short-lived interactions in the excited state This is certainly a breakthrough in chiral photochemistry — particularly where synthesis is concerned — that will further stimulate research in this rapidly growing area of science. This method is not useful for practical synthetic purposes, but has been discussed in relation to a possible extraterrestrial origin of the chiral homogeneity of biomolecules on Earth  This process brings about the desired enantioselection, so that one of the possible two mirror images of the reaction product will form preferentially This process spoils the chiral recognition between the sensitizer and the substrate; the reaction will eventually create a racemic product — that is, an equal mixture of two enantiomers This technique is more difficult to control than its thermal counterpart, and has therefore been less extensively studied, despite its inherent advantages — the low activation energy required for such reactions and the ability to create unstable molecules unique to photochemical reactions, for example Throughout the whole process, the dual hydrogen bonds tie the substrate to the chiral catalyst in close proximity and in the right orientation
 A central goal in condensed matter and modern atomic physics is the exploration of quantum phases of matter—in particular, how the universal characteristics of zero-temperature quantum phase transitions differ from those established for thermal phase transitions at non-zero temperature Compared to conventional condensed matter systems, atomic gases provide a unique opportunity to explore quantum dynamics far from equilibrium For example, gaseous spinor Bose–Einstein condensates (whose atoms have non-zero internal angular momentum) are quantum fluids that simultaneously realize superfluidity and magnetism, both of which are associated with symmetry breaking Here we explore spontaneous symmetry breaking in 87 Rb spinor condensates, rapidly quenched across a quantum phase transition to a ferromagnetic state The latter are topological defects resulting from the symmetry breaking, containing non-zero spin current but no net mass current . We observe the formation of spin textures, ferromagnetic domains and domain walls, and demonstrate phase-sensitive in situ detection of spin vortices A small shift quadratic in m F from the optical beam was negligible A Stern–Gerlach analysis of populations in each of the magnetic sublevels was applied to establish that the field ramp was sufficiently slow so as not to alter the spin state of the condensate At later times T hold after the quench, such measurements showed significant mixing of populations coincident with the onset of spontaneous Larmor precession  At the low-field setting following the quench, magnetic field gradients along the ◯ and zcirc; directions were nulled to less than 0.2 mG cm -1  At this setting, the phase-contrast signal is given approximately as ζ ( 6 5 + 〈 Fcirc; y 〉 + 1 5 〈 Fcirc; 2 y 〉) where ζ = (5/48) ñ σγ / δ , ñ is the column density of the gas, σ  = 3 λ 2 /2π is the resonant cross-section, λ = 795 nm is the wavelength of the probe light, and γ is the natural linewidth Following this sequence, two additional image frames were obtained within 5 ms in which the magnetic field was adiabatically reoriented in the ŷ and - ŷ directions Image analysis The identification of spin vortices in the magnetization images relied on the identification of a core of ‘dark’ pixels, consistent with zero Larmor precession amplitude, which were surrounded by ‘bright’ pixels with a finite amplitude and well-defined phase of Larmor precession Magnetization imaging The probe light for magnetization-sensitive phase-contrast imaging was circularly polarized and detuned by δ = -200 MHz from the 5 S 1/2 ( F = 1) → 5 P 1/2 ( F ′ = 2) transition Methods Experimental sequence Optically trapped BECs were obtained by loading around 10 8 atoms in the | F = 1, m z = -1〉  state with temperature of 2.5 µK into an optical dipole trap Probe pulses were 1 µs in duration, much shorter than the ∼35 kHz Larmor precession frequency at a 50 mG field Such an analysis bounded the populations in each of the | m z = ± 1〉  spin states to be less than 0.3% of the total population, both before and right after the field ramp Sufficient magnification was used so that the finite pixel-size of our camera caused no degradation of the image The distinction between bright and dark pixels (at about one-quarter of the maximum Larmor precession amplitude) was chosen to eliminate false-positive vortex detections in simulated data taking into account the measured noise (optical shot-noise limited) and resolution of our imaging system, and using estimates for the width of contiguous domain walls. The image sequence began with 24 images taken of the same atomic sample at a strobe frequency of 10 kHz while the magnetic field remained oriented along the zcirc; direction The imaging system was diffraction-limited, with a resolution defined by the modulation transfer function dropping to half for features with pitch 6 µm in the object plane The longitudinal magnetization was determined from the difference between these last frames The normalization constant ζ ( ρ ) was obtained by averaging the signal over all image frames and fitting with a Thomas–Fermi distribution for the density of the condensate The optical trap was formed by a single focused laser beam with a wavelength of 825 nm, which was linearly polarized to ensure that all components experience the same trap potential These images were used to measure the orientation and magnitude of the transverse magnetization This yielded nearly pure condensates of 2.1(1) × 10 6 atoms Using radio-frequency rapid adiabatic passage followed by application of a transient magnetic field gradient of 4 G cm -1 , all atoms in the optical trap were placed in the | m z = 0〉  magnetic sublevel We identified vortices based on two criteria: (1) that there be an island of dark pixels, a candidate for the vortex core, which is surrounded entirely by bright pixels and that is at least two bright pixels away from nearby dark pixels, and (2) that the transverse magnetization traced along a closed loop through bright pixels surrounding the core have a non-zero net winding We ignore the small 〈 Fcirc; y 2 〉  signal in this work While the magnetic field was held at a magnitude of 2 G, the trap depth was decreased over 400 ms to k B × 350 nK and the temperature of the gas to ∼40 nK, well below the Bose–Einstein condensation temperature A spinor gas Bose–Einstein condensate (BEC) is described by a vector order parameter and therefore exhibits spontaneous magnetic ordering After the condensate was formed, the magnetic field was oriented in the zcirc; direction, ramped linearly over 5 ms to a magnitude of 50 mG, and held at this setting for a variable time T hold before we imaged the gas After the quench, transverse ferromagnetic domains of variable size formed spontaneously throughout the condensate, divided by narrow unmagnetized domain walls All observed vortices were singly quantized, with no apparent preferred direction of circulation An important aspect of rapid spontaneous symmetry breaking, whether in the laboratory or of a cosmological nature, is the creation of topological defects  Analogues of cosmological topological defect formation have been studied using liquid crystals and superfluid helium  Any magnetization during this stage was either too low in magnitude or varied over too short a length scale to be discerned by our imaging As shown in Fig. 1 , at short times after the quench ( T hold 50 ms), images probing the transverse magnetization show no significant variation across the cloud or between frames (similarly for the longitudinal magnetization images), indicating the presence of BECs remaining in the unmagnetized phase As shown in Fig. 3a , G t (0) rises after the quench from a near-zero value characteristic of the unmagnetized state to a nearly constant value of G t (0) ≃ 0.5 At later times, a non-zero transverse magnetization signal spontaneously developed, yielding a Larmor precession signal that varied both in amplitude and in phase across the condensate At this field, the quadratic Zeeman energy q = h × 0.2 Hz is negligible compared to twice the spin-dependent interaction energy of 2| c 2 |〈 n 〉  y = h × 16 Hz, where 〈 n 〉  y is the density averaged in the ŷ direction At variable times T hold after the quench, high-resolution maps of the magnetization vector density were obtained using magnetization-sensitive phase-contrast imaging  By rapidly reducing the magnitude of the applied magnetic field, we quenched the gas to conditions that favour the ferromagnetic phase ( q ≪2| c 2 | n ) Concurrent with the formation of these domains, we also observed topological defects that we characterize as singly charged spin vortices with circulating spin currents and unmagnetized filled cores 4  Ferromagnetic domains from a quenched unmagnetized (| m z = 0〉) gas arise through a dynamical instability in a spinor BEC  Ferromagnetism thus arises by the spinodal decomposition of a binary gaseous mixture into neighbouring regions of oppositely oriented transverse magnetization Fitting G t (0) at early times ( T hold 90 ms ) to a rising exponential yields a time constant of τ  = 15(4) ms, in agreement with the predicted τ  fm = ℏ / 2| c 2 |〈 n y 〉  = 13.7(3) ms For 87 Rb F = 1 spinor gases , the spin-dependent energy per particle in the condensate is the sum of two terms, c 2 n 〈 Fcirc; 〉 2 + q 〈 Fcirc; z 2 〉, where Fcirc; denotes the dimensionless spin vector operator For example, symmetry breaking is presumed to have occurred at thermal phase transitions in the early Universe, giving rise to the specific elementary particles and interactions now observed For this vortex, the central region of near-zero Larmor precession amplitude has a diameter of about 3 µm, comparable to the spin healing length ξ s = 2.4 µm defined earlier For this, we recall that the | m z = 0〉  state represents a coherent superposition of the | m φ  = ± 1〉  eigenstates of any transverse spin operator, Fcirc; φ  = Fcirc; x cos  φ  + Fcirc; y sin  φ , and that, because c 2 0, the ± 1 eigenstates of any spin component are immiscible  Further time-resolved experiments in which one varies the rate at which the system is swept into the ferromagnetic state may also uncover universal temporal dynamics that typify this and other quantum phase transitions. Furthermore, the present work focuses on a quantum rather than a thermal phase transition  Given c 2 0 for our system , the interaction term alone favours a ferromagnetic phase with broken rotational symmetry Here we describe the observation of spontaneous symmetry breaking in a 87 Rb spinor BEC that is rapidly quenched across this quantum phase transition However, we observe domain walls that form at the onset of visible ferromagnetism in the gas and persist for all times thereafter Improved magnetization imaging may allow studies of hourspin vortices are produced and of their subsequent evolution In comparison with these previous experiments, the present investigation focuses on a simpler physical system, in which the time for thermal equilibration and domain formation is much longer than that needed to bring the system across the symmetry-breaking transition In contrast with their topological nature in some other magnetic systems, domain walls in a F = 1 ferromagnet are not topologically stable; rather, they may decay by the formation of spin vortex–antivortex pairs In Fig. 2 , the derived transverse magnetization for samples at variable times T hold are presented, rendered in colour to portray both the magnetization orientation (as hue) and amplitude (as brightness) In future experiments, our non-destructive imaging method may be adapted to allow the behaviour of a single quenched condensate to be recorded, allowing a closer examination of the dynamical evolution of domain walls In our two-dimensional system, spin vortices are topological point defects about which the orientation of magnetization has a 2π l winding with l being a non-zero integer In the context of mean-field theory, the above mentioned dynamical instability describes the amplification of an initial seed of non-zero transverse magnetization of a particular spin orientation (denoted above as φ ) once the rotational symmetry of the initial unmagnetized gas is already broken In this work, the forced depletion of atoms not in the | m z = 0〉  state and the energy gap for magnetization fluctuations in the unmagnetized (high- q ) phase suggest that ferromagnetism formed purely by the amplification of quantum fluctuations, that is, shot noise, a suggestion that warrants experimental justification Longitudinal magnetization was then measured from images in which the magnetic field was adiabatically reoriented in the ± ŷ directions Many types of vortices that can occur in a gas with a multi-component order parameter can be distinguished by the composition of their cores  Nearly pure spinor BECs were prepared in the unmagnetized | m z = 0〉  phase at a high quadratic Zeeman shift ( q ≫2| c 2 | n ) Nevertheless, freedom remains for the type of ordering that can occur On the basis of our measurements of the transverse and longitudinal magnetization at the vortex core, the spin vortices seen in our experiment appear to have unmagnetized filled cores Over the same period of evolution, no significant longitudinal magnetization was observed, confirming the presence of purely transverse ferromagnetic domains Spatial correlations in the transverse magnetization ( Fig. 3b ) are typified by a central region of positive correlations (near δ ρ  = 0) and then several equally sized regions of alternating negative and positive correlations displaced from one another in the narrow ◯ dimension of the condensate Spin-vortex defects were observed with high confidence in about one-third of all images containing significant ferromagnetism ( T hold 90 ms), with some images indicating as many as four vortices (see Methods) Spinor atomic gases are those comprised of atoms with non-zero internal angular momentum—the sum of electronic and nuclear angular momenta, denoted by quantum number F —and in which all orientations of the atomic spin may be realized Spinor BECs in the | F = 1,  m z = 0〉  hyperfine state were confined in an optical dipole trap characterized by oscillation frequencies ( ω  x , ω  y , ω  z ) = 2π(56,350,4.3) s -1  Such a vortex is thus characterized by zero net mass circulation and a spin current with one quantum of circulation The alternate identification of these vortices as merons is ruled out by the absence of longitudinal magnetization at the vortex core The complex transverse magnetization F t = F x + iF y was then determined as A ( ρ )exp( iφ ( ρ )) = iζ ( ρ ) F t ( ρ ) from the amplitude A ( ρ ) and phase of φ ( ρ ) of Larmor precession at each pixel position ρ  The condensate magnetization was measured in situ using phase-contrast imaging, which yields a magnetization-sensitive signal given approximately as ζF y , where ζ is proportional to the gas column density and F y = 〈 Fcirc; y 〉  is one component of the (dimensionless) magnetization of the gas (see Methods) The condensates, typically containing 2.1(1) × 10 6 atoms, were formed at a magnetic field of 2 G and characterized by a peak density n 0 = 2.8 × 10 14  cm -3 and Thomas–Fermi radii ( r x , r y , r z ) = (12.8,2.0,167) µm (see Methods) The first term describes spin-dependent interatomic interactions, with n being the number density and c 2 = (4π ℏ  2 /3 m )( a 2 - a 0 ) depending on the atomic mass m and the s -wave scattering lengths a f for collisions between pairs of particles with total spin f (refs 2 and 3 ) The generation of such vortices under conditions of our experiment was predicted in ref. 4  The landscape of domains includes small regions of homogeneous magnetization, with unmagnetized domain walls separating regions of nearly opposite orientation, and also larger ferromagnetic spin textures free of domain walls in which the magnetization orientation varies smoothly over tens of micrometres The origin for such spin currents is presumably the spinodal decomposition by which ferromagnetism emerges from the unmagnetized cloud The preferential phase separation in the narrow ◯ direction rather than along zcirc; , as indicated by G t ( δ ρ ), may arise because the momentum distribution of the unmagnetized condensate in that direction is broader owing to the finite condensate size The presence of negative correlation regions supports the model of spin-conserving phase separation discussed above The presence of several alternations of positive and negative correlations further suggests that the phase separation occurs through a small number of discrete, unstable magnetization modes The second term describes a quadratic Zeeman shift in our experiment, with q = ( h × 70 Hz G -2 ) B 2 at a magnetic field of magnitude B (the linear Zeeman shift may be neglected owing to spin conservation) The source of such a symmetry-broken seed is either thermal or quantum magnetization fluctuations in the gas before the quench The spontaneous symmetry breaking observed in this work is one of many examples of symmetry breaking that occur in nature The types of topological defects that may be formed depend on the group structure of the ground-state manifold reached at the transition The wavevector of the dominant instability k fm = 2 m | c 2 | n / ℏ  defines the typical size l = π k fm - 1 of single-component domains in the phase-separated fluid, and also the width b ≃  k fm - 1 of domain walls in which the two components still overlap  These spatial maps show ferromagnetic domains of variable size and orientation arising spontaneously after the quench These two phases have distinct symmetries, and are therefore divided by a quantum phase transition at q = 2| c 2 | n  This instability, which is a consequence of coherent collisional mixing between magnetic sublevels , may also be regarded as the phase separation of a two-component condensate  This observation indicates heterogeneous, spontaneous symmetry breaking in the gas, specifically the breaking of O (2) rotational symmetry in the transverse plane in a direction given by the phase of Larmor precession This observation supports their characterization as ‘polar-core’ spin vortices (denoted as (± 1,0, ∓ 1) vortices in ref. 27 ), for which the superfluid order parameter is a superposition of atoms in the | m z = 1〉  state rotating with one quantum of circulation, atoms in the | m z = -1〉  state rotating with one quantum of circulation in the opposite sense, and non-rotating atoms in the unmagnetized | m z = 0〉  state, which also fill the vortex core This phase separation is dominated by a fast-growing instability with an exponential timescale of τ  fm = ℏ / 2| c 2 | n  This saturation value measures the area occupied by domain walls This term favours instead a phase with no net magnetization, that is, a condensate in the | m z = 0〉 magnetic sublevel, with unbroken O (2) rotational symmetry in the transverse spin plane Thus, imaging the condensate in the ◯ – zcirc; plane produced complete maps of the magnetization density Thus, upon quenching the system, a greater population of atoms is available to seed the faster-growing, shorter-wavelength instabilities with wavevector in the ◯ direction To compare our data to the model of dynamical instabilities described above, we considered the density-weighted transverse magnetization correlation function: G t ( δ ρ ) = Re ∑  ρ  ( ζ ( ρ ) F t ( ρ ))*( ζ ( ρ  + δ ρ ) F t ( ρ  + δ ρ )) ∑  ρ  ζ ( ρ ) ζ ( ρ  + δ ρ ) At zero range, G t (0) measures the degree to which the condensate has evolved toward the ferromagnetic state Transverse magnetization was detected by imaging its Larmor precession about a zcirc; -oriented guide field  Variations in the internal-state wavefunction were constrained in these anisotropic condensates to just two spatial dimensions ( ◯ and zcirc; ) because the spin healing length, ξ s = ℏ  2 /2 m | c 2 | n 0 = 2.4 µm, was larger than the cloud size r y in the ŷ direction We determined all three components of the vector magnetization density with repeated imaging of the same atomic sample We emphasize that domain formation is neither the cause nor the mechanism for spontaneous symmetry breaking We estimate a typical size for single-component domains as ≃10 µm, twice the displacement at which the transverse spin–spin correlation changes sign, in good agreement with the predicted π k fm - 1 = 8.3(2) µm
 Academics and universities are often hotbeds of such reform movements, and every year hundreds of academics worldwide consequently face threats, or worse All scientists can contribute, by making themselves aware of current cases of human-rights abuses and by lending their support to campaigns against them. At the very least, this serves to remind perpetrators that they are under international scrutiny But beyond humanitarian grounds, in this interconnected world we are engaged in a battle of ideas, and the failure to defend any abuse of academic freedom undermines the very principles that guarantee the rights we currently enjoy Cases are many, and no one community can give sustained attention to them all Enquiry is further undermined in such environments by the award of senior academic posts to the politically loyal rather than the competent, and the selection of policies or actions that suit governments agendas, regardless of the scientific evidence It is important that we do not forget them Many learned societies, including the American Physical Society and the American Chemical Society, as well as several scientific academies, have human-rights committees that play an active role in defending individuals at risk Most readers of Nature take it for granted that they can travel to work each day, free to enquire, express opinions and criticize government policy, without fear of intimidation or reprisals — let alone imprisonment or torture Most societies human-rights activities are run on a shoestring by volunteers Often these committees use political contacts and letter-writing campaigns to try to influence the outcome of particular cases Oppressive regimes typically stifle enquiry, as critical minds will inevitably also scrutinize their leaders Sadly, these freedoms can only be dreamt of in many countries of the world, where academics must live with, and often suffer directly, human-rights abuses Scientists must find the means to better fund and professionalize such activities Scientists who have been freed testify that, although difficult to pin down, such support is crucial So it is encouraging that several major scientific bodies have now weighed in to demand that the court hears the scientific facts That latter characteristic is central to the trial of six medical workers — five Bulgarian nurses and a Palestinian doctor — currently facing the death penalty in Libya on charges of infecting hundreds of children with HIV (see page 612 ) The real evidence has been purged from the trial The US National Academies Committee on Human Rights is among the most effective, and has a full-time secretariat Their plight is our business Then they came for me, and there was no one left to speak up for me.” Martin Niemöllers poem, criticizing the inaction of German intellectuals in the face of the rise of the Nazis, serves as a powerful analogy for why scientists should be concerned by abuses of academic freedom, wherever they occur Then they came for the Jews, and I didnt speak up, because I wasnt a Jew This diverse range, and the mechanism whereby one body takes the lead on a case where it knows the community, is an effective way of dividing up resources Tripoli may seem far away, but knowledge and academic freedom are central planks in many other struggles across the world for more open, democratic societies Yet it runs on a budget of just $0.5 million a year, most of it contributed by philanthropies “First they came for the Socialists, and I didnt speak up, because I wasnt a Socialist..
 A visit to The Gates, Christo and Jeanne-Claudes temporary art installation in New Yorks Central Park this February allowed me not only to visualize coherent eddies, but also to measure their sizes and local lifespans But the assumption has been that a seed falling in a forest is doomed to travel only a short distance, because the wind is impeded as it passes among the trees Distrib. 11, 131–137; 2005) Eddies at The Gates Tree seeds that are dispersed by the wind have parachutes, wings or sails to slow their descent Footprints spanning at least 12–13 gates (about 45 metres) were common at wind speeds of 2 to 5 metres per second From timed sequences of photographs of sets of gates, I recorded local lifespans of 32 to 57 seconds I measured the ‘footprint’ of a coherent eddy by counting a consistent number of contiguous billowing gates and calculating the distance they span If the updraft is part of a coherent rolling eddy, the seed might ‘surf the wave’ to a great distance My colleagues and I have produced computer models that predict wind dispersal over long distances, but it has been difficult to convince others that our models are realistic (Nathan et al  Nature 418 , 409 – 413 ; 2002 ; Div Nevertheless, the general pattern and its spatial and temporal scales are highly suggestive of features to be expected in a natural landscape Of course, the aerodynamic presence of The Gates is part of the landscape that may interact with the generation and propagation of coherent eddies Praise is also due to Christo for having anticipated realistic sizes for the wind eddies that drive The Gates in his conceptual drawings, which were made before construction of the work itself Saffron-coloured fabric panels were hung from the top of each Seeds that are kept aloft by updrafts in a 45-metre coherent eddy, for 50 seconds, in a horizontal wind of 5 metres per second, could travel at least 0.25 kilometres So the seed can indeed fall far from the tree. Some details are likely to be peculiar to Central Park, and even to the installation itself Some eddies lasted longer than 100 seconds, and the their footprints tended to move along a line of gates at scales of about 100 metres Thanks to Christo, Jeanne-Claude and The Gates, I now have direct quantitative observations, in moderate winds, of the coherent eddies that are crucial to long-distance dispersal of seeds and other biotic agents The Gates in Central Park, New York City, 1979–2005 comprised 7,500 gates, around 4 metres apart and 5 metres high, following the line of the paths through the park The measurements came from 57 photographs that I took with a digital camera on the afternoons of 24, 25 and 27 February 2005 The panels billowed out to within 20° of the horizontal for winds recorded near the ground at 2 to 5 metres per second ( http://www.cdo.ncdc.noaa.gov/ulcd/ULCD ) These records are biased toward shorter lifespans, as I chose to photograph sequences only when the gates were changing orientation rapidly This is farther than we thought, even though the measurements behind the calculation are all substantial underestimates This keeps them in the airflow longer, allowing them to travel farther To guess how far a seed might get, it becomes important to know the sizes and lifespans of coherent wind eddies, but it seems that no one has made the appropriate measurements To travel far, a seed must rise above the forest canopy on an updraft whose velocity exceeds the rate of fall of the seed in still air When there was no detectable wind or only a light breeze, the fabric of The Gates hung vertically with minimal flutter
 Every nominee has to be nominated by five individuals who between them were mentored over different periods of the mentors career In each region, two prizes will be awarded: one for a lifetimes achievement in mentoring, and another to an individual in the middle of his or her career Last year we inaugurated the Nature /NESTA awards for creative mentoring in science, co-sponsored by Britains National Endowment for Science, Technology and the Arts Nature has chosen to favour the latter approach Nomination forms and details of the awards can be found at http://www.nature.com/nature/nestaawards . The closing date is 19 June The prizes are intended to celebrate a scientific activity that otherwise tends to be taken for granted The UK awards are now open for nominations There are many heads of labs whose students have turned into outstanding scientists, but all too often such cases have exemplified survival of the fittest rather than being the product of deliberate nurturing This year we are pleased to announce that Nature will be sponsoring awards for high-achieving mentors in two regions: the United Kingdom, again co-sponsored by NESTA, and, later this year, Australasia
 A Allen and Hoffman propose that large, wave-generated sand ripples (orbital ripples) in Precambrian rocks were generated by sustained, extreme winds driven by rapid climate change after termination of the Marinoan glaciation Allen P Arising from: P F Hoffman Nature 433 , 123 – 127 ( 2005 ) ; Allen and Hoffman reply  Quantitative estimation of environmental properties using sedimentary structures preserved in rocks is complicated by the fact that some relationships between the fluid flow, sediment transport and bed topography are not unique We show here that these features could equally well have formed under normal storm conditions in tens of metres of water We therefore contend that the ripples do not provide direct evidence for a climatic transit after the break-up of a snowball-Earths global ice cover. A bathymetric survey of the continental shelf off North Carolina in the United States found ripples with wavelengths of up to 4 m and a median grain diameter ( D ) of 0.1–5 mm covering the shelf at h values of 20–40 m A rate of deposition associated with this climb is tightly constrained by T , and is calculated to be about 1 cm min −1  A small number of short-duration events do not place any constraint on associated climate conditions Airy wave theory relates wavelength ( L ), H and h to near-bed flow conditions ; however, an infinite combination of these variables can produce the same near-bed conditions ( Fig. 1 ) Allen and Hoffman conclude that the observed ripples developed in deep water (depth h , 200–400 m), by waves of unusually large period ( T , 21–30 s) and amplitude ( H , 7.5–12 m) Allen and Hoffman only consider transport conditions at ψ = ψ  c , which yields a maximum estimate for T  An independent constraint on any one of these three variables is necessary for closure An upper limit for bed stress associated with steep orbital ripples is 3 ψ  c (ref. 2 ) At this rate, the entire sequence shown in Fig. 3 of ref. 1 could have been deposited in less than 3 h Critical shear stress ( ψ  c ) for the initial motion of a particle of size D provides a minimum bed-stress condition for ripple formation  Detection of this bed topography seems to be limited by instrument resolution, rather than by a paucity of these features on the sea floor  Field observations link formation of these ripples to specific hurricanes and tropical storms Flanks of some preserved ripples exceed the angle of repose, indicating deformation and making the measured steepness values inexact For ψ =3 ψ  c , T is reduced by a factor of √(1/3) ( Fig. 1 ) Measured values of T and H for the water waves developed during these events commonly exceeded 60 s and 3 m, respectively Modern storm-generated waves of similar period produce orbital ripples of the same morphology and grain size as the Marinoan examples, but under conditions of much smaller h , H and L  More important, Allen and Hoffman assume, without justification, that wind of unlimited fetch and duration generated the long-period surface waves producing the bedforms Our results ( Fig. 1 ) show that the preserved orbital ripples could have formed under rather mundane environmental conditions , and therefore do not provide evidence for extreme climate change Perhaps the most remarkable aspect of the reported stratigraphy is the continuous vertical climb of the ripples The most reasonable procedure would be to estimate water depth based on the physiographical position of ripples found within the ancient basin Their environmental reconstruction represents a possible, but non-unique, inversion of the geological data Their estimates for H are based on this model and these values, in turn, are used to calculate h  They suggest that a discrete cyclone or hurricane is likely to be too short-lived an event to produce the observed sedimentary structures and that present-day orbital ripples seldom have wavelengths (λ) exceeding 1 m, both of which we contest This high rate seems to rule out spontaneously precipitating carbonate as the sediment source for the ripples This narrow range in bed shear stress plus the mean value for λ constrain the associated near-bed flow field ( Fig. 1 ) We wish to make clear that our analysis does not address larger issues of the snowball-Earth hypothesis , but rather serves to show that small-scale observations must be carefully placed within a basin-scale context to produce a unique set of environmental conditions associated with the accumulation of the observed sedimentary deposits. With these parameters, T is the only surface-wave property that can be estimated from sedimentary deposits 
 A public effort is essential, argues Hart, because it should provide users with access to the full text of books and high-quality images that they can use in whatever way they wish, without restriction Alternatively, the Google move might result in healthy competition and an increased demand for a public-domain service, Kahle says But its scanning costs — which could amount to $230 million over four years — are due to be paid by participating libraries But this plan is being viewed with trepidation by backers of existing, public-domain projects that aim to do the same kind of thing Chiracs move is widely interpreted as a response to Googles announcement late last year that it intends to scan millions of library books — primarily from collections at the universities of Harvard, Stanford, Michigan and Oxford, as well as that of the New York Public Library — over the next ten years He called on France and Europe to take “a major role” in a “vast digitization of knowledge” He cites as a precedent the human genome project, where the private company Celeras plans to sequence the genome galvanized the public consortiums determination to deliver its own version He fears that his and other public projects could be hurt if funders think Google can do the job alone His statement, issued on 16 March, asked Renaud Donnedieu de Vabres, Frances minister of culture, and Jean-Noël Jeanneney, the president of the Bibliothèque nationale de France, to come up with proposals to accelerate the dissemination of French and other European works on the Internet However, Raj Reddy, a computer scientist who is the founder and director of the Universal Digital Library at Carnegie Mellon University, welcomes the competition from Google, and says that, if anything, it should increase support for public-domain projects. “The more the merrier,” says Reddy, whose project scans a million pages a day and has already indexed some 100,000 volumes as part of a plan to scan one million books. “It is going to take us a long time to digitize all these things.” In contrast, Googles current system allows users to search texts online and to browse images, but provides access to only a small portion of the texts In December, Internet Archive teamed up with Carnegie Mellon University, the Library of Congress American Memory Project and universities in Canada, Egypt, India, China and Europe to digitize 9 million books over the next four years Kahle says that the Google project could have three possible outcomes Michael Hart, the founder of Project Gutenberg — the first ambitious attempt to digitize libraries, launched in 1971 and based in Urbana, Illinois — expresses concern about the proprietary nature of the Google project More than 50,000 of them will be digitized by the end of this month One backer of the public-domain approach is Brewster Kahle, founder of the Internet Archive project, based in San Francisco Paris French president Jacques Chirac instructed his government last week to come up with proposals for digitizing the collections of libraries in France and other European countries The first is that funding for public-domain projects could dry up, with library collections effectively being privatized by Google The Internet Archives annual administrative costs of about $2 million are met by grants from the US National Science Foundation, the Library of Congress, national archives such as those in Britain and France, and philanthropists such as the William and Flora Hewlett Foundation The third possibility, Kahle says, is that Google might collaborate successfully with the public-domain efforts There is now “fear, uncertainty and doubt” over this, says Kahle, with some libraries “waiting to see if they can get a handout from Google” instead
 A more general examination of the number of carbon atoms in the other, differently sized clusters that were found led to the gradual realization that they must all be carbon cages consisting of exactly 12 pentagons and a number of hexagons that grew with increasing cluster size As his end neared, Smalleys fourth wife Deborah and older son Chad cared for him constantly Because of the transatlantic conflict between the experimentalists over the exact name of the ball and the sport it belonged to — and because the structure was reminiscent of the geodesic domes of the architect Buckminster Fuller — the C 60 structure was named buckminsterfullerene Between 1993 and 2005, Smalley found a generally better way of making the tubes, as well as ways of cutting them up, performing chemical reactions on them and producing them in solution Each new project was better than the last, offering further valuable scientific information Efforts in Smalleys laboratory to make a macroscopic sample of buckminsterfullerene were abandoned fairly quickly after experiments to vaporize a graphite rod using a laser left no trace of C 60  Everyone got along amiably, both former wives seeming to have a wonderful time He always tackled the most challenging problems, was indefatigable in the pursuit of answers, and in all arguments met logic with logic He demonstrated that the method greatly simplified the complex spectra of the molecules energy levels, and allowed complexes bound together by very weak van der Waals interactions to be created and observed He had become fascinated by the prospect that fullerenes — the massive carbon molecules with distinctive geometrical shapes that he had co-discovered in 1985 — might be re-formed into single-walled nanotubes with exciting properties He had two sons almost thirty years different in age, and four wives — the first two of whom were his guests at the Nobel ceremony in 1996 (when he himself was single) In his early career as an independent researcher, he had tended to create a new research field about every two years, often abandoning them with equal frequency In March 1984, the British chemist Harry Kroto, whose radio astronomy observations had detected long carbon-chain compounds in interstellar clouds, visited Rice In particular, he dreamt of making a metallically conducting cable of billions of these carbon nanotubes, which, for the same weight, would be many times stronger than steel In the last week of his life, desperately ill with leukaemia, he was enthusiastically receiving progress reports in his hospital bed and suggesting new ideas and experiments In this, Smalley was studying jet-cooled molecular clusters formed by the condensation of laser-vaporized metals or semiconductors Kroto saw the vaporizing graphite in Smalleys apparatus as a way of testing his idea that these chains were being formed by the condensation of species ejected from carbon-rich stars On arriving, in 1976, at Rice University in Houston, Texas — where he was to stay for the rest of his career — he rapidly created a series of spectroscopic tools based on this technique that are used to this day Others usually found it to their advantage to follow his lead, as collaboration with Smalley generally resulted in excellent scientific results Rick Smalley was a remarkable person, both professionally and personally Smalley had a whimsical sense of humour and tremendous personal charisma Smalley reinvestigated the laser vaporization technique, and found that the amount of C 60 produced depended strongly on the temperature of the wall of the quartz tube that surrounded the graphite rod: no C 60 was obtained when it was at room temperature, but there was a 20% yield at 1,100 °C Smalleys ability to vacuum up information, organize it and use it for creative scientific endeavour was prodigious Smalleys approach was to conceive a way to investigate a chemical system or phenomenon, construct the necessary sophisticated apparatus, do enough work to show the true potential of the method, and move on Smalleys persuasiveness came most effectively to bear in the campaign to convince the US government to create its National Nanotechnology Initiative, a great achievement in public policy. Smalleys time ran out before he achieved that goal; nevertheless, the legacy of this research already extends far beyond the confines of materials science, to such diverse fields as energy technology and medicine Soon Smalley found that, by impregnating these metals into the graphite rods used to make C 60 in the laser vaporization experiments, he could create SWNTs in the form of ropes containing more than a hundred individual tubes The development of synthesis techniques for SWNTs was a challenge unlike anything Smalley had encountered before 1990, and virtually all that was known was the need for a metal catalyst — iron, cobalt or nickel The discovery of the fullerenes, which led to his Nobel Prize in Chemistry in 1996, grew out of one such project The experiments also showed striking evidence that more interesting, much larger carbon clusters of between 40 and 80 atoms were being formed simultaneously The isolation in 1990 of a mixture of C 60 and C 70 , using an apparatus consisting of a carbon arc inside a bell jar, seemed ridiculously simple compared with Smalleys high-tech approach The isolation of single-walled carbon nanotubes (SWNTs), announced in June 1993, soon drove Smalleys attention and considerable powers to another domain The particularly high abundance of the C 60 cluster could only be explained if it were a stable, closed cage with 20 hexagonal and 12 pentagonal interlocking faces, rather like a football, or soccer ball The single-minded obsession that Smalley, who died on 28 October, brought to nanotube research was in fact rather out of character The tenor of this period was set in postdoctoral work at the University of Chicago, where he pioneered a technique that combined laser excitation of molecules with their cooling by supersonic jets of gas Towards the end of his life, Richard Smalley had begun to say, “If it aint tubes, we dont do it” When the experiments were finally performed at the facility in September 1985, proof for the formation of carbon chains between 7 and 12 atoms long, the size range of the astronomical observations, was indeed found
 50 YEARS AGO OBITUARY — Prof Albert Einstein Andrew Carnegie the gift of the full-sized model of the skeleton of the gigantic American dinosaur known as Diplodocus carnegii , which has been mounted in the reptile gallery of the Natural History Branch of the British Museum.. But it was clear in the discussion which followed that many German-speaking men of science were not yet converted to his ideas.. Einstein remained smilingly unperturbed and said he was prepared to stand or fall by the results of an empirical examination of his predictions From Nature 25 May 1905. He had not very long to wait, for when I translated his popular work on “Relativity” in 1920, I suggested to him that he might like to include an appendix on the experimental confirmation of the theory.. His first comments in Britain on the results of the solar eclipse expeditions were published at the request of The Times .. His world-wide and unsought fame undoubtedly reached its zenith with the confirmation of his predicted gravitational deflexion of light rays by Eddington and others in 1919.. I should like to utilize the favourable circumstances to contribute as much as possible towards the reconciliation of German and English colleagues.”  Robert W It is almost an appalling thought that the skeleton of a creature which lived at least several million years ago should have come down in such a marvellous preservation to our own day Lawson From Nature 28 May 1955. 100 YEARS AGO On Friday, May 12.. Lord Avebury, on behalf of his fellow trustees, received from Mr My first contact with Einstein was in Vienna in September 1913... he lectured to the Physics Section on “Gravitation”, and his lecture quite obviously impressed most of his hearers as the work of a master-mind Referring to this in a letter to me, he wrote: “It cannot do any harm, for, thank God, the solar eclipse and the theory of relativity have nothing in common with politics..
 Downregulation of CckA activity therefore results in the dephosphorylation and degradation of CtrA, which in turn allow the initiation of DNA replication Furthermore, we show that CtrA triggers its own destruction by promoting cell division and inducing synthesis of the essential regulator DivK, which feeds back to downregulate CckA immediately before S phase Here we identify ChpT, an essential histidine phosphotransferase that controls the activity of CtrA, the master cell cycle regulator How bacteria regulate cell cycle progression at a molecular level is a fundamental but poorly understood problem In Caulobacter crescentus , two-component signal transduction proteins are crucial for cell cycle regulation, but the connectivity of regulators involved has remained elusive and key factors are unidentified Our results define a single integrated circuit whose components and connectivity can account for the cell cycle oscillations of CtrA in Caulobacter . We show that the essential histidine kinase CckA initiates two phosphorelays, each requiring ChpT, which lead to the phosphorylation and stabilization of CtrA Briefly, equal numbers of cells were labelled for 10 min with [ 32 P]H 3 PO 4 , lysed, and immunoprecipitated with anti-CtrA or anti-CckA serum For detailed methods, including growth conditions and strain construction, see Supplementary Information, Note 3 . For measurements of CtrA and CtrA˜P levels in the chpT depletion strain, cells were grown in the presence of xylose which produces a mild cell cycle phenotype ( Fig. 2 , Supplementary Fig. 3 ), but avoids the potential confounding effects of cell death during growth in glucose ( Fig. 2a ) For phosphorelay reconstitutions ( Fig. 1b, e ), reactions were initiated by the addition of [γ- 32 P]ATP, incubated for 5 min, and analysed by SDS–PAGE (SDS–polyacrylamide gel electrophoresis) and phosphorimaging Measurements of CtrA and CckA phosphorylation in vivo were performed as described  Methods Protein purifications, in vitro phosphorylation experiments, and phosphotransfer profiling were performed as described  Samples were analysed by SDS–PAGE and band intensities quantified by phosphorimaging Values per cell were obtained by normalizing to relative cell size A cold-sensitive, loss-of-function mutation in divK ( divK cs ) causes cells to arrest in G1 at the restrictive temperature  Accordingly, cell division should be essential for DivK˜P to trigger the delocalization of CckA in a new stalked cell After the shift, cells from the chpT depletion strain became filamentous, in a manner strikingly similar to ctrA ts and cckA ts strains grown at the restrictive temperature ( Fig. 2b ) Although cckA , chpT , ctrA and divK are each essential for cell cycle progression, divJ and divJ pleC mutants are viable, albeit with severe phenotypes (see Supplementary Fig. 12a–d ), indicating that other factors might regulate DivK Although many of the components of this cell cycle circuit were previously known, their connectivity had remained elusive Although the cell cycle of eukaryotes has been described in molecular detail, the bacterial cell cycle remains poorly understood Analysis of CckA–GFP localization in pleC::Tn5 and Δ divJ strains confirmed these predictions ( Fig. 3b, c ) Another essential cell cycle regulator in Caulobacter is the single-domain response regulator DivK  As CtrA is necessary for cell division , it ultimately helps to trigger feedback inhibition of itself through DivK As CtrA˜P accumulates, it triggers the expression of several genes that are required for late stages of the cell cycle, including divK and the essential cell division genes ftsQ and ftsA  As histidine kinases exhibit a kinetic preference in vitro for their in vivo cognate substrates, this technique allows the rapid identification of targets for a given kinase  As the delocalization of CckA is correlated with the G1–S transition, we asked whether DivK was required for this delocalization and hence for the onset of S phase As the swarmer cell develops, DivJ replaces PleC at the newly formed stalked pole , DivK˜P accumulates, and CckA is delocalized and inactivated As with the stalked cell, these steps allow the initiation of DNA replication, the expression of gcrA , and a resetting of the cell cycle At earlier time points CckA-HK transferred only to PetR (CC2931) and CckA-RD (see Supplementary Fig. 1a ) At the G1–S transition, CtrA˜P is dephosphorylated and degraded, thereby freeing the origin and permitting the initiation of DNA replication  At the heart of this circuit is a negative feedback loop from CtrA to DivK and then back to CtrA, via CckA ( Fig. 4c ) Both proteolysis and dephosphorylation of CtrA occur at the G1–S transition and in the stalked compartment of the predivisional cell, just before cell separation  But it is unclear how this difference in DivK˜P levels in the daughter cells is translated into a difference in CtrA activity and in cell cycle position By contrast, the swarmer cell inherits PleC and dephosphorylates its pool of DivK Caulobacter is easily synchronized and follows a pattern of once-and-only-once replication so that the G1, S and G2 phases are temporally distinguished, as in eukaryotes CckA is dynamically localized in a pattern that parallels its in vivo kinase activity, which might indicate that CckA is active when localized to polar regions  CckA is localized to the swarmer pole and is active in early G1 cells, is delocalized and downregulated before the G1–S transition, and then is bipolarly localized and phosphorylated in the predivisional cell ( Fig. 4b ) CckA is then delocalized first in the stalked progeny, which enters S phase first (see Supplementary Figs 5, 9 ) Cell cycle regulation in Caulobacter relies on two-component signal transduction systems, comprising histidine kinases and their response regulator substrates  Cell division partitions DivJ and PleC into separate compartments—the stalked and swarmer cells, respectively  Cells that overproduce DivK showed delocalization of CckA–GFP, a dramatic decrease in CtrA˜P ( Fig. 3b–d ), and a terminal phenotype similar to ctrA ts strains Cells that synthesize CtrA(D51E)Δ3Ω, a version of CtrA that cannot be proteolysed and that mimics the phosphorylated state, arrest in G1 because CtrA activity must be temporarily eliminated to allow DNA replication ChpT had a single, highly preferred substrate, the CckA receiver domain ( Fig. 1c ), indicating that CckA is the only input to ChpT ChpT mediates a phosphorelay from CckA to CtrA Hybrid kinases, such as CckA, can directly phosphorylate a response regulator or initiate a phosphorelay in which a phosphoryl group is passed intramolecularly to the kinase’s own receiver domain, then to a histidine phosphotransferase (HPT), and finally to a soluble response regulator Clearing CtrA from the cell also leads to the synthesis of GcrA, which accumulates and triggers de novo transcription of ctrA  Consequently, CtrA is dephosphorylated and degraded, permitting another round of DNA replication and expression of the CtrA-repressed gene gcrA  Consequently, the two phosphorelays identified here (CckA–ChpT–CtrA and CckA–ChpT–CpdR) lead to CtrA phosphorylation and its protection from proteolysis Table 1 ) Conversely, Δ divJ cells, which contain reduced levels of DivK˜P, should have CckA localized mainly to a single pole CtrA directly activates divK expression late in the cell cycle  CtrA helps to activate cell division in predivisional cells , but cell division is delayed until after DNA replication and chromosome segregation have finished CtrA protein was present at roughly twofold lower levels in the chpT depletion strain than in the wild type ( Fig. 2c ) Detailed time courses showed that ChpT˜P transferred phosphate to these regulators at approximately equal rates (see Supplementary Fig. 1b ) Discussion Our data establish an integrated molecular-level model of a regulatory network that accounts for Caulobacter cell cycle oscillations and the ability of a single cell to produce daughter cells committed to different cell cycle phases ( Fig. 4 ) DivJ, the primary kinase for DivK, is located at the stalked pole whereas PleC, a phosphatase for DivK˜P, resides at the swarmer pole  DivK feeds back to control CckA The CckA–ChpT–CtrA phosphorelay culminates in the phosphorylation of CtrA and its activation as a transcription factor DivK has also been implicated in controlling cellular asymmetry and differentiation DivK is present throughout the cell cycle but increases in abundance late in the cell cycle , coincident with the peak in transcription Either nonlinearities or a time delay is also essential  For instance, the core oscillating machinery in Caulobacter involves a master regulator, CtrA, whose activity accumulates during the cell cycle Genome sequencing projects have shown that the main regulators of the eukaryotic cell cycle, such as cyclin-dependent kinases, are not found in bacteria Given our evidence that these events are controlled simultaneously by CckA and ChpT, we hypothesized that DivK does not control CtrA directly, but rather inhibits the activity of CckA Here, we use a combination of biochemical, genetic and cell biological assays to map the connectivity of a regulatory network comprising two-component signalling proteins that can account for cell cycle oscillations in Caulobacter  How then do bacteria regulate cell cycle progression, and is the logic of the underlying regulatory circuit similar despite the use of different molecules? The bacterium Caulobacter crescentus is an attractive model for examining cell cycle regulation in bacteria  However, cells that constitutively transcribe ctrA still proceed through the cell cycle, indicating that transcriptional control of ctrA is not strictly necessary  However, CtrA phosphorylation was even lower, dropping below the level of detection in the P xyl – chpT strain ( Fig. 2c ) However, negative feedback alone is insufficient to produce oscillations However, no model has emerged to suggest how DivK regulates both proteolysis and dephosphorylation of CtrA However, the essential response regulator DivK has also been implicated in controlling these two processes However, the precise biochemical connectivity of these proteins is unknown However, when shifted to 37 °C, most cells (70%) showed delocalization of CckA–GFP within 20 min, and 100% of these then divided within 120 min (see Supplementary Fig. 7 ) However, when shifted to the restrictive temperature (24 °C) to induce G1-arrest , the divK cs culture showed a marked increase in cells with a single bright focus of CckA–GFP at the stalked pole ( Fig. 3b, c ) HPTs are difficult to identify by sequence homology as they require conservation of only a small number of crucial residues, and none were predicted in the original annotation of the Caulobacter genome  If so, constitutive expression of divK should disrupt normal cell cycle oscillations by causing the inappropriate downregulation of CtrA Imposing this criterion yielded a single candidate, CC3470, which we name chpT for cell cycle histidine phosphotransferase (see Supplementary Fig. 2 ) In a 5-min incubation, the kinase domain of CckA (CckA-HK) did not transfer phosphate to CtrA, but it did transfer phosphate to four other response regulators ( Fig. 1a ), including its own receiver domain (CckA-RD) In a mixed population of divK cs cells at the permissive temperature (37 °C), the pattern of CckA–GFP localization was similar to that of wild-type cells ( Fig. 3b, c , Supplementary Fig. 6 ) In eukaryotes, an analogous regulatory strategy is employed where the activity of cyclin-dependent kinase accumulates during the cell cycle, ultimately triggering its own destruction  In G1 cells, CtrA is present and phosphorylated (CtrA˜P), enabling it to bind and silence the origin of replication  In our model, the accumulation of active DivK˜P in the stalked progeny depends on cell division, introducing a time delay into the feedback loop In predivisional cells, CtrA˜P drives the expression of more than 50 genes, many of which are required for completing the cell cycle  In stalked and predivisional cells, CckA is active and localized to both cell poles In this case ChpT˜P efficiently phosphorylated two response regulators, CtrA and CpdR ( Fig. 1d ) Incubation of purified CckA-HK, CckA-RD, ChpT and CtrA with [γ- 32 P]ATP led to accumulation of radiolabel in CtrA ( Fig. 1b ) Inhibiting cell division was sufficient to prevent the downregulation of CckA and CtrA, indicating that cell division is the key time delay, but the temporal dynamics of the circuit must now be dissected in more detail Instead, regulation of CtrA activity by either temporally controlled phosphorylation or proteolysis is required to drive cell cycle progression  Many two-component signalling genes have been identified in genetic screens for cell cycle regulators  Mapping the connectivity of the Caulobacter cell cycle regulatory network now allows us to compare it to that of eukaryotes at the level of regulatory architecture Moreover, each cell division in Caulobacter is asymmetric and produces daughter cells—stalked and swarmer cells—that are committed to different stages of the cell cycle Moreover, the autophosphorylation of CckA is cell cycle-regulated and correlates with the protein’s polar localization , but factors that influence CckA activity have not been identified Most cells overproducing CtrA(D51E)Δ3Ω showed delocalization of CckA from the stalked pole ( Fig. 3b, c ) Next, we examined the effect of DivK on the subcellular localization of CckA (see Supplementary Note 2 ) Next, we profiled ChpT˜P against each of the 44 purified, soluble Caulobacter response regulators No single, coherent model had been produced to explain the rise and fall of CtrA activity, only its changes in transcription  Once cell division occurs, DivK˜P can trigger the rapid turnover of CtrA and entry to S phase in the stalked cell Our data show that CtrA triggers its own destruction by inducing divK transcription and cell division, which ultimately enable DivK˜P to feedback and inhibit CckA and CtrA Our model predicts that cells lacking PleC ( pleC::Tn5 ), which contain elevated levels of DivK˜P, should show reduced polar localization of CckA Our results therefore show that two phosphorelays, both stemming from CckA and ChpT, simultaneously regulate the phosphorylation and proteolysis of CtrA Phosphorylation of DivK increases during the G1–S transition , and immediately after cell division DivK is phosphorylated at higher levels in the new stalked cell than in the new swarmer cell  PleC is a phosphatase for DivK, whereas DivJ is the primary kinase  Recent work has also shown that two separable but interlinked oscillating circuits control yeast cell cycle progression  Relative to the wild type, divK cs cells contained ∼1.8-fold more CckA˜P per cell at the permissive temperature, and at least fourfold more CckA˜P at the restrictive temperature ( Fig. 3a ) Restoring ftsZ expression after prolonged depletion restored cell division and delocalization of CckA–GFP (see Supplementary Fig. 9 ) Septum formation and cell division therefore produce daughter cells with different levels of DivK˜P, with higher levels in the stalked cell than in the swarmer cell  Such similarity in phylogenetically distant organisms could indicate that this regulatory architecture confers a strong selective advantage, regardless of the molecules used to implement it. The CckA–ChpT–CpdR phosphorelay culminates in the phosphorylation of CpdR, which prevents CpdR from triggering the proteolysis of CtrA (see Supplementary Information Note 1 , Supplementary Fig. 4 ) The cold-sensitive mutant divK341cs ( divK cs ) arrests in G1 when incubated at the restrictive temperature The constitutive localization of CckA in divK cs cells is therefore not a consequence of G1-arrest, but is specifically due to the loss of DivK function The histidine kinase CckA is required in vivo for the phosphorylation of CtrA , but a direct biochemical link between the two has not been shown The initial synthesis of CtrA leads to positive transcriptional autoregulation and a burst of CtrA synthesis in late stalked cells  The late induction of divK by CtrA might help to ensure that DivK does not accumulate to high levels and inhibit CckA during early stages of the cell cycle The lower levels of DivK˜P allow CckA to remain localized and active, which stabilizes CtrA˜P levels and blocks DNA replication initiation The master regulator of the Caulobacter cell cycle is CtrA, an essential response regulator whose activity as a transcription factor varies as a function of the cell cycle  The multiple feedback loops present in the Caulobacter cell cycle circuit indicate that bacteria might also have evolved separate but interlaced oscillators ( Fig. 4c ) The newly synthesized CtrA is phosphorylated and is not immediately subject to proteolysis The order of phosphotransfer was determined by omitting individual components ( Fig. 1b ) The primary DivK kinase (DivJ) and phosphatase (PleC) are located at opposite ends of the predivisional cell such that daughter cells inherit one or the other  The reciprocal regulation of CtrA and GcrA at a transcriptional level has been suggested to form an oscillating genetic circuit that drives the cell cycle  The similarity between this phenotype and that of cells that synthesize CtrA(D51E)Δ3Ω indicates that DivK might somehow promote both the proteolysis and dephosphorylation of CtrA in preparation for DNA replication The stalked cell inherits DivJ, but not PleC, and can therefore accumulate phosphorylated DivK The strain bearing P divK – divK was similar to the wild type, whereas the strain bearing P xyl – divK had a severe cell cycle defect, similar to that seen in ctrA ts strains (see Supplementary Fig. 10b–d ) The time needed to complete cell division thus enables CtrA to accumulate and persist at high levels in predivisional cells These criteria yielded more than 50 genes These data confirmed the existence of a CckA–ChpT–CtrA phosphorelay and identified a second phosphorelay with shared components, leading from CckA to ChpT to CpdR ( Fig. 1e ) These data further support the conclusion that DivK˜P feeds back to downregulate CtrA These differences from the wild type are probably due to substitution of the native chpT promoter with P xyl  These in vitro data confirm a phosphorelay in which CckA-HK autophosphorylates and then passes a phosphoryl group intramolecularly to CckA-RD, then to ChpT, and finally to CtrA These observations indicate that the CtrA-dependent transcription of divK , which occurs only late in the cell cycle, after CtrA has accumulated to high levels, helps to ensure the proper timing of DivK-mediated feedback on CtrA These results support the conclusion that cell division is required to activate the DivK-dependent feedback inhibition of CckA and CtrA These results support the conclusion that DivK˜P causes the delocalization and inactivation of CckA and hence the inactivation of CtrA, which is required for the G1–S transition These strains produce approximately equal levels of DivK (see Supplementary Fig. 10a ), so the only difference is the promoter driving divK  This DivK˜P triggers the delocalization and downregulation of CckA, thereby preventing the phosphorylation of CtrA and CpdR This eventually triggers new synthesis of CtrA and, hence, resets the cell cycle  This indicates that DivK is required to inactivate CckA at the G1–S transition This indicates that phosphorylated DivK (DivK˜P) might trigger the delocalization or inactivation of CckA This phenotype depended on the presence of DivJ (see Supplementary Fig. 11b ) This phenotype is also seen in cells expressing ctrA(D51E)Δ3Ω , the constitutively active allele of ctrA , which might indicate that DivK is normally required to trigger CtrA dephosphorylation and degradation at the G1–S transition  This strain doubled every 150 min in rich medium containing xylose ( Fig. 2a ; wild-type doubling time was 90 min), and individual cells grown in xylose were elongated ( Fig. 2b ) To confirm the existence of a CckA–ChpT–CtrA pathway, we measured levels of CtrA protein and phosphorylation in vivo in the chpT depletion strain To determine the effects of chpT depletion, we constructed a strain in which the only copy of chpT is under the control of P xyl , a xylose-inducible promoter  To determine whether CckA and CtrA are the exclusive partners of ChpT, we used phosphotransfer profiling  To ensure that the effect of divK cs on CckA localization was not a non-specific consequence of the G1-arrested state, we examined CckA–GFP localization in a strain that overproduces CtrA(D51E)Δ3Ω, which induces a G1-arrest independent of CckA  To identify putative HPTs for the CtrA pathway, we searched the Caulobacter genome for predicted proteins that shared the following characteristics of known HPTs: (1) 250 amino acids in length; (2) 70% α-helical; and (3) a histidine residue within a predicted α-helix To test this hypothesis, we examined the effect of blocking cell division on the dynamics of CckA–GFP localization To test this hypothesis, we measured the level of CckA˜P in vivo in wild-type and divK cs cells To test this, we generated strains in which the only copy of divK is expressed from a low-copy plasmid under the control of either its native, CtrA-regulated promoter, P divK , or a constitutive promoter, P xyl  To test whether CckA phosphorylates CtrA directly, we used phosphotransfer profiling in which a purified kinase domain is tested, in parallel, for phosphotransfer to each of the 44 purified response regulators from Caulobacter  Together, these data show that depletion of chpT produces a phenotype similar to ctrA and cckA mutants, supporting the conclusion that chpT encodes an HPT that lies between CckA and CtrA Two CckA/ChpT-dependent phosphorelays To prove that CckA–ChpT–CtrA comprises a phosphorelay, we examined phosphotransfer relationships among purified components of the pathway in vitro  Using time-lapse microscopy to examine individual cells, we found that divK cs cells maintained at 24 °C continued to grow, but never lost polar localization of CckA–GFP and never divided (see Supplementary Fig. 7 ) Using whole-genome DNA microarrays, we found that the global pattern of gene expression in the chpT depletion strain was highly correlated with the expression patterns seen in ctrA ts and cckA ts strains (see Supplementary Table 2 , Supplementary Fig. 3 ) We also found that expressing divK at higher levels completely disrupted cell cycle progression (see Supplementary Fig. 11a–d ) We also showed that CtrA˜P levels were elevated in a divK cs strain, but significantly reduced in pleC::Tn5 ( Fig. 3d ), whereas a recent study showed that CtrA˜P levels increase in a Δ divJ mutant  We conclude that CtrA is not phosphorylated directly by CckA-HK, and that a phosphorelay probably leads from CckA to CtrA through an unknown HPT We first examined the ability of ChpT˜P to transfer phosphate to the purified receiver domains from each of the 27 hybrid histidine kinases encoded in the Caulobacter genome We further predicted that an HPT that mediated a phosphorelay from CckA to CtrA should be present only in organisms that also contain orthologues of cckA and ctrA  We predicted that an HPT that connected the essential signalling proteins CckA and CtrA would also be essential for viability We propose that the integrated network identified here forms the basis of an oscillatory circuit that underlies cell cycle progression in Caulobacter ( Fig. 4a ) When shifted to medium containing glucose, which represses P xyl , the chpT depletion strain began to lose viability within 2–3 h ( Fig. 2a ), supporting the conclusion that chpT is an essential gene When stalked cells were depleted of the essential cell division protein FtsZ , CckA–GFP remained localized at the pole for extended periods of time (see Supplementary Fig. 8 ) Whether PetR is a target of CckA in vivo remains to be shown
 A numerical perspective on Nature authors At Technion, the Israel Institute of Technology in Haifa, Moti Segev runs a nonlinear optics group that puts light to work in novel ways He provides guidance and advice every day, but team members present the results of their own projects at conferences and take lead authorship on publications Segev gives each member of his team a well-defined project to lead Segevs guiding principle is to nurture original ideas, because ideas that are extensions of known ideas will be pursued by other, larger, groups This system is noteworthy because light passing through the ten-fold symmetrical structure changes the crystals properties, and these changes then affect the light refracting from the crystal (see page 1166 ). 185 citations have been made to the 2003 Nature paper written by Segevs group on solitons in photonic lattices. 13 researchers working in Israel have reviewed papers submitted to Nature since January 2006 (1% of all reviewers). 157 submissions to Nature in the past year have been made from Israel (12% of all submissions). 12% of submissions to Nature from Israel in the past year were made by researchers at the Technion. This week, the group presents the first ever nonlinear photonic quasi-crystal
 But did their patterns of communication differ from those associated with the instant-access e-mail of modern times? Here we show that, although the means have changed, the communication dynamics have not: Darwins and Einsteins patterns of correspondence and todays electronic exchanges follow the same scaling laws However, the response times of their surface-mail communication is described by a different scaling exponent from e-mail communication, providing evidence for a new class of phenomena in human dynamics. In an era when letters were the main means of exchanging scientific ideas and results, Charles Darwin (1809–82) and Albert Einstein (1879–1955) were notably prolific correspondents Although, on average, they wrote 0.59 (Darwin) and 1.02 (Einstein) letters a day during the last 30 years of their lives, these averages hide significant daily fluctuations As shown in Fig. 1b,c, the probability that a letter will be replied to in τ  days is well approximated by a power law, P ( τ )≈ τ  −α , where α =3/2 But our results indicate that Darwins and Einsteins late responses or resumed correspondences are not singularities or exceptions: they are part of a universal scaling law , representing a fundamental pattern of human dynamics that the famous are no better at escaping than the less distinguished. During their lifetimes, Darwin sent at least 7,591 letters and received 6,530; Einstein sent more than 14,500 and received more than 16,200 Each letter is assigned a priority, with high-priority letters being answered soon after their arrival, and others having to wait Encouraged by this, Kaluza published his famous paper on five-dimensional unified field theory , a key component of todays string theory For example, Darwin wrote 12 letters on New Years Day in 1874 and Einstein received 120 letters on 14 March 1949, his 70th birthday For example, on 14 October 1921 Einstein returned to a correspondence with Theodor Kaluza that he had left off two years earlier, when he discouraged Kaluza from publishing one of his papers: having second thoughts, he recommended that the paper be submitted Given that Darwin and Einstein answered only a fraction of letters they received (their overall response rate being 0.32 and 0.24, respectively), we have λ µ  In some cases, however, the correspondence was stalled for months or years Numerical simulations (see supplementary information ) indicate that in this supercritical regime the waiting-time distribution of the responded letters also follows a power law with exponent α =3/2, which is different from the α =1 obtained for e-mail communications  Occasional delays were not always without consequence Others, however, correspond to genuine delays, like Einsteins response on 14 October 1921 to Ralph De Laer Kronigs letter of 26 September 1920, which starts with: “In the course of eating myself through a mountain of correspondence I find your interesting letter from September of last year.”  To understand the origin of the observed scaling behaviour, we have to realize that, given the wide range of response times, both Darwin and Einstein must have prioritized correspondence in need of a response Some of these represent long breaks in the correspondence and a few are a consequence of missing letters The correspondence patterns of Einstein and Darwin are examples of well mapped patterns of human interaction, but are also of historical interest The fact that the scaling spans close to four orders of magnitude, from days to years, indicates that most responses (53% for Einstein, 63% for Darwin) were sent within less than ten days The response time, τ , represents the time interval between the date a letter was received and the date that the reply was sent The waiting-time distribution of this simple model follows P ( τ )≈ τ  −3/2 exp(− τ/τ  0 ), which predicts a power-law waiting time for the critical regime λ = µ , when τ  0 =∞ Their correspondence exploded after their rise to fame, and reached a highly fluctuating pattern afterwards ( Fig. 1a ) Their timely responses to most letters show that they were both aware of the importance of this intellectual intercourse Therefore, although the response times in e-mail and mail communications follow the same scaling law, they belong to different universality classes This places the model in the supercritical regime, where a finite fraction of letters are never answered Thus, a simple model of their correspondence assumes that letters arrive at a rate λ and are answered at a rate µ  We start from a record containing the sender, recipient and the date of each letter sent or received by the two scientists Would it have changed the course of science if Einstein had not wavered for two years? We shall never know
 Because it weighs little, responds instantaneously and has no need of heating, this miniaturized electron source should prove valuable for microwave devices used in telecommunications. Here we describe a microwave diode that uses a cold-cathode electron source consisting of carbon nanotubes and that operates at high frequency and at high current densities To communicate, spacecraft and satellites rely on microwave devices, which at present are based on relatively inefficient thermionic electron sources that require heating and cannot be switched on instantaneously A spectrum analyser connected to the output antenna confirmed the presence of the fundamental 1.5-GHz peak in the cavity Arrays of vertically aligned carbon nanotubes were integrated on a coaxial post in a resonant cavity As the cavity walls and emitters are grounded, the radiofrequency electric field exists only inside the cavity, as shown in the equivalent electrical circuit in Fig. 1c  Because of their small size, and ability to generate and modulate the beam directly and on demand without the need for high temperatures, carbon-nanotube cathodes hold promise for a new generation of lightweight, efficient and compact microwave devices for telecommunications in satellites or spacecraft. Carbon-nanotube emitters are robust and do not suffer from electromigration because of their strong C–C covalent bonding Each cathode has an active area of 0.5×0.5 mm 2 (or 2,500 carbon nanotubes) and 16 cathodes can be created simultaneously ( Fig. 1b , inset) In contrast, carbon-nanotube cold cathodes that have a vacuum gap to a stand-off grid or anode of a few hundred micrometres or less, as we describe here, have low capacitances and can be operated at very high frequencies (for example, 32-GHz modulation of carbon-nanotube emitters has been achieved from a microwave diode and triode; L.H. et al ., manuscript in preparation) In the device simulation shown in Fig. 1a , radiofrequency electromagnetic radiation at the input induces a high, oscillating electric field at the end of the coaxial post; this electric field is further amplified by the carbon-nanotube array (for details, see supplementary information ) In this study, cathodes were operated at 1 mA and 1.5 GHz for 40 h without degradation or a decrease in current output (within the measurement error of 5%) Metal emitters, on the other hand, often fail owing to field-induced sharpening, which leads to thermal runaway of the emitters Our carbon-nanotube cathode already delivers average- and peak-current densities that are similar to those used in present-day microwave transmission devices The ability directly to generate or modulate an electron beam at high current density and gigahertz frequencies from carbon nanotubes is an important technological advance The carbon-nanotube array ( Fig. 1b ) consists of uniform individual carbon nanotubes spaced at a distance corresponding to roughly twice their height in order to minimize electrostatic-field shielding from adjacent emitters  The device was operated at 1.5 GHz using various radiofrequency-input powers to generate different macroscopic electric fields at the array of carbon-nanotube emitters Thermionic sources used in todays microwave devices are operated by direct current or at low frequency; their electron beam is usually modulated downstream in an extended interaction line, leading to physically long devices They can therefore be used directly as the input stage of a microwave amplifier This corresponds to a peak current of 30 mA and a current density of 12 A cm −2 in the output waveform (see supplementary information ) We constructed a microwave diode in which the carbon-nanotube field-emission source was directly driven at gigahertz (GHz) frequencies With an applied radiofrequency electric field of 29 megavolts per metre, the output at the anode reaches 3.2 mA, with an average current density of 1.3 A cm −2 ( Fig. 1d )
 Electrical current can be completely spin polarized in a class of materials known as half-metals, as a result of the coexistence of metallic nature for electrons with one spin orientation and insulating nature for electrons with the other Here we predict half-metallicity in nanometre-scale graphene ribbons by using first-principles calculations However, organic materials have hardly been investigated in this context even though carbon-based nanostructures hold significant promise for future electronic devices  In view of the potential for use of this property in realizing spin-based electronics, substantial efforts have been made to search for half-metallic materials  Such asymmetric electronic states for the different spins have been predicted for some ferromagnetic metals—for example, the Heusler compounds —and were first observed in a manganese perovskite  The results are not only of scientific interest in the interplay between electric fields and electronic spin degree of freedom in solids but may also open a new path to explore spintronics at the nanometre scale, based on graphene . We show that this phenomenon is realizable if in-plane homogeneous electric fields are applied across the zigzag-shaped edges of the graphene nanoribbons, and that their magnetic properties can be controlled by the external electric fields A periodic saw-tooth-type potential perpendicular to the direction of the ribbon edge is used to simulate the external electric fields ( E ext ) in a supercell ( Fig. 1 ) After gap closure, an electron channel near ka  = π and a hole channel near ka  = 0.75π appear at E F , all with the same spin direction Another consideration is that, when in the half-metallic state the ZGNRs are in a transverse electric field, the current-carrying electrons moving from the source to the drain in the longitudinal direction would experience an effective magnetic field due to spin–orbit interactions and the spins are expected to rotate At a critical electric field of 0.045 V Å -1 for a 32-ZGNR, the estimated energy for spin–orbit coupling due to E ext is only 1.1×10 -4  meV Because edges are inevitably susceptible to defects, we have examined the robustness of the predicted half-metallicity to edge defects Because oppositely oriented spin states are located at the opposite sides of the ZGNR, the effect of E ext on them is opposite, moving the occupied and unoccupied β-spin states closer in energy but moving the occupied and unoccupied α-spin states apart ( Fig. 3 ) Because the energy shifts of the edge states depend on the total voltage drop between the two sides, the variation of the energy gap is expected to exhibit a universal behaviour as a function of wE ext , where w is the width of the ZGNR Because the interaction between spins on opposite edges increases with decreasing width, the total energy of an n -ZGNR with antiferromagnetic arrangement across opposite edges is always lower than that of a ferromagnetic arrangement if n  ≤ 32 Because the states around E F are the edge states and linear combinations of them, the effects of external transverse fields are expected to be significant on these states, in contrast with those on the extended states  But the spinless state is not the ground state By invoking band ferromagnetism, it has been suggested that an opposite spin orientation across the ribbon between ferromagnetically ordered edge states on each edge in ZGNRs is the ground-state spin configuration; that is, the total spin is zero  Considering first the spin degree of freedom, we find as in previous studies that the configuration with opposite spin (antiferromagnetic) orientation between ferromagnetically ordered edge states at each edge ( Fig. 2b ) is favoured as the ground state over the configuration with same spin orientation between the two edges (The present result of antiferromagnetic spin configuration on the honeycomb lattice is consistent with a theorem for electrons on a bipartite lattice .) Our calculations show that the magnetic interaction energies are quite large Correspondingly, the energies for localized edge states on the right side are shifted upwards and those on the left side downwards, eventually leaving states of only one spin orientation at E F ( Fig. 3b ) For a 32-ZGNR whose width is 67.2 Å, E ext  = 0.045 V Å -1 is required to close the bandgap for the β-spin electrons ( Fig. 4 ) For example, the total energy difference between a spin-polarized edge and a spin-unpolarized one is 20 meV per edge atom for 8-ZGNR, and the spin configuration is further stabilized by 2.0 meV per edge atom as a result of the antiferromagnetic coupling between the spin-polarized edges For now, we label the gap-opening states as α-spin (shown in red in Figs 2 –  4 ) and the gap-narrowing states as β-spin (blue) From the calculations, the required critical field is estimated to be 3.0 (V)/ w  (Å) Hence, under these conditions, the half-metallic nature is robust even though a transverse electric field is applied, and spin-polarized current should be obtained in a transport experiment with split gates. Here we also expect that the spin orderings are realizable because of the large anisotropic exchange interactions between the spins in ribbons with split-gate geometry on the substrate However, the energy splitting at ka  = π is ∼0.52 eV, regardless of width, if n  ≥ 8 However, we find that the resulting extremely weak effective magnetic fields are parallel to the spatial spin direction ( z direction in Fig. 1 ) already determined by the intrinsic spin–orbit interactions of carbon atoms In a 16-ZGNR, the bandgap associated with β-spin is completely closed by an E ext of 0.1 V Å -1 , whereas the gap for α-spin electrons remains very large at 0.30 eV ( Fig. 2c ) In a 16-ZGNR, the occupied α states and unoccupied β-spin states on the left side move downwards in energy by 19 meV and 110 meV, respectively, and occupied β-spin and unoccupied α-spin states on the right side upwards by 112 meV and 74 meV, respectively, as E ext increases to 0.1 V Å -1 ( Fig. 3c ) In accordance with previous convention , the ZGNRs are classified by the number of zigzag chains ( n ; Fig. 1 ) forming the width of the ribbon It is known that spontaneous magnetic orderings in one-dimensional and two-dimensional spin lattice models are difficult to achieve at finite temperature  Moreover, the electronic structures of the ZGNRs show marked alterations when spins and E ext are included Our calculations show that the system remains purely of one spin type at E F in the presence of different types and concentrations of defects Our study of the spin-resolved electronic structure of ZGNRs is based on the ab initio pseudopotential density functional method within the local spin density approximation  Results on 8-ZGNRs with three different kinds of defect (dangling bonds, vacancies and Stone–Wales defects at 6–12% defect concentration per edge) are presented in Supplementary Fig. 1 , confirming that the predicted half-metallicity is indeed robust So, the spatial spin direction once determined would not change even if a strong transverse electric field were applied So, under appropriate field strengths, the ZGNRs are forced into a half-metallic state by the applied electric field, resulting in insulating behaviour for one spin and metallic behaviour for the other Spin correlation lengths comparable to nanometre-scale systems, however, are possible in practice  Such separate and opposite energy shifts are made possible by the localized nature of the edge states around E F  Such states have been observed in monoatomic step edges of graphite by using scanning probe techniques  Suppose that we have the β-spin electrons moving with velocity v  =  v ŷ in E  =  E ext ◯, the effective magnetic field exerted on the β-spin electrons would be , where ħ is the Planck constant, m is the mass of an electron, e is the charge on an electron, and c is the speed of light The electrostatic potential is raised on the right side and lowered on the left side as E ext (0) increases The energies of the occupied and unoccupied α-spin states in the middle also follow movements of those of the corresponding localized states on each side, resulting in an increased gap value ( Fig. 3c ) The energy gap for the β-spin electrons changes to an indirect gap from a direct gap as E ext increases, and is closed indirectly ( Fig. 2c , inset) The half-metallicity of the ZGNRs originates from the fact that the applied electric fields induce energy-level shifts of opposite signs for the spatially separated spin-ordered edge states The localized edge states form a twofold degenerate flat band at the Fermi energy ( E F ), existing in about one-third of the Brillouin zone away from the zone centre  The occupied β-spin states in the middle of a 16-ZGNR are the tails of the localized β-spin states on the right side and the unoccupied β-spin states are from the left side, so that occupied and unoccupied β-spin states in the middle of the ZGNR move oppositely to close the gap The states of opposite spin orientation are degenerate in all bands ( Fig. 2c , left) These edge states (which are extended along the edge direction) decay exponentially into the centre of the ribbon, with decay rates depending on their momentum  This implies that, if we change the direction of E ext , the spin polarity of the carriers at E F of the half-metallic ribbon will be reversed because the induced potentials at the edges change their signs This is seen in the inset in Fig. 4  This total energy hierarchy is maintained when external electric fields are applied Thus the small magnitude of spin–orbit interaction (4–6 meV) in carbon atoms would not change the half-metallic nature of the ZGNRs but would function in determining the spatial direction (normal direction with respect to the ribbon plane) of spin up and down in the ZGNRs  To establish half-metallicity, the relevant energy scale is given by the field-induced energy shift, and its magnitude is in the order of 100 meV We also find that, as a result of the energy gap asymmetry for each spin, there is no spin precession even when the direction of E ext is tilted or when the spatial spin direction is altered by spin–orbit interaction arising from the substrate We find that the ground state of the ZGNRs, including the spin degree of freedom, has a bandgap inversely proportional to the ribbon width We note that the critical electric field for achieving half-metallicity in ZGNRs decreases as the width increases because the electrostatic potential difference between the two edges is proportional to the system size We shall defer the discussion of spin–orbit interactions later We will hereafter refer to an ZGNR with n zigzag chains as an n -ZGNR When a single graphite layer is terminated by zigzag edges on both sides, which we refer here to as a zigzag graphene nanoribbon (ZGNR) ( Fig. 1 ), there are peculiar localized electronic states at each edge  When spins are included, the degeneracy between the occupied and unoccupied edge-state bands at E F is now lifted and the edge states near E F have dispersion along the direction of the edge with a bandwidth of ∼2 eV when extended over the Brillouin zone When the spin degree of freedom is neglected, our calculation from first principles also predicts a twofold degenerate flat band at E F ( Fig. 2a ) With applied transverse electric fields, we find that the valence and conduction edge-state bands associated with one spin orientation close their gap, whereas those associated with the other widen theirs ( Fig. 2c )
 A key mechanism to prevent inbreeding is self-incompatibility through rejection of incompatible (‘self’) pollen  Here we show that p26.1 comprises two proteins, Pr-p26.1a and Pr-p26.1b, which are soluble inorganic pyrophosphatases (sPPases) In higher plants, sexual reproduction involves interactions between pollen and pistil In Papaver rhoeas, S proteins encoded by the stigma interact with incompatible pollen, triggering a Ca 2+ -dependent signalling network resulting in pollen tube inhibition and programmed cell death  Reduced sPPase activity is predicted to result in the inhibition of many biosynthetic pathways, suggesting that there may be additional mechanisms of self-incompatibility-mediated pollen tube inhibition The cytosolic phosphoprotein p26.1, which has been identified in incompatible pollen, shows rapid, self-incompatibility-induced Ca 2+ -dependent hyperphosphorylation in vivo  These proteins have classic Mg 2+ -dependent sPPase activity, which is inhibited by Ca 2+ , and unexpectedly can be phosphorylated in vitro  We provide evidence that sPPases are required for growth and that self-incompatibility results in an increase in inorganic pyrophosphate, implying a functional role for Pr-p26.1. We show that phosphorylation inhibits sPPase activity, establishing a previously unknown mechanism for regulating eukaryotic sPPases Additional materials and methods, including cloning, antisera, western blotting, immunolocalization, transient expression using particle bombardment, imaging, His-tag affinity purification of recombinant proteins, phosphocolumn affinity purification, mass spectrometry are described in Supplementary Methods . Antisense oligonucleotide experiments A phosphorothioated antisense oligodeoxynucleotide (as-ODN) and its sense control (s-ODN) were designed to downregulate both genes (see Supplementary Methods for sequences) Details of determination of phosphorylated endogenous pollen sPPase activities are described in Supplementary Methods  For endogenous pollen and tissue sPPase activities, cytosolic extracts were assayed and are expressed as μmol Pi per mg total protein per min In vitro kinase reactions Pollen cytosolic extracts were phosphorylated in vitro by standard procedures ; phosphorylation of the recombinant Pr-p26.1a and Pr-p26.1b His-tagged proteins was carried out in the presence of cytosolic pollen protein extracts (see Supplementary Methods for full details). sPPase assays To determine recombinant sPPase activity, recombinant Pr-p26.1a and Pr-p26.1b aliquots were assayed for sPPase activity as described and are expressed as μmol Pi per mg Pr-p26.1a/Pr-p26.1b per min (μmol Pi mg -1  min -1 ) Methods Cytosolic protein extraction Cytosolic proteins were extracted from pollen and other tissues as described  Pollen was grown in vitro as described and treated with as-ODN and s-ODN as described (see Supplementary Methods for full details) PPi assays Pollen was grown in vitro and SI induced as described  PPi assays were carried out with a PPiPer pyrophosphate assay kit ( Molecular Probes ) in accordance with the manufacturer’s instructions (see Supplementary Methods for full details) Some pollen cytosolic extracts were phosphorylated in vitro and subjected to phosphocolumn purification (see Supplementary Methods ) Statistics Statistical tests were carried out with MINITAB Tests on most data were two-way comparisons between pairs of data using Student’s t -test Two-way analyses of variance were carried out on sPPase activity data from Fig. 2a, e  A possible explanation for the unusual cytosolic localization of these sPPases is that they are abundant in metabolically highly active cells A rapid increase in SI-specific phosphorylation of a cytosolic pollen protein, p26.1, in incompatible pollen undergoing SI in vivo , identified this protein as being involved in SI (ref. 3 ) Actin depolymerization will rapidly inhibit pollen tube growth, and programmed cell death will ensure that pollen tube growth does not resume Almost no sPPase activity was detected when Mg 2+ was chelated by EDTA Although examples of kinase-dependent phosphorylation of sPPases in prokaryotes exist , the only demonstration of phosphorylation of a eukaryotic sPPase has been in vitro ; thus, the biological significance of this modification is unknown Although several cytosolic sPPases have been cloned and characterized from plants , examples of these are rare; indeed, it has been stated that the plant cytosol lacks sPPases  Although their predicted molecular masses differ, the endogenous Pr-p26.1a and Pr-p26.1b proteins co-migrated on SDS polyacrylamide gel electrophoresis ( Fig. 1a ) As expected, both phosphorylated and non-phosphorylated forms of Pr-p26.1 showed Ca 2+ -dependent inhibition of sPPase activity ( Fig. 2e ), with a reduction in specific activity of 62.0 ± 1.5% and 59 ± 3.0%, respectively As p26.1 was identified through its SI-induced phosphorylation, we examined whether Pr-p26.1a and Pr-p26.1b isolated from pollen cytosol are phosphorylated by using a phosphocolumn to select phosphorylated proteins As the SI-stimulated phosphoprotein p26.1 was originally identified in cytosolic extracts , we fractionated pollen protein extracts to confirm its localization As we have shown here, sPPase modification also has a key functional role in SI by regulating pollen tube growth. At the amino acid level, Pr-p26.1a and Pr-p26.1b have 78% identity Because pollen tubes require high metabolic activity for extensive biosynthesis, which will release PPi, the inhibition of sPPase activity is expected to be especially effective in contributing to growth arrest ( Supplementary Fig Because SI induces Ca 2+ -dependent phosphorylation of p26.1 (ref. 3 ), we ascertained whether phosphorylation could modify sPPase activity Both Pr-p26.1a and Pr-p26.1b possess the classic sPPase signature sequence DXDXXDX with three aspartate residues comprising a divalent-ion-binding site (usually for Mg 2+ ) essential for catalytic activity , 14 conserved residues common to all sPPases, and putative phosphorylation sites ( Supplementary Fig Both predicted amino acid sequences have high homology to Family I sPPases Both recombinant Pr-p26.1a and Pr-p26.1b had high Mg 2+ -dependent sPPase specific activities of 2,320 ± 140 and 2,170 ± 160 μmol Pi mg -1  min -1 (mean ± s.e.m., n  = 4), respectively ( Fig. 2a ) Ca 2+ inhibited sPPase activity, reducing the specific activity of Pr-p26.1a and Pr-p26.1b by 53.2 ± 1.52% and 50.4 ± 2.50%, respectively ( n  = 4, P   0.001) Furthermore, we have provided evidence showing its importance in regulating pollen tube growth His-affinity purification showed that both Pr-p26.1a and Pr-p26.1b are phosphorylated ( Fig. 2c ) in a Ca 2+ -dependent manner ( Fig. 2d ) Immunolocalization and green fluorescent protein (GFP) fusion proteins confirmed that these sPPases were cytosolic ( Fig. 1c, d ) In addition, overexpression of a bacterial sPPase in the cytosol of potato tubers increases starch synthesis  In SI, inhibition of biosynthetic activity could clearly contribute to the arrest of growth required to prevent self-fertilization In summary, we have demonstrated phosphorylation of the sPPases Pr-p26.1a and Pr-p26.1b and provide evidence that this phosphorylation inhibits sPPase activity Inorganic pyrophosphatases (PPases) are highly conserved across prokaryotes and eukaryotes Matrix-assisted laser desorption-ionization quadrapole time-of-flight (MALDI-QTOF) tandem mass spectrometry identified three peptides that matched Pr-p26.1a and Pr-p26.1b sequences ( Supplementary Fig Mn 2+ could not substitute for the effect of Ca 2+  Normally growing pollen tubes had a PPi concentration of 38.2 ± 5.2 pmol mg -1  pollen -1 ( n  = 6), whereas the PPi concentration in SI-induced incompatible pollen tubes was 180% of the control value ( n  = 9; Fig. 3b ) Notably, an sPPase has been purified from the latex of Hevea braziliensis that is involved in rubber biosynthesis Other divalent cations (Ca 2+ , Mn 2+ ) could not substitute for Mg 2+  Other tissues showed low activity ( Supplementary Fig Our data identify a regulatory mechanism for the inhibition of this important class of enzyme Our data thus show that Pr-p26.1 sPPase activity is markedly reduced by phosphorylation and that Ca 2+ also reduces its activity Phosphorylated Pr-p26.1 showed a reduction in sPPase specific activity of 59.3% as compared with equivalent unphosphorylated extracts Plant sPPases are localized primarily to plastids rather than the cytosol  Pollen tube growth requires extensive biosynthesis of membrane and cell wall components to enable it to grow PPi is generated during biopolymer (for example, cellulose) synthesis and hydrolysed to inorganic phosphate (2Pi); this reaction provides a thermodynamic pull favouring biosynthesis  Pr-p26.1a and Pr-p26.1b were detected only in the soluble fraction ( Fig. 1b ) Pr-p26.1a is predicted to encode a 24.4-kDa protein, pI 6.11, comprising 217 amino acids; Pr-p26.1b is predicted to encode a 26.5-kDa protein, pI 6.03, comprising 236 amino acids Protein phosphorylation is an important regulatory mechanism for altering enzyme activity S1 ), making it an ideal mechanism for operating in SI, which depends on pollen tube inhibition to prevent self-fertilization S2 ) S2 ) S2 ) S2 ), indicating that both sPPases are present in pollen and phosphorylated S3 ) S4 ) Several targets of SI-induced Ca 2+ signals have been identified, including the F-actin cytoskeleton and a programmed cell death signalling cascade  So far, the only indication of a role for sPPase phosphorylation has been in regulation of purine biosynthesis in bacteria ; however, the effect of phosphorylation on sPPase activity was not ascertained in that study Statistical analysis showed that both phosphorylation and Ca 2+ had highly significant effects ( n  = 3 for both, P   0.001) on sPPase activity; the effects of phosphorylation and Ca 2+ were not independent ( P  = 0.027) Taken together with our previous identification of p26.1 (ref. 3 ), this observation seems to represent, to our knowledge, the first example of the phosphorylation of eukaryotic sPPases involved in a physiological process The earliest SI response is an increase in intracellular Ca 2+ (refs 2 , 25 ), which triggers a signalling network to stop pollen tube growth The increase in PPi in SI-induced pollen as compared with untreated controls ( P  = 0.001) is consistent with the prediction that SI results in high PPi owing to a decrease in sPPase activity The lack of crossreactivity in cytosolic extracts from other tissues suggested that they contain low concentrations of sPPases The mean sPPase specific activity in germinated pollen was 36.8 ± 0.83 μmol Pi mg -1  min -1 ( n  = 4), 7.8-fold higher than that in mature leaf (sPPase specific activity of 4.7 ± 0.15 μmol Pi mg -1  min -1 , n  = 4, P   0.001) The protein encoded by Pr-p26.1a contains peptide sequence obtained from p26.1 ( Supplementary Fig The self-incompatibility (SI) response in pollen of Papaver provides a model system in which to investigate signalling in plant cells The sPPase specific activities of phosphorylated endogenous pollen proteins containing phosphorylated Pr-p26.1 were compared with those of unphosphorylated extracts containing equivalent amounts of Pr-p26.1 ( Fig. 2e ) The two proteins show indistinguishable sPPase specific activities ( P  = 0.617, NS) The ubiquitous function of sPPases is axiomatic. sPPases are important enzymes in biosynthesis , and extensive evidence indicates that inhibition of sPPases decreases metabolic activity. sPPase activity is essential for growth in bacteria and yeast , and increasing sPPase activity in the plant cytosol (where it is not usually located) results in an increase in starch  There is considerable evolutionary conservation of Family I sPPases ; bacterial sPPases and Pr-p26.1a or Pr-p26.1b have 57% overall identity These data indicate a functional involvement for Pr-p26.1a and Pr-p26.1b in pollen-specific processes, during either pollen germination or pollen tube growth, because there is little evidence for their expression during pollen development These data suggest a mechanism for regulating incompatible pollen tube growth They are enzymes that, through hydrolysis of inorganic pyrophosphate (PPi), provide the driving force for many metabolic reactions This demonstration that phosphorylation inhibits sPPase activity establishes a previously unknown mechanism for regulating sPPase catalytic activity in eukaryotes This finding supports our hypothesis that pollen is unusual in having high cytosolic sPPase activity This finding unequivocally shows that Pr-p26.1a and Pr-p26.1b have classic Mg 2+ -dependent sPPase activity that is inhibited by Ca 2+  This observation provides evidence for a mechanistic link between sPPases and SI in vivo in pollen tubes This shows that p26.1 is crucial for pollen tube growth Thus, identification of sPPases as a target for the SI signals in Papaver pollen represents a significant advance in our understanding of SI Thus, our data provide insight into the regulation of sPPases, implicating a key role for kinase-dependent phosphorylation Thus, phosphorylation of Pr-p26.1 markedly reduces its sPPase activity Thus, pollen tubes may express cytosolic sPPases because they require high metabolic activity to generate new membrane and cell wall for pollen tube extension To confirm the functional requirement of Pr-p26.1 sPPases in pollen tube growth, we used an antisense oligonucleotide approach to downregulate Pr-p26.1 To determine the nature of p26.1, we cloned the complementary DNA encoding it from pollen, obtaining two full-length sequences, Pr-p26.1a and Pr-p26.1b ( Supplementary Fig To establish unequivocally that Pr-p26.1a and Pr-p26.1b can be phosphorylated, we carried out in vitro kinase assays using recombinant His-tagged sPPase proteins To our knowledge, signalling to sPPases in a eukaryote has not previously been demonstrated To provide a functional link between changes in sPPase activity and SI induction in pollen, we measured the concentration of PPi after SI induction To verify that the proteins encoded by Pr-p26.1a and Pr-p26.1b are sPPases, we tested whether the recombinant proteins had the key properties of sPPases by measuring their sPPase specific activities  We considered that if sPPase activity is reduced by SI induction, then the cellular PPi concentration would increase, because sPPases remove excess PPi by hydrolysing it to 2Pi We found that expression is limited primarily to mature pollen ( Fig. 1a ) We observed a significant reduction in pollen tube length (79.8 ± 1.1%) in the presence of antisense oligonucleotides targeted to the Pr-p26.1a and Pr-p26.1b sequence ( n  = 3, P  0.001), but not in the presence of the corresponding sense oligonucleotides ( n  = 3, P  = 0.058, NS; Fig. 3a and Supplementary Fig We tested the hypothesis that cytosolic sPPases might be abundant only in cells with high metabolic activity by comparing sPPase activities in cytosolic extracts from Papaver pollen with those from other tissues Western blotting showed that the phosphorylated fraction contained Pr-p26.1a and Pr-p26.1b ( Fig. 2b )
 A difference in response was seen for chocolate, but not for three non-food smells A team led by Berislav Zlokovic at the University of Rochester Medical Center in New York made this discovery by studying gene expression in endothelial cells from the brains of Alzheimers patients Although nano-mail has yet to be fabricated, interlinked carbon nano-rings, where each ring measures a few hundred nanometres in diameter, have been observed in experiments Although Sirt1 may be involved in prolonging the life of mammals on calorie-restricted diets, a link has not been proven An interesting twist is that the alleles found in low-plated fish also turn up in marine sticklebacks, indicating that evolution in the different freshwater populations was driven by selection on pre-existing alleles, rather than on parallel mutations And adherence to these routes maintains lineages with distinct genetics and song type And unlike the response of structures made from metal, the deformation would also be totally reversible Austin Smith of the University of Edinburgh, UK, and his colleagues show that a combination of fibroblast growth factor 2 and epidermal growth factor encourages isolated neural stem cells to propagate B 72, 085416 (2005) The concept of chains and chain-mail constructed from ring-shaped carbon nanotubes has been explored through molecular dynamics, using a new computational method to study the materials response to loading Bacteriology: Tactical defence Cell 122, 461–472 (2005) The bacterial pathogen Salmonella typhimurium senses when it has become the target of its hosts immune system, and takes steps to avoid destruction But a study now suggests that none of this is necessary But in the past, researchers have had to use trial-and-error to design photonic-crystal cavities that trap light in very small volumes But speculation that a few very bold, or badly lost, whales switch routes has been reinforced by Cristina Pomilla and Howard Rosenbaum, both of the American Museum of Natural History and the Wildlife Conservation Society in New York But work such as this gives me hope. Calves learn a route from their mothers and follow it every year Cancer: Timing is everything Cancer Cell 8, 99–110 (2005) Timing could be the key to successful combination cancer treatments, reports Mark Dewhirsts lab at Duke University Medical Center in North Carolina Cell Biology: Calorie burner Cell Metab. 2, 105–117 (2005) A role in glucose metabolism in mammals has been revealed for a class of proteins associated with longevity in worms, flies and yeast Chains of interlinking nano-rings could lengthen by more than a third without snapping, whereas the mail could withstand a strain of 25% Changes in the brains of mice lacking one copy of the gene that encodes GAX, Meox2 , provide supporting evidence of GAXs role Compared with control mice, the engineered animals produced more insulin, the protein that regulates carbohydrate metabolism, in response to doses of glucose Dana Small of the John B David Lows group at the University of California, Santa Barbara, report that the EC93 strain of Escherichia coli transfers growth-inhibiting signals when it comes into contact with neighbouring cells of a different strain Express 13, 5961–5975 (2005) What is the best way to cage light? This is a useful feat in building all kinds of optical devices including lasers GAX is known to regulate the development of the vascular system, and restoring GAX levels in these endothelial cells in vitro stimulated the growth of blood vessels I have long been fascinated, for no sensible reason at all, by pufferfish and their various spiny, prickly and armoured relatives Impressive body armour and spines are also found in Gasterosteiformes, a group that includes seahorses, pipefish and sticklebacks It also enhanced expression of a factor that helps clear the protein plaques typically found in the brains of Alzheimers patients Journal club Elizabeth Brainerd Brown University, Providence A specialist in functional anatomy hopes that advances in stickleback genetics will help solve a mystery about her favourite group of vertebrates Last year, Dewhirst and his team showed that radiation increases the activity of the hypoxia-inducible factor-1 (HIF-1) protein in tumours, which in turn affects the responsiveness of the tumours to the treatment Lett. doi:10.1098/rsbl.2005.0351 (2005) Humpback whales ( Megaptera novaeangliae ) are known for their yearly migrations between the poles and tropics Microbiology: Close encounters Science 309, 1245–1248 (2005) Cell-to-cell contact seems to allow certain bacteria to stymie their rivals Microsatellite analysis made the match, and snapshots of the whales dorsal fin confirmed it Nanotechnology: Mini might Phys Natl Acad Neurobiology: A taste sensation Neuron 47, 593–605 (2005) Neuroscience: Underlying Alzheimers Nature Med. doi: 10.1038/nm1287 (2005) The vascular lesions in the brain that are a distinctive, but little understood, feature of Alzheimers disease have been linked to low expression of the transcription factor GAX Now a team at Stanford University in California has devised an equation that does the job in a single computational step Now they have teased apart the pathways through which HIF-1 works — identifying three that make a tumour more radiosensitive, and one that makes it more resistant to radiation One male whale whose DNA was sampled when it was found wintering in the Indian Ocean by Madagascar in 2000 was sampled again in 2002 in the South Atlantic, near Gabon Optics: Caught behind bars Opt Pierce Laboratory in New Haven, Connecticut, and her colleagues show that a smell arriving through the nose can stimulate different regions of the brain compared with the same odour delivered through the mouth Population genetics: Sea change Biol Recently, progress has been made in revealing the genetics of armour in the threespined stickleback ( Gasterosteus aculeatus ) Rev Samuel Miller at the University of Washington Medical School in Seattle and his colleagues have elucidated the mechanism Sci Shin-ichiro Imai and his colleagues of the Washington University School of Medicine, Missouri, engineered mice to overexpress Sirt1 proteins in their pancreatic beta cells Some unknown trait of this group Tetraodontiformes predisposes its members to repeated evolution of mechanical defences against predation, such as body inflation in pufferfish, stout spines in triggerfish and whole-body armour in boxfish Stem cells: Easy does it PLoS Biol. doi:10.1371/journal.pbio.0030283 (2005) Neural stem cells used to be difficult to grow because they had to be cultured alongside more differentiated cells within floating clusters called neurospheres The calculated tensile strength of such structures is very impressive, given their low mass density The EC93 strain was isolated from the guts of rats, where it had eliminated all other bacteria The inputs to the equation are the desired pattern of the trapped light field, the volume within which the light must be confined and the quality factor, or leakiness, of the cavity The more immediate implication of this study is the possibility that Sirt1 could be used to treat type 2 diabetes, which strikes when the body becomes resistant to insulin, or when the pancreatic cells produce too little of it The neural stem cells were able to differentiate into both neurons and their companion glial cells, astrocytes The outputs are instructions for how to arrange the different layers of material that form the photonic crystal The populations separated after the end of the last glaciation, some 20,000 years ago The question tackled by the new research is how freshwater sticklebacks evolved to have fewer armoured plates along their sides than marine sticklebacks The researchers speculate that the contact-dependent inhibition may involve interactions between tiny tentacles called pili found on the surface of the cells The team identified two proteins that the bacterium releases to inhibit its neighbours growth, and also found a DNA sequence in the EC93 strain that provides it with immunity against its own secretions The team suggests that the mechanism distinguishes between the availability and receipt of food The team used functional magnetic resonance imaging to probe the brains response to scents delivered into the nostrils or — to simulate odours arriving through the mouth — to the back of the nasal passage They conclude that radiation followed by HIF-1 inhibition would be the most effective cancer treatment, but the strength of the effect varies from tumour to tumour — and probably from patient to patient They deciphered how the PhoQ enzyme bound to the bacterial cell membrane is activated by the positively charged peptides released by the host cell to kill the bacteria This triggers a cascade of events that affects the expression of more than 200 genes, including some that strengthen the bacterial outer membrane, and so protect the bacteria from attack To get the most from your meal, you should savour the scent before tucking in Understanding the evolution of tetraodontiform defences will be a harder problem, in part because they diverged over 50 million years ago Unexpectedly, Cresko et al . showed that the loss of lateral armour plates has the same genetic basis in geographically isolated freshwater populations ( Proc USA 101, 6050–6055; 2004) Using this trick, they derived a pure culture of self-renewing neural stem cells from embryonic stem cells obtained from mice Variation in Ectodysplasin , a gene known to affect skin and scale development, was then implicated as the causal factor by Colosimo et al . ( Science 307, 1928–1933; 2005)
 A problem not addressed in the book is that, because altruistic punishment is costly, natural selection should tend to eliminate it A recent human example in Britain is the decline in voluntary take-up of the combined measles–mumps–rubella (MMR) vaccination by parents who wished to avoid an alleged health risk to their own children while implicitly relying on enough other children being vaccinated to maintain ‘herd immunity’ A similar social dilemma is devastating UK fish stocks: overfishing destroyed British herring fisheries long ago and is now causing terminal decline in other fish stocks in the English Channel, the North Sea and the Baltic According to the theory, cooperation is necessary for the provision of public goods, and the punishment of non-cooperators, or free-riders, is itself a public good — a service provided for the benefit of the whole community An introductory chapter is followed by three on the behavioural ecology of cooperation, four on modelling and testing strong reciprocity, and five on reciprocity and social policy, all by researchers in the vanguards of their fields Anyone who makes a living by fishing is motivated to catch as many fish as possible, because restraint is pointless if enough others are exercising restraint, and is futile if they are not Bill Hamiltons theory of ‘inclusive fitness’, or kin selection, explains the evolution of cooperation among genetically related individuals But then fish are driven to extinction and everyone is worse off than if they had all restrained themselves cooperatively But what about sanctions against third-order defectors who neglect to punish second-order defectors, and so on? This is an infinite regress that becomes less credible with the addition of each successive layer Failure to punish defectors must presumably be treated as second-order defection, itself subject to sanctions from other group members Fehr and Gächter have provided persuasive experimental evidence, reviewed in this book, that cooperation flourishes when punishment is possible and breaks down when it is not For example, birds often emit alarm calls when they spot predators, but how could such behaviour have evolved? A mutant bird that never gave alarm calls would save energy and avoid the additional risk to itself while enjoying the benefits of its conspecifics alarm calls For the same reason, cooperation is difficult to maintain when individuals are tempted to defect It can explain the extreme self-sacrificing cooperation of female social Hymenoptera, who have 75% of their genes in common, but cannot explain cooperation among non-relatives Its ‘selfish gene’ should therefore spread to fixation in the population Moral Sentiments and Material Interests is devoted to their theorys biological, anthropological, economic and social ramifications and related ideas Other explanations of cooperation in unrepeated interactions between strangers hardly get a look in, however People benefit by cooperating, even in one-off encounters with strangers, because cooperation enhances ones reputation for cooperativeness and elicits reciprocal cooperation from others Robert May began his last presidential address to the Royal Society on 30 November 2005 by saying: “The most important unanswered question in evolutionary biology, and more generally in the social sciences, is how cooperative behaviour evolved and can be maintained in human or other animal groups and societies” Robert Triverss theory of reciprocal altruism shows how cooperation between non-relatives can evolve if its cost is small and is outweighed by favours returned in the future Strong reciprocity is an important and illuminating discovery, but we seem to have replaced the problem of explaining cooperation with that of explaining altruistic punishment Such punishment is altruistic because it is costly to those who administer it, as it takes time and energy and invites retaliation The book provides a superb interdisciplinary synthesis of cooperation as explained by strong reciprocity and associated phenomena The most important is Richard Alexanders theory of ‘indirect reciprocity’, according to which people use observations of direct reciprocity between others when deciding how to act towards them in the future These two theories go some way towards explaining how cooperation evolved, but neither can explain human cooperation in unrepeated interactions between strangers This has the strategic structure of a social dilemma, because if all parents followed this reasoning, everyone could end up worse off than if they all behaved cooperatively This is a powerful theory, supported by evidence from computational and experimental studies, but Moral Sentiments and Material Interests mentions it only in passing. To fill this gap, Ernst Fehr and Simon Gächter introduced in 2000 a version of the theory of strong reciprocity incorporating the ‘altruistic punishment’ of non-cooperators
 Nuclear waste A Nevada family is threatened after their daughter, a contestant in this years Miss America pageant, made comments in favour of a planned nuclear-waste repository at Yucca Mountain Number crunch newsad; Even as Japan plans to significantly increase the number of whales it kills for scientific research, the Japanese are turning up their noses at the pungent, chewy meat On the record “It makes me mad that I could have had hot fudge sundaes all these years.”  A California woman who has been on a low-fat diet for 30 years responds to a major study revealing that such diets do not reduce the risk of cancer or heart disease. “Its really sad the girls are winning Source: Associated Press Sources: San Francisco Chronicle, Washington Post Scorecard Science ‘journalism’  Petroleum geologists give author Michael Crichton a journalism award for his novel State of Fear , which dismisses the threat of global warming as an unrealistic scenario overhyped by wayward scientists The government sells on carcasses for public consumption, but no one seems to be wildly enthusiastic. 65% more whale meat reached the market in 2005, compared with a decade earlier. 60% more minke whales will be killed this year compared with last year under government targets. 30% was the drop in the price of whale meat between 1999 and 2004 This isnt the game they should be winning at.”  A paediatrician is dismayed by statistics showing that more US teenage girls than boys are smoking and abusing prescription drugs
 Andersons elegant book contains a host of other insights and observations Bees famously indicate the direction, distance and quality of sources of pollen to their fellow workers by means of a ‘waggle dance’, which is often taken to show that they have a ‘cognitive map’ of the local terrain But they never master anything like a human language and seem incapable of doing so: the complexity of their grammar is not remotely comparable to ours Current views of first-language acquisition in children treat it as a process of selection, rather than instruction Doctor Dolittle was the hero of a series of childrens books written by Hugh Lofting (1886–1947) First, the essence of syntax is recursion: the possibility of including one sentence inside another ad infinitum For example: [Anderson discusses the claim that [many people think that [animals can talk]]] He concludes that, just as the dance of bees, the song of birds and the calls of monkeys are unique to their respective species, so human language is unique to us. He provides a masterly overview of what is currently known about the communicative abilities of a wide range of creatures: the dance of honeybees, the communicative croaking of frogs, the warning cries of monkeys, and the remarkable cognitive abilities of bonobos and parrots Here, “John” and “him” can, but need not, refer to the same individual Humans are born with a set of principles known as ‘universal grammar’ that define the notion of possible human language and a set of parameters that characterize possible variation among languages Importantly, this theory predicts that there are logically possible, but linguistically impossible, mistakes that children cannot make In [John expects to visit him], “John” and “him” must refer to different people, but consider this: [I wonder who [John expects to visit him]] In a meticulous dissection of the properties of this dance, Anderson undermines this claim, showing that the bees perception of distance is largely a function of differences in their visual experience Judgements such as these have no parallel in the communication systems of other animals Many birds have songs that develop appropriately only after interaction with conspecifics: the song is partly innate and partly dependent on experience Much of this is superficially familiar from other popular accounts, but Andersons synthesis provides illuminating comparisons with the infinitely more sophisticated resources of human language, whether spoken or signed Nightingales, like children, only make mistakes that correspond to patterns that could occur as possible song elements for their species, just as children only make mistakes that are licensed by universal grammar Our vocabularies are dramatically larger than those of other animals, and our sound systems are more complex, but the essential design property of human language is syntax — the way we use combinations of words to convey meaning Second, we all have subtle and consistent intuitions not only of what is possible in our language, but also of what is impossible Similarly, attempts to teach American Sign Language to chimpanzees have made it clear that, although human infants read intentions into the actions of others, chimps never do So we should be able to learn their languages or, just as good, they could learn ours Stephen Anderson pours cold water on this belief, arguing convincingly that it is a delusion The acquisition of language consists largely of fixing the values of these parameters on the basis of clues in the input The calls can affect behaviour but not knowledge The dance, then, reflects the bees subjective experience, rather than a map of the external world The doctors ability to talk to every animal in its own language had a seductive appeal that finds current expression in the widespread belief that the communication systems of animals, from bees to bonobos, are essentially similar to human language The parallel with birdsong is striking Their systems of communication, however, are less similar to human language than is popularly supposed There are undeniable parallels between humans and other animals, but the differences are equally striking and confirm the view that our language is qualitatively different from theirs These calls can be extended to new types of threat — humans, for instance — and they are under some degree of voluntary control, yet they do not seem to ‘refer’ to the respective animals in the way we refer with our language This complexity is exemplified at length in the book, but two examples should suffice This concept is alien to the communication systems of other species To complement his critique of ‘animal language’, Anderson also outlines what is special about human language: in a word, syntax Vervet monkeys have distinct alarm calls for leopards, eagles and snakes We are evolutionarily closer to birds than to bees, but we are closer still to other primates We are evolutionarily rather remote from bees; closer parallels to human language and how we learn it can be found in birds What animals learn is impressive and their cognitive abilities may be remarkable When bees are made to fly through tunnels with visual patterns on the walls, the distance they indicate corresponds to the complexity of the pattern to which they have been exposed
 As your report highlights, nations differ in child-care facilities — but they all share a shortage of women scientists, particularly at higher levels Childless women and those with children have strikingly similar patterns of salary disparity and lag in achieving tenure and promotion compared with men Denmark, Psychological Dimensions, New York, 1975) Fidell in Woman: Dependent or Independent Variable? 774–782, eds R For example, when the heads of 147 psychology departments were sent fictitious resumés of prospective faculty members and asked to name the rank — assistant, associate or full professor — to which the candidate would be appointed in their department, the recommended rank was higher if the resumé had a male name than if the same qualifications had a womans name attached (L Furthermore, the proportion of women in different sub-disciplines varies dramatically, but child-care availability is no different for a microbiologist or an engineer However, this recent attention to child care in the scientific workplace merely addresses a symptom, rather than a cause, of under-representation of women in science K L More recently, women had to produce twice as many scientific papers of equivalent quality as men to be considered equally competent in a Swedish Medical Research Fellowship postdoctoral programme (C Research shows that both men and women tend to overrate men and underrate women in competence, particularly when women are in a non-traditional field such as science (V S Sir In your Editorial “All things equal” ( Nature 437 , 296 ; 2005 ) and Special Report “Small steps towards campus child care” ( Nature , 446–447; 2005 ), much was made of the need for women scientists to have access to good child care if they are to succeed Unger and F Valian Why So Slow? MIT Press, Cambridge, MA, 1998) We suggest that lying behind the paucity of women in science is an unconscious bias in evaluating the sexes Wennerås and A Wold Nature 387 , 341 – 343 ; 1997 ).
 A single female can hold up to 111 males After much head-scratching, it became apparent that Pinky was just a polychaete worm — the class that includes ragworms and lugworms — albeit much larger than its shallow-water relatives. “Pinky is a giant,” says Rouse. “Hes more than one centimetre long, whereas his relatives are of the order of a couple of millimetres Although the bacteria are similar to those found in oil slicks, this sort of microbe has never been found in a symbiotic partnership with another creature before Although whale carcasses tend to accumulate along these migratory paths, they fall at random locations and can be spaced very far apart And another 20 have been sampled accidentally by trawling fishermen Another oddity is a whale-fall worm nicknamed ‘Pinky’, which at first evaded identification by its researchers, including Greg Rouse at the University of Adelaide in Australia As anaerobic bacteria further the whales decomposition, they create a sulphide-rich environment allowing sulphur-loving creatures to move in As bits of whale tissue spread around the carcass, the enriched seafloor sediment provides nutrition for opportunistic worms and crustaceans Body hunt “Theyre hard to find because you cant just follow a particular geological feature on the sea floor and drive up to them like you can with hydrothermal vents,” says Smith But atop this mass of bones the pilot did find something exotic: a carpet of creatures, including bacteria and worms, similar to those found on the flanks of underwater volcanoes But in the past few centuries they have faced a serious threat But sinking a four-tonne juvenile grey whale, or a 35-tonne adult, is a major undertaking, says Smith By the time they reach the whale it is often bloated with gases from decomposition Crunch time Such research has unveiled a number of strange creatures Dahlgrens lab also keeps whale bones with live specimens in a seawater tank Each time a whale was dragged aboard a ship, it not only depleted the live stocks, but also those of the dead falling to the sea floor For one thing, scientists are trying to find out how larvae from whale-fall organisms that are spawned into the water live long enough to find their way to another bone. “It is really clever For scientists such as Smith, studying whale falls presents some inherent challenges — not least of which is finding a body to examine He and his team can sample the whale fall as often as once a week If hunting had continued apace it might have wiped out not only the great whales, but Pinky too. In 1987, a manned submersible called Alvin was making a routine dive along the muddy plains of the deep sea when its pilot spotted what he thought was the fossilized remains of a dinosaur In an attempt to increase these numbers, whale-fall researchers have resorted to sinking beached dead whales In the barren depths of the open ocean, a fallen whale carcass is a veritable feast In the early 1990s, the US Navy surveyed more than 300 square kilometres of the Pacific sea floor in search of a lost missile and found eight whale skeletons In the Pacific, for example, there are often casualties on the long treck north to Alaska from birthing grounds along the Baja Peninsula of Mexico Instead of an exotic underwater beast, it turned out to be the 21-metre-long skeleton of a blue whale It can take two days to get a whale from the shore to the sea floor — and all those involved agree that it is a highly unpleasant process. “We often throw away our clothes because you cant get the smell out,” says Smith. “Its one of the hazards of the job.”  Researchers have so far sunk about 20 whales this way Its not just the whales that needed saving, notes Smith Just as windfalls deliver a sudden bounty of ripened fruit, whale falls see the death of a whale bring a host of nutrients to the sea floor Many mysteries about the whale-fall communities remain Many whales die when female whales or newborns, stressed by the process of birth, make their annual migration Others send submersibles to the sites, which can pick up rib bones and vertebrae and bring them to the surface with the communities still alive and mostly intact Perhaps the prize find so far is a newly described worm genus, Osedax — Latin for ‘bone-devourer’ — which has a clever metabolic strategy Pinkys also quite fat.” The worm measures a whopping one to two millimetres across Scavengers such as sleeper sharks, hagfish and squat lobsters can dine for months to many years on the soft tissue of a single whale, depending on its size Scientists guess that the creatures in whale-fall communities probably date back some 35 million years Scientists now estimate that a whale-fall community can survive for up to a century by sucking the fats and sulphides from these bones Smith estimates that whaling in the 1800s and 1900s reduced whale-fall habitat by up to 95%, potentially wiping out up to half of the species that were specialized to live on whale carcasses in some ocean basins  Smiths group placed a time-lapse camera on one carcass, which took pictures more-or-less continuously for eight months So far, researchers have found five species of Osedax — four in the Pacific and, most recently, one in the Atlantic, implying that the worms have a worldwide distribution So far, ten natural whale falls have been investigated by the dozen or so scientists who study them Some 39 of the species discovered so far are thought to be especially suited or even unique to this environment Such complex communities have not been reported on the bones of other marine mammals, says Craig Smith, a whale-fall expert from the University of Hawaii at Manoa The Alvin team had happened upon what have since become known as ‘whale falls’ — communities of creatures that thrive among the sulphur-laden ooze of decaying whales The bacteria that make their home on whale falls are so good at degrading fat in cold waters that the biotechnology company Diversa in San Diego, California, is looking to see whether their enzymes might prove useful in cold-water detergents The falls are few and far between, and difficult to track and study, but researchers are learning ever more — sometimes through extreme measures — about the new species to be found among the remains The navy contacted Smith, but didnt take exact coordinates of where the skeletons were located The whale falls that have been studied off the coast of California tend to be 1,200–3,000 metres deep and at least half-a-days cruise away from the nearest lab; Dahlgrens whale is 125 metres deep and just half an hour from his office. “Were not stuck on a ship in the Pacific bobbing around with a limited time until the cruise is over,” says Dahlgren The worms then rely on bacteria within their tissues to digest fats and oils from the bone marrow The worms tunnel into the bones with their green, fleshy roots and turn them into “Swiss cheese”, says Smith They return to these whale falls regularly to monitor the colonization of organisms on the remains This is probably because whale bones are so much larger and fat-rich, he says Thomas Dahlgren, a population geneticist at the Tjärnö Marine Biological Laboratory in Strömstad, Sweden, has been fortunate enough to sink a whale near his lab To get it to sink, the scientists have to weigh it down with up to 3,000 kilograms of scrap metal, from train wheels to anchor chains Two of the species have a matriarchal society of sorts, in which all of the female members are about the length of an index finger, and the males are mere microscopic threads that live inside the females oviducts Unlike creatures found at hydrothermal vents, which can only survive at the high pressures found at the bottom of the deep sea, some whale-fall organisms seem to adapt quite well to life on the surface. “Whale bones are hanging in our cold room with cultures of these whale bacteria stuck all over them,” says Dahlgren We dont know how they do it, but they do it,” says Paul Tyler, a deep-sea ecologist at the Southampton Oceanography Centre, UK When researchers get a call about a washed-up whale, they mobilize their teams and ships When Smiths team returned to the site, it could find only one of the eight With no mouth, stomach or eyes, Osedax has evolved a root system to excavate the fat out of whale bones Worms, clams and mussels, to name but a few, all take up residence, each getting their metabolic fix from the chemical energy provided by the fat-rich marrow in whale bones 
 Advocates say the system is fair and would focus peoples attention on conserving energy And unlike a blanket carbon tax, it encourages individuals to think about their emissions. “It makes carbon more visible,” says Richard Starkey, a carbon-policy expert at the University of Manchester, UK. newsad; Starkey also points out that low-income families, which tend to use less energy than higher earners, could save and then sell carbon credits At current UK emission levels, he reckons each individual would receive around 1.25 tonnes of carbon But could it ever succeed? Here is how the system would work By regulating the amount of personal credits handed out each year, the government could cap total carbon emissions and help tackle climate change. “Instead of banning particular products, services or activities — or taxing them heavily — a personal carbon allowance enables citizens to make trade-offs,” said Miliband as he floated the idea on 19 July Civil servants will look into the proposal and report back to government next year For an idea of scale, a 200-km journey in a car that uses petrol would use about 1% of that For transactions that involve direct purchases of energy, such as buying petrol or paying fuel bills, a person would hand over money and some of the carbon credits he or she had been allocated by government If those credits ran out, the person would have to buy extra when paying for the fuel or electricity It sounds like a triumph for the doctrine that people should think globally but act locally — and like a nightmare scenario for libertarian opponents of big government Last week, UK environment secretary David Miliband suggested issuing all British adults with an annual carbon allowance Oil-industry groups have previously claimed that attempts to tackle climate change such as the Kyoto Protocol will damage lifestyles — an accusation that most politicians, particularly in the United States, are careful to avoid Personal carbon credits may sound too much like energy rationing. “It would be awfully hard to explain this to Americans,” says one senior US environmental advocate, who asked not to be named. Researchers who have studied the idea say domestic quotas are a sensible way to extend emissions trading to the personal level — such trading is already used to limit emissions from some European industries Such ideas are going down rather less well in the United States, where environmental activists privately hope the UK proposal will attract as little attention as possible The allowance would be worth only a few tens of pounds (or US dollars) at todays prices, but if policies are enacted to meet the ambitious UK target of reducing emissions to 60% below 1990 levels by 2050, that would rise significantly
 Agnew, who was present at several tests of the W76, says that it never failed to detonate Arms-control experts are sceptical of the project, which will cost $9 million in 2006. “The existing stockpile is safe and reliable, and it is likely to be so for some time,” says Daryl Kimball, executive director of the Arms Control Association in Washington, DC. “This programme seems unnecessary.”  The replacement warhead programme would itself replace an ‘advanced concepts’ project, which has been criticized as a step toward development of new nuclear weapons (see Nature 428 , 455 ; 2004 10.1038/428455a ) Brooks is the administrator of the National Nuclear Security Administration, which oversees the US nuclear stockpile But Brooks added that his agency is now planning a study to create a more robust type of warhead Exact numbers are classified, but arms-control experts estimate that the W76 makes up almost one-third of the US stockpile of 10,000 warheads, as well as dominating the far smaller British nuclear arsenal For about a year, some scientists have been expressing concern to government officials about the uranium case surrounding the warhead He adds that six to nine warheads are carefully analysed every year to make sure that ageing will not affect their performance. “We have looked into this concern extensively, and our best technical judgement is that it is simply wrong,” Linton Brooks told the Senate on 4 April He says that the Reliable Replacement Warhead programme will design weapons that have wider performance margins and can be more easily maintained without testing Leading scientists who designed the warhead say that the accusations are completely unfounded, however, and that the reports sources werent heavily engaged in the design project. “There is nothing wrong with the W76,” says Harold Agnew, who was director of the Los Alamos National Laboratory in New Mexico when the lab designed and tested the warhead 30 years ago Morse did not respond to Nature s requests for an interview Opponents of new weapons note that doubts about the W76s reliability could boost political support for the replacement programme. Other scientists familiar with the weapon dispute Morses assertions. “I think hes wrong,” says Richard Garwin, a prominent former hydrogen-bomb designer The bombs are “at best unreliable and probably much worse”, Richard Morse, a retired plasma physicist from Los Alamos told the The New York Times  The case is thin and light so that it can be carried on smaller, submarine-launched missiles The critics claim that it might fail when the fission trigger of the bomb detonates, meaning the bombs powerful fusion fuel would not ignite The New York Times reported on 3 April that the W76, a thermonuclear warhead launched from submarines, has a flaw in the design of its casing that could cause it to explode with much less force than expected — or not at all The warheads are compact and lethal: up to eight of them can sit in a single missile, each yielding an explosive force more than five times bigger than that of the bomb dropped on Hiroshima in 1945 This might eventually replace weapons such as the W76, which was designed for minimum size and weight Washington Senior weapons scientists emphatically denied a report this week that the most important US nuclear warhead has a design fault that could make it unreliable
 Another class of materials are metal-organic coordination polymers , which are based on metal ions coordinated by polydentate organic ligands and explored for potential use in catalysis , gas storage , nonlinear optics and molecular recognition and separations  Here we show that simple addition of an initiation solvent to a precursor solution of metal ions and metalloligands results in the spontaneous and fully reversible formation of a new class of metal–metalloligand particles In a subset of these materials, the use of organometallic complexes as ligands (so-called metalloligands) provides an additional level of tailorability, but these materials have so far not yet been fashioned into nano- or microparticles In the case of inorganic materials, particle fabrication tends to involve the reduction of a metal salt , or the controlled mixing of salt solutions supplying a metal cation and an elemental anion (for example, S - , Se - , O - ) , respectively; in some instances, these methods even afford direct control over the shape of the particles produced  Micrometre- and nanometre-sized particles play important roles in many applications, including catalysis , optics , biosensing and data storage  Organic particles are usually prepared through polymerization of suitable monomers or precipitation methods  The ease with which these particles can be fabricated, and the ability to tailor their chemical and physical properties through the choice of metal and organic ligand used, should facilitate investigations of their scope for practical applications. We observe initial formation of particles with diameters of a few hundred nanometres, which then coalesce and anneal into uniform and smooth microparticles All reactions, with the exception of pyridine, which dissolves the particles (see above), appear to be completely reversible, and can be effected within seconds of introduction to the appropriate small molecule Although they cannot be completely ruled out, physical effects probably play a more minor role in the polymerization process as the reaction mixture is not stirred while the particles are forming As BMSB building blocks can be prepared in enantiopure form and are important compounds in homogeneous catalysis , this new class of material may find use in asymmetric catalysis and chiral separations At early stages of the reaction, the clusters of smaller particles are readily observable ( Fig. 3a and 3d , bottom); the clusters then slowly anneal into single particles with smoother surfaces ( Fig. 3b ) and ultimately form uniform spherical particles ( Fig. 3c and 3d ,top) Average particle size was also measured by dynamic light scattering (DLS) and was in agreement with the SEM determined value Compound 2b also was characterized in the solid state by a single-crystal X-ray diffraction study ( Supplementary Information ) Control experiments with 2d , which has no carboxylate groups, show that the coordination polymer and, therefore, microparticles, will not form in the absence of the carboxylate groups Coordination polymers formed from metal ions and carboxylate-functionalized building blocks are well known in transition metal coordination chemistry  Emission and diffuse reflectance spectra of this series of particle compositions demonstrate the reversibility of these reactions and the ability to fine-tune the optical properties of the particles through choice of ancillary ligands ( Fig. 4b ) Fast addition results in nanoscale particles by quenching the growth process at an early stage in the reaction Featureless powder X-ray diffraction data for these particles show that they are amorphous and not crystalline materials For example, a red toluene suspension of the spherical particle composition of 3a turns yellow when methanol is added to the reaction vessel If the solvent is removed from this complex and the particles are redispersed in toluene with DMSO (10% by volume), the yellow solution turns red owing to the formation of Zn–DMSO adducts In a typical experiment, a precursor pyridine solution consisting of a 1:1 mixture of the appropriate metal acetate salt (M′(OAc) 2 , M′ = Zn, Cu and Ni, 1 ) and BMSB, 2 , is prepared (alternatively, a 3:1 mixture of 1 and enantiopure carboxylate-functionalized binapthyl bis-tridentate Schiff base (BSB) can be used) In addition to the aforementioned control experiments and Fourier-transform infrared spectroscopy, we also find that 1 H and 13 C NMR spectroscopy, and electrospray ionization mass spectrometry, are all consistent with the proposed mode of polymerization (see Supplementary Information ) In contrast to 3a , particle compositions 3b and 3c are not fluorescent because they are not made of fluorescent BMSB building blocks In contrast, the fast addition of pentane as the initiation solvent under nearly identical conditions resulted in particles with an average diameter of 780 ± 230 nm ( Fig. 3g ) In our system, spherical microparticles Zn–BMSB–Zn, 3a ( Fig. 2 ), instead of the more typically observed macroscopic materials, form within one hour upon slow diffusion of diethyl ether into a precursor solution containing homochiral Zn–BMSB ( 2a ) and Zn(OAc) 2 ( 1a ) in a 1:1 ratio in pyridine at room temperature In these applications, the small size of the particles results in a high overall surface area that ensures major advantages over bulk materials. Indeed, the emission spectra of the polymer particles 3a and monomer building block 2a are nearly identical ( Supplementary Fig. 2 ) Infrared spectra taken before and after formation of the particles show that the carboxylate groups are coordinating to metal ions, as evidenced by a shift in CO stretching frequency from 1,653–1,659 cm -1 for the monomeric unbound forms ( 2a – c ) to 1,597–1,605 cm -1 for the polymer particles ( 3a – c ) It is well known that isoelectronic monomers of this class of compounds exhibit characteristic red-shifts in the solution state as a function of the increasing σ-donor properties of the ancillary ligands  Nanoparticles of 3a with an average diameter of 190 ± 60 nm ( Fig. 3f ) could be prepared by the rapid addition of diethyl ether to the reaction mixture of 2a and 1a in pyridine Optical microscopy ( Fig. 2a ), fluorescence microscopy ( Fig. 2b and c ), and scanning electron microscopy (SEM, Fig. 2d ) images of example compositions show spherical particles with an average diameter of 1.60 ± 0.47 µm Similarly, the reaction between Ni–BMSB ( 2c ) and Ni(OAc) 2 ·4(H 2 O) ( 1c ) gives spherical particles Ni–BMSB–Ni ( 3c ) Slow addition of an initiation solvent such as diethyl ether or pentane results in the spontaneous formation of spherical inorganic polymer particles, 3  Slow diffusion of pentane into a precursor solution containing 2b and 1b yields particles that are on average significantly larger than the particles formed from the fast addition method Spherical nanoparticles of Cu–BMSB–Cu ( 3b ), synthesized from the fast addition of pentane into a precursor solution containing Cu–BMSB ( 2b ) and Cu(OAc) 2 (H 2 O) ( 1b ) in pyridine, have diameters similar to Zn–BMSB–Zn particles ( 3a ) prepared via an analogous procedure The addition of diethyl ether or pentane to the polar precursor solution results in precipitation due to the low solubility of the particles in non-polar media The ancillary ligands (L in Fig. 1 ) in these polymer particles allow the particles physical properties to be controlled by adjusting the electronic nature of the metals to which they are coordinated The BMSB building blocks were prepared from the reaction of two equivalents of M(OAc) 2 (M = Zn, Cu and Ni) and one equivalent of BSB in a N , N -dimethylformamide (DMF) solution at room temperature The building blocks 2a – c have been characterized by 1 H NMR, 13 C NMR, infrared spectroscopy and electrospray ionization mass spectrometry, and all data are consistent with the proposed structures The chemical composition of the particles was determined by energy dispersive X-ray spectroscopy and elemental analysis The cluster fusion step can involve dozens of particles or only a few, depending upon conditions, and the ultimate size of the large spherical particles depends upon the number of smaller particles involved in the fusion process The homochiral BMSB building blocks 2a – c are key components which are readily polymerizable through their carboxylate groups; the choice of BMSB ligand, type of metallation, and ancillary ligands makes it possible to manipulate the chemical and physical properties of the resulting structures 3 in a systematic manner The observations reveal two kinds of intermediate particles: clusters formed by aggregation of small particles, and a fused version of such clusters The optical properties of the nanoparticles are highly dependent upon the type of coordinating ligands, and the effects of different ligands (DMSO, pyridine, DMF, acetone, methanol and water) can be observed with the naked eye ( Fig. 4a ) The polarity of the solvent affects the solubility of the resulting particles and, therefore, their average size The rate of addition and type of initiation solvent allow control of particle size The resulting particles are stable in organic solvents (toluene, methanol, DMF and dimethyl sulphoxide (DMSO)), in water and in the dried state The Zn–BMSB–Zn particles ( 3a ) are fluorescent in the red and green regions of the spectrum ( Fig. 2b and c ) as a result of the highly fluorescent BMSB building block, 2a (ref. 24 ) These observations suggest a two-step cluster-fusion growth mechanism ( Fig. 3e ), where several small particles first aggregate to form large cluster particles, which in a second step undergo intra-particle fusion to yield large uniform spherical particles These particles form via coordination of the carboxylate groups on the BMSB precursor with the metal ions supplied by the acetate salt, and the polymerization process is completely reversible, as evidenced by the formation of the starting materials upon addition of excess pyridine ( Fig. 1 ) They are typically prepared as macroscopic crystalline materials by one of several methods, including slow diffusion of solvent into solutions consisting of precursors, solvothermal synthesis, layering, and slow evaporation  This can occur because of the reversible nature of the metal coordination chemistry, allowing the system to anneal into a smooth particle This colour change is attributed to the replacement of the pyridine ligand on the Zn metal centres with methanol This size control will probably be refined as this process evolves Under these synthesis conditions, the growth of the particles can be observed by taking aliquots from the synthesis mixture at various stages and characterizing the particles by SEM and optical microscopy We also investigated the utility of this method for producing spherical particles of coordination polymers with other metal ions such as Cu 2+ and Ni 2+ (see Supplementary Information ) We have discovered that spherical micro- and nanoparticles composed of polymerized metal-ligand networks can be made by the coordination-chemistry-induced assembly of metal ions and homochiral carboxylate-functionalized binapthyl bis-metallo-tridentate Schiff base (BMSB) building blocks ( Fig. 1 ) When pentane is used as an initiation solvent instead of diethyl ether, larger spherical microparticles (∼5 µm) form ( Fig. 3a–d , Supplementary Fig. 4 )
 A Canadian federal agency has denied funding to a science-education researcher partly because of its doubts about the theory of evolution At a public lecture on 29 March, Alters revealed excerpts from the rejection letter he received from the Social Sciences and Humanities Research Council (SSHRC) Brian Alters, director of the Evolution Education Research Centre at McGill University in Montreal, had proposed a study of the effects of the popularization of intelligent design — the idea that an intelligent creator shaped life — on Canadian students, teachers, parents, administrators and policy-makers David Green, director of McGill Universitys Redpath natural-history museum, adds: “I was quite surprised that such an opinion could be tendered by a high-powered granting agency.”  The SSHRC is the top social-sciences funding agency in Canada He has received funding from the SSHRC before; for instance, his centre was awarded a Can$175,000-grant to study the understanding of biological evolution in Islamic societies. newsad; Jennifer Robinson, associate vice-principal for communications at McGill, says the university will ask the council to review its decision. “In our view it is a factual error,” she says. “The theory of evolution is a well-established science, and intelligent design is a religious belief.”  Philip Sadler, a board member of the centre and director of science education at the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, is more philosophical. “If he was trying to answer the question as to whether all this popularization had had an impact, he just saved the government $40,000,” says Sadler. “He found the evidence without doing the study.” Spokeswoman Eva Schacherl says its funding decisions are based on the comments submitted by a committee of peer reviewers, and that the council cannot comment on the sentence in question. “We rely on the expertise of our committees to make recommendations,” she says Susan Bennett, an English professor at the University of Calgary in Alberta and chair of the SSHRC committee, could not be reached for comment by the time Nature went to press The letter stated that, among its reasons for rejection, the committee felt there was inadequate “justification for the assumption in the proposal that the theory of evolution, and not intelligent-design theory, was correct.”  “It illustrates how the misunderstanding of evolution and intelligent design can go to all levels of Canadian society,” says Alters The maximum value of Alterss requested grant was Can$40,000 (US$34,000)
 Here we show that mixtures of diblock copolymers and either cadmium selenide- or ferritin-based nanoparticles exhibit cooperative, coupled self-assembly on the nanoscale In thin films, the copolymers assemble into cylindrical domains, which dictate the spatial distribution of the nanoparticles; segregation of the particles to the interfaces mediates interfacial interactions and orients the copolymer domains normal to the surface, even when one of the blocks is strongly attracted to the substrate Organization of both the polymeric and particulate entities is thus achieved without the use of external fields , opening a simple and general route for fabrication of nanostructured materials with hierarchical order. Previous efforts have concentrated on using such scaffolds to spatially arrange nanoscopic elements as a strategy for tailoring the electrical, magnetic or photonic properties of the material Recent theoretical arguments have suggested that synergistic interactions between self-organizing particles and a self-assembling matrix material can lead to hierarchically ordered structures The organization of inorganic nanostructures within self-assembled organic or biological templates is receiving the attention of scientists interested in developing functional hybrid materials A cross-sectional TEM image of pure PS- b -P2VP film after annealing is shown in Fig. 3a  A detailed analysis is provided in the Supplementary Information  A series of incident angles ranging from 0.04° to 0.12° (the critical angle, θ c , was measured to be 0.11°) were used to achieve penetration depths from 44 Å to full penetration into the film After spin-coating, a weak but readily observable in-plane scattering peak at 0.0196 Å -1 indicates the initial ordering of the diblock copolymer with a d -spacing of 320 Å All surface features are lost upon annealing, as seen in Fig. 1c and d  Although there is only very weak contrast between the PS and P2VP, the very bright areas are attributed to the CdSe nanoparticles, almost completely capping the tops of the P2VP cylindrical microdomains (schematically shown in Fig. 3d ) An array of microphase-separated domains of P2VP in a PS matrix, similar to those found in previous investigations , is seen An array of microphase-separated domains, identical to that of the pure PS- b -P2VP, can be seen As soon as the incident angle is slightly above θ c , only the (1 0) reflection is pronounced (shown in Fig. 2d at 0.12°), suggesting a slight reduction in the hexagonal ordering and scattering contrast of the microdomains due to a decrease in the nanoparticle concentration within the film Below θ c (for example, 0.08° and 0.09°), as shown in Fig. 2b and c , when the X-ray penetration depth is 54 and 61 Å, respectively, the (1 0) and (1 1) scattering peaks are clearly observable Block copolymer/nanoparticle films were prepared by spin-coating toluene solutions of a mixture of 3- or 5-wt% polystyrene- block -poly(2-vinylpyridine) copolymer, denoted PS- b -P2VP, and 1-wt% tri- n -octylphosphine oxide-(TOPO)-covered CdSe nanoparticles (4 nm in diameter) onto silicon wafers Consequently, two orders of the in-plane diffraction peaks are seen at 0.0131 and 0.0227 Å -1 , corresponding to the (1 0) and (1 1) reflections of a two-dimensional hexagonal lattice with a d -spacing of 480 Å Consequently, we deduce that interfacial interactions with the substrate are mediated in a manner similar to that at the air surface Consistent with the results of Kim et al. , enhanced lateral ordering was observed upon solvent-vapour annealing  Coupled with recent advances in the synthesis of nanocrystals and the large variety of bionanoparticles that can be surface-modified and biomineralized , the synergistic assembly process described here provides remarkable control and flexibility over the fabrication of nanostructured materials with applications including chemical sensing, separation, catalysis, high-density data storage and photonic materials. Depth profiles obtained by sequential SEM images of oxygen-plasma-etched samples showed a hexagonal array of microdomains oriented normal to the film surface that persisted throughout the film (see Supplementary Information ) Each treatment imparts mobility to the thin film mixtures, allowing them to attain an equilibrium morphology within about two days Experiments on different substrates and film thicknesses showed that the perpendicular orientation is found regardless of the nature of the substrate or the film thickness Figure 1a and b show scanning force microscopy (SFM) height and phase images of a 400-nm-thick PS- b -P2VP film spin-coated from toluene and dried Figure 1e and f show the SFM height and phase images of the as-spun sample Figure 2f shows linescans as a function of the momentum transfer at q y = 0.0131 Å -1 (the (1 0) plane) for different incident angles Figure 3b shows a TEM image of a PS- b -P2VP film mixed with nanoparticles after thermal annealing Films of the pure diblock copolymer and the block copolymer mixed with TOPO were prepared and used as controls to assess the influence of the nanoparticles on the thin-film behaviour From Fourier transformation of the SFM images, a change in the lattice spacing of the cylindrical domains from 320 ± 20 to 480 ± 20 Å is seen upon annealing—this is consistent with SAXS data obtained from the bulk samples Furthermore, the orientation of microdomains, built into the system by the segregation of the nanoparticles to the interfaces, is independent of film thickness, the nature of the interfaces and the geometry of the system and eliminates the need for external fields to manipulate the orientation GISAXS investigations of the solvent-annealed samples yielded similar results Here, all the cylindrical microdomains are oriented parallel to the substrate However, after thermal annealing ( Fig. 1g , h ), hexagonally ordered features are found on the film surface In addition, the spatial correlation of the nanoparticles is characterized by the ‘shoulder’ in the data at q y ≈ 0.1 Å -1 , corresponding to an average distance between the nanoparticles of ∼60 Å, as would be expected for a closely packed nanoparticle array Incommensurability between the film thickness and period of the copolymer leads to the formation of islands and holes on the surface with a step height of one period Owing to the low magnification necessary to observe the morphology over large distances, individual particles cannot be discerned Similar surface features were also found for films that were annealed in supercritical fluid CO 2 or chloroform vapour The 150–600-nm-thick films were annealed thermally at 170 °C under vacuum, in a supercritical fluid CO 2 environment at 70 °C, or in chloroform vapours at room temperature (see Supplementary Information ) The above results indicate that, given sufficient mobility, the microdomains reorient to form hexagonally packed cylindrical microdomains oriented normal to the film surface and substrate interface The average separation distance between the particles is too large to be observed (inset to Fig. 2a ) The curves in Fig. 2f can be fitted to obtain the spatial location of the nanoparticles in the P2VP cylinders quantitatively The hexagonal packing suggests that the addition of nanoparticles has caused an orientation of the cylindrical P2VP microdomains normal to the substrate The higher-resolution SEM image in Fig. 3c , a top view of a PS- b -P2VP–nanoparticle mixture film, shows that the nanoparticles also assemble on the surface of the P2VP cylinders The nanoparticles are closely packed and the scattering ‘shoulder’ near q y = 0.1 Å -1 can be seen, even at very low incident angles where the penetration depth is only a fraction of the nanoparticle size, so the nanoparticles must be concentrated near the air–film interface The phase image maps onto the height variations from the topography of the sample The preferential interaction of P2VP with the substrate and the lower surface energy of PS force an orientation of the cylindrical microdomains parallel to the substrate The SFM images from these latter experiments are shown in Fig. 1i and j  The very pronounced phase shift indicates that the hard nanoparticles have been incorporated into the P2VP phase The X-ray penetration depth can be controlled by the incident angle, providing details on the depth dependence of the thin-film morphology These data quantitatively show the penetration of the microdomains normal to the surface, and the persistence of order over very large distances These features are macroscopic in size and the copolymer film is otherwise smooth; structural features on the nanoscopic level are absent  Thin-film samples of the block copolymer with and without ferritin-PEG particles were prepared and annealed in saturated benzene vapour This causes an orientation of the cylindrical microdomains normal to the surface This indicates that the system has reached equilibrium This interplay between assembly processes should be applicable to a wide variety of other systems, because the surface chemistry of the nanoparticles can be tuned This is consistent with the structure observed in the bulk by SAXS This is particularly important for systems like PS- b -P2VP, where interfacial interactions are so strong that even large external fields cannot reorient the domains through the entire film This is seen more clearly in Fig. 2e , where the q y linescans at q z = 0.0376 Å -1 ( q y and q z being the momentum transfer normal to the diffraction plane and normal to the sample surface, respectively) are shown at four incident angles, corresponding to penetration depths of 44, 54 and 73 Å, and the full film thickness, respectively This reorientation is similar to that seen in the PS- b -P2VP–CdSe nanoparticle mixtures This result was found to be independent of film thickness This synergy represents a significant advance over other processes that rely on sequential fabrication steps to incorporate functionality into pre-organized templates  Thus, the cylindrical microdomains of the higher-surface-energy P2VP ( γ P2VP ≈ 47 mN m -1 ) are coated with the lower-surface-energy, hydrocarbon-coated CdSe nanoparticles ( γ hydrocarbon = 30–33 mN m -1 ) , effectively balancing the surface interactions relative to the PS matrix ( γ PS = ∼39 mN m -1 )  Thus, the ferritin-PEG bio-nanoparticles are incorporated into PEO microdomains, suppress crystallization, mediate interfacial interactions and reorient the microdomains To test this, we used a blend of poly(ethylene glycol) (PEG)-tagged ferritin bio-nanoparticles, denoted ferritin-PEG (see Supplementary Information ), and a lamella-forming diblock copolymer of P2VP and poly(ethylene oxide), denoted P2VP- b -PEO To understand better the morphological changes in the thin-film blend, we carried out grazing incidence small-angle X-ray scattering (GISAXS) measurements before ( Fig. 2a ) and after ( Fig. 2b–d ) thermal annealing Together with the SFM data, these results indicate that the nanoparticles cap the P2VP cylinders at the air surface Unstained samples reveal that the nanoparticles preferentially reside within the P2VP microdomains Upon annealing at 170 °C, the nanoparticles preferentially segregate to the cylindrical P2VP microdomains where the lateral ordering of the microdomains has improved Upon thermal annealing at 170 °C for two days, the equilibrium morphology of the polymer—that is, cylindrical microdomains of P2VP in a PS matrix—develops We have shown here examples of synthetic and biologically inspired systems, where a one-step hierarchical self-organization occurs via an interplay between distinct self-assembling processes, producing spatially ordered, organic–inorganic and organic–bioparticle hybrid materials We note here that the control samples composed of mixtures of the block copolymer and TOPO showed the same behaviour We note that the bulk concentration of the nanoparticles is low and the average interparticle distance is too large to be seen by GISAXS We note that the TOPO-covered CdSe nanoparticles are stable at the temperatures used, such that aggregation caused by ligand disassociation was not observed Whereas GISAXS provides an average orientation of the microdomains in the film, TEM was used to determine whether the orientation extended from the substrate to the film surface (see Supplementary Information for experimental methods) With ferritin-PEG, the PEO crystallization is suppressed ( Fig. 4d ), and the lamellar microdomains orient normal to the surface ( Fig. 4e and f ) With the block copolymer–nanoparticle mixtures, a completely different behaviour is observed With this ability to genetically and chemically manipulate the surface properties of bio-nanoparticles such as ferritin, and to incorporate different inorganic materials into the cores using biomineralization, copolymer–bioparticle hybrid systems can be developed with unique functionalities Without ferritin-PEG particles, the P2VP- b -PEO microphase-separated into lamellae oriented parallel to the surface with the crystalline PEO located at the surface, as seen by optical microscopy ( Fig. 4a ) and SFM ( Fig. 4b and 4c )
 A 16-strong team of young conservation biologists, many already friends, decided to test that assumption But the key to this probably controversial work, he adds, was working with friends. “If youre working with people you dont know, or who are senior to you, your creativity may be constrained Former housemates and PhD labmates Richard Grenyer and David Orme kept in touch while doing their respective postdocs Grenyer was working on a massive mammal database at the University of Virginia in Charlottesville, while Orme, based at Imperial College London, UK, focused his attention on a global distribution of birds In lieu of exact species counts, conservation strategies typically rely on the assumption that geographic diversity patterns are the same among all taxonomic groups Inspired by the compatible data sets, they combined them with an amphibian database to form a huge inventory of more than 19,000 species On page 93 , the team reports that whereas the distribution of overall species richness is similar among the three groups, there is little similarity in the distribution patterns of rare and threatened species. “All of the data coming online at the same time was critical,” says Grenyer, now a researcher at the Royal Botanic Gardens in Kew, London You dont take risks,” he says.
 A peculiarity of the central disk (also possibly related to the presence of planets) is the asymmetry in the brightness of the ‘wings’  , in which the southwestern wing is brighter and more extended at 12 µm than the northeastern wing Here we present thermal infrared images of the central disk that imply that the brightness asymmetry results from the presence of a bright clump composed of particles that may differ in size from dust elsewhere in the disk Its large-scale complexity has been well characterized, but the detailed structure of the disks central ∼200- au region has remained elusive This region is of special interest, because planets may have formed there during the stars 10–20-million-year lifetime , perhaps resulting in both the observed tilt of 4.6 degrees relative to the large-scale main disk and the partial clearing of the innermost dust  We suggest that this clump results from the collisional grinding of resonantly trapped planetesimals or the cataclysmic break-up of a planetesimal. When viewed in optical starlight scattered by dust, the nearly edge-on debris disk surrounding the A5V star β Pictoris (distance 19.3 pc; ref. 1 ) extends farther than 1,450  au from the star  A detailed description of the modelling for β Pic will be presented elsewhere by M.C.W. and co-workers. At 8.7 and 12.3 µm the disks major axis was oriented vertically (that is, along a 240-pixel-long column) on the detector array At each wavelength the observation sequence consisted of imaging the PSF star, then β Pic, then the PSF star Between each exposure within a stack, the telescope was offset (‘dithered’) approximately 1 arcsec Dust mass and models To characterize the NE disk emission, we considered a single population of dust grains with the commonly used approximation that the emission efficiency Q ν is proportional to frequency Each annulus is assumed to be uniform in temperature and density Methods Observational procedure We used standard chop-nod techniques at the Gemini South telescope with a 15-arcsec chop throw orthogonal to the disks major axis Optical depths and temperatures of the annuli were used to determine the flux in the appropriate wavebands emitted by the portion of the disk in a narrow radial range Other forms for Q ν basically raise or lower the temperature and optical depth distributions, but our purpose, which is to contrast the dust properties in the NE and SW wings, is well served by our simple assumption Previous mid-infrared imaging of β Pic indicates that the major axis of the central disk is oriented at position angle 33° Regarding the clumps apparent in the 24.6-µm image, we estimate the contrast of the brightest clump at SW 60  au with the adjacent inner minimum to be approximately three times the noise, but the centroid of that clump is separated from the minimum (SW 52  au ) by less than the 24.6-µm resolution of 14  au ( Table 1 ) Some artefacts are apparent: the bright spots, due to previously known detector cross-talk, 2.5 arcsec above and below the main peak at 8.8 µm, and the optical ghost 2 arcsec above the peak at 11.7 µm The assumed value for the stellar luminosity is 8.7 L ⊙ , where L ⊙  is the luminosity of the Sun The disk observations were simulated with the flux from the model being integrated along the line of sight of each pixel The final images at 11.7, 18.3 and 24.6 µm were formed from registered stacks of five, seven and seven individual images, respectively The image was then convolved with the PSF observed at the appropriate wavelength and additional smoothing added at the same level applied for the displayed images The images at 8.7 and 12.3 µm were each obtained as a single on-source exposure The model disk extends out to 150  au and is composed of 11 annuli that are 10  au wide in the 0–110  au region and one annulus that is 40  au wide in the 110–150- au region The model is three-dimensional, with flux spread evenly in both latitude (in the range allowed by the disk opening angle) and longitude The modelling computes the distributions of temperature and face-on optical depth for the annuli that give rise to the brightness distributions observed at 11.7 and 18.3 µm The modelling procedure started with initial values for the annuli, then the parameters for each annulus were improved in turn by considering how varying them affected the resulting image The models incorporate an inclination of the whole disk to the line of sight and opening angles as free parameters for each annulus The point-like stellar flux was then included at the centre The probability that the SW 52  au clump is a chance superposition of an unrelated background object is negligibly small ( 4 × 10 -5 ), as determined elsewhere for a source of comparable brightness The PSF at 8.7–18.3 µm was determined from the K1 III star PPM 335509 (HR 2553) located ∼10° from β Pic The sky was clear during all observations, and all images were made at airmasses less than 1.2 with Gemini facility guiding and tip-tilt engaged This procedure worked from the outermost to the innermost annulus and was repeated until the parameters converged Thus, we make no firm judgement about the reality of the 24.6-µm clumps, ignoring for now the detailed 24.6-µm structure To improve the signal-to-noise ratio, the images displayed in Fig. 1 have been smoothed with gaussians of FWHM of 0.223, 0.223, 0.267, 0.356 and 0.445 arcsec at 8.7, 11.7, 12.3, 18.3 and 24.6 µm, respectively To minimize the introduction of any spurious features due to row- or column-correlated pattern structure known to be associated with this detector device, while also allowing for the possibility of detecting extended emission along the major axis at 11.7, 18.3 and 24.6 µm, T-ReCS was rotated so that the disks major axis was oriented diagonally on the array Uncertainties in the derived parameters were determined from the pixel-to-pixel deviation in the observation We ignore results for the region within 20  au of the star because of the contribution of the silicate feature and uncertainties in the PSF We note that, if ultimately confirmed, it could provide significant additional insight into disk processes We used the standard γ Reticulum to determine the PSF at 24.6 µm A point source with peak brightness normalized to the clump peak at 8.7, 11.7, 12.3 and 18.3 µm, respectively, would emit 16, 11, 17 and 15% of the total residual emission between 26 and 113  au in radius and ± 43  au along the minor axis A similar event in the β Pic debris disk would result in its flaring into visibility, perhaps as we see it today and in accord with recent suggestions that catastrophic collisions must lead to just such dramatic observable consequences. lve the issue Although detailed dust models are needed to explore this issue robustly, the key conclusion based on the relative appearance of the component SEDs is reasonably firm: the particles in the vicinity of the clump at SW 52  au differ in temperature, size and/or composition from the dust elsewhere in the disk Another possibility is that the very small particles that we observe in the β Pic clump are produced by ongoing, grinding collisions among a planetesimal population itself trapped in planetary resonances , which has the appealing attribute that the resultant clumps are quasi-permanent and thus more likely to be observable At 18 µm the minor-axis distribution through the clump peak is noticeably asymmetric, with an intrinsic width of about 19  au  At 8.7 µm, the feature, if present, is less distinct and perhaps slightly shifted towards the star At 8–12 µm, the measured minor-axis FWHM values through the clump peak are about twice the smoothed point-spread function (PSF) values (0.4–0.5 arcsec, or 8–10  au ) Because C′ coincides with our source at SW 52  au , our interpretation of their noise characterization may be inaccurate Because they are blown out of the system quickly, this collision would have occurred within a fraction of the orbital period of 270 yr, unless blow-out is substantially inhibited by gas drag  Comparing our results to recent deconvolved Keck images at 17.9 µm (refs 11 , 12 ), we do not confirm at any wavelength the tilted inner feature extending out to roughly ± 1″ from the star (see also ref. 13 ) Depending on the size distribution of collision fragments, the parent body could be substantially larger than this During six nights between ut 2 December 2003 and 3 January 2004, we imaged β Pic at the 8.7-, 11.7-, 12.3-, 18.3- and 24.6-µm regions using the Thermal Region Camera and Spectrograph (T-ReCS), the facility mid-infrared camera on Gemini Observatorys 8-m telescope in Chile For composite grains composed of silicate and organic refractory material , 1-µm-diameter particles at 52  au can be heated to 140 K, whereas the particles must be five-to-ten times smaller (0.1–0.2 µm) to attain 190 K at that distance Fragment post-collision velocities of ∼1–2 km s -1 could account for the bright clumps tentatively identified vertical size of ∼10–20  au if the collisional break-up occurred 50 yr ago However, in view of the relatively young age of the β Pic system and the evidence of orbital dynamism there , we emphasize the alternative possibility that the catastrophic collisional break-up of a large planetesimal has released a distinct, spatially asymmetric population of particles into the disk However, those disks are relatively tenuous, in contrast to the higher-density β Pic disk, where the particles are expected to be destroyed by mutual collisions on timescales too short for them to experience significant Poynting–Robertson drag  If planets are present in a debris disk, the inward migration of dust particles due to Poynting–Robertson drag can lead to resonant trapping , which produces localized structure sensitive to the physical properties of the particles If their standard deviation σ  applies to the flux within a smoothed resolution element (that is, the 0.7-arcsec-diameter smoothing kernel), the statistical significance of feature C′, as judged by its contrast with the adjacent minimum, is about unity In contrast to the total wing emission from either side ( Fig. 4 ), for which the flux density increases with wavelength to beyond 25 µm, the SED of the residual peaks shortward of 25 µm In contrast, for the same power-law efficiency we estimate the temperature of the clump particles at SW 52  au to be ∼190 K ( Fig. 4b ) In the 8.7–18.3-µm images, the SW wing of the disk is noticeably brighter than the NE wing Inseparable from the brightness asymmetry at 11.7, 12.3 and 18.3 µm is a prominent clump centred near SW 52  au  Most of the resultant residual emission, which has a high signal-to-noise ratio, arises in the projected radial band from 40 to 60  au , although it is not entirely confined to that region Nevertheless, we have found in simulations that white noise applied to a uniformly bright, extended source before image smoothing can lead to the appearance of unresolved clumps in the smoothed image resembling those detected in ref. 12  Of the several clumps identified by Wahhaj et al. in their deconvolved image (with stated resolution twice as good as the observed resolution of 0.7 arcsec), only the one near SW 52  au , which they designate C′, has a discrete counterpart in our 18.3-µm image Our mid-infrared images ( Fig. 1 ) show the elongated structure identified previously with emission from dust particles in β Pics central disk Quadratic subtraction of the PSF implies intrinsic minor-axis clump widths roughly in the range 13–17  au  Recent mid-infrared spectroscopy indicates an asymmetric distribution of sub-micrometre glassy olivine grains emitting within 30  au of the star , which is much closer to the star than the clump region That timescale is also commensurate with radiation-pressure-driven dispersal from the clump peak of high- β , submicrometre-sized debris particles at typically 4–6 km s -1 to account for the ∼40- au radial extent of the residual distribution ( Fig. 3 ) The 24.6-µm image shows several clumps, but none corresponds exactly with the one at SW 52  au  The bright ridge of emission in our image extends to the NE and includes their source C, which we do not see as a discrete source The central peak coincides with the star, for which the photospheric contribution to the total detected flux density ranges from 3% at 24.6 µm to 71% at 8.7 µm The clump appears resolved along the minor (vertical) axis at all wavelengths The clump particles may have distinct, detectable spectroscopic signatures The contrast and positions of those clumps are ambiguous enough (Methods) that we do not consider them further here The distribution is resolved along the major axis at all four wavelengths (resolution elements, Table 1 ) and is defined by the bright clump at SW 52  au and a fainter ridge extending out to ∼70  au , both of which seem to be embedded in a fainter component The model, based initially only on the 11.7- and 18.3-µm images, indicates that the optical-depth distribution in the NE wing has a maximum at 60–80  au and a gradual fall-off between 60 and 30  au ( Fig. 5 ) The NE-wing optical depth drops smoothly by factors of two and three between 70 and 120  au and 70 and 30  au , respectively, roughly compatible with the results obtained by Pantin et al. , who incorporated the brighter SW wing into their models, thereby enhancing the deduced density contrast of the hole The possible relationship of these components has yet to be explored, but the lower inferred temperatures of the clump particles ( 200 K) compared to those inner particles ( 300 K; ref. 13 ) suggests that the silicate feature, if emitted by the clump particles, would probably be at least one to two orders of magnitude weaker than that seen closer to the star The probability of observing such an event is low , but we do know that during the late stages of planet formation in the Solar System, violent, catastrophic collisions must have been common; such collisions have even been suggested to account for the origin of the Moon and structures in the zodiacal cloud  The resolution (full-width at half-maximum, FWHM) of our 18.3-µm image is 0.54 arcsec, compared to 0.5 arcsec (ref. 11 ) and 0.7 arcsec (ref. 12 ) for the original Keck images, and that feature should have been clearly evident in the innermost contours shown in our 18.3-µm image The resultant temperature distribution, which decreases gradually with distance, is much hotter than a blackbody, as expected for small, inefficiently emitting particles  The temperature is ∼140 K near NE 52  au  There are several mechanisms that produce a selective enhancement or diminishment of particles with certain ranges of size, shape or composition that can lead to a spatially localized, visually prominent inhomogeneity in the dust population of a disk They do not discuss the statistical significance of the features They would also have very high values (≫1) of β , the ratio of radiation and gravitational forces, and so be expelled quickly from the system This 200- au -sized region coincides with the slightly tilted inner disk identified optically with the Hubble Space Telescope  This distinct population, we speculate, might have a size distribution favouring particles smaller than those more widely distributed in the disk  This mid-infrared asymmetry has been seen at ∼12 µm (refs 9–11 ), and there are previous hints of it at ∼18 µm (refs 11 , 12 ) To assess this, we consider the strongest source C′, for which their contour levels are 3.6 σ  at C′ and in the range 2.4–3.0 σ  for the adjacent minimum 0.8 arcsec to the northeast To explore this contrast, we constructed a multi-annulus model for the NE emission wing, assuming it represents part of a disk, with dust particles having an emission efficiency with the generic power-law form Q ν ∝ ν , where ν is the frequency To probe the nature of the brightness asymmetry, we subtracted the emission in the fainter NW wing from the SW wing at those wavelengths for which we observed an asymmetry ( Fig. 3 ) Together these results indicate unambiguously that this feature is real We do not understand the nature of this discrepancy We emphasize that the derived structure and resolution of the clump must be viewed cautiously (and confirmed in detail), because it depends in a complex way on details of the emission on both sides of the disk We estimate the difference in the clump flux density (integrated over an image-resolution element in each unsmoothed image; Table 1 ) and that of the adjacent minimum at SW 43  au to be 15, 2 and 7 times the noise at 11.7, 12.3 and 18.3 µm, respectively, in the unsmoothed images We estimate the total mass of the mid-infrared-emitting clump particles (density, 1 g cm -3 ) to be 4 × 10 20  g, which would constitute a spherical parent body around 100 km in diameter We find that the spectral energy distribution (SED) of the residual emission is noticeably different from that of the NE wing and the central disk as a whole We identify this central fall-off with the hole inferred previously from the larger-scale SED and from 12-µm images with an assumed temperature distribution  We see it clearly at 18.3 µm, but more significantly our images show a clear trend of decreasing asymmetry with increasing wavelength ( Fig. 2 )
 After all, motion is, well, relative Although I am not sure what is meant by “Never-Ending” — infinite in physical extent, or in intellectual scope? — I agree with the phrase “A Tourists Guide”, as that is exactly what this book is But there is always a hint of doubt — otherwise why do the experiment? Such quibbles aside, I hope this book does well Chown also jumps the gun when claiming that NASAs Gravity Probe B experiment has confirmed the general-relativistic effect of space-time frame dragging by the Earths rotation when, as far as I am aware, the data are still being analysed Chown returns to the quantum only in the last two-and-a-half pages, when he touches on theories of quantum gravity Great stuff He stomps through quantum superposition, interference, uncertainty, tunnelling and indistinguishability with breathless enthusiasm He suggests that you measure gravitational energy via the heat generated from the impact He then asks how much energy would be released were the gravitational pull of the Earth trillions of times stronger — at which point I found myself worrying more about the size of the bump on my head Here we move to the einsteinian scale of the very fast, the very large, and curved space-time I am not in any doubt that the effect will be observed and reported, probably in the coming year, such is our confidence in the predictions of general relativity I could not fault the physics in either half of the book, and would take issue with only a couple of points I have seen many of the descriptions and analogies elsewhere, but that is to be expected I preferred the second half of the book, as I felt that the author enjoys the subject matter more I should give one example of the authors eye for a quirky analogy If you were travelling at constant velocity, you would see the opposite happen: everything outside your rocket would run in slow motion In his description of special-relativistic time dilation Chown describes how, if you were to travel very close to the speed of light, your time would slow down so much that the Universes whole future would flash by in an instant It is a great introduction for anyone who does not care to gain a deep understanding of the subject, or sign up to an authors pet theories, but just wants to know what all the fuss is about It is an entertaining little gem that leads the reader through many of the wonders of twentieth-century physics with a light and sometimes quirky touch that I thoroughly enjoyed It is so full of little insights and neat analogies that I found myself folding over the top corners of countless pages containing quotable passages Of course, this would be true only if you were speeding up or slowing down On consecutive pages he refers to the “weirdest manifestation of [quantum] entanglement”, the “sexiest potential use of entanglement”, and the “most mind-blowing consequence of entanglement” Such superlatives carry the reader through the subatomic landscape, not always appreciating what one sees —as is inevitable with quantum mechanics — but being left in no doubt that this really is a mind-blowing subject The first part deals with the quantum world, whereas the second focuses on Einsteins special and general theories of relativity The latter subject is easier to discuss at a non-technical level, and Chown seems more relaxed once he has guided us through the counterintuitive and wacky quantum world The Quantum Zoo is really two books in one There are many ways to describe the effects of gravitational energy, but in his playful and understated style, Chown describes the force with which a falling roof slate hits you on the head This entertaining account of modern physics carries an interesting subtitle This is what good popular science writing is all about. What is remarkable is the number of new ways Marcus Chown has found to explain difficult and often abstract concepts
 Accumulating evidence suggests that neuronal activity regulates adult neurogenesis and that new neurons contribute to specific brain functions  Adult neurogenesis, the birth and integration of new neurons from adult neural stem cells, is a striking form of structural plasticity and highlights the regenerative capacity of the adult mammalian brain  Conversion of GABA-induced depolarization (excitation) into hyperpolarization (inhibition) in newborn neurons leads to marked defects in their synapse formation and dendritic development in vivo  GABA, the major inhibitory neurotransmitter in the adult brain, initially exerts an excitatory action on newborn neurons owing to their high cytoplasmic chloride ion content  Here we show that newborn granule cells in the dentate gyrus of the adult hippocampus are tonically activated by ambient GABA (γ-aminobutyric acid) before being sequentially innervated by GABA- and glutamate-mediated synaptic inputs Our study identifies an essential role for GABA in the synaptic integration of newly generated neurons in the adult brain, and suggests an unexpected mechanism for activity-dependent regulation of adult neurogenesis, in which newborn neurons may sense neuronal network activity through tonic and phasic GABA activation. The mechanism that regulates the integration of newly generated neurons into the pre-existing functional circuitry in the adult brain is unknown A bipolar electrode ( World Precision Instruments ) was used to stimulate (100-µs duration) the perforant pathway input to the dentate gyrus A total of 530 animals were used and all animal procedures were treated in accordance with institutional guidelines Additional drugs were used at following final concentrations: bicuculline (100 µM, Sigma ), SR95531 (100 µM, Tocris ), NO-711 (2.5 µM, Sigma ) Adult (7–8-week-old) female C57BL/6 mice ( Charles River ) and Nkcc1 -/- mice housed under standard conditions were anaesthetized and retroviruses were stereotaxically injected at four sites (0.5 µl per site at 0.25 µl min -1 ) with the following coordinates (from bregma in mm), as previously described : anterioposterior, -2; lateral, ± 1.6; ventral, 2.5; and anterioposterior, -3; lateral, ± 2.6; ventral, 3.2 Construction, production and stereotaxic injection of engineered retroviruses Engineered self-inactivating murine retroviruses were used to label and genetically manipulate proliferating cells and their progeny  Data were collected using an Axon 200B amplifier and acquired with a DigiData 1322A ( Axon Instruments ) at 10 kHz Electrophysiological recordings were obtained at 32–34 °C Electrophysiology Mice housed under standard conditions were processed for slice preparation and electrophysiology as previously described  For characterizing tonic GABA currents, potassium salt was substituted with CsCl in the intracellular solution and tetrodotoxin (0.5 µM) was added to the recording solution  For dendritic analysis, three-dimensional reconstructions of the dendritic processes of each GFP + neuron were made from Z -series stacks of confocal images For measurement of E GABA , focal pressure ejection of 10 µM GABA through a puffer pipette controlled by a Picrospitzer (5-ms puff at 3–5 psi) was used to activate GABA A receptors on the GFP + DGCs with gramicidin perforated patch under voltage-clamp at different holding potentials ( Supplementary Fig. 3a ) For perforated patch recordings, the gramicidin stock (10 mg ml -1 in DMSO) was diluted in the pipette solution (135 mM CsCl, 4 mM MgCl 2 , 0.1 mM EGTA, 10 mM HEPES, pH 7.4, 300 mOsm) to a final concentration of 25 µg ml -1 just before experiments GFP + DGCs were identified by their green fluorescence, location within the subgranule or granule cell layer, neuronal morphology and capacity to generate Na + spikes (7 dpi and onwards) GFP and shRNA were co-expressed under the control of the EF1α and human U6 promoters , respectively Images were acquired on a Zeiss LSM 510 META multiphoton confocal system using a multi-track configuration Immunostaining, confocal imaging and analysis Coronal brain sections (40 µm thick) were prepared and processed for immunostaining using the following antibodies, as previously described : goat anti-DCX ( Santa Cruz ; 1:500), mouse anti-NeuN ( Chemicon ; 1:200), mouse anti-NKCC1 (T4 , Developmental Studies Hybridoma Bank ; 1:200), rabbit anti-KCC2 ( Upstate ; 1:200) and rabbit anti-Ki67 ( Novocastra ; 1:500) Intracellular chloride concentrations were calculated using the following equation: [Cl - ] i = [Cl - ] o e( E GABA F / RT ), where the extracellular Cl - concentration [Cl - ] o is 134.1 mM ( Supplementary Fig. 4 ) Methods See Supplementary Information for detailed methods Microelectrodes (4–6 MΩ) were filled with the following solution: 120 mM potassium gluconate, 15 mM KCl, 4 mM MgCl 2 , 0.1 mM EGTA, 10.0 mM HEPES, 4 mM MgATP, 0.3 mM Na 3 GTP, 7 mM phosphocreatine (pH 7.4, 300 mOsm) Perforated patch recordings with a series resistance of 80 MΩ and without significant changes ( 25%) during recordings were used for data analysis Sections were also stained for 4′,6-diaminodino-2-phenylindole (DAPI; 1:5,000) Series and input resistances were monitored, and only those with changes less than 20% during experiments were analysed Statistical significance ( P 0.01) was assessed using the Kolmogorov–Smirnov test Statistical significance ( P 0.05) was assessed using Students t -test The following short hairpin sequences were used: ACACACTTGTCCTGGGATT ( Nkcc1 -shRNA1); GGACAATATCTACCCAGCT ( Nkcc1 -shRNA2); AGTTCCAGTACGGCTCCAA (DsRed-shRNA) The peak amplitude and holding potential were plotted and E GABA was determined for each cell The projection images were semi-automatically traced with NIH ImageJ using the NeuronJ plugin The series resistance ranged from 10–30 MΩ and was uncompensated The Sholl analysis for dendritic complexity was carried out by counting the number of dendrites that cross a series of concentric circles at 5-µm intervals from the soma The specificity and efficiency of the shRNAs were validated, and high titres of engineered retroviruses (1 × 10 9  units ml -1 ) were produced as previously described  The stimulus intensity (∼30 µA) was maintained for all experiments To confirm a lack of evoked synaptic transmission, the stimulation intensity was then increased to 200 µA. To examine the evoked synaptic transmission, a train of 20 stimuli was delivered at 0.1 Hz Total dendritic length and branch number of each individual GFP + neuron in the granule cell layer were analysed We monitored V rest based on the reversal potential of the K + current through cell-attached patches ( Supplementary Fig. 3b ), to avoid underestimation of V rest due to a shunt through the seal contact between the pipette and the membrane in perforated and whole-cell recording  Activity-dependent anatomical reorganization is widely regarded as a fundamental mechanism of developmental and adult neural plasticity  Bicuculline (10 µM)-sensitive GABA-mediated PSCs ( Fig. 1c ) and CNQX (50 µM)-sensitive glutamate-mediated PSCs ( Fig. 1d ) were first detected in some GFP + DGCs at 7 dpi and 14 dpi, respectively Both voltage-dependent and -independent Ca 2+ -permeable channels could be involved Combining electrophysiology with retrovirus-mediated birth-dating and labelling, we have delineated the sequential steps involved in the integration of newly generated neurons into the pre-existing functional circuitry in the adult brain: from tonic GABA activation to GABA-mediated synaptic innervation and finally glutamate-mediated synaptic innervation ( Figs 1 , 3 ) Consistent with results from the electrophysiological studies, we found that Nkcc1 -shRNA-expressing DGCs had marked defects in dendritic arborization ( Fig. 4b , c ) Despite the caveats of defects and potential compensation during embryonic development , we found similar defects in the formation of GABA- and glutamate-mediated synapses by newborn DGCs in adult Nkcc1 -/- mice ( Supplementary Fig. 6 ) GABA exerts a depolarizing action during the initial development of new DGCs due to their high [Cl - ] i from the expression of NKCC1 ( Fig. 2 ) GABA-mediated synaptic transmission was examined in the presence of kynurenic acid (5 mM), which blocks ionotropic glutamate-mediated currents ( Fig. 3a–c ) GFP + DGCs expressing Nkcc1 -shRNA, but not the control shRNA, had significantly lower [Cl - ] i ( Supplementary Fig. 4 ) Here we have shown that tonic GABA activation depolarizes newborn DGCs ( Fig. 2 and Supplementary Fig. 3c ), and more importantly, it constitutes the bulk of GABA-induced activation during the initial integration process when the phasic GABA activation either does not exist or is weaker than the tonic activation (Figs 2d and 3b , c ) However, bath application of bicuculline (100 µM), a specific GABA A receptor antagonist , revealed the presence of a tonic current in all GFP + DGCs recorded from 3 dpi and onwards ( n = 48; Fig. 1b ) ntary Fig. 3b ) In addition, E GABA was more negative than V rest in the Nkcc1 -shRNA-expressing DGCs throughout their development ( Fig. 2c ) In addition, the frequency of SSCs recorded at 28 dpi, but not the mean amplitude, was also significantly reduced ( Fig. 3c ), further indicating defects in the formation of GABA-mediated synapses by Nkcc1 -shRNA-expressing cells In addition, we found that injection of the GABA A receptor agonist pentobarbital seems to promote dendrite growth of newborn DGCs in vivo ( Supplementary Fig. 7 ) In contrast, NO-711 (2.5 µM), a specific GABA transporter inhibitor , significantly enhanced the tonic current ( Supplementary Fig. 2b ) In the adult brain, ambient GABA is known to regulate the excitability of certain mature neurons, notably in the cerebellum and dentate gyrus  Many physiological and pathological stimulations, including neurosteroids and epilepsy, affect GABA signalling and might therefore influence the integration of new neurons in the adult brain Moreover, the mean peak amplitude of PSCs and frequency of SSCs at 28 dpi were only about 42% and 7% of those from control GFP + DGCs, respectively ( Fig. 3e , f ) Newborn DGCs in the adult brain express high levels of low-voltage activated T-type Ca 2+ channels that are activated below -57 mV (ref. 8 ) None of these shRNAs affected KCC2 expression in the infected cells in vivo ( Fig. 2b and Supplementary Fig. 5c ) Notably, stimulation of local interneurons, such as basket cells , also enhanced the tonic currents in newborn DGCs ( Supplementary Fig. 2c ) Notably, V rest was significantly more negative than E GABA during the first two weeks after viral injection ( Fig. 2a ) Our study might also have important implications for the use of stem cells in neuronal cell-replacement therapy for degenerative neurological diseases. Our study thus suggests an unexpected mechanism for activity-dependent regulation of adult neurogenesis, in which newborn neurons, before receiving any synaptic innervations, may sense neuronal network activities through local ambient GABA levels Retroviral labelling provides adequate time resolution for birth-dating and does not seem to affect the neuronal development of labelled cells ( Fig. 1a , Supplementary Fig. 1 , Supplementary Videos 1, 2 and Supplementary Table 1 ) Sequential expression of the Na + -K + -2Cl - transporter NKCC1 (a Cl - importer) and the K + -coupled Cl - transporter KCC2 (a Cl - exporter) is believed to underlie the conversion from depolarization to hyperpolarization by GABA during neuronal maturation in the fetal brain  SR95531 (100 µM), another GABA A R antagonist , also abolished the tonic current ( Supplementary Fig. 2a ) Taken together, these results suggest that GABA-induced depolarization is essential for the establishment of functional GABA- and glutamate-mediated synapses for newly generated DGCs in the adult brain The amplitude of the tonic GABA currents under whole-cell recording, however, was similar ( Fig. 2d ), suggesting that the expression levels of functional GABA A receptors responsible for the tonic activation was not significantly affected The levels of ambient GABA, regulated by interneuron activities ( Supplementary Fig. 2c ), may serve as a general indicator of dynamic neuronal network activity The mean amplitude of SSCs, however, was not significantly different ( Fig. 3f ), suggesting that there were no general defects in receptor expression at the synapses The mean amplitude of the recorded PSCs at 14 and 28 dpi was only about 12% and 65% of those observed in control GFP + DGCs, respectively ( Fig. 3b ) The mechanism by which tonic GABA activation regulates neuronal development and synaptic integration of new DGCs in the adult brain remains to be determined The polarity of GABA action is largely determined by neuronal [Cl - ] i (refs 9–12 ) The total dendritic length and branch number of these new neurons, as well as their dendritic complexity, were significantly reduced These results show that newborn neurons in the adult brain, as in neonates, follow a stereotypical integration process—first receiving tonic GABA activation, then GABA-mediated synaptic inputs and finally glutamate-mediated synaptic inputs  Three days post viral injection (3 dpi), none of the GFP + cells recorded under voltage-clamp ( V m = -65 mV) showed any spontaneous synaptic currents (SSCs) or any detectable evoked postsynaptic currents (PSCs) when the perforant pathway was stimulated ( n = 15; Fig. 1b–d ) Thus, GABA initially depolarizes newborn DGCs in the adult brain Thus, GABA-induced depolarization/excitation regulates the dendritic development of newborn neurons in the adult brain Thus, newborn DGCs in the adult brain are tonically activated by ambient GABA before any detectable phasic/synaptic activation Thus, tonic depolarization by GABA may lead to an activation of these Ca 2+ channels and subsequent Ca 2+ influx To determine the nature of GABA activation, we made perforated whole-cell patch-clamp recordings using gramicidin (25 µg ml -1 ) to allow reliable recording of GABA-induced currents  To directly examine the functional role of GABA-induced depolarization in the structural plasticity of newborn neurons, we used confocal microscopy to reconstruct the dendritic arborization of GFP + DGCs at 14 dpi ( Fig. 4a ), when active synaptogenesis occurs for GABA- and glutamate-mediated inputs To monitor the integration of new neurons in the adult brain, we used whole-cell patch clamping and recorded from GFP + DGCs in slices prepared from virus-infected animals (see Methods) Tonic activation may also provide an initial depolarization that allows a small phasic GABA activation to reach the threshold of these Ca 2+ channels Under perforated patch recording using gramicidin, tonic GABA activation led to hyperpolarization of Nkcc1 -shRNA-expressing DGCs at 7 dpi, in contrast to depolarization of the control newborn DGCs ( Fig. 2d ) Using a retroviral strategy to express green fluorescent protein (GFP) specifically in proliferating cells and their progeny , we examined the synaptic integration of newly generated granule cells (DGCs) in the dentate gyrus of adult mice ( Fig. 1 ) Using a retrovirus-mediated ‘single-cell genetic’ approach, we have shown that converting GABA-induced depolarization into hyperpolarization led to significant defects in the formation of GABA- and glutamate-mediated synapses as well as in the dendritic development of newly generated neurons in the adult brain ( Figs 3 , 4 ) We also examined the synaptic integration of newborn DGCs in Nkcc1 germline knockout ( Nkcc1 -/- ) mice  We constructed several retroviruses expressing specific short hairpin RNAs (shRNA) against different regions of mouse Nkcc1 (also known as Slc12a2 ) (ref. 22 ) We could not detect any PSCs in Nkcc1 -shRNA-expressing DGCs at 7 dpi ( Fig. 3a , b ) We could not detect any PSCs or SSCs in Nkcc1 -shRNA-expressing DGCs at 14 dpi, and the percentage of cells recorded with PSCs was greatly reduced at 28 dpi ( Fig. 3d , e ) We found that newborn DGCs (doublecortin-positive) in the adult brain express high levels of NKCC1 and little KCC2 ( Fig. 2b and Supplementary Fig. 5b, c ) We found that the reversal potential for GABA-induced currents ( E GABA ) in GFP + DGCs gradually decreased during maturation ( Fig. 2a , Supplementary Fig. 3a ), indicating a higher concentration of intracellular chloride [Cl - ] i in younger neurons ( Supplementary Fig. 4 ) We found that two different Nkcc1 -shRNAs, but not the control shRNA, almost completely knocked down the expression of NKCC1 as shown by western blot analysis of HEK293 cells ( Supplementary Fig. 5a ) and immunostaining of newborn DGCs ( Fig. 2b and Supplementary Fig. 5b ) We next examined the synaptic integration of new DGCs in the absence of GABA-induced depolarization in vivo  We then examined glutamate-mediated synaptic transmission in the presence of bicuculline (10 µM) to block ionotropic GABA-mediated currents ( Fig. 3d–f ) Within the dentate gyrus, principal neurons and interneurons form extensive recurrent connections
 And if proponents of ID reject the hypothesis of intelligent deception, their objections would be most interesting to hear, particularly the ones that dismiss the deceiver without imperilling the designer. Individuals who understand how to debate alternative scientific hypotheses would never intentionally promote religious dogma as science Sir In the ongoing debate over whether intelligent design (ID) should be taught as a legitimate alternative to evolution in schools (“Expert witness: the scientists who testified against intelligent design”  Nature 438 , 11 ; 2005 ), I suggest that ID could be presented as an alternative so long as it is always accompanied by a third option: intelligent deception So an intelligent deceiver must be at work, guiding proponents of ID to sow confusion over valid scientific debate This hypothesis proposes that the ID movement is motivated by an ‘intelligent deceiver’ To exclude intelligent deception from debates over ID versus evolution could be considered hypocritical on both legal and moral grounds
 As we report on page 19 , a boom in the solar-energy business, led by Japan and Germany, has now attracted serious interest from, among others, the technologists and venture capitalists of Californias Silicon Valley But a healthy respect for the power of entrepreneurs and free markets cannot hide the fact that they do best when choosing between possibilities that are close to market, rather than inventing entirely new options But even the possibility that the research may not get done is a reason for government to step in and ensure that it does, while trying not to crowd out private capital in the process Frances Cairncross, chair of Britains Economic and Social Research Council, has been thinking about the economics of climate change longer than most natural scientists and economists Governments need to be willing to take advice on directed research and then make it happen, rather than just hoping that curiosity will triumph unaided History may not be a guide, of course If the current rate of heady growth is to keep going for the quarter-century needed to start making a real change in the worlds energy outlook, we will need new materials to capture the Suns power ever more cheaply and easily, and new solutions to the problem of storing it In her presidential address to the annual meeting of the British Association for the Advancement of Science this week, she rightly emphasized one of the most important things that governments can do: invigorate and focus research into the basic and translational science needed for new energy-conversion technologies It is essential that curiosity-led research should flourish in these areas, and that funding bodies should encourage it so to do It is to the abiding shame of the worlds governments that, as the threat to the climate has become ever more apparent over the past two decades, funding for energy research and development has actually fallen It shouldnt Its great economic attraction is that, unlike nuclear power or carbon capture and storage, it does not need vast capital investment in order to spread Its most vigorous proponents suggest that attracting the attention of high-tech entrepreneurs could in itself be an end to our energy woes — a “distributed Manhattan project that attracts the smartest, most ideal people for the task”, as Bill Gross, serial entrepreneur and trustee of the California Institute of Technology, put it to The New York Times earlier this year Its products just need to be priced in such a way that consumers and companies want to buy them Many scientists are eager to set out in search of those technologies Once that point is reached, a solar-cell factory can produce the capacity to generate electricity as easily as a power station does, thus offering the possibility of exponential growth One of the strengths of the Manhattan project was that it tried out as many roads to nuclear weaponry as seemed plausible Solar power is a case in point Talk of a Manhattan project to tackle the generation and storage of clean energy may seem overblown The challenge of increasing energy use in the developing world while at least stabilizing and ideally decreasing carbon dioxide emissions is immense The current solar boom is dependent on old and trusted technologies — the companies now piling in are mostly finding new ways to manufacture and process familiar products The people who brought the world Moores law are eager to help it sustain itself through clean technology while accumulating yet more wealth on the way There are also areas where directed research might come into its own — where the best approach may be to try out lots of possibilities, rather than go with what a few bright people think is best There is research into new materials and technologies that small start-up companies cant do, and that larger, more staid ones, if history is a guide, wont To suggest that spending on energy research should be limited only by the capacity of scientists and technologists to make practical use of it is not to be profligate, but rational.
 A fundamental property of stem and progenitor cell division is the capacity to retain a proliferative state or generate differentiated daughter cells ; however, little is currently known about signals that regulate the balance between these processes Adult stem cells maintain organ systems throughout the course of life and facilitate repair after injury or disease  Furthermore, we show that reduction of Notch signalling leads to an increase in the number of midgut progenitor cells, whereas activation of the Notch pathway leads to a decrease in proliferation Here, we characterize a proliferating cellular compartment in the adult Drosophila midgut The ability to identify, manipulate and genetically trace cell lineages in the midgut should lead to the discovery of additional genes that regulate stem and progenitor cell biology in the gastrointestinal tract. Thus, the midgut progenitors default state is proliferation, which is inhibited through the Notch signalling pathway Using genetic mosaic analysis we demonstrate that differentiated cells in the epithelium arise from a common lineage Adult flies were cultured on standard fly media vials augmented with 200 µl of 6 mg ml -1 BrdU plus 20% sucrose After heat shock, MARCM clones were grown at 18 °C to minimize background signal from the Gal4/UAS system All steps completed at 4 °C, with no mechanical agitation All stocks were obtained from the Bloomington stock centre unless otherwise indicated Antisera The following primary antibodies were used: goat anti-GFP ( Molecular Probes ) 1:2,000; rabbit anti-β-gal ( Cappel ) 1:2,000; rabbit anti-phospho-histone H3 ( Upstate Biotechnology ) 1:1,000; mouse anti-tubulin ( Sigma ) 1:1,000; mouse anti-BrdU ( Becton Dickson ) 1:100; anti-Pros ( Developmental Studies Hybridoma Bank ) 1:40 BrdU labelling BrdU staining was performed using standard methods and modified as follows Confocal images were collected using a Leica TCS SP2 AOBS confocal system Control flies did not receive heat shock and were maintained at 18 °C Crosses were cultured at either 18 or 25 °C in humidity controlled incubators on a 12 h light/dark cycle Cultures were transferred onto fresh food augmented with yeast paste every 2–3 days during the experimental period Equal numbers of adult flies were then divided into experimental and control groups Experimental animals were subjected to between one and three 37 °C heat shocks for clone induction Flies were shifted to 29 °C for the following periods of time: N ts (15–18 days); UAS - N RNAi ; esg-Gal4,UAS-GFP , tub-Gal80 ts (17–19 days); esg-Gal4 , UAS-GFP , tub-Gal80 ts ; UAS - N intra (7–17 days) Flies were subsequently cultured at 25 °C and transferred to new media every 2 days for between 4–8 days to achieve maximal labelling Histology Adult flies were dissected in Drosophila Ringers solution Images were processed and assembled in Photoshop CS In the experiments described here only female flies were analysed Methods Fly culture and strains Flies were maintained on standard media Microscopy and imaging Fluorescent samples were examined on a Zeiss Axioskop 2 mot plus upright microscope Midguts were examined between 7–27 days after clone induction Mosaic analysis For MARCM clones, fly crosses were established and cultured at 18 °C to generate adults of the genotype y,w,UAS- GFP, hsflp ; tubulin-Gal4 / + ; FRT 82B , tubulin Gal80 / FRT 82B , hs pi-Myc or y,w,UAS -GFP, hsflp ; tubulin-Gal4 / esg K606 ; FRT 82B , tubulin Gal80 / FRT 82B , hs pi-Myc  Mounting media containing DAPI ( Vectashield ) was added and the samples were allowed to clear for 1 h before mounting Negatively marked clone crosses were established and cultured at 25 °C to generate adults of the genotype y,w, hsflp 122 / y , w ; FRT 40A , ubiq GFP / FRT 40A y +  Nomenclature In consensus with the accompanying paper , we have agreed to use the terms intestinal stem cell (ISC) and enteroblast (EB) to refer to progenitor cells of the adult Drosophila midgut epithelium. Primary antibodies were removed and samples were washed in PBST for 2 h Samples were washed in ×1 PBS plus 0.1% Triton X-100 (PBST) for 2 h, then incubated with primary antibodies over night Secondary antibodies were incubated for 3 h Secondary antibodies were removed and samples washed in PBST for 2 h Temperature shift experiments Crosses were established and cultured at 18 °C, the permissive temperature, until adulthood The entire gastrointestinal tract was removed and fixed in ×0.5 PBS ( Sigma ) plus 4% EM grade formaldehyde ( Polysciences ) for 30 min The following fly strains were used: Oregon R (wild type); esg - Gal4 (Hayashi laboratory); UAS-mCD8GFP ; esg K606 / Cyo ( esg-lacZ ); y,w, hsflp 122 ; FRT 40A , ubiq GFP/Cyo; y,w; FRT 40A y + ; y,w,UAS-GFP , hsflp ; tubulin-Gal4 ; FRT 82B , tubulin Gal80/TM6B ; y,w,hsflp ; FRT 82B , hs pi-Myc; y,w,hsflp ; esg K606 / Cyo ; FRT 82B , hs pi-Myc ; sqh-GFP ; P( tubP-Gal80 ts ) 9,w/FM7c ; Su(H)GBE-lacZ (Bray laboratory); N 55e11 (null allele of N ); N 264.47 ; N ts1 (a temperature-sensitive allele of N ); and N nd.1 ; w, UAS-N RNAi ; w ; UAS-N intra (constitutively active form, deleted extracellular domain) The following secondary antibodies were used: donkey anti-goat Alexa 488 ( Molecular Probes ) 1:500; donkey anti-goat Alexa 594 ( Molecular Probes ) 1:500; donkey anti-goat Alexa 633 ( Molecular Probes ) 1:500; donkey anti-rabbit rhodamine RRX ( Jackson ImmunoLabs ) 1:250; donkey anti-mouse Cy5 ( Jackson ImmunoLabs ) 1:250 The progeny were divided into two equal pools; controls were cultured at 18 °C and the experimental group was shifted to 29 °C We used the following dyes and mounting media: Alexa 546- and Alexa 594-conjugated phalloidin ( Molecular Probes ) 1:500; Vectashield plus DAPI ( Vector ) A greater than sixfold increase in the number of GFP-labelled cells was detected after heat shock ( n = 10,481 cells) A second population of cells containing small nuclei can be detected at a basal position within the tissue Adult esg-Gal4,UAS-GFP , tub-Gal80 ts flies grown at the permissive temperature showed no detectable GFP expression in their midguts ( Supplementary Fig Although the cystoblast and gonialblast both have the capacity to generate the differentiated cells of their respective tissues, they are thought to be more restricted in their fate than the germline stem cells Careful examination revealed that very low levels of phospho-histone H3 staining could be detected in all cells Early reports suggested that somatic stem cells were present in the adult because of morphological similarity to certain larval cells and by analogy to different insect species  Finally, although vertebrate enteroendocrine cells arise from endodermal origins they are known to express neural-specific markers  ion  High levels of phospho-histone H3 can be detected specifically in esg -expressing cells ( Supplementary Fig However, both endoreplication and the canonical cell cycle require new DNA synthesis However, double staining with DAPI revealed that elevated levels of phospho-histone H3 indicative of mitosis could only be detected among the population of cells with small nuclei ( Fig. 2e , f ) However, if a common stem cell progenitor exists in the adult midgut, then marked lineages should contain both large and small nuclei within a clone However, the esg + cell population can be divided on the basis of Su(H)GBE-lacZ expression ( Table 1 ) If the large and small nuclei are lineally distinct then marked clones should be restricted to one or the other cell type In addition, although some esg + cells appear to be wild type, we observed a region-specific decrease in the levels of esg expression and a concomitant increase in nuclear size similar to that of midgut epithelial cells ( Fig. 4f ) In addition, both esg expression and anti-Pros-labelled cells could be detected within the clones ( Fig. 3e ) In addition, the distribution of esg messenger RNA has been used as a marker for male germline stem cells  In contrast, 3 H-thymidine labelling experiments detected DNA synthesis in the adult Drosophila midgut, but no mitotic figures were observed in a large sample analysed  In contrast, esg-Gal4,UAS-GFP , tub-Gal80 ts ; UAS-N intra flies shifted to the non-permissive temperature showed a decrease in phospho-histone H3 staining compared to controls that were not shifted (mitotic index = phospho-histone H3 positive cells/adult midgut: mitotic index experimental = 0.1, n = 17; mitotic index controls = 16, n = 15) In contrast, UAS-N RNAi ; esg-Gal4,UAS-GFP , tub-Gal80 ts flies shifted to the non-permissive temperature showed an increase in the number of small cells (19 out of 20 midguts; Fig. 4d ) In contrast, when these flies were shifted to the non-permissive temperature they showed high levels of GFP expression that were detectable after 1 day and maximal by 2 days ( Supplementary Fig In control experiments, esg-Gal4,UAS-GFP , tub-Gal80 ts ; UAS-N intra flies grown at the permissive appeared to have wild-type midguts and showed no detectable GFP expression (0 out of 23 midguts; Fig. 4e ) In control experiments, UAS-N RNAi ; esg-Gal4,UAS-GFP , tub-Gal80 ts flies grown at the permissive temperature appeared to have wild-type midguts and showed no detectable GFP expression, suggesting that under these conditions UAS transgenes are efficiently suppressed (0 out of 20 midguts; Fig. 4c ) In order to characterize further the small cell population, an expression screen was conducted to identify cell-specific molecular markers In the first assay we used genetically marked wild-type cell lineages to identify dividing cells In these experiments clones were marked by the loss of a ubiquitously expressed GFP and similar results were observed (data not shown) In these experiments, wild-type lineages were positively marked in adult flies using the MARCM system  Large nuclei adjacent to each other can be differentially labelled, suggesting asynchrony in the timing or extent of DNA synthesis over the course of the labelling period Lineage analysis shows that marked clones generated in the adult contain both large and small nuclei (Figs 2b and 3f ) Mitotic recombination was induced by heat shock and green fluorescent protein (GFP)-marked clones could be detected in the midgut ( Fig. 2b ) N ts / N ts flies produced viable adults at the permissive temperature with midguts similar to wild type (11 out of 12 midguts; Fig. 4a ) N ts / N ts flies shifted to the non-permissive temperature led to a mild increase in the number of small cells (8 out of 12 midguts; Fig. 4b ) N ts flies were first crossed to an allelic series that included N 55e11 , N 264.47 , N ts1 and N nd.1  Notably, the presence of esg-Gal4 , UAS - GFP in this experiment enabled us to determine that the increased number of small cells were also esg +  Nuclei of the midgut display a distinct distribution and fall into two main categories ( Fig. 1a–d ) On the basis of nuclear size, position and morphology two general populations of midgut cells can, therefore, be distinguished On the basis of these observations, the authors concluded that no somatic cell division occurs during the lifetime of Drosophila  On this basis, we suggest that an analogous progenitor may also exist in the adult Drosophila midgut; we refer to this cell as the enteroblast (EB) Our analysis of the Notch signalling pathway in esg + cells suggests that esg +   Su(H)GBE-lacZ - cells mark a population of dividing progenitors and that Notch is necessary and sufficient to regulate proliferation Our results demonstrate that esg expression marks a population of proliferating progenitor cells in the midgut Previous studies in Drosophila have led to conflicting views over the existence of cell proliferation in the adult gastrointestinal tract  Previous studies show that prox1 , the vertebrate pros homologue, is associated with post-mitotic cells and early steps of differentiation in the central nervous system  Quantification reveals that each cell type is present in the midgut in different proportions ( Table 1 ) S1 ) S1 ) S2a, b ) S2c ) S3a, b ) S3c ) S4a–c ) Several lines of evidence suggest that pros + cells correspond to gut enteroendocrine cells Similar results were obtained when adults were heat shocked up to 10 days after eclosion (data not shown) Simultaneous detection of esg expression ( esg - Gal4 , UAS - GFP ), anti-Pros, Su(H)GBE-lacZ expression and DAPI demonstrated that small cells could be subdivided into the following classes on the basis of differential gene expression: esg -positive ( esg + ), pros -positive ( pros + ), esg -negative pros -negative ( esg -   pros - ), esg -positive Su(H)GBE-lacZ-positive ( esg +   Su(H)GBE-lacZ + ) and esg -positive Su(H)GBE-lacZ -negative ( esg +   Su(H)GBE-lacZ - ) ( Fig. 3a–d ). esg + and pros + expression define distinct cell populations ( Fig. 3c ), whereas Su(H)GBE-lacZ expression subdivides the esg + class into esg +   Su(H)GBE-lacZ + and esg +   Su(H)GBE-lacZ - subpopulations ( Fig. 3d ) Simultaneous staining with anti-BrdU and DAPI reveals that esg -expressing cells are among the population of cells that are also positively labelled by BrdU ( Supplementary Fig Studies of stem cell compartments in Drosophila have led to the characterization of two types of progenitor cells in the germ line  Taken together our experiments suggest that Notch signalling in esg + cells is necessary to restrict proliferation Taken together, our characterization of the adult Drosophila midgut suggests that a population of adult stem cells resides within this tissue The ability to distinguish different cell types using molecular markers enabled us to determine the cell lineage relationships in this tissue The adult Drosophila midgut can be identified on the basis of two anatomical landmarks along the anterior–posterior axis of the gastrointestinal tract: the cardia and pylorus ( Supplementary Fig The first is referred to as the germline stem cell and is sufficient to give rise to the respective cells of either the male or female germ line The inner surface of the midgut is lined with a layer of cells that project into the gut lumen The most prominent cells lining the midgut contain large oval nuclei that stain strongly with DAPI ( Fig. 1a , b , d ) The population of esg +   Su(H)GBE-lacZ - progenitor cells, which we have described, display characteristics of both the ISC and the EB; therefore, additional experiments will be necessary to distinguish unambiguously these alternatives. The production of marked clones after mitotic recombination depends upon subsequent cell division and is, therefore, a direct means to assay proliferation The requirement of Notch was then tested in esg + cells using a UAS-N RNAi transgene , to reduce Notch signalling The second type of progenitor cell described is called the cystoblast in female germ line and gonialblast in the male germ line The small nuclei are distant from the gut lumen and often lie in close apposition to the two layers of overlying visceral muscle that surround the gut ( Fig. 1a–c ) The weakest allelic combination, N ts / N nd.1 , also produced viable adults at the permissive temperature but showed no detectable phenotype when shifted to the non-permissive temperature (data not shown) Therefore, pros + cells probably define a population of enteroendocrine cells in the midgut These cells exhibit a region of the nucleus that does not stain with DAPI, giving the nucleus a hollow appearance These cells exhibit apical–basal polarity, as staining for F-actin reveals the presence of a distinct striated border on their lumenal surface ( Fig. 1a , b , d and Supplementary Fig These lineage-tracing experiments suggest that a stem cell progenitor exists and is sufficient to generate the distinct cell types of the adult midgut These observations demonstrate that Notch activation is sufficient to limit proliferation of esg + cells and suggests that Notch may also be sufficient to promote early steps of epithelial cell differentiation These observations suggest that esg + cells give rise to pros + cells in a Notch-independent manner This is consistent with the notion that the large nuclei are endoreplicating This observation is consistent with the suggestion that the midgut is lined by a cellular epithelium  This suggests that the ability to generate clones is not transient, and probably persists throughout the entire life of the animal This unstained region may correspond to the large nucleolus characteristic of differentiated cells Thus, cells in the midgut seem to have two distinct cell cycles; whereas both large and small nuclei undergo DNA synthesis, only the cells with small nuclei undergo cell division To ask whether esg -expressing cells also undergo cell division, the midgut was double stained to detect both esg expression and phospho-histone H3 To distinguish between these possibilities we generated positively marked MARCM clones and labelled nuclei using DAPI To distinguish between these possibilities, we used a series of three independent assays to test whether cell proliferation can be detected in the adult midgut To distinguish endoreplicating from dividing cells in the midgut we next stained the tissue with an antibody raised against phospho-histone H3 To distinguish functionally the two esg + populations, we examined the consequences of altering Notch signalling in the adult midgut To extend these findings, we conducted 5-bromodeoxyuridine (BrdU) incorporation studies To obtain both spatial and temporal control over transgene expression in esg -expressing cells, we combined the temperature-sensitive Gal80 inhibitor, Gal80 ts (ref. 12 ), with the esg-Gal4 transcriptional activator To quantify the background signal, we compared the number of GFP-labelled cells in control and experimental animals To verify that the Gal80 ts transgene functions in the midgut, we first characterized the temporal and spatial induction of a UAS-GFP transgene Together, these observations raise the hypothesis that esg expression may also mark a population of progenitors in the midgut Under conditions of Notch activation we observed a decrease in the proliferation and promotion of epithelial cell fate differentiation, while the number of pros + cells remained unaffected (data not shown) Under conditions of reduced Notch function we observed an expansion of both esg + progenitor cells and pros + cells Under the experimental conditions used, the MARCM system produced some background GFP signal that could be detected in control animals ( Fig. 2a ) We also tested the effect of Notch activation in esg + cells using N intra , a constitutively active form of Notch We also used a second independent clone marking method that did not rely on either Gal4 or Gal80 (ref. 8 ) We conclude that a population of actively dividing somatic cells is present in the adult Drosophila midgut We first tested the effect of globally reducing Notch signalling using the conditional Notch temperature-sensitive ( N ts ) mutant We found that the strongest loss of function combinations ( N ts / N 55e11 and N ts / N 264.47 ) failed to generate viable adult flies even at the permissive temperature, often dying as pharate adults (data not shown) We identified three markers expressed in small cells: escargot ( esg ), a transcription factor that belongs to the conserved Snail/Slug family; prospero ( pros ), a conserved homodomain transcription factor; and Su(H)GBE-lacZ , a transcriptional reporter of the Notch signalling pathway  We next sought to test the requirement of N only in esg + progenitor cells We note that this general conclusion of our study is consistent with an accompanying paper  We observed both large and small BrdU-labelled midgut cells ( Fig. 2c , d ) We propose a model in which esg +   Su(H)GBE-lacZ - progenitors generate at least two different types of daughter cells depending on the level of Notch activation ( Supplementary Fig We refer to this cell as the adult intestinal stem cell (ISC). esg expression in diploid cells has been shown to be necessary for the maintenance of diploidy  We therefore asked whether esg expression correlates with markers of cell proliferation When these guts were co-stained with anti-Pros antibody we observed ectopic small cells that also expressed pros , and these cells were often associated with lower levels of esg expression ( Fig. 4d ) Wild-type midguts were stained with 4,6-diamidino-2-phenylindole (DAPI) to reveal the distribution of cell nuclei within the tissue
 A two-pronged approach to silencing makes good sense Although a polymerase from bacteriophage (a virus that infects only bacteria) can produce transcripts from a eukaryotic chromosome, silencing does not occur Although bacteriophage polymerases and eukaryotic RNA polymerase III can transcribe through chromatin without disrupting nucleosomes , passage of the RNApII elongation complex leads to large changes in the chromatin  An RNA polymerase IV that apparently specializes in synthesizing siRNA precursors has recently been discovered in plants  Another question is whether siRNAs are themselves generated during transcription, a possibility suggested by the findings of Kato et al .  Because target recognition uses complementary RNA sequences, once a particular element or gene is recognized by the RNAi system, all copies in the cell will be targets for inactivation Both enzymes associate with RITS or RISC complexes and could therefore be present at the site of transcription But if this were the only mechanism, considerable cellular energy might still be wasted in making transcripts from the repetitive elements By coupling the RNAi machinery to ongoing transcription, siRNAs can identify target transcripts as they are synthesized, resulting in efficient and almost immediate repression. DNA is packed into nuclei by being wrapped around histone proteins to form nucleosomes Each of these explanations makes some testable predictions, so the process that links RITS-mediated repression specifically to RNApII may soon become clear For example, is transcription required only to initiate silencing, with the repressive chromatin being subsequently propagated by epigenetic mechanisms such as histone methylation? Or is some low level of transcription paradoxically required to maintain repression? Any transcripts made from a ‘silenced’ gene would be subject to RISC-mediated degradation, so some leakiness of transcriptional silencing may easily be tolerated Furthermore, RITS and its associated factors can be chemically crosslinked to genes undergoing silencing, and this requires siRNA and the nascent transcripts  Furthermore, several transcription-dependent modifications of histones, including the methylations described above, have been identified Histone subunits may be exchanged as the transcription complex passes through a nucleosome However, in many organisms this ‘post-transcriptional’ gene silencing is only part of the story: production of the mRNA can be shut off by a second siRNA complex called RITS (for ‘RNA-induced transcriptional silencing’) However, other questions remain However, there are several other models that could explain why only RNApII can mediate RITS-dependent silencing In addition to mRNA-processing enzymes, the RNApII elongation complex carries several chromatin-modifying enzymes  In this regard, it is interesting that a screen for factors that promote RNAi in the nematode worm Caenorhabditis elegans identified several factors that are required for proper mRNA processing  Indeed, molecular-interaction experiments show that RITS is linked to nascent transcripts as well as to RNApII (ref. 2 ) It is possible that RITS interacts with the transcript not only through base-pairing, but also by recognizing an RNApII-specific modification of mRNA (such as the cap structure or poly(A) tail) It may be that one or more of these alterations are prerequisites for the RITS-associated histone methyltransferase to modify its substrate It will be interesting to see whether transcription by RNApIV is directly coupled to the silencing complex Molecular biologists have been amazed in recent years by the discovery of an RNA-mediated mechanism for inhibiting the expression of specific genes — the RNA interference (RNAi) pathway More surprisingly, this transcription must be specifically carried out by RNA polymerase II (RNApII), the enzyme responsible for making mRNAs in eukaryotic organisms Nucleotide sequences provide a high level of specificity, but there must be an opportunity for the target sequences to be recognized Once targeted by RISC/RITS, the transcript slated for destruction can be used to generate new siRNAs One of the main functions of the RNAi system is probably to suppress expression of the repetitive elements that parasitize eukaryotic genomes Perhaps the simplest model to explain the coupling of RNA-induced silencing with transcription ( Fig. 1 ) is that RITS is tethered to some part of the RNApII elongation complex, which produces the target mRNA RITS represses transcription by recruiting a histone methyltransferase to the target genes RITS requires siRNAs for its association with chromatin, and, based on its similarity to RISC, it seemed likely that RITS would also be targeted via base-pairing of siRNAs, either to DNA or RNA  Schramke et al . ( RNA-interference-directed chromatin modification coupled to RNA polymerase II transcription ) and Kato et al . (writing in Science ) now show that a gene must first be transcribed if it is subsequently to be silenced Schramke et al . show that the transcription of the gene targeted for silencing must be carried out specifically by RNApII The dependence on transcription suggests that the target is RNA The mechanisms by which these factors affect RNAi are unknown The nuclear RITS complex can repress expression of those RNAs before they are even made The RISC complex can target any transcripts that manage to reach the cytoplasm from the nucleus, preventing them from being translated The two groups find that very different mutations in RNApII disrupt the formation of heterochromatin: truncation of the RNApII largest-subunit carboxy-terminal domain (the CTD, normally required for coupling mRNA synthesis to mRNA processing ), or a specific point mutation in the RNApII Rpb2 subunit, both lead to loss of silencing, but with an interesting difference The ‘RNA-induced silencing complex’ (RISC) contains small interfering RNAs (siRNAs) whose sequence of nucleotide bases can pair with that of a particular messenger RNA, targeting this mRNA for destruction before it can be translated into protein  There is clear precedent for the coupling of transcription with chromatin modification: two other histone methyltransferases (Set1 and Set2) bind directly to elongating RNApII and modify transcribed regions of genes  Therefore, although RITS may be targeted via base-pairing to nascent RNA transcripts, an additional mechanism must exist for specifically coupling silencing to RNApII Therefore, RNApII may have multiple roles in the siRNA pathway This enzyme modifies histones so as to make the wrapped DNA inaccessible to the gene-expression machinery, creating a silenced nucleosome configuration known as heterochromatin This requires two enzymes — an RNA-dependent RNA polymerase that generates double-stranded RNA, and the Dicer enzyme that cuts the RNA into siRNA lengths This suggests another mechanism for simultaneous transcription and silencing: perhaps RNApIV can transcribe through chromatin structures that block RNApII Through this interaction, as well as recognition of specific transcript sequences, the histone methyltransferase would be localized to the appropriate target gene and so could modify the histones as the gene is being transcribed Whereas siRNAs are made normally in the CTD truncation mutant, the Rpb2 mutant seems to be blocked in processing the siRNAs
 Calcification of the aortic valve is the third leading cause of heart disease in adults  Consistent with the valve calcification phenotype, Notch1 transcripts were most abundant in the developing aortic valve of mice, and Notch1 repressed the activity of Runx2, a central transcriptional regulator of osteoblast cell fate Despite the frequency, neither the mechanisms of valve calcification nor the developmental origin of a two, rather than three, leaflet aortic valve is known Here, we show that mutations in the signalling and transcriptional regulator NOTCH1 cause a spectrum of developmental aortic valve anomalies and severe valve calcification in non-syndromic autosomal-dominant human pedigrees The hairy-related family of transcriptional repressors (Hrt), which are activated by Notch1 signalling, physically interacted with Runx2 and repressed Runx2 transcriptional activity independent of histone deacetylase activity The incidence increases with age, and it is often associated with a bicuspid aortic valve present in 1–2% of the population  These results suggest that NOTCH1 mutations cause an early developmental defect in the aortic valve and a later de-repression of calcium deposition that causes progressive aortic valve disease. All phenotypic information was reviewed by cardiologists An annealing temperature of 56 °C was used for PCR analysis At least three independent experiments were performed in duplicate Bound proteins were analysed by SDS–PAGE and autoradiography. Clinical evaluations and genetic studies were performed in accordance with human subject guidelines after informed consent according to the protocol approved by the individual Institutional Review Boards Exons containing R1108X and H1505del mutations were amplified by PCR for each additional family member and sequenced bidirectionally Family members were studied by history, physical examination, 12-lead electrocardiogram, and echocardiography Genetic linkage analysis Autosomal genome linkage analysis was performed with 372 polymorphic DNA markers at ∼10-cM intervals (ABI Mapping Set v2.5) Genomic DNA for genetic analyses was extracted from peripheral lymphocytes Glyceraldehyde 3-phosphate dehydrogenase (G3PDH) RNA was amplified as a loading control GST pull-down assay Mouse GST–Hrt2 fusion proteins were purified with glutathione Sepharose 4 Fast Flow beads ( Roche ) for 12 h and washed twice in binding buffer (300 mM NaCl, 50 mM Tris-HCl, pH 8.0, 1 mM EDTA, 1% Triton X-100, 1% NP-40, 0.1% SDS, 0.5 mM dithiothreitol). 35 S-labelled Runx2 protein was synthesized using the T7 TNT coupled reticulocyte lysate system ( Promega ) according to the manufacturers instructions Hrt2 deletion constructs were generated as described and protein levels of mutants kept constant Identification of NOTCH1 mutations All NOTCH1 exons were sequenced bidirectionally to search for sequence variations in the probands of families A and B Immunoblots verified appropriate protein expression In brief, initial linkage analysis of family A, assuming 90% penetrance and a disease allele frequency of 1.5%, demonstrated the highest LOD score on chromosome 9q34-35 Labelled protein was incubated with GST fusion protein (2 µg) for 8–10 h at 4 °C in binding buffer with 1 mg of nonfat dried milk to compete for nonspecific interactions Luciferase activity was measured 40 h after transient transfection as described and was normalized to LacZ expression to generate relative luciferase activity ( Fig. 3a ) or expression of Hrt and Runx2 proteins ( Fig. 3e ) Luciferase assays COS7 cells were transfected using Fugene 6 ( Roche ) according to the manufacturers instructions Markers were genotyped in all family members, and linkage analysis was performed with GENEHUNTER as described  Medical records were reviewed for individuals who had died Methods Clinical phenotype evaluation and DNA collection The congenital heart disease families and individuals were ascertained for genetic linkage analyses at Childrens Medical Center, Dallas (University of Texas Southwestern Medical Center) and the University of California, San Diego Negative controls for each sample used non-reverse-transcribed RNA PCR amplification was performed with the BD Biosciences Advantage GC Genomic PCR kit following the manufacturers instructions, with annealing at 60 °C PCR analysis was performed using primers specific for Hrt1 and Hrt2 Phenotypic analysis assuming 100% penetrance yielded a single peak at 9q34-35 and a maximum LOD score of 3.5 Quantitative RT–PCR Total RNA from COS7 cells collected 40 h after transfection with empty vector and Notch1 intracellular domain expression plasmid was purified with the Trizol method ( Invitrogen ) Radioactive-section in situ hybridization 35 S-labelled antisense riboprobes were synthesized with T7 RNA polymerase ( MAXIScript , Ambion ) from 400-bp partial mouse Notch1 cDNA or plasmids encoding Hrt1 and Hrt2 Screening of identified human NOTCH1 mutations was performed with allelic discrimination assays and the ABI Prism 7900 HT Sequence Detection System using TaqMan probes on DNA from participants in the Dallas Heart Study, as described  Sequences of the 42 primer pairs for the 34 NOTCH1 exons are available on request Simultaneous duplicate experiments with an identical amount of DMSO served as a control The reporter plasmid (250 ng), p6OSE2 luciferase , and CMV β-galactosidase expression plasmid (50 ng) to control for transfection efficiency were transfected along with Runx2 expression plasmid (100 ng) and Hrt1, Hrt2, Notch1 intracellular domain and Hrt2 deletion expression plasmids (300–1,000 ng) To inhibit HDAC activity, trichostatin A diluted to 0.1 µM in dimethyl sulphoxide (DMSO) was added 24 h before collecting cell lysates Total RNA (1 µg) was reverse transcribed using the Superscript First Strand Synthesis System for RT–PCR ( Invitrogen ) With these riboprobes, radioactive-section in situ hybridization was performed on paraffin-embedded sections of E11.5, E13.5 and E17.5 mouse embryos, as described  A genome-wide scan of available family members revealed linkage of the congenital heart disease phenotype to a single locus on chromosome 9q34-35 between D9S1826 and D9qter (logarithm of odds (LOD) score, 3.5, θ = 0), spanning approximately 3 megabases (∼9 cM) (for haplotype data, see Supplementary Fig. 2 ) A proposed cellular mechanism by which valvular calcification develops is via differentiation of valvular cells into osteoblast-like cells , including upregulation of genes, such as osteopontin  A single base pair deletion at position 4515 that segregated with aortic valve disease in this family was not found in 1,138 ethnically diverse controls ( Fig. 1f ; see also Supplementary Fig. 3 ) About 10% of relatives of hypoplastic left heart syndrome patients have bicuspid aortic valve, often undiagnosed, suggesting a common genetic aetiology with phenotypic heterogeneity  Abundant evidence suggests a major inherited component to the aetiology of aortic valve disease in children and adults  All affected subjects who were clinically evaluated had the R1108X mutation, suggesting autosomal-dominant inheritance of the disease phenotype with complete penetrance ( Fig. 1a ) Although haemodynamic alterations induced by bicuspid aortic valve may contribute to calcification, several family members with tricuspid aortic valves also developed calcification Although Runx2 can be inhibited by histone deacetylase (HDAC) activity , Notch1-mediated repression of Runx2 was unaffected by the potent HDAC inhibitor trichostatin A, suggesting that it was HDAC-independent An isolated ventricular septal defect or tetralogy of Fallot with a bicuspid pulmonary valve was identified in two other affected family members (III-4 and IV-1, respectively) As bicuspid aortic valve and hypoplastic left heart syndrome may represent extremes of the aortic valve disease spectrum, the discovery of NOTCH1 as a cause of bicuspid aortic valve and a hypoplastic left ventricle in the same family suggests that NOTCH1 mutations may be the genetic basis for hypoplastic left heart syndrome in some patients As with Notch1, Hrt1 and Hrt2 inhibited Runx2 activation of the osteocalcin enhancer At mouse embryonic day (E) 11.5, Notch1 messenger RNA transcripts were abundant in the outflow tract mesenchyme, which gives rise to the valves, and in the endocardium ( Fig. 2a–d ) Because Runx2 is upregulated in mouse and rabbit models of valvular calcification , we investigated whether Notch1 normally represses Runx2 activation Bicuspid and even unicuspid aortic valves typically contain a ridge where the valve leaflets did not separate in utero ( Fig. 1g ) By E13.5, when septation of the common arterial trunk occurs, Notch1 was expressed at high levels in the endothelial layer ( Fig. 2e–h ) and mesenchyme of aortic valve leaflets ( Fig. 2g , h ), possibly explaining the increased dose sensitivity of the aortic valve Clinical evaluations demonstrated autosomal-dominant inheritance of congenital heart disease Detailed clinical phenotype information for this family is shown in Supplementary Fig. 1a  Direct sequencing of NOTCH1 in a smaller, unrelated Hispanic family with aortic valve disease revealed a second mutation that segregated with three affected family members, all with bicuspid aortic valve ( Fig. 1d , e ) Direct sequencing of NOTCH1 in an affected patient revealed a heterozygous C-to-T transition of nucleotide 3322 that predicted a premature stop codon instead of arginine at position 1108 in the extracellular domain ( Fig. 1c ) Disruption of Notch1 in mice results in death by E9.5 from vascular endothelial defects, precluding analysis of the aortic valve , but in fish and frogs Notch1 appears to be important for early valve development  Expression of osteopontin, osteocalcin and other osteoblast-specific genes is directly regulated by upstream cis elements that bind to the transcription factor Runx2 (ref. 18 ) Family member II-2 had an ascending aortic aneurysm ( Fig. 1e ; see also Supplementary Fig. 1b ) but no aortic valve disease Four family members have required aortic valve replacement for severe calcification Further studies of the NOTCH1 signalling pathway in the adult calcific process may identify preventative and pharmacological approaches to slow this age-related disease Future studies of NOTCH1 mutations in this population may reveal those at risk for a subset of severe congenital heart lesions. Hrt1 and Hrt2, also known as Hey1 and Hey2, were co-expressed in the endothelial lining of the murine aortic valve leaflet at E17.5, as well as in the endocardium and vascular endothelium ( Fig. 3b–d ) In eight, an abnormal aortic valve was the only cardiac malformation; six had bicuspid aortic valve, and seven developed calcific aortic stenosis, including three cases in the setting of a three leaflet valve In extreme cases, blood flow may be so restricted that the left ventricle fails to grow, resulting in hypoplastic left heart syndrome, the most frequent cause of death in children with congenital heart disease In glutathione S -transferase (GST) pull-down studies performed to investigate the mechanism of Hrt2-mediated repression, Hrt2 and Runx2 specifically interacted ( Fig. 3h ), consistent with the repression we observed and the reported in vitro interaction between Hes1 and Runx2 (ref. 24 ) In the fibroblast cell line COS7, constitutively active Notch1 intracellular domain repressed Runx2-induced activation of luciferase through a multimerized Runx2-binding cis element normally present upstream of osteocalcin ( Fig. 3a ) In the proband (the index case), sequencing of 100 additional regulatory genes essential for, or expressed during, cardiac development identified no other linked mutations, consistent with a monogenic aetiology (V.G. and D.S., unpublished observations) Moreover, semi-quantitative RT–PCR demonstrated upregulation of Hrt1 and Hrt2 transcripts in COS7 cells transfected with Notch1 intracellular domain ( Fig. 3g ) Nine affected family members had aortic valve disease ( Fig. 1b,g ) No cardiac conduction abnormalities, neurological deficits, or other birth defects were identified Notch directly activates the hairy family of transcriptional repressors, the central mediators of Notchs effects on gene expression Notch intracellular domain translocates to the nucleus, where it interacts with the DNA-binding protein CSL (CBF-1, suppressor of hairless, and Lag-1) to activate downstream target genes, including members of the hairy/enhancer of split (Hes) family of transcriptional repressors Notch receptors (1–4) interact with Delta(1–4) or jagged(1, 2)/serrate, resulting in two independent cleavages, first by a metalloprotease and then by presenilin , that release the Notch intracellular domain from the membrane, in a manner similar to that first described for sterol response element binding protein  NOTCH1 encodes a large protein containing an extracellular domain with 36 tandem epidermal growth factor (EGF)-like repeats and three cysteine-rich Notch/LIN-12 repeats, an intracellular domain with six ankyrin repeats, and a transactivation domain One family member (IV-4) had an associated abnormal mitral valve, resulting in mitral stenosis, and a ventricular septal defect Review of 30 known (and 57 predicted) genes revealed NOTCH1 , which encodes a transmembrane receptor (2,556 amino acids) that functions in a highly conserved intracellular signalling pathway involved in cellular differentiation, cell fate and lateral inhibition  Somatic NOTCH1 mutations have been identified in human blood cancers , but the discovery of NOTCH1 mutations as a cause of aortic valve calcification and aortic valve anomalies represents the first demonstration of NOTCH1 germline mutations in human disease The bHLH domain of Hrt2 can recruit HDACs ; however, as with Notch1, Hrt repression of Runx2 activation was not dependent on HDAC activity ( Fig. 3 ) The families reported here provided insights into the cause of a common human developmental malformation (bicuspid aortic valve) and revealed a potential mechanism mediated by NOTCH1 mutations that may predispose to endothelial dysfunction and inflammation underlying abnormal cardiovascular calcification events The heart and vasculature are enriched in the hairy-related transcriptional repressors Hrt1 and Hrt2, which mediate the Notch signal  The most severe type of aortic valve obstruction in children results in failure of the fetal left ventricle to grow, a condition known as hypoplastic left heart syndrome The mutant allele was not detected in unaffected family members or in 1,136 unrelated subjects of diverse ethnicity ( Supplementary Fig. 3 ), making it unlikely that R1108X is a rare polymorphism The Notch signalling pathway is highly conserved across species  The proband (III-1) also had mitral valve atresia, hypoplastic left ventricle and double-outlet right ventricle; his sibling (III-2) and mother (II-1) had aortic valve calcification and stenosis The valve calcification often observed in bicuspid aortic valve is a result of inappropriate activation of osteoblast-specific gene expression , but the mechanism is unknown These data suggest that Hrt proteins repress Runx2 through a physical interaction, and may mediate Notch1 repression of Runx2 These findings suggest a role for Notch signalling in the morphological development of the aortic valve These NOTCH1 mutations generate truncated transcripts that probably undergo nonsense-mediated decay and provide compelling genetic evidence that NOTCH1 haploinsufficiency results in human congenital heart disease, although dominant-negative effects cannot formally be ruled out This deletion resulted in a frameshift mutation (H1505del) that predicted a severely altered protein containing 74 incorrect amino acids at the carboxy terminus of the extracellular domain followed by a premature stop codon ( Fig. 1f ) This observation, along with the severity of calcification, led us to test whether NOTCH1 may directly affect calcium deposition This pathway participates in cell fate determination and differentiation during organogenesis throughout the embryo and is regulated by glycosylation of the extracellular EGF-like repeats in Notch1 (ref. 16 ) To determine whether Notch1 expression during development correlates with the predominant phenotype in humans, we performed in situ hybridization at multiple stages during cardiogenesis, focusing on Notch1 transcripts in cardiac valves and their precursors in mice Using Hrt2 truncation mutants, we determined that the basic helix–loop–helix (bHLH) domain of Hrt2 is necessary for full Hrt2-mediated repression of Runx2 ( Fig. 3e , f ) We identified a family of European–American descent spanning five generations with 11 cases of congenital heart disease ( Fig. 1a ) Whereas the role of NOTCH1 in preventing aortic valve calcification is relevant for adult-onset disease, its essential function in normal development of the valve is equally intriguing
 Although the southern basin is more productive, pike survival in the south decreases more quickly with population density than it does in the north Although we need additional tests and experiments at these large scales, the message seems clear: if you study populations, then you must include the potential for habitat selection. And it was, most of the time As a passenger, you want to pass through as quickly as possible At an ideal free equilibrium, every fish in each basin will, on average, produce the same number of descendants At equilibrium, the distribution of individuals among habitats is evolutionarily stable : no individual can improve its fitness by moving to another habitat But even if the system is in equilibrium after spawning, the different survival rates in each basin cause fitness to rebound more rapidly in the south But everyone with a boarding pass is trying to do the same But habitats and population sizes change, disturbing that balance But there is a catch But what if you cant do the experiment? Then you can stand the theory on its head By assuming that these growth rates were equalized through habitat selection, they could back-calculate the number of pike expected in each basin each year Can such a model really apply to natural populations? Writing in Proceedings of the Royal Society , Thrond Haugen and colleagues provide convincing evidence that it can Critics will demand more proof Dispersal between basins equalizes fitness and homogenizes population growth Do pike disperse to the basin where higher fitness was assured? And, when placed in an experimental environment, do pike adjust their habitat choice to equalize fitness? Haugen et al . answer both questions Each of these probabilities depends on such things as the size and sex of the fish, and the basin in which it currently lives First, you can do an experiment: you measure the fitness, density and dispersal of a model species living in adjacent habitats Fisheries officials, during only those three years, had reduced the population of pike in the northern basin by approximately 20% For more than 40 years, biologists captured, measured, marked and recaptured pike ( Esox lucius ) in Lake Windermere in northwest England Haugen et al . searched for the most likely models describing the pattern of pike captures in each basin Haugen et al . use an incredible data set to perform this second type of test How should animals choose which habitat to live in? An evolutionary biologist is likely to answer that they should maximize their evolutionary fitness — the likelihood that their genes will be passed on to future generations — and live in the habitat that will produce the most descendants If all individuals make the same choice, the habitat will become crowded, the probabilities of survival and reproduction will suffer, and fitness will decline If there are several queues, you choose the one that you think will move the fastest If, despite changes in density, the mean fitness actually remains equal in each habitat, the animals are following an ideal free distribution Individuals will track those changes by moving from one habitat to another until their distribution regains its evolutionary stability Instead of testing whether fitness is equal, you measure fitness at different population sizes in different habitats Many ecologists have questioned whether the theory is hamstrung by these preconditions Most previous tests of ideal free theory have been at a small scale where foragers choose between patches differing in food supply  Now apply the same principle to animals choosing their habitat Other habitats with fewer individuals might be a better option Pike in Lake Windermere provide compelling evidence that the ideal free distribution occurs at much larger scales where populations are regulated Pike reproduce only once each year, so it is appropriate to census their densities and assess habitat selection annually So animals maximizing fitness through habitat selection will disperse among habitats until no individual can improve its fitness by moving So the number of people in each queue is in dynamic equilibrium because, if one line moves more slowly than others, passengers will swap queues So with each passing year — if pike are ideal and free — their net annual dispersal should be biased towards the southern basin The authors use capture histories of individually marked pike to estimate survival and dispersal of the fish The density in every habitat thus depends on the density in others, just as the length of one security queue depends on the others The population density in both basins increases during spawning The probability of observing a given fish depends on the probability of it staying alive between census periods, the probability of it being captured when alive, and the probability of it moving between the two basins The research tells us that the spatial distribution of populations may often represent a dynamic equilibrium caused by habitat selection The system will move away from its former equilibrium Then you vary the population size; the densities and fitness of individuals in the two habitats should also vary There are two ways to test the theory There was a nearly perfect fit between predicted and actual densities There was a three-year anomaly when pike reversed their dispersal and headed north They merged these models with data on egg production to calculate density-dependent population growth rates in the two habitats They show that, every year, pike in a northern English lake move from a habitat with low fitness (a higher mortality rate) to one with higher fitness, thus eliminating the initial difference This coincided with a remarkable, serendipitous experiment This ideal free distribution assumes that an individual can estimate accurately the fitness that can be attained in different habitats, and is free to move and occupy the ideal place that maximizes fitness This lake has two basins ( Fig. 2 ), which are separate pike habitats Thus, at any given time, the average wait before passing through the checkpoint is similar for everyone at the end of the lines Thus, pike choosing between the two basins of Lake Windermere behaved as though capable of ideal free habitat selection Thus, the fitness curves in the two basins diverge ( Fig. 1 ) To understand the principle of the ideal free distribution, think of queues at airport security You assume that fitness is equalized, and then calculate how many animals should live in each habitat ( Fig. 1 )
 And, he says, scientists can apply for money for functional-screening projects as part of the pilot But Francis Collins, director of the National Human Genome Research Institute (NHGRI), says it would be a mistake to wait But opponents argue that cancer biology is too poorly understood to make such a cataloguing approach viable and say that the money would be better spent on basic research into how cancer functions But supporters point to earlier success from a similar but smaller effort — the UK Cancer Genome Project at the Wellcome Trust Sanger Institute in Cambridge Elledge and G First, the agency will pick two or three types of cancer to study and collect samples of their tumours Hannon Science 310, 439–441; 2005). “I would really like to have the sequence of all the cancer genomes, but it may not be that useful and cost-effective,” Elledge says. “They need an independent panel of scientists who can evaluate the data and really have the possibility that they will change the way the project is going to go forward.”  Collins says that the projects scientific advisory board is looking at this very question and that the agencies will take any recommendations seriously. “We will have very explicit goals,” Collins says, adding that finding drug targets should be one of them In 2002 it turned up a gene called BRAF that is mutated in most melanomas and is now a target for drug development ( Nature 417 , 949 – 954 ; 2002 ) Its budget of $100 million over three years is high, considering that the agencys budget for 2006, which has not yet been finalized, is likely to stay flat or even drop Its proponents say that tallying up all the genetic mutations in cancer cells may reveal new drug targets J J Many cancer researchers and cell biologists, though, say the big-science tactic could suck money away from other grants for years to come Others caution that the project may not generate useful information unless it includes tests that are not currently planned, such as functional assays that could identify mutations crucial for cancer-cell survival Second, it will award money to centres that can do high-throughput analyses, such as gene-expression experiments, on the tumours Stephen Elledge, a geneticist at Harvard Medical School in Boston, Massachusetts, co-wrote an open letter in October calling on the National Cancer Institute to set up clear standards by which the pilot project can be judged (S The cancer projects scientific advisory board has not yet decided which genes will be resequenced The fourth and fifth components will be grants for technology development and for bioinformatics systems The genome project was proposed by the National Cancer Institutes board of advisers earlier this year The NHGRI and the National Cancer Institute — both based in Bethesda, Maryland — will split the cost evenly. “The chance to apply this incredibly powerful engine called genomics to cancer is extremely compelling, and to say, ‘Budget times are tough, were gonna have to wait a while,’ would be unacceptable,” says Collins The NIH pilot project, announced on 13 December, is itself a major endeavour The pilot plan has five stages The pilot will be a crucial test for the institute, and for all genome scientists, as they try to make the case that they can make a difference to medicine. The project is a potentially huge undertaking that could take 10 years and cost US$1.5 billion Third, the agencies will ask its genome sequencing centres to resequence about 2,000 genes in each tumour This is part of a larger shift in focus at the NHGRI towards repetitive sequencing of genes associated with disease (see Nature 437 , 1233 – 1234 ; 2005 ) Washington DC The US National Institutes of Health (NIH) has launched the pilot phase of its controversial Human Cancer Genome Project, which aims to catalogue the genetic changes associated with cancer
 But for stars ∼10 times more massive than the Sun (∼10 M circdot; ), the powerful stellar radiation is expected to inhibit accretion and thus limit the growth of their mass Clearly, stars with masses 10 M circdot; exist, so there must be a way for them to form Here we report observations of an ammonia line towards a high-mass star forming region The problem may be solved by non-spherical accretion , which allows some of the stellar photons to escape along the symmetry axis where the density is lower The recent detection of rotating disks and toroids around very young massive stars has lent support to the idea that high-mass (≳8 M circdot; ) stars could form in this way Theory predicts and observations confirm that low-mass stars (like the Sun) in their early life grow by accreting gas from the surrounding material We conclude that the gas is falling inwards towards a very young star of ∼20 M circdot; , in line with theoretical predictions of non-spherical accretion. A detailed derivation of the mass accretion rate is presented in Supplementary Information  Although evidence of circumstellar disks or toroids in massive objects had been provided by a number of observational studies (see ref. 11 for a review), it remained to be proved that these are accretion structures, sustaining the growth of the central star(s) As expected, the line is seen in absorption towards the continuum of the H ii region: this is shown by the white contours in Fig. 1a , where one can also see the emission (black contours) detected towards the adjacent toroid G24 A2, not discussed here As the blue-shifted lobe is directed towards the northwest , it cannot originate from G24 A2 or it would not pass in front of G24 A1 As the H ii region is very bright at centimetre wavelengths (≳2,000 K), it is easy to observe the colder molecular gas (∼100 K) in absorption against it At this stage, their powerful radiation pressure appears to be strong enough to halt the infalling material , which should inhibit further growth of the star beyond the limit of ∼8 M circdot;  Clearly, the peak of absorption as well as the peak of the 1.3-cm continuum emission (that is, of the H ii region) lie at the centre of the toroid previously imaged by us (yellow line) and along the axis of the associated bipolar outflow (black arrows) Detailed models support this conclusion, and predict that hypercompact H ii regions could be long-lived because of trapping of the ionized gas owing to infall in the gravitational field of the star Evidence of infall had been found only in a very limited number of massive objects , but in no case had the simultaneous presence of rotation, outflow and infall towards an O-B (proto)star been established Figure 2 illustrates the most important finding of our study For an O9.5 star this is , much less than Mdot; acc : this should suffice to prevent the formation of an H ii region From N H 2 and the infall velocity, v inf ≈ 2 km s -1 , assuming free-fall one obtains the mass accretion rate onto the star inside a solid angle Ω : Mdot; acc ≈  Ω /(4 π )[4 × 10 -4 –10 -2 ] M circdot;  yr -1  Higher rates can be achieved either by assuming a large turbulent pressure in the molecular cores forming O-B type stars, or deepening the gravitational well around a massive star by surrounding it with a tight cluster of lower mass companions If the toroid is not only rotating, but also accreting onto the central star, one expects to see absorption at positive velocities (that is, red-shifted by Doppler effect) relative to the stellar velocity  In fact, even if the accretion phase were finished, the presence of a rotating toroid infalling on a hypercompact H ii region, located at the base of a powerful collimated bipolar flow, is broadly in agreement with the expectations of the non-spherical accretion scenario for the formation of massive stars In Fig. 2 we show position–velocity plots for both the main line ( Fig. 2a ) and the mean satellite emission ( Fig. 2b ), where the offset in position is measured along the plane of the rotating toroid In Fig. 2c we show the same plot for the CH 3 CN(12–11) K = 3 line, which was used by us to trace rotation in the toroid  In one of these, G24 A1, the presence of an early-type star is witnessed by a hypercompact H ii region (M.T.B. et al. , manuscript in preparation) with a diameter ≲0.2″ (≲1,500  au ) and located at the geometrical centre of the toroid (see Fig. 1 ) In order to solve this problem, merging of low-mass stars has been proposed , although—even in the most favourable case of induced binary mergers—to be effective this scenario requires very large stellar densities, at least of the order of 10 6 stars pc -3  In order to understand this figure, one must keep in mind that the NH 3 inversion transitions have a complex structure, made of a ‘main’ component and four ‘hyperfine satellites’ In our case, direct accretion onto the central massive (proto-)star has not yet been detected, so that the system may be in a (relatively) late phase, when the final mass of the central object has been assembled and the infalling material is being deflected in the outflow instead of being accreted In the work we report here, we have revealed the simultaneous presence of three elements in the same massive object: outflow, rotation and infall Incidentally, we note that the broad blue-shifted absorption can be used to discriminate between sources G24 A1 and G24 A2 as the origin of the outflow Increasing the mass accretion rate may be a viable theoretical solution to overcome the radiation pressure with the ram pressure of the infalling material It is also interesting to estimate the rate needed for the ram pressure to overcome the thermal pressure of the H ii region ( ) More ‘exotic’ mechanisms (such as stellar mergers) might still be required to form stars of even higher mass. Moreover, this would solve the lifetime problem ; this is related to the fact that with accretion rates typical of low-mass stars (10 -5 M circdot;  yr -1 ) the time needed to form a star 10 M circdot; would be too long ( 10 6  yr), comparable to the entire lifetime of the star Nevertheless, our detection of infall towards G24 A1 is an important milestone towards an observational constraint of the theoretical models Non-spherical accretion may also soften the problem : focusing accretion into a circumstellar disk reduces significantly the radiation pressure force along the equator by beaming the radiation in the direction of the poles Noticeably, is much larger than the critical rate above which formation of an H ii region is inhibited if accretion is spherically symmetric (that is, for Ω = 4 π ) On the other hand, the faint and broad blue-shifted absorption seen in the main line is probably due to the low-column-density gas in the lobe of the molecular outflow that is moving towards the observer: this is indicated by the lower main line/satellite ratio (that is, lower optical depth) observed in the blue line wing with respect to the one in the red-shifted absorption One sees that independently of Ω , which indicates that the accretion is large enough to brake or slow down the expansion of the H ii region through the toroid Our findings hence represent a substantial advance in this field Our results thus suggest that this is a plausible mechanism for the formation of stars at least as massive as 20 M circdot;  Stars as massive as ∼8 M circdot; are believed to reach the zero-age main sequence still accreting The continuum spectrum resembles that of a classical (Strömgren) H ii region around a zero-age main sequence star of spectral type O9.5 (ref. 18 ), corresponding to a mass of ∼20 M circdot; , a luminosity of ∼33,000 L circdot; (where L circdot; is the solar luminosity) and a Lyman continuum of 5 × 10 47  s -1  The fact that, instead, an H ii region is detected can be explained only if the accretion is not spherically symmetric ( Ω 4 π ), which in turn supports the existence of a circumstellar disk-like structure, detected by us on a larger scale as a toroid The former line is intrinsically stronger than the latter ones by a factor of ∼14, so that, roughly speaking, emission in the main line is representative of lower gas densities, whereas the satellites trace the densest material The important conclusion is that the densest gas seen in the satellite absorption is moving away from the observer at a speed of ∼2 km s -1 (see Fig. 2b ) towards the hypercompact H ii region, namely towards the star The latter (∼110.8 km s -1 ) is equal to the mean velocity of the gas in the toroid, estimated from molecules whose lines are not affected by absorption , such as methyl cyanide (CH 3 CN) The range of values reflects the uncertainty on N H 2 and on the radius at which v inf is measured The source under investigation is G24.78 + 0.08, a massive star forming region located at a distance of 7.7 kpc, studied by us in great detail  The velocity gradient in the rotating toroid is shown in Fig. 1b , overlaid on an image and contour map of the CH 3 CN emission at 1.4-mm wavelength previously obtained by us with the IRAM Plateau de Bure interferometer (PdBI) in the most extended configuration This conclusion is strengthened if one takes into account the effect of stellar gravity, which is probably non-negligible in such a small H ii region This contains a cluster of young stellar objects, three of them associated with rotating toroids This fact proves the presence of infall onto the O-type star at the centre of the toroid This has been obtained assuming an electron density and diameter of the H ii region respectively of ∼10 6  cm -3 (ref. 18 ) and 0.2″ (see above) or 0.0075 pc Three considerations are in order: (1) towards the hypercompact H ii region, the satellite absorption is strongly biased towards positive velocities, that is, red-shifted with respect to the velocity of the star; (2) the NH 3 main line is seen in absorption at both positive and negative velocities, but the blue-shifted absorption is fainter, broader, and more optically thin than the red-shifted one; and (3) the velocity gradient seen in the CH 3 CN line (indicated by the green line in Fig. 2c ) is detected also in the NH 3 main line (green line across the two emission peaks in Fig. 2a ), thus confirming the presence of rotation We hence believe that the star in G24 A1 is powering the flow We now consider the effect of our findings on current theories of massive star formation What are the implications of the detection of infall in G24 A1? Using the properties of the NH 3 (2,2) transition and an estimate of the gas temperature , one can derive the column density of the infalling gas, N H 2 , from the ratio between the main line intensity and that of the satellites , assuming an NH 3 abundance relative to H 2 of 10 -6 –10 -7 (refs 18 , 23 ) With this in mind, we observed simultaneously the continuum emission and the ammonia (NH 3 )(2,2) inversion transition at 1.3-cm wavelength using the Very Large Array (VLA) interferometer of the National Radio Astronomy Observatory (NRAO) in the B configuration
 A chance encounter “I wanted to solve the problem of consciousness,” she recalls A computer can never be perfectly isolated from its environment, so there will always be ‘noise’ in the system and, inevitably, errors will arise Aharonov devotes herself to the theory behind quantum computers Aharonov says that balancing life and work is essential to her research Aharonov, now 34, has already made important contributions to this goal by showing that a quantum computer could perform reliably and accurately despite a ‘noisy’ environment Aharonovs office is a jumble of red-and-orange patterned cushions, article reprints and wicker furniture All computers make errors when they operate, but quantum computers are more susceptible to failure As a graduate student she was not shy about contacting leading figures in the field to discuss their work, he recalls As well as her work on error tolerance, he cites an important proof Aharonov developed with Oded Regev and others while working at the University of California, Berkeley As-yet unbuilt, these machines would harness the power of quantum mechanics to perform tasks that defeat conventional computers — such as factoring large numbers At what point does the world switch from looking quantum to looking classical? Is it simply a matter of scale? Aharonov showed that for many noisy quantum systems, there is a level of noise above which a transition to classical behaviour is inevitable Back then, in 1994, the problem facing theorists such as Ben-Or was how to prevent a quantum computer from crashing Ben-Or says that what sets Aharonov apart is her boldness Ben-Or told her about quantum computation. “It fascinated me But she began to think that the problem was still beyond the reach of todays science. “Then, one day, at a wedding, a friend asked me for advice about what direction to take in the study of the brain By failing, she adds, we might discover some entirely new physics. For instance, Aharonov is not fixated on the actual construction of a quantum computer. “The most interesting thing that might come out of an attempt to build one is the discovery that we cant do it,” she says Her daily yoga session is particularly rewarding, she says: “It disperses the fog Her uncle, Yakir Aharonov, is a physicist at Tel Aviv University, and her father is a mathematician who taught her the beauty of numbers when she was little I advised him to check out what people in computer science were doing,” she says It did It was mathematics, physics and philosophy all in one package,” she says Its an appropriate setting for a theorist who has proved that when disorder reaches a certain level, the physics of the quantum realm switches into the classical domain of the world we see every day Like many theorists, she says that she has her best ideas when not thinking about work at all Moreover, correcting such errors is almost as difficult as doing the calculation in the first place My intuition becomes sharper Physics runs strong in Aharonovs family Realizing she should take her own advice, Aharonov went to the Hebrew Universitys computer-science building to find someone to talk to She later chose physics and mathematics for her undergraduate studies, but the quantum world did not initially capture her imagination She wanted instead to use physics to study the brain She was directed to Michael Ben-Or and, as she knocked on his door, she says that she had a strong feeling something important was going to happen So will it ever be possible to do a reliable quantum calculation? “That was the problem I posed to Dorit,” says Ben-Or, who became Aharonovs dissertation supervisor and later her collaborator Such transitions are much sharper than expected from other theories that predict a gradual shift away from quantum behaviour  The corridors of the computer-science building at the Hebrew University of Jerusalem are stark, white and neat The proof showed that two existing models for quantum computing are actually equivalent and, as a result, made writing quantum algorithms easier This is because the quantum states on which calculations depend are very delicate: complex phenomena, such as the spin states of atomic nuclei, can store quantum information but this data can easily be lost if the particles interact with their surroundings To enter Dorit Aharonovs office is to experience a sudden transition between order and disorder When there is less struggle, ideas become clear.”  Eastern ideas about the interconnectedness of everything also influence her work While at Berkeley, Aharonov extended her work on computers to address a fundamental puzzle presented by quantum mechanics — why its laws are evident in the world of elementary particles, but not in everyday life Working with Ben-Or, Aharonov proved that at a constant but low level of system noise, a quantum computer can still produce accurate results . “I consider her to be one of the most outstanding young people in this field,” says Peter Zoller, a theoretical physicist at the University of Innsbruck, Austria Zeph Landau, a mathematician at the City College of New York who collaborated with Aharonov on the model equivalence paper, says that she is focused but not single-minded, finding time to discuss other pursuits Zoller wants to build a quantum computer, and he says that Aharonov has been instrumental in laying the theoretical foundations on which a real machine could be constructed
 Although he did assert that a religious education is harmful to the development of a free, enquiring spirit, he focused almost exclusively on the personal traits of the scientists, not on the social structures and contexts that impeded or aided their research And yet, as Jack Meadows explains in The Victorian Scientist , Galton was living through, and even helping to bring about, a revolution in the way science was done And, more importantly, the achievements of science owe at least as much to salaries and state support as to flashes of brilliant insight As Meadows emphasizes, the quality and quantity of science rose dramatically when, having been put on the state payroll, scientists were seldom hamstrung by having poorly connected relations or little inherited wealth As the states purse strings loosened, the social complexion of science altered, with more members of the middle and lower classes of society entering its ranks British science, it is generally acknowledged, finally became a professional activity during the lengthy reign of Queen Victoria But by 1900 it had emerged as a full-time occupation practised by salaried experts But Meadows also makes more serious points But, as Meadows points out, there were plenty of losers in this process of professionalization, as those with dual loyalties to science and other callings were increasingly forced out, demoted to the rank of mere collectors and made to feel unwelcome at the ‘high tables’ of science, such as the Royal Society Charles Darwin seldom called on the government for financial assistance, but his great breakthrough was critically dependent on Britains trading interests, a well-funded navy, and a vast network of trading posts, consulates and scientific societies back home that encouraged his activities and helped him make sense of his finds For instance, some Victorian scientists thought the word implied creating not university posts but a powerful intellectual élite made up largely of independently wealthy gentlemen He explores how scientists forged links with both industry and universities, and demonstrated the practical advantages of scientific discovery (not least Lord Kelvins contribution to laying the undersea cables for international telegraphy), as well as the potential of pure research His aim was to work out the ingredients of heredity, education, outlook and aptitude that went into making a good scientist Huxley and his allies, for example, fought hard to exclude amateurs from Victorian science, even though many of the greatest discoveries of the day had arisen from the earnest endeavours of those who, like Darwin, had neither laboratories nor official positions In 1873 the Victorian scientific polymath Francis Galton sent out a printed questionnaire to the most distinguished fellows of the Royal Society in London In an accessible style, Meadows charts the long struggle that saw science enter school and university curricula despite fulsome opposition from the admirers of ancient languages It is also widely agreed that this was a virtually unqualified boon It was a calling once dominated by amateurs, many of them clergymen with undemanding livings, barristers with few briefs or little interest in the law, and gentlemen of leisure unfulfilled by rural sports Less and less often were scientists of humble means obliged to eke out a living writing textbooks and going on lecture tours Meadows adds colour to this story with plenty of striking anecdotes, such as William Buckland dining on bluebottles, and Lyon Playfairs near-suicidal chemistry experiments Meadows discusses the transfer of mainstream science from the garden, field and makeshift laboratory to the purpose-built and lavishly equipped labs of the late nineteenth century Nevertheless, The Victorian Scientist is to be recommended for giving non-specialist readers a much more complete picture of the context of nineteenth-century science. Nor does Meadows consider how professions operate as technocratic monopolies, often hostile to the non-professional, no matter how competent his or her research One serious omission from this book is any real discussion of what the term ‘professional’ means, then and now One somewhat embittered contemporary pointed out further advantages that Darwin enjoyed. “Darwin is an enviable man,” he wrote, having “a pleasant place, a nice wife, a nice family, station neither too high nor too low, a good moderate fortune, and the command of his time.” These last three were particularly important P Snows phrase — is neither realistic nor especially helpful The professionalization of science, which began in German universities but later spread across the developed world, was a vital prerequisite for the discoveries that have made science such a powerful force in the modern world The received model of scientific progress — that it was brought about by a handful of other-worldly “scientific Shakespeares”, to use C The results were published in his 1874 book English Men of Science  There are mentions too of Lord Kelvins self-belief and Thomas Huxleys wit There is much more to telling the history of science than cataloguing its intellectual attainments This book also shows how the prestige of science rose, and with it the willingness of government to bankroll its endeavours To nobodys great surprise, this dogmatic hereditarian concluded that most scientists were born rather than made
 Animal-rights groups force researcher to quit studies Chalk one up for the animal-rights activists Announcements of new commitments to the Global Fund may come during the AIDS meeting Barnes refuses to take Ringachs home address off the Primate Freedom Project website until he apologizes Bush announced plans to redirect NASA towards exploration of the Moon and Mars ( Nature 427 , 667 ; 2004 10.1038/427667a ) But it fell to Sloan Kulper, an architecture student at the Massachusetts Institute of Technology (MIT), whose interest in biology led him to sit in on the lectures of Shuguang Zhang, an MIT biomedical engineer But Jean Barnes, head of the Primate Freedom Project of Fayetteville, Georgia, is not satisfied But the die is not yet cast Ecologists warn that the hardy, fast-spreading strain could overwhelm native species in the northwestern United States Electronic ark to hold all known animal species Its being called a genome project for zoology, the fields equivalent to the Moon landing Gates gift to Global Fund shames governments On the eve of the XVI International AIDS Conference, held in Toronto this week, the Bill and Melinda Gates Foundation stepped up pressure on governments by pledging the largest non-governmental donation yet to the Geneva-based Global Fund to Fight AIDS, Tuberculosis and Malaria He gave up after an incident on 30 June in which Lynn Fairbanks, another primate researcher at UCLA, found an unexploded home-made bomb on her front porch He is still seeking funds. In 2003, NASA joined forces on the project, but pulled out a year later when President George W In a 4 August e-mail to activists titled “You win”, Dario Ringach, a neurophysiologist at the University of California, Los Angeles (UCLA), announced that he would cease all research on animals immediately. “Please dont bother my family any more,” he added It already contains details of the 1.5 million species compiled as the electronic archive of the past 150 years of the Zoological Record  Its interior is packed with biological references, from a crystal-shaped lecture theatre to handrails jointed with nucleosome shapes NASA also announced plans to study concepts for two smaller missions to study dark energy: ADEPT from Johns Hopkins University in Baltimore, Maryland, and DESTINY from the National Optical Astronomy Observatory in Tucson, Arizona NASA climbs back on board dark-energy mission NASA is renewing its support for a space mission to investigate dark energy, the mysterious force that could make up two-thirds of the energy density of the Universe On 9 August NASA said it will re-enter SNAP by supporting a concept study, which will also provide a cost estimate, likely to be several hundred million dollars. “Im optimistic,” says Saul Perlmutter at Lawrence Berkeley Laboratory, a principal investigator on the SNAP collaboration Paul Zeitz, executive director of the non-profit organization Global AIDS Alliance, based in Washington DC, estimates that the Global Fund will require $11 billion per year by 2010 Ringach had been harried by activists protesting against his work on visual processing in macaques Scientists working for the US Environmental Protection Agency in Corvallis, Oregon, say they have found the plant, known as creeping bentgrass ( Agrostis stolonifera ), 3.8 kilometres away from experimental plots Seeds and pollen have been dispersed by the wind, they report in a forthcoming issue of Molecular Ecology  Since 2002, the Global Fund has provided $5.5 billion, mostly from governments, to 132 countries Students organic design gives lab a cell structure Its an opportunity any architect would die for The database was established to end the confusion caused by information on new species being published in different journals (see Nature 437 , 477 ; 2005 ) The funds executive director, Richard Feachem, says it still needs $500 million to finance its next round of grants in November The Gates Foundation said on 9 August that it will give US$500 million over five years on top of the $150 million it has already donated to the fund The resulting cell-shaped building has passed through technical review The strain, bred by horticulture supplier Scotts, in Marysville, Ohio, is engineered to be resistant to the herbicide Roundup The Supernova Acceleration Probe (SNAP) was first proposed by scientists at the US Department of Energys Lawrence Berkeley National Laboratory in California in 1999 This will make it hard to eradicate from areas where other grasses are grown and managed with herbicides, warn ecologists Transgenic grass strain escapes into the wild A transgenic strain of grass bred for golf courses has spread from test plots and established itself in the wild, researchers say UCLA has defended the animal research it hosts, arguing that it helps to improve human health and society When Zhang was asked to advise on a new nanobiomedical institute at his alma mater, Sichuan University, he encouraged Kulper to design a building for it, drawing on the biology he had learned With the backing of the International Commission on Zoological Nomenclature (ICZN), ZooBank will be the official registry for new species. “ZooBank will revolutionize the way in which those people using scientific animal names can work,” says Andrew Polaszek, a taxonomist at the Natural History Museum in London and executive secretary of the ICZN Zhang says the building would be too expensive in Europe or the United States, but will cost no more than US$10 million in China ZooBank, an online database of all known animal species, was launched on 10 August ( www.zoobank.org )
 And several states have legislation that bans the import of nuclear waste Australia has an obligation, he says, as one of the worlds largest uranium suppliers, to be part of the solution for disposing nuclear waste. “We would be doing a good turn, environmentally, for the world,” he told Nature  Australias geological and political stability makes it an attractive site for waste disposal, he says But Byrne thinks attitudes may be shifting. “If Hawke had suggested this a year or so ago, it would have been seen as ridiculous But the nuclear debate has come a long way.” He adds, “if Australia is to be part of the nuclear cycle as a supplier, then we need to be thinking about waste disposal as well”. Environmentalists disagree. “Its fanciful,” says Ben Pearson, an energy campaigner for Greenpeace in Australia, who argues that it would be too dangerous to transport large amounts of nuclear waste around the world. “Ships sink; accidents happen,” he says Hawke claims that the arrangement would be worth billions to Australias economy. “It would be an enormous source of income that we could use to address our own environmental problems,” he says. “Its not a far-fetched idea,” says nuclear physicist Aidan Byrne, who heads the department of physics at the Australian National University in Canberra Hawke plans to rally further discussion on the topic. “I want to get a sensible debate going,” he says. “I would like the Australian scientific community to put resources into confirming the safest sites.”  The proposal will struggle to get political support; the federal and state governments cannot even agree on where to store the nations own small amount of low-level nuclear waste Overseas nuclear-power users would pay to ship their waste to Australian shores, where it would then be transported to sites within the vast, sparsely populated regions of Western Australia or the Northern Territory Robert (Bob) Hawke, prime minister from 1983 to 1991, made his suggestion to a gathering of graduates in Sydney on 26 September Sydney Australia should become an international repository for nuclear waste, according to a former prime minister The idea has outraged environmentalists, but some scientists are giving it cautious consideration
 A few years ago, Albert Stolow of the National Research Council Canada in Ottawa and his colleagues married this method with a laser whose pulses last less than 100 femtoseconds, or 10 −13 seconds A new species arises when populations within an existing species have diverged so far that their members can no longer interbreed to produce fertile offspring A new study reveals how tweaking the materials pore size might maximize the amount of hydrogen they can store A promising technique is the femtosecond version of photoelectron spectroscopy Although larger pores would in theory accommodate more hydrogen, researchers at the University of Nottingham and the University of Newcastle upon Tyne, UK, found that bigger pores have a smaller affinity for the gas Animal behaviour: Once bitten Anim Astronomy: When the giant has passed Science 313, 1413–1416 (2006) Earth-like planets could exist in as many as a third of the planetary systems that have been found to harbour giant planets, new simulations suggest, despite the havoc wrought when the giants wander Behav. 72, 305–311 (2006) In queenless ant colonies, one or a few workers nevertheless corner the mating and egg-laying market Better predictions of monsoon failure would allow rural communities to prepare in advance Blanchet et al  But a siblings offspring share only around a third of the ants genes, so the victim would do better by reproducing itself But a team led by Sheng Yang He of Michigan State University in East Lansing has shown that the kidney-shaped guard cells around the pores on Arabidopsis leaves use receptors that detect bacterial compounds and trigger the stomata to close Cell biology: A twist in the tail Cell 126, 905–916 (2006) Researchers have discovered a novel type of histone modification Chem Christian Peeters of the Pierre and Marie Curie University in Paris, France, and his colleagues wondered whether the newborns fight back Combining these data with photoelectron measurements gave a picture of the electron clouds in the molecular frame — a most important milestone CXCL12, a cell-signalling molecule secreted by the meninges, seems to play a key part Edn doi:10.1002/anie.200601991 (2006) Fuel tanks for the hydrogen-powered cars of the future could be made from sponge-like materials known as metal organic frameworks Either approach, or both combined, should get us closer to understanding reaction dynamics from the most natural point of view: the molecules! Evolutionary genetics: One small hop for a gene.. George Whitesides and his team used the pores of an aluminium oxide membrane as a template to make arrays of columns some 200 nanometres wide and a few micrometres long Geßner et al  Hoerling and his team compared El Niño events that led to drought with those that did not In many of these systems, giant planets that formed in the outer reaches appear to have migrated inwards, forming hot Jupiters In most Diacamma species (pictured below), they do so by mutilating every other ant In the materials the team studied, the optimum pores had a diameter of about 0.7 nanometres In the traditional version, ultraviolet light knocks photoelectrons from the target molecule, revealing the molecular electronic structure In this reaction, the molecule breaks up, which allows its initial orientation to be determined by detection of the fragments Int It turns out they dont when the attacking ant has reproduced and might therefore be their mother, but do when the attacker is young and so probably a sibling John P Journal club Henrik Stapelfeldt Aarhus University, Denmark A chemist tries to see things from the molecules perspective JYAlpha hopped between the chromosomes at least 300,000 years ago Masly of the University of Rochester, New York State, and his colleagues identify a novel molecular mechanism by which this can happen Materials science: Hydrogens happy medium Angew Menno de Jong of the Hospital for Tropical Diseases in Ho Chi Minh City, Vietnam, and his colleagues characterized 18 cases of H5N1 and 8 of regular flu Monsoon forecasting Science doi:10.1126/science.1131152 (2006) Detailed measurements of sea surface temperatures may improve predictions of Indias monsoon, say Martin Hoerling of the National Oceanic and Atmospheric Administration in Boulder, Colorado, and his colleagues My lab recently developed a complementary solution, using laser-based techniques to hold molecules in fixed orientations Nanotechnology: Short straws Nano Lett. doi:10.1021/nl061786n (2006) An approach to building complex pillars from polymers and gold, devised by chemists at Harvard University in Cambridge, Massachusetts, could find application in solar cells and light-emitting diodes Nature 401 , 52 – 54 ; 1999 10.1038/43410 ) Neuroscience: Guided trips in the brain Nature Neurosci. doi:10.1038/nn1764 (2006) The thin layer of tissue that surrounds the brain, known as the meninges, has an unexpected role in brain development, say Victor Borrell and Oscar Marín of the Institute of Neuroscience in Alicante, Spain Now researchers in the United States report simulations that suggest that Earth-like planets can form in the habitable zones after the giant has passed One key element was missing, however One research goal in my laboratory is to watch, in real time, how atoms exchange and electrons rearrange during a chemical reaction Plant biology: Plants shut out invaders Cell 126, 969–980 (2006) Researchers in the United States report that plants batten down their hatches to protect against invaders, by closing the small pores on their leaves that are known as stomata (pictured below) Previously it was thought that stomata were simple portholes, which open to allow carbon dioxide uptake and close to prevent excessive water loss Recently, Stolows group found a way around this problem for one process: the photoinduced cleavage of the nitric oxide dimer ( O Researchers thought such migrations were likely either to disrupt the formation of terrestrial planets in the stars neither-too-hot-nor-too-cold habitable zone, or to scatter such planets into unsuitable orbits Science 311, 219–222; 2006 ) Science 313, 1448–1450 (2006) Genes relocating from one chromosome to another could underlie a defining event in the origin of species, say researchers Scientists want to observe these processes from the molecules frame, rather than from the laboratory Such planets, the model predicts, would be peculiarly water-rich and iron-poor compared with Earth The authors tracked the migration of Cajal-Retzius cells in mice, and found that the cells move to their positions by travelling along the meninges The cis form bends the tail sharply and allows another enzyme, Set2, to chemically alter a neighbouring amino acid, which affects the activity of genes in the surrounding DNA The crop-watering rains are known, from historical records, to be prone to fail when a climatic event known as El Niño warms the surface waters of the Pacific The inflammation response may contribute to respiratory failure The mutilated ant would only have passed on half its genes to any of its offspring, the same fraction that it shares with the offspring of its mother The researchers also found elevated levels of inflammatory molecules known as chemokines and cytokines in H5N1-infected individuals, consistent with earlier results from in vitro and animal studies The researchers also show that, to get around this defence mechanism, the plant pathogen Pseudomonas syringae manufactures a compound that forces the stomata to re-open after 3 hours The researchers reason that this makes genetic sense The researchers suggest it would be possible to create efficient light-collecting or light-emitting devices from these structures by filling their hollow parts with a conducting polymer The team suggests that these tail changes could also alter the structure of chromatin, the larger-scale packaging of DNA and proteins, which is known to control gene behaviour Their discovery comes from a study of Cajal-Retzius cells, a transient population of cells that sits at the edge of the brain and guides the development of neuronal layers in the cerebral cortex They bite off an appendage necessary for mating soon after the ant emerges from the cocoon They conclude that the optimum pore size is obtained when increasing capacity is balanced with decreasing affinity They conclude that the risk of monsoon failure depends on where the waters warm most: elevated temperatures in the central Pacific seem to be more strongly associated with drought than elevated temperatures in the eastern Pacific They found that it switches the amino acid proline, found in the protruding tail of histone H3, between two different mirror-image forms known as cis and trans  They identified a gene essential for male fertility, JYAlpha , on the third chromosome of the fruitfly Drosophila simulans , but on the fourth chromosome of Drosophila melanogaster  They produced an assortment of composite structures: some with a hollow polymer core surrounded by a gold shell electrode, others containing adjoining gold and polymer segments They show that this was responsible for making some of the male offspring bred from a cross between the two species sterile This provided the time resolution needed to follow the flow of charge and energy during reactions (V This requires that we measure the electrons emission directions with respect to the parent molecule, a fundamental experimental problem because the molecule tends to orient randomly This structural change to the proteins that package DNA can affect gene regulation Those patients killed by H5N1 showed the highest loads of the virus Tony Kouzarides and his team at the University of Cambridge, UK, studied an enzyme called Fpr4 in yeast Virology: Deadly response to bird flu Nature Med. doi:10.1038/nm1477 (2006) A comparison of patients infected by the avian influenza virus H5N1 with those suffering from human flu adds weight to arguments that H5N1s deadliness is linked to the strength of the immune response that it provokes
 A report from a National Academies panel chaired by Thomas Cech, president of the Howard Hughes Medical Institute in Chevy Chase, Maryland, says that postdoctoral training should be limited to five years Between 1980 and 2003, for example, the percentage of grants going to researchers aged under 40 fell from more than a half to less than one-fifth. “Weve come up with recommendations that are evolutionary, not revolutionary,” says Cech, who hopes this will make it easier for the NIH to implement them. “The vitality of the biomedical sciences in the United States depends on taking some action soon,” he adds. Cech says that, if implemented, the recommendations will “encourage young investigators to take on top-rate, important projects, to deviate from the research of their previous mentors, and to strike out in new directions, tackle new systems and develop new methods” He notes that a steering committee to deal with the other recommendations has already been set up It recommends awarding 200 of them annually, worth $500,000 each over five years. “The current NIH grant system really honours safe research in well-established pathways,” Cech claims. “We want to break away from that and find mechanisms that will free up researchers in the early stages of their career to make the big discoveries that are really going to have an impact on medicine and on human health.”  Last June, NIH director Elias Zerhouni asked the National Academies to look into mechanisms that would enhance postdoctoral training and foster young researchers independence The 18 March report also says that postdoc training grants should be made available to non-US citizens, and that money should be transferred from the NIHs main funding mechanism to support independent research awards that would enable postdocs to pursue their own projects The report was requested after it emerged that the NIH budget is increasingly going to fund older, established researchers The study also suggests that the NIH should introduce a class of investigator grant specifically tailored to help young scientists moving into their first posts as independent investigators Washington The US National Institutes of Health (NIH) is being urged to introduce a set of reforms to improve the lot of postdocs and increase their chances of establishing independent scientific careers Zerhouni says that some of the committees recommendations — such as that requiring senior researchers to describe in their grant applications what they would do to nurture their postdocs careers — could be implemented relatively quickly
 Analysis of GSCs mutant for dicer-1 ( dcr-1 ), the double-stranded RNaseIII essential for miRNA biogenesis, revealed a marked reduction in the rate of germline cyst production Hence, the miRNA pathway might be part of a mechanism that makes stem cells insensitive to environmental signals that normally stop the cell cycle at the G1/S transition. Here, we report the necessity of the microRNA (miRNA) pathway for proper control of germline stem cell (GSC) division in Drosophila melanogaster  On the basis of cell cycle markers and genetic interactions, we conclude that dcr-1 mutant GSCs are delayed in the G1 to S transition, which is dependent on the cyclin-dependent kinase inhibitor Dacapo, suggesting that miRNAs are required for stem cells to bypass the normal G1/S checkpoint One of the key characteristics of stem cells is their capacity to divide for long periods of time in an environment where most of the cells are quiescent Therefore, a critical question in stem cell biology is how stem cells escape cell division stop signals These dcr-1 mutant GSCs exhibit normal identity but are defective in cell cycle control For female germline clones, Flp-FRT flies were heat shocked (third instar larvae for 1 h, pupae for 1 h at 37 °C) and dissected 5–12 days after the last heat shock For male germline clones, adult flies were heat shocked for 40 min at 37 °C twice per day for 3 days and dissected 2–6 days after the last heat shock Hariharan), anti-BrdU (1:20, PharMingen ) and anti-c-Myc (1:50, Calbiochem ), rabbit anti-PH3 (1:200, Upstate Biotechnology ), anti-GFP (1:1,000, Molecular Probes), anti-Vasa (1:10,000, P Lasko) and anti-P-Mad (1:500, P. ten Dijke), guinea-pig anti-CycE (1:500, T McKearin), Alexa 488, 568, or 633 goat anti-mouse , anti-rabbit and anti-guinea-pig (1:500, Molecular Probes ), and goat-anti-rat Cy5 (1:250, Jackson Immunoresearch ). Methods We used the following stocks: eyFLP;FRT82Bdcr-1 Q1147X /TM3Sb , eyFLP;FRT82Bdcr-1 d102 /TM3Sb , eyFLP;FRT42Ddcr-2 L811X /CyO , eyFLP;FRT82B parental , w ; FRT42Bdap 4 /CyO (ref. 25 ), dap5gm (ref. 23 ), w;NGT40/SM6a;nosGal4VP16/TM3Sb , hsFlp;FRT82BUbi-GFP/TM3Sb , hsFlp;FRT42BUbi-GFP/CyO , hsFlp;FRT42DUbi-GFP/CyO , FRT82BhsNmyc  Orr-Weaver), rat anti-BamC (1:1,000, D We used the following antibodies: mouse anti-CycA, anti-CycB, anti-Adducin (1:20) and anti-Armadillo (1:40) (Developmental Studies Hybridoma Bank), mouse anti-Dap (1:5, I A Dap transgene lacking these sites showed no response to Dcr-1 levels ( Fig. 4b ; see also Supplementary Fig. 3b, c ), suggesting that the potential binding sites are responsive to Dicer-1 Although dcr-1 mutants showed reduced numbers of gametes, most developing gametes appeared morphologically normal (although they exhibit polarity defects; data not shown) Analysis of dcr-1 mutant clones in the Drosophila ovary 12 days after clone induction revealed a marked depletion of developing egg chambers (see Fig. 1b–f for dcr-1 Q1147X and Supplementary Fig. 1a for dcr-1 d102 ) Because Dap is a key component of the G1/S transition , it is a plausible target for machinery that assures continuous cell division in a microenvironment in which most of the cells are quiescent Because miRNAs are a novel class of genes involved in human tumorigenesis , it is tempting to speculate that miRNAs could have a similar role in cancer cells. Clonal experiments revealed that the percentage of germaria with clonal stem cells at different time points after clone induction was similar in the dcr-1 Q1147X mutant and the wild-type control ( Fig. 2b ), suggesting that the loss of cysts in dcr-1 mutants is not primarily due to problems in the maintenance of GSCs Consistent with this, overexpression of a Dap transgene resulted in some germaria resembling dcr-1 germline mutants: the germaria were small, containing a few cysts, and had a high number of CycE-positive GSCs ( Fig. 4d ; see also Supplementary Fig. 3d ) Dap protein traps the CycE/CDK2 complex in a stable but inactive form , and elevated levels of Dap lead to cell cycle arrest at the G1/S phase transition with prolonged expression of CycE protein  Dicer-1 (Dcr-1) is essential for processing miRNAs, whereas Dicer-2 (Dcr-2) is required for siRNAs; loss of Dcr-1 completely disrupts the miRNA pathway and only has a weak effect on the siRNA pathway Drosophila oogenesis depends on the presence of self-renewing GSCs in the adult ovary , as has recently been reported in a mammalian system  Each male testis contains approximately ten GSCs surrounding a somatic structure called the hub ( Fig. 3h–i )  Examination of individual germaria containing a single heterozygous GSC and a single dcr-1 Q1147X mutant GSC revealed that GSCs lacking Dcr-1 activity produced cysts at a frequency that was reduced to 18% of normal levels (41% for dcr-1 d102 ; Table 1 and Fig. 3a–c ) Experimental evidence has suggested that small RNAs regulate stem cell character in plants and animals  Female GSCs are identified by their location and the expression patterns of three markers ( Fig. 2a ): the presence of Adducin, a protein present in the spectrosome ; the presence of phosphorylated Mad protein (P-Mad), indicating TGF-β signalling ; and the absence of Bam, repressed by the TGF-β pathway  From these analyses, we conclude that decreased cyst production from dcr-1 Q1147X GSCs does not result from either a loss of GSCs or a change in their identity Furthermore, as with wild-type GSCs, dcr-1 Q1147X GSCs did not stain positively for the Bam protein ( Fig. 2e ) Furthermore, pulse labelling of ovaries with the nucleotide analogue 5-bromodeoxyuridine (BrdU) revealed that the number of dcr-1 Q1147X mutant GSCs in S phase was reduced ( Fig. 3e ; see also Supplementary Table 1 ) Furthermore, the number of GSCs staining positive for CycE was reduced to normal levels ( Fig. 4d ), demonstrating that the CycE defect observed in dcr-1 mutant GSCs is dependent on Dap How is this regulation achieved? We found that expression of a Dap transgene containing the Dap promoter and essentially all of the endogenous gene except some of the 3′ UTRref. ( dap-5gm ) was similar in dcr-1 mutant and wild-type GSCs ( Fig. 4b ; see also Supplementary Fig. 3b, c ) However, it is also possible that the Dap misregulation in dcr-1 mutant GSCs might be due to a secondary effect of Dcr-1 loss However, the molecular mechanisms underlying stem cell control by miRNAs are not understood In contrast, dcr-2 null mutant GSCs produced a normal progression of egg chambers In contrast, GSCs that were homozygous for dcr-2 or the parental chromosome expressed CycE with frequencies similar to that of wild-type GSCs ( Supplementary Fig. 1b ) In contrast, the frequency of division was not significantly reduced for GSCs that were homozygous for the dcr-2 mutation or for the isogenized parental chromosome from which the dcr-1 mutant alleles were generated ( Table 1 and Fig. 3c ) MicroRNAs and short interfering RNAs (siRNAs), processed by the type III double-stranded RNase Dicer, function in an RNA-based mechanism of gene silencing  Moreover, some miRNAs are differentially expressed in stem cells, suggesting a specialized role in stem cell regulation  Most characterized miRNAs from animals repress gene expression by blocking the translation of complementary messenger RNAs into protein; they interact with their targets by imperfect base-pairing to mRNA sequences within the 3′ untranslated region (3′ UTR)  Notably, the number of Dap-positive GSCs increased in the dcr-1 mutant GSC population ( Fig. 4b ; see also Supplementary Table 1 and Supplementary Fig. 3a ) Our finding that miRNAs are required for stem cell division suggests that miRNAs might be part of a mechanism that makes stem cells insensitive to environmental signals that normally stop the cell cycle Similar to female GSCs, the number of male GSCs staining positive for CycE was increased in dcr-1 mutants ( Fig. 3g–i ) Similarly, the number of dcr-1 Q1147X mutant GSCs staining positive for Cyclin A (CycA), Cyclin B (CycB) and the mitotic marker Phosphohistone-3 (PH3) was reduced ( Fig. 3e ; see also Supplementary Table 1 ) The continuous division of GSCs generates an array of progressively developed egg chambers in wild-type ovarioles ( Fig. 1 ) The dcr-1 Q1147X GSCs showed normal spectrosome morphology and position (100%, n = 53), and normal TGF-β pathway activity (P-Mad: wild type 88%, n = 114; dcr-1 Q1147X 85%, n = 47; Fig. 2c , d ) The Drosophila genome contains two Dicer isozymes: Dicer-1 and Dicer-2 (ref. 10 ) The fact that reduction of Dap levels led to a normal GSC CycE profile, but partial rescue of cyst generation, suggests that Dcr-1 might also regulate later cyst development The frequency of cell division in dcr-1 Q1147X GSCs was impaired The number of dcr-1 Q1147X mutant cells in imaginal discs was approximately equal to the number of marked wild-type cells that descended from a common parent cell, indicating that the frequency of cell division in imaginal disc cells is not reduced in a dcr-1 mutant ( Supplementary Fig. 2a, b ). dcr-1 Q1147X dividing germline cysts express CycE at a frequency comparable to that of wild-type dividing cysts, suggesting that the mitotic cystoblast cell divisions are not affected in dcr-1 mutants ( Supplementary Fig. 2c, d ) The transition between the G1 and S phases of the cell cycle is negatively regulated by Dap  Therefore, the reduction in cell division frequency observed in the dcr-1 mutant germ line is specific to the GSC division These data indicate that perturbation of the miRNA pathway by mutant dcr-1 in GSCs delays the cell cycle at the G1/S transition These data show that Dcr-1 also functions in the male GSC niche, and suggest that Dcr-1 has a conserved role in GSC division These data suggest that Dcr-1 is required for efficient germline production These data suggest that miRNAs act on stem cell division by reducing the levels of Dap These data suggest that the effect of Dcr-1 on Dap regulation in GSCs ( Fig. 4b ) is at a post-transcriptional level and might involve the 3′ UTR region that is missing in the dap-5gm transgene ( Fig. 4a ) This downregulation might be direct, because the Dap 3′ UTR contains several predicted miRNA-binding sites ( Supplementary Fig. 4 ) Thus, Dcr-1 is required cell autonomously in GSCs for the cell divisions that produce developing cystoblasts (no obvious defect in cyst division was observed; see Supplementary Fig. 2c, d ) To determine the role of miRNAs in the control of stem cell biology, we specifically eliminated processing of all miRNAs in stem cells To determine whether Dap mediated the effect of dcr-1 on the GSC cell cycle, we reduced the level of Dap by 50% in dcr-1 Q1147X mutant GSCs and observed a partial rescue in cyst production ( Table 1 and Fig. 4c , e ) To determine whether reduced cyst production in dcr-1 germaria was due to altered GSC fate, we analysed the identity of the dcr-1 mutant GSCs To determine whether the reduced cyst formation reflected a block in the normal cell cycle programme, we analysed the distribution of cell cycle stages in mutant dcr-1 Q1147X GSCs by staining mosaic germaria with antibodies against different cell cycle markers ( Fig. 3d ) To test the possibility that the miRNA pathway might be a general cell cycle regulator, we examined other cell types to determine whether the G1/S delay and reduced cell division frequency are also observed in other mitotically dividing dcr-1 mutant cells. dcr-1 Q1147X clones in imaginal discs revealed that the number of CycE-positive cells was not increased in mutant cells ( Supplementary Fig. 2a ) Together, these data suggest that the miRNA pathway has a specific role in regulating stem cell division Using Drosophila GSCs as a model system, we impaired Dcr-1 activity with two dcr-1 alleles: dcr-1 d102 and a null dcr-1 Q1147X (ref. 10 ) We explored the potential cause for the G1/S arrest by examining the expression of Dacapo (Dap; a homologue of the p21/p27 family of cyclin-dependent kinase (CDK) inhibitors) in dcr-1 Q1147X mutant GSCs We observed an increase in the number of dcr-1 mutant GSCs staining positive for Cyclin E (CycE) using two independent dcr-1 alleles ( Fig. 3e , f ; see also Supplementary Table 1 and Supplementary Fig. 1b ) We propose that miRNAs are required for GSCs to transit the G1/S checkpoint by repressing directly or indirectly the G1/S inhibitor Dap ( Fig. 4f ) We propose that while the TGF-β pathway—which can upregulate p21/p27 (ref. 24 )—is active in GSCs , miRNAs downregulate Dap to assure the continuous cell division essential for stem cells We tested whether loss of Dcr-1 function has similar consequences on the cell cycle in the GSCs of male flies We therefore analysed potential problems in GSC maintenance, identity and division
 Although the cost was very reasonable, development opportunities will be limited if the extra dimensions are, as currently predicted, subatomic in scale Nominators felt that the fuss over The Promise — which is up for a Golden Globe — raised awareness of environmental concerns Number crunch 12% of Americans see the environment as one of the three most important issues facing the United States today. 48% see global warming as the most important environmental problem facing the United States, up from 22% in 2003. 45% think there is a lot of disagreement among scientists on global warming, but 61% feel that there is enough evidence to justify action. 60% of Americans would be willing to pay at least $10 more a month for electricity to solve the global warming problem Rewarding virtue Having been fined in May for despoiling a beautiful lake while making a film, Chinese director Chen Kaige has been nominated for a Green Chinese award Scorecard Property rights Air rights above land have a value to high-rise developers separate from the plot itself So conceptual artist Jonathon Keats has bought the rights to the higher dimensions predicted in string theory associated with six properties in San Francisco Sources: Reuters, MIT, ABC News Zoo news Steve Johnston, of the University of Queensland, Australia, wants to set up a sperm bank for koalas in order to help prevent the spread of sexually transmitted diseases in breeding programmes
 A corresponding atlas of the human brain is an obvious next step, however, and the Allen Institute has initiated pilot studies towards this end. “We plan to address key questions about the human brain and will be focusing our internal research efforts on understanding the cortex — the part of the brain associated with higher order functions,” says Jones. A personal interest in neuroscience saw Paul Allen, the billionaire philanthropist who co-founded Microsoft, establish the Allen Institute for Brain Science in Seattle, Washington, in 2001 A three-dimensional map of gene expression in the mouse brain, the atlas is the most comprehensive study of its kind to date According to the Allen Institute for Brain Science, 250 scientists are using the atlas each day, and it is turning up in citations. “Combining the classical approaches of brain research with this new genetic approach is a breakthrough in neuroscience,” says Susumu Tonegawa, director of the Picower Center for Learning and Memory at the Massachusetts Institute of Technology. “Its an extremely powerful approach to try to understand the brain.”  “This will likely become the reference atlas for molecular and cellular neuroscientists,” adds Thomas Insel, director of the National Institute of Mental Health in Bethesda, Maryland Allan Jones, chief scientific officer at the Allen Institute, is confident that the atlas will “dramatically propel neuroscience forwards” An alternative project, the Gene Expression Nervous System Atlas (GENSAT), launched by the US National Institutes of Health in 2003, is mapping gene expression in the mouse brain throughout development Charles Watson is an expert on brain mapping, currently working with George Paxinos to produce the sixth edition of The Rat Brain in Stereotaxic Coordinates — one of the most cited texts in the field. “The project is doing a really good thing and its fantastic that someone has invested so much money in neuroscience,” he says. newsad; But Watson notes that the makers of the mouse atlas have chosen a different set of abbreviations from those in Paxinos books. “We have the lingua franca and theyre refusing to use it, which seems a bit silly,” he says He donated $100 million: half went on the Brain Atlas, launched in 2003 as the institutes first major project after two years of consultation He says the atlas has already produced two surprising results: “First, the percentage of genes expressed in the adult brain is greater than we had expected, and second, the regional distribution is more selective than expected.”  Alongside data on gene expression, the atlas provides an anatomical map of the mouse brain Mice are an important model species in neuroscience research, due in part to their potential for genetic manipulation and drug testing not possible in humans Much of the Allen Brain Atlas information was released before the project was completed, and researchers in the field already seem pleased with the resource Researchers mapped where each of the mouse brains 21,000 genes are expressed by staining brain sections with probes specific to each gene The atlas is available free of charge online in the form of a database The completed atlas contains around 85 million images and 600 terabytes of data — enough to fill more than 7,500 top-of-the-range iPods The mice used in the Allen Brain Atlas were all 56 days old The project has begun to publish results but is still some way from completion The resulting atlas provides insight into the brains function, helping researchers understand how different regions operate and interact Three years, 21,000 genes and US$41 million after the Allen Brain Atlas was begun, it is finished Users can search for particular genes, then scroll through photographs of vertical or horizontal sections to see how expression is distributed
 Although subtle differences in these steps can be detected between different substrates , it is not known whether they can be exploited to modulate protein translocation selectively Cotransin acts in a signal-sequence-discriminatory manner to prevent the stable insertion of select nascent chains into the Sec61 translocation channel Despite such sequence diversity, these signals are all recognized and interpreted by a highly conserved protein-conducting channel composed of the Sec61 complex  Here we describe cotransin, a small molecule that inhibits protein translocation into the endoplasmic reticulum Signal recognition by Sec61 is essential for productive insertion of the nascent polypeptide into the translocation site , channel gating and initiation of transport The segregation of secretory and membrane proteins to the mammalian endoplasmic reticulum is mediated by remarkably diverse signal sequences that have little or no homology with each other  Thus, the range of substrates accommodated by the channel can be specifically and reversibly modulated by a cell-permeable small molecule that alters the interaction between signal sequences and the Sec61 complex. Abundances of about 2 pmol equiv -1 and about 0.2 pmol equiv -1 for the Sec61 complex and SR, respectively, have been established in previous studies  After being labelled with 400 µCi ml -1 [ 35 S]methionine/cysteine for 30 min, proteins in the medium were collected by precipitation with 15% trichloroacetic acid, washed in acetone, dissolved in 1% SDS, 0.1 M Tris-HCl pH 8, and analysed by SDS–polyacrylamide-gel electrophoresis (SDS–PAGE) and autoradiography All constructs were verified by sequencing Antibodies against Sec61α were a gift from R Antibodies against VCAM1 , PDI , actin and SRP54 were purchased from Santa Cruz , Stressgen , Sigma and BD Biosciences , respectively Antibodies and proteins Antibodies against Sec61β were described previously  Assays with RNCs and purified Sec61 complex in detergent solution Nascent 145-mer chains translated in the absence of compound and isolated in the presence of high salt concentration were resuspended in half the original volume of 50 mM HEPES pH 7.4, 25 mM potassium acetate, 2 mM magnesium acetate, 0.3% DeoxyBigCHAP ( Calbiochem ) and 25 µM cotransin or nor-cotransin where indicated Bovine pPrl in the SP64 vector ( Promega ) has been described previously  Cell-free translocation assays In vitro transcription, translation, translocation, and protease protection assays were performed as described previously  Cells were harvested in 1% SDS, 0.1 M Tris-HCl pH 8 and analysed by SDS–PAGE and immunoblotting COS-7 cells were maintained in accordance with standard procedures Crosslinking assays Crosslinking with 145-mers was with 0.5 mM disuccinimidyl suberate ( Pierce ) at 23 °C for 30 min; the reaction was quenched with 0.1 M Tris-HCl pH 8.0, 1% saponin ( Sigma ), 10 mM EDTA, 50 µg ml -1 RNase A ( Sigma ), then added to 1% SDS, 0.1 M Tris-HCl pH 8 and heated to 37 °C Crosslinking with 180-mers (isolated in the presence of high salt concentration) was with 50 µM bismaleimidohexane ( Pierce ) at 23 °C for 15 min; the reaction was quenched with 100 mM 2-mercaptoethanol, then added to 1% SDS, 0.1 M Tris-HCl pH 8 and heated to 37 °C Gilmore Immunoblotting relative to a titration of starting RM at a defined concentration of 1 equivalent (equiv) µl -1 was used to determine the concentration of purified proteins Immunoprecipitation with the indicated antibodies was performed after the dilution of samples tenfold with 1% Triton X-100, 50 mM HEPES pH 7.4, 100 mM sodium chloride In Fig. 4c , d , nascent chains were isolated in the absence of compound, then resuspended in the presence of cotransin or nor-cotransin (25 µM) before treatment with proteinase K (PK) Inhibition of glycosylation was with a competitive peptide inhibitor ( NH 2 -Asp-Tyr-Thr-COOH ; California Peptide Research ) at 100 µM ( Fig. 2d ) Isolated nascent chains were resuspended in PSB containing 0.25 M sucrose before further manipulations Luecke) and cloned into the pcDNA3.1 vector ( Invitrogen ) Mammalian cell culture and transient expression of VCAM1 A detailed description of cell-based models of inflammation is given in Supplementary Methods  Mammalian Sec61 complex and SR were purified from canine RM as described previously  Methods Constructs The coding region for human VCAM1 was amplified by polymerase chain reaction with reverse transcription (RT–PCR) from total RNA isolated from tumour necrosis factor-α-stimulated A549 cells (gift from H Nascent chains were isolated at 4 °C by sedimentation in a TLA 100.3 rotor (75,000 r.p.m. for 45 min (for RNCs) or 70,000 r.p.m. for 10 min (for membrane-bound RNCs)) through a sucrose cushion (100 µl, 0.5 M) in PSB buffer (50 mM HEPES pH 7.4, 150 mM potassium acetate, 5 mM magnesium acetate) Proteolysis reactions were with 0.5 mg ml -1 PK for 60 min on ice as described . Pulse-labelling of secreted proteins was performed on cells preincubated for 60 min at 37 °C with cotransin or nor-cotransin (5 µM) in medium lacking methionine, cysteine and serum Purified Sec61 complex was added to a final concentration of about 500 nM and the samples were incubated at 32 °C for 20 min before transfer to ice for protease protection assays Quantitative analysis of translocation experiments used a Typhoon 9400 phosphorimager ( Amersham ) with accompanying software Reconstituted proteoliposomes Glycoprotein-depleted and Q Sepharose-depleted proteoliposomes were prepared as described previously  Sec61-depleted proteoliposomes and proteoliposomes containing purified Sec61 and SR were prepared as described  Small molecule synthesis Cotransin and nor-cotransin were synthesized by adapting the published synthesis of HUN-7293 (ref. 28 ) and were characterized by 1 H-NMR and mass spectrometry The Gal4–NFκB coding region (from plasmid pBD-NFκB ( Stratagene )] containing a carboxy-terminal KDEL sequence was amplified by PCR and subcloned into signal sequence cassettes containing the VCAM1 or pPrl signal sequence to generate the signal-Gal4–NFκB constructs Translation reactions to measure salt-resistant binding were adjusted to 0.5 M potassium acetate and sedimented through a 0.5 M sucrose cushion containing 0.5 M potassium acetate in PSB Translations were at 32 °C for 60 min (full-length constructs) or for 20 min (truncated constructs) Treatment with puromycin (1 mM; Calbiochem ) was for 15 min at 25 °C ( Fig. 3c ) Truncated transcripts lacking a stop codon were synthesized from PCR-generated templates  VCAM1 expression analysis was performed 24 h after transfection with Lipofectamine 2000 ( Invitrogen ) Where indicated, cotransin, nor-cotransin or MG-132 (5 µM; Calbiochem ) was added 5 h after transfection A productive interaction between RNCs and Sec61 shields the nascent chain from protease digestion because of its insertion into the translocation channel  A screen for inhibitors of the expression of cell adhesion molecules led to the identification of HUN-7293, a cyclodepsipeptide natural product that potently inhibits vascular cell adhesion molecule 1 (VCAM1) expression in endothelial cells  Addition after translocation intermediate assembly had no effect (data not shown), indicating that once nascent chains have initiated translocation, they are no longer influenced by cotransin Alternatively, cotransin might directly or allosterically alter the topography of a signal sequence binding site, postulated to involve transmembrane helices 2 and 7 of Sec61α  Although both signals directed efficient translocation of the reporter, only the VCAM1 fusion construct was inhibited by cotransin ( Fig. 2e ) sin-sensitive and cotransin-resistant substrates indicated that this is improbable ( Supplementary Table 1 ) Analysis of either total secreted proteins ( Fig. 1d ) or cellular glycoproteins ( Supplementary Fig As expected, a major cytosolic crosslink was identified by immunoprecipitation as SRP54 ( Fig. 3a , lanes 7–9), the signal sequence-binding subunit of SRP  Because every known accessory protein previously implicated in translocation was represented in these depletions, the target of cotransin is likely to be a novel protein or the Sec61 complex itself Both VCAM1 translocation and its inhibition by cotransin were observed even when glycosylation was prevented ( Fig. 2d ), whereas the addition of cotransin after translocation had no effect on either glycosylation or protease protection (data not shown) By contrast, RNCs synthesized in the presence of cotransin showed diminished Sec61α and PDI crosslinks but enhanced Sec61β crosslinks By contrast, translocation reactions containing nor-cotransin (or dimethylsulphoxide; DMSO) resulted in efficient glycosylation and protease protection of VCAM1 ( Fig. 2c , lanes 3, 4, 8 and 9) Comparison of their signal sequences failed to reveal either a consensus cotransin-binding motif shared by the sensitive substrates or the basis for cotransin resistance Cotransin had no effect on the pPrl nascent chain ( Fig. 4d ) Cotransin inhibits translocation in a signal sequence-dependent manner, despite targeting a translocation channel utilized by all secretory and membrane proteins Cotransin therefore acts at a step after the targeting and transfer of RNCs to the translocon, but before the nascent chains have access to the ER lumen Cotransin therefore selectively inhibits the expression of a small subset of secretory and membrane proteins, including VCAM1 Cotransin thus provides a powerful new probe for investigating the molecular function of a protein-conducting channel as well as a selective, reversible method of inhibiting cotranslational translocation in living cells. Cotransin, but not nor-cotransin, inhibited the stimulated expression of only two proteins, VCAM1 and P-selectin ( Fig. 1b , c , and Supplementary Fig Deciphering the molecular details of how cotransin influences the signal sequence interaction with the Sec61 channel is likely to shed light on the mechanism by which unrelated signal sequences gate a communal translocation channel Differences in crosslinking were apparent with RNCs of several different lengths and with both lysine-reactive and cysteine-reactive crosslinkers ( Fig. 3a , b , and data not shown) Furthermore, cotransin, but not nor-cotransin, significantly altered the pattern of crosslinks between RNCs and ER proteins ( Fig. 3a , lanes 10–12; Fig. 3b , lanes 4–6) Given that targeting to the translocon is unaffected by cotransin ( Fig. 3a ), these results suggest that cotransin acts to prevent signal sequence-dependent gating of the Sec61 translocation channel However, it is already apparent that differences between natural signal sequences can markedly influence sensitivity to cotransin ( Supplementary Table 1 ) However, key structural features of HUN-7293 important for its activity have been defined by Boger and colleagues in a systematic analysis of 40 structural variants  However, removal of these and other components from the membrane or lumen had little effect on VCAM1 translocation beyond that observed for pPrl ( Supplementary Figs S4 and S5 ) Identical results were obtained when another reporter (the prion protein) was fused to the VCAM1 and pPrl signals (data not shown) Identification of the exact features in the signal that confer sensitivity (and resistance) to cotransin must await systematic mutagenesis studies Immunoprecipitation studies identified the primary differences ( Fig. 3b ) In striking contrast to VCAM1, the translocation of pre-prolactin (pPrl) was unaffected by cotransin ( Fig. 2c , d ) In the cytosol, 145-residue ribosome-nascent chain complexes (RNCs) of VCAM1 formed crosslinks with several proteins, none of which were affected by cotransin ( Fig. 3a , lanes 7–9) In these experiments, RNCs in the cotransin, nor-cotransin and DMSO samples quantitatively achieved salt-resistant binding to microsomes, a previously defined indicator of tight interaction between ribosome and translocon after transfer from SRP  In this model, the altered binding site would be less accommodating or flexible, resulting in increased substrate selectivity In this study we have characterized cotransin, the first small-molecule modulator of protein translocation into the ER Indeed, proteasome inhibition during treatment with cotransin stabilized a non-glycosylated form of VCAM1 ( Fig. 2a ) Instead, the first cotransin-sensitive step occurs at the membrane Moreover, an analysis of model type I, type II and multi-spanning membrane proteins with cotransin showed no effect on their proper translocation, glycosylation, membrane insertion or topology in vitro ( Supplementary Fig On the basis of this seminal study, we designed and synthesized a simplified analogue of HUN-7293, which we named ‘cotransin’ ( Fig. 1a ) One possibility is that cotransin stabilizes the channel in a closed conformation such that gating by low-affinity signal sequences is inefficient Protease accessibility and inhibition of translocation were observed only if cotransin was present during the assembly of translocation intermediates Remarkably, insertion of the VCAM1 nascent chain into the Sec61 channel is selectively inhibited by cotransin ( Fig. 4c , lanes 11 and 12) RNCs are therefore in close proximity to the Sec61 complex with or without cotransin; however, their orientation with respect to Sec61 subunits is significantly perturbed by cotransin RNCs in DMSO and nor-cotransin samples crosslinked efficiently to Sec61α and luminal chaperones (such as protein disulphide isomerase; PDI), but not to Sec61β S1 ) S2 ) from pulse-labelled COS-7 cells revealed a similarly selective effect S3 ) S5 ), a component also essential for pPrl translocation  S6 ), the minimal machinery required for protein translocation  Sedimentation, protease protection and transport assays of translocation intermediates led to similar conclusions Selective, potent and reversible inhibition of VCAM1 ( Fig. 2a , b ), but not other proteins (for example green fluorescent protein; data not shown) expressed heterologously from the constitutive cytomegalovirus promoter, indicated that the site of cotransin action is likely to be post-transcriptional and, possibly, post-translational Sensitivity to cotransin is therefore determined primarily by the signal sequence Signal sequence cleavage, an indicator of nascent chain access to signal peptidase on the luminal side of the membrane, was not observed with cotransin ( Fig. 3a , lanes 5 and 11) Taken together, the identical crosslinking patterns before targeting, equal efficiencies of SRP54 interaction and equal efficiencies of SRP release are evidence that cotransin has no effect on the steps preceding the SRP receptor (SR)-mediated transfer of RNCs to the translocation channel The amino-terminal signal sequences that mediate the translocation of VCAM1 and pPrl into the ER are markedly different from one another ( Fig. 2e ) The cotransin-treated RNCs remained accessible to protease even after release from the ribosome with puromycin ( Fig. 3c , lane 10), indicating that although they were at the translocon, they could not translocate into the lumen The mechanism of action and molecular target of HUN-7293 are unknown The only protein whose depletion prevented VCAM1 translocation was the Sec61 complex ( Supplementary Fig The post-targeting step inhibited by cotransin involves insertion of the nascent chain into the translocation channel and opening of the channel towards the lumen, and proteins engaged in this step are potential molecular targets of cotransin The precise molecular mechanism by which cotransin inhibits nascent chain insertion and gating of the Sec61 channel for select substrates is not known These accessory components are therefore largely dispensable for VCAM1 translocation and are unlikely to be targets for cotransin inhibition These data suggest that cotransin inhibits VCAM1 expression in cells by selectively preventing its cotranslational translocation into the ER These include the Sec61 complex and several accessory components of the translocon (such as TRAM , the TRAP complex , the Sec62/63 complex or BiP ) These results also argue against the VCAM1 signal sequence itself as the direct target of cotransin This implies that signal sequence variation can be exploited to modulate the functional expression of secreted and membrane proteins at their point of entry into the secretory pathway This indicated that cotransin might cause newly synthesized VCAM1 to be degraded rather than productively enter the secretory pathway, a conclusion consistent with data reported in a recent patent application  This interaction was unperturbed by cotransin ( Fig. 3a , lane 8) but was lost after the addition of microsomes (lanes 10–12) This is evident by a decrease in VCAM1 glycosylation and complete digestion of non-glycosylated product by exogenous protease ( Fig. 2c , lanes 6 and 7) This pattern of crosslinks changed when the RNCs were prepared in the presence of RM, indicating a clear shift in the environment surrounding the nascent chain ( Fig. 3a , lanes 10–12) Thus, cotransin acts in a signal sequence-discriminatory manner to prevent the nascent chain from interacting productively with the Sec61 channel ( Fig. 4e ) To evaluate the activity of cotransin and nor-cotransin, primary human cells were stimulated under several conditions and characterized for the expression of 26 cell surface and secreted proteins  To explore the latter possibility, we prepared proteoliposomes containing only the Sec61 complex and SR ( Supplementary Fig To identify the step at which VCAM1 is rerouted from a biosynthetic to a degradative fate, its translation and translocation were analysed in vitro by using reticulocyte lysate containing rough endoplasmic reticulum (ER) microsomes (RM) To identify the step of protein translocation inhibited by cotransin, we analysed interactions between VCAM1 nascent chains and the translocation machinery by chemical crosslinking To test this hypothesis directly, we examined the interaction between VCAM1 or pPrl nascent chains and purified Sec61 To test whether this difference underlies cotransins substrate selectivity, we prepared chimaeric constructs in which the signals of VCAM1 and pPrl were fused to an otherwise non-translocated reporter Treatment of these salt-resistant translocation intermediates with protease showed that cotransin-treated RNCs were accessible to exogenous protease ( Fig. 3c , lane 8), whereas the control samples were protease-protected in the absence, but not the presence, of detergent (lanes 3, 4 and 12) Using this assay, we found that purified 145-mer RNCs of either VCAM1 or pPrl, which are readily digested by protease, become protected on addition of the Sec61 complex ( Fig. 4c , compare lanes 7 and 8; Fig. 4d , compare lanes 5 and 6) VCAM1 and pPrl were both translocated into the lumen of these minimal proteoliposomes (at reduced efficiency); however, only VCAM1 was inhibited by cotransin ( Fig. 4a , b ) We also synthesized ‘nor-cotransin’, a putatively inactive variant lacking a critical N -methyl moiety  We therefore focused on the targeting and translocation machinery, components of which are known to interact with diverse signal sequences, as potential targets of cotransin Whereas the translation of VCAM1 was unaffected by cotransin, its translocation into RM was markedly inhibited ( Fig. 2c )
 Although MSU crystals were first identified as the aetiological agent of gout in the eighteenth century and more recently as a ‘danger signal’ released from dying cells , little is known about the molecular mechanisms underlying MSU- or CPPD-induced inflammation Development of the acute and chronic inflammatory responses known as gout and pseudogout are associated with the deposition of monosodium urate (MSU) or calcium pyrophosphate dihydrate (CPPD) crystals, respectively, in joints and periarticular tissues Here we show that MSU and CPPD engage the caspase-1-activating NALP3 (also called cryopyrin ) inflammasome, resulting in the production of active interleukin (IL)-1β and IL-18  Macrophages from mice deficient in various components of the inflammasome such as caspase-1 , ASC and NALP3 are defective in crystal-induced IL-1β activation Moreover, an impaired neutrophil influx is found in an in vivo model of crystal-induced peritonitis in inflammasome-deficient mice or mice deficient in the IL-1β receptor ( IL-1R ) These findings provide insight into the molecular processes underlying the inflammatory conditions of gout and pseudogout, and further support a pivotal role of the inflammasome in several autoinflammatory diseases. Additional details on mice, preparation of crystals and reagents are given in the Supplementary Information . After 6 h, mice were killed by CO 2 exposure and peritoneal cavities were washed with 10 ml of PBS All cells were stimulated in OptiMEM medium All cells were stimulated in OptiMEM medium as indicated Cells were cultured in RPMI complemented with 10% FCS, sodium pyruvate, penicillin/streptomycin and L -glutamine Cells were plated at the density of 7 × 10 5 cells in 12-well dishes and non-adherent cells were removed after 3 h Homologous recombinant ES cells were identified by Southern blot analysis and microinjected into C57BL/6 blastocysts Human mature IL-1β was detected with a specific antibody directed against the cleaved epitope ( D116 ) from Cell Signaling  Human monocytes were purified as described previously  In vivo mouse peritonitis model Peritonitis was induced by injection of 1 mg of crystals or 0.2 mg of zymosan in 0.5-ml sterile PBS Methods Primary human monocyte and THP1 preparation and stimulation THP1 cells were stimulated for 3 h with 0.5 µM of PMA the day before stimulation, as described  Mice and reagents NALP3 targeting vector ( Supplementary Fig. 1 ) was electroporated into C57BL/6 embryonic stem (ES) cells ( Ozgene ) Mouse macrophage preparation Eight-to-twelve-week-old mice of indicated genotypes were injected intraperitoneally with 4% thioglycollate solution, and macrophages were collected by peritoneal lavage 3 days later Offspring were backcrossed to C57BL/6 mice and germline transmission was confirmed by PCR of tail genomic DNA The lavage fluids were analysed for PMN recruitment by FACS using the neutrophil marker Ly-6G (1A8, BD Biosciences ) This treatment increases the phagocytic properties of the cells and induces a constitutive production of pro-IL-1β Although neutrophil influx was slightly increased in BALB/c mice, both BALB/c and C57BL/6 strains adequately reproduced crystal-induced inflammation ( Fig. 4 and data not shown) As expected, MyD88-deficient PMΦs did not produce mature IL-1β due to their defective TLR signalling, resulting in a failure to produce pro-IL-1β after LPS pre-stimulation ( Fig. 2a ) As shown in Fig. 1d , a strong response to both pathogenic crystals was also elicited in primary cells As shown in Fig. 3c , pre-treatment with colchicine, but not its solvent ethanol, completely blocked the processing of IL-1β ASC is a crucial adaptor protein required for the recruitment of caspase-1 to the NALP platform of inflammasomes  ASC-deficient PMΦs did not produce any mature IL-1β after stimulation by MSU and CPPD crystals ( Fig. 2b ) Because inflammasome-activating MSU crystals and inflammasome neutral allopurinol are chemically and structurally similar and, additionally, are both internalized, inflammasomes must have the capacity to distinguish between subtle differences in crystal surface charge or form Both MSU and CPPD crystals elicited a considerable increase in the recruitment of neutrophils compared with PBS or allopurinol when injected in wild-type C57BL/6 mice ( Fig. 4a ) Cells from the differentiated monocytic cell line THP1 were incubated with MSU crystals Clinically, gout and pseudogout are associated with oedema and erythema of the joints, with consequent severe pain, conditions that are associated with strong infiltration of neutrophils in the intra-articular and periarticular spaces Colchicine is another drug that is frequently used for the treatment of autoinflammatory diseases, including familial Mediterranean fever, acute gout and pseudogout episodes  Combining colchicines known mode of action as an inhibitor of microtubule assembly with the observation that colchicine blocks crystal-induced IL-1β generation upstream of inflammasome activation ( Fig. 3c ), it is likely that the drug acts at the level of crystal endocytosis and/or presentation to the inflammasome  Compared to the known activators of the inflammasome (that is, crude LPS, ATP), MSU and CPPD were more active ( Fig. 1c ) Consistent with our previous findings in human monocytes, murine PMΦs stimulated with MSU or CPPD activated caspase-1 and secreted mature IL-1β ( Fig. 2a ) CPPD, another type of pathogenic crystal involved in calcium pyrophosphate deposition disease, also known as pseudogout, was as active as MSU ( Fig. 1b ) Crystal-induced IL-1β processing was specific for pathogenic agents, as the non-inflammatory allopurinol or diamond crystals and particulate elements such as zymosan and aluminium powder failed to induce pro-IL-1β processing ( Fig. 1c ), despite their similar size and/or chemical composition Despite differences underlying their pathogenesis, their clinical presentation and treatment share many common features Given the absence and/or rapid degradation of pro-IL-1β in PMΦs ex vivo , and because we failed to see any direct induction of the transcription or translation of pro-IL-1β by MSU or CPPD, we stimulated TLR4 in PMΦs with highly purified LPS to induce the synthesis of the cytokine  Gout and pseudogout are two common causes of inflammatory joint diseases Hereditary periodic fevers, systemic onset juvenile idiopathic arthritis, Stills disease, Behçets disease and the metabolic disorders gout and pseudogout are examples of such inflammatory maladies How these danger signals are recognized by cells is mostly unknown, but based on our results inflammasomes probably constitute some of the long-sought proximal sensors for stress or danger signals designed to initiate inflammation However, PAMPs (non-self) are not the only triggers of innate immunity However, the inflammasome is also proficient in sensing stress or endogenous danger signals, such as extracellular ATP or hypotonic stress  IL-1β induction by ATP, the other known non-microbial stimulus of inflammasomes, was also dependent on NALP3 ( Fig. 2c ) IL-1β, also known as the endogenous pyrogen, is a highly inflammatory cytokine whose production is tightly controlled by at least three distinct steps  Importantly, inflammation in hereditary periodic fevers patients with mutations in NALP3 can be markedly improved by treatments designated to block IL-1β  Importantly, when pathogenic crystals were injected in mice deficient in caspase-1 or ASC, neutrophil influx was markedly impaired ( Fig. 4b , c ), indicating a pivotal role of the inflammasome and IL-1β in this process In addition to cytokines whose activity is dependent on caspase-1 activation, MSU and CPPD are known to induce release of other cytokines such as TNF , suggesting additional, inflammasome-independent activities of the crystals In addition to gouty inflammation, the NALP3 inflammasome is also implicated in other autoinflammatory diseases In agreement with this notion was the observation that IL-1R-deficient mice exhibited a similarly reduced recruitment of neutrophils after MSU and CPPD injection ( Fig. 4d ) In contrast, colchicine did not affect IL-1β activation by extracellular ATP, indicating that the drug acts upstream of inflammasome activation In contrast, zymosan-induced neutrophil influx was not affected by ASC or IL-1R deficiency In order to exclude the possibility that crystal-mediated activation of caspase-1 is a unique property of the THP1 cell line only, MSU and CPPD were added to purified human monocytes In order to provide direct evidence for the involvement of the inflammasome in crystal-induced inflammation, we analysed peritoneal macrophages (PMΦs) derived from mice deficient in various key proteins of the inflammasome complex or other proinflammatory pathways In patients with these diseases, mutations in NALP3 lead to a constitutive processing of IL-1β  In the case of gout and pseudogout, aberrant NALP3 inflammasome activation is not genetic, but mediated by local deposition of crystals Increased production of the inflammatory cytokine IL-1β was recently identified as the cause of several autoinflammatory diseases, providing clear evidence for a pivotal role of this cytokine in triggering autoinflammation  Indeed, blocking the maturation of IL-1β with zYVAD-fmk considerably reduced the production of TNF induced by MSU and CPPD, without affecting TNF production by the TLR2 agonist zymosan ( Fig. 3a ) Innate immunity is able to recognize abnormal self or danger signals, such as uric acid released by injured cells  It is also reasonable to foresee that further identification of additional inflammasome-activating endogenous danger signals will probably shed some light on the molecular aetiology of other autoinflammatory diseases such as systemic onset juvenile idiopathic arthritis and Behçets disease that share similarity with hereditary periodic fevers, gout or pseudogout. It is currently not clear how many of them form inflammasomes It was therefore possible that TNF secretion was initiated, at least in part, by the released mature IL-1β Its ability to form an inflammasome and to drive inflammation in humans is well supported by its implication in many hereditary autoinflammatory syndromes  Maturation of IL-1β was indeed detected after stimulation with as little as 10 µg ml -1 of the crystals ( Fig. 1a ) Maturation was abolished in PMΦs from caspase-1-deficient mice, confirming the specificity of the activation Microbial components (pathogen-associated molecular patterns (PAMPs)) provide signals that alert our immune system to danger and promote the innate generation of immunity  MSU, CPPD or allopurinol crystals were injected and the peritoneal recruitment of neutrophils was analysed 6 h later Muramyl dipeptide (MDP), a degradation product of the bacterial cell wall component peptidoglycan and contaminant of crude lipopolysaccharide (LPS), was recently shown to activate a NALP3 inflammasome through the leucine-rich repeat domain of NALP3, suggesting that NALPs, like Toll-like receptors (TLRs), are fundamental for microbial detection  NALP3 is expressed in both monocytes and macrophages and is well conserved in human and mouse Nevertheless, MyD88 -/- PMΦs still activated caspase-1 ( Fig. 2a ), further suggesting that this activation is TLR independent and is consistent with a possible involvement of the inflammasome  Notably, MSU uptake was also proposed to be partly dependent on the presence of TLR2 and TLR4 (ref. 26 ) On the basis of our findings that pathogenic crystal-mediated IL-1β maturation requires the inflammasome components NALP3, ASC and caspase-1, we propose that both aetiological agents of gout and pseudogout (that is, MSU and CPPD) mediate inflammation in an inflammasome-dependent manner Owing to the similarity between NALP3-mediated hereditary periodic fevers and gout and pseudogout, we can anticipate that similar treatments could benefit gout and pseudogout patients Pre-treatment with intravenous colchicine before intra-articular MSU injections greatly reduces inflammation , suggesting that colchicine targets the initial phase of inflammation Previously, we demonstrated that the inflammatory caspases are cleaved and released along with active IL-1β after activation of the inflammasome  Recently, MSU crystals were identified as a danger signal formed after release of uric acid from dying cells  Signals and mechanisms leading to inflammasome activation are still poorly understood Similar to PMΦs from Asc -/- mice, IL-1β release was impaired in NALP3-deficient PMΦs upon MSU and CPPD exposure ( Fig. 2c ) ling, significantly affected the production of TNF and IL-6 by human monocytes ( Fig. 3b ) Specific gain-of-function mutations in the NALP3 protein lead to three related familial autoinflammatory diseases: Muckle–Wells syndrome, familial cold autoinflammatory syndrome and chronic infantile neurologic cutaneous and articular syndrome  Taken together, the above results indicate that crystals are proinflammatory by virtue of their capacity to activate the NALP3 inflammasome The caspase-1 dependency of the pro-IL-1β cleavage was confirmed by addition of the caspase-1 inhibitor zYVAD-fmk, which completely blocked MSU-induced IL-1β activation ( Fig. 1a ) The first step involves the production of the pro-IL-1β protein (p35); this is followed by cleavage of the precursor pro-IL-1β to produce the active IL-1β protein (p17), and finally IL-1β is released into the extracellular environment The human genome harbours a repertoire of 14 NALPs The mechanism whereby endocytosed MSU and CPPD are sensed by the NALP3 inflammasome is currently not known, nor is it clear whether the crystals directly interact with NALP3 or whether sensing occurs via intermediary protein(s) The middle step, processing of pro-IL-1β, involves the activation of a caspase-1-activating complex, the best characterized being the inflammasome  The notion of autoinflammatory diseases delineates a heterogeneous group of pathologies characterized by spontaneous periodic inflammation and fever in the absence of infectious or autoimmune causes  These results suggest that the processing of IL-1β is a proximal event in the inflammatory cascade initiated by pathogenic crystals, possibly explaining the extraordinary success of IL-1ra in the treatment of some autoinflammatory diseases  This marked neutrophil influx can be reproduced experimentally in mice by intraperitoneal injection of crystals  This notion is further supported by clinical data demonstrating that colchicine, a drug able to resolve the initial inflammatory phase of both gout and pseudogout, blocks IL-1β maturation by MSU and CPPD This observation, and the well-known role of uric acid crystals in gouty arthritis , prompted us to investigate whether MSU crystals could activate the inflammasome This superior potency was particularly evident when analysing processing of pro-IL-18, the second known substrate of caspase-1 ( Fig. 1c ) This was also observed when cells were treated with MSU and CPPD ( Fig. 1c , d ) Upon activation, the inflammasome is formed by a member of the NALP protein family, such as NALP1, NALP2 or NALP3, and the adaptor protein ASC that connects the NALPs with caspase-1 (ref. 12 ) We considered that the NALP3 inflammasome was possibly implicated in crystal-induced caspase-1 activation and we therefore generated NALP3-deficient mice ( Supplementary Fig. 1 and V.P., F.M. and J.T., manuscript in preparation) We therefore investigated the role of colchicine in crystal-induced maturation of IL-1β We used this well-established model to investigate the in vivo role of the inflammasome in crystal-induced inflammation When assaying the release of TNF, we realized that the production of TNF was relatively slow and was preceded by the release of IL-1β ( Fig. 3a ) Whereas blocking of the ATP receptor P2X 7 inhibited ATP-driven inflammasome activation, it had no effect on MSU-induced activation, indicating that the two inflammasome-activating pathways act independently ( Supplementary Fig. 2 )
 As Lagendijk points out, the archaic and myopic value system now used in science favours a limited set of outcomes, often at the expense of scientific progress But this value system and associated behaviours have other, far-reaching consequences First, they can compromise the integrity of the scientific enterprise through tremendous pressure to publish Implicitly, this could reduce the potential to identify and address scientific issues of more global relevance Second, they may reduce the diversity of the workforce by attracting, rewarding and therefore retaining those who thrive in particular kinds of competitive environments — who are not necessarily those of greatest scientific ability, insight or creativity Sir The story told in Ad Lagendijks Essay “Pushing for power” ( Nature 438 , 429 ; 2005 ) is very familiar to many of us who have chosen to make a living in science The current reward system needs reassessing and reformulating in order to accommodate and reflect wider, more inclusive values. Third, they may limit the range and relevance of scientific pursuits and may devalue interactions between scientists and the public
 Although high-time-resolution observations are often possible in radio astronomy , they are usually limited to quite narrow fields of view Here we report a transient radio source, GCRT J1745–3009, which was detected during a moderately wide-field monitoring programme of the Galactic Centre region at 0.33 GHz If located in or near the Galactic Centre, its brightness temperature (∼10 16  K) and the implied energy density within GCRT J1745–3009 vastly exceed those observed in most other classes of radio astronomical sources , and are consistent with coherent emission processes that are rarely observed The characteristics of its bursts are unlike those known for any other class of radio transient The dynamic radio sky is therefore poorly sampled, in contrast to the situation in the X-ray and γ-ray bands in which wide-field instruments routinely detect transient sources  Transient astronomical sources are typically powered by compact objects and usually signify highly explosive or dynamic events  We conclude that it represents a hitherto unknown class of transient radio sources, the first of possibly many new classes that may be discovered by emerging wide-field radio telescopes . A 77-min rotation period radio pulsar is excluded because the rotational energy loss rate from such a pulsar is insufficient to power the radio emission unless the magnetic field is extreme (10 18  G) or the distance is unreasonably small (0.5 pc) A search of all of the Galactic bulge scans starting in February 1999 finds one scan, on 3 July 2003, in which a 15-mCrab (6.5 σ ) outburst was detected Although GCRT J1745–3009 is conceivably a ‘local’ radio source belonging to one of the classes of objects considered above, it is much more likely that it is located significantly farther from us An investigation of whether a new, long-period type of magnetar could produce the observed emission timescales and transient behaviour is under way (K Another conceivable option is that 77 min is an orbital period and the outbursts are flux variations as a function of orbital phase similar to the pulsar PSR J0737–3039B (ref. 28 ) Assuming even a uniform distribution of transients, and not the vastly increasing spatial density of all astronomical objects toward the Galactic Centre, the relative spatial volume covered by our wide-field observations results in an extremely small probability (6 × 10 -7 ) that GCRT J1745–3009 is located within 70 pc Brown dwarfs also emit flares, apparently as a result of processes involving high magnetic fields  Bursts of such highly circularly polarized radio emission are also predicted, by analogy to the giant planets in our Solar System, from extrasolar giant planets  Coherent emission from the magnetosphere of a magnetar addresses the energy budget difficulties seen in the pulsar models, but all known magnetars have much shorter spin periods (∼10 s) than the 77-min period observed for GCRT J1745–3009 Few radio flares from brown dwarfs have been detected , and none at low frequencies  Four infrared sources detected in the Two-Micron All-Sky Survey that lie within the ∼10″ uncertainty of the transients radio position could possibly be brown dwarfs Furthermore, in contrast to the low-frequency bursts from GCRT J1745–3009, the observed flares from brown dwarfs at high frequencies are significantly polarized (30–70%), but the degree of polarization may be significantly reduced at low frequencies where self-absorption can become large  GCRT J1745–3009 is located approximately 1.25° south of the Galactic Centre and is notable for a series of ∼1-Jy bursts, each with a duration of ∼10 min, and occurring at apparently regular intervals of 1.27 h GCRT J1745–3009 is located near the supernova remnant, SNR 359.1–00.5 (ref. 9 ), and other prominent sources , as shown in Fig. 3  GCRT J1745–3009 is located only 14′ from the image centre compared to the ∼3° field of view, and therefore, together with its detection at multiple frequencies around 0.33 GHz and in both circular polarizations, we consider the evidence that the source is real to be very strong GCRT J1745–3009 is not detected between bursts with a 5 σ  upper limit of 75 mJy, determined by imaging the entire observation with the bursts removed GCRT J1745–3009 is unresolved in our observation GCRT J1745–3009 was detected in 2002 using the Very Large Array radio telescope operating at a frequency of 0.33 GHz Hence, there is no compelling evidence for such an identification However, its detection at a low frequency, its regular bursting pattern, and significant detection in both circular polarizations, are all novel features in comparison to known characteristics of brown dwarfs However, no detections have been made in searches for such emission from known extrasolar planets at 0.33 GHz and 1.5 GHz, at sensitivity limits comparable to or better than what we report here  However, possible confusion with other X-ray sources in the field of view (∼30′) prevents a conclusive identification However, their distances are unknown and their spectral colours, to the extent measured, are inconsistent with those of brown dwarfs  If the transient source is at the Galactic Centre, ∼8.5 kpc distant, its brightness temperature far exceeds 10 12  K, the upper limit for incoherent synchrotron radiation produced by relativistic electrons gyrating in a magnetic field, and therefore its emission is probably coherent If we constrain its size to be less than cτ , with c the speed of light in vacuum and τ  ≈ 2 min taken to be the decay time of the ∼1-Jy bursts, then the energy density within the source as measured by the brightness temperature is ∼10 12  K ( D /70 pc) , where D is the distance to the source Images made from three 6-h observations in 1996 and 1998 have similar upper limits, and the combination of these images has a 15-mJy upper limit for quiescent emission In addition, the apparent lack of a bright X-ray counterpart of the bursts argues strongly against accretion as the power source for the bursts In both of these observations, 3 σ  upper limits on the X-ray flux from the source are 6 mCrab In contrast to GCRT J1745–3009, however, no regular flaring pattern is evident for any of these sources, and they were observed only at high frequencies, because emission is predicted to be self-absorbed at lower frequencies  In principle, GCRT J1745–3009 could be located 70 pc from us, in which case it could be either a coherent or an incoherent emitter It is conceivable that relativistic beaming is responsible for the high calculated brightness temperature, but the light curve of GCRT J1745–3009 does not resemble that for known microquasars or other sources of jet emission, most of which exhibit a fast rise and a slower decay and much longer timescales  Known and hypothesized classes of ‘local’ ( D 70 pc) sources that show flare activity include dwarf M-type (dMe) stars, brown dwarfs and extrasolar planets. dMe flare stars emit coherent bursts produced through electron cyclotron maser emission Like the bursts from GCRT J1745–3009, the observed flares have timescales of minutes, and, for two of the brown dwarfs, LP944 - 20 and 2MASS 0036 + 18, they also have faster decay than rise times Many transient radio sources are also detectable at X-ray and γ-ray wavelengths N.E.K., manuscript in preparation). Next, we consider radio pulsar origins for the source No variable X-ray (2–10 keV) emission was seen and we place a conservative 25 mCrab upper limit on the flux of any interburst X-ray counterpart emission (1 mCrab ≈ 2 × 10 -11  erg cm -2  s -1 ) One of us (C.B.M.) performs regular scanning observations of the Galactic bulge with RXTE One other class of sources to consider are magnetars, neutron stars with immense (10 14 –10 15  G) magnetic fields whose radiation is powered by field decay  S Similarly, the γ-ray source 3EG J1744–301 was detected near the position of GCRT J1745–3009 during the 1990s by the Energetic Gamma Ray Experiment Telescope, but the positional error on that source is also large (∼20′) and the source is in a highly confused region with numerous diffuse and discrete sources of γ-ray emission  The bursts from flare stars show some similarities to the light curve of GCRT J1745–3009 but, in contrast, they are detected in only one circular polarization at low frequencies (for example, at 0.43 GHz for AD Leo and YZ Canis Minoris)  The bursts show no significant frequency dependence and no molecular-line masers are known to emit near 0.33 GHz; the lack of a frequency dependence therefore suggests that GCRT J1745–3009 is not a maser The closest of these were on 25 September and 2 October 2002 The extent to which flares from brown dwarfs are self-absorbed at low frequencies is somewhat uncertain, though, because flares from only two objects (LP944-20 and DENIS 1048-3956) have been observed at multiple frequencies simultaneously, and these frequencies were much higher (4.8 and 8.5 GHz) than 0.33 GHz, at which we detect GCRT J1745–3009 The light curves appear to be similar in shape, although the missing data during the first, second and third bursts hinders a comprehensive comparison The magnitude of errors in radio astronomical images typically increases with distance from the centre of the image The variability of GCRT J1745–3009 is shown in the light curve of Fig. 1 , and the average burst light curve is shown in Fig. 2  This scenario does not explain the transient behaviour from the source or the lack of interburst emission, and favours a distance of the order of 1 kpc or less We also do not detect the source in 0.33 GHz, ∼1-h Galactic Centre monitoring observations made earlier in 2002 and afterwards in 2003; the 5 σ  upper limit for detection in a bursting state is ∼250 mJy with 5-min integrations, and in a quiescent state is ∼50 mJy We conclude that GCRT J1745–3009 is not likely to be a dMe flare star or an extrasolar planet We conclude, therefore, that we cannot rule out that GCRT J1745–3009 is a flaring brown dwarf We have analysed a serendipitous pointed observation about 32′ from GCRT J1745–3009 in the Rossi X-Ray Timing Explorer (RXTE) archive that runs between the third and fourth burst, although it overlaps neither We next consider the possibility that the bursts from GCRT J1745–3009 could be relativistically beamed toward us, as is the case for microquasars, which are accreting black holes in binary systems that occasionally power radio-bright relativistic jets (for example GRS 1915 + 105, whose apparent superluminal motion has a Lorentz factor of γ ≈ 5)  Wood, P.S.R., S.D.H., T.J.W.L
 But we dont collaborate too much with any of them But we feel constantly misunderstood Evolution should be taught in schools, and creation discussed along with it Fighting against these prejudices is extremely hard Fundamentalism is immediately associated with Islamic fundamentalism: read terrorism How would you compare your group with creationists in the United States? We are aware of other creationist groups in Europe and the United States How would you describe your relationship with scientists? You dont have to agree on everything to do good, accurate science together with [non-creationist] scientists Intelligent design gives an alternative answer to this question Scientific naturalism as we know it doesnt allow for a creator who can interfere with the physical world Scientists — and the media — always say we are dilettantes, Christian fundamentalists The US debate is more aggressive, there is more foul play from both sides This is mean This is not helpful. newsad; Do you advocate intelligent design? Theres an open question about how the many complex structures observed in the Universe came into being We can subscribe to most of its arguments. We dont want to put anyone down We use the same methods as other scientists, namely falsifying and verifying hypotheses We want to do accurate and honest scientific work under the premise that God has created the world We would very much like to have an open discussion with evolutionary biologists about the issues at stake What about evolution? Microevolution, the adaptation of species to their environment, is an observed scientific fact, which we of course do not deny.But macroevolution, the gradual process of development of new species, is a mere conclusion, theres no observational evidence for that What are your main goals? We are a Protestant group
 A paper published in this weeks issue of the journal AIDS (19, 529–547; 2005) argues that an excess of boys in Chinas population could exacerbate the AIDS problem in cities Beijing Chinas AIDS crisis could take a turn for the worse because of a surplus of men in the population, suggests a new study But he hopes it will focus more attention on a possible seed of disaster But sexual transmission is playing an increasing role and some fear it will lead to an urban explosion of AIDS He calls for more education at construction sites, military areas and unemployment centres, where the surplus males gather. “These boys are coming of age,” he says. Historical precedents, such as a sex-ratio imbalance caused by mass migration to Shanghai in the 1930s, have led to rampant sexually transmitted infections It says that there are now about 12 boys born for every 10 girls in China Some epidemiologists and HIV experts have challenged the speculative nature of Tuckers argument, however Terry Hull, a social demographer at the Australian National University, Canberra, questions the idea that “poor unemployed migrant males” will be fertile ground for HIV transmission. “We might as easily argue that they will also ignore safety messages on the job and have more occupational deaths,” he says The number of prostitutes in China has also skyrocketed: it has admitted that there are now between 4 million and 6 million, compared with only 25,000 in 1985 The paper, “Surplus men, sex work, and the spread of HIV in China”, is authored by Joseph Tucker, a medical doctor in training at the University of North Carolinas Center for Infectious Diseases, and his co-workers The sex bias is the result of the nations ‘one-child’ policy and the fact that many parents want that child to be male The widespread availability of ultrasound techniques, which allow doctors to identify the sex of fetuses and give parents the ability to choose, is worsening the imbalance Tucker admits that his theory is only a hypothesis Tucker argues that the resulting “surplus men” — which he calculates to be about 8.5 million — are likely to be unmarried, poor and lacking education Tucker, who spent a year working at a clinic for sexually transmitted diseases in Nanjing, says that another such situation could be developing Until now, consideration of the HIV problem in China has often focused on isolated communities, such as intravenous drug users or the victims of contaminated blood banks
 A highly strategic approach is required, says Hartung. “In most cases it is not just a question of replacing one animal test with one in vitro test,” he explains A short while later, the European Commission proposed its controversial REACH legislation (Registration, Evaluation and Authorization of Chemicals) Almost overnight, industrys interest in cheaper, animal-free testing skyrocketed Although Hartung acknowledges the immense challenges ahead, he sees this as an opportunity for toxicology “to turn itself at last into a respectable science” Among these, some are better at predicting mild irritation than physical damage An additional 40 or so tests are under peer review, with more to come And industry claims that the testing process could cost it billions of euros And this is just the beginning. “Weve made a lot of progress with the low-hanging fruits, but many of the remaining animal tests — particularly the tests for toxicity in the long term — are much more challenging to replace,” says Hartung Animal-welfare groups fear that this will mean millions more animals will be used in tests to meet the regulatory requirements Any replacement tests will need to reassure both regulators and industry As their experience grows, ECVAM staff are finding out just how complicated it is to develop persuasive alternative tests At an ECVAM workshop in February, 30 industrial scientists met to develop the most effective strategy for using the alternative Draize tests, so that the false negatives and false positives of each test compensate for each other At least 70% of the chemicals registered in the past two decades fall into this category, says Hartung But Spielmanns 1995 study of animal-free alternatives to the Draize test showed that they were equally unreliable  But the longer-term picture should see a reduction in animal suffering going hand in hand with use of better science. But the numbers involved have fallen from 150 animals per chemical in the 1970s to just eight animals in 2002 But the toxicology tests on which regulators rely to gather this information are stuck in a time warp, and are largely based on wasteful and often poorly predictive animal experiments By this time, governments were highly sensitive to public concerns and called on their authorities to develop animal-based tests that would predict all conceivable toxic effects of drugs and chemicals Chemicals shown to be harmful in this test would be excluded from any LD 50 animal tests ECVAM believes that it can halve the total number of animals used for regulatory testing within a decade ECVAM found itself facing an unexpectedly short deadline for delivering a slew of animal-free methods for testing chemical toxicity ECVAM has so far seen 17 alternative tests through validation — 11 use in vitro methods, another six involve refining in vivo tests to reduce the number of animals used ECVAM is still pushing on both fronts ECVAM was set up in 1993 to support European Union policy aimed at reducing the number of animals used in regulatory testing Efforts in Europe are about to change this, and the man charged with bringing toxicology into the twenty-first century is a plain-talking German: Thomas Hartung Europe produces some 30,000 chemicals for which toxicity data have never been registered Every time you reach for an eyedrop or reapply a lip salve, you do so confident that the chemicals they contain are safe to use For example, several in vitro alternatives have been developed to replace the Draize test, each with its own advantages and limitations For example, the LD 50 acute toxicity test, which involves feeding animals with a chemical to determine the lethal dose, still accounts for one-third of all animal tests worldwide Fortunately, the 2013 deadline can be renegotiated If, as expected, the REACH directive is approved next year, it will come into effect in 2007 In 1971, a comparison of animal Draize tests in different labs revealed the test to be hopelessly non-reproducible  In addition, tests must be carried out to define the risk a chemical might pose to the environment, such as toxicity to fish and other aquatic species In the decade since ECVAM was established, the number of animals used in toxicology testing has fallen slightly, although it still hovers at about one million per year Instead, a number of tests will be required, each of which has been shown to match data on toxicity in humans, assuming such information is available It has just completed its first large-scale validation study of an in vitro cytotoxicity test, which monitors death of cultured cells following short-term exposure to a chemical It is dramatically over-predictive: more than 50% of the results are positive, of which 90% are false positives  It was developed by the US Food and Drug Administration in 1944 after reports in the 1930s that some cosmetics were causing permanent eye injuries Last month ECVAM was put in charge of developing, with industry and regulatory agencies, the testing strategies for REACH Life or death Scientists also cannot assume that in vitro alternatives are automatically better, says Spielmann More than half of all animals that will be needed to support REACH legislation are likely to be used in reproductive toxicology testing Most animal tests over- or underestimate toxicity, or simply dont mirror toxicity in humans very well Most of the new tests assess acute toxicity, but animal use is highest when testing for the toxic effects of prolonged exposure to chemicals for long-term consequences such as cancer and reproductive toxicity Now commanding 50 staff, Hartung is rising to the challenge One 38-year-old woman had gone blind after dyeing her lashes with Lash-Lure, a product that contained a derivative of coal tar Others are more suited to a particular chemical class, such as detergents Poor prediction This is despite the acknowledged poor quality of most animal tests, which have never undergone the rigours of validation that in vitro alternatives now face REACH aims to make registration mandatory for both future and existing chemicals — even those that have been on the market for decades Relevance requires a good match between the test results and human data Rule change The first change was to the European Unions Cosmetics Directive, which phases out over ten years the use of animals in cosmetics testing Safety catch Each chemical that goes through the multiple tests required for registration can use up to 5,000 animals — or 12,000 if the chemical is a pesticide Scientists know that they are likely to find it hardest to convince regulators about alternative tests for highly emotive issues such as cancer and birth defects Since then the in vitro tests have been standardized, and they are intrinsically more reproducible. “Although reproducibility and relevance are not the same thing,” Spielmann cautions Sounds familial This is why, apart from the €30 million it uses to support ECVAM annually, the European Commission is funding three multimillion-euro ‘Integrated Projects’ Take the embryotoxicity test in which chemicals are fed to pregnant animals and the fates of their embryos, and the progeny of two subsequent generations, are studied. “Animal embryotoxicity tests are not reliably predictive for humans,” says Horst Spielmann, a toxicologist at the Federal Institute for Risk Assessment in Berlin. “When we find that cortisone is embryotoxic in all species tested except human, what are we supposed to make of them?”  The same goes for cancer The battery of tests demanded by European authorities covers all eventualities, from acute effects that are seen shortly after exposure — such as eye and skin irritation — to concerns about whether in the longer term a compound might cause cancer, or brain or birth defects The centre, which nestles on the sleepy shores of Lake Maggiore in the Italian Alps, originally had ten members of staff and faced an uphill struggle to cut back the millions of animal tests carried out in Europe every year The cost of doing this for the 30,000 unregistered chemicals so that they comply with REACH has been estimated at between €5 billion (US$6 billion) and €10 billion The notorious Draize test, which assesses the irritation or damage caused by chemicals simply by putting them into the eyes of rabbits, is a prime example The principles behind most of those tests remain more or less unchanged today The REACH legislation is yet to be finalized, and alternatives to tests that present the highest financial and animal burden, such as reproductive toxicology and carcinogenicity, will not be in place when REACH first becomes law The ReProTect consortium has broken down the human reproductive cycle into smaller elements, from male and female fertility to implantation, to pre- and postnatal development, and is trying to develop a meaningful package of tests . “Quite correctly everyone feels uneasy about taking risks where stakes are so high and issues so emotive,” says Hartung. “We all want to be sure that there is real evidence that alternative tests are predictive of human toxicity.”  For example, regulators know the weaknesses of the rat cancer test as well as scientists but, wanting to be safe rather than sorry, they accept it because it is believed to throw up few false negatives The toxicity tests that have been used for decades are “simply bad science”, he explains. “We now have an opportunity to start with a clean slate and develop evidence-based tests that have true predictive value.”  Many of the animal tests used today were developed under crisis conditions The €9-million Integrated Project called ReProTect has 27 labs dedicated to developing alternatives to these tests Then came the calamity of thalidomide, which was given to pregnant women in the late 1950s to control morning sickness, but which caused horrific birth defects Then in 2003, two major policy changes were announced from above, increasing the pressure on the centres labs These costly procedures are harder to mimic in vitro and may never be completely replaced They prefer to let industry prove the innocence of any compound that shows up positive This reduction is a result of the refinement of existing tests, and the introduction of some alternative methods that rely on in vitro tests using cell cultures This strategy is now going through the crucial validation procedure, in which human data, often from occupational health databases, will be used as points of reference (see ‘The validation game’ ) Three years ago, when Hartung became director of the European Centre for the Validation of Alternative Methods (ECVAM) in Ispra, Italy, he didnt know that the job was about to shift gear dramatically To test a single chemical for its potential to cause cancer takes five years and involves 400 rats, each of which is treated with the maximum tolerated dose Under these, dozens of labs will collaborate for five years to tackle more difficult issues, such as allergic reactions or widespread toxicity resulting from chemicals entering the bloodstream With so much yet to be achieved, is Europe on target to deliver toxicity tests to meet the new regulations? The Cosmetics Directive phases out animal use in acute toxicity testing in 2009, and in testing for long-term effects in 2013. “We are on target for the first deadline, but the second deadline may be more difficult,” says Hartung Yet the number of compounds proved to be carcinogenic to humans is very low — the International Agency for Research on Cancer in Lyons, France, has identified just 95 proven and 66 probable human carcinogens
 By comparing these results with geophysically inferred conductivity , we infer that the water content in the mantle transition zone varies regionally, but that its value in the Pacific is estimated to be ∼0.1–0.2 wt% Here we determined the effects of water and temperature on the electrical conductivity of the minerals wadsleyite and ringwoodite to infer the water content of the transition zone However, the amount of water in the transition zone has remained unknown Minerals in the transition zone of the Earths mantle (from ∼410 to ∼660 km depth) have large water solubility , and hence it is thought that the transition zone might act as a water reservoir The distribution of water in the Earths interior reflects the way in which the Earth has evolved, and has an important influence on its material properties These values significantly exceed the estimated critical water content in the upper mantle , suggesting that partial melting may indeed occur at ∼410 km depth, at least in this region. We find that the electrical conductivity of these minerals depends strongly on water content but only weakly on temperature When the water content of the transition zone exceeds a critical value, upwelling flow might result in partial melting at ∼410 km, which would affect the distribution of certain elements in the Earth  A comparison of the experimental results with this table suggests that the charge-carrying species in wadsleyite and ringwoodite under the present experimental condition is the free proton and not the most abundant defect, that is, hydrogen trapped at an M-site A promising way to infer the water content in the actual Earth is to compare some geophysical observations with experimental data on the effects of water  A thin disk of a sample was cut and the electrical conductivity was measured at P = 14–16 GPa and T = 773–1,273 K in the frequency range 10 2 –10 6  Hz using the technique developed in ref. 20  After pressurization, temperature was increased to a desired value at a rate of ∼50 K min -1 below 873 K and ∼200 K min -1 above 873 K All recovered samples were examined using a micro-Raman spectrometer for phase identification Assuming that water (hydrogen) affects the conductivity through its influence on defect concentration, the results can be interpreted by using the Nernst–Einstein relation, σ  = ∑  j n j q j µ j (where n j is the concentration of the j th type of charge carrier, q j is the effective charge, and µ j is its mobility) Because the pressure effect on electrical conductivity is usually small and the variation of pressure in the transition zone is small, the pressure effect is ignored Consequently the value of r in equation (1) must be identical to the value of p in equation (2) for the defect that carries most of the electric current Consequently, determining the distribution of water in the Earths mantle is an important issue in solid Earth geophysics and geochemistry Experimental studies have shown that the mantle transition zone can be a large reservoir for water, and a water-enriched transition zone may be important in geochemical cycling , but the exact amount of water in the transition zone is poorly constrained Figure 2 shows the trade-off between the effects of water content and temperature on the electrical conductivity of wadsleyite and ringwoodite For the upper mantle of the North Pacific Ocean, where a detailed inversion was made using mineral physics constraints , the conductivity in the transition zone is ∼10 -1 to ∼5 × 10 -1  S m -1 and the corresponding water content in the transition zone is estimated to be ∼0.1–0.2 wt% for the temperature range of 1,825–1,900 K ( Fig. 3 ) Given this model, the electrical conductivity is predicted to depend on chemical environment as: σ ∝ f H 2 O 3 4 f O 2 - 1 8 a MeO - 1  exp - H * RT (4) The oxide activity in our experiments is controlled by the presence of excess (Mg,Fe)SiO 3 which is probably the same in the Earth Here we investigated the effects of water on the electrical conductivity of wadsleyite and ringwoodite, and by comparing the results with geophysically determined electrical conductivity in the transition zone, we estimated the water content in the transition zone However, previous studies on Fe-bearing olivine showed no appreciable effect of grain size However, some regional variation in electrical conductivity was also reported , suggesting a large regional variation in hydrogen content (and temperature) in the transition zone. In contrast, the expected water contents in the transition zone range from almost dry (∼ 10 -4  wt%) to water-saturated (∼ 3 wt%), which corresponds to the variation of conductivity by a factor of ∼10 3  In most runs, the water content changed during a run: in water-poor samples, the water content increased, and in water-rich samples, the water content decreased In particular, a model of water (hydrogen) dissolution in olivine, wadsleyite and ringwoodite shows that water is dissolved in these minerals mostly as a neutral defect 2H M ×  (two protons trapped at an M-site) , and the water solubility is related to the chemical environment as: C W ∝ f H 2 O f O 2 0 a MeO - 1 (3) In our experiments, both f O 2 and a MeO were fixed and f H 2 O was different for different samples In particular, melting behaviour of silicate rocks , plastic deformation , electrical conductivity and diffusion are known to be affected significantly by the presence of water Owing to the small activation enthalpy, the temperature effect is relatively small: a variation in temperature of ∼200 K results in a change in conductivity of a factor of ∼2 Oxygen fugacity in the Earths transition zone is unknown, and therefore we consider a range of oxygen fugacity (from the value similar to that of the upper mantle, that is, fayalite–magnetite–quartz buffer, to Mo/MoO 2 buffer) Synthesis was performed either under water-free conditions or with a certain amount of free water The absolute value of impedance approaches an asymptotic value at low frequencies The change in water content is typically small (∼ 30% or less), and we estimate that the overall uncertainty of hydrogen content for each measurement is better than ∼20% The concentration of hydrogen in samples was determined by Fourier-transform infrared (FT-IR) spectroscopy both before and after each measurement of electrical conductivity, using a ∼30-µm-thick sample in crack-free regions of ∼40 µm × 40 µm The conductivity values corresponding to these asymptotic values correspond to those determined by geophysical methods The correction for oxygen fugacity is made using: σ  Earth ( T , C W ) = f O 2 ,Earth f O 2 ,Lab q σ  Lab ( T , C W ) (5) where σ  Earth is the electrical conductivity of the Earth, σ  Lab is the electrical conductivity of wadsleyite and ringwoodite, f O 2 ,Lab is the oxygen fugacity corrections to the Mo/MoO 2 buffer, f O 2 ,Earth is the oxygen fugacity in the Earth, and q is a constant (- 1/8) The defect chemistry of minerals under hydrous conditions shows that the concentration of hydrogen-related defects [ X ] depends on the chemical environment as: [ X ]∝ f H 2 O p f O 2 q a MeO s (2) where p , q and s are constants that depend on the type of defect, f H 2 O is water fugacity, f O 2 oxygen fugacity and a MeO the activity of metal oxide (such as (Mg,Fe)O) The electrical conductivity in the transition zone ranges from ∼10 -2  S m -1 to ∼1 S m -1 (refs 5–7 ) The estimated water content in the north Pacific transition zone (∼ 0.1–0.2 wt%) is significantly higher than the estimated water content in the upper mantle and probably exceeds a critical concentration for partial melting The influence of grain size on electrical conductivity was not investigated systematically in this study The oxygen fugacity in our experiments is controlled by the Mo/MoO 2 buffer The oxygen fugacity was buffered by the Mo/MoO 2 solid-state reaction The parameters for wadsleyite and ringwoodite are summarized in Table 1  The Paterson calibration was used to calculate hydrogen content from infrared absorption The pressure was estimated from the load-pressure calibration using several pressure standards, and the temperature was measured by a W5%Re–W26%Re thermocouple The rapid temperature ramp at high temperature was chosen to minimize water loss The results are shown in Fig. 1  The starting material was San Carlos olivine, and ∼5% orthopyroxene was added to control the oxide activity to the silica-rich end The values of p , q and s for typical defects in wadsleyite and ringwoodite are summarized in Table 2  Therefore water content is well-constrained by the conductivity data Therefore we do not consider the grain-size effect here This asymptotic value is used to calculate the conductivity of a sample This corresponds to water contents of ∼0.001 to ∼0.4 wt% This is consistent with a recent model of material circulation involving the separation of the circulation of incompatible elements from that of major elements near 410 km, but is not consistent with a model involving vertical circulation of hydrogen together with major minerals This suggests that there is a marked layering in water content in the Earths mantle This will reduce the conductivity by a factor of ∼2 ( σ  Earth ≈ 0.5 σ  Lab ) Wadsleyite and ringwoodite samples with a grain size of 5–10 µm were prepared at pressure P = 14–16 GPa and temperature T = 1,273–1,473 K with controlled water contents using a Kawai-type multianvil apparatus at Yale University Water (hydrogen) plays an important role in a number of geophysical or geochemical processes We analyse the results assuming the following relationship: σ  = AC W r  exp - H * RT (1) where σ  is electrical conductivity, A and r are constants, C W is water content, H * is activation enthalpy, R is the gas constant and T is temperature We assumed that the f O 2 in the mantle is close to that of the Ni/NiO buffer  We determined the frequency-dependent impedance that has both real and complex components
 A significant aspect of the story of the modern sciences of nature consists of combating what came to be seen as the literary, artistic and antiquarian stigmas associated with natural history A “careless” creature, says the Physiologus , the “sparrow camel” ( Strutho camelus ) abandons its eggs in the sand, but returns to hatch them by staring at them And, of course, if we do not want to face reality, we bury our heads in the sand like an ostrich. But like many of the Christian rituals, the origin lies in other cultures But the legends of the bestiary remain deeply embedded, albeit largely unnoticed, in our own culture Eggs and Easter are now indissolubly linked From China to Egypt, the egg is the symbol of rebirth in spring, and even of the Universe itself He next outlines its utility for man, before an extensive section on its wider history in various cultures, its symbolic, moral and geographical connotations, and its role in literature His account emphasizes the ‘history’ in natural history — a name that now applies largely to museums — in the face of the rise of the more ‘scientific’ terms zoology and botany, or, more recently, animal and plant sciences However, Konrad Gesner, the great Swiss natural historian often seen as the father of zoology, on the basis of the superb illustrations in his Historia Animalium (1551), diligently records stories from the Physiologus and subsequent bestiaries In churches they hung in places of honour In the thirteenth century, Bishop Guilelmus Durandus gave two reasons for exhibiting ostrich eggs in church It seems that we may have incorrectly characterized the origins of modern science It told of the ostrichs strange incubation habits Like other exotic curiosities, such as unicorns (really narwhals) horns, they testified to the wonder of creation More specifically, they carried an intricate Christian message, derived from the Physiologus or Bestiary , probably compiled in the fourth century from classical, Egyptian and Indian sources No natural object is more loaded with meaning Not the least of the avoiding actions was to abandon the deluxe picture-book that had dominated the study of animals and plants from the sixteenth century Prized in cabinets of curiosities, the eggs were often given extravagant mounts in silver The aim was nothing less than a comprehensive review of each animal in its widest context from a humanist perspective The Christian interpretation given in the Physiologus and by subsequent writers is that worshippers should keep their eyes on Christ at all times The heat of its sight incubates the chicks, in accordance with the theory that seeing rays emanate from the eye The largest egg of all, the ostrichs, has drawn intense secular and religious attention The learned text supplied for each illustrated beast begins by comparing the animals names in various languages, a necessary preliminary in the era before standard nomenclature The most famous is suspended from the shell niche behind the Virgin in Piero della Francescas Brera Altarpiece (pictured here), painted in the mid-1460s for Duke Federigo Montefeltro in Urbino The wonder of its shape and the miracle of the life within have an endless fascination Then Gesner deals with the animals appearance and form, its food, generation and life in its habitat, including its enemies These legends may seem to have little to do with what we regard as the science of animals We talk, for instance, of crying crocodile tears, as crocodiles were reputed to weep insincerely after devouring a man
 An important goal that now seems attainable is to understand how this processing translates into, in some instances, innate behaviours and, in others, learned behaviours As always, Nature carries sole responsibility for all editorial content and peer review. Despite this, research into chemical sensing historically took a back seat to vision and audition, challenged by the complexities of indefinable stimuli that are often not even consciously processed, and by difficulties in uncovering even the basic mechanisms of transduction and representation New experimental tools, such as sophisticated methods for labelling, recording and manipulating neuronal activity and projections, have provided researchers with insight into the principles by which the taste and olfactory systems decode and represent environmental stimuli Taste and smell contribute critically to our experience of our environment, from the pleasure of eating to the formation of childhood memories The findings reviewed here are not only remarkable intellectual achievements, but are also of great potential value to society The reviews in this Insight highlight the progress made during the past fifteen years, and emphasize how the stage is set to tackle fundamental questions about the brain and behaviour Then, in 1991, Buck and Axel identified the genes for odorant receptors, launching chemical-sensing research to the forefront Understanding the cues and mechanisms through which humans and other animals are attracted to or repulsed by chemosensory stimuli holds promise for tackling several major problems facing modern human society — from the control of disease-bearing insects to causes of overeating We are pleased to acknowledge the financial support of our principal sponsor Givaudan and our supporting sponsors ChemCom and the National Institute on Deafness and Other Communication Disorders in producing this Insight
 A major unresolved issue is the relative timing of CAI and chondrule formation  Both chondrule-bearing CAIs are 26 Al-poor with initial 26 Al/ 27 Al ratios of (4.7 ± 1.4) × 10 -6 and 1.2 × 10 -6  Chondrules and Ca-Al-rich inclusions (CAIs) are high-temperature components of meteorites that formed during transient heating events in the early Solar System From the presence of chondrule fragments in an igneous CAI, it was concluded that some chondrules formed before CAIs (ref. 5 ) Here we report that relict chondrule material in the Allende meteorite, composed of olivine and low-calcium pyroxene, occurs in the outer portions of two CAIs and is 16 O-poor (Δ 17 O ≈ - 1‰ to -5‰) Spinel and diopside in the CAI cores are 16 O-rich (Δ 17 O up to -20‰), whereas diopside in their outer zones, as well as melilite and anorthite, are 16 O-depleted (Δ 17 O = -8‰ to 2‰) This conclusion is contrary to the presence of relict CAIs inside chondrules , as well as to the higher abundance of 26 Al in CAIs ; both observations indicate that CAIs pre-date chondrules by 1–3 million years (Myr) We conclude that these CAIs had chondrule material added to them during a re-melting episode ∼2 Myr after formation of CAIs with the canonical 26 Al/ 27 Al ratio of 5 × 10 -5 . A coarse fragment of forsteritic olivine (5 mole% fayalite; Fa 5 ) intergrown with low-Ca pyroxene (1 mole% ferrosilite, 4 mole% wollastonite; Fs 1 Wo 4 ) occurs in the CAI portion containing Cr-rich, Al-Ti-poor diopside ( Fig. 1a , c ; Supplementary Table 1 ) ABC is a coarse-grained, igneous, anorthite-rich (type C) CAI fragment composed of lath-shaped anorthite (99 mole% anorthite; An 99 ) and Cr-poor Al-Ti-diopside, both poikilitically enclosing spinel grains, and interstitial, åkermanite-rich (Åk 74 ) melilite ( Fig. 1a , b ; Supplementary Table 1 ) Although coarse olivine grains occasionally associated with low-Ca pyroxene are also found in amoeboid olivine aggregates and in forsterite-rich accretionary rims around CAIs, these olivines and pyroxenes have characteristic 16 O-rich compositions  Although the mineralogy and petrology of both CAIs were described previously , the presence of relict chondrule material inside them remained unnoticed At face value, these results suggest that chondrule formation began contemporaneously with the formation of CAIs, and continued for at least 1.5 Myr Bizzarro et al . reported high precision Mg isotope analyses of micro-drilled Allende chondrules Both igneous and non-igneous CAIs are surrounded by 16 O-rich multilayered rims (called ‘Wark–Lovering’ rims), with the outermost layers, composed of Al-diopside and forsterite, probably formed by condensation  Data for 15 chondrules show model isochrons with initial 26 Al/ 27 Al ratios ranging from (1.4 ± 0.5) × 10 -5 to (5.7 ± 0.8) × 10 -5 , systematically higher than ion probe data for Allende chondrules Here we report new observations of the mineralogy, petrography and oxygen and magnesium isotopic compositions of two chondrule-bearing CAIs (ABC and TS26) from Allende, which provide important constraints on the relative chronology of CAI and chondrule formation In addition, spatial heterogeneity in 26 Al distribution in the solar nebula cannot be ruled out In addition, TS26 and ABC show significant 16 O-depletion in Al-diopside; the degree of depletion increases towards the relict chondrule fragments and the CAI peripheries In contrast, most chondrules originated in a 16 O-poor (Δ 17 O -5‰) gaseous reservoir at low ( 1,000 K) ambient temperatures and higher total pressure or dust/gas ratios than CAIs  It has a coarse-grained core composed of lath-shaped anorthite (An 99 ) and sector-zoned Al-Ti-diopside, both poikilitically enclosing spinel grains, and interstitial åkermanite-rich (Åk 72 ) melilite Melting of pre-existing solids accompanied by evaporation-recondensation is believed to have been the dominant process during chondrule formation  Mineralogical, chemical and isotopic data suggest that refractory inclusions formed in an 16 O-rich gaseous reservoir (Δ 17 O SMOW ≈ - 20‰) at high ambient temperatures (near or above the condensation temperatures of forsterite; ∼1,375 K at a total pressure of 10 -4  bar), and were subsequently isolated (physically or kinetically) from reactions with the high temperature solar nebula gas . (Here Δ 17 O = δ 17 O - 0.52 × δ 18 O; δ 17,18 O = [( 17,18 O/ 16 O) sample /( 17,18 O/ 16 O) SMOW - 1] × 1,000, where SMOW is Standard Mean Ocean Water.) Evaporation and condensation are believed to have been the dominant processes during formation of refractory inclusions  Most CAIs show large 26 Mg excesses ( 26 Mg*), produced by the in situ decay of 26 Al (half-life t 1/2 = 0.73 Myr), corresponding to an initial 26 Al/ 27 Al ratio, ( 26 Al/ 27 Al) 0 , of ∼5 × 10 -5 (called ‘canonical’), whereas most chondrules have smaller 26 Mg* corresponding to ( 26 Al/ 27 Al) 0 ratios of ≤1.2 × 10 -5 (ref. 11 and references therein) Most coarse-grained igneous CAIs in Allende, including TS26 and ABC, show oxygen isotopic heterogeneity: spinel and Al-Ti-diopside are typically 16 O-rich (Δ 17 O ≈ - 20‰), whereas melilite and anorthite are 16 O-depleted (Δ 17 O up to 5‰)  Olivine and high-Ca pyroxene have 16 O-poor compositions; spinel is 16 O-rich, whereas Al-Ti-diopside and anorthite are 16 O-depleted to varying degrees ( Fig. 2b ) Olivine and low-Ca pyroxene have 16 O-poor compositions; spinel and Al-Ti-diopside are moderately 16 O-enriched, whereas Cr-spinel, Al-Ti-poor diopside, high-Ca pyroxene, anorthite and melilite are 16 O-depleted to varying degrees ( Fig. 2a ) On the basis of these observations and the assumption that 26 Al was uniformly distributed in the solar nebula, it is generally inferred that CAIs formed at least 1–1.5 Myr before chondrules  On the basis of these observations, we infer that ABC and TS26 experienced incomplete oxygen isotopic exchange and dilution with 16 O-poor relict chondrule materials during their last melting in an 16 O-poor gas, probably in the chondrule-forming region On the other hand, the relative timing of CAI and chondrule formation can be resolved by studying compound objects composed of chondrule and CAI, because both constituents of such objects were affected by the same heating episode Subsequently, some CAIs (called ‘igneous’) experienced extensive melting accompanied by evaporation  The 207 Pb– 206 Pb ages of a group of Allende chondrules (4,566.7 ± 1.0 Myr) cannot be distinguished from those of CV CAIs (4,567.2 ± 0.6 Myr)  The absence of Wark–Lovering rim layers around TS26 could also be due to the inferred melting episode The CAI anorthite, spinel and Al-Ti-diopside show no resolvable 26 Mg*; the inferred ( 26 Al/ 27 Al) 0 ratio is 1.2 × 10 -6 ( Fig. 3 ) The CAI shows a resolvable 26 Mg* corresponding to a ( 26 Al/ 27 Al) 0 ratio of (4.7 ± 1.4) × 10 -6 ( Fig. 3 ) The coarse Al-Ti-diopside grains in the core are less 16 O-depleted compared to those in the finer-grained mantle The coarse-grained nature of relict forsteritic olivine associated with low-Ca pyroxene and their 16 O-poor compositions suggest that these grains are probably fragments of ferromagnesian chondrules The corroded appearance of olivine-pyroxene fragments in ABC and TS26 and the presence of high-Ca pyroxene haloes suggest that these grains were present inside the host CAIs during final solidification and were partly dissolved in the CAI melt The fact that many CAIs show no evidence for being affected by chondrule heating suggests that the chondrule-forming events were highly localized. The finer-grained mantle is composed of Al-Ti-diopside, lath-shaped anorthite, and abundant coarse grains of forsteritic olivine (Fa 8–17 ) and low-Ca pyroxene (Fs 1 Wo 1–4 ) The high abundance of relict chondrule-like material in the outer portion of TS26 (see Supplementary Fig. 2b ) suggests there was a high abundance of dust in the region where melting occurred, consistent with the dusty environment inferred for chondrule formation  The late-stage melting and oxygen isotopic exchange of ABC and TS26 are also consistent with the recently proposed model for the global evolution of the oxygen isotope composition of the inner solar nebula gas from 16 O-rich to 16 O-poor with time  The low ( 26 Al/ 27 Al) 0 ratios observed in ABC and TS26 may have recorded their late-stage re-melting during incorporation of the chondrule fragments The observed differences in grain size between the core and the mantle of TS26 (see Supplementary Fig. 2a ) suggests that melting was incomplete and was followed by relatively fast cooling The olivine and low-Ca pyroxene grains are corroded by the diopside and surrounded by haloes of high-Ca pyroxene (Fs 0.4–0.6 Wo 35–42 ; Fig. 4c ) The olivine-pyroxene fragment is corroded by the diopside and surrounded by a halo of high-Ca pyroxene (Fs 0.2–0.6 Wo 30–40 ; Fig. 1c ) The only exception is the chondrule-bearing CAI A5 from the Yamato-81020 chondrite that has been interpreted as providing evidence for chondrule formation pre-dating the formation of CAIs  The proposed multi-stage formation history of ABC and TS26 is consistent with the extended (∼ 2 Myr) formation time of several other igneous CAI from CV chondrites inferred from a range of the ( 26 Al/ 27 Al) 0 ratios within a single inclusion and petrographic observations  The relict origin of the olivine-pyroxene fragments is consistent with their dissolution textures and with the absence of olivine and low-Ca pyroxene in the crystallization sequence (spinel → anorthite → Al-Ti-diopside → melilite) predicted for a melt having ABC- or TS26-like bulk composition (see Supplementary Fig. 3 ) This conclusion has recently been questioned on the basis of the new lead and magnesium isotopic measurements This heterogeneity has recently been attributed to oxygen isotopic exchange between an 16 O-poor nebular gas and initially uniformly 16 O-rich CAIs during incomplete melting  TS26 is an irregularly-shaped type C CAI that shows a well-defined core-mantle structure ( Fig. 4a ; Supplementary Fig. 2 ), but lacks the Wark–Lovering rim layers observed around most coarse-grained CAIs from Allende  We note, however, that because Allende experienced thermal metamorphism that may have disturbed the 26 Al- 26 Mg systematics in CAIs and chondrules , the exact age difference between the formation of CAIs ABC and TS26 and their re-melting should be considered with caution We note, however, that the ( 26 Al/ 27 Al) 0 ratios inferred from bulk Mg isotope measurements of chondrules may date the time for the formation of chondrule precursor materials, not the time of chondrule melting; the latter requires Mg isotope measurements of mineral separates or individual mineral grains, which have not been completed yet With one exception, all CAI-chondrule compound objects consist of relict CAIs inside chondrules, suggesting that the host chondrules formed by melting of solid precursors containing pre-existing CAIs 
 A shiny drop of pitch, which gradually changes in shape from a sphere to a pear, is “a thing of beauty”, he says At the fifteenth Ig Nobel ceremony, held on 6 October before a boisterous crowd in Harvards Sanders Theatre, ten prizes were awarded to winners from a dozen countries Boston Unlike other days at Harvard University, the first Thursday in October is a time when levity overtakes gravity, irreverence prevails over reason, and the flight of paper aeroplanes is actively encouraged He had unwittingly stumbled across Parnells experiment, by then three decades old He hoped to show that this apparently solid substance — brittle enough to shatter on impact — has fluid-like properties In work that earned them the chemistry prize, two researchers from the University of Minnesota in Minneapolis showed that people can swim as fast in syrup as in water (see Nature doi:10.1038/news040920-2; 2004 ) It is hard to know what motivated Parnell, but Mainstone suspects it had to do with the quantum revolution — the idea that “things are not what they seem” — that had overtaken physics. “This was his way of showing there are strange things in classical physics too,” Mainstone surmises It is time, in other words, for the Ig Nobel Prize Ceremony It shows that an ostensibly solid tar derivative can behave like a liquid, forming drops at the rate of about one every nine years Its viscosity, Mainstone and his colleagues calculate, is 100 billion times that of water John Mainstone of the University of Queensland in Australia accepted the physics prize for the ‘pitch-drop’ experiment started back in 1927 by the prizes co-winner, the late Thomas Parnell Looking to the future, Mainstone has already picked a successor, his former student Andrew White, to oversee the project when he finally steps down Mainstone believes that fibres supporting the drop in its final stages become unstable and fail catastrophically, but this hypothesis is unconfirmed Mainstone never imagined that he would look after this experiment for four-and-a-half decades, but says he has become “enthralled by the historical continuity of it all” Mainstones labour of love, along with Parnells pioneering work, were recognized in 2003 when the Guinness World Records named the pitch-drop demonstration the worlds longest-running laboratory experiment No one knows, for example, how each drop actually detaches Parnell, Queenslands first physics professor, had taken a sample of pitch, heated it, and placed it in a funnel Part of the problem is that in the experiments 78-year history, no one has seen a single drop fall Science has become a “rat race”, largely as a result of the pressure to compete for grant money, he claims, adding that its important to get a break from that sometimes. “When we cease to see the amusing side of science, its all over,” he says. Shortly after arriving at Queensland in 1961, Mainstone found a curious piece of equipment tucked away in a cupboard Sure enough, the material did form drops, albeit at an exceedingly slow rate Thats not surprising, says Mainstone. “Were talking about a descent of a few centimetres, lasting a tenth of a second, that occurs just once a decade.” The last drop, which fell in November 2000, should have been recorded on a webcam, but technical problems intervened. “Well have to wait until next time, which could be 2010 or later,” Mainstone notes The biology prize, for example, went to an international team for smelling and cataloguing the odorous secretions of 131 species of stressed-out frog The experiment has attracted a cult following, he says, yet it also raises some serious scientific questions The Ig Nobel prize, which Mainstone shares with the late Parnell, provides further recognition There is enough pitch left to sustain the experiment for another century, he estimates, and he hopes it will continue, despite the constant battles he has waged with the “philistines” who believe the experiment wastes precious time and space While acknowledging the importance of quantum mechanics, he cant help but wonder: “Is the pitch drop any less fascinating than wave–particle duality?”  Mainstone is a great believer in the Ig Nobels, and not just because of his award Winners travelled from as far as Australia and Japan to take home the ‘Ig’, a prize devoted to “achievements that first make people laugh, and then make them think”
 Allen and R But the nature of compensation will always remain contested However, these mechanisms are not the obligatory compensation transfers that Byravan and Rajan espouse Indeed, the prospect of enforceable migration threatens voluntary processes, such as the UNFCCC, as they may deter large greenhouse-gas polluters from participating in the process Legislating for flows of people may simply not appeal to migrants Lord, Nature 432 , 551 – 552 ; 2004 ) New Zealands creation of the Pacific Access Category, in response to concerns about climate change, is an instructive example R Sir Sujatha Byravan and Sudhir Chella Rajan, in Correspondence (“Immigration could ease climate-change impact”  Nature 434 , 435 ; 2005 10.1038/434435a ), argue that major greenhouse-gas emitters should provide compensation for the impacts of climate change The notion that migration is a sustainable adaptation strategy for future climate change ignores the fact that patterns of migration are strongly based on social networks and cultural links The scheme allows for up to 75 people from Tuvalu to migrate each year, but since it began in July 2002, fewer than half the places available have been filled The United Nations Framework Convention on Climate Change (UNFCCC) is developing mechanisms to help vulnerable countries adapt to climate change This example points to the need for policies and measures that help people adapt to climate change, in order to lead the kind of lives they value in the places where they belong, rather than to encourage migration This possibly suggests that even in Tuvalu, where there is widespread concern about climate change, people are not eager to leave their homeland We also believe there will eventually be the science to accurately establish liability for those impacts (see M We believe that compensation is on the cards We believe that promoting and funding activities that enhance in situ adaptation for vulnerable populations is a more practicable and equitable approach than migration-based compensation strategies.
 Cytonemes are actin-based filopodial extensions that have been found to orient towards the A/P organizer from outlying cells Decapentaplegic (Dpp), a member of the transforming growth factor-β (TGF-β) superfamily, embodies the activity of the A/P organizer Here we show that in the wing disc, cytonemes orient towards both the A/P and D/V organizers, and that their presence and orientation correlates with Dpp signalling It is produced at the A/P organizer and distributes in a gradient of decreasing concentration to regulate target genes, functioning non-autonomously to regulate growth and patterning of both the anterior and posterior compartments  The anterior/posterior (A/P) and dorsal/ventral (D/V) compartment borders that subdivide the wing imaginal discs of Drosophila third instar larvae are each associated with a developmental organizer The mechanisms that distribute Dpp and Wg are not known, but proposed mechanisms include extracellular diffusion , successive transfers between neighbouring cells , vesicle-mediated movement , and direct transfer via cytonemes  These observations are consistent with a role for cytonemes in signal transduction. We also show that the Dpp receptor, Thickveins (Tkv), is present in punctae that move along cytonemes Wingless (Wg) is produced at the D/V organizer and embodies its activity  Bier Chanut) in- trans to each other. hh ts was obtained from the Bloomington stock centre ( BL-1684 ), hs- dpp was from E Confocal images were acquired with a Leica TCS laser scanning microscope and analysed using NIH Image J. Cytochalasin D was used at 20 µg ml -1 in Grace medium containing 5% dimethylsulphoxide  Imaging Images were taken using an upright Zeiss Axioplan2 microscope equipped with a Cooke CCD camera, and were refined with deconvolution software ( Slidebook v4.0 , Intelligent Imaging Innovations ) In both dpp ts and hh ts experiments, larvae were grown at 18 °C, shifted to 29 °C and then immediately dissected and imaged, or were returned to the permissive temperature (18 °C) before dissection Luo. dpp ts was created by placing dpp 4 and dpp 56 (obtained from F Methods Fly stocks brinker (brk)-Gal4 is an enhancer trap on the X chromosome  Note that in the finished preparation, the samples, buffer and the smaller coverslip used for flattening, are all ‘hanging’ under the larger coverslip that contacts the objective lenses (see illustration in Fig. 1a ) Random CD8–GFP clones were generated by applying a heat shock to hsFlp ; abxubx FRT Gal4 / UAS - CD8 – GFP to early third instar larvae for 12 min at 37 °C Sample preparation method Imaginal discs were dissected and mounted in 1 × PBS buffer Samples were incubated in the solution for 30 min on ice before imaging Samples were placed on a coverslip, apical side down in a PBS droplet, and overlaid with a smaller coverslip to enhance flattening The ‘sandwich’ was then turned upside-down, placed over the depression well of a slide and secured with halocarbon oil at the edges This allows the field to be scanned without damaging the sample, and minimizes additional compression of the samples Time-lapse sequences and kinetic analysis of TKV–GFP trafficking were accomplished using Slidebook software Tkv–GFP movement was captured with 100–153-ms exposure intervals UAS - CD8 – GFP was a gift from L UAS - tkv – GFP was created by inserting the enhanced ( E ) GFP coding sequence at the carboxy terminus of tkv and cloning into pUAST  A concentration gradient does not imply a mechanism for distribution; it is conceivable that cytonemes sense and respond to Dpp but do not ferry it A/P cytonemes as long as 80.2 µm have been recorded; the average length in these preparations is 20.8 µm After incubation at 29 °C, however, cytonemes in hh ts and dpp ts mutant discs were more numerous ( twofold), and were not uniformly oriented towards the A/P organizer region ( Fig. 2d , f ) Although Dpp is essential for cell survival in the notum , there is no indication that the A/P compartment border in the notum has an associated organizing centre, and it is ambiguous whether Dpp functions as a morphogen in the notum region Although we favour a model in which they extend from cells in random directions but become stabilized when functional contacts are made with signalling cells, we cannot exclude the possibility that their directionality is directly influenced by extracellular cues As these patterns of Tkv–GFP punctae could be imaged in unflattened discs, we compared their distribution in both flattened and unflattened discs As this work shows, the Dpp receptor Tkv is present in cytonemes, and the presence, orientation and shape of cytonemes in wing discs correlates with what is known about the different roles that Dpp has in the wing, notum and hinge primordia At the permissive temperature (18 °C) in mutant discs, or at either the permissive or non-permissive (29 °C) temperatures in normal discs, cytonemes emanating from cells at the lateral flanks of discs oriented towards the A/P organizer ( Fig. 2a–c ) Bright punctae were observed on the surface of cells expressing Tkv–GFP, and they appeared to move along the surface of the cells even in the presence of drug ( Fig. 4e ) Clones in the notum primordium radiated cytonemes in all directions, without a consistent bias towards either the A/P or D/V axes of the disc Cytonemes appear as fluorescent strands emanating from the apical surface of disc cells that express green fluorescent protein (GFP)  Cytonemes associated with notum clones averaged 7.4 µm in length, almost 65% shorter than A/P cytonemes in the wing primordium Cytonemes with such shapes were never observed under normal conditions, or if mutant larvae were returned to the permissive temperature after a period of incubation at 29 °C ( Fig. 2e ) D/V cytonemes were shorter, averaging 8.8 µm ( Supplementary Table 1 ) Dpp is apparently not required for either growth or cell survival in the hinge/pleural region  Dpp is synthesized and secreted by a narrow stripe of 5–7 cells adjacent to the A/P compartment border in the wing primordium, and it distributes in a gradient of decreasing concentration that extends across the wing pouch  Even more striking were the cells in the hinge domain, which normally do not extend cytonemes Figure 1 shows a clone imaged at two adjacent optical planes: A/P-oriented cytonemes are visible in the more apical plane and D/V-oriented cytonemes are visible in the more basal plane of the clone First, when we reduced Dpp levels at the A/P organizer using temperature-sensitive mutants of either dpp ( dpp ts ) or hedgehog ( hh ts ) ( dpp expression depends upon Hh signalling), cytonemes in the wing primordium were affected High-magnification views of clones in this and similar discs reveal cytonemes extending outwards from some, but not all clones However, bright, motile punctae were also present in more central regions, as far as 30 µm from the edge of the expression domain ( Fig. 4a ) However, on the basis of the results presented here, we consider cytoneme-based transport to be an attractive possibility However, the wing pouch primordium is convex, and cytonemes can only be imaged in discs that have been slightly flattened In contrast, expression of a human guanine nucleotide exchange factor (GEF) protein, Vav–GFP, which has been shown to localize to filopodia in vertebrate cells , labels basal filopodia when expressed in wing disc cells ( Fig. 5c , f ) In contrast, the bright punctate fluorescence distant from GFP-expressing cells was not motile In contrast, Tkv–GFP punctae in heat-shocked hs- dpp discs were more numerous and projected in various directions all around the circumference of the clones ( Fig. 4g ) In control discs, cells projected cytonemes towards A/P and D/V axes only ( Fig. 3a ), but in discs with heat-shock-induced Dpp (hs- dpp ) 50% of the clones projected cytonemes outwards in all directions ( Fig. 3b ) In normal discs, Tkv–GFP punctae were polarized in the direction of the A/P border ( Fig. 4f ) In such images, we observed that cytonemes labelled with CD8–GFP ( Fig. 5a , d ) as well as cytonemes containing Tkv–GFP punctae ( Fig. 5b , e ), extend from the apical surface of the disc columnar epithelial cells In the micrograph shown in Fig. 1b , small clones (averaging 10–15 cells) express CD8–GFP and are visible in a speckled pattern In the wing blade primordium, approximately 20% of the clones extended cytonemes oriented towards either the A/P ( Fig. 1c , i ) or D/V compartment borders ( Fig. 1h , i ) In these mutant discs, we observed curved and bent cytonemes, and cytonemes crossing over each other More than 95% of these clones had cytonemes oriented towards one of the two borders, and 5% had cytonemes orientated towards both Moreover, cytonemes change in response to conditions of Dpp gain-of-function and loss-of-function No differences were detected between the two conditions with respect to either the total number of punctae, or to the distance from or position relative to the clones ( Supplementary Table 2 ) On the basis of the presence or absence of cytonemes and on the orientation of cytonemes, three regions of the disc can be distinguished Our ability to image cytonemes is limited to preparations in which discs have been extracted from larvae and the cytonemes are static, but their varied appearance under the conditions we have tested illustrates that they are dynamic in vivo  Our previous work has demonstrated that cytonemes bind phalloidin (a specific F-actin-binding protein) and can be labelled with an actin–GFP fusion protein, suggesting that cytonemes are actin-based  Second, to test whether Dpp is sufficient for cytoneme induction, we imaged cytonemes in discs in which Dpp was expressed ubiquitously Several recent studies reported have cellular extensions in Drosophila cells that correlate with signalling by Branchless (a Drosophila FGF, or fibroblast growth factor) , Notch and Scabrous , extensions in spider cells that correlate with signalling by Dpp , and extensions in mammalian cells that correlate with signalling by epidermal growth factor (EGF)  The contour of the apical surface of the notum primordium is rather flat (see Supplementary Fig. 1 ), and cytonemes can be imaged in this region in discs that are suspended in liquid The fragile nature of disc cells requires that physical and osmotic insults be minimized, and the methods we have developed to image wing cytonemes avoid rupture, delamination and other responses to injury (see Methods) The number of Tkv–GFP punctae at a distance from the cell bodies was dramatically reduced in treated discs (reduction estimated to be 90%; Fig. 4d , e ) The resolution of these studies could not establish whether they were inside or on cytonemes The widespread occurrence of cytonemes and cytoneme-like filopodia suggests that their role in long-distance signalling might be a general one, one that might permit selective signalling in ways that enable cells to regulate both release and uptake of signals. These correlations are consistent with the idea that Dpp moves from its source in an oriented manner imposed by the directionality of these cellular extensions These cytonemes were significantly shorter than those in untreated discs, averaging about 10.6 µm in length These observations suggest that cytonemes can function as vehicles for active, actin-based transport of receptors These punctae were motile, moving in both anterograde and retrograde directions, and some images clearly revealed their association with cytonemes ( Fig. 4b , see Supplementary Video ) These three distinct cell types—cells with A/P- or D/V-oriented cytonemes, cells with cytonemes lacking a directional bias, or cells without cytonemes—could each be imaged in a restricted and defined region of the same disc Third, we monitored the distribution of the Dpp receptor Tkv, as a Tkv–GFP fusion protein  This confirms that the slight flattening we use to image cytonemes does not generate or substantially alter these structures This preferential placement of proteins into different types of filopodial extensions indicates that apical and basal extensions are structurally distinct, it suggests that these cell extensions may be functionally distinct, and it implies the existence of a mechanism for sorting proteins to specific types of extensions Thus, directional cytonemes are present in the wing primordium (where Dpp functions as a morphogen), cytonemes are present and ‘omni-directional’ in the notum (where Dpp may function only to support cell proliferation), and cytonemes are absent in the hinge/pleural region, where Dpp function appears not to be required To better document the structure of cytonemes, we reconstructed optical sections of cytoneme-producing clones to render their three-dimensional structure To test whether cytonemes and the movement of Tkv–GFP punctae is actin-dependent, we treated discs containing clones of Tkv–GFP-expressing cells with cytochalasin D, an actin-binding drug Trafficking of these punctae was approximately 5–7 µm s -1 ( Fig. 4c ), a rate consistent with measured rates of vesicular movement on actin filaments  Typical examples of successful preparations with flattened discs are shown in Fig. 1  Under conditions of ubiquitous Dpp expression, cells in the hinge domain extended cytonemes in apparently random orientations ( Fig. 3c ) Unlike cells in the wing and notum primordia, cells in the hinge/pleural primordium did not extend cytonemes Using standard epifluorescence microscopy, cytonemes are visible only if neighbouring cells have low background fluorescence, only in unfixed discs, and only if they extend in a single optical plane We examined these hinge/pleural cells by expressing GFP in clones ( Fig. 1e ) and by using an enhancer trap expressed in the hinge region (not shown), but did not observe cell extensions in either case We have not been able to establish whether all cells extend cytonemes, whether cells can extend more than one cytoneme, or whether a single cell can extend cytonemes towards both axes We plotted the distribution of Tkv–GFP punctae around clones in discs with normal expression of Dpp or with ubiquitous Dpp expression We tested whether the shape and distribution of cytonemes in wing discs correlates with the presence of Dpp When expressed in the lateral flanks of wing discs, most of the fluorescence was localized to the plasma membrane of expressing cells
 A sum that will be merely compensation for one woman could be enticement for another, poorer one And in the real world, where questions over clinical research, informed consent and conflicts of interest have lately enjoyed a high profile, confidence in the ability of these review boards to ensure adequate oversight will not be universally shared But the question is being asked, nonetheless — indeed, it is at the forefront of a vigorous debate about whether and how much to pay women for donating their eggs for research (see page 606 ) But they wont overrule local laws and regulations, the uneven application of which looks set to slow down stem-cell research How, then, can a fair level of compensation be set for risks that are essentially unknown? One possible way forward lies in a practice called egg-sharing, in which women who are already considering or undergoing IVF are asked to contribute surplus eggs to research in return for treatment at reduced cost Hyun argues that institutional review boards and other oversight bodies can select a level of remuneration that is enough to ensure that donors are compensated for their trouble, but not enough to blind them to the risks involved If stem-cell researchers are to suggest that payments should be more extensive, they will have to make a more convincing case that adequate safeguards will be in place to protect donors rights. In a Commentary in this weeks issue, Insoo Hyun of Case Western Reserve University in Cleveland, Ohio, who chairs a task force exploring the issue at the International Society for Stem Cell Research, argues that women who donate eggs should be financially compensated for their time, discomfort and trouble (see page 629 ) In April 2005, the US National Academies issued guidelines stating that women who donate eggs for research should receive only direct expenses, such as travel to the clinic Others might contend that the same egg is priceless — because it could, if introduced to the correct sperm, form the seed of a new person Others still will find it morally problematic even to pose the question, on the grounds that it treats human cells as merchandise Proponents point out that, by working with donors who are using ovulation-stimulating drugs anyway, this avoids exposing otherwise healthy women to any risks associated with them Researchers in nations that prohibit payment for eggs, for example, may find themselves unable to work on stem cells derived from eggs secured by collaborators elsewhere from paid donors Some biologists are keen to use fresh human eggs for the production of human embryonic stem cells Some will argue that an egg has no monetary value when it is just one of those ovulated each month by billions of women and that perishes unfertilized That will be an exquisitely fine line to draw The idea does not, however, impress those who object on ethical grounds to any financial inducements to donors The International Society for Stem Cell Research is currently drafting guidelines on this issue The North East England Stem Cell Institute in Newcastle Upon Tyne, UK, will soon start offering this scheme The situation is further complicated by the health risks that may be posed by ovarian stimulation (see page 607 ) There are hints, but no definitive evidence, that the drugs used to stimulate the ovaries for both in vitro fertilization (IVF) and egg donation increase the long-term risks of cancer What price a human egg? The question provokes a variety of emotions and responses Yet they are anxious to distance themselves from the path taken by disgraced South Korean researcher Woo Suk Hwang, who lied about paying women for eggs and tainted the whole idea of oocyte donation
 Bush back in 2001 (see page 544 ) But the president has chosen to draw what he sees as a moral line in the sand that he feels he cannot cross But the veto, if it is used, will place him squarely against public opinion in the United States, which increasingly views embryonic stem-cell research not with fear, but with hope. Even if the measure passed by the House becomes law, the United States would retain more restrictions on publicly funded research than do nations such as South Korea and Britain, both of which allow publicly supported scientists to use somatic cell nuclear transfer to derive fresh embryonic stem-cell lines Even that wont erase the significance of this first victory in the Republican-controlled House for advocates of stem-cell research He has threatened to make this the first bill that he has vetoed in four-and-a-half years in office However, Bush said both before and after the House vote that he will veto the measure if it reaches his desk If it obtains these votes, the bill will arrive on President Bushs desk — and hell face a difficult choice In the Senate, Sam Brownback (Republican, Kansas) has already said that he will attempt to block a vote on the stem-cell measure, so that for the measure to pass it will need the support of 60 out of the 100 senators Indeed, the desperate language used by opponents of embryonic stem-cell research suggests they know they are losing the debate Last week, the US House of Representatives voted by 238 to 194 to reverse the policy restricting embryonic stem-cell research that was implemented by President George W Polling evidence suggests that most Americans instead have high hopes for the research, and biomedical advocacy groups have done an effective job convincing lawmakers that the research deserves a chance to fulfil these hopes So too did competitive pressure from overseas, with South Korean research making headline news just ahead of the vote, and from state governments, whose own initiatives in this sphere are forging ahead in California, New Jersey and elsewhere Some influential Republicans — including Nancy Reagan, the wife of a former president, and conservative Utah senator Orin Hatch — have spoken out in favour of embryonic stem-cell research, making it easier for others to publicly support the work as well That augers well for the eventual loosening of federal policies that have kept scientists hands tied in the United States The fact that 50 Republican members voted for the change in policy underlines the fact that the pendulum of public opinion is swinging strongly in favour of allowing more of the research to go ahead The measure will now be taken up by the Senate, where it has a good chance of success The proponents of stem-cell research have mooted the idea of some sort of compromise, which might, for example, update the 2001 policy to allow publicly funded work on more recently derived stem cells The US measure would allow federal funding only for work on embryos left over from in vitro fertilization clinics Theres no indication that the public is buying this Tom DeLay (Republican, Texas), majority leader in the House, said on Tuesday last week that a vote for the stem-cell bill was a vote “to fund with taxpayer dollars the dismemberment of living distinct human beings for the purposes of medical experimentation” Years of tireless lobbying by these groups played a major role in the 24 May victory
 And at last weeks annual genome meeting in Cold Spring Harbor, New York, scientists revealed a wealth of data indicating a surprising conclusion about human diversity — much of it might be explained by large structural differences between individual genomes, not by tiny differences in individual genes And at last weeks meeting, Evan Eichler of the University of Washington in Seattle reported that this is just the beginning: not only do we carry different copy numbers of parts of our DNA, we also have varying numbers of deletions, insertions and other major rearrangements in our genomes At the Cold Spring Harbor meeting, scientists presented more evidence that structural differences are important in human evolution At these spots, some of us might carry a major deletion, for example, or an extra hundred bases of DNA Biologists used to think that our genomes all had the same basic structure — the same number of genes, in roughly the same order, with a few minor differences here and there in the sequence of DNA bases But do such differences mean anything? Here, too, fresh evidence paints an intriguing picture But its our differences that really fascinate us Cold Spring Harbor, New York When the finished sequence of the human genome was unveiled last year, biologists said that it told a story of harmony for the human family Duc-Quang Nguyen, a postdoctoral fellow in Chris Pontings laboratory at the University of Oxford, UK, reported an analysis of areas where there are different numbers of copies of DNA stretches Every one of us, it turns out, shares 99% of our DNA with all the other people on Earth For instance, many work in the immune system, and affect how we fight off disease Genome Res. 13, 2291–2305; 2003) In fact, Eichler found at least 297 places in the genome where different individuals have different forms of these major structural variations In January, scientists at the Iceland-based company deCODE Genetics found a long inversion — a stretch of DNA that is flipped around backwards — that is common in Europeans, but not in Asians and Africans (H Lucito et al  Nature Genet. 37, 129–137; 2005) Nguyen found that natural selection is actively working on these genes Now, technologies comparing whole human genomes show that this picture is incomplete Stefánsson et al  These are exactly the sort of genes that could explain our diversity — why some of us get asthma when exposed to air pollution, or why some of us can eat plenty of cheeseburgers without gaining weight. “We knew these variations existed, but this year were asking, do they matter?” says Ewan Birney, head of bioinformatics for the European Molecular Biology Laboratory, based in Cambridge, UK. “The answer seems to be yes.”  Were still one human family, of course; but our DNA landscapes are a lot more varied than we had thought. They also found that women who have this inversion bear more children than those who dont — a classic sign that the inversion confers an evolutionary advantage Two years ago, a group of researchers led by Michael Wigler at Cold Spring Harbor Laboratory found the first evidence that some of us have more copies of certain genes than do others (R Whats more, he found that many of these genes belong to groups that seem to help us interact with our environment
 But its not like the students are thrown in the water and then are asked to thrash around But one thing I have reasonable luck in is identifying new opportunities a couple of years or a couple of months before others — and being there Contributing Author Shri Kulkarni, professor of astronomy at the California Institute of Technology, has an abundant publication record thanks, in part, to his attitude towards graduate students and postdocs Every three to five years I feel its time to move on Hard work is part of it but, more importantly, Kulkarni gives graduate students a greater role in the process than many senior scientists give their protégés Having a whole bunch of tool kits gives you more opportunities How has this approach contributed to your publication record and overall output? The top-ranking students, they talk among themselves How have you been able to pick up new sub-disciplines and tools? I have a lot of bright young people in my group and they really keep me alive this way I get lots of ambitious, self-driven students. I have so many weaknesses If they hear they can be first author of a big paper in a high-profile journal, they will consider joining my lab In the paper on page 845 , his group uses four different methods to observe short, intense γ-ray bursts that result from the merger of neutron stars or black holes Its just me Its not a value judgment or anything Kulkarni is also a proponent of learning different observational techniques Since 1982, he has chalked up some 200 articles and reviews What role do graduate students and postdocs play in your research and publication? I tell them: “Youre the one who will trigger the great telescope What sort of scientific advantages does switching techniques and research goals provide? Part of my strategy is to get ahead in new fields Why did you learn them all? I have an attention deficit syndrome Why not just pursue obvious targets? I dont do ‘me too’ stuff Why so many observational techniques for this paper? A lot of people stick to one kind of instrument or another You really have to know something special in an existing field Youre the one who will write the submission letter, deal with referees...” I have almost all graduate students in their second year submit a paper
 Finally, withholding details of methodologies (misbehaviour no. 13) presents no ethical dilemma to scientists working in industry If these ideas are not patent-protected, so much the better! Many companies employ scientists specifically to look for such opportunities In my experience, some of the behaviours listed as “unacceptable” will seem quite normal to scientists working in industry It could be argued that publishing identical information at geographically dispersed conferences or journals is an aid to scientific communication It is up to conference organizers and journal referees to police this behaviour if they do not like it Martinson and colleagues ( Nature 435 , 737 – 738 ; 2005 ), with interest Similarly, publishing the same data in multiple places (misbehaviour no. 11) is not considered ethically dubious if there is no link between the number of publications and promotion prospects, which is generally the case in industry Sir As a physicist working in industry, I read the Commentary article “Scientists behaving badly”, by Brian C Specifically, using someone elses ideas (misbehaviour no. 5) is regular commercial practice The results are largely from scientists in academia Virtually all successful businesses are on the lookout for new ideas that can be applied within their own company for the purpose of gaining competitive advantage When proprietary tests are developed to give competitive advantage, the results from such tests may be published, but the company should not be expected to divulge the underlying details.
 A further upshot of Palter and colleagues investigations is the recognition of a source of long-term variations, occurring on timescales of decades, driven by the slow cycle of mode waters A likely explanation for the nutrient depletion in Subtropical Mode Water is that phytoplankton growth consumes nutrients on a large scale in winter, at the same time as the mode water is starting to subduct and embark on its subsurface journey A second aspect is the large-scale distribution of phytoplankton productivity, in this case in the North Atlantic, as measured by levels of surface chlorophyll ( Fig. 1 ) Along with other work, Palter and colleagues observations add a new dimension to our growing appreciation of the various controls on marine productivity But how can winter phytoplankton growth be sustained before the onset of conditions that produce the especially vigorous burst of growth in spring? The answer may lie in a specific biological regime that pertains over the area of mode-water formation, in which light and nutrient limitations on growth are balanced in such a way that winter growth is greater than it is farther north and farther south But Palter et al . argue that deep convective mixing in the area of Subtropical Mode Water formation in the 1960s severely diminished primary production in downstream regions because of the ensuing subsurface delivery of nutrient-poor waters But there are also differing east–west gradients of chlorophyll in the two gyres, which the patterns of Ekman transport or convection cannot explain Complementary work by Williams et al . fills in the picture in the subpolar gyre Extended periods of cold winters (as occurred in the 1960s compared with the 1990s) promote deep convective mixing and vigorous mode-water formation: in a one-dimensional view , increased convection in the subtropical gyre should lead to stronger phytoplankton growth through the increase in nutrient supply In the open ocean, so-called ‘mode waters’ are water masses of uniform density that form at the surface in winter, subduct and then may travel long distances beneath the surface In this case, it is the induction flux of nutrients that sustains the high productivity ( Fig. 1 ) — induction is a subsurface-to-surface process and directly provides the sunlit layer with nutrients; subduction, by contrast, is a surface-to-subsurface process that affects the nutrient reservoir One aspect of the background to these investigations is that, at mid-latitudes in the open ocean, convection caused by seasonal changes in temperature and wind conditions makes the nutrients required for phytoplankton growth available in the sunlit surface waters One is wind-driven (Ekman) pumping, which induces upwelling of water in the subpolar gyre and downwelling in the subtropical gyre One question that exercises oceanographers is the nature of the mechanisms that refill the nutrient reservoir in subsurface waters Palter et al . ( page 687 of this issue) show that in one circulation system in the North Atlantic, known as the North Atlantic subtropical gyre, this lateral process adversely affects nutrient availability along the mode-water route — and so, by providing only limited amounts of nitrate and phosphate, exerts a remote control on phytoplankton productivity Palter et al . argue convincingly that the chlorophyll minimum in the western part of the subtropical gyre is the signature of this underlying, nutrient-depleted reservoir when it mixes with the surface waters ( Fig. 1 ) Palter et al . show that the reservoir south of the Gulf Stream is fuelled laterally with Subtropical Mode Water, which forms to the north of the gyre and then circulates southwards beneath the surface Such a ‘mid-latitude regime’ is evident in the northeast Atlantic , in a narrow band between 37° N and 43° N The authors suggest that a drop in the formation rate of Subtropical Mode Water was responsible for the large increase in phytoplankton production in the 1990s, compared with the 1960s, that was observed close to Bermuda (33° 22′ N, 64° 41′ W) downstream of mode-water formation The North Atlantic can be broadly divided into two huge circulation systems The other is winter convection, which mixes nutrient-depleted surface waters with nutrient-rich subsurface waters, and which increases towards higher latitudes The past 20 years have seen a great deal of research into how nutrients are delivered to the ocean surface The remineralization process, which replenishes nutrients and occurs at depth, is inadequate to redress this initial nutrient loss on the timescales involved The traditional view is that this large-scale contrast is determined by two factors  The variability of the subsurface nutrient reservoir has received much less attention: achieving a better understanding of that variability is one of the next challenges in marine biogeochemistry. There is minimum productivity in the western part of the subtropical gyre (purple region in Fig. 1 ), and a tongue of maximum productivity in the western subpolar gyre (green region in Fig. 1 ) These subsurface water masses are particularly poor in nutrients, as measured in vertical profiles by the World Ocean Circulation Experiment They identify an opposite effect north of the Gulf Stream, in which mode waters are the primary cause of high phytoplankton productivity in the west of the subpolar gyre This induction flux covers a larger area on the western side than on the eastern side of the ocean basin, and so may also explain the east–west gradient in the subpolar gyre This is a counterintuitive proposal This is not the end of the story This is where nutrient levels in the subsurface reservoir come into the picture This mode water is rich in nutrients, because it is formed in a ‘high-nutrient, low-chlorophyll’ region where low productivity is the norm To the north of the Gulf Stream, the subpolar gyre is productive, with high concentrations of chlorophyll To the south, the subtropical gyre is a vast biological desert Using model diagnostics, Williams et al . go further, providing evidence that the induction flux is mainly composed of Sub-Antarctic Mode Water , which originates from the Southern Ocean and travels northwards along the western boundary of the Atlantic
 Furthermore, we were able to successfully classify poorly differentiated tumours using miRNA expression profiles, whereas messenger RNA profiles were highly inaccurate when applied to the same samples Here we use a new, bead-based flow cytometric miRNA expression profiling method to present a systematic expression analysis of 217 mammalian miRNAs from 334 samples, including multiple human cancers Recent work has revealed the existence of a class of small non-coding RNA species, known as microRNAs (miRNAs), which have critical functions across various biological processes  The miRNA profiles are surprisingly informative, reflecting the developmental lineage and differentiation state of the tumours These findings highlight the potential of miRNA profiling in cancer diagnosis. We observe a general downregulation of miRNAs in tumours compared with normal tissues After reverse-transcription using adaptor-specific primers, products were PCR-amplified (95 °C for 40 s; 50 °C for 30 s; 72 °C for 30 s; 18 cycles for 10 µg starting total RNA) using a 3′-primer 5′-TACTGGAATTCGCGGTTA-3′ and 5′ primer 5′-biotin-CAACGGAATTCCTCACTAAA-3′ ( IDT ) Bead-based detection miRNA capture probes were 5′-amino-modified oligonucleotides with a 6-carbon linker ( IDT ) Beads were spun down, resuspended in 1 × TMAC containing 10 µg ml -1 streptavidin-phycoerythrin ( Molecular Probes ) and incubated at 50 °C for 10 min before data acquisition on a Luminex 100IS machine Before clustering, data were filtered to eliminate genes with expression lower than 7.25 (on a log 2 scale) in all samples Briefly, two synthetic pre-labelling-control RNA oligonucleotides (5′-pCAGUCAGUCAGUCAGUCAGUCAG-3′, and 5′-pGACCUCCAUGUAAACGUACAA-3′, Dharmacon ) were used to control for target preparation efficiency Capture probes for miRNAs and controls were divided into three sets (see Supplementary Table 1 ) Cells were harvested after 1, 3 and 5 days Computational analyses Profiling data were first scaled according to the post-labelling-controls and then the pre-labelling-controls, in order to normalize readings from different probe/bead sets for the same sample, and to normalize for the labelling efficiency, respectively, as detailed in Supplementary Methods  Culturing conditions for other cells are detailed in the Supplementary Information . miRNA labelling Target preparation from total RNA followed the described procedure , with modifications Data were thresholded at 32 and log 2 -transformed Distances were based on the cosine in the selected feature space Expression data miRNA expression data have been submitted to the Gene Expression Omnibus (GEO; http://www.ncbi.nlm.nih.gov/geo ) with the series accession number GSE2564. mRNA expression data were published previously , and are available together with miRNA expression data at http://www.broad.mit.edu/cancer/pub/migcm . Feature number and the gaussian width were optimized on the basis of leave-one-out cross-validations on the training data set Features were selected for the distinction between all normal samples versus all tumours (for colon, kidney, prostate, uterus, lung and breast; P 0.05 after Bonferroni correction) Features were selected on the basis of the variance-thresholded t -test score, requiring equal numbers of up- and downregulated features For each probe set, 3 µl of every probe–bead conjugate was mixed into 1 ml of 1.5 × TMAC (4.5 M tetramethylammonium chloride, 0.15% sarkosyl, 75 mM Tris-HCl pH 8.0, 6 mM EDTA) For each test sample, the tissue type that had the highest probability in multiple one-tissue-versus-the-rest predictions was assigned For side-by-side comparison of bead detection and the glass microarray, a 5′-Alexa-532-modified primer was used for compatibility with the glass microarray Hierarchical clustering was performed with average linkage and Pearson correlation HL-60 cells were plated at 1.5 × 10 5  cells ml -1 and induced to differentiate using 1 µM all-trans retinoic acid ( Sigma ; in ethanol) Hybridization was carried out overnight at 50 °C with 33 µl of the bead mixture and 15 µl of labelled material Individual lung tumours and normal lungs were dissected and immediately frozen on dry ice before RNA preparation Jude Childrens Research Hospital and at the Dana-Farber Cancer Institute, and their immunophenotype and genotype were determined as previously described  Leukaemia bone marrow mononuclear cells were collected from patients treated at St Lungs from four- to five-month-old mice were inflated with phosphate-buffered saline before removal Median fluorescence intensity values were measured Methods Samples Information regarding samples is available in Supplementary Table 2  Multi-class predictions of poorly differentiated tumours were performed using the probabilistic neural network algorithm, a gaussian-weighted nearest neighbour method Next, all features were centred and normalized to a mean of 0 and a standard deviation of 1. k -nearest-neighbour classification of normal versus tumour samples was performed with k = 3 in the selected feature space using euclidean distance measure Normal mouse lung and mouse lung cancer samples were collected from K-Ras LA1 mice and genotyped as described  Note that different metrics were used for clustering and normal/tumour classification P values were calculated using a variance-thresholded t -test with a minimal standard deviation of 0.75, while treating the tissue type as a confounding variable PCR products were precipitated and dissolved in 66 µl TE buffer (10 mM TrisHCl pH 8.0, 1 mM EDTA) containing two biotinylated post-labelling-control oligonucleotides (100 fmoles of FVR506, 25 fmoles PTG20210; see Supplementary Table 1 ) Probes were conjugated to carboxylated xMAP beads ( Luminex Corporation ) in 96-well plates, following the manufacturers protocol Samples were hybridized in a 96-well plate, with two mock PCR samples (using water as template) in each plate as a background control Small RNAs (18–26 nucleotides) were recovered from 1–10 µg total RNA through denaturing polyacrylamide gel purification Small RNAs were adaptor-ligated sequentially on the 3′-end and 5′-end using T4 RNA ligase ( Amersham Biosciences ) They were each spiked at 3 fmoles per µg total RNA To profile a sample with all probes, three assays were performed on the sample, each using one of the three probe sets Total RNAs were prepared from tissues or cell lines using TRIzol ( Invitrogen ), as described , and in compliance with IRB protocols A training set of 68 more-differentiated tumours, representing 11 tumour types and for which both mRNA and miRNA profiles were available, was used to generate a classifier Accordingly, a tumour/normal classifier constructed with human samples had 100% accuracy when tested in the mouse Although miRNA expression has been explored in small sets of tissues or isolated cell types (for example, chronic lymphocytic leukaemia ), the extent of differential miRNA expression across cancers has not been determined Among the epithelial samples, those of the gastrointestinal tract were of particular interest An implication of this hypothesis is that downregulation of some miRNAs might play a causal role in the generation or maintenance of tumours As a group, poorly differentiated tumours had lower global levels of miRNA expression compared with the more-differentiated training set samples (see Supplementary Fig. 5 ), consistent with the notion that miRNA expression is closely linked to differentiation As predicted, miRNA profiling revealed the induction of many miRNAs coincident with differentiation ( Fig. 3c ) As shown in Fig. 2b , hierarchical clustering revealed non-random partitioning of the samples into three major branches: one containing all five t(9;22) BCR / ABL -positive samples and 10 out of 11 t(12;21) TEL / AML1 samples; a second branch containing 15 out of 19 T-cell ALL samples; and a third branch containing all but one of the samples with an MLL gene rearrangement As shown in Fig. 3b , the same distinction between normal and tumour samples is observed in mouse Bead-based hybridization has the theoretical advantage that it might more closely approximate hybridization in solution, and as such, we might expect the specificity to be superior to glass microarray hybridization Because abnormal cell proliferation is a hallmark of human cancers, it seems possible that miRNA expression patterns might denote the malignant state Cancer cell lines also showed low miRNA expression relative to normal tissues (see Supplementary Fig. 4 ) Despite the overall low level of miRNA expression, the miRNA-based classifier established the correct diagnosis of the poorly differentiated samples with far greater accuracy than would be expected by chance for an 11-class classifier (12 out of 17 correct; P 5 × 10 -11 ) Epithelial cells affected in C. elegans lin-4 and let-7 miRNA mutants generate a stem-cell-like lineage, dividing to produce daughters that, like themselves, divide rather than differentiate  Following adaptor ligations which use both the 5′-phosphate and the 3′-hydroxyl groups of miRNAs , reverse-transcribed miRNAs were (1) amplified by polymerase chain reaction (PCR) using a common biotinylated primer, (2) hybridized to the capture beads, and (3) stained with streptavidin-phycoerythrin For example, samples of epithelial origin were located on a single branch of the dendrogram, whereas the other major branch was predominantly populated with samples of haematopoietic malignancies For example, we examined the miRNA profiles of 73 bone marrow samples obtained from patients with acute lymphoblastic leukaemia (ALL) Furthermore, the miRNAs partitioned tumours within a single lineage Glass-slide microarrays have been used for miRNA profiling , but cross-hybridization of related miRNAs has been problematic Having determined that miRNA expression distinguishes tumours of different developmental origin, we next asked whether miRNAs could be used to distinguish tumours from normal tissues However, the potential for miRNA expression to inform cancer diagnosis has not been systematically explored However, we observed differential expression of nearly all miRNAs across cancer types ( Fig. 2a ) In addition, the bead method showed linear detection over a hundred-fold range of expression (see Supplementary Information ) In addition, unlike mRNAs, miRNAs remain largely intact in routinely collected, formalin-fixed, paraffin-embedded clinical tissues  In all cases, bead-based detection paralleled the data from northern blotting ( Fig. 1c ) In contrast, the mRNA-based classifier was highly inaccurate (1 out of 17 correct; P = 0.47), as we previously reported  In contrast, when the same samples were profiled in the space of ∼16,000 mRNAs, the coherence of gut-derived samples was not observed in hierarchical clustering ( Fig. 2c ) In particular, it has become clear that among the ∼22,000 protein-coding transcripts are mRNAs that can be used to classify a wide variety of human cancers  In primary human haematopoietic progenitor cells undergoing erythroid differentiation in vitro , we observed a similar increase in miRNA expression at a stage in differentiation when the cells continued to proliferate (see Supplementary Information ) Indeed, a spiking experiment involving 11 related sequences showed increased specificity of bead-based detection compared with microarray-based detection, even for single base-pair mismatches ( Fig. 1a , b ) Indeed, altered expression of a few miRNAs has been found in some tumour types  Indeed, we might not expect that miRNA expression patterns could be informative with respect to cancer diagnosis, because of the relatively small number of miRNAs encoded in the genome It is estimated that 2–4% of all cancer diagnoses represent cancers of unknown origin or diagnostic uncertainty (see ref. 23 ) It was therefore striking to observe that despite the fact that some miRNA expression levels were upregulated or unchanged, most of the miRNAs (129 out of 217, P 0.05 after correction for multiple hypothesis testing) had lower expression levels in tumours compared with normal tissues, irrespective of cell type ( Fig. 3a ) More work is required to establish the clinical utility of miRNA expression in cancer diagnosis, but the work described here indicates that miRNA profiling has unexpected diagnostic potential Moreover, hierarchical clustering of the samples using miRNA profiles paralleled the developmental origins of the tissues Moreover, the bead-based miRNA detection method has the attractive property of being not only accurate and specific, but also easy to implement in a routine clinical setting Much progress has been made over the last decade in developing a molecular taxonomy of cancer (see ref. 3 ) Oligonucleotide-capture probes complementary to miRNAs of interest were coupled to carboxylated 5-micron polystyrene beads impregnated with variable mixtures of two fluorescent dyes (that can yield up to 100 colours), each representing a single miRNA Our observation that miRNA expression seems globally higher in normal tissues compared with tumours led us to the hypothesis that global miRNA expression reflects the state of cellular differentiation Our unexpected findings are the extraordinary level of diversity in miRNA expression across cancers, and the large amount of diagnostic information encoded in a relatively small number of miRNAs Owing to miRNA sequence conservation between human and mouse, the same miRNA capture beads could be used to profile the murine samples Recently, hundreds of small, non-coding miRNAs have been discovered (see ref. 1 ) Samples from colon, liver, pancreas and stomach all clustered together ( Fig. 2a ), reflecting their common derivation from tissues of embryonic endoderm Taken together, these studies indicate that miRNAs are unexpectedly rich in information content with respect to cancer The bead-based detection platform also provides flexibility, in that additional miRNA capture beads can be added to the mixture, allowing detection of newly discovered miRNAs The beads were then analysed using a flow cytometer capable of measuring bead colour (denoting miRNA identity) and phycoerythrin intensity (denoting miRNA abundance) (see Supplementary Fig. 1 ) The experiments reported here demonstrate the feasibility and utility of monitoring the expression of miRNAs in human cancer The expression patterns of eight miRNAs in seven different cell lines were validated by northern blotting The findings reported here are consistent with the hypothesis that in mammals, as in C. elegans , miRNAs can function to prevent cell division and drive terminal differentiation The first identified miRNAs, the products of the C. elegans genes lin-4 and let-7 , have important roles in controlling developmental timing and probably act by regulating mRNA translation  The implication is that, unlike with mRNA expression, a modest number of miRNAs (∼200 in total) might be sufficient to classify human cancers The mechanism by which miRNAs are under-expressed in cancer remains unknown These experiments demonstrate that even within a single developmental lineage, distinct patterns of miRNA expression can be observed that reflect mechanisms of transformation, and further support the idea that miRNA expression patterns encode the developmental history of human cancers These experiments support the hypothesis that global changes in miRNA expression are associated with differentiation, the abrogation of which is a hallmark of all human cancers These findings are also consistent with the recent observation that mouse embryonic stem cells lacking Dicer, an enzyme required for miRNA maturation, fail to differentiate normally  These results demonstrate that bead-based miRNA detection is feasible, and has the attractive properties of improved accuracy, high speed and low cost This classifier was then used without modification to classify the 17 poorly differentiated test samples This goal is challenging, because of the short size of miRNAs (about 21 nucleotides) and the sequence similarity between miRNA family members This observation might result from the large amount of noise and unrelated signals that are embedded in the high-dimensional mRNA data To address this, we analysed 17 poorly differentiated tumours, the histological appearance of which was non-diagnostic, but for which clinical diagnosis was established by anatomical context, either directly (for example, a primary tumour arising in the colon) or indirectly (a metastasis of a previously identified primary tumour) To determine the expression pattern of all known miRNAs, we first needed to develop an accurate and inexpensive profiling method To exclude any possibility that this differential miRNA expression might be related to differences in the collection of tumour samples versus normal samples, we studied a mouse model of K-Ras -induced lung cancer  To test this hypothesis, we explored an experimental model in which we treated the myeloid leukaemia cell line HL-60 with all-trans retinoic acid, a potent inducer of neutrophilic differentiation  We did not observe substantial decreases in the mRNAs encoding components of the miRNA processing machinery (Dicer, Drosha, Argonaute2 or DGCR8 (ref. 24 ); see Supplementary Information ), but clearly other mechanisms of miRNA regulation are possible We have previously reported that there are no robust mRNA markers that show consistent differential expression between tumours and normal tissues of different lineages  We isolated miRNAs from normal lung or lung adenocarcinomas from different individual mice, thereby precluding any differences in collection procedure We next turned to a more challenging diagnostic distinction: that of tumours of histologically uncertain cellular origin We speculate that abnormalities in miRNA expression might similarly contribute to the generation or maintenance of ‘cancer stem cells’, recently proposed to be responsible for cancerous growth in both leukaemias and solid tumours . We suggest that sample clustering in miRNA space is predominantly driven by developmental history We then set out to determine the expression pattern of all known miRNAs across a large panel of samples representing diverse human tissues and tumour types We therefore developed a bead-based profiling method When lin-4 or let-7 is inactivated, specific epithelial cells undergo additional cell divisions instead of their normal differentiation Whether or not the miRNAs that are highly expressed in the gut-associated cluster (miR-192, miR-194 and miR-215) have a functional role in the specification of gut development or gut-derived tumours remains to be investigated
 A woman uses only one of her two X chromosomes in each cell, so if one of her X chromosomes has a defective gene, only some of her cells will suffer According to one analysis, there are 221 known human genetic defects that can cause mental impairment, some 10% of which reside on the X chromosome, even though it carries less than 4% of known human genes  According to their theory, the genes for super-intelligence and for the preference of intelligent males were closely linked, and so were inherited together All in the mind Many different types of mental retardation have since been linked to defects in genes on the X chromosome — far more than can be explained by their chance distribution throughout the genome And because successful males have the potential to sire very large numbers of children with multiple partners, mutations on the X chromosome that are advantageous to both sexes can spread rapidly through a population And because superior intelligence also aided survival, the process wasnt kept in check by natural selection — unlike other sexually selected characteristics such as the peacocks tail, which makes its bearers more vulnerable to predators And some are even suggesting that the X chromosome will tell us why we are different from our closest relatives — why we can write poetry and design nuclear weapons, but chimpanzees cant And the complete sequence of the X chromosome, published in Nature this week (see also News and Views, page 279 ), confirms that an unusually large number of its genes code for proteins important to brain function Another gene, known as MECP2 , leads to a whole range of mental disorders when mutated; its protein seems to be involved in the silencing of other genes required for normal learning, memory and the growth of brain cells  As geneticists search for the roots of humanitys unique mental abilities, they are beginning to pay close attention to the ‘feminine’ X chromosome As mammals began to diverge from their reptilian ancestors, some 300 million years ago, the proto-X and proto-Y chromosomes took on the role of determining an individuals sex Because a male carries only one copy, any new mutations are revealed in all their glory Both initially started accumulating genes from elsewhere in the genome, but over time the two chromosomes began to grow apart; the Y started to shrink and lost many of its genes But men have only one X, so any defective brain genes from that chromosome are invariably expressed But there is some indirect evidence that genes on the X chromosomes are involved in higher cognitive functions But why should the X chromosome have emerged as a hotspot for genes influencing our cognitive abilities? Evolutionary geneticists believe that the two mammalian sex chromosomes, X and Y, were once identical Detailed studies have also shown that the specific genes linked to mental disabilities play crucial roles in normal brain function  Each female twin inherits two X chromosomes, one from her mother and one from her father, but each individual twin randomly inactivates one of her two X chromosomes Early in human evolution, they suggest, females developed a preference for intelligent males Every two years, for instance, scientists meet as part of a European consortium that catalogues genes involved in such conditions For instance, a gene called JARID1C seems to be evolving from a similar gene called JARID1D , which is found on the Y chromosome For instance, more than a decade ago, an international team reported the discovery of the gene that causes fragile X syndrome , a disorder that leads to a range of problems including mental disability If men inherit a damaged version of the JARID1C gene on their single X chromosome, they develop mental disabilities If we want to understand the cognitive ‘X factor’ that separates us from the rest of the animal kingdom, then it seems that the X chromosome is the place to start looking In a sense, they argue, the feminine chromosome could hold the secrets of humanity. “We used to think that the X was boring,” says Jenny Graves, an evolutionary geneticist at the Australian National University in Canberra. “Now were seeing just how wrong we were.”  Todays understanding of the X chromosome helps to explain a puzzling observation from the late nineteenth century, when doctors combing through data from the 1890 US Census noticed that more boys than girls were mentally disabled  In contrast, biology presents a challenge to those who still believe women are better off at home than in the hallowed halls of universities In contrast, male identical twins inherit only one X chromosome, from their mothers, and so must activate the same X-linked genes In London, Craigs team plans to identify twins who score high or low on certain ‘people skills’, such as sharing their toys and volunteering help to others In our own species, where intelligence and social skills are thought to be central to success, genes on the X chromosome seem to have evolved rapidly to provide us with the necessary brain power. “If higher cognitive abilities were a critical step in our own evolution, it makes sense that you might find those functions on the X chromosome,” says Hunt Willard, a human geneticist and director of the Institute for Genome Sciences and Policy at Duke University in Durham, North Carolina In some instances, geneticists have pinpointed genes on the X chromosome that still seem to be in the process of adopting new roles in the brain In the British study, researchers led by Ian Craig of Kings College London found that in some traits linked to intelligence, such as verbal skills and good social behaviour, male twins were more alike than female twins  In the meantime, Summers and his acolytes can chew on this thought: even if theres any truth in the idea that men are more suited to a career in science than women, they just might owe this mental predisposition to the ‘girly’ chromosome. Its still a giant step from understanding defects in single genes to proving that the X chromosome allows us to write novels and solve calculus equations Many of the genes on the X chromosome associated with human brain function seem to have distant relatives with different functions in other vertebrates, such as chickens and fish  Once they find a region of DNA that seems to link to a particular trait, the group will look at the detailed sequence of individual chromosomes to try to pin down the exact gene involved One hint comes from a study of 4,000 sets of British identical twins Other researchers plan to continue the quest for genes involved in X-linked brain disorders Personality profiles Geneticists are now gearing up to go after other X-linked genes that may help explain what makes us human Provocatively, researchers led by Horst Hameister at the University of Ulm in Germany speculate that this process was driven by sexual selection  Researchers believe that the information so far gleaned about human brain function from these studies barely scratches the surface Scientists now know that the defective gene, called FMR1 , normally makes a protein that is involved in shuttling the genetic messages that enable nerve cells to send signals through the brain  So identical twin sisters can express different X-chromosome genes So in boosting our cognitive abilities, the X chromosome seems to have co-opted a diverse range of existing genes, rather than evolving a new set of genetic sequences for the purpose. “These old genes are getting new use,” says Hameister Solid foundation Eventually, the sex chromosomes diverged to the point where they were no longer able to exchange genetic material during the cell divisions that give rise to sperm and eggs, as do the members of every other pair of chromosomes The fact that the healthy Y chromosome version cannot compensate for its defective cousin hints that JARID1C is becoming more crucial to the brain as it evolves  The researchers will then use gene chips to scan the twins DNA, looking for particular genetic variations that correlate with these traits The resulting pandemonium has revealed few genuine insights into male and female mental abilities — although it has shown that old prejudices linger on campus, and beyond The X chromosome data, with its wealth of information about human brain genes, is likely to feature prominently in this endeavour The X chromosome gets a chance to shine, or to fail miserably, each time it passes through the male line This has left the X chromosome as one of the most stable in the mammalian genome — which paradoxically may have exposed its genes to more intense pressure to evolve This January, Harvard University president Larry Summers incited a near riot by suggesting that men might be better than women at science We now know that this reflects a preponderance of genes for brain function on the X chromosome Why this should be the case is sparking debate among evolutionary biologists Women have two copies of this chromosome, whereas men have only one
 Both CPSF-73 and CPSF-100 contain two domains, a metallo-β-lactamase domain and a novel β-CASP (named for metallo-β-lactamase, CPSF, Artemis, Snm1, Pso2) domain  Despite the characterization of many proteins that are required for the cleavage reaction, the identity of the endonuclease is not known  Here we report the crystal structures of human CPSF-73 at 2.1 Å resolution, complexed with zinc ions and a sulphate that might mimic the phosphate group of the substrate, and the related yeast protein CPSF-100 (Ydh1) at 2.5 Å resolution Most eukaryotic messenger RNA precursors (pre-mRNAs) undergo extensive maturational processing, including cleavage and polyadenylation at the 3′-end  Our studies provide the first direct experimental evidence that CPSF-73 is the pre-mRNA 3′-end-processing endonuclease. Purified recombinant CPSF-73 possesses RNA endonuclease activity, and mutations that disrupt zinc binding in the active site abolish this activity Recent analyses indicated that the 73-kDa subunit of cleavage and polyadenylation specificity factor (CPSF-73) might be the endonuclease for this and related reactions , although no direct data confirmed this The active site of CPSF-73, with two zinc ions, is located at the interface of the two domains A solution that had been infected by a fungus was crucial for the crystallization of this protein  Cleavage assays were carried out in reaction mixture (10 μl) containing ∼1 ng labelled RNA substrates, 10 mM HEPES (pH 7.9), 10% (v/v) glycerol, 50 mM KCl, 0.25 mM DTT, 0.25 mM PMSF, 0.125 mM EDTA, 50 μM CaCl 2 , RNase inhibitor (2 units), 500 ng BSA and indicated amounts of recombinant CPSF-73 Cleaved RNAs were isolated and fractionated on 6% urea PAGE Crystals of human CPSF-73 were obtained at room temperature by the sitting-drop vapour diffusion method Crystals of yeast CPSF-100 were obtained at 4 °C by the same protocol Data collection, structure determination and refinement X-ray diffraction data were collected on an ADSC CCD at the X4A beamline of Brookhaven National Laboratory Figs 1 –  3 were produced with Ribbons  In an attempt to increase the occupancy of zinc ions, some crystals were grown from a reservoir solution that also contained 0.5 mM ZnCl 2  Methods Protein expression, purification and crystallization Residues 1–460 of human CPSF-73 were sub-cloned into the pET28a vector ( Novagen ) and overexpressed in Escherichia coli at 20 °C Pre-mRNA 3′-end cleavage assay CPSF-73 was pre-incubated with 5 mM CaCl 2 at 37 °C for 30 min The crystallographic information are summarized in Supplemental Table 2  The crystals were frozen in liquid propane for data collection at 100 K The data were analysed by Phospho-Imager. The diffraction data were collected at the zinc absorption peak for crystals of CPSF-73, and at the gold absorption peak for a KAu(CN) 2 derivative of CPSF-100 The soluble protein was purified by nickel–agarose affinity chromatography and gel-filtration chromatography The structure of CPSF-100 was determined by the single-isomorphous replacement method, supplemented with anomalous diffraction The structure of CPSF-73 was determined by the single-wavelength anomalous diffraction method , using the anomalous signal of zinc Yeast CPSF-100 (Ydh1, residues 1–720) was expressed and purified by nickel–agarose affinity chromatography, anion exchange and gel-filtration chromatography A close structural homologue of this domain is the L1 metallo-β-lactamase from Stenotrophomonas maltophilia (see Supplementary Fig. 2c ) , with a root mean squared (r.m.s.) distance of 3.3 Å for 167 equivalent Cα atoms, calculated using the program Dali  A similar-sized RNA from adenovirus was also entirely degraded by wild-type but not mutant CPSF-73 ( Fig. 4a ) After hydrolysis, the His 396 side chain can function as the general acid to protonate the oxyanion in the reaction product Although an earlier sequence analysis indicated that motif B might be the best candidate for the zinc ligand in CPSF-73 (ref. 12 ), our structure shows that the ligand is the His residue from motif C Although most metallo-β-lactamases ( Supplementary Fig. 2c ), and RNase Z ( Supplementary Fig. 2d ), have an open zinc-binding site, the active site in CPSF-73 is located deep in the interface between the metallo-β-lactamase and the β-CASP domains ( Fig. 1a ) Although our data are consistent with purified CPSF-73 possessing non-specific endonuclease activity, they do not conclusively rule out that it might have exonuclease activity, as previously suggested  Although the presence of a 5′ cap on the RNAs analysed above largely excludes 5′→3′ exonuclease activity, we nonetheless compared the ability of CPSF-73 to degrade 5′ and 3′ end-labelled RNA ( Fig. 4b ) Among the possibilities tested to increase nuclease activity was preincubation with divalent cations Another important difference between CPSF-73 and other metallo-β-lactamases is the presence of the β-CASP domain Another subunit of CPSF, CPSF-100, shares sequence conservation (see Supplementary Fig. 1b ) and a similar domain architecture (see Supplementary Fig. 1a ) with CPSF-73 but lacks the putative zinc-binding residues As it is related to the β-CASP motif identified earlier on the basis of sequence analyses , we have named it the β-CASP domain (see Supplementary Fig. 1a ) At lower CPSF-73 enzyme levels, partially degraded, higher-molecular-weight intermediates were seen (see Supplementary Fig. 10b ) Canonical metallo-β-lactamases contain five signature sequence motifs—Asp (motif 1), His-X-His-X-Asp-His (motif 2), His (motif 3), Asp (motif 4) and His (motif 5), most of which are ligands to the two zinc ions in their active site Clear electron density for two zinc ions (confirmed on the basis of anomalous scattering data) was observed in the CPSF-73 active site (see Supplementary Fig. 6a ), regardless of whether zinc was present in the crystallization solution CPSF-73 belongs to the metallo-β-lactamase superfamily of zinc-dependent hydrolases  Despite the overall similarity to canonical metallo-β-lactamases, the structure of this domain of CPSF-73 contains several distinctive features Even in the absence of added zinc, the zinc ions in the structure seem to have full occupancy as their temperature factor values are comparable to those of their protein ligands Finally, the two zinc ions are coordinated by oxygen atoms from a sulphate ion ( Fig. 3a ), which was present at 300 mM in the crystallization solution and has clear electron density ( Supplementary Fig. 6a ) Furthermore, there is no evidence that Ca 2+ is required in authentic 3′ processing, indicating that its activating function is probably performed by other components of the polyadenylation machinery His 71, His 73 (motif 2) and His 158 (motif 3) provide three more ligands to the first zinc atom (Zn1), and Asp 75, His 76 (motif 2) and His 418 (motif C, see below) are the ligands to Zn2 ( Fig. 3a ) However, the sequence identity for these structurally equivalent residues is only 17% However, the β-CASP domain lacks the Walker A motif for binding nucleotide phosphate groups (see Supplementary Information and Supplementary Fig. 3 ) In addition, a small β-hairpin structure is on the surface of the domain In addition, our data indicate that the close sequence homologue of CPSF-73, RC-68 or Int11, is probably the endonuclease in the 3′-end processing of small nuclear RNAs . In addition, the β-CASP domain of CPSF-100 ( Fig. 2b ) is much larger than that of CPSF-73, but contains a highly flexible segment (see Supplementary Information and Supplementary Fig. 5 ) In canonical metallo-β-lactamases, the hydroxide that bridges the two zinc ions is the nucleophile for the hydrolysis reaction, and the substrate is directly liganded to the zinc atoms  In fact, the β-CASP domain severely restricts access to the active site ( Supplementary Fig. 8 ), and the scissile phosphate group probably cannot reach the zinc ions in the current structure In our structure, the hydroxide is directly below the sulphate group ( Fig. 3a ), which is probably a good mimic for the phosphate group of the pre-mRNA substrate at the cleavage site In yeast, mutation of either of these residues is lethal  Indeed, there is evidence that Artemis has exonuclease activity  It was diluted to 50 μM in the reactions and nuclease activity was not sensitive to the addition of 5 mM EGTA (results not shown) Most importantly, motifs for zinc binding in the metallo-β-lactamase domain are missing in CPSF-100 (see Supplementary Fig. 2b ), and therefore this protein cannot bind zinc and is unlikely to possess nuclease activity Most remarkably, residues 395–460, at the carboxy-terminal end of the expression construct (see Supplementary Fig. 1a ), are also part of the metallo-β-lactamase domain ( Fig. 1a ) Motif B was proposed to be equivalent to motif 5 in the canonical metallo-β-lactamases Our analysis indicates that His 396 (motif B, in the linker between the β-CASP domain and the metallo-β-lactamase domain; see Supplementary Fig. 2a ) is the general acid for catalysis Our structural studies showed that there are binding sites for additional Zn 2+ on the surface (see Supplementary Fig. 7 ), and it is possible that (non-specific) binding of divalent cations to the protein surface could affect its activity Preincubation with Ca 2+ , although required for enzyme activation (results not shown), was unnecessary for catalysis Preincubation with Zn 2+ and all other divalent cations tested, except Ca 2+ , resulted in precipitation of the enzyme RNase Z is also distinct from CPSF-73 in that it lacks the second domain ( Fig. 1a , Supplementary Fig. 2d ) Sequence conservation between CPSF-73 and the canonical metallo-β-lactamases is limited to these signature motifs Significant cleavage required relatively high concentrations (10 ng μl –1 or ∼200 nM), which we attribute to only a small fraction of the enzyme being activated by the preincubation Strikingly, after preincubation with Ca 2+ , the wild-type enzyme degraded the SVL substrate almost entirely to oligonucleotides, whereas the mutant was still inactive ( Fig. 4a ) The amino-terminal residues (amino acids 1–208) form a domain similar to the structure of canonical metallo-β-lactamases, with a four-layered αβ/βα architecture (see Supplementary Fig. 2a ) The binding modes of the zinc ions in CPSF-73 ( Fig. 3a ) are similar to that in RNase Z but distinct from those in canonical metallo-β-lactamases ( Fig. 3b ; see Supplementary Information ) The closest structural homologue of the β-CASP domain is the nucleotide-binding fold (NBF, Supplementary Fig. 3 ), with a Z score of 6 from Dali  The other bridging ligand is the side-chain carboxylate oxygen atom of Asp 179 from motif 4 ( Fig. 3a ) The overall structure of yeast CPSF-100 ( Fig. 1b ) is remarkably similar to that of human CPSF-73, despite the low degree of sequence conservation between them (see Supplementary Fig. 1b ) The r.m.s. distance for 210 equivalent Cα atoms between CPSF-73 and RNase Z is 2.6 Å, but the sequence identity is only 18% The r.m.s. distance for 235 equivalent Cα atoms in the metallo-β-lactamase domain (see Supplementary Fig. 2b ) of the two structures is 2.2 Å (with 21% sequence identity), and that for 154 equivalent Cα atoms in the β-CASP domain is 2.3 Å (with 17% identity) The second domain of CPSF-73 covers residues 209–394 ( Supplementary Fig. 1a ), and contains a central, fully parallel, six-stranded β-sheet that is surrounded by five α-helices on both faces ( Fig. 2a ) The structure of CPSF-73 can be divided into two domains ( Fig. 1a ) The structure of its active site strongly implies that CPSF-73 possesses hydrolase/nuclease activity The structure-based sequence alignment also indicates a change in the assignment of residues equivalent to motifs B and C in CPSF-100 (ref. 12 ; see Supplementary Fig. 1b ), although neither residue is His in CPSF-100 The two RNAs were degraded with comparable kinetics and generated similar patterns of intermediates, consistent only with endonuclease activity The two structures obtained for CPSF-73 were crystallized in the absence or presence of 0.5 mM zinc (although both structures contained zinc atoms; see below) The two zinc atoms in the active site are each bound in an octahedral environment, with a hydroxide ion as one of the bridging ligands ( Fig. 3a , Supplementary Fig. 6b ) There are, however, significant differences in the structures of CPSF-100 and CPSF-73 (see Supplementary Fig. 4 ) Therefore, the hydroxide is located at the perfect position for an inline nucleophilic attack on the phosphate group to initiate the nuclease reaction ( Fig. 3a ) Therefore, the Zn2 atom might have a different coordination sphere in Artemis Therefore, the β-CASP domain seems to be a new example of the NBF superfold but is unlikely to bind nucleotides These additional β-strands in the metallo-β-lactamase fold are also seen in the structure of CPSF-100 ( Fig. 1b , Supplementary Fig. 2b ; see below) and RNase Z (see Supplementary Fig. 2d ) , indicating that they might be unique to RNA/DNA-processing nucleases These residues add three strands (β13 to β15) to the central β-sandwich, and the last residue of the structure is located next to the first residue (see Supplementary Fig. 2a ) These results, together with previous data , establish CPSF-73 as a strong, sequence-independent endonuclease that functions with specificity in 3′-end processing of both polyadenylated and histone pre-mRNAs by interacting with other factors This domain is highly conserved among CPSF-73 proteins, and probably has important functions in regulating their activity (see below) This feature of the metallo-β-lactamase fold is crucial for the activity of these proteins, as the loop after strand β13 provides one of the ligands (motif C) to the zinc ions in the active site (see Supplementary Fig. 2a and see below) This indicates that a conformational change in the enzyme might be required for pre-mRNA binding (see Supplementary Information ) This indicates that the active site of CPSF-73 might possess extremely high affinity for zinc ions, making it impossible to remove the zinc from the protein, consistent with the known resistance of 3′ cleavage to relatively high concentrations of EDTA  This induced us to attempt to optimize conditions to obtain more efficient cleavage This oxygen is located opposite to the direction of attack of the hydroxide ( Fig. 3a ), and therefore probably represents the leaving group in the hydrolysis reaction This pair of Glu-His residues is also found in the structure of RNase Z, hydrogen-bonded to a phosphate group in the active site  This residue is conserved among CPSF-73 proteins and its close homologues (RC-68 or Int11) , but not in the DNA nuclease Artemis (see Supplementary Fig. 1b ) This residue is hydrogen-bonded to the side chain of Glu 204 (motif A, last residue of strand β12 in the metallo-β-lactamase domain, see Supplementary Fig. 2a ) as well as an oxygen atom of the sulphate ( Fig. 3a ) This second domain can be considered as a cassette inserted into the metallo-β-lactamase domain, between strand β12 and helix α5 ( Fig. 1a ) To show that CPSF-73 has endonuclease activity in vitro and to provide direct evidence for its role in 3′-end processing, we assessed the nuclease activity of the bacterially expressed CPSF-73, together with a derivative containing a double mutation (D75K/H76A) that destroys two of the zinc ligands in motif 2 ementary Table 2 ) Two additional zinc ions were observed on the surface of CPSF-73 in the crystal grown in the presence of 0.5 mM zinc (see Supplementary Information and Supplementary Fig. 7 ) Using standard conditions for 3′ processing reactions, there was evidence for weak cleavage with the wild-type but not the mutant derivative ( Supplementary Fig. 10a ); a similarly prepared CPSF-100 derivative was also inactive (results not shown) We discovered serendipitously that in situ proteolysis by a fungal protease is crucial for the crystallization of yeast CPSF-100 (ref. 16 ) We used a 5′-capped, uniformly labelled RNA containing the SV40 late polyadenylation site (SVL) as the substrate  Whereas the first four motifs have been identified in the N-terminal segment of CPSF-73 (see Supplementary Fig. 1a , Supplementary Table 1 ), the fifth motif was uncertain, with three candidates, A (Asp or Glu), B (His) and C (His) (see Supplementary Fig. 1a ), in the so-called β-CASP motif 
 Here we show that transcription of some mRNAs in humans and rodents is mediated by a previously unknown single-polypeptide nuclear RNA polymerase (spRNAP-IV). spRNAP-IV is expressed from an alternative transcript of the mitochondrial RNA polymerase gene ( POLRMT ) The promoters for spRNAP-IV differ substantially from those used by RNA polymerase II, do not respond to transcriptional enhancers and contain a common functional sequence motif. The spRNAP-IV lacks 262 amino-terminal amino acids of mitochondrial RNA polymerase, including the mitochondrial-targeting signal, and localizes to the nucleus Transcription by spRNAP-IV is resistant to the RNA polymease II inhibitor α-amanitin but is sensitive to short interfering RNA specific for the POLRMT gene Transcription of eukaryotic genes is performed by three nuclear RNA polymerases, of which RNA polymerase II is thought to be solely responsible for the synthesis of messenger RNAs  Chromatin immunoprecipitation pGL3-luc ( Promega ) constructs containing the 278-bp upstream region of human ALDH12 gene (- 290 to -12) or the 202-bp SV40 early promoter were lipofected into HeLa cells Computational methods Amino acid sequence alignments were constructed using the MACAW program  Consortium clones: RNAP I large subunit, I.M.A.G.E: 4413694; RNAP II large subunit, I.M.A.G.E: 4359716; POLRMT , I.M.A.G.E. 6572256; GAPDH , MGC:2031, I.M.A.G.E. 3543589; p21 (CDKN1A) , MGC:97077, I.M.A.G.E:7262289; ALDH12 , I.M.A.G.E. 4998434; MGC3265, I.M.A.G.E: 3506623; ZBTB1 , MGC:60335, I.M.A.G.E: 6141266 For the expression of recombinant mtRNAP cDNA (a gift from V Immunostaining Cells were fixed with 4% formaldehyde in phosphate-buffered saline (PBS) for 20 min, washed and incubated overnight at 4 °C with anti-mtRNAP or anti-Flag M2 antibodies (1:200) in blocking buffer  Luciferase assays for promoter activity Upstream regions of ALDH12 , ZBTB1 and MGC3265 genes and mitochondrial DNA H-strand promoter (mtHs) were cloned into pGL3-luc reporter vector ( Promega ) Methods Cell culture Human carcinoma cell lines HeLa, A431, H1299 and RKO, normal human lung fibroblasts MRC5, mouse fibroblasts 3T3 and rat fibroblasts Rat1 were cultured in Dulbeccos modified Eagle medium (DMEM), supplemented with 10% fetal bovine serum ( HyClone ) and penicillin/streptomycin Microarray hybridizations The microarray hybridizations were performed using total RNA from HeLa or ρ0 HeLa cells treated with 10 µg ml -1 α-amanitin for either 12 h or 48 h after introduction of siRNA-expressing lentivirus vector Mitochondrial DNA-deficient ρ0 HeLa were obtained, subcloned and cultured as described  Northern analysis Radioactive probes were prepared from DNA inserts of appropriate I.M.A.G.E PCR amplifications (typically 20–25 cycles) were performed with primers specified in the figure legends Preparation of high-titre lentiviral stocks and infection of target cell cultures were performed as described  Recombinant constructs Inhibition of expression of different genes was achieved by infection with recombinant lentiviral vector constructs (pLSLG) expressing hairpin siRNAs controlled by H1 RNA gene promoter as previously described  RT–PCR amplification Total RNA that was isolated by Trizol reagent was converted to cDNA using SuperScript II reverse transcriptase ( Invitrogen ) Search for known transcription-factor binding sites was performed using the MATCH program  Shadel) or anti-Flag antibodies M2 ( Sigma-Aldrich ) The absence of mtDNA was confirmed by PCR The activity of luciferase was measured in cell extracts with the Luciferase assay system ( Promega ) using a fluorimetric plate reader The beads were washed six times with 20 mM Tris-HCl, 200 mM NaCl, 0.5% Triton-X100, 0.05% deoxycholate, 0.1% NP-40, 1 mM phenylmethylsulphonyl fluoride (PMSF) containing 250 mM LiCl, and precipitates were eluted with 1% SDS and 200 mM NaCl The cells were fixed with 1% formaldehyde 24 h thereafter and the prepared cell extracts were incubated overnight with antibodies to either mtRNAP (1:200) or RNAP II ( N-2, sc-899 , Santa Cruz Biotech ) and Protein G Agarose beads The conservation of the promoter sequences in orthologous mammalian genes was determined using the BLAT server . The filters were developed with peroxidase-labelled anti-rabbit polyclonal antibodies and ECL-Plus Western detection reagents ( Amersham Biosciences ) The following 19–21-bp regions corresponding to appropriate mRNAs were present in the hairpin transcripts: RNAP I large subunit, 5′-GTTTACAAGCCACTGAATCGC-3′ and 5′-GAAACCAGCTTCCAGTTTCTG-3′; RNAP II large subunit, 5′-GAACTATTCTCCAACCAGTCC-3′ and 5′-GATACACACCACAGTCTCCAA-3′; exon 3 of POLRMT gene, 5′-CAAAGATACTGGAGAAGGATA-3′; exon 17 of POLRMT gene, 5′-CAACACACGTAAGCAGAAGAA-3′; intron 1 of POLRMT gene, 5′-GGCAAAGAAGGTAACACAA-3′ The mitochondria in control and ρ0 cells were stained with MitoTracker Red 589 ( Invitrogen ) The number of ampicillin-resistant colonies representing immunoprecipitated plasmids was counted The plasmids were transfected into HeLa or ρ0 HeLa cells using Lipofectamine reagent ( Invitrogen ), along with a plasmid expressing β-galactosidase for normalization The samples were heated at 65 °C for 6 h, extracted with phenol/chloroform, ethanol-precipitated and transfected as five independent parallel samples into competent DH5α E. coli  The search for nucleotide motifs in promoter regions and statistical assessment of the detected motifs was performed using the ParaMEME , Gibbs sampling , CONSENSUS and MULTIPROFILER methods The U133A or U133 2.0 Plus human cDNA microarrays were used at the Gene Expression Array Core Facility (Case Western Reserve University) according to Affymetrix protocols Tiranti) or truncated forms of mtRNAP we used modified lentiviral expression vector pLV (ref. 21 ) (from I TRITC-labelled anti-rabbit or FITC-labelled anti-mouse (FITC) antibodies ( Jackson Immune Research ) were used for immunostaining Verma) Western analysis Samples of total protein, mitochondrial and nuclear fractions were isolated as described , heated at 95 °C, separated in 4–12% SDS polyacrylamide electrophoresis (SDS–PAGE), transferred to nitrocellulose membranes and probed with antibodies raised to a peptide (vnlepsdvpqdvy) of human mtRNAP (gift from G A comparison of the upstream sequences of the ALDH12 , ZBTB1 and MGC3265 genes revealed two shared motifs (see Supplementary Fig. 8 ); counterparts to these motifs were also identified in several additional genes putatively transcribed by spRNAP-IV, including ULK1 (data not shown) A further important question is what are the transcription factors that affect spRNAP-IV function? The fact that spRNAP-IV promoters share no sequence similarity with mtDNA and that three known transcription factors (mtTFA, mtTFB1 and mtTFB2) that cooperate with mtRNAP seem to localize exclusively to the mitochondria suggest that spRNAP-IV might use a distinct set of factors for transcription of nuclear genes. A similar pattern was observed for the orthologous transcripts in mouse 3T3 cells ( Supplementary Fig. 5c ) Also, cooperation between spRNAP-IV and RNAP-II in the expression of certain genes cannot be ruled out Attaching an N-terminal Flag to the alternative ORF resulted in a protein that did not react with anti-Flag antibodies but reacted with antibodies to mtRNAP ( Fig. 2c ), suggesting that the first ATG was not used for the translation initiation Both motifs were conserved among the orthologous genes from other mammals (see Supplementary Fig. 8 ) By contrast, inhibition of POLRMT transcripts in ρ0 HeLa cells by RNAi was accompanied by a dramatic decrease in transcripts from the α-amanitin-resistant genes ( Fig. 3c ), which was reversed by overexpression of the spRNAP-IV ORF ( Fig. 3d ) By contrast, RNAi against the proximal portion of intron 1 caused abrogation of nuclear immunostaining concomitant with the disappearance of the nuclear 110 kDa band, with no changes in mitochondria ( Fig. 1d ; see also Supplementary Fig. 2b ) By contrast, the ALDH12 promoter fragment did not respond to the enhancer at all, and its basal activity remained responsive to stimulation by α-amanitin By sequencing polymerase chain reaction with reverse transcription (RT–PCR) products produced with these primers, we found that a fraction of the transcripts in human, mouse and rat cell lines correspond to the splice variant retaining intron 1 sequences (see Supplementary Fig. 1a, b ), confirming that the transcripts specifying an N-terminally truncated mtRNAP are produced in both primates and rodents Certainly, some of the changes might be attributed to secondary effects of inhibition of the true spRNAP-IV-regulated genes Conceivably, spRNAP-IV could be the fourth nuclear RNA polymerase of animal cells, although alternative functions of this protein, other than direct involvement in transcription, can not be ruled out Confocal microscopy revealed both mitochondrial and nuclear localization of immunoreactive proteins in HeLa cells ( Fig. 1a ) Deletion of the sequences spanning these motifs from the ALDH12 , ZBTB1 and MGC3265 promoters abrogated α-amanitin-resistant expression of luciferase, suggesting that the motifs are, indeed, functional elements of spRNAP-IV promoters (see Supplementary Fig. 9 ) For the ALDH12 -promoter-containing plasmid, substantial enrichment was observed with the POLRMT antibodies; a tenfold lower enrichment was seen with antibodies to RNAP-II, suggesting that spRNAP-IV preferentially binds to this construct Hybridization of a total RNA probe from HeLa cells treated with α-amanitin with an Affymetrix microarray U133A showed ∼70 upregulated (twofold or greater) transcripts Identification of spRNAP-IV as a second polymerase transcribing mRNAs in mammals raises a wealth of questions for future investigation Immunostaining showed exclusively mitochondrial localization of the overexpressed mtRNAP and exclusively nuclear localization of the protein encoded by the alternative ORF ( Fig. 2a ) In an attempt to identify genes that could be transcribed by the putative spRNAP-IV, we hypothesized that transcription of these genes would be resistant to α-amanitin, a specific inhibitor of RNA polymerase II (RNAP-II) In isolated mitochondria there was a single band of ∼135 kDa, whereas nuclear extracts contained only the ∼110 kDa band ( Fig. 1b ) In northern hybridization, the α-amanitin-resistant transcripts encoding the zinc-finger BTB domain-containing protein 1 ( ZBTB1 ), prenylcysteine oxidase (MGC3265) and aldehyde dehydrogenase 8A1 ( ALDH12 ) genes showed dose-dependent stimulation by α-amanitin, whereas control transcripts from the p21 WAF1/CIP1 ( CDKN1A ) and GAPDH genes were sensitive to α-amanitin ( Fig. 3a ; see also Supplementary Fig. 6 ) In particular, it remains to be determined at what stage of eukaryotic evolution was a single-polypeptide RNA polymerase recruited for a nuclear role, what is the repertoire of genes transcribed by spRNAP-IV, how is the spRNAP-IV-dependent transcription regulated, how RNAP-II and spRNAP-IV divide and/or share their tasks in the transcription of mRNAs, and whether spRNAP-IV participates in gene silencing, similarly to the recently identified structurally unrelated RNAP IV of Arabidopsis  Indeed, the product of an N-terminally truncated alternative ORF fragment starting at the first initiation codon conserved between mouse and human (ATG-6) was identical in size to the endogenous nuclear protein, whereas the fragment starting at ATG-8 produced a smaller protein (see Supplementary Figs 3 and 4 ) Inhibition of POLRMT by RNAi 24 h before the transfection of reporter constructs led to a decreased activity of the ALDH12 promoter but did not affect the SV40 promoter ( Fig. 4b ) Inhibition of the largest subunit of RNAP-III with siRNA oligonucleotides also resulted in slightly increased levels of all three transcripts (see Supplementary Fig. 6b ) Inhibition of the POLRMT gene by RNA interference (RNAi) resulted in abrogation of both nuclear and mitochondrial immunostaining (see Supplementary Fig. 2b ) and almost complete disappearance of the two protein forms ( Fig. 1b ) and both transcripts from the POLRMT gene (see Supplementary Fig. 1a ) Of 17 randomly selected transcripts that showed downregulation on the microarray, nine demonstrated an α-amanitin-resistant/inducible expression when assayed by RT–PCR (data not shown), suggesting that the number of mammalian spRNAP-IV-dependent genes might be in the hundreds Of the 15 transcripts tested by RT–PCR, four showed lack of sensitivity to or even stimulation by α-amanitin (see Supplementary Fig. 5a, b ) Of ∼20,000 transcripts that gave a positive signal, ∼1,000 transcripts were substantially inhibited (twofold or greater), whereas ∼300 transcripts showed comparable levels of upregulation (see Supplementary Table 1 ) On transfection into HeLa cells, the CMV enhancer stimulated α-amanitin-sensitive transcription from the SV40 promoter by more than tenfold On western blots, total cell extracts showed two protein bands of ∼135 kDa and ∼110 kDa Our findings suggest that the POLRMT gene specifies two single-polypeptide polymerases, one (mtRNAP) targeted to the mitochondria, and the other (spRNAP-IV) having a putative function in the nucleus Overexpression of the complementary DNA encoding the full-length mtRNAP (ref. 6 ) caused a substantial increase in the mitochondrial 135-kDa band but no increase in the 110-kDa nuclear form ( Fig. 1c ; see also Supplementary Fig. 2b ), suggesting that the latter protein does not originate from the mtRNAP mRNA neither through internal initiation of translation nor processing of the 135 kDa precursor Replication and expression of the eukaryotic mitochondrial genome fully depends on the nuclear genome: during evolution, most of the genes derived from the DNA of the proto-mitochondrial endosymbiont and required for mitochondrial function were translocated to the nucleus, such that most components of the mitochondrial proteome are imported into the mitochondria  Similarly, in HeLa cells producing the artificial transcription factor tTA , the activity of the ALDH12 promoter did not change when coupled with the tetracycline-responsive element (see Supplementary Fig. 10 ), confirming that RNAP-II enhancers do not affect transcription by spRNAP-IV The electrophoretic mobility of the overexpressed Flag-tagged proteins corresponded precisely to the two endogenous bands as shown with POLRMT-specific antibodies ( Fig. 2b ), although the size of the nuclear protein determined by electropheresis (∼110 kDa) was much smaller than the size of the alternative ORF product predicted from the mRNA sequence (∼130 kDa) The expression of luciferase driven by the ALDH12 and ZBTB1 promoters was resistant to α-amanitin, in contrast to the α-amanitin-sensitive expression from the SV40 promoter ( Fig. 4a ) The human mtRNAP precursor has an N-terminal mitochondria-targeting peptide , which is cleaved from the protein during mitochondrial import  The mitochondrial RNA polymerase (mtRNAP) is a homologue of to the bacteriophage single-polypeptide RNA polymerases and displaced the typical, multisubunit bacterial RNA polymerase during the evolution of the endosymbiont  The mtHs promoter was inactive in this system, suggesting that the regulation of spRNAP-IV transcription in the nucleus is distinct from that of the mtRNAP in the mitochondria ( Fig. 4c ) The mtRNAP is encoded in the spliced 3.8-kilo-base transcript from the nuclear gene POLRMT  The N-terminal structure of mtRNAP is supported by 19 available expressed sequence tags (ESTs); however, three ESTs correspond to an alternative structure, with a longer exon 1 including the proximal 224 base pairs (bp) of intron 1 The open reading frame (ORF) encoded by the alternative transcript is truncated at the N terminus and would specify a protein lacking the mitochondria-targeting peptide The putative spRNAP-IV promoter motifs showed no detectable similarity to the sequences of RNAP I–III promoters , those of the known transcription-factor-binding sites , the sequences of mtDNA that are involved in mtRNAP-directed transcription, or the promoters of T-odd bacteriophage genes transcribed by single-polypeptide phage polymerases homologous to mtRNAP The reciprocal enrichment was observed with the SV40 promoter construct ( Fig. 4c ) Therefore, spRNAP-IV seems to have a distinct role in cell physiology These results indicate that the truncated nuclear protein product of the POLRMT gene participates in the production of certain mRNAs This resulted in a substantial growth retardation and cell death, which was reversed by co-expression of recombinant spRNAP-IV ( Fig. 2d ) Thus, the nuclear form of the protein seems to start at ATG-6 of the ORF and correspond to the 968 C-terminal amino acids of mtRNAP, which include the entire catalytic domain (see Supplementary Fig. 3 ) Thus, these genes apparently are not transcribed by known nuclear RNA polymerases To analyse promoters used for initiation of transcription by spRNAP-IV, we amplified and cloned the upstream regions of ALDH12 and ZBTB1 genes into a reporter plasmid To determine whether or not spRNAP-IV is important for cell viability, we inhibited the expression of POLRMT gene by siRNA expression To determine whether spRNAP-IV binds to the ALDH12 promoter, formaldehyde-fixed extracts of HeLa cells transfected with an empty vector or with the constructs bearing ALDH12 and SV40 promoters were precipitated with antibodies to RNAP-II or POLRMT , and the number of ampicillin-resistant colonies indicating the efficiency of immunoprecipitation was determined by transformation of Escherichia coli  To determine whether the shorter polypeptide lacking the mitochondrial targeting peptide is indeed synthesized, we analysed proteins that react with antibodies to a carboxy-terminal peptide of mtRNAP (ref. 8 ) To examine the repertoire of transcripts affected by spRNAP-IV, we monitored changes in the expression pattern in ρ0 HeLa cells after 48 h expression of siRNA targeting the POLRMT gene using hybridization to a cDNA microarray To verify the existence and to explore potential functions of an alternative, possibly non-mitochondrial product of the POLRMT gene, we designed primers to show variations within the 5′ region of the POLRMT transcripts Total extracts from the mitochondrial DNA-depleted ρ0 HeLa cells (see Supplementary Fig. 2a ) contained reduced amounts of the mitochondrial 135 kDa form, whereas the nuclear 110 kDa protein was unaffected ( Fig. 1b ) Transcription initiated by RNAP-II can be substantially activated by transcription factors that bind to transcriptional enhancers  Upregulation of some of these transcripts by α-amanitin was confirmed by northern analysis in three different ρ0 HeLa cell lines (see Supplementary Fig. 7 ) We tested whether the activity of promoters of spRNAP-IV-controlled genes could be stimulated by placing a strong cytomegalovirus (CMV) enhancer close to ALDH12 , SV40 and mitochondrial DNA H-strand (mtHs) promoters in a luciferase reporter plasmid We then overexpressed the predicted alternative ORF and, separately, the mtRNAP ORF in ρ0 HeLa cells, both tagged with a C-terminal Flag epitope When RNAP-I or RNAP-II was inhibited by RNAi, gradual decrease and disappearance of transcripts encoding each of these polymerases was observed by day 4, which correlated with substantial stimulation of ZBTB1 , MGC3265 and ALDH12 transcripts ( Fig. 3b ) When they were transfected into HeLa cells, both putative spRNAP-IV promoters supported luciferase expression with activities comparable to that of the SV40 early promoter ( Fig. 4a )
 Although the experiment used gas as the test fluid, liquids could be used As a result, the gas had a ‘memory’ of its position at the time of spin encoding But taking a closer look at the fluid distribution remains a difficult task, even under laboratory conditions By lowering an entire NMR spectrometer inside a small borehole, the residence-time distribution of a fluid inside the rock might identify pockets of oil that would be too costly to recover Each image acquired with a particular delay provides a snapshot of the fluid distribution at the corresponding instant ( Fig. 1b ) Excitation of the spins occurs at one place and the signal is collected at a different location, with magnetic fields and detectors independently optimized in the two steps to maximize signal quality ( Fig. 1a ) Finally, NMR remote detection has promising applications in chemical engineering For instance, combining NMR with advanced spin-detection technologies, such as using superconducting quantum interference devices, or SQUIDs , becomes feasible For their latest work , Pines and colleagues joined forces with researchers at Schlumberger–Doll, a company that provides technical advice and NMR hardware for the oil industry Here, the same issue of the imaging of flow through tiny channels occurs in the microreactors used in fine chemical synthesis However, xenon gas has the advantage of ensuring that the spin magnetization has a long enough lifetime to survive the transport process In the first stage of the procedure, the nuclear spins in the gas were manipulated inside the encoding coil by a combination of radiofrequency pulses and varying magnetic-field gradients In the second step, fluid flow carried the gas through the sample and then past a small, highly sensitive detector coil, where the stored NMR information was collected More achievable applications might exploit the advantages of small magnetic fields for the encoding step ; even Earths weak magnetic field can suffice , because magnetic couplings between nuclei are independent of field strength and become the dominant source of information about molecular structure in small external fields Moreover, xenon-129 is extremely sensitive to its molecular environment and its spin polarization can be boosted dramatically by optical methods , making it a popular tracer in NMR studies NMR is used in oilfield prospecting and provides valuable information about the oil and water content of rocks Notably, the authors modified their original concept by exploiting the information contained in the travelling time to the detector Nuclear magnetic resonance (NMR) is an outstandingly versatile technique, used across the sciences One such advance, reported in Physical Review Letters , stems from the work of Pines and colleagues Pines and colleagues have previously questioned the view that the whole NMR procedure needs to take place in one location Problems to be overcome before this goal can be achieved include the small space available for the probe and the limited timeframe for executing the measurement while drilling Recently, Pines and colleagues have monitored fluid residence times inside a microreactor, and find that the remote-detection approach might well be used to optimize transport and reaction efficiency in such microstructured devices . Similar obstacles dog the application of NMR to samples that are very large, very small or highly diluted, and researchers have long tried to adapt their hardware to cope with the field distortions induced by such samples So the technique could potentially provide more complete information than can be obtained by even a full three-dimensional rendering of the pore space Studies of this kind of sample are limited by the many interfaces and, in some cases, the metal content of natural rocks, which bend the applied magnetic field and blur the magnetic resonance image Such a prospect had previously seemed unpromising because of the restrictions of conventional NMR conditions The basic principles — manipulating the nuclear spins of atoms in a sample by means of radio waves and magnetic fields, and recording the resonance signal obtained — can be applied to provide information in such disparate fields as chemistry and medical diagnostics The concept of remote detection is being explored further, opening up other possibilities The currently used inside-out configuration for NMR — where the sample is outside the instrument — can be modified by Pines and colleagues two-coil design so that the otherwise weak signal is ‘concentrated’ into a small and efficient receiver coil The distributions and transport properties of gases, however, are notoriously difficult to detect by conventional approaches because of their low density, and here the two-coil design pays dividends because the gas can be collected outside the sample The molecules closest to the sample outlet are the first to pass the detector coil; by contrast, those trapped in dead-end rock pores remain undetected, and so heterogeneities in the pore space can be identified The problem they have tackled is that of obtaining sharp images of fluid flow inside a rock The sample they used was a small cylinder of sandstone rock, 20 mm in diameter and 38 mm long, and the test fluid was a gas mixture that included the isotope xenon-129 The two steps of manipulating the spins and acquiring the resonance signal are usually combined in the NMR apparatus, but in the authors ‘remote-detection’ approach they are separated not only in time, but also in space The ultimate goal of this particular line of research is to be able to perform such experiments in the field They aimed at obtaining a sharper view of the object under study by the counterintuitive approach of moving away from it Yet the method has its limitations, leaving scope for further innovation
 But there are worries abroad. “US government officials are likely to have great concern about Japans development of its own military satellites because they are nervous of the spread of understanding of technology,” says Howard McCurdy, a space-policy expert at the American University in Washington DC In a country constitutionally wedded to peace, the move could cause public uproar It plans to submit a bill to the Diet next year to change the way space development is defined, which is likely to pass. “Space development should be a source of national pride, but Japan doesnt have a diplomatic strategy to take advantage of it,” says Kenichi Kawamura, a spokesman for committee head Takeo Kawamura Japanese researchers are also worried On 28 March, a committee of the Liberal Democratic Party proposed that Japan should revise a 1969 policy limiting the use of space to “peaceful” objectives Scientists are also worried that they might lose out Since then, Japan has launched two spy satellites, but their resolution is a quarter of that of other countries reconnaissance satellites, and Japan has relied on the United States for high-resolution images and communications The committee suggests that Japan should lift its self-imposed limit on the imaging resolution of military satellites The government is concerned about possible attacks from terrorists and from North Korea, which fired ballistic missiles into Japanese water in 1998 The new law would enable Japans defence agency to have spy satellites with a resolution that could detect a missile launch by another country. newsad; The move is being welcomed by Japans space industry, which hopes that new investment will make satellite manufacturers more competitive internationally They fear that although the Japan Aerospace Exploration Agency (JAXA) might enjoy a budget boom in defence-related technologies, smaller-scale science missions could be cut back if government money was funnelled into the space industry. “Research areas that can be applied to defensive use would be in the spotlight,” says Yasunori Matogawa, JAXAs associate executive director, adding that even areas where Japan has traditionally been strong, such as X-ray astronomy and infrared technologies, may be affected. “Those technologies look close to military ones but they are not the same.” Tokyo Japans ruling party is poised to revolutionize the countrys space programme by allowing it to expand into military applications Under the current pacifist constitution, Japan has shied away from developing high-tech military satellites even for defence
 Padian and Dial challenge our view that the evolution of flight involved a four-winged stage This disagreement stems from our different views on the origin of bird flight and from the methodology we use to analyse functional morphology in the non-avian theropod Microraptor and in an enantiornithine bird from the Early Cretaceous period in China. Although long leg feathers are found (but not to assist flight) in many living birds, these do not show the asymmetry or curved shaft indicative of aerodynamic properties Although the wing produced the main force for lift and thrust in the new enantiornithine bird, the curved shaft and asymmetric vanes of the leg feathers indicate that they could still produce some lift and thrust, as well as reducing drag Although we believe that leg feathers had some aerodynamic function in Microraptor and that this was weaker in early birds, they were probably not the main flight apparatus Contrary to Padian and Dials assertions , attachments of leg feathers to the external side of the leg bones (tibia or metatarsals) have now been documented not only in Microraptor gui but also in Archaeopteryx , Confuciusornis and several enantiornithine birds , which would have enabled them to be extended into the lateral plane to produce some lift However, their role in the origin of bird flight should not be ignored — functional inferences should be based mainly on functional studies, not on phylogenetic brackets . It is not self-evident that small non-avian theropods were good runners: indeed, some of them may actually have been arboreal  Leg feathers first appeared in non-flying theropods, which may have conferred some aerodynamic advantage, judging by their asymmetry and by the presence of an alula in the forelimb Padian and Dial argue that there is no evidence for a four-winged stage in flight origin Reduction of drag is probably one of the main functions of the leg feathers in Microraptor and early birds, and modern birds such as kittiwakes use the leg feathers on their extended hindlimbs as well as their webbed feet for this purpose So the original function of leg feathers might have been for gliding The absence of aerodynamic function in leg feathers in modern birds does not mean that it did not exist in their ancestors The arboreality of this bird is indicated by the curvature of the pedal claws and toe proportions  We agree with Padian and Dial that these feathers were probably not used for active flight in Microraptor or in early birds
 Ever since Pasteur noticed that tartrate crystals exist in two non-superimposable forms that are mirror images of one another—as are left and right hands—the phenomenon of chirality has intrigued scientists Here we show an alternative mechanism that gives rise to asymmetric amplification based on the equilibrium solid-liquid phase behaviour of amino acids in solution In chemical synthesis, much effort has been directed towards developing asymmetric synthesis strategies that yield product molecules with a significant excess of either the left-handed or right-handed enantiomer In recent years, however, an increasing number of asymmetric reactions have been documented where this relationship is nonlinear , an effect that can lead to asymmetric amplification On the molecular level, chirality often has a profound impact on recognition and interaction events and is thus important to biochemistry and pharmacology Theoretical models have long suggested that autocatalytic processes can result in kinetically controlled asymmetric amplification, a prediction that has now been verified experimentally and rationalized mechanistically for an autocatalytic alkylation reaction This amplification mechanism is robust and can operate in aqueous systems, making it an appealing proposition for explaining one of the most tantalizing examples of asymmetric amplification—the development of high enantiomeric excess in biomolecules from a presumably racemic prebiotic world. This is usually achieved by making use of chiral auxiliaries or catalysts that influence the course of a reaction, with the enantiomeric excess (ee) of the product linearly related to the ee of the auxiliary or catalyst used A particularly appealing feature of the scenario we outline here is that it is based on an equilibrium mechanism, in contrast to the far-from-equilibrium environments invoked in kinetically induced amplification via autocatalytic reactions or crystallizations  A scenario for homochiral evolution based on our amplification mechanism was hinted at some years ago , and it also shares some similarities with the suggestion that chiral enrichment may result from the selective dissolution of only one (enantiopure) crystal of a conglomerate in a microenvironment , but seems ultimately much simpler Although all but two of the twenty proteinogenic amino acids are known to form racemic compounds (crystals with a 1:1 ratio of the d and l enantiomers) and not conglomerates (a mixture of pure d and pure l crystals), we were unable to find literature values for the eutectic composition of any ternary phase system of free amino acids that form racemic compounds in water or other solvent Any saturated solution of scalemic proline in equilibrium with a sufficient excess of solid will exhibit this ee, regardless of the overall ee of the proline employed As expected from the eutectic values listed in Table 1 , serine offers the most significant chiral amplification: nearly racemic (1% ee) serine gives a product enantioselectivity virtually indistinguishable from that obtained using enantiopure serine Figure 3 shows how the product enantiomeric excesses obtained with catalysts of varying ee values compare with the product ee that is obtained when using enantiopure amino acid catalyst Finally, we note that further enhancements in solution-phase enantiomeric excess may be discovered in more complex multi-component systems with a greater number of equilibrium solid and liquid phases For proline in DMSO at 25 °C, the eutectic composition corresponds to a solution enantiomeric excess of about 50% ee Fourier-transform infrared (FTIR) spectroscopic analysis of the solids confirmed that these are a racemic compound (that is, crystals in which l : d = 1:1), and an enantiopure solid of the excess enantiomer Given that the proline-catalysed aldol reaction (1) occurs in the solution phase, this finding readily explains the relationships between proline ee and the product ee illustrated in Fig. 1a ; that is, the ee of the aldol product appears to depend linearly on the ee of the accessible proline catalyst Here we have established that the coupling of solid–liquid phase behaviour and amino acid catalysis results in an efficient and robust mechanism for asymmetric amplification However, our findings suggest that aiming for the opposite effect—high solution enantiomeric excess and lower solid ee—provides a means of realizing asymmetric amplification in solution However, this phenomenon mirrors the trend in the ee of dissolved proline as a function of total proline ee ( Fig. 1b ), with the proline solution ee found to remain constant at about 50% ee even though the total proline ee is varied from near racemic to near enantiopure If the reaction is carried out using proline concentrations low enough that the catalyst is fully dissolved, the relationship is linear ( Fig. 1a , squares) In fact, our studies show that serine meets the first two criteria, and recent work has demonstrated that serine catalyses certain asymmetric aldol reactions with high enantioselectivity; it has also been highlighted as one of a small number of amino acids likely to have played an important role in prebiotic chemistry  One can easily imagine the coexistence of solid and dissolved amino acids under a range of environmental conditions in a prebiotic landscape, and high ee could then evolve from an initially small imbalance in ee if (1) the amino acid forms a racemic compound rather than a conglomerate; (2) the amino acid exhibits high enantiopurity at its eutectic; and (3) the amino acid acts with high selectivity as an asymmetric catalyst in solution phase transformations Only proline compositions with very low ee (where the excess of the major enantiomer is too low to establish its solid phase) or very high ee (where the minor enantiomer concentration is insufficient to form the solid racemic compound) will show a variation of solution ee with overall proline ee, dictated by the lines E′R (or ER) and E′A′ (or EA), respectively, in Fig. 2  Our measurements on the proline-catalysed aldol reaction (1) (see Supplementary Information for experimental details) reveal behaviour more complex than was found in either the earlier or later work: two regimes exist with different relationships between the ee of the proline catalyst and the ee of the aldol product Our own measurements collated in Table 1 reveal that several of the proteinogenic amino acids that form racemic compounds in fact exhibit high eutectic ee values Phase diagrams such as the one shown in Fig. 2 are useful for optimizing crystallization conditions, where the aim is typically the production of a solid of high enantiopurity by depleting the solution enantiomeric excess Prediction of enantioselectivity in solution catalysis from knowledge of these eutectics was confirmed in the results of the aldol reaction of equation (1) carried out using instead of l -proline several of the amino acids listed in Table 1 at varying levels of enantiopurity, with three-phase equilibrium established before reaction Product enantioselectivities for aldol reactions carried out in aqueous media using these amino acid catalysts were also found to correlate well with the position of the eutectic, although yields and chemo- and enantioselectivities were in general lower (see Supplementary Information ) Recent investigations have rekindled interest in exploring nonlinear effects in amino acid catalysis despite experimental and theoretical work that has effectively discounted earlier reports of nonlinear behaviour in these systems Serine, with its eutectic at 99% ee, provides a virtually enantiopure solution from a nearly racemic sample under solid–liquid equilibrium conditions The data indicate that the position of the eutectic dictates the product selectivity for this amino-acid-catalysed transformation The diagram is symmetric: racemic mixtures are represented along the vertical line intersecting the DMSO vertex, and the phase behaviour of d -proline to the left side of this line reflects the l -proline phase behaviour on the right The low solubility of proline means that the part of the diagram that is of interest for our solution phase system is located very near to the apex, and this portion is expanded in the main part of Fig. 2  The phase rule dictates that at constant temperature the composition of a solution of proline in equilibrium with the two solid phases is fixed, and this composition is given in Fig. 2 by the eutectic at E′ (or E) The solid-solution phase behaviour of enantiomers and their racemates was the focus of extensive study at the turn of the last century and is generally well-understood , but non-enantiopure, non-racemic mixtures (particularly those of free amino acids) have received less attention The ternary phase diagram for the system d -proline/ l -proline/DMSO constructed from our data is shown in Fig. 2 , where pure DMSO is represented at the apex, and pure d and l proline at the left and right vertices, respectively The two amino acids that form conglomerates, threonine and arginine, exhibit 0% ee at the eutectic This finding suggests that amino acids may have played a role in the evolution of biomolecular homochirality  This latter, unusual relationship cannot be explained by any of the existing models for nonlinear effects in asymmetric catalysis  This possibility and the influence of interactions between different amino acids and between amino acids and other molecules such as sugars is the subject of ongoing investigations by our group, as is the search for high selectivity in amino-acid-catalysed reactions of potential biological relevance. This prompted us to examine the phase behaviour of a number of amino acids, to explore their potential for higher asymmetric amplification than is possible with proline and its eutectic positioned at about 50% ee We therefore explored the phase behaviour of proline and found that when the two enantiomers ( l and d ) of proline are present in unequal proportions above their solubility limit in dimethyl sulphoxide (DMSO), two separate solid phases are formed at equilibrium When using higher catalyst concentrations, so that dissolved proline is in equilibrium with solid proline, the product ee is largely independent of proline ee ( Fig. 1a , circles)
 A tsunami hits northern Europe All showed up in the novel under their own names, to their initial consternation As a novel The Swarm may be unlikely to repeat its phenomenal German success out in the English-speaking world As crisis becomes global catastrophe, the US government — represented by the ambitious, single-minded General Judith Li — takes over the worldwide effort to unravel the mystery At more than 900 pages, even avid supporters admit that it is simply too long But he was pleased with his modest role as the scientist who confirms that ice worms have reached the Japanese Pacific. “I am surprised at his knowledge of biogeosciences,” he says. newsad; Despite his interest, Matsumoto has yet to finish the book But its future in Hollywood looks brighter — it is, after all, a thriller packed with technology, danger, spectacle, romance and a watery hint of apocalypse But once they had read the book, none of them minded. “I was worried when I started reading, but in the end I found myself nicely characterized,” says Bohrmann, who has plenty of adventures in real life on research vessels in stormy seas — albeit not on the scale of his fictional namesake, who escapes a vicious shark attack while trying to save humanity from the ice worms But worms are not the only creatures swarming Curious yet nervous, Matsumoto had to wait two years for the English translation to be published to find out how he appeared in the novel Death and destruction is everywhere Descriptions of the science — often disguised as discussions between researchers, or as lectures — can run on for pages He developed a particularly close relationship with those at the Leibniz Institute of Marine Sciences at the University of Kiel in Germany He has Johanson dub this intelligence Yrr by striking a computer keyboard three times at random He is an advertising executive in Cologne, and none of his previous five novels dealt with science His case was unsuccessful His studies led him to the dozen or so researchers with whom he hammered out the details of how the science could be made to serve the plot without becoming distorted. “With them, I tried to see how far I could stretch my ideas,” he says. “We developed methods together, for example the way the Yrr communicated” — through pheromones in the water If The Swarm sounds destined for the silver screen, it is: Hollywood actor and producer Uma Thurman has already snapped up the film rights to the best-selling German thriller, now hitting the shelves in an English-language translation Marine biologist Sigur Johanson is wary when Tina Lund, an oil-company scientist, visits his remote Norwegian home Mussels, sea wasps, and Portuguese men-of-war also gather in untold numbers, killing seafarers and beach tourists On waking, he began to wonder: “What would happen if...?”  Yet much of The Swarm is based in reality — indeed, it contains a level of scientific verisimilitude unusual in any novel, let alone an airport thriller Other scientists join in too, as the invasion turns out to be related to the mysterious breakdown of methane hydrate reservoirs on the sea bed off Europe Ryo Matsumoto, a gas-hydrate expert from the University of Tokyo, was tipped off about his role by his German colleagues Schätzing developed the plot over three years of devouring popular science books, research reviews and internet sources Schätzing did not speak to all the scientists he characterized Schätzing smiles, recalling how he originally intended Bohrmann to play a tiny role. “But then he ended up as the Bruce Willis of marine science.”  Bohrmann says that Schätzing had done his research well before coming to Kiel for an interview: “He already knew everything about gas hydrates.” Sahling was also impressed: “His questions were very intelligent and he was a good listener — he adopted much of what we said word-for-word in his novel.” Suess was less charmed, however, remarking that Schätzing claimed as his own ideas that were generated in discussion with colleagues Schätzing visited scientists across Germany and further afield, including in Vancouver, Canada Schätzing, a self-assured, well-coiffed 49-year-old, seems at first glance an unlikely figure to have authored such a book Science communicator Thomas Orthmann was similarly unimpressed and tried to sue Schätzing for plagiarising from his website The antagonist, after all, is pure fantasy: “I created an environment as real as possible and added only one fictional element — a deep-sea, non-human intelligence crucial to the plot,” says Schätzing The books author, Frank Schätzing, says he based his plot on a dream. “Sea life was flocking together, threatening us,” he remembers The prospect certainly has Schätzing in dream mode again: George Clooney and Lucy Liu in the main roles — and a cameo for himself, Hitchcock-style. There he spent hours discussing his ideas with researchers including Erwin Suess, a prominent methane-hydrate researcher; marine biologist Heiko Sahling; and marine geologist Gerhard Bohrmann This is both the fascination of the book and its literary weakness, as it drastically slows the plot Which is not to say that the novel is a truly realistic portrayal of the oceanographic world With mixed feelings — he has long been secretly attracted to her — he agrees to help her employer with a serious problem: swarms of Hesiocaeca methanicola , or ice worms, at potential North Sea oil-drilling sites With no formal scientific education, Schätzing has managed to cover a swathe of scientific territory without significant error Yet readers have found themselves absorbed not only in the tensions and romances of a tough mystery, but also in the details of up-to-the-minute research in fields such as neurocomputing, seafloor oceanography and cell signalling
 Any place for diversity of opinion as to who/what the Designer is/was? The ID literature makes it very clear that there is no room for scientific discourse on that Building a straw man based on natural selection alone makes it easy for opponents to poke holes in evolution But after a century of close scrutiny, evolutionary theory has passed so many litmus tests of validation that evolution is as much a fact as respiration and digestion But features of the genome, such as genomic parasites or non-coding introns, which arent so evolutionarily favourable (nor obviously ‘intelligent’ innovations), can be more readily explained by models that include random genetic drift and mutation as substantial evolutionary forces First, IDers like to portray evolution as being built entirely on an edifice of darwinian natural selection Have a problem explaining something? Forget about it: the Designer made it that way Here is a missed opportunity However, it has long been known that purely selective arguments are inadequate to explain many aspects of biological diversity However, there is a related and equally disturbing issue: the legitimization of intellectual laziness Less widely appreciated is that evolution has long been the most quantitative field of biology, well grounded in the general principles of transmission genetics Mathematics becomes more digestible, and even attractive, when students see its immediate application Most molecular, cell and developmental biologists subscribe to the same creed, as do many popular science writers Our failure to provide students with the mathematical skills necessary to compete in a technical world is a major concern in the United States Second, IDers like to portray evolution as a mere theory Sheltered within the confines of academia, most biologists find it hard to believe that the slain need to be slain again Sir Much of the concern over ID ( Nature 434 , 1053 and 1062 – 1065 ; 2005 10.1038/4341053a ) has focused on veiled attempts to inject religion into public education The teaching of evolution purely as history, with little consideration given to the underlying mechanisms, reinforces the false view that evolution is one of the softer areas of science Think Im exaggerating? To get a good idea of what IDers would have the face of science look like, check out the journal Perspectives on Science and Christian Faith ( http://www.asa3.org/ASA/PSCF.html ) This caricature of evolutionary biology is not too surprising Those in the trenches — school boards, school biology teachers and their national representatives — often dont know how to respond, in part because they themselves never really achieved a deep understanding of evolutionary biology at college Two factors have facilitated the promotion of ID What better place to start than with the population-genetic theory of evolution, much of which is couched in algebraic terms accessible to school students? Yet few students at university, and almost none at high school, are exposed to the mathematical underpinnings of evolutionary theory
 According to a 2001 Statistics Canada survey, the main reason biotech companies in Ontario havent taken on more staff is a shortage of qualified candidates According to the Canada Research Chairs programme, 15% of recipients were recruited abroad and a further 14% were expatriates who returned to Canada Alastair Summerlee, the universitys president, says that the planned scientific environment and opportunities for collaborations have been key to recruiting Already an established leader in Ontarios agbiotech industry and veterinary medicine, the university has begun construction of a 32,500-m 2 expansion that will nearly double the size of its science complex and put it next door to physics, mathematics, chemistry and computer science Although salaries are rumoured to remain lower in Ontario than in the United States, universities across the province are successfully luring expatriates and foreigners. “In the past four years weve seen a brain gain — the president of the Ontario Genomics Institute is an American,” says Martin Godbout, president and chief executive of Genome Canada, a not-for-profit genomics and proteomics funding agency that has received Can$375 million from the federal government since its inception in 2000 Before the year was over, the pharmaceutical company Eli Lilly had picked up the research and went on to sell insulin to diabetics around the world But if its strategies are successful, the province is poised to become a world-class destination for top-quality researchers But Ontarios commitment to science goes beyond MaRS and Toronto But universities across the province now declare that a new kind of brain drain is under way — running from south to north Centre director Brenda Andrews anticipates hiring ten principal investigators over the next three years, who will help determine the centres direction Christopher Paige, vice-president of research at UHN, says the floors will be filled according to their priorities: clinical genomics and proteomics, health informatics, image-guided diagnostics, and therapy and regenerative medicine Companies and services will also be housed there David Andrews, a cancer biochemist involved in setting up the centre, sees it becoming a destination for cancer researchers from all over Canada and the United States In 2000, the federal government created the Canada Research Chairs programme that enables universities to attract top-quality researchers In February, the University of Guelph was actively seeking 12 assistant professors in the biological sciences, and anticipated hiring more In Hamilton, McMaster University was recently awarded a Can$4.4-million Canada Foundation for Innovation grant to open a Centre for Functional Genomics In January 1922, Fredrick Banting and Charles Best administered the first insulin injection to a 14-year-old diabetic, in a lab located on the corner of College Street and University Avenue in downtown Toronto, Canada In recognition of the role that serendipity often plays in scientific progress, the building will also have a large conference hall and a central atrium that Cook hopes will encourage tenants to rub shoulders and exchange ideas. “Its like those squares in old Italian cities where everyone meets and the chances of serendipitous discovery increase,” he says Its supporters claim Ontario as the fourth largest biomedical-industry cluster in North America, and the government has its sights set on being third Last year, the province pledged Can$27 million (US$22 million) to help universities, colleges and hospitals identify discoveries with commercial potential, and Can$36 million to help them establish seed money for spin-off companies MaRS will create more than 120,000 m 2 of labs, offices, meeting rooms and conference space close to both the University of Toronto and the hospitals and their research institutes that line University Avenue Nearby, Torontos top genetics researchers are developing the Toronto Centre for Phenogenomics, which will serve as a resource for mouse models of human disease Never has the federal government been more generous to science Ontario is competing with many other would-be world leaders in life sciences Opposite MaRS, the Terrence Donnelly Centre for Cellular and Biomolecular Research is due to open its doors in September Researchers from the University Health Network (UHN) and the Hospital for Sick Children will occupy the Toronto Medical Discoveries Tower, a state-of-the-art 37,000-m 2 wet-lab space on the east side of the complex Ten other centres give the province significant cluster power within the life-sciences industry Tenants will include Salt Lake City-based NPS Pharmaceuticals, which has chosen Toronto as its primary location for research and development activities in Canada, and Boston-based VIMAC Ventures The boy suffered an allergic reaction, but by the end of the month the team had honed its techniques and given him a second dose, free of side effects, that eliminated the symptoms of his diabetes The building that housed Banting and Bests lab is now a heritage site and is at the centre of one of Canadas largest initiatives to commercialize research The Can$67-million mouse house is set to open in 2006 with 180,000 rodent tenants The Canada Foundation for Innovation is funding projects that strengthen the countrys research infrastructure, to the tune of almost Can$971 million in Ontario alone The centre will bring together researchers from the faculties of medicine, pharmacy, and applied science and engineering to investigate living systems at the molecular and cellular level, and build on the University of Torontos strong functional genomics, proteomics, bioimaging and biomaterials programmes The centre, which will come under the umbrella of the McMaster Institute for Molecular Biology and Biotechnology, will use functional genomics to identify genetic markers and drug targets for human disease The city is just one node in the biotechnology corridor that runs along the southern edge of Ontario from London to Ottawa The development of the Medical and Related Sciences (MaRS) Discovery District is an effort to establish Toronto as one of the worlds leading bioparks, and to foster the commercialization of science The initiatives primary objective is to take biomedical research from Toronto to rural communities The new facilitys design promotes better exchange between the biological and physical sciences, and will help the university handle rising numbers of students The south tower will hold start-up and medium-sized companies and the heritage building will house services, from lawyers and accountants to funding agencies and venture-capital companies The university has 40% more undergraduates and 30% more graduate students than five years ago, forcing a 30% growth in the faculty The University of Toronto St George campus (downtown) is also undergoing a transformation The university will also be connected to the Toronto MaRS Discovery District through MaRS LANDING — Links to Agricultural Network for Development and Innovation with Guelph This will build on a foundation of basic research that is already in place, he adds To date, 1,348 chairs have been awarded, including 401 to Ontario in health and natural sciences, and in engineering To the west, the University of Guelph is anticipating significant growth UHN has signed a 30-year lease to occupy 12 of the buildings 15 floors, where its researchers will engage in drug development, image-guided diagnostics and therapy Web links Medical and Related Sciences (MaRS) Discovery District http://www.marsdd.com MaRS LANDING http://www.marslanding.ca Toronto Phenogenomics Centre http://www.phenogenomics.ca Terrence Donnelly Centre for Cellular and Biomolecular Research http://tdccbr.med.utoronto.ca Canada Foundation for Innovation http://www.innovation.ca Canada Research Chairs http://www.chairs.gc.ca Welcome to MaRS The strength of the MaRS Discovery District will be its ability to gather researchers, big companies, spin-offs and venture capital, and offer researchers the chance to turn ideas into products and partnerships, says MaRS president John Cook When full, the 20,000-m 2 building will support the research and teaching activities of 500 people, including 40 to 45 principal investigators Will all this be enough to push Ontario to the head of the pack? It seems so
 Alcohol wasnt an issue At 10 p.m. each night we listened to the tapes with drinks: wine, soft drinks But I was taken aback when one Israeli confessed she had never had a social conversation with an Arab, even a Palestinian, before she came to the Petra workshop But in a different way there were risks to students from the Arab countries But people do have a choice — and we gave some of them the opportunity to do so. But perhaps many small actions that build trust and connections between people, especially young people, will help But we also did things that bring people close Camaraderie builds in such intense situations Can academic classes really help? It is unrealistic to think a scientific gathering will solve the problems of the region Can scientific ties counter political tensions? Roald Hoffmann hopes so Did the participants get on with each other? Yes, although at the beginning there was much shyness Do you think they will stay in contact with each other? I hope so Everything that Pere and I had to teach them from a lifetime of molecular orbital lore For me, music is the next best thing to science for bringing people together Half of the applicants were women He said: “They grew part of me that week.”  Did the participants risk attack or denunciation by taking part in the workshop? Part of me says there was no risk; part says, be realistic Hoffmann taught the first of his workshops, called ‘Chemistry Bonds’, in Jordans ancient city of Petra in January How much chemistry did they learn? A lot I asked each participant to bring a favourite piece of music I learned in Malta how little communication there actually is between scientists from the various Arab countries I was touched that one of the Jordanians called the conference coordinator, Vanessa Buisson, to find out if the Israelis had got home alright despite a bombing in Tel Aviv on the day of departure I was touched when at the end of the course, one student thanked me for “making chemistry come alive for me again” I wasnt going to go without wine! Was religion an issue? No, not really, but it surprised me how little the participants knew about each others customs It will serve them well Lets be frank: the risks were personal, perhaps greatest to the three Israelis and the American organizers Most were from Muslim backgrounds, a few were Jewish and there was at least one Christian My dream is to convince a Saudi prince to host a workshop for everyone in the region — for his young people, Israelis and others. ‘Chemistry bonds’ — is a metaphor intended? Atoms bond because they dont have a choice One day we all cooked a Jordanian meal together; on another, we all trekked through the pink sandstone monuments of Petra One of the Jewish students ate kosher, which led to illuminating discussion of dietary rites Only one or two will become theoretical chemists Political relations in the Middle East are very tense Several of the participants said something changed in them that week So how could chemistry possibly build trust? Pere Alemany, my co-teacher from the University of Barcelona, and I worked those young people hard So there was a certain shared suffering, and victory over that, on their part Some drank it, some did not Some were secular, some religious Thats not bad; good chemistry comes from that bonding The 13 attendees hailed from Jordan, Palestine, Saudi Arabia and Syria, as well as from Israel and Iran The bonds that formed are strong; I feel that The group I brought together could be future leaders of science The idea stemmed from a small international chemistry meeting in Malta in 2003, which was attended by many chemists from Arab countries The rest will use their learning in whatever they do They spent time with Israelis; some people back home dont like that This is my small contribution to peace, but Im not romantic or do-gooding about it This Nobel laureate from Cornell University, New York, has organized a series of three chemistry workshops for young scientists from the Middle East, with the aim of forging trust and friendship between participants Was gender an issue? Only in that it showed the ignorance we have in the West We could teach more We will help them, but I think it will come naturally Where will the next two workshops take place? newsad; In the next 18 months, Harvards George Whitesides will lead one in Egypt on nanochemistry and Harry Gray from the California Institute of Technology will teach another on bioinorganic chemistry in Qatar
 DNA microarray studies have shown that hundreds of genes are transcribed periodically during the mitotic cell cycle of humans , budding yeast , fission yeast and the plant Arabidopsis thaliana  Here we show that despite the fact the protein complexes involved in this process are largely the same among all eukaryotes, their regulation has evolved considerably Moreover, we show that these changes in transcriptional regulation have co-evolved with post-translational control independently in several lineages; loss or gain of cell-cycle-regulated transcription of specific genes is often mirrored by changes in phosphorylation of the proteins that they encode Our comparative analysis of several large-scale data sets reveals that although the regulated subunits of each protein complex are expressed just before its time of action, the identity of the periodically expressed proteins differs significantly between organisms Our results indicate that many different solutions have evolved for assembling the same molecular machines at the right time during the cell cycle, involving both transcriptional and post-translational layers that jointly control the dynamics of biological systems. A set of human phosphoproteins (not CDK-specific) was compiled from high-throughput mass-spectrometry studies  Correlation analyses of transcriptional regulation and phosphorylation Lists of human and budding yeast CDK phosphoproteins were compiled from the Phospho.ELM database and large-scale screens  Curation of complexes The composition of the individual complexes in Fig. 2 was based on literature and annotations from the relevant model organisms databases (SGD for budding yeast; GeneDB for fission yeast; Ensembl, Uniprot and Reactome for human) Details on the annotations can be found in Supplementary Information and at http://www.cbs.dtu.dk/cellcycle  For each of these sets of phosphoproteins, Fishers exact test was used to assess the statistical significance of the correlation between transcriptional regulation and phosphorylation. For each periodic gene, the time of peak expression was calculated, and the time scales were made comparable across organisms through time warping (see Supplementary Information ) Identification of orthologous proteins All-against-all Smith–Waterman similarities were calculated, and the proteins were grouped into orthologous groups using a triangular linkage clustering similar to the original COG (Clusters of Orthologous Groups) procedure (see Supplementary Information ) In addition, CDK substrates were predicted from protein sequences using the NetPhosK cdk5 method , which we benchmarked on known CDK substrates (see Supplementary Information ) Methods Analysis of microarray expression data Periodically expressed genes were identified by applying the same computational method to 19 cell-cycle microarray timecourses , and the results were benchmarked against genes for which other evidence indicates periodic expression The quality of these orthologous groups was assessed on the basis of the manually assigned orthology relationships for DNA replication complexes in Fig. 2  Also, only two subunits of the pre-replication complex are subject to transcriptional regulation, namely cdt1 and cdc18, which when overexpressed can induce re-replication  Although microarray expression studies from more closely related model organisms will be needed to investigate this globally, we show that changes in regulation can take place in the order of only a hundred million years (see examples in Supplementary Information ), implying that even within vertebrates regulation might differ considerably. Although the true overlap might be slightly better than is shown in Fig. 1 , the large differences cannot be explained by the quality of the gene expression data or the orthology analysis (see Supplementary Information ) Although these data are too weak to prove co-evolution, the results show that targeted degradation preferentially affects the transcriptionally regulated proteins in all four organisms (see Supplementary Information ) Despite normalizations to correct for organism-specific differences in the relative lengths of the cell-cycle phases (see Supplementary Information ), we found that the timing of expression is only conserved for 42% of the orthologous groups (allowing a relaxed 20% tolerance, Fig. 1 ) Dynamic proteins are thus often controlled through both mechanisms ( Fig. 2 ), although the identity of the dynamic proteins varies greatly between organisms ( Fig. 1 ) Even among this subset we found that periodicity is poorly conserved across the four organisms ( Fig. 1 ), meaning that although the protein sequences are conserved through evolution, their transcriptional regulation during the cell cycle is not Examples of the latter include the human RRM2 subunit of the RNR complex and the budding yeast DPB2 subunit of DNA polymerase-ɛ ( Fig. 2 ), which are both dynamic and phosphorylated whereas their orthologues are neither (see Supplementary Information ) For example, both the sister chromatid cohesion complex and securin, which prevents separase from cleaving cohesin, are expressed during mitosis in human and fission yeast but at the G1/S transition in budding yeast For other proteins, transcriptional regulation might be sufficient for activation, whereas phosphorylation might cause inactivation, for example, by targeting them for degradation For the genes for which periodic expression per se is conserved, we compared whether their expression peaks during the same phase of the cell cycle in each organism ( Fig. 1 ) Furthermore, the differences in temporal expression are in remarkable agreement with current knowledge about the order and timing of assembly of the individual complexes that are involved in DNA replication and mitosis , and even provides new insight into the regulation of these complexes However, our analysis also shows that the identity of the dynamic subunits within each complex has changed during evolution However, protein complexes that are involved in the cell cycle often comprise a mixture of static (constitutively expressed) and dynamic (periodically expressed) subunits, the latter being expressed just before the stage of the cell cycle in which the complex is active (‘just-in-time assembly’ of complexes)  In fission yeast, it is expressed as early as M phase ( Fig. 2 ) owing to the very short G1 phase  In humans, the pre-replication complex is regulated through many more subunits In this regard, we have noted that periodically expressed S. cerevisiae proteins tend also to be phosphorylated  It is tempting to speculate on the driving force that leads to the co-evolution of transcriptional and post-translational regulation, which we could prove in three of the four separate lineages studied Many more details on individual complexes are presented in Supplementary Information  Notably, this co-evolution is supported by all pairwise organism comparisons and by both experimental data and sequence-based predictions Of these groups, 381 contain orthologues from all four organisms and have at least one periodic member Only five orthologous groups are periodic in all four organism, namely a group of mitotic cyclins, three groups of histone proteins, and subunits of the ribonucleotide-diphosphate reductase (RNR) complex Our current results raise the intriguing possibility that all three levels of regulation have co-evolved Requiring both transcription and phosphorylation of the same key components might increase robustness to prevent accidental activation Sequence-based predictions provide yet another complementary, unbiased source of CDK phosphorylation sites, which supports the experimental results and shows that the correlation holds true also in fission yeast ( Fig. 3a ) Surprisingly, MCM4 is expressed in M phase, whereas the rest of the dynamic subunits appear in G1/S, which has to our knowledge never been described before The agreement between the timing of transcription and the timing of action of the protein products is not necessarily to be expected, as phosphorylation is at least as important as transcription for regulating cell-cycle complexes The complete list of orthologous groups with periodic members and their peak times is available at http://www.cbs.dtu.dk/cellcycle  The differences in temporal expression of individual, orthologous genes can thus be understood when viewed at the level of protein complexes and cellular processes ( Fig. 2 ) The distinct transcriptional regulation of MCM4 is intriguing, considering that phosphorylation of this subunit regulates the chromatin association of the entire Mcm2–7 complex  The fact that CDK substrates are enriched among the dynamic proteins in three organisms could be due to a core set of dynamic orthologues that are phosphorylated by CDKs in all organisms or, alternatively, it could reflect that loss or gain of transcriptional regulation of a gene is correlated with loss or gain of phosphorylation of the corresponding protein The genes for which periodicity is highly conserved thus encode either key regulators of the cell cycle or components that are needed for synthesizing the building blocks of new DNA and chromatin The regulation of the DNA replication machinery has also evolved considerably The same evolutionary changes in timing are observed for Pds5 and shugoshin, supporting the recent suggestions that Pds5 is a fifth subunit of cohesin and that shugoshin might help to protect mitotic cohesin from degradation (see Supplementary Information )  The three additional orthologous groups that are periodic in all organisms except A. thaliana consist of the CDC20 recognition subunit of the anaphase-promoting complex/cyclosome (APC/C), the pre-replication complex component CDC6, and the sister chromatid cohesion protein MCD1 The widespread differences in both identity and timing of the transcriptionally regulated genes are at first glance surprising, considering the high degree of conservation of the core cell-cycle machinery These gene lists are more conservative than those originally proposed, but achieve better sensitivity (estimated to be 80–90% for human and the two yeasts, but only 50% in the plant; see Supplementary Information ) They clearly indicate that although the same general underlying principles, namely just-in-time assembly and multi-layer regulation of functional modules, are widely conserved in eukaryotes, the detailed regulation of individual genes and proteins varies greatly and thus generally cannot be inferred from distantly related organisms This comparison revealed highly significant over-representation of dynamic proteins among human cyclin-dependent kinase (CDK) substrates identified by small-scale experiments , among human phosphoproteins identified by mass-spectrometry studies, and among S. cerevisiae Cdc28 substrates identified in at least one of two systematic screens  This conserved set includes 550 of the total set of 2,100 periodically expressed genes, implying that most of the periodically expressed genes do not have orthologues in all four organisms This is compatible with the results of earlier comparisons of periodically expressed genes from two or three organisms  This raises the question of how fast regulation evolves and how closely related two organisms have to be for regulatory details to be transferable To assess the evolutionary significance of this correlation, we applied two proteome-wide statistical tests to several independent sets of known and predicted phosphoproteins from each organism ( Fig. 3 ) To confirm the consistency of the periodic expression of complex subunits within each organism, and to test a previously stated hypothesis that the just-in-time assembly principle allows the identity of the regulated subunits to change during evolution , we carefully annotated the composition of some of the best-understood cell-cycle complexes in human and the two yeasts ( Fig. 2 ; A. thaliana was omitted owing to the poor sensitivity of the expression data and the lack of knowledge on complex composition) To generalize this observation, we annotated the complexes in Fig. 2 with information on phosphorylation by cyclin-dependent kinases, and found that the dynamic subunits are three times as likely to be targeted by phosphorylation as the static ones ( P 10 -3 ) To obtain comparable sets of transcriptionally regulated genes from distantly related eukaryotes, we reanalysed the existing cell-cycle gene expression data and found 600 periodically expressed genes in Homo sapiens , 600 in Saccharomyces cerevisiae , 500 in Schizosaccharomyces pombe and 400 in Arabidopsis thaliana  Together, our results provide a first global view of the evolutionary dynamics of the transcriptional and post-translational regulation of a large and complex biological system Unfortunately, experimental data on cell-cycle-regulated proteolysis is scarce, and we therefore applied the two statistical tests described above to sets of proteins whose sequences contain putative degradation signals We first compared the phosphorylation of dynamic and static proteins from each organism ( Fig. 3a ) We further assigned genes with a common descent to orthologous groups, of which we estimate at least 80% to contain the correct set of functionally equivalent genes (see Supplementary Information ) We have previously found in S. cerevisiae that, like CDK phosphorylation, cell-cycle-regulated proteolysis preferentially affects the dynamic proteins When mapping periodically expressed genes onto equivalent protein complexes, it becomes obvious that the dynamic subunits of individual complexes are consistently co-expressed, and that the timing of expression is similar for complexes that are involved in the same cellular process within each organism but differs between organisms ( Fig. 2 ) Within each organism, we therefore compared the dynamic proteins with static orthologues to static proteins with dynamic orthologues ( Fig. 3b ) and found that transcriptional regulation and phosphorylation have co-evolved in the three organisms studied
 Ah, yes! I want the match to start An expectant silence is building in the stadium And the algorithms for realistic decision-making in sports had existed in computer games for decades As a child, my creator met the real Pelé, the greatest soccer player of the previous century Based on variations of natural antibodies, they could be engineered to catalyse any aspect of biological function, and so enhance human performance Besides, once the robosports got under way, most sports fans really couldnt tell the difference: robot technology was that good But I listen, always, and, mostly, I understand But the roboplayers arent really smart But things are different today By the late 2040s, doping in sport was rife Climb inside my circuits Climb inside my thoughts Come join me as I bounce about the grassy soccer pitch of the Camp Nou, Barcelona David Beckyham was given a cockney accent and programmed to say ‘at the end of the day’ three times every sentence Eventually, with no simple solution to the fiasco in sight, the insurers reneged on all their sports contracts Female fans were also quietly impressed He had been building a secret army of sportsbots, one to represent each great competitor in history He had foreseen He has filled me with pinprick ears and eyes but given me no movable parts or mouth. “Youre perfect,” he often says, while tinkering in his workshop. “You listen and watch but you never tell He knows I like nothing more than to be passed around the pitch He says its because he has no real friends He unveiled his robotic doppelgangers to the world He was prepared Hes a genius that no one understands Hes lonely His lofty status and his perceived probity allow him to ensure Im used in certain soccer matches How were they going to fill the back pages of the newspapers? Chess? Lawn bowls? But my creator was pleased I am the culmination of my masters plans: an artificially intelligent football I know this because my creator tells me everything I wait impatiently in the centre circle, trapped beneath the right studded boot of the Pelé Mark VII Im excited but I also feel nervous It was illegal to participate in professional sports without a protective compensation policy: no one else could stand the litigation Just as with the natural antibodies of the immune system, an almost infinite array of catalytic variants could be generated Last night in his workshop, my master tampered with one of the synthetic strips on my surface and inserted a micro-device underneath. “With this,” he said, leaning close to me, “I can remotely manipulate your flight-path during the game.”  “Isnt that cheating?” he then said, speaking on my behalf. “Why of course, yes!” he answered, laughing. “You wont tell anyone will you?”  No, I never tell. Many of the catalytic antibodies overworked the body, stretching the limits of biological endurance No insurance meant no sport No, you never tell.”  My creators notoriety came not just from his genius but also from his prescience Not like me Ordinary citizens were in uproar, and so were the media People laughed at first Players were increasingly picking up career-ending injuries and demanding compensation So by the time the Antidoping Federation had developed an assay to detect one catalytic antibody the dopers had already designed another with the same function — but with a different structure to escape detection Some of the robots in once male-dominated sports were modelled on the female physique: the soccerbot David Beckyham, the basketbot, Michelle Jordan, even the basebot, Babe Ruth. “This time around he really is a babe!” my master often jokes Sports veterans (and their dwindling bank accounts) were glad to have been immortalized in a new form That was the beginning of his grand design The Antidoping Federation had been rendered impotent The media didnt: they seized the moment, hailing the robots as the solution, at least until the honour of human sport could be reclaimed The media werent the only ones pleased by this solution The message was clear: no more cheating The robots could even act like humans in the pre- and post-match interviews The robots were programmed with the skill levels of the sporting heroes on whom they had been modelled There are a million fans in the stadium, all anticipating the start of the match, roaring down from the tiers that stretch to the same height as the Eiffel tower They were a dopers dream They were desperate Winning at any cost was the only maxim, and catalytic antibodies were the tonic With no easy way of proving whether or not a player had been doped with catalytic antibodies at the time of injury, the insurers were more reluctant than ever to pay up Yet it was the insurers who were the main problem
 Arising from: T However, this claim was dependent on a sequence analysis using databases that inappropriately label β-propeller sequences as PQQ-binding motifs Kasahara T Kato Nature 422 , 832 ( 2003 ) ; see also communication from Rucker et al .; Kasahara et al . reply The announcement by Kasahara and Kato of a new redox-cofactor vitamin for mammals , pyrroloquinoline quinone (PQQ), was based on their claim that an enzyme, predicted to be involved in mouse lysine metabolism, is a PQQ-dependent dehydrogenase What the evidence actually suggests is that the enzyme is an interesting novel protein that has a seven-bladed β-propeller structure, but there is nothing to indicate that it is a PQQ-dependent dehydrogenase. As would be expected from the method used by Kasahara and Kato in searching for the LYS2 analogue , the U26 sequence contained no carboxy-terminal NAD(P)-binding domain However, this conclusion is based on the misconception that the Smart and Pfam databases are able to recognize PQQ-binding sites even when, as in this case, there is negligible sequence similarity to known PQQ-dependent enzymes In bacteria, PQQ is an essential cofactor for various dehydrogenase enzymes known as quinoproteins  In the course of a study on bipolar disorder (see http://www.brain.riken.go.jp/labs/mdmd/pqq/index-e.html ), these authors cloned a mouse gene encoding a protein (U26) with some similarity to yeast aminoadipate reductase (LYS2) ; they proposed that mouse U26 could be involved in one of the important first steps in the degradation of dietary lysine, acting as a PQQ-dependent adipic 6-semialdehyde dehydrogenase Nutritional experiments have indicated some (unknown) metabolic or nutritional role for PQQ in mammals , but it cannot be accepted as a vitamin until it is proved to be required by an enzyme as an essential cofactor; this is the key evidence that Kasahara and Kato claim to have provided The propeller fold is not related in any direct way to PQQ binding , and these folds are found in many other types of protein, which have extreme functional and phylogenetic diversity  The ‘sites’ wrongly identified by the databases do not represent PQQ-binding sites but represent the β-sheets that form the ‘blades’ of the ‘propeller fold’ that happens to be a feature of all PQQ-dependent dehydrogenases, whose main structure is a superbarrel made up of either six or eight ‘propeller blades’ ( Fig. 1 ) They noted from sequence analysis that U26 has an alternative carboxy-terminal domain that contains seven repeats of the ‘PQQ-binding motif’ that is conserved among bacterial PQQ-dependent dehydrogenase enzymes, leading to the conclusion that mouse U26 could be a PQQ-dependent dehydrogenase We contend that there is still no compelling evidence for a PQQ-dependent enzyme in the mouse and that the authors announcement of a new vitamin was therefore premature.
 Because the production of ribosomes is a major metabolic activity, the function of the nucleolus is tightly linked to cell growth and proliferation, and recent data suggest that the nucleolus also plays an important role in cell-cycle regulation, senescence and stress responses  Here, using mass-spectrometry-based organellar proteomics and stable isotope labelling , we perform a quantitative analysis of the proteome of human nucleoli In vivo fluorescent imaging techniques are directly compared to endogenous protein changes measured by proteomics Proteins that are stably associated, such as RNA polymerase I subunits and small nuclear ribonucleoprotein particle complexes, exit from or accumulate in the nucleolus with similar kinetics, whereas protein components of the large and small ribosomal subunits leave the nucleolus with markedly different kinetics The data establish a quantitative proteomic approach for the temporal characterization of protein flux through cellular organelles and demonstrate that the nucleolar proteome changes significantly over time in response to changes in cellular growth conditions. The nucleolus is a key organelle that coordinates the synthesis and assembly of ribosomal subunits and forms in the nucleus around the repeated ribosomal gene clusters We characterize the flux of 489 endogenous nucleolar proteins in response to three different metabolic inhibitors that each affect nucleolar morphology Actinomycin D (5 mg ml -1 stock solution in EtOH) was added at a final concentration of 1 µg ml -1 to Arg6- and Arg10-labelled cells and incubated for 20 and 80 min, respectively After recording the first three time points, actinomycin D was added and cells were imaged for 2–3 h ( SoftWoRx image processing software , Applied Precision ) Cells were imaged 60 × (NA 1.4) Plan Apochromat objective  Experiments with a reversed database indicated that, under these conditions, proteins with two matching peptides were identified with a false positive rate of less than 0.1 per cent For the QSTAR-XL, precursor ion spectra ( m / z 350–1,500) and product ion spectra ( m / z 70–1,500) of the four most intense ions were collected for 1 s Fuller-Pace) In control experiments an equal volume of ethanol was added instead of actinomycin D In independent experiments, cells were treated with actinomycin D to give a total of nine time points, and with the proteasome inhibitor MG132 (10 µM for 1, 4, 8 and 16 h) and the polymerase II inhibitor DRB (25 µg ml -1 for 2 h and mock treated) Isolated nucleolar proteins were separated on NuPAGE 4–12% Bis-Tris gel and excised into 16–20 slices Janknecht), which recognized both the YFP-tagged and untagged forms of p68 ( Fig. 4a ) and an antibody against fibrillarin (gift from F Live cell imaging HeLa YFP–p68 cells , HeLa YFP–FIB cells and HeLa YFP–RPL27 cells were cultured in Willco thin glass-bottomed microwell dishes ( Intracel ), mounted on a Deltavision Spectris microscope ( Applied Precision ) fitted in a transparent environmental chamber ( Solent Scientific ) Mass spectrometry and data analysis Mass spectrometric analysis was performed by liquid chromatography ( Agilent HP1100 ) combined with tandem mass spectrometry (LC MS/MS) using a quadrupole time-of-flight instrument ( QSTAR-XL , ABI-MDS-Sciex ) or a linear ion-trap Fourier-transform ion-cyclotron resonance mass spectrometer ( LTQ-FT-ICR , Thermo-Finnigan ) Methods Isolation of stable isotope-labelled nucleolar proteins Cells were grown for at least five cell divisions in l -arginine-, l -arginine 13 C 6 14 N 4 -, or l -arginine 13 C 6 15 N 4 -labelling media before drug treatment  Microscopy and image handling was performed using a Deltavision Spectris microscope as described above. MS-Quant ( http://msquant.sourceforge.net/ ), an in-house developed software program was used to evaluate the certainty in peptide identification and in peptide abundance ratio Normalized inverted ratios were calculated for ratios smaller than one [1 - (1/ x )] Nucleoli or nuclei (see Fig. 3 ) were outlined manually and five nucleoli/nuclei were measured from two independent experiments Nucleoli were isolated from HeLa cells or from a 1:1:1 mixture of Arg0, Arg6 and Arg10 HeLa YFP–p68 cells as previously described ( http://www.lamondlab.com/f5nucleolarprotocol.htm ) Peptides resulting from in-gel digestion were extracted from the gel pieces, desalted and concentrated on reverse-phase C18 tips, and eluted into 96-well plates for automated mass spectrometry analysis Protein ratios were calculated for each arginine-containing peptide as the peak area ratio of Arg6/Arg0 and Arg10/Arg0 of each single scan mass spectrum Stringent criteria were required for protein identification in the International Protein Index database using the Mascot program ( Matrix Science ) and LTQ-FT-ICR data: at least two matching peptides per protein, a mass accuracy within 3 p.p.m. (average absolute peptide mass accuracy was 0.7 p.p.m.), a Mascot score for individual peptides of better than 20, and a delta score of better than 5 The experiment was repeated with drug treatment for 40 and 160 min of Arg6- and Arg10-labelled cells, respectively, to give a total of five time points with untreated Arg0 cells as a common zero time point The incubated nucleoli were spotted on a poly-L-lysine coated slide ( BDH ) then fixed in 2% paraformaldehyde (5 min, room temperature) and permeabilized in 0.5% Triton X-100 (10 min, room temperature), before being immunolabelled with anti-BrdU antibody ( Sigma Chemicals ), FITC-conjugated anti-mouse immunoglobulin ( Jacksons lab ) and counterstained with Pyronin Y ( Sigma Chemicals ) The ions were simultaneously fragmented in the linear ion trap with a normalized collision energy setting of 27% and a target value of 2,000 The LTQ-FT-ICR instrument was operated in the data-dependent mode to acquire high-resolution precursor ion spectra ( m / z 300–1,500, R = 25,000 and ion accumulation to a target value of 10,000,000) in the ICR cell The peptide ratios were averaged for all arginine-containing peptides sequenced for each protein and normalized to zero ( x - 1) The three most intense ions were sequentially isolated for accurate mass measurements by selected ion monitoring (SIM) scans (10 Da mass window, R = 50,000, and a target accumulation value of 50,000) Transcription assays Briefly, isolated nucleoli were incubated with run-on buffer (100 mM KC1, 50 mM Tris–HCl pH 7.4, 5 mM MgC1 2 , 0.5 mM EGTA, 0.5 mM ATP, 0.5 mM CTP, 0.5 mM GTP and 0.2 mM Br-UTP ( Sigma Chemicals )) for 20 min at room temperature  Transcription in intact HeLa cells was detected as reported  Twelve optical sections separated by 0.5 µm were recorded for each field and each exposure lasted for 0.05 s Western blots were performed with an antibody against p68 (gift from R A comparison of the increasing fraction of the human homologues of yeast nucleolar proteins found in each separate determination of the HeLa cell nucleolar proteome during the past two years suggests that detection levels are approaching saturation coverage, at least with the technology currently available ( Fig. 1b ) A decrease in RNA synthesis levels, assayed by Br-UTP incorporation, was detected within 15–30 min, reflecting the time required for drug uptake by the cells (data not shown) A HeLa cell line was metabolically labelled with either normal arginine ( 12 C 6 14 N 4 -Arg, termed here Arg0), carbon substituted arginine ( 13 C 6 14 N 4 -Arg, termed here Arg6) or carbon plus nitrogen substituted arginine ( 13 C 6 15 N 4 -Arg, termed here Arg10) respectively A SILAC experiment was performed on HeLa YFP–p68 cells treated for up to 16 h with MG132 at a final concentration of 10 µM A similar close agreement of fluorescence and SILAC data was also seen for two additional cell lines analysed that stably express either YFP-tagged fibrillarin ( Fig. 3d ) or YFP-tagged ribosomal protein L27 ( Fig. 3e ) A subset of proteins accumulated within nucleoli after transcription had been arrested, including all 11 proteins we identified previously to accumulate in nucleoli after actinomycin D treatment  Although it is possible that some changes in protein levels could occur after blocking transcription, we dont expect this to have a major effect on nucleolar proteome dynamics during the 2 h time course of transcription inhibition tested because most mammalian messenger RNAs have a half-life greater than 6 h (ref. 20 ) Analysis of isolated nucleoli by electron microscopy shows that they remain intact and preserve the internal morphology seen in situ ( Supplementary Fig. 1a, b ) Approximately 11,130 unique peptide sequences were unambiguously matched to human genes with an average mass accuracy of 0.7 p.p.m. (see Supplementary Table 1 ) As illustrated for all three proteins tested, the changes in protein levels in nucleoli result primarily from redistribution Because every arginine-containing tryptic peptide occurs in three isotopic forms, the intensities of these three mass spectrometry peaks directly reveal the relative ratios of the corresponding protein in the nucleolus at each of the three time points Bioinformatic classification ( Fig. 1a ) demonstrates functional diversity of the nucleolar proteome and the presence of approximately one-third of proteins with no previous functional information Different nucleolar factors show major differences in their kinetics, of either decrease or accumulation Factors depleted from nucleoli after actinomycin D treatment included ribosomal proteins, RNA processing factors, exosome components and RNA polymerase I ( Fig. 4a ) Factors known to be depleted from the nucleolus upon transcription inhibition (for example, PTB, Ki-67, GU and NOH61) were also found to decrease in our data set ( Fig. 4b ) Figure 2b , c shows representative mass spectra for peptides derived from p68 Figure 4h shows that changes in protein levels brought about by either recruitment to or loss from an organelle can be visualized and analysed by hierarchical clustering in a similar manner to the visualization of expression changes in microarray experiments  Finally, we treated cells with the proteasome inhibitor MG132, which affects nucleolar morphology but does not directly inhibit RNA polymerase activity  For example, separate nucleolar members of the DEAD box helicase family, which are likely to have distinct and non-overlapping functions in the nucleolus, respond to transcription inhibition with different kinetics ( Fig. 4c ) Further experiments will therefore be focused on the cause and effect of the relocalization of individual nucleolar proteins under these perturbations, and how these redistributions can orchestrate the regulation of cell growth and proliferation Furthermore, functional and/or structural protein complexes such as the snRNPs, Pol I subunits and exosome cluster in tight regions (indicated in the rightmost column) Groups of strongly recruited and depleted proteins clearly show the same pattern in both experiments (top and bottom clusters in Fig. 4h ) HeLa cell nucleoli were isolated in high purity by density gradient fractionation  However, DRB caused fewer proteins to decrease in nucleolar abundance Importantly, both show a similar kinetic response, indicating that the presence of the YFP tag does not significantly alter the dynamic behaviour of p68 In addition, it was possible to resolve separate peptides from the YFP-tagged p68 and the endogenous untagged p68 proteins, allowing a comparison of their kinetic profiles in response to actinomycin D ( Fig. 3c ) In contrast, separate subunits of RNA polymerase I, which physically associate in a stable protein complex, each leave nucleoli at an almost identical rate ( Fig. 4d ) In our previous study , ∼58% of the yeast homologues were present in the proteome of 271 human factors Inspection of the graph indicates reproducibility between patterns of the five and nine time point experiments Instead, transcription inhibition leads to a more subtle redistribution of nuclear proteins, and the partition of proteins between the nucleolus and nucleoplasm may reflect the general physiological status of the cell It will be important to study the dynamic nature of other subcellular structures, compartments and organelles because it is likely that their protein compositions can also vary extensively under different growth and/or metabolic conditions MG132 caused a striking increase in the levels of ribosomal proteins in the isolated nucleoli, particularly in the case of small ribosomal subunit proteins, which contrasts with the general decrease in ribosomal proteins in nucleoli caused by actinomycin D Multiple protein components of the exosome and the RNase P complex each also showed coordinate kinetics ( Fig. 4e ) Next, equal amounts of cells from each time point were mixed and nucleoli isolated directly from this mixed cell pool ( Fig. 2a ) Nonetheless, there remain some proteins previously reported to reside in the nucleolus that were not detected, such as the transcription factor RRN3 (ref. 11 ) and gemin 4 (ref. 12 ), which is a component of the survival of motor neuron (SMN) complex Notably, the large and small ribosomal subunit proteins and components of the exosome remained relatively unchanged after DRB treatment Note that many proteins that stably copurify with nucleoli are also present at other cellular locations and some only accumulate transiently in nucleoli Nucleolar proteins were fractionated and analysed by LC MS/MS as before Out of the 142 yeast nucleolar proteins that have at least one human homologue, 124 are found in the updated nucleolar proteome (87%) Possible reasons for their continued absence from the observed proteome could include that they are present in exceedingly small amounts, or are not associated sufficiently stably with nucleoli to be isolated using the purification methods available Protein mixtures from individual one-dimensional gel slices were in gel digested with either trypsin or endoproteinase Lys-C Quantitative proteomics showed that MG132 also caused a major change in the nucleolar proteome, but largely affected a different set of proteins as compared with inhibitors of transcription ( Fig. 4j ) Recent light microscopy studies, analysing nuclear fluorescent fusion proteins using techniques such as fluorescence recovery after photobleaching (FRAP) or fluorescence loss in photobleaching (FLIP), have revealed the high mobility of many nuclear factors and their often rapid exchange between nuclear bodies and the surrounding nucleoplasm  Regulatory proteins in the nucleolar proteome included casein kinase II and the phosphatase PP1, which may have roles in nucleolar regulation , and protein kinases CDK2, CDK7, CDK9, CDC2L5, Cip1/p21 interacting protein and Aurora B, which are involved in controlling cell-cycle progression Remarkably, the level of some proteins increased up to tenfold ( Fig. 4a ) Similar relative changes in nucleolar p68 levels were measured by both techniques ( Fig. 3c and other data not shown) Similarly, separate small nuclear ribonucleoprotein particle (snRNP) proteins accumulate within nucleoli at identical rates, consistent with their association in a stable RNP complex Tandem mass spectra were searched in the human sequence database, considering only peptides conforming to full trypsin or Lys-C specificity and whose mass matched the calculated mass within 3 p.p.m. (see Methods) Temporal studies have uncovered evidence for maturation pathways in which nuclear factors can transit between different nuclear bodies in a defined sequence  The cells are identical in all respects except that peptides derived after proteolytic digestion of the proteins can be distinguished in the mass spectrometer by their offsets of either zero, six or ten mass units The data indicate that approximately 90% of the yeast nucleolar proteins with human homologues are also nucleolar components in HeLa cells and that the nucleolus is highly conserved throughout the eukaryotic kingdom The data set from all our nucleolar mass spectrometry analyses defines an updated group of 692 proteins that reproducibly copurify with human nucleoli (also available in a searchable online database at http://www.lamondlab.com/NOPdb/ ) The data show good reproducibility between the two experiments ( Fig. 4 and see below) The dynamic profile of the human homologues of the yeast small-subunit (SSU) processome , which is involved in the biogenesis of the 40S preribosomal subunit, displayed some of the most marked changes, decreasing by 10–15-fold in abundance within nucleoli after actinomycin D treatment ( Fig. 4f ) The increased peak heights for the 20 (Arg6) and 80 (Arg10) minute time points show that p68 is recruited to the nucleolus ( Fig. 2d ) The inhibition of transcription caused by actinomycin D treatment was confirmed by 5-fluorouridine incorporation analysis of control and actinomycin D-treated HeLa cells ( Supplementary Fig. 1e, f ) The isolated nucleoli retain transcriptional activity, as determined by 5-bromo-UTP (Br-UTP) incorporation ( Supplementary Fig. 1d ) The kinetic experiments were performed using the HeLa YFP–p68 cell line , allowing a direct comparison of changes in the level of YFP–p68 determined either by this proteomic analysis, or in vivo by digital fluorescence microscopy ( Fig. 3 ) The preparations are homogeneous with virtually all particles visible by electron microscopy corresponding to nucleoli ( Supplementary Fig. 1c and other data not shown) The previously described effects of cellular growth and environmental conditions on nucleolar morphology and ribosome synthesis are reflected here by the large-scale and specific changes in the nucleolar proteome in response to distinct metabolic inhibitors The protein components of the large and small ribosomal subunits leave nucleoli with markedly different kinetics ( Fig. 4g ), consistent with previous reports that biogenesis and nuclear export of the large and small ribosomal subunits occur independently in budding yeast  The proteins identified included a minor fraction of potential contaminants, which have been included for completeness but are marked in Supplementary Table 1  The reason for this unexpected effect is unclear but may reflect a novel regulatory link between ribosome biogenesis and protein degradation pathways, acting to balance rates of protein synthesis and breakdown The relative levels of all 489 factors were therefore quantified in two large-scale experiments, measured at five or nine separate time points after inhibiting transcription with actinomycin D ( Supplementary Table 2 ) The resulting peptide mixtures were analysed in several runs of nanoscale liquid chromatography—tandem mass spectrometry (LC MS/MS) on an ion trap—Fourier Transform mass spectrometer, capable of very high mass accuracy and of sequencing several peptides per second (see Methods) The steady-state levels of many nucleolar proteins decreased to various extents on actinomycin D treatment The three HeLa cell populations were treated with actinomycin D at a final concentration of 1 µg ml -1 , which inhibits transcription by RNA polymerase I, II and III for different lengths of time The variation in kinetics for different ribosomal proteins probably occurs because ribosome subunit assembly is a complex, multi-step process and not all the factors assemble on the rRNAs simultaneously There was no overall change in the total cellular YFP–p68 fluorescence level following actinomycin D treatment, demonstrating that the increased nucleolar p68 fluorescence results from the intranuclear redistribution of p68 ( Fig. 3c ) These data are consistent with RNA polymerase I proteins moving coordinately, either as part of stable complexes or through the actions of common receptors These data indicate that at least a subset of the processome components (homologues of Sof1, Upt11, Upt6, Upt7 and Upt14) are strongly dependent upon rRNA expression for their accumulation within nucleoli These data provide a more detailed and quantitative insight into how the cellular response to environmental stress and growth conditions affect the nucleolus These peptides were used to identify proteins in the purified nucleoli with high stringency, requiring at least two high-scoring peptides per protein (see Supplementary Table 1 ) This probably reflects the export of assembled ribosomal subunits taking place without ongoing RNA polymerase I activity to synthesize new ribosomal RNA substrate, and suggests that the association of many components with the nucleolus is dependent on ribosome subunit synthesis This result suggests that the nucleolus is not a simple ribosome synthesis machine that progressively breaks down in the absence of transcription This study establishes a quantitative approach for the high-throughput characterization of the flux of endogenous proteins through cellular organelles, demonstrated here for the nucleolus This supports the view that the decrease in ribosomal proteins and some other factors following inhibition of RNA polymerase I activity is caused, at least in part, by the export of ribosome subunits in the absence of new rRNA synthesis This ‘triple encoding’ procedure allows three cell states to be measured in one experiment  Thus the data do not support the view that the nucleolus is a transient structure formed only as a result of ongoing rRNA synthesis and indicate that at least a core of the nucleolar proteins remain associated in the absence of nascent rRNA transcription and ribosomal subunit assembly Thus, the combination of mass spectrometry and fluorescence kinetic data measurements offers a powerful new way to validate these cell lines as model systems for in vivo studies of nucleolar dynamics To evaluate in a comprehensive and quantitative approach how dynamic the nucleolar proteome may be, we performed a series of proteomic studies on nucleoli isolated either from control cells, or from cells treated with drugs that inhibit transcription or protein degradation To reduce false positives caused by random impurities, we independently prepared nucleoli in our two laboratories and only included proteins identified in both preparations in the final proteome Treatment with 5,6-dichlorobenzimidazole riboside (DRB), which selectively inhibits RNA polymerase II but not polymerase I (ref. 24 ), resulted in nucleolar accumulation of a similar set of proteins to those seen in actinomycin D treatment ( Fig. 4i and other data not shown) Typically, several peptides per protein are quantified (see Methods and Supplementary Table 2 ) Under these conditions, we estimate a false positive rate for protein identification below 0.1% (see Methods) Unlike cytosolic organelles, nuclear bodies are not membrane bound and the principles of their organization and assembly are not well understood  We also observed key regulators of p53, such as p14ARF, and the Ser/Thr protein kinases VRK1 and ATM, which were reported to be sequestered in the nucleolus We compared this expanded nucleolar proteome with published information on proteins localized to the nucleolus in budding yeast from a recent large-scale study of yeast protein localization using green fluorescent protein (GFP) fusion proteins  We conclude that there is no unique, complete proteome for the nucleolus, or probably for any other organelle, but rather an overlapping set of proteomes that are relevant to different cell states or conditions. We infer also that the accumulation of proteins in nucleoli following transcription inhibition results primarily from a block of RNA polymerase II activity We infer that these factors are specifically recruited into nucleoli to participate in ribosome subunit biogenesis and are not retained within nucleoli under conditions when no new rRNA substrate is being transcribed We monitored by microscopy the YFP–p68 fluorescence signal in nucleoli of live HeLa YFP–p68 cells following actinomycin D treatment and compared these in vivo data with the SILAC measurements of YFP–p68 in isolated nucleoli after actinomycin D treatment ( Fig. 3b , c ) We observed a wide range of responses to actinomycin D treatment for different proteins ( Fig. 4 ) We repeated the kinetic analysis with different inhibitors that also affect nucleolar morphology We used stable-isotope labelling by amino acids in cell culture (SILAC) to characterize the response of the nucleolar proteome to transcription inhibition ( Fig. 2 ) Werners syndrome protein, which was not sequenced at all in our previous study, was here detected with six different peptides, demonstrating that the combination of increased sensitivity, resolution and peptide sequencing speed achieved much greater sequencing depth Western blotting analysis showed that the ratio between the yellow fluorescent protein (YFP)-tagged and untagged, endogenous p68 in isolated nucleoli remained the same during actinomycin D treatment and that both similarly increased in nucleoli when transcription was blocked ( Fig. 3a ) Whereas multiple components appear to accumulate within the nucleolus only in the presence of rRNA substrate, the fact that many other proteins either remain at similar levels, or even increase within nucleoli after transcription inhibition, indicates that not all resident nucleolar proteins are dependent upon rRNA substrate synthesis Within the detected nucleolar proteome, 489 proteins produced peptides that allowed SILAC analysis
 An aggregate forms, with a characteristic blue-purple colour ( Fig. 1b ) An alternative strategy for increasing detection sensitivity might be to apply the principles of Liu and Lus approach to the distance-controlled assembly of another class of nanoscale materials — quantum dots As several identical DNA strands are attached to each nanoparticle, many nanoparticles can be glued together in this way As used by Liu and Lu , each nanoparticle has an average of 17 linkages, all of which need to be broken to disassemble the aggregate Both systems proved to be highly specific, exactly reflecting the specificity of the parent aptamers But Liu and Lu take the established principle one step further by adding in the unique features of aptamers — short, single-stranded DNA sequences that recognize specific molecules and bind to them — to create a fast, analyte-specific indicator But the lustre that makes gold so attractive in its bulk state changes entirely at the nanoscale By controlling the distance between two differently labelled quantum dots using an aptamer linker-and-target complex, one might be able to take advantage of a phenomenon known as fluorescence resonance energy transfer (FRET) to alter the emission wavelength of a quantum-dot probe, and so its colour First, each separated — and therefore red — gold nanoparticle has several single-stranded DNA sequences attached to it by covalent bonds ( Fig. 1a ) Gold particles of 10–100 nanometres possess optical properties that change according to their configuration: separated particles appear red in colour, and aggregated particles appear blue Imagine that simple litmus tests for every analyte for which aptamers exist were available! To be able to look at a ‘paper strip’ to gain an instant idea of whether a compound is present and in what quantities would be worth more than its weight in gold. Improving the sensitivity of the technique could, however, easily be accomplished simply by reducing the number of linkages on each nanoparticle In the absence of adenosine, the aptamer behaves essentially like any short, linear DNA sequence, and does not adopt a well-defined three-dimensional structure In the presence of adenosine, however, the aptamer markedly changes its conformation ( Fig. 1c ) In this case, the colour change is triggered by a small molecule that might need to be detected in situations when elaborate analytical equipment is not readily available: cocaine It folds to form well-defined binding pockets for adenosine molecules, exhibiting a three-dimensional structure stable enough to be elucidated by NMR spectroscopy  Juewen Liu and Yi Lu exploit this chameleon-like nature of gold nanoparticles to create a colorimetric indicator for the detection of specific biomolecules Microbeads labelled with quantum dots of different sizes in controlled ratios can be made to exhibit a unique fluorescent signal for every DNA sequence  Quantum dots are nanocrystals (for example, zinc sulphide-capped cadmium selenide) that can be used as fluorescent probes in biodetection assays, including those for the detection of nucleic acids So any part of the aptamer is equally accessible for hybridization to a complementary sequence, and therefore to function as a linker So Liu and Lus method is more energy-intensive than other detection principles, and so less sensitive The authors found that, with slight adjustments of the appropriate aptamer, the dissociation of the DNA linker from one set of gold nanoparticles could be brought about upon cocaine binding to the aptamer The binding process also requires the participation of endmost nucleotides of the DNA linker to form the compact structure of the aptamer–adenosine complex The colour of the ensemble therefore turns back to an intense red, and so acts as a visual indicator of the presence of adenosine The detection limit of the nanoparticle-based assay is correlated with the appropriate dissociation constant, a number that measures the strength of the small molecules binding to the aptamer The innovative part of Liu and Lus strategy is that the DNA linker is itself an extension of a DNA aptamer that binds specifically to adenosine , a representative small molecule The more conventional part of the new approach is loosely based on the concept of nanoparticle aggregation through DNA hybridization, a process in which two complementary single DNA strands anneal to form a double strand The principle of the technique is not new: nanoparticles were first used as colour indicators to detect certain DNA sequences a decade ago , and have since become an important tool in biodiagnostics  The rapidity with which these sensors can detect analytes (a response is given within seconds), as well as the sensors simple design and the fact that mere inspection is, in principle, sufficient for semi-quantitative detection, are outstanding advantages of the technique, and ones that set it apart from previously developed aptamer-based detection approaches  These aptamer-based tools could become a very useful addition to the nanostructure biodiagnostics workbox They publish their results in the journal Angewandte Chemie International Edition  This can only happen if the gold nanoparticle right at the end of the aptamer is released, and so the whole network of aggregated gold nanoparticles disassembles This principle is not limited to adenosine detection, as Liu and Lu show with a neat second example  This sentiment, from Goethes masterpiece Faust , reflects mankinds fascination with this metal This sequence is then released in the presence of the analyte molecule to which the aptamer links  Two strands attached to neighbouring nanoparticles are then bound to one another through a parallel DNA linker consisting of a series of nucleotides complementary to both strands Using this system, the amount of cocaine present could be quantified in the range 50 to 500 micromoles per litre Writing in a recent edition of ChemBioChem , Andrew Ellington and colleagues have taken a first step in this direction, using an aptamer-labelled quantum dot, the fluorescence of which is reduced by an annealed fluorescent sequence ”  Zum Golde drängt, am Golde hängt doch alles ” — “Towards gold throng all, to gold cling all”
 A research career begins with research: you have to find the right graduate programme for you After that, the application period was governed by doubt Am I good enough to apply successfully? When I first noticed the post Im now in, I was immediately excited But for me, it was the second question that was more important — and the hardest to ask First: what is the ideal graduate programme? Quite a few factors matter I dont know how many hours I spent on the Internet searching for the ideal position I wanted to get it Months elapsed before I dared send a letter Political atmosphere in the country youre considering, distance from home and accommodation are equally essential Salary and career opportunities also matter So a feeling of insecurity is natural The best way to deal with doubt is to fill in the application, send it off, and try not to think too much about the response. The number of people competing for a post can be huge The programmes scientific scope, quality and reputation are, of course, very important Was I the ideal student for this position? What about the level of competition? Most graduate opportunities are now advertised globally Why so long? Mainly because of two simple questions
 Along the way she learned Indonesian and, with her banker husband, raised three children. “Not a typical career path,” she laughs. (see CV ) An encounter at a Gordon research conference sent her home to France to do a PhD Back in France after a decade, a 40-year-old mother-of-three without a job offer, she was undeterred by advice to stay at home Carole Moquin-Pattey, head of unit, European Medical Research Councils, Strasbourg, France The jewellery designed by Carole Moquin-Pattey embraces duality: a brooch may transform into a necklace, and small studs into long elegant earrings During a few years in Australia and Indonesia, a mix of stubbornness and opportunism kept her going when the science job outlook looked bleak. “I was translating drug-approval documents, but couldnt get a full-time job,” she recalls. “I took care of my children, and it was a very enjoyable period.” A successful sideline in jewellery design didnt, however, distract her when she had a chance to return to science From there it was a short step to the centre of national research funding at the medical research foundation (FRM) and policy making at the national institute of health and medical research (Inserm) Her efforts eventually secured her a postdoc in the United States Her EMRC post involves creating a new pathway for clinical research in Europe with a single entry point: part of the European public–private initiative for developing new therapeutic tools It has led her from work in a hospital pharmacy to heading the European Medical Research Councils (EMRC), via plant biology, marine chemistry and membership of the French ethics committee It uses her experience in science and legal and regulatory areas — and with her easel at home, she still finds time for art. Moquin-Patteys own career is marked by a series of double lives — art and science, chemistry and biology, adaptability and obstinacy One of many unsolicited letters persuaded Boehringer Mannheim to create a new position for her She dropped in on the Scripps Institution of Oceanography during a holiday after graduating as a pharmacist That impulsive move led to four months research with William Fenical on soft corals, and to the realization that her future lay in life sciences
 Despite these efforts, the incidence of TB in cattle has risen consistently, re-emerging as a primary concern for Britains cattle industry For three decades, European badgers ( Meles meles ) have been culled by the British government in a series of attempts to limit the spread of Mycobacterium bovis , the causative agent of bovine tuberculosis (TB), to cattle  Here we use data from a large-scale, randomized field experiment to help resolve these apparent differences Human and livestock diseases can be difficult to control where infection persists in wildlife populations Recently, badger culling has attracted controversy because experimental studies have reached contrasting conclusions (albeit using different protocols), with culled areas showing either markedly reduced or increased incidence of TB in cattle These findings are biologically consistent with previous studies but will present challenges for policy development. This has confused attempts to develop a science-based management policy We show that, as carried out in this experiment, culling reduces cattle TB incidence in the areas that are culled, but increases incidence in adjoining areas All trial areas were surveyed for badger activity and then randomly allocated to treatments (except in triplet I, for which security concerns directed a specific allocation) such that each treatment—proactive culling, reactive culling, or no culling (‘survey only’)—was repeated ten times, once within each triplet Analyses based on VETNET herd locations include 2,810 herds inside trial areas and 2,163 herds in neighbouring areas Any herds within 2 km of more than one trial area boundary (whether proactive, reactive or survey-only) were omitted from these analyses ( Fig. 2 ) As in previous analyses , the regression models adjusted for triplet, the log of the number of baseline herds at risk, and the log of the number of confirmed breakdowns recorded in a three year period before RBCT culling (other time periods investigated are presented in the Supplementary Information ) Attempts were made to place trial area boundaries along geographic features that might impede badger movement (for example, coastline, rivers or major roads; Fig. 2 ), but in most cases this was impossible and trial area boundaries mainly followed property boundaries Badgers were captured in cage traps placed primarily at setts; details of culling protocols have been published previously  Cattle herd locations from the animal health information system VETNET were used to identify herds inside trial areas Data were available until 4 September 2005, and consisted of accrued totals from 46.6 ‘triplet years’ since initial proactive culls and 34.1 ‘triplet years’ since first follow-up culls (where a ‘triplet year’ is one triplet observed for 12 consecutive months) Excluding earlier data therefore indicated the maximum potential benefits of culling inside trial areas, but also risked underestimating any detrimental effects in neighbouring areas, which were expected to be greatest immediately after initial culls Few badgers sustained trap-related injuries , and badger killing (by gunshot) was deemed ‘humane’ by independent audit  Field surveys showed that badger activity in trial areas changed according to the treatment applied , providing no evidence that treatment comparisons were substantially compromised by illegal culling in survey-only areas First, some breakdowns early in the trial could represent infections acquired (but not detected) before culling began Herds up to 2 km outside trial area boundaries could be identified comprehensively only using VETNET, because the RBCT database did not include all farms on neighbouring land Immediately after treatment allocation, initial proactive culls were conducted on all land for which consent was given (see Supplementary Information ) In the absence of geographical barriers, the boundaries of the area to be culled were delineated (beyond trial area boundaries as necessary; Fig. 2 ) using field survey data to ensure that culling targeted all badgers likely to use farms inside the trial areas Initial culls for each proactive trial area were completed between December 1998 and December 2002. ‘Follow-up’ culls were repeated approximately annually (dates in Supplementary Information ) Methods Trial design Thirty trial areas were recruited sequentially as ten matched ‘triplets’ denoted A–J  Models were also fitted replacing the log of the number of baseline herds at risk with either the log of the estimated number of cattle at baseline, the log of the number of tests conducted, or the log of the estimated number of cattle tested, and varying the time period over which past incidence was calculated Neighbouring trial areas were separated by buffer zones at least 3-km wide No such differences were detected in the analyses of confirmed breakdowns (see Supplementary Information ) No trapping occurred between 1 February and 30 April each year, to avoid killing mothers with dependent cubs below ground  Once the initial proactive cull was complete, data were collected on cattle TB incidence in and around trial areas, using established veterinary surveillance (see Supplementary Information ) Parallel analyses were performed using the RBCT database to identify herd locations; the results obtained were similar but less consistent (see Supplementary Information ) Primary analyses included all breakdowns since completion of the initial proactive cull, but we also performed secondary analyses investigating incidence recorded after completion of the first follow-up cull Second, badger capture rates (see Supplementary Information ) suggested that a higher level of badger removal was achieved after the first follow-up cull Statistical analysis We used log–linear Poisson regression to compare the numbers of confirmed breakdowns recorded in trial areas subjected to the proactive and survey-only treatments The method used provides a good estimate of the disposition of badger home ranges when based on good survey data  The results obtained were similar in each case (see Supplementary Information ). This could make treatments appear more similar, leading to underestimation of effects; excluding data before the first follow-up cull avoided this potential problem Trial areas were selected on the basis of high cattle TB incidence We performed these secondary analyses for two reasons We sought evidence that the effects of proactive culling were systematically influenced by particular circumstances of local cattle and badger populations, land occupier consent, time since enrolment in the RBCT, and the geographic isolation of trial areas, by investigating interactions of these measures with treatment effects Again, analyses revealed no significant change in the effect of culling on breakdown incidence over time (see Supplementary Information ) Again, the effect was consistent across proactive/survey-only pairs (the test for overdispersion was not significant, P = 0.38), but the estimated increase was smaller when measured from the first follow-up cull rather than the initial cull (22% increase, P = 0.15; 95% CI: 6.9% reduction to 59% increase) Analyses revealed a 29% increase in cattle TB incidence ( P = 0.015; 95% CI: 5.0–58% increase; Fig. 1b ) on land neighbouring proactive areas, relative to land neighbouring survey-only areas Bovine tuberculosis is a zoonotic disease with serious consequences for Britains cattle industry  Despite these efforts, over the past two decades substantial increases have been recorded in both the incidence and geographic extent of cattle infection, prompting repeated reviews of control options  Detailed consideration is needed to determine whether culling on any particular scale would be economically and environmentally sustainable. However, contacts with cattle might be particularly frequent at the onset of culling, when territorial organization is disrupted but badger population densities may still be comparatively high However, in two of these studies we would expect such effects to be weak because culled areas were isolated from neighbouring cattle and badger populations by coastline, rivers or motorways However, neither this explanation nor the effect itself has been universally accepted  However, the ecological patterns observed are consistent with the hypothesis that culling affects the probability of contact between infected badgers and cattle herds, because badgers range more widely when their densities are artificially reduced  In contrast, a field experiment conducted in Britain (the randomized badger culling trial or RBCT) indicated higher cattle TB incidence in nine study areas (each approximately 100 km 2 ) where badgers were culled locally (average area 5.3 km 2 per cull) in response to specific cattle TB outbreaks (‘reactive’ culling) than in nearby areas randomly allocated to a no-culling treatment  Localized ‘reactive’ culling sought to reduce TB risks to cattle while minimizing the number of badgers culled . ‘Proactive’ culling involved widespread and repeated culling of badgers across entire trial areas and was included in order to estimate the maximum reduction in cattle TB incidence achievable by culling badgers (subject to animal welfare considerations, non-compliance by land occupiers, and other practical constraints likely to influence the long-term sustainability of a potential culling policy)  None of the three previous studies has investigated effects of culling on neighbouring areas One explanation for the greater beneficial effect of culling in the Irish studies is that greater reductions in badger density may have been achieved, both because land occupier compliance was higher and because the culling method (snaring ) was probably more efficient than that used in the RBCT (although arguably less publicly acceptable, being perceived as less humane) Our analyses reveal that, thus far, the incidence of cattle herd breakdowns has been 19% lower in proactive trial areas than in survey-only areas ( P = 0.005; 95% confidence interval (CI) 6.2–30% reduction; Fig. 1a  Our analyses revealed no significant change in the effect of culling on breakdown incidence over time (see Supplementary Information ) Our finding that widespread culling of badgers has simultaneous positive and negative effects on the incidence of TB in cattle has important implications for the development of sustainable control policies Our results are also consistent with findings from the reactive culling treatment of the RBCT Our results help to resolve apparently contrasting findings from previous studies of badger culling Parallel ecological studies have revealed reduced population densities and expanded ranging behaviour in badger populations studied up to 2 km outside proactive areas, as well as in reactive areas  Patterns of infection in cattle and badgers are closely associated and, in Britain, cattle-based TB controls have been supplemented with various forms of badger culling  Regular testing of cattle herds and slaughterhouse surveillance form the main components of national TB surveillance and control; animals that test positive for TB are slaughtered and affected herds are placed under temporary movement restrictions Similar measures have eradicated TB in cattle across much of the developed world  Such disruption would be expected to occur throughout the period of a culling strategy, for in the absence of substantial geographic barriers, badgers continue to immigrate into culling areas  The 19% reduction in cattle TB incidence observed inside proactive culling areas can be compared with reductions detected, on similar timescales, by two previous studies of widespread culling in Ireland (26% reduction and 58% reduction (95% CI: 41–70%) ; see Supplementary Information for details; the different design of a third study (in Britain) precluded direct comparison) The 29% increase in TB risk that we recorded among cattle herds living close to (but outside) proactive trial areas is similar to the 25% (95% CI: 2.6–52%) increase recorded in reactive areas  The causative agent, Mycobacterium bovis , has a broad host range, which in Britain includes the European badger, a widespread but protected wildlife species  The CI is conservatively inflated (like all CIs reported here) to account for any overdispersion) The data suggest that the beneficial effects of culling might increase as one moves deeper inside trial area boundaries (see Supplementary Information ), but this trend is not consistent The development of improved TB control strategies has been hindered by contrasting findings regarding the effectiveness of badger culling as a management tool The estimated effect was stronger when measured after the first follow-up cull rather than the initial cull (23% reduction, P = 0.008; 95% CI: 6.5–36% reduction) The Independent Scientific Group on Cattle TB (ISG, with members F.J.B., C.A.D., D.R.C., G.G., J.P.M., W.I.M. and R.W.) designed and oversees the RBCT The ISG has tentatively suggested that this apparently detrimental effect of localized badger culling might be generated by the disruption of badgers territorial organization at artificially reduced population densities , potentially influencing contact rates with cattle The mechanism by which proximity to badger culling may influence cattle TB risks is uncertain The rates of cattle TB incidents (‘herd breakdowns’) in culled areas were then compared with rates in unculled ‘survey-only’ areas  The RBCT included two culling treatments ovement patterns caused the increase in cattle TB incidence recorded in reactive areas, we predicted that a similar pattern would be observed on farms neighbouring proactive trial areas This result was consistent across ten proactive culling areas, each paired with a survey-only area (the test for overdispersion was not significant; P = 0.58) This similarity would be expected if proximity to badger culling increases TB risks for cattle (whatever the mechanism) because, in reactive culling areas, small-scale culls were scattered across the landscape, placing a high proportion of herds close to one or more culled areas Two studies in the Republic of Ireland and one in Britain have associated substantial reductions in the incidence of TB in cattle with the near-eradication of badgers from large areas of land (a total of six areas ranging from 104 to 528 km 2 ) We also compared the incidence of cattle herd breakdowns in areas up to 2 km outside proactive and survey-only trial areas ( Fig. 2 ) We will continue to examine this possibility as additional data become available We would expect the overall reduction in cattle TB to be greatest for very large culling areas (with consequently lower perimeter:area ratios), although in absolute terms the costs, as well as the benefits, will be greatest for large areas
 A lot of my friends are scientists And I have a lot of sympathy for female scientists But if the robot in my short story did your review, youd be in a lot of trouble Despite this, he has never stopped thinking about what the future may hold and what impact science might have on society Futures Author Greg Bear has been fascinated by both science and science fiction since he was a child Getting that far — in a tough crowd — pleases me immensely He pursued a scientific career, but left the bench after flunking advanced calculus as an undergraduate Hed be as mean and as nasty as the worst human reviewer — probably nastier, as hes so naive His books range from Blood Music , which discusses the effects of nanotechnology, to Darwins Radio , which explores evolution and genetic engineering How does your own scientific background affect your choice of topics? Im kind of a philosopher scientist How have scientists reacted to your work? Many of the ideas and proposals in Darwins Radio have been met with real interest I cant do the lab work and I certainly cant do the math! How does your role of philosopher scientist play out in your work? Science fiction lets scientists dream without being responsible I hang out with them and talk to them In this weeks Futures (see page 1050 ), Bear ponders the downsides of artificial intelligence courtesy of a robot book reviewer It also models how the public might react to science It lets you figure out where your ideas stand in the culture Its always been an old boy network Many of your protagonists are scientists — and a disproportionately high number of your heroes are women Nature caught up with him to find out more The beginning will be: “Everything you know is wrong...” They dont complain They get cut out, but they are so humble about it They have a tough role What would happen if robots took over peer review? I like the idea: your equipment looks over your scientific results Whats next? Im in the early stages of writing about thermodynamics and information — writ cosmologically, 100 trillion years in the future Why the wide range? I love all aspects of science Why? There hasnt been a surfeit of well-rendered scientists in any form of fiction You cover topics from planetary science to biology
 A proposal that 10% of US electricity should come from renewable sources by 2020 was also ditched Bushs desk last week But in the end, critics say, the 1,700-page Energy Policy Act is more of a compromise than a strategy But its various tax breaks and incentives may change the landscape of energy science But these are really just a starting point for negotiations by the appropriations committee, which is widely expected to be more frugal Energy companies interested in ending that streak can now count on a tax credit and reimbursement of any losses associated with unforeseen regulations, although it is not yet clear whether the industry will bite In fact, energy efficiency and renewables take home just $5 billion of the bills $14.5 billion in tax incentives, which are spread over ten years In the past few months, sections of the bill protecting manufacturers of the water-contaminating petrol additive MTBE and opening the Arctic National Wildlife Refuge to oil drilling were scrapped so that Congress could finally pass it It has been shorn of many of its controversial provisions, and wont do much to make the countrys energy use more environmentally friendly, at least in the short term One clear change, however, is the creation of an undersecretary for science in the energy department, a position that many physical scientists hope will increase the clout of research in the departments budget wrangles. “This provides a voice at the table where the crucial decisions are made,” says Michael Lubell, head of public affairs at the American Physical Society. Science seems to do well out of the bill, with more than $30 billion assigned to various research and development programmes over three years The bill may also pave the way for a resurgence of the nuclear industry in the United States, which has not signed off a new nuclear-plant construction since 1973 The bill sets no emissions limits and does not change fuel-efficiency standards for cars The rest is largely a list of benefits for traditional energy industries, including a $1.5-billion scheme for research and development into drilling for oil and gas in the Gulf of Mexico The United States uses vastly more energy than any other country on the planet, and the bill was initially seen as a chance to set out a clear strategy for the country in terms of energy efficiency Washington DC The US Congress slapped an energy bill, four years in the making, on President George W
 Although Id sometimes like to ignore its significance, I cant And I wonder whether my increasing anxiety should be excitement instead Anxiety and doubts or not, I know that I have to start writing At the very least, I have to convince unknown peer reviewers that my data add something of importance to the collective knowledge But its a challenge to put the story into a package that the rest of the scientific community will find interesting Especially now, when I find myself facing the task of writing my first paper Having never written a paper before, I wonder if I will be able to do this convincingly at all I need to highlight how my story is new and different — and why it deserves to published It may be that my anxiety at not being able to do so is the reason I havent started writing yet Its almost the interesting story I imagined it would be when I first began the project two years ago Otherwise, my work will remain unpublished — a nightmare for any ambitious researcher. The data are nearly there To do that, I need to understand its place in the context of what has come before Whether for the advancement of science, of ones career or of a controversial theory, the importance of publishing remains incontrovertible
 A sensitive method for detecting the magnetic particles directly is to measure their magnetic fields using relaxometry ; but this approach has the drawback that the inverse problem (associated with transforming the data into a spatial image) is ill posed and therefore yields low spatial resolution Consider, for example, the use of magnetic tracers in magnetic resonance imaging: detection thresholds for in vitro and in vivo imaging are such that the background signal from the host tissue is a crucial limiting factor Here we present a method for obtaining a high-resolution image of such tracers that takes advantage of the nonlinear magnetization curve of small magnetic particles Initial ‘phantom’ experiments are reported that demonstrate the feasibility of the imaging method The resolution that we achieve is already well below 1 mm The use of contrast agents and tracers in medical imaging has a long history  They provide important information for diagnosis and therapy, but for some desired applications, a higher resolution is required than can be obtained using the currently available medical imaging techniques We evaluate the prospects for further improvement, and show that the method has the potential to be developed into an imaging method characterized by both high spatial resolution as well as high sensitivity. A robot (Flachbettanlage 1, Iselautomation KG) is used to move the sample from the upper left to the lower right corner of a square region (approximately parallel to the page plane in Fig. 2a ) in subsequent horizontal lines After amplification and subsequent filter stages, the signal is digitized (12 bit 20 MHz, type PCI-9812, Adlink Inc.) Black was assigned to the lowest obtained concentration Both the ‘P’ and the reference object were measured with identical parameters (field amplitudes, frequency, robot path, delay and recording times) Finally, the mean value over a set of these individual concentration images is computed, and shown in Fig. 3a  Finally, the three images were averaged to form Fig. 3b . G n ( r ) denotes the delta response of the system, representing the induced signal in the n th harmonic of the set-up if an infinitesimally small object is placed at position r  In addition, a single hole (reference object) with the same dimensions was filled with tracer and used as a reference response of the entire system In addition, the recorded signal is passed through a passive notch filter In d.c. mode, the spatial derivative of the selection field X s at the FFP is 3.4 T m -1   µ 0 -1  In order to achieve that, the spatial Fourier transform of equation (1) is used (functions in Fourier space are denoted as the corresponding lower case letters with caret): vcirc; n ( k ) = ĝ  n  ( k ) ĉ * ( k ) (2) After division by the known concentration function ĉ *( k ) of the reference object, a Fourier back-transformation yields G n ( r ) Its measurement, and later use in reconstruction, accounts for all imperfections of the coils and the complex behaviour of the tracer Matrix inversion For image reconstruction, a direct inversion of the discretized equation (1) was used, as it gives more flexibility with respect to data reduction Methods Hardware An outline of the MPI scanner is given in Fig. 2a  Obtaining the delta response from the reference response Owing to the use of a relatively large object (0.5 mm diameter), it is necessary to deconvolute the delta response from the reference response before starting with the reconstruction Reconstruction principles The two acquired sets of data (‘P’ and reference response) were both used for reconstruction Reduced data set inversion If the robot moves only in one horizontal line, the matrix equation (1) is no longer overdetermined, and all reasonable higher harmonics have to be included in the matrix to be used for inversion The concentration C ( x ) in equation (1) was determined numerically for each harmonic n separately, using a zero order regularization scheme  The drive field amplitude is 10 mT  µ 0 -1  The drive field frequency is arbitrarily set to 25.25 kHz The field-producing coils of the scanner are separated by 50 mm, and do not contain ferromagnetic material The first test object was the letter ‘P’, formed by 13 holes (diameter 0.5 mm, length 1 mm) in a flat plastic plate that were filled with the magnetic tracer The grey scale was assigned to the image in a linear way The induced signal is hence: V n ( y i ) = δ 2 ∑  j ∈{52 × 52} G n ( x j + y i )  C  ( x j ) (3) Here, x j and y i refer to different measuring positions within the scanning plane, and δ 2 is a normalization factor due to the discretization The n th harmonic V n ( y ) of the induced signal, at the robot position vector y , can be written as: V n ( y ) = ∫ G n ( x + y )  C ( x ) d x (1) Here C ( x ) is the magnetic particle concentration in the object, being unknown for the image reconstruction The new equation can be written as: V n (min) = δ 2 ∑  j ∈{1 × 52} G n (min) ( x j + y i )  C  ( x j ) ⋮ V n (max) = δ 2 ∑  j ∈{1 × 52} G n (max) ( x j + y i )  C  ( x j ) (4) The inversion was performed in same way as above, but for each of the three lines independently The resulting 52 × 52 data points cover a 9.4 × 9.4 mm 2 region The two recording coils are of square shape, with about 16 mm side length and a separation of about 16 mm They are surrounded by larger windings with opposite sense (not shown in the figure) to compensate the induced voltage due to the drive field This function includes all the complex dynamics of the magnetic tracer, as well as the shape of the drive field and the recording coils This leads to several complete images of the object A high SNR may speed up the image acquisition, provided that an adequate encoding speed is possible A reasonable value for H k may be obtained by equating the thermal energy with the Zeeman energy of the magnetic particles Additionally, MPI does not necessarily require a large scanner Additionally, the drive field moves the FFP in the vertical direction Additionally, the electronics offers significant potential for improvement Additionally, the observed signal and the noise level are included All other magnetic material remains in the state of saturation All required magnetic fields may be applied from one side An image of the magnetic tracer in the object is directly obtained by mapping the magnitude of the harmonics Analysing the signal and noise in Fig. 4 , we estimate the current detection limit to be about 100 µmol Fe l -1 for a resolution of about 1 mm As a result, the resolution in the vertical direction is better than 0.3 mm As the drive field amplitude was not sufficiently high to move the FFP over the whole object, three separate images were reconstructed Assuming H k = 0.5 mT  µ 0 -1 , reachable with particles of 30 nm diameter, and the currently used X s = 3.4 T m -1   µ 0 -1 , the observed resolution is obtained But only the magnetic material located at the FFP will respond to the a.c. modulation field By driving each coil pair with a predefined current waveform, the FFP can be moved on a continuous trajectory over the object By steering the FFP through the volume of interest, a tomographic image can be generated. (As a spatial variation in one direction of one field component is in general accompanied by a spatial variation of another component in another direction, only a single selection field is needed in MPI to obtain a three-dimensional spatial encoding.) The movement can be performed by moving the whole coil assembly or by moving the object within the coil assembly By using drive fields, it is possible to accelerate the movement of the FFP dramatically Components used in the present set-up are illustrated in Fig. 2a  Consequently, the introduction of the drive fields overcomes both drawbacks mentioned above, namely the low encoding speed and the low SNR Drive field amplitudes of up to 20 mT  µ 0 -1 , and frequencies up to 100 kHz, may be used without harming the patient through heating Figure 3a shows an image of the object, for the case of pure mechanical movement of the object Figure 4 shows the calculated normalized signal for particles in the range 10–40 nm as a function of the number of the higher harmonics Finally the object is moved (spatial encoding) to discrete positions and the magnitudes of the harmonics are recorded Finally, the method for localized interaction could be used not only for imaging, but also for therapy by local heating  First, the robot alone is used for the spatial encoding (mechanical FFP movement) For a drive field frequency of f 1 = 25 kHz and N = 50, an encoding time of the order of 100 ms can be achieved For a relatively small imaging volume, the scanner itself may be quite small and inexpensive For medical applications, a larger field of view as well as a higher coding speed is desired For medical applications, such as vascular or small intestine imaging, the high resolution and sensitivity of MPI can be expected to be advantageous For simplicity, we assumed a low amplitude of the modulation field For such particles, the Langevin theory of magnetism would predict quite smooth magnetization curves with H k = 210 mT  µ 0 -1 , leading to a resolution of the order of 10 cm For this purpose, a different sinusoidal current with a high frequency is applied to each coil pair Further work will be needed to exploit the full potential of this new imaging method. Furthermore, both possibilities can be combined Furthermore, the signal can penetrate tissues virtually unattenuated, allowing the inspection of regions located deep below the surface Given that the particles have a reported diameter of 4 nm it is remarkable that the achieved resolution is so high However, a drive field ( A = 10 mT  µ 0 -1 ) for the generation of the harmonics is used in place of the low-amplitude modulation field, owing to the higher achievable SNR However, improvements in magnetic tracers and recording electronics can be expected to lower the detection limit to 20 nmol Fe l -1  However, the mechanical movement leads to low scanning speed and the signal to noise ratio (SNR) is low owing to the weak modulation field If an oscillating magnetic field, called the ‘modulation field’, is applied, with frequency f 1 and sufficiently high amplitude A , the magnetic material will exhibit a magnetization M ( t ), where t is time If the magnetic particles are also exposed to a time constant magnetic field with a sufficiently large magnitude, they saturate and the generation of harmonics is suppressed ( Fig. 1b ) If the signal is induced by an oscillating magnetization M , and the object dominates the noise (‘patient noise limited’), the SNR is proportional to M but independent of frequency  If there is any magnetic material at the position of the FFP it will produce a signal containing higher harmonics In addition to the modulation field, a time-independent field is superimposed (field plot in Fig. 2a ) that vanishes in the centre of the imaging device (the field-free point, FFP) and increases in magnitude towards the edges In Fig. 3b the drive field encodes vertically and the robot is used for the horizontal encoding In order to form two-dimensional images, the object can be moved in two dimensions using a robot In our experiment, the coding time was rather long, but in principle coding speed can be fast in MPI In summary, to form an image, magnetic tracer material has to be applied to, or introduced into, the object ×  N  voxel) can be shown to be roughly T = N 2 / f 1  In the horizontal direction, the resolution is about 0.5 mm, as the derivative of the field component of the selection field in that direction is lower It can also be adapted to compromise resolution while improving sensitivity M ( t ) contains not only the drive frequency f 1 , but also a series of harmonic frequencies ( Fig. 1a ) MPI may find a variety of applications, such as medical imaging, crack detection, polymer processing or fluid dynamics MPI relies on the nonlinearity of the magnetization curves of ferromagnetic material and the fact that the particle magnetization saturates at some magnetic field strength On the other hand, a well tolerated dosage of maghemite particles in humans is about 70 µmol Fe l -1 , resulting in an SNR two orders of magnitude higher than that achieved using MRI Otherwise, the a.c. field shifts the FFP significantly Second, the robot provides the spatial encoding in the horizontal direction, while the drive field moves the FFP in the vertical direction Selective suppression of the harmonics is employed for the spatial encoding as follows So the detection limit estimated above seems to be reasonable, as the corresponding MRI signal can be detected So the spatial encoding can be realized in two ways, as follows: (1) using mechanical movement, or (2) using field-induced movement of the FFP The amplitudes of the currents must be large enough to generate magnetic fields capable of cancelling the selection field at the border of the desired region of interest The detection limit extrapolated above can be verified via comparison with magnetic resonance imaging (MRI) The experimental data fit well, assuming that particles of 30 nm diameter are responsible for the signal The fast FFP movement leads to a rapid local change in magnetization as soon as the FFP passes a location containing magnetic material The iron mass of the signal-generating particles represents only 3% of the total iron mass The magnetization change induces a signal in the recording coil that exhibits higher harmonics of the drive field frequencies The mechanical movement is dispensable if three additional orthogonal homogenous magnetic fields, called drive fields, are provided ( Fig. 2b ) The method described so far is capable of generating images of the spatial distribution of magnetic material The modulation field with low amplitude ( Fig. 1 ) is now obsolete The object is placed in the selection field, and a weak magnetic modulation field is superimposed The potential for improvement of the tracer can be seen in Fig. 4  The potential of MPI becomes clear when considering the resolution and the encoding speed, in combination with the high SNR, which can be converted to imaging speed and/or sensitivity The resolution in both cases ( Fig. 3a and b ) is the same, although the SNR differs owing to the shorter measurement time in the second case The same experiment was evaluated in both cases, but in the second case only a subset of robot scan positions was used The signal could be increased by at least two orders of magnitude (compare red line with dashed ‘40 nm’ line) by a better initial composition and a particle separation process The size in each direction of a volume depends on the maximum possible shift F = 2 A / X s of the FFP, which is of the order of 6 mm for X s = 3.4 T m -1   µ 0 -1 and the drive field amplitude A = 10 mT  µ 0 -1  The theoretically expected resolution ( R ) is given by the ratio 2 H k / X s , where H k is the a.c. field strength at which the material produces substantial higher harmonics, and X s is the largest spatial derivative of a selection field component The three components of the selection field can be cancelled, at any given point in space, by appropriate adjustment of these three fields The two-dimensional object used for imaging consisted of distinct holes filled with an undiluted (0.5 mol Fe l -1 ), commercially available contrast agent (Resovist , Schering AG Berlin) These higher frequencies can be easily separated from the received signal by means of appropriate filtering They covered the upper, middle and lower regions of the object, and were averaged to form Fig. 3b  This detection limit is already within the range of the allowed dosage for medical use  This field is called the ‘selection field’ This induced signal is sufficient for image reconstruction This is the situation realized in the present experimental set-up This means that the simple method for generating an image (for the case of the weak modulation field) by mapping the magnitude of the harmonics is not appropriate, and a reconstruction is necessary; see Methods section This offers new opportunities for imaging magnetic tracers with high resolution and sensitivity This set-up is analogous to a mechanical motion set-up This would require the use of three orthogonal drive fields responsible for the FFP movement ( Fig. 2b ), as already mentioned in the basic description Thus far, the reconstruction was optimized to obtain the best possible resolution To achieve a still larger field of view, an additional, slower movement of the FFP can be superimposed Two alternative encoding types are demonstrated Using a drive field leads to a contribution of neighbouring points to the recorded signal at a given robot position Using permanent magnets, a maximum X s of about 3 T m -1   µ 0 -1 seems to be possible for human applications, with reasonable effort We first introduce the general concept of magnetic particle imaging (MPI) We have demonstrated the possibility of directly mapping magnetic material, without relying on the ill-posed inversion problem We therefore compared the observed performance to that of ideal particle ensembles acting according to the Langevin theory With an optimized version, we expect an improvement in SNR of between one and two orders of magnitude even for a human-size system With the detection limit of 20 nmol Fe l -1 , the expected magnetization would still be about 5% of a typical MRI equilibrium magnetization, assuming a proton magnetization M MRI (1T) = 4 × 10 -9  T  µ 0 -1 
 Contrary to the proinflammatory role of mast cells in allergic disorders, the results obtained in this study establish that mast cells are essential in CD4 + CD25 + Foxp3 + regulatory T (T Reg )-cell-dependent peripheral tolerance Finally, immunohistochemical analysis clearly demonstrates the existence of this novel T Reg –IL-9–mast cell relationship within tolerant allografts. Here we confirm that tolerant allografts, which are sustained owing to the immunosuppressive effects of T Reg cells, acquire a unique genetic signature dominated by the expression of mast-cell-gene products High levels of interleukin (IL)-9—a mast cell growth and activation factor—are produced by activated T Reg cells, and IL-9 production seems important in mast cell recruitment to, and activation in, tolerant tissue Our data indicate that IL-9 represents the functional link through which activated T Reg cells recruit and activate mast cells to mediate regional immune suppression, because neutralization of IL-9 greatly accelerates allograft rejection in tolerant mice We also show that mast cells are crucial for allograft tolerance, through the inability to induce tolerance in mast-cell-deficient mice A total of 5 × 10 6  BMMCs were then injected intradermally into the W sh recipients 8 weeks before grafting After 5 days of culture, cells were harvested and their purities were verified by FACS analysis of Foxp3 expression (data not shown) All animals were maintained in a pathogen-free facility at Dartmouth Medical School Briefly, secondary-challenge skin transplants from different groups were removed 7 days after grafting CD8 + , CD4 + CD25 - and CD4 + CD25 + T cells were purified by magnetic separation with MACS ( Miltenyi Biotec ) according to the manufacturers instructions Cell debris was removed by filtration through a 100-µm nylon cell strainer and a 40-µm nylon cell strainer, sequentially Cell preparation, BMMC generation and cell reconstitution Single-cell spleen suspensions were prepared from 8–10-week-old mice Cells were harvested after 5 days of culture and their purities were verified by real-time PCR analysis of lineage-specific gene expression ( Tbx21 for T H 1 and Gata3 for T H 2; data not shown) Complementary DNA was then prepared and applied to real-time PCR analysis ( SYBR green ; BioRad ) Control recipients received identical amounts of mouse immunoglobulin Cytokine secretion assay and immunohistology Secretion of IL-9 was assayed by ELISA Different T-cell populations (1 × 10 6 ) were cultured in 24-well plates precoated with 1 µg ml -1 anti-CD3 (clone 2C11) with or without 10 µg ml -1 anti-GITR (also known as Tnfrsf18; clone DTA-1) or anti-CD28 (clone PV-1) Enriched cell populations and purified cells were phenotypically analysed by fluorescence-activated cell sorting (FACS) For blocking IL-9 activities in vivo , 200 µg of neutralizing anti-IL-9 antibody (clone MM9C1) was administered through intraperitoneal injection every other day throughout the duration of the experiments For gene array analysis, as shown in the previous literature , RNAs purified from different cell populations with various treatments were analysed using Affymetrix mouse genome A430 oligonucleotide arrays  For IL-9 staining, biotinylated rabbit polyclonal anti-mouse IL-9 antibodies ( Peprotech ) and PE-conjugated streptavidin ( eBioscience ) were used For immunohistology, previously grafted skins were snap frozen, cryocut, and acetone-fixed For iT Reg cell preparation, recombinant human TGF-β (1 ng ml -1 ; PeproTech ) and human IL-2 (100 U ml -1 ; PeproTech ) was added For mast cell reconstitution, BMMCs were generated by culturing bone marrow cells with IL-3 (20 ng ml -1 ; PeproTech) for 5 weeks as shown previously  For Rag -/- mice reconstitution, 1 × 10 6  CD8 + T cells were adoptively transferred through intravenous injection with or without 2 × 10 5  CD4 + CD25 + T cells 1 day before grafting For T H 1 cell preparation, recombinant mouse IL-12 (5.0 ng ml -1 ; PeproTech ) with neutralizing anti-IL-4 monoclonal antibody (10 µg ml -1 ; clone 11B11; BD Pharmingen ) were added; for T H 2 cell preparation, recombinant mouse IL-4 (5.0 ng ml -1 ; PeproTech ) with neutralizing anti-interferon (IFN)-γ monoclonal antibody (10 µg ml -1 ; clone 37895.11; RD Systems) were added For T Reg cell depletion, 250 µg of anti-CD25 antibody (clone PC61) was administered through intraperitoneal injection 4 days before skin grafting IL-9 was quantified according to the manufacturers instructions (Peprotech) In all skin transplantation experiments, W sh mice were at least 8 weeks old before grafting, to ensure mast cell deficiency  In brief, full-thickness tail skins from CB6F 1 (F 1 ) donors were transplanted onto the dorsal area of age-matched C57BL/6 recipients Methods Mice C57BL/6, CB6F 1 (hybrid of C57BL/6 and BALB/c), C57BL/6 Kit W-sh ; Kit W-sh (W sh ) and C57BL/6 Rag -/- mice were purchased from the Jackson Laboratory  Real-time PCR and gene array analysis Total RNA from isolated skin-infiltrating cells or different T-cell subsets was purified using the RNeasy system ( Qiagen ) Relative expression of various gene targets normalized to β-actin was calculated as: (2 - (experimental CT - β-actin CT)) × 1,000 where CT is the cycle threshold of signal detection Seven days before skin grafting, 4 × 10 7  T-cell-depleted splenocytes from an F 1 donor were transferred into recipients through intravenous injection along with three injections of 250 µg anti-CD154 monoclonal antibody (clone MR-1) on days -7, -5 and -3 to induce allograft tolerance Skin grafting and immunization Skin grafting was performed following the procedure described previously  Skin grafts were then cut into small pieces, followed by trypsin digestion at 37 °C for 1 h Skin-infiltrating-cell isolation Skin infiltrating cells were isolated following the modified protocol described previously  Slides were blocked with normal mouse serum Supernatants were collected at the time indicated The purity of each population was around 90–95% The purity was assessed by anti-CD117 (c-Kit) and anti-FcɛRIα staining The remaining pieces were washed with RPMI 1640 medium over nylon mesh The resulting cell suspension was then washed twice in cold HBSS media and used for further analysis The specificity of IL-9 staining has been confirmed by the absence of staining in skin tissue from Il9 -/- mice (our unpublished data). Tissue sections were stained for CD4 (clone GK1.5), CD117 (clone 2B8) and Foxp3 (clone FJK.16 s) To generate different T-cell subsets, purified CD4 + CD25 - T cells were cultured with plate-bound anti-CD3 monoclonal antibody (clone 145-2C11) at 10 µg ml -1 and soluble anti-CD28 monoclonal antibody (clone PV-1) at 1 µg ml -1  A reduced number of mast cells in the skin of mice treated with anti-IL-9 compared with those treated with control-mouse immunoglobulin was observed at day 10 after the transplantation of the allograft into Rag –/–  mice ( Supplementary Fig. 5a, b ) Active suppression/regulation by T Reg cells is essential to establish and sustain self-tolerance Also, it has been shown that mast cells may contribute to tumour growth and metastasis  Although at this time we cannot definitively say IL-9 production by T Reg cells mediates mast cell recruitment and function, IL-9 has clearly been shown to be instrumental in peripheral suppression of alloreactive CD8 + T cells Although the rapid allograft rejection in the anti-CD154/DST-treated W sh mice indicates a role for mast cells in allograft survival, the data can merely implicate c-Kit + cells Analysis of gene array data from anti-CD3/anti-glucocorticoid-induced tumour necrosis factor related gene (GITR)-activated T Reg cells indicated that Il9 was highly upregulated on T Reg -cell activation ( Fig. 4a ) As CD8 + T cells did not produce IL-9, and there were no other CD4 + T cells in this system, this approach allowed us to speculate that IL-9 production by T Reg cells delayed allograft rejection As expected, Foxp3 and Il10 expression was highly upregulated in the tolerant group As reported and shown in Fig. 4d , T-helper-2 (T H 2) cells secreted IL-9 on activation; however, T Reg cells were superior in terms of IL-9 production on a per-cell basis As reported, the co-transfer of T Reg cells delayed the onset of graft rejection (MST = 42 days) mediated by CD8 + T cells in this model (MST = 19.5 days; P = 0.0243) As shown in Fig. 3d , local reconstitution of mast cells in the back skin was able to extend graft survival on W sh mice (MST = 44 days) that were initially unable to sustain allografts following anti-CD154 and DST treatment (MST = 20 days; P = 0.0052) As shown in Fig. 4a , following anti-CD3/anti-GITR stimulation, which has been shown to have an important role in controlling T Reg cell activities , Il9 was markedly upregulated in T Reg cells, but not the CD4 + CD25 - T-cell population As such, this may be a mechanism used by mast cells to limit T-cell activation BMMC-reconstituted W sh mice were then grafted with skin transplants after anti-CD154/DST co-administration and the acceptance of allografts was monitored over time ( Fig. 3c ) BMMCs were harvested five weeks after the initiation of culture ( Supplementary Fig. 2a ), and a total of 5 × 10 6  cells ( 99% c-Kit + FcɛRIα + ) were injected intradermally into the back skin of W sh mice CD4 + CD25 - T cells cultured in the absence of TGF-β produced 10% of the IL-9 compared with iT Reg cells ( Fig. 4c ) Co-administration of anti-CD154 and DST induced long-term acceptance of skin allografts in wild-type mice (median survival time (MST) 70 days), but not in the W sh mice (MST = 17 days; P 0.0001; log-rank test; Fig. 3b ) Collectively, these data indicate that both mast cells and T Reg cells increase in number in tolerant allografts and may be crucial in sustaining allograft survival Discussion There are a number of novel, unanticipated findings that emerge from the studies presented here Eight weeks after intradermal reconstitution, mice showed comparable mast cell frequency in back skin to that observed in wild-type C57BL/6 mice, as reported previously ( Supplementary Fig. 2b, c ) First, even though recent studies have underscored the plasticity of mast cells in regulating acquired immune responses , the fact that mast cells may be instrumental in orchestrating T Reg -cell-mediated peripheral tolerance is unprecedented First, immunohistochemical and quantitative real-time PCR analysis of skin transplants indicated that IL-9 was detected in tolerant grafts but not in syngeneic grafts ( Fig. 4e and Supplementary Fig. 4 ) Furthermore, IL-9-deficient mice contained far fewer mast cells than their wild-type littermates  Future studies will continue to unravel this pathway and will allow us to understand other mediators and cells that ultimately control peripheral immune suppression. Given the high levels of IL-9 produced by T Reg cells and the role of IL-9 in mast cell homeostasis, a functional link between IL-9, mast cells and allograft tolerance was examined Hence, IL-9, mast cells and their gene products may become attractive therapeutic targets to ameliorate the impact of T Reg cells in vivo  Hence, mast cells were essential for anti-CD154/DST-induced tolerance Hence, the loss of mast cells in rejecting grafts was unlikely to be due to the inflammation-induced migration of mast cells to the regional lymph node, but rather the direct cytotoxic elimination of mast cells by the host Hence, the regional production of IL 9 within the tolerant allograft facilitated mast cell accumulation However, despite the increasing body of knowledge about T Reg cells, the mechanisms by which these cells mediate immune suppression and prevent graft rejection are not well resolved However, it remained unclear whether these two cell types functionally interacted to establish regional tolerance in the tolerant allograft However, recent studies have shown that mast cells are heterogeneous, can produce an array of both pro- and anti-inflammatory mediators, can act as antigen-presenting cells and express a spectrum of co-stimulatory molecules However, there was no significant increase in mast cell numbers in the draining lymph nodes in the rejecting group when compared to the syngeneic or tolerant groups ( Supplementary Table 1 ) However, together with the mast-cell-reconstitution experiments, these results strongly suggest an indispensable role for mast cells in the establishment of skin transplant tolerance However, we could see only a partial effect with regard to alterations in graft rejection kinetics (data not shown) IL-9 links mast cells to T Reg -cell-mediated allograft tolerance The data presented thus far indicated that both T Reg and mast cells were important in long-lived allograft tolerance IL-9 production seems to be a common feature of T Reg cells because both nT Reg cells (CD4 + CD25 + ) as well as iT Reg cells (CD4 + CD25 - T cells cultured with anti-CD3 and transforming growth factor (TGF)-β in vitro ) produced high levels of IL-9 on activation ( Fig. 4c ) IL-9 was initially cloned as a T-cell growth factor whose receptor shares the common γ-chain with IL-2 family members such as IL-2, -4, -7, -15 and -21 (refs 15 , 16 ) Immune suppression has been shown to be mediated by unique subsets of T cells called regulatory T cells (T Reg )  Immunohistochemical analysis of rejecting primary grafts at day 7 revealed an apparent increase in infiltrating CD4 + T cells relative to that seen in syngeneic or tolerant grafts In addition to allograft tolerance, a number of tumour models have documented the accumulation of mast cells, as well as T Reg cells, to the tumour sites In addition, CD117 + mast cells that were present in syngeneic grafts were noticeably absent from rejecting grafts at day 7 ( Fig. 2a ; Table 1 ) In addition, TPH1, like indoleamine-pyrrole 2,3-dioxygenase (Indo), is an enzyme that can metabolize tryptophan and create a tryptophan-deficient environment  In contrast to rejecting grafts, in established tolerant grafts (day 60) there was massive T Reg (CD4 + Foxp3 + )-cell infiltration ( Supplementary Table 2 ) as well as sustained, or increased, mast cell (CD117 + ) density ( Fig. 2b ; Table 1 ) In contrast, another population of T Reg cells develops from the activation and differentiation of mature CD4 + CD25 - T cells in the periphery; these T Reg cells are called adaptive or induced T Reg cells (iT Reg ) In contrast, granzyme B and perforin expression in the rejecting group was much higher than in either the syngeneic or tolerant groups, as shown in other allograft models ( Supplementary Fig. 1 )  In fact, anti-CD154/DST-treated W sh mice rejected allografts at a rapid pace that was almost indistinguishable from the untreated control mice (MST = 13 days) In general, there are two classes of regulatory T cells that impact on peripheral immunity In multiple systems of allograft tolerance, the importance of these T Reg cell populations to long-lived allograft survival has been shown by the fact that depletion of T Reg cells before, and even after, the induction of transplantation tolerance results in rapid graft rejection  In summary, mice were rendered tolerant to alloantigens by the intravenous infusion of allogeneic cells (a process known as donor-specific transfusion; DST) and concomitant administration of an antibody to CD154 (anti-CD154; ref. 2 ) It is known that host-derived TGF-β is crucial for the peripheral immunosuppression mediated by T Reg cells, and it is tempting to speculate that T Reg -cell-activated mast cells are responsible for TGF-β production, or the liberation and activation of TGF-β via other known or unknown factors that mast cells secrete  Mast cell numbers in W sh mice decrease exponentially after birth owing to their developmental dependence on c-Kit , whereas the frequency of other haematopoietic and lymphoid cell populations remains relatively normal Mast cells in tolerant allografts Mast cells are derived from haematopoietic stem cells, which migrate into vascularized tissues and serosal cavities where they complete their maturation  Moreover, CD28 co-signalling could induce levels of IL-9 production that greatly exceeded those observed with GITR co-signalling ( Fig. 4b ) Naturally arising CD4 + CD25 + Foxp3 + T Reg cells (nT Reg ) are derived from the thymus and have been extensively studied for their roles in autoimmunity and tolerance  No long-term allograft tolerance in mast-cell-deficient mice Mast cells were functionally implicated in T Reg -cell-mediated allograft survival through a series of studies in mast-cell-deficient mice (C57BL/6 Kit W-sh ; Kit W-sh (W sh ) mice) Notably, although high levels of IL-9 were produced, IL-9 did not seem to have a role in autocrine T Reg cell growth or suppressive activity in vitro ( Supplementary Fig. 3a, b ) Notably, in agreement with previous results , all mast-cell-associated genes examined, including mast cell protease 1 ( Mcpt1 ), mast cell protease 5 ( Mcpt5 ), tryptophan hydroxylase ( Tph1 ) and the high-affinity IgE receptor ( Fcer1a ), were upregulated in the tolerant group compared with the syngeneic and rejecting groups ( Fig. 1c ) One of the control groups (syngeneic C57BL/6 skin transplant onto W sh mice) demonstrated delayed rejection (MST = 45 days) with long-term survival of 40% of the grafts ( Fig. 2b ) Owing to the complexities of the anti-CD154/DST system, which may obscure the potential involvement of IL-9 in T Reg -cell-mediated tolerance, a Rag -/- reconstitution system was employed that allowed the use of defined, enriched populations of T Reg cells and effector T cells to study allograft survival  Previously, extensive serial analysis of gene expression (SAGE) in tolerant tissue showed that genes predominantly expressed by mast cells were overexpressed in cultures of activated T Reg cells and in tolerant allografts  Previously, it has been shown that mast cells can be reconstituted both systemically and/or regionally in mast-cell-deficient mice by adoptive transfer of bone-marrow-derived mast cells (BMMCs) generated in vitro  Previously, it was shown that skin mast cells can migrate to the regional lymph node following antigen challenge to the skin  Purified CD8 + T cells were transferred with or without purified CD4 + CD25 + T cells into grafted Rag -/- mice ( Fig. 5a ) Second, our functional studies in vivo indicated a role for IL-9 in T Reg -cell-mediated suppression Second, recruitment of mast cells into sites of peripheral tolerance may be a common mechanism to control long-lived immune unresponsiveness at that site Subsequently, IL-9 was shown to be a mast cell growth factor on the basis of its capacity to enhance the survival of primary mast cells and to induce their production of inflammatory cytokines, mast cell proteases and the high-affinity IgE receptor (FcɛRIα)  The establishment of immunological tolerance requires both the induction of clonal deletion/anergy and active immune suppression The finding that mast cells are critical in T Reg -cell-dependent allograft tolerance further expands the knowledge of the interplay of different cellular components in controlling immune responses The increased presence of mast cells in tolerant versus rejecting grafts was consistent with the previous SAGE result, which was indicative of increased mast-cell-gene expression, and the reverse transcription–polymerase chain reaction (RT–PCR) data reported herein The mast cell density in syngeneic, rejecting and tolerant grafts was quantified to determine if the increase in mast-cell-gene expression was due to increased mast cell infiltration in tolerant grafts The T Reg -cell-mediated delay in graft rejection could be completely reversed with anti-IL-9 treatment (MST = 23 days; P = 0.0161; Fig. 5b ) Therefore, the lack of mast cells in the rejecting allografts could be the result of mast cell migration These findings indicate that mast cells are far more functionally diverse than previously imagined and can function as immunoregulatory cells that influence both innate and adaptive immunity  These unexpected findings linking mast cells to tolerance prompted our investigation of the potential functional role of mast cells in the establishment of T Reg -cell-mediated allograft tolerance They are best known as primary responders in allergic reactions such as anaphylaxis and asthma Third, both nT Reg cells and iT Reg cells seem to be producers of IL-9, and through the production of IL-9—and other effector molecules—may mediate the activities of mast cells in vivo  This approach allowed for the long-term acceptance of allogeneic skin grafts compared with the non-tolerant control group, which rejected grafts approximately two weeks after grafting This delayed rejection could be due to differences in minor histocompatibility molecules in addition to the impaired development of melanocytes in the W sh mice  This indicated the presence of T Reg cells that were producing immunosuppressive mediators in tolerant tissue ( Fig. 1b )  Thus, like in the allograft model presented, the T Reg cell–mast cell partnership may also have an immunosuppressive role in dampening the immune response to tumours To ascertain whether anti-IL-9 administration resulted in a reduction of mast cell accumulation to the tolerant grafts, mast cell numbers in various tissues were quantified To assess the role of mast cells in allograft survival, W sh mice were administered anti-CD154 and DST to induce allospecific tolerance ( Fig. 3a ) and grafted with allogeneic skin To compare mast-cell-associated gene expression during graft rejection or tolerance, mice received a second graft (30 days after the first grafting), which was harvested seven days later ( Fig. 1a ) To confirm earlier results, the presence of mast cells and their gene products in tolerant allografts in a skin transplantation model was examined To examine further the role of mast cells in transplantation tolerance, mast-cell-knockin mice were prepared  To investigate this, we first applied neutralizing anti-IL-9 to the anti-CD154/DST skin allograft model previously described Upregulation of IL-9 protein expression in T Reg cells was confirmed by an IL-9 enzyme-linked immunosorbent assay (ELISA; Fig. 4b ) W sh mice express c-Kit in melanocytes at an early age, which should allow the central tolerance to become established; however, the lack of normal melanocyte development in the adult may allow for this minor, delayed rejection response W sh mice have an inversion mutation in the transcriptional regulatory elements upstream of the c-Kit open reading frame, which influences c-Kit gene expression in a tissue- and age-specific manner  We present a new paradigm through which T Reg cells operate, and describe a novel set of cells and mediators that control peripheral tolerance We then performed quantitative analysis of messenger RNAs in the infiltrating cells extracted from skin transplants
 Ari Patrinos, who has directed biological and environmental research at the US Department of Energy since 1995, was last month appointed president of Synthetic Genomics, a company that Venter founded last year to create such organisms. “Ive known Craig for many years and we have always worked very well together,” says Patrinos, adding that Venter approached him about the job — based in Rockville, Maryland — several months ago. “Im going to be 59 this year,” says Patrinos. “I felt I wanted to do one other, different thing.”  Strong Prescription A US physicians group has called for special government incentives to push companies into developing antibiotics for drug-resistant hospital nasties such as Staphylococcus aureus , better known as staph Botanic yield A UK biotechnology firm whose drug candidates are based on Chinese plants has launched itself successfully on Londons Alternative Investment Market (AIM) In an article in the March issue of Clinical Infectious Diseases , the Infectious Diseases Society of America argues that few antibiotics are being developed because they are used for only a short time and do not fetch the prices that give manufacturers a decent return Oxford-based Phynova raised about £4 million (US$7 million) in its share offering on 27 February: two days later its shares were selling for £1.20 — 50% above the offer price Phynova has six drug candidates under development, including potential therapies for hepatitis C and cancer. The society calls for tax breaks and other incentives to get things going Venter venture Biologist Craig Venter has enlisted a high-profile ally in his quest to build microbes that are specially tailored to solve environmental problems
 A dramatic demonstration of the potential consequences came in July 2002, when researchers at the University of New York at Stony Brook reported that they had synthesized an infectious poliovirus using mail-order DNA (see Nature 418 , 265 ; 2002 10.1038/418265a ) A working group on the topic, set up by the board, will begin its discussions later this month And one of the first public discussions of the issue comes this week, at a synthetic-biology meeting in San Francisco on 19–20 August As a result, the US government, academics and the fields first private companies are now working together to address the potential problems before they become a reality As well as looking at the fields potential in areas such as drug development, cellular reprogramming and biological robotics, participants will tackle ethical and legal issues As well as monitoring orders for components such as synthetic genes, he says the government should screen certain raw materials that scientists could use to brew up their own DNA. “Basically you want a series of licences to cover almost every step where theres a reasonable bottleneck you can regulate,” he says But many argue that the openness of the field offers a built-in safety mechanism against unintentionally creating something harmful But some, such as Paul Rabinow, an anthropologist at the University of California, Berkeley, think that the field needs to take a broader view than it has so far Does this increased sophistication mean that the field needs radically new rules? Drew Endy, a synthetic biologist at Massachusetts Institute of Technology and one of the leaders of the Sloan Foundation project, is not sure. “There hasnt been a clear conversation about whether de novo synthesis poses a different threat from genetic engineering,” he says For instance, Endys lab hosts an online library of parts that can be built into genomes Genome sequencer Craig Venter followed that by announcing plans to build a bacterium from lab synthesized DNA and by taking just three weeks to synthesize a virus that infects bacteria (H George Church, who co-founded Codon Devices this spring, wants to go further, arguing that strict regulation is a key to heading off the public-relations problems that have plagued other areas of biotechnology He is speaking at the San Francisco meeting this week and says he will tell attendees to pay more attention to the danger that synthetic biology could be abused for biowarfare or bioterrorism, something that is harder to control than the risk of accidents. “The field has been attempting to turn this into a safety issue, but were living today in a security regime,” he told Nature . “Dealing with safety is good, but theyre fooling themselves if they think thats going to be the end of this question.”  Venter agrees, arguing that rather than regulating labs and companies, governments need to use synthetic biology to develop ways to defeat bioterrorist attacks, such as producing drugs and vaccines, or sensors to detect altered organisms in the environment. “If were not concentrating 100% of our defensive effort on countermeasures, I think were missing the big picture,” he told the NSABB in June. Improved DNA synthesis means, for example, that microbial genomes can be built from scratch, bypassing the need to get hold of the actual organism In theory, these techniques could be used to create deadly organisms in the lab, such as Ebola or anthrax, or to make bacteria more dangerous by giving them antibiotic resistance, for example, or the ability to make additional toxins Its members have already consulted synthetic biologists who have set up their own governance project, funded by the Alfred P Many think it would make sense to monitor products ordered from companies that generate synthetic genes on demand, such as Codon Devices in Cambridge, Massachusetts, and Blue Heron Biotechnology in Bothell, Washington Natl Acad Now synthetic biologists have much more powerful techniques at their disposal O Other synthetic biologists point out the success of initiatives to encourage young scientists to think about safety and ethical issues relating to their work. “Its important to talk about ways to minimize risk, and one of the most important ways to do that is to train responsible scientists and engineers,” says Christina Smolke, a chemical engineer at the California Institute of Technology in Pasadena Others are using made-to-order components to re-engineer the genomes of bacteria or viruses — either to investigate how they work or to try to give them abilities that they would not have naturally, such as producing drug molecules or generating hydrogen for use as an energy source Proc Sci Sloan Foundation in New York, which will have its first meeting in September Smith et al  So far, observers are giving synthetic biologists credit for tackling such issues Synthetic biology is one of the priorities for the newly formed US National Science Advisory Board for Biosecurity (NSABB), which met for the first time in June The discussion will echo an event in 1975, when pioneers of genetic engineering retreated to the Asilomar Conference Center in California to set safety and ethical principles to guide their field The fear was that modified microorganisms might escape into the environment with unpredictable effects, perhaps causing disease or out-competing wild strains The library is open source, meaning that all scientists in the field can test them. “Theres an element of safety in using well characterized components,” says Christopher Voigt, a synthetic biologist at the University of California, San Francisco USA 100, 15440–15445; 2003) Washington DC Concerns about safety and security in the young field of synthetic biology are developing almost as rapidly as the research itself Wendell Lim at the University of California, San Francisco, who uses synthetic biology to study basic processes such as how cells grow and move, says that there is nothing special about the field that requires blanket restrictions and that each type of study should be judged on its own risks and merits. “To broadly raise alarms about all such approaches is akin to saying we should worry about all uses of semiconductors because one of their uses could be in launch systems for nuclear weapons,” he says. “We need to distinguish the sub-areas of the field and specific biological components that truly pose a hazard, and figure out how to regulate them.”  Taking care But there are some general precautions that most synthetic biologists support With scientists now able to create complete genomes from scratch and to introduce new characteristics into viruses and bacteria, there are fears that accidental — or worse, intentional — release of such creatures could occur
 Arising from: K Boyd Nature 432 , 499 – 502 ( 2004 ) ; K Boyd reply Panchanathan and Boyd describe a model of indirect reciprocity in which mutual aid among cooperators can promote large-scale human cooperation without succumbing to a second-order free-riding problem (whereby individuals receive but do not give aid) Here I present a simplified version of their model to demonstrate how cooperation unravels if second-round defectors enter the population, and this shows that the free-riding problem remains unsolved. However, the model does not include second-order free riders as one of the possible behavioural types Panchanathan R Panchanathan R Although Panchanathan and Boyd include in their model individuals who receive a benefit without paying the cost in the first round (defectors), they do not consider such a type for the second round Assuming growth of each type in the population is proportional to mean pay-offs, how can we explain the emergence and persistence of cooperators? Panchanathan and Boyd propose that a first-round public-goods game is followed by a second-round ‘mutual-aid’ game But even this assumes that there is no evolutionary pressure on the reliability of information Considering a human context in particular, what keeps these individuals from evolving deceptive behaviours that would reduce the reliability of information and allow them to benefit from aid without providing it? Cooperation can only be maintained when the pay-off to shunners, B − C + bp (1− e )− c [ p (1− e )+ e (1− p )], is greater than the pay-off to second-round defectors, B − C + ebp , or e p b − c 2 p b − c + c This means a population of shunners ( p =1) is only evolutionarily stable if the error is sufficiently small e b − c 2 b − c In other words, cooperation will unravel if second-round defectors cannot be detected most of the time However, they do not give aid to others However, this is only possible if shunners can exclude second-round defectors from mutual aid If at least some acts of giving are not observable, then individuals may have an incentive to misrepresent their behavioural histories in order to secure the benefits of indirect reciprocity without paying the costs If second-round defectors invade a population of shunners, then second-round cooperation collapses, pay-offs to second-round defectors fall, and eventually ordinary defectors can invade and dominate the population — leaving us back where we started If we denote the proportion of shunners in the population by p , then the average pay-off for second-round defectors is B − C + bp and the average pay-off to shunners changes to B + C + bp − c  In contrast, a population of second-round defectors ( p =0) is stable for any positive error rate and can resist invasion even when shunners are common In each period, ‘cooperators’ pay a cost C to contribute to a public good and receive a benefit B . ‘Defectors’ also receive benefit B but do not pay the cost In other words, shunners must be able to recognize and exclude second-round defectors from receiving aid In other words, shunners will prevail if they can create an in-group net surplus from mutual aid in the second round that exceeds the cost of cooperation in the first round In this game, each ‘shunner’ cooperates in the first round and then pays a cost c to generate a benefit b to one randomly chosen shunner, which yields a pay-off of B − C + b − c  Note that the simple model presented here raises a broader concern with all models of indirect reciprocity and related experimental results  Panchanathan and Boyd implicitly acknowledge this problem when they note that each individual must have perfect information about the cooperation and aid-giving histories of all other members of the population in order for mutual aid to be sustained Previous work has already shown that indirect reciprocity is stable only when donors have very reliable information about the behavioural histories of all individuals in the population  Shunners can invade and dominate a population of defectors if b − c C  Suppose a population shows two types of behaviour Suppose that e is the probability that shunners mistakenly aid a second-round defector or withhold aid from a shunner These individuals receive the same pay-off as shunners in the first round and are eligible to receive aid in the second round They do incorporate an error term into their model, but they do not consider errors in which individuals mistakenly help a recipient of bad reputation during the mutual-aid game  Thus, rather than solving the second-order free-rider problem, their model merely assumes it away Thus, the emergence of shunners when they are rare cannot be explained by the authors model  To see why, suppose that ‘second-round defectors’ enter the population
 Above all, they should provide the media with succinct statements and readily reproducible graphics that clearly illustrate not only the conclusions drawn by the working group but also the state of the uncertainties All the more onus on other scientists, then, to help journalists with analyses for public consumption And where there is a maverick voice, that extreme perspective needs to be exhibited as such As a result, many children were not vaccinated, and deaths resulted that could have been avoided But the mass media find it hard to handle scientific uncertainty — and all the more so when vocal scientists promote minority views that have their own appeal to segments of the public, and which gain profile because of media obligations to provide balance But whether scientists take initiatives themselves through campaigning and blogging, or learned societies get sharp, or intermediaries such as the SMC are established, journalists and the public need to be treated as the sophisticated recipients of prompt and well tailored information that most of them are. Even if a high-profile scientist is judged by peers to be lacking credibility, the media will rightly be provoked by attempts at censorship, which fuel allegations of a conspiracy, adding perceived weight to maverick claims In all of this it acts independently, on behalf of both journalists and scientists — but it ultimately serves the media In May 2002, the Science Media Centre (SMC), a UK organization dedicated to providing journalists with access to scientists, conducted a closed seminar in which government officials, reporters, researchers and others reviewed a calamity of communication and of public response to science Is it better for authorities simply to reassure, resisting discussion of uncertainties in the expectation that the public would be paralysed or panic-stricken by the lack of clarity? Or should leaders assume a degree of maturity on the part of the media and public, and represent the state of the science, risks and all? Nature would always urge the latter It is better to attack such claims explicitly on a scientific basis It provides quotes from experts in immediate response to breaking stories, and in-depth briefings for longer-running controversies It should be presented in the context of the range of scientific judgement: not dismissed by assertion, but discussed and visualized against a background of expert opinion and the conclusions of studies It tutors scientists in communicating complexities such as risk with respectable but effective soundbites Learned societies have a particular responsibility in such circumstances Nothing could be more counter-productive Other countries are beginning to take note of the SMC, and Australia is set to clone it Rather, where the stakes for public interests are high, they should promptly convene a working group charged with delivering a statement of the state of relevant evidence, within a few days if necessary Some societies have been known to lobby the media publicly or discreetly to try to discourage them from allowing minority voices to be heard Such problems arise in any scientific country The brainchild of Susan Greenfield, the director of the Royal Institution of Great Britain, which hosts it, its success can be credited above all to the robust leadership of its director Fiona Fox The flashpoint had been some ill-judged remarks made at a press conference in late 2001, suggesting that the triple-vaccine regimen supplied to the UK population against measles, mumps and rubella might be associated with autism The media cannot always be trusted — sometimes for lack of resources and knowledge, or for rank editorial bias The seminar concluded on a dilemma that still faces any government faced by a crisis bedevilled with scientific uncertainties, such as todays threat of avian flu The SMC has made a particular contribution to mitigating them in Britain They should not wait to be called on by a government to provide an analysis What followed were campaigns by the government to reassure parents, and by parents for separate vaccines on demand and against alleged conspiracies by the scientific establishment
 Advocates are encouraged that rich nations have not yet taken up a strong position against them. But the lack of new treatments is now affecting richer countries too But this is the first time the issues have been addressed by the WHO, and advocates for reform are optimistic Developed countries — especially the United States — have in the past strongly opposed such interventions, perceiving them as a threat to the drug industry For instance, one study found that only 1% of drugs brought to market between 1975 and 1999 targeted tuberculosis and tropical diseases such as malaria (P It doesnt endorse specific reforms, although advocates have suggested many options, from an international fund for research into neglected diseases, to a cash prize for developers of innovative drugs It follows a report commissioned by the WHO, released on 3 April, which concluded that the patent system is not working to drive innovation in drugs needed by poor countries It makes 50 recommendations for action Lancet 359, 2188–2194; 2002) Many believe that recent trends — such as the massive and growing cost of health care in the United States, the scarcity of treatments for avian influenza, and the lack of biodefence countermeasures against diseases such as anthrax — are persuading the Western world that the current system does not meet all public-health needs Other studies have found, for example, that an increasing percentage of new drugs are slight variations of already-approved medications. “Theres possibly a recognition that somethings going to have to change,” says Tim Hubbard, a genome biologist at the Wellcome Trust Sanger Institute in Cambridge, UK, who has become heavily involved in the issue. “Everyone can see that spending on research and development is going up, but the number of new drugs coming to market is going down.”  The proposal has been endorsed by a long list of consumer groups, activists and scientists, including Hubbard The first proposal to come before the World Health Assembly, the WHOs governing body, is raised by Kenya and Brazil, and calls on the agency to consider measures that would boost the development of new drugs The global debate over the high cost of drugs reaches Geneva this month, when the governing body of the World Health Organization (WHO) will consider two proposals aimed at reshaping the forces that drive medical research and development The important thing, they say, is that the WHO commits to tackling the issue. “Its been an uphill struggle to get the WHO interested in this question, and if you look at the enormous health needs out there you think, how the hell can this be the case?” says Ellent Hoen of Geneva-based Médecins Sans Frontières. newsad; The second proposal asks the WHO to act on the issue of whether patent laws restrict access to essential medicines The other 99% targeted disorders more relevant to the developed world, such as cancer and heart disease The proposals direct the WHO to act on two controversial issues: the lack of affordable, effective medicines for people in poor countries, and the international intellectual-property system that governs the distribution of medical treatments The proposals will be heard when the assembly meets on 22–27 May The reform movement stems from a growing concern about the lack of treatments, vaccines and diagnostic products for diseases that affect developing countries Trouiller et al 
 An ‘incipient’ spreading centre east of (and orthogonal to) the East Pacific Rise at 2° 40′ N has been identified as forming a portion of the northern boundary of the Galapagos microplate  Here we present evidence that the ‘incipient rift’ has also rifted towards the east and opens anticlockwise about a pivot at its eastern end Our kinematic solution for microplate motion relative to the major plates indicates that the two counter-rotating microplates may be treated as rigid blocks driven by drag on the microplates edges 3 . The Galapagos triple junction region, in the eastern equatorial Pacific Ocean, thus consists of two counter-rotating microplates partly separated by the Hess Deep rift The ‘incipient rift’ then bounds a second microplate, north of the clockwise-rotating Galapagos microplate This spreading centre was described as a slowly diverging, westward propagating rift, tapering towards the East Pacific Rise A crustal magnetization high is centred over the IR at ∼101° 43′ N, which can be explained by a thicker magnetic source layer, younger and therefore more highly magnetized rocks (for example, erupted 10 kyr ago), and/or lavas with higher Fe or Ti contents than the surrounding region A kinematic solution shows that edge-driven microplate mechanisms can explain the motions of this dual microplate system A newly discovered trough, which we call the ‘extinct rift’, located north and east of the IR ( Fig. 3a ) may represent the northern boundary of such an extinct microplate A study of the western portion of the IR suggested that it consists of a slowly diverging (∼ 15 mm yr -1 ), westward propagating, spreading centre between the Cocos and Galapagos plates, which leaves a wedge-shaped gore in its wake  Along the eastern portion of the IR, reflection amplitudes delineate an eastward-narrowing, highly reflective ‘wedge’ that coincides with the location of the bathymetric trough Although not as fresh as lavas observed at recent EPR axial eruptions, the lavas photographed along the eastern IR appear significantly younger than the calculated crustal age of ∼400–700 kyr (based on the EPR spreading rate), and therefore probably erupted in situ  Cocos–Nazca–Pacific motion and distances between IRRAs scale the relative rotation rates about those axes Considered in the evolutionary history of the GMP region, we speculate that the eastern tip of the IR or Dietz Deep may ultimately break through the bounding walls of the Hess Deep gore to connect with the Cocos–Nazca spreading centre Details of the kinematic modelling are provided in Supplementary Information  Early studies suggesting that the northern boundary consisted of the westward extension of the Cocos–Nazca spreading centre were later refuted by the finding that the Cocos–Nazca spreading centre does not link to the EPR, but rather terminates ∼50 km east of it at the Hess Deep  Estimated spreading rates predict that since its initiation at 0.5 Myr ago, a maximum of ∼7.5 km of new IR-generated crust should have formed, a distance that agrees well with the maximum width of the lozenge ( Fig. 1 ) Here we present findings based primarily on our bathymetric, side-scan, magnetic and camera tow results If the IR opens about a pivot at its eastern end, lithosphere immediately south of the IR must rotate anticlockwise about this pivot ( Fig. 3 ) If this happens, the driving torque for the microplate will cease, and the microplates will stop rotating and will be rafted away from the EPR axis If this model is correct, we speculate that it may be applicable to other triple junctions  In a number of photographs, particularly along the eastern portion of the IR, lavas appear to emanate from local fissures with east–west orientations (for example, Fig. 2b ) In August 2002, aboard the R/V Melville , we mapped and sampled a broad region centred on the IR, including its intersection with the EPR and extending ∼140 km to the east In contrast to the relatively well-understood southern boundaries of the GMP, the configuration of its northern boundary has not been fully elucidated In edge-driven microplate systems like the Easter and Juan Fernandez microplates, these axes commonly lie ahead of the tips of the microplate bounding rifts In the absence of radiometric age dates, we speculate that these lavas are a few thousand years old, based on age-dating studies performed on lavas photographed in place elsewhere  In the current plate configuration, this plate boundary widens and deepens as it approaches the southern bounding scarps of the Galapagos gore, near 101° W, in what is called the Dietz Deep In the specific case of the Galapagos triple junction, we suggest that the dual microplate system acts to control the location and configuration of the Hess Deep rift and the stability of the Galapagos triple junction. In this approach, the rotation of a microplate is driven by a shear couple between a pair of bounding plates moving in opposite directions It follows that what was previously considered one coherent microplate, must, in fact, form two separate microplates ( Fig. 3 ): the northern portion of the GMP (NGMP), rotating anticlockwise, and the remaining portion of the GMP to the south, rotating clockwise Lonsdale proposed that isolation of ocean crust generated at the East Pacific Rise (EPR) initiated in the south at ∼1 Myr ago with the growth of a prominent seamount adjacent to the Pacific–Nazca spreading centre Magnetic anomaly profiles run over the IR also support recent magmatic activity ( Fig. 1b ) Our new view of the Galapagos triple junction is that of two adjacent counter-rotating microplates distributing the strain around this triple junction Over time, this spreading centre propagated northeastwards, becoming the Nazca–Galapagos spreading centre Photographs of the crust along the IR show sparsely sedimented lavas, often with delicate ornamentation and basaltic glass (recovered by dredging), with local in-filling of sediment between pillows ( Fig. 2a–c ) Previous studies of northern EPR crust show that within a few kilometres of the ridge axis, undisturbed lavas generally become buried under a thick pile of sediment  SeaBeam amplitudes for the IR indicate high reflectivity consistent with relatively sparse sediment cover compared to adjacent sea floor ( Fig. 2a ) Since that time, it has propagated eastward at a rate that we are not able to determine (that is, instantaneously as a crack or more slowly) Subsequent surveys further north, however, identified the ‘incipient rift’ (IR), a magmatically active, newly forming, spreading centre east of and orthogonal to the EPR at ∼2° 40′ N (refs 1 , 2 , 8 ), forming at least a portion of the northern boundary of the GMP The apex of this wedge clearly cuts north–south-oriented abyssal hills and then dies out in the vicinity of 101° 30′ W ( Fig. 2a ) The development of the Galapagos microplate (GMP) in the eastern equatorial Pacific Ocean begins with the confluence of the Cocos–Nazca, Pacific–Nazca and Pacific–Cocos spreading centres, forming a diffuse triple junction ( Fig. 1b inset) The east–west-trending IR is shallowest (∼ 2,900 m below sea level) near its intersection with the EPR (at ∼2° 40′ N), and deepens progressively eastward ( 3,500 m), exceeding average depths of ambient sea floor to its north ( Fig. 1a ) The fact that the eastern portion of the reflective IR wedge cuts north–south-oriented abyssal hills, combined with the side-scan, magnetic and camera-tow data suggesting recent magmatism along this wedge, raises the possibility that the IR is opening like a small sphenochasm (a wedge-shaped opening) about a pivot located near the eastern tip of the wedge The higher iron contents of basalts (13–16 wt% Fe 2 O 3 ) dredged from this region can explain only half the amplitude of the magnetization  The IR sea floor at this location would also have been subjected to ∼6.5° of rotation, an angle that is probably too small to be resolved in the form of deformed fabric of the sea floor The loci of greatest depths along the eastern half of the IR form a sinuous trough that trends ∼100° to the southeast The maximum width of the lozenge shape of the IR marks the location and time (0.5 Myr ago) when the IR was established adjacent to the EPR The photographic and magnetic data support the idea that the IR, including the eastern reflective trough, is magmatically active The solution in Fig. 3b , which has NG-C, G-N and NG-G IRRAs respectively located on the NGMP–Cocos, GMP–Nazca, and NGMP–GMP boundaries, suggests that the counter-rotating microplates can be modelled as rigid blocks and that their rotation could be driven by drag on the microplates edges rather than by shear flow of mantle underneath  The three axes and major plate motions ( Fig. 3a inset) determine a solution for the instantaneous motion of the two microplates ( Fig. 3b ) that satisfies the triple junction geometries at 2° 40′ N 1 and 1° 10′ N 2  The two points of coupling between the microplate and bounding plates are represented by two instantaneous relative rotation axes (IRRAs) There is some evidence that this has happened in the past This anticlockwise rotation contrasts with the known clockwise rotation of the southern portion of the GMP, south of the Hess Deep rift  This led to a zone of weakness and magma upwelling between the seamount and the adjacent EPR, forming a short, east–west-trending spreading centre This suggests that although the IR is magmatically active along its length, it may be only sporadically so, interspersed with periods of magmatic inactivity and sediment burial, consistent with its slow spreading rate Thus, the IR can be viewed as a lozenge-shaped feature, with the western taper reflecting westward growth of the IR at the EPR triple junction , and the eastern taper indicating opening about a stable pivot at the eastern tip ( Figs 1 and 2 ) Using magnetic field data (collected on our own cruise and on previous cruises), we calculated crustal magnetization, taking into account bathymetry and assuming a constant source thickness of 0.5 km (refs 12 , 13 ) Various geological, geophysical and rock sampling tools were used, including SeaBeam2000 bathymetry and side-scan (amplitude) coverage; towed magnetometer; bottom photography (14 camera tows using the WHOI Towed Camera System); water column hydrothermal surveying ; and rock sampling  We estimate the kinematics of the GMP and NGMP by drawing upon the concepts of edge-driven microplate mechanisms  We identify three likely IRRA locations—labelled NG-C, G-N and NG-G in Fig. 3a —at the tips of three of the rifts that bound the microplates, that is, at the eastern end of the IR, at the Hess Deep and at the Dietz Deep We suggest that the other half is caused by the high magnetization of young lavas that record the high geomagnetic field intensity of the past 10 kyr (ref. 15 )
 All this puts pressure both on researchers to publish in journals with high rankings and on journal editors to attract papers that will boost their journals profile Bollen, however, proposes combining the two metrics. “One can more completely evaluate the status of a journal by comparing and aggregating the different ways it has acquired that status,” he says But for Bollen, ranking journals more effectively by combining different ranking systems could help protect the integrity of science But the rise of online journals, coupled with sophisticated search engines that permit rankings of web resources, is triggering a wave of other measures For example, among physics journals, the IF places Reviews of Modern Physics at the top of the list, but the Y-factor shifts the emphasis to rapid-publication journals He predicts that metrics such as the PR ranking may come to be more influential in the perception of a journals status than the traditional IF. “Web searchers have collectively decided that PageRank helps them separate the wheat from the chaff,” he says He warns that scientists and funding agencies have used the ranking system well beyond its intended purpose. “Weve heard horror stories from colleagues who have been subjected to evaluation by their departments or national funding agencies which they felt were strongly influenced by their personal IF,” he says. “Many fear this may eventually reduce the healthy diversity of viewpoints and research subjects that we would normally hope to find in the scholarly community.”  Jim Pringle, vice-president of development at Thomson Scientific, is also keen on the idea. “We have always advocated that research evaluation should be derived not only from metrics such as the IF but also from a thorough knowledge of research content,” he says. “Journal status metrics such as this, used in combination with our data, should be encouraged.” It counts the total number of citations a journals papers receive, and divides it by the number of papers the journal publishes Journal rankings should measure quality, not just quantity, say researchers who are proposing a new way to assess the status of science publications Last year, for example, physicist Jorge Hirsch of the University of California, San Diego, proposed a metric called the h-index for assessing the quality of researchers publications (see Nature 436 , 900 ; 2005 ) Now Johan Bollen and his colleagues at the Research Library of Los Alamos National Laboratory in New Mexico are focusing on Googles PageRank (PR) algorithm Physical Review Letters is the most influential, with a Y-factor of 5.91×10 −2 . (Declaration of interest: Nature receives a very high Y-factor.) newsad; Reinhardt Schuhmann, an editor on Physical Review Letters , calls the proposal “an interesting idea”, but thinks that such metrics arent really needed to prove status. “We dont pay much attention to impact factors,” he says Ranking journals and publications is not just an academic exercise So a link from a popular page is given a higher weighting than one from an unpopular page So Bollen and his colleagues propose ranking journals according to the product of the IF and PR, a measure they call the Y-factor Some journals, he points out, can have high IFs but low PRs (perhaps indicating a popular but less prestigious journal), and vice versa (for a high-quality but niche publication) Such schemes are increasingly used by funding agencies to assess the research of individuals and departments The algorithm can be applied to research publications by analysing how many times those who cite a paper are themselves cited The algorithm provides a kind of peer assessment of the value of a web page, by counting not just the number of pages linking to it, but also the number of pages pointing to those links, and so on The most popular index of a journals status is the ISI Impact Factor (IF), produced by Thomson Scientific They also serve as a guide for librarians choosing which journals to subscribe to Using information from different metrics would also make the rankings harder to manipulate, he adds Whereas the commonly used impact factor simply measures the number of citations per paper, the researchers say their ranking scheme also measures the significance of those citations, giving a truer measure of a journals standing in the community Whereas the IF measures crude ‘popularity’, PR is a measure of prestige, says Bollen Whereas the top ten list by IF includes many journals that publish only review articles, or that serve primarily as data resources, the Y-factor ranking pushes up journals widely regarded as publishing prestigious original research (see table )
 As hot, acidic and reduced hydrothermal fluids mix with cold, alkaline and oxygenated sea water, minerals precipitate to form porous sulphide–sulphate deposits Culture-independent surveys based on ribosomal RNA genes from deep-sea hydrothermal deposits have identified a widespread euryarchaeotal lineage, DHVE2 (deep-sea hydrothermal vent euryarchaeotic 2)  Deep-sea hydrothermal vents are important in global biogeochemical cycles, providing biological oases at the sea floor that are supported by the thermal and chemical flux from the Earths interior Despite the ubiquity and apparent deep-sea endemism of DHVE2, cultivation of this group has been unsuccessful and thus its metabolism remains a mystery Here we report the isolation and cultivation of a member of the DHVE2 group, which is an obligate thermoacidophilic sulphur- or iron-reducing heterotroph capable of growing from pH 3.3 to 5.8 and between 55 and 75 °C In addition, we demonstrate that this isolate constitutes up to 15% of the archaeal population, providing evidence that thermoacidophiles may be key players in the sulphur and iron cycling at deep-sea vents. It has been proposed that fluid pH in the actively venting sulphide structures is generally low (pH 4.5) , yet no extreme thermoacidophile has been isolated from vent deposits These structures provide microhabitats for a diversity of prokaryotes that exploit the geochemical and physical gradients in this dynamic ecosystem  A suite of carbon source sugars and proteinaceous compounds were tested at 0.1–0.5% (w/v, final concentration; Supplementary Methods ) as alternative carbon sources in media amended with vitamins or 0.01% yeast extract Confidence of tree topologies were estimated by performing 100 bootstrap replicates using fastDNAml Enrichment cultivation and isolation Enrichment cultures were started several months later in the land-based laboratory at Portland State University Growth was monitored by cell counts in triplicate cultures, and repeated at least twice Initial enrichments were incubated at 70 °C in anaerobic marine media ( Supplementary Methods ) Membrane lipid analysis Membrane lipids were extracted ( Supplementary Methods ) and analysed by high performance liquid chromatography/atmospheric pressure chemical ionization/mass spectrometry  Methods Full details are given in the Supplementary Methods  Once on board ship, subsamples where the DHVE2 were detected were taken by using sterile spatulas and removing the ∼1–3-mm-deep superficial sulphur or iron crusts Phylogenetic analysis of 16S rRNA sequences 16S rRNA gene sequences were amplified by PCR ( Supplementary Methods ) and manually aligned on the basis of secondary structure constraints in the ARB software package  Phylogenetic relationships were determined using evolutionary distance and maximum likelihood analysis Phylogenetic trees were constructed using 1,356 homologous nucleotides with the fastDNAml program , using an optimized T transition/transversion ratio of 1.52 and the global branch rearrangements option Quantitative PCR Samples were analysed for DHVE2 abundance and total archaeal abundance by quantitative PCR (qPCR; Supplementary Methods ) Samples were stored anaerobically in serum vials at 4 °C as rock slurries or frozen immediately for DNA extractions Sampling sites Actively venting sulphide samples were collected using the DSRV Alvin or DSROV Jason II from the EPR or the ELSC, respectively Transmission electron microscopy Both negatively stained cells and stained thin sections ( Supplementary Methods ) were viewed with a Philips CM10 operating under standard conditions at 100 kV. A DHVE2 genome fragment from a metagenome library contained a thermostable DNA polymerase, which was further suggestive of the thermophilic nature of this lineage  Acidulus (Latin), a little sour, acidulous; profundus (Latin), deep; Aciduliprofundum , a bacterium isolated from acidic deep-sea vents; boonei (Latin), of Boone, named in honour of David Boone for his contributions to the study of archaeal diversity Additional thermoacidophilic enrichments of DHVE2 were obtained from two sites along the ELSC (Kilo Moana, 20° 3.2′ S, 176° 8.0′ W, ∼2,620 m, and Tow Cam, 20° 19.1′ S, 176° 8.2′ W, ∼2,720 m; ref. 21 ) and five sites along the EPR (at 9° 17′ N, 9° 33′ N, 9° 46′ N, 9° 47′ N, 9° 50′ N) Additionally, owing to the association of DHVE2 with dense biofilms that form among iron oxides and elemental sulphur, it is possible that these communities provide both the oxidized substrates and the complex organics to support the observed metabolism of this archaeon Additionally, owing to the high guanine and cytosine content of the 16S rRNA sequence and its occasional co-occurrence with thermophiles such as Thermococcus , it has been suggested that the DHVE2 are thermophiles, perhaps heterotrophs whose growth may be stimulated by sulphur  After a week, two cultures (designated strains T449 and T469) were purified by three serial dilutions Although S-layers are quasi-crystalline, this S-layer bends into small highly curved structures ( Fig. 2d , vesicles) Anaerobic heterotrophic sulphur- and iron-reducing thermoacidophile belonging to the kingdom Euryarchaeota As this organism is the first isolate in the DHVE2 clade, representing a new Order within the phylum Euryarchaeaota, we propose the following candidate status of this taxon; ‘ Aciduliprofundum boonei ’, gen. et sp. nov Cells are pleiomorphic to spherical, about 0.6–1 µm in diameter, with a single flagellum and an S-layer Chemical analyses showed that its membrane lipids are predominantly composed of glycerol dibiphytanyl glycerol tetraethers containing 0–4 cyclopentane rings Comparative sequence analysis of the 16S rRNA gene of strains T449 and T469 placed these isolates within the DHVE2 Culture-dependent and culture-independent approaches have exposed a vast diversity of Bacteria and Archaea associated with deep-sea vent deposits (see, for example, refs 1 , 13 , 14 ), with the Bacteria being dominated by many novel branches of the ɛ-Proteobacteria  Diagnosis Etymology For example, calculations of transport across chimney walls showed that the pH of fluids (at 120 °C) within pores of chimneys should be very low (pH 3) if only diffusion is occurring For example, Thermococcus , perhaps the most frequently cultivated thermophile from deep-sea vents, grows best around pH 6.5, with the majority of species unable to grow below pH 5.5 and only some species can grow very poorly at about pH 4 (ref. 12 ) From actively venting deep-sea vent deposits, first isolated from deep-sea vents at 22° 10.8′ S, 176° 36.1′ W (Mariner vent field) Furthermore, this archaeon shares an overlapping niche with other fast-growing thermophilic heterotrophs, such as Thermococcus  Generally, the occurrence of DHVE2 appeared to be associated with the fine-grained white elemental sulphur (S 8 ; identified in three different samples by X-ray diffraction; Supplementary Methods ) or iron oxyhydroxide (X-ray amorphous—identified on the basis of orange colour and texture; Supplementary Table 3 ) deposits that often coat the outside of mature actively venting sulphide deposits ( Supplementary Fig Grows best at 70 °C and pH 4.2–4.8 Here, the contrasting geochemistry of hydrothermal fluids and sea water, the mineralogy of porous substrates, and microbial activity are tightly coupled However, all attempts to culture this group—using standard media and conditions to select for sulphate reducers, methanogens or fermenters at 60, 80 and 90 °C and around pH 6.5—have been unsuccessful  However, although numerous Archaea have been isolated from these deposits, few isolates are found in environmental 16S rRNA gene clone libraries and most environmental clones have no representatives in culture  4–6); with advection of vent fluid outward, pH at 50–80 °C should range from 3 to 6 for low rates of flow, or from pH 3 to 4.5 (similar to that of the vent fluid measured at 25 °C) for rapid rates of flow  In addition, localized acidity is produced chemically as minerals such as pyrite and chalcopyrite form: Fe 2+ + 2H 2 S = FeS 2 + H 2 + 2H + and Cu + + Fe 2+ + 2H 2 S = CuFeS 2 + 0.5H 2 (aq.) + 3H +  In particular, one lineage is widespread at deep-sea vents and is frequently associated with actively venting sulphide deposits It is likely that under most enrichment conditions of higher pH, Thermococcus would rapidly outcompete the DHVE2, and this prevented our successful isolation of this novel lineage in the past It is therefore surprising that all thermophiles thus far isolated from deep-sea vents are neutrophiles, or slightly acidophilic and at best acidotolerant , and grow very poorly or not at all at the predicted low pH conditions from which they were isolated It is thus possible that the numerous lineages that have been identified from similar environments using culture-independent approaches may be acidophiles, or inhabit some microhabitat yet to be identified Like many other Archaea (for example, Methanococcus and Sulfolobus ), they are enveloped by a plasma membrane and a single S-layer ( Fig. 2a , e ) Likewise, these deep-sea oases have provided a vast array of newly described free-living microbes, many associated with the actively forming porous deep-sea vent deposits such as ‘chimneys’ On the basis of predictions that conditions within many sulphide deposits should be acidic, and owing to the presence of novel sequences most closely related to the acidophiles Thermoplasma , Picrophilus and Ferroplasma ( Fig. 1 , sequence LART667E06) and the presence of the DHVE2 group from two samples obtained from the Mariner deep-sea vents along the ELSC (22° 10.8′ S, 176° 36.1′ W—depth of vent field ∼1,920 m; ref. 18 ), we enriched for heterotrophic thermoacidophiles (pH 4.5) using trypticase peptone, yeast extract and elemental sulphur One strain from the Mariner vent site, T469, was further characterized and its purity was confirmed by repeated sequencing of the 16S rRNA gene S1 ) S2 ) S3 ) at 70 °C and to a maximum cell density of about (4–6) × 10 8  cells ml -1  Since their discovery in 1977, deep-sea hydrothermal vents have provided one of the few environments on Earth for searching for the upper temperature limits of life; these ecosystems may represent models for both the origin of life on Earth and exploration of life on other planets Some flagella have their proximal end encased in an unusual complex periodic sheath ( Fig. 2c ) Strain T469 is, to our knowledge, the first obligate thermoacidophile to be reported from deep-sea vents and the first cultivated member of the DHVE2 group Such isolates will not only expand our understanding of the role these organisms play in the hydrothermal vent environment, but also provide clues to the biosignatures that remain in the ancient hydrothermal rock record. The ability of DHVE2s S-layer to bend into such high curvature structures as these vesicles suggests that the bonding forces between S-layer subunits are weak or transient The cells are pleiomorphic to spherical, about 0.6–1 µm in diameter and are motile with a single flagellum ( Fig. 2a , b ) The DHVE2 are often found co-occurring with lineages such as the ɛ-Proteobacteria (based on 16S rRNA gene data, not shown) The DHVE2 were identified in 36 samples, and represented up to 10% and 15% of the archaeal population at EPR and ELSC, respectively (as determined by quantitative polymerase chain reaction (qPCR); Table 1 ) The group forms a monophyletic clade, and isolates are closely related (about 95–97% similar) to cloned 16S rRNA gene sequences obtained from deep-sea vents and a sequence obtained from methane-hydrate-bearing marine sediments at about 200 m below the sea floor (m.b.s.f.) from the Cascadia margin ( Supplementary Table 1 ) The isolate does not grow above 77 °C or below 50 °C, but like Thermococcales and Thermotogales it is an obligate anaerobe requiring elemental sulphur (or ferric iron), NaCl (optimum 2.5–3.5% w/v) and complex organics such as trypticase peptone, casein and yeast extract for growth ( Supplementary Methods , Table 2 ) The new isolates are only 83% similar in 16S rRNA sequence to their closest relative in culture, Thermoplasma volcanium , an isolate from shallow marine vents and solfataras that grows best at pH 2.0 and 60 °C ( Table 2 ) The organism grows between pH 3.3 and 5.8, growing best between pH 4.2 and 4.8 ( Supplementary Fig The S-layer, similar to that of Picrophilus oshimae , is thick (∼40 nm), with a presumed tetragonal ( p 4) lattice and resembles a delicate bridal veil bordering the cells ( Fig. 2a ) The steep chemical and thermal gradients within the walls of these vent deposits provide a wide range of microhabitats for microorganisms  The successful cultivation of this thermoacidophile from deep-sea vents points to the importance of the role that culture-independent approaches have played in exposing the vastness and ecological significance of the diversity of microbes, but also to the integrative approach where geochemical modelling has predicted the environmental conditions in which this diversity thrives The ‘deep-sea hydrothermal vent euryarchaeotic’ lineage DHVE2 is often found in clone libraries (see, for example, refs 3 - 6, 14 –16 ) and has been reported as the most dominant clone type in some archaeal clone libraries ( Supplementary Tables 1 and 2 ) These bacteria are probably autotrophic sulphide/sulphur or hydrogen oxidizers that could create a localized anaerobic environment (and also biologically lower the local pH), providing a microniche for anaerobic acidophiles These membrane lipids have also been detected in the closest cultured relatives Ferroplasma and Thermoplasma and are thought to be unique to acidophilic Crenarchaeota and Euryarchaeota  These vesicles bud from the cell, partitioning small quantities of cytoplasm that could then anneal to adjacent cells This agrees well with an in situ measurement of pH made at the exterior of a chimney wall at 13° N on the East Pacific Rise (EPR), beneath a colony of Alvinella pompejana ; the pH was 4.1 at a temperature of 120 °C (ref. 9 ) This ecosystem, fuelled largely by geochemical energy, hosts many invertebrates new to science, and they often thrive because of their endosymbiotic bacterial partners This is a process that is common among their Gram-negative bacterial counterparts  This is unusual , especially as this S-layer is the sole cell wall structure Using a specific primer set for the DHVE2 16S rRNA gene ( Supplementary Methods ), we screened 63 samples from multiple vent sites along two ridge systems (the EPR from 9° 16.8′ N, 104° 13′ W to 20° 50′ N, 109° 07′ W, and the Eastern Lau Spreading Centre, ELSC, from 20° 3.2′ S, 176° 8.0′ W to 22° 10.8′ S, 176° 36.1′ W) during three different research cruises ( Supplementary Table 2 , Supplementary Fig With this confirmation of extreme thermoacidophiles from deep-sea vents, it is likely that this physiological group plays a central role in the biogeochemistry and mineralogy at deep-sea vents
 Gap-junction-mediated peptide transfer is restricted to a few coupling cells owing to the high cytosolic peptidase activity Here we show that peptides with a relative molecular mass of up to ∼1,800 diffuse intercellularly through gap junctions unless a three-dimensional structure is imposed Major histocompatibility complex (MHC) class I molecules present peptides that are derived from endogenous proteins  These antigens can also be transferred to professional antigen-presenting cells in a process called cross-presentation, which precedes initiation of a proper T-cell response ; but exactly how they do this is unclear This intercellular peptide transfer causes cytotoxic T-cell recognition of adjacent, innocent bystander cells as well as activated monocytes We present a mechanism of antigen acquisition for cross-presentation that couples the antigen presentation system of two adjacent cells and is lost in most tumours: gap-junction-mediated intercellular peptide coupling for presentation by bystander MHC class I molecules and transfer to professional antigen presenting cells for cross-priming. We tested whether peptides can be transferred directly from the cytoplasm of one cell into the cytoplasm of its neighbour through gap junctions A431 and A431/Cx43 cells were stably transfected with HLA-A2.01 cDNA cloned in pcDNA3 A431 cells revealed monocytes with only background fluorescence A431 cells were stably transfected with human Cx43 complementary DNA in pcDNA3 (provided by B A431 or A431/Cx43 cells were transfected by electroporation using a Biorad Gene Pulser  A431/Cx43 cells expressing GFP-Ub-FluM 57–65 were co-cultured with A431/Cx43 cells expressing HLA-A2, and stained with MA2.1, followed by formaldehyde fixation and staining with anti-Cx43 antiserum and secondary TexasRed- and Cy5-labelled antibodies About 10–20% calcein-positive monocytes were recovered from HUVEC co-cultures and 5–8% from A431/Cx43 Activated HLA-A2-positive monocytes were added to the culture (in approximately a twofold cell excess) After 16 h, propagation of infection was inhibited by 10 µg ml -1 ribavirin ( ICN ) and 25 µg ml -1 chloroquine After 18 h co-culture, IFN-γ secretion was measured by enzyme-linked immunosorbent assay (ELISA) ( PeliKine Compact , CLB ) and quantified using internal standards An N-terminal naftylsulphonyl group and C-terminal aminidation were introduced to prevent degradation  Both monocytes and HUVECs were tested for HLA-A2 expression with the mAb BB7.2 Calcein-positive and -negative monocytes were isolated by FACS and pulsed with different concentrations of the FluM 57–65 peptide before co-culture with the CTL clone for another 18 h and detection of IFN-γ secretion by ELISA. Calcein-positive and -negative monocytes were subsequently co-cultured for another 18 h with the CTL clone and IFN-γ secretion was determined by ELISA assay Cells were co-cultured for 18 h and removed by trypsinization because both populations were strongly adhering to the underlying monolayer Cells were subsequently labelled with calcein-AM ( Molecular Probes ) at a concentration of 1 µg ml -1 for 45 min followed by extensive washing Cross-presentation assays The GFP-Ub-FluM 57–65 construct was made by PCR on ubiquitin using a reverse primer with a flanking region containing the sequence encoding the FluM 57–65 peptide, placing the peptide directly adjacent into the ubiquitin-splicing site following Gly 76 of ubiquitin Cyclization (thioether formation by reaction of cysteine with the bromo-acetyl moiety) was performed at pH 8, followed by fluorescein isothiocyanate (FITC) conjugation of lysine FACS was subsequently used to isolate the calcein-positive and -negative monocytes FluM 57–65 peptide sequence: GILGFVFTL Fluorescein was conjugated to cysteine residues using fluorescein-5-iodoacetamide ( Molecular Probes ) Fluorescent secondary antibodies were from Molecular Probes  FRAP experiments were performed with a Leica TCS-SP2 CLSM , as described  Giepmans) Human monocytes were obtained from healthy HLA-typed volunteers by isolation of peripheral blood lymphocytes (PBL) by Ficoll centrifugation and a subsequent short adherence step HUVEC cells were isolated following standard protocols HUVEC cells were transfected using the Amaxa HUVEC Nucleofector kit . 24 h after transfection, cells were FACS sorted for equal GFP expression and the GFP-positive cells were co-cultured with equal numbers of acceptor cells for another 24 h followed by the addition of T-cell clone InfA13TGA Images were made with a Leica TCS-SP2 CLSM  Internally quenched peptides were synthesized as described: with sequences T[K-Dabcyl]NKTER[C-fluorescein]Y with either an N-terminal P or LGP addition for the 10- and 12-mer peptide Methods Cells, antibodies and peptides The following antibodies were used: mAb MA2.1 and BB7.2 (anti-HLA-A2), mAb 1B5 (anti-HLA-DR); rabbit anti-Cx43 ( Sigma ) Monocytes were activated by an 18-h culture in the presence of IFN-γ (1 ng ml -1 ) and TNF-α (1 ng ml -1 ), as described  No fluorescence was detected in control stainings (secondary antibody only) No post-wash labelling of monocytes was detected under these conditions One cell was micro-injected with a mixture of FL-peptide and TxR-dextran ( M r 70K; Molecular Probes ) in the presence or absence of 100 µM 2-aminoethoxydiphenylborate ( 2-APB , Sigma ) Paraffin-embedded sections of human epidermis and appendix were stained with the mAb 1B5 and Cx43 antiserum followed by TexasRed-, Cy5- or fluorescein-labelled secondary antibodies Peptide degradation of internally quenched peptides was assayed as described  Peptide transfer and degradation To detect intercellular peptide transfer, cells were seeded at a high dilution on coverslips resulting in small cell islands after 2–3 days of culture Peptides for intercellular peptide transfer experiments were composed of d -amino acids Peptides were synthesized by Fmoc (fluorenylmethoxycarbonyl) chemistry, purified and confirmed by mass spectrometry Quantification was performed 30–90 min after micro-injection The circular peptide was prepared by extending the sequence LDRLDRCK with a bromo-acetyl moiety The human T-cell clone (InfA13TGA) overexpressing telomerase is recognizing FluM 57–65 in the context of HLA-A2 (ref. 30 ) The sequences were: LDRLDRLDR[C-fluorescein] and N-terminal truncations down to LDR[C-fluorescein] These inhibitors were present during all subsequent culture steps This product was cloned in pEGFP-C1 ( Clontech ) To control for antigen presentation capacity, HLA-A2-expressing monocytes were co-cultured with HUVEC cells without influenza infection and inhibitors To determine the rate of intercellular peptide transfer, the identical experiment was performed followed by subsequent bleaching of one of the FL-peptide acceptor cells with 488-nm laser light To study antigen transfer, A431, A431/Cx43 or (HLA-A2-negative) HUVEC cells were infected with influenza A virus strain A/WSN/33 (H1N1) at a concentration of 4 × 10 6 plaque-forming units (PFU) per ml for 18 h A 9-mer FL-peptide was introduced in A431/Cx43 and control A431 cells by micro-injection, together with dextran-TexasRed (TxR) ( M r 70K) as an injection marker A CTL response was detected only for the dye-containing monocytes, implying that these monocytes presented an influenza peptide generated in HUVEC and A431/Cx43 cells ( Fig. 4d ) A functional channel is formed when a hemichannel, composed of six connexin molecules, assembles with a hemichannel from an adjacent cell  A T-cell response resulting in interferon-γ (IFN-γ) secretion was observed only when both the peptide-expressing donor and the HLA-A2-expressing acceptor cells express gap junctions (which is required for a functional channel) and no significant response is found for the other conditions ( Fig. 3c ) A431 cells were stably transfected with human Cx43 ( Fig. 1a ), resulting in functional gap junctions After 16 h of infection, influenza propagation was inhibited and the infected cells were loaded with the dye calcein-AM that diffuses through gap junctions Again, the calcein-positive and -negative monocyte populations were isolated and pulsed with FluM 57–65 peptides before addition of specific CTLs ( Fig. 4e ) Again, through immunological coupling these tissue-specific APCs may sample peptides from their environment for cross-presentation to T cells at other locations Also, auto-antigenic peptides may be transferred through gap junctions, which could explain the observed recognition of endothelial cells surrounding Islet cells by activated CD8 + insulin-specific T cells  Although stable peptides can be transferred intercellularly, the high cytosolic peptidase activity might restrict or even prevent intercellular transfer of normal peptides in vivo  Antigen acquisition by gap junctions couples the antigen presentation pathways of neighbouring cells, resulting in cross-presentation by innocent bystanders and APCs. Antigenic peptides from infected cells are thus exclusively loaded on the cells own MHC class I molecules and not on those of innocent bystander cells Antigens coupled to beads can be transferred to the cytoplasm in early phagosomes of dendritic cells  Apoptotic bodies are a possible physiological equivalent for beads and are cross-presented by CD8 + DCs in the mouse (this DC subset has not been identified in man)  At the same time, HLA-A2-negative A431, A431/Cx43 or HUVEC cells were infected with influenza Because A431 cells do not endogenously express HLA-A2, activation of the FluM-specific T-cell clone can only occur following gap-junctional transfer of the peptide between the peptide-expressing (donor) and the HLA-A2-expressing (acceptor) cells Because gap-junction-negative A431 cells only revealed monocytes with background fluorescence, T-cell stimulation was determined only for the dye-negative population Because intracellular antigens and antigenic peptides usually cannot traverse membranes, only endogenous peptides can be presented by MHC class I molecules  Because many tumours as well as viruses express anti-apoptotic proteins, their antigens will not induce a proper T-cell response Both monocyte populations were strongly adhering to the monolayer and collection required trypsin treatment By comparing the half-life of peptides in vivo and the rate of intercellular peptide transfer, the efficiency of intercellular peptide transfer in A431/Cx43 cells can be estimated By establishing gap-junctional contact with local cells, they may sample a fraction of peptides expressed in these cells and transfer their antigenic peptides to lymph nodes for T-cell activation and expansion Cells were subsequently analysed by confocal laser scanning microscopy (CLSM) ( Fig. 1b ) and transfer was quantified in both cell lines ( Fig. 1c ) Characteristic MHC class II-positive Langerhans cells expressed high levels of Cx43 compared with the surrounding keratinocytes ( Fig. 4a ) Closure of gap junctions by chemical inhibitors such as 2-APB (ref. 16 ) prevented this intercellular peptide transfer between A431/Cx43 cells Connexin 43 (Cx43) is broadly expressed, whereas the other connexin family members are expressed in specific tissues only Consequently, antigens have to be expressed at relatively high levels to ensure antigen transfer to APCs for cross-presentation to occur, as has been previously suggested  Consequently, neighbouring cells can be primed with a viral peptide, recognized and possibly killed by CTLs before actual infection by the virus or before the production of viral DriPs , albeit at the cost of some cells that would not have been infected Cross-presentation implies the transfer of antigenic (usually intracellular) antigens from diseased cells to professional antigen-presenting cells (APC) such as dendritic cells, activated monocytes or Langerhans cells  Cross-presentation is analogous to presentation by bystander cells when the acceptor cell is a professional APC Cross-presentation of antigenic peptides by APCs is required for expansion of a specific T-cell population Cross-presentation requires that antigens somehow enter the MHC class I presentation pathway of an APC Cross-presentation then would require proteins to be released from the apoptotic bodies during an early phase of uptake  Cx43 is also expressed in various haematopoietic cells like follicular dendritic cells, B cells, activated lymphocytes and monocytes  Cx43 is upregulated in human monocytes upon stimulation with IFN-γ and TNF-α , and non-stimulated monocytes did not cross-present antigens in our protocol (not shown) Cytosolic peptidase activity will therefore limit, but not prevent, spreading of peptides to adjacent cells, thus restricting cross-presentation by innocent bystander cells Exogenous (stable) proteins and heat-shock protein-associated antigens can induce CD8 + T-cell responses but these proteins first have to enter either the general MHC class I presentation pathway, or be presented on recycling MHC class I molecules  For the initiation of a CTL response, professional APCs have to present antigenic peptides to T cells in the secondary lymphoid organs in a process called cross-priming For this, professional (mobile) APCs have to acquire antigenic peptides from tissue cells, possibly by gap-junction-mediated peptide transfer Gap junctions are assemblies of intercellular channels that form an integral part of multicellular organisms Gap junctions are thought to be non-specific channels that allow passive diffusion of molecules with a relative molecular mass of up to 1,000 ( M r  1K) and intracellular signalling controls the gating  Gap-junction-mediated immunological coupling can result in innocent bystander recognition controlled by cytosolic amino peptidase activity Gap-junctional contact with HUVEC does not affect antigen presentation by monocytes HLA-A2-negative HUVEC were transfected with the GFP-Ub-FluM 57–65 construct and co-cultured with HLA-A2-negative or HLA-A2-positive HUVEC cells HLA-A2-restricted presentation of FluM 57–65 peptide generated by the neighbouring cells still strongly stimulated specific T cells when compared with direct presentation However, only a few peptides will successfully enter neighbouring cells and peptidase activity will destroy the ‘visiting’ peptides, restricting further diffusion into another cell layer However, this will efficiently prevent spread of infection whereby neighbouring cells form a ‘ cordon sanitaire ’ surrounding the infected cell Immunological coupling allows a very quick CTL response against cells at high risk of infection Immunologically relevant peptides, normally between eight to ten amino acids in length, can be transferred through Cx43 gap junctions from the cytosol of one cell into its neighbour Importantly, many tumour cells are uncoupled from their environment, for example after inactivation of their gap junctions by ras, src and neu oncogenes or by APC deficiency  In addition, gap junction intercellular communication seems to be important for the bystander effect in cancer gene therapy  In line with previous results , a 10- or 12-mer peptide had a longer half-life in the cytoplasm than a 9-mer peptide but no significant differences were observed between the cell lines ( Fig. 2e ) In neighbouring cells most of the transferred peptides will also be degraded by cytosolic amino peptidases, allowing transfer of only few peptides into the next cell layer In principle, tissue interconnected by gap junctions may be eliminated after antigenic peptide transfer In this study, we investigated the possibility of direct gap-junction-mediated transfer of antigens between the cytoplasm of two adjacent cells Internally quenched peptides of various lengths were micro-injected in A431 cells, a melanoma cell line (MelJuSo) or primary human umbilical cord endothelial cells (HUVEC) and the half-life was determined It can be envisaged that longer peptides inherently contain more secondary structure, hampering gap-junctional transfer Less than 2% of intracellular peptides are handled by the peptide transporter TAP and gap-junction-mediated intercellular peptide transfer is about equally inefficient because most peptides are destroyed by amino peptidases MHC class I molecules present peptides to the immune system for surveillance by CD8 + cytotoxic T cells (CTL) Monocytes making gap-junctional contact with the dye-loaded cell population acquired the calcein dye and were separated from the dye-negative monocytes from the same culture by fluorescence-activated cell sorting (FACS) ( Fig. 4b , c ) Monocytes upregulate Cx43 after receiving ‘danger signals’ in the form of IFN-γ and TNF-α or lipopolysaccharide  Only the ‘linear’ peptide was efficiently transferred between cells, indicating that its three-dimensional structure is an important factor for gap-junction-mediated peptide transfer Our data reveal a previously unknown mechanism of antigenic peptide transfer, in which the peptide diffuses, via gap junctions, from the cytoplasm of one cell directly into the cytoplasm of another and thus to the MHC class I antigen presentation pathway of its neighbour, resulting in CTL recognition of these innocent bystanders Peptides can probably be transferred through many different gap junctions but haematopoietic cells only express Cx43 Peptides of various lengths were micro-injected along with dextran-TxR and the rate of transfer was determined using fluorescence recovery after photobleaching (FRAP) techniques Peptides were permitted to migrate to neighbouring cells before the start of a FRAP experiment Presentation of the FluM 57–65 peptide in the context of HLA-A2 was subsequently assayed for both monocyte populations by CTL ( Fig. 4d ) Probably gap-junctional transfer is restricted to peptides that are able to adopt an extended conformation Reappearance of FL-peptides was readily observed with this protocol as illustrated in Fig. 2b , due to peptide exchange between the bleached and surrounding cells So far only a few mechanisms explaining cross-presentation have been described  Staining of sections from human appendix (intestine) also revealed Cx43 gap junctions between MHC class II-positive (probably dendritic) cells and the surrounding tissue ( Fig. 4a ) Subsequently, peptide fluorescence was ablated by photobleaching one neighbouring cell and the fluorescence recovery measured ( Fig. 2a ) Subsequently, the activated monocytes were co-cultured with the influenza-infected cells for 18 h The activated monocytes then sample a blueprint of peptides generated in the infected cells for presentation and cross-priming at other sites The APCs subsequently present these antigenic peptides on their own MHC class I molecules, and migrate to draining lymph nodes where activation and expansion of the specific CD8 + T-cell population occurs The FluM 9-mer peptide is released from GFP-Ub by ubiquitin hydrolase activity in the cytosol and can be recognized by a specific T-cell clone only when presented by HLA-A2 molecules The half-time of maximal FL-peptide recovery ( t 1/2 ) was determined for FL-peptides varying from four up to ten amino acids ( M r 1,082–1,851) in length in A431/Cx43 cells ( Fig. 2c ) The monocytes apparently obtained these peptides after gap-junctional contact with the influenza-infected cells, whereas both peptides and dye from A431 cells were not transferred to monocytes because of the absence of gap-junctional contact The peptide-expressing wild-type A431 and A431/Cx43 cells were co-cultured overnight with HLA-A2 transfectants, and subsequently an HLA-A2-restricted FluM 57–65 -specific T-cell clone was added ( Fig. 3a , b ) The presence or absence of gap junctions in antigen-expressing cells may explain why some have reported that antigenic proteasomal degradation products can be transferred from antigen donor cells to acceptor cells , and others that such fragments are excluded from cross-presentation  The resulting gap junctions electrically couple cells by direct exchange of ions and allow exchange of nutrients and second messengers The same experimental conditions were used to test whether primary HUVEC endothelial cells could cross-present peptides The size of a peptide seems to determine the rate of transfer between cells, because this rate decreases for longer peptides ( Fig. 2c ) These data suggest that monocytes are able to form gap junctions with other tissues after receiving a ‘danger signal’ in the form of IFN-γ and TNF-α These experiments indicate that antigenic epitopes can be cross-presented after transfer through gap junctions to neighbouring cells, resulting in innocent bystander recognition These gap junctions facilitate the transfer of many small molecules, but they might also enable the APCs to sample a fraction of the peptide content of surrounding cells These peptides are not degraded in cells because they are composed of d -amino acids with a protective group at the amino terminus  These peptides become fluorescent upon degradation, due to spatial separation of quencher and fluorophore  This concept has been challenged by a process called cross-presentation  This human squamous carcinoma cell line does not express gap junctions, as shown by biochemical and biophysical techniques  This implies that intercellular peptide spreading can occur, possibly resulting in the elimination of innocent bystander cells when connected by gap junctions to the infected cell This may be a crucial method of ensuring proper T-cell responses against viruses hiding in cells and cells protected from undergoing apoptosis through anti-apoptotic viral proteins This mechanism is fundamentally different from those proposed until now and allows direct antigenic fragment transfer between the cytoplasm of cells This protocol also showed calcein transfer from HUVEC into monocyte-derived dendritic cells but not between dye-loaded apoptotic bodies from A431/Cx43 and intact A431/Cx43 cells (not shown) Tissue-specific APCs also seem to form Cx43 gap junctions with surrounding cells To control for any effect of gap-junctional communication on antigen presentation by monocytes, the experiment was repeated without prior influenza infection To determine the relative efficiency of direct presentation, HLA-A2-positive HUVEC cells were transfected with the same construct followed by identical co-culture ( Fig. 3d ) To investigate whether immunologically relevant peptides can be cross-presented, we expressed a green fluorescent protein (GFP)-tagged-ubiquitin (Ub)-influenza matrix peptide (GFP-Ub-influenza matrix(57–65), or FluM 57–65 ) chimaera in A431/Cx43 cells To study peptide transfer between cells, stable fluorescently labelled (FL-) peptides were synthesized To test the efficiency of gap-junction-mediated peptide transfer, small groups of A431/Cx43 cells were grown on coverslips To test this hypothesis we stained human epidermis with antibodies against MHC class II to detect professional APCs (Langerhans cells) and antibodies against Cx43 To test whether professional APCs are able to contact infected cells and acquire peptides by gap-junctional contact, HLA-A2-positive human primary monocytes were activated by IFN-γ and TNF-α to induce Cx43 expression  To test whether structure or molecular mass are determining factors, an 8-mer peptide was synthesized in two conformational states—linear (probably flexible) and circular—and the efficiency of Cx43-mediated peptide transfer was determined in A431/Cx43 cells ( Fig. 2d ) To visualize peptide transfer between cells, we used A431 cells Transfer of antigenic proteins from a cell into an APC may occur following protein secretion and uptake by dendritic cells Viral proteins of the herpesvirus HSV-2 (ref. 11 ) and the human papilloma virus HPV-16 (ref. 12 ) are able to close gap junctions of infected cells We present here an alternative mechanism for cross-presentation: gap-junction-mediated immunological coupling (GMIC) We previously determined the intracellular half-life of peptides by micro-injecting internally quenched fluorescent peptides Whereas dextran-TxR is maintained in the micro-injected cell, the 9-mer peptide diffused into surrounding cells only when the cells expressed Cx43
 A wind of fresh foreign air blew through the drawing rooms of the French savanterie with the pioneering work of Smith, the so-called father of English geology All ten chapters are beautifully illustrated, with 179 contemporary black-and-white prints interwoven with the text As promised by its title, Rudwicks book deals expertly with the topic of geological time, which developed when no absolute measure of time was available Bursting the Limits of Time is a massive work and is quite simply a masterpiece of science history But a much shorter text could have covered the same subject matter, even over a broader time range, and thus reached a wider audience But most of the intense geotheoretical arguments of those days have long since been lost or won But right from the start, people realized that geology, like any other science, could advance only through informed and rational disagreement Cuvier ultimately emerges as the pivotal figure in the history traced in this book, but numerous others of scarcely less importance produced the foundations of the new geology For some today, science and religion continue to coexist peacefully, but in the early days one can see little precedent for the hardline, anti-scientific attitudes practised today by fundamental biblical creationists From studies of rocks and fossils, most scientists felt that at least the pre-human timescale was vastly longer than the 6,000 years prescribed by the Bible He correlated sedimentary rocks by means of their characteristic fossil assemblages, recognized the relative time sequence of sedimentary strata, made the first meaningful geological maps of parts of England and Wales, and created the important subject of stratigraphical geology, also known as stratigraphical palaeontology In the late eighteenth century, geology — a term that had been creeping in since the 1770s — was a complex mixture of geotheory, geohistory and geognosy (an early version of structural geology) in which much of the reasoning seems remote to modern eyes In those days, theology was still regarded as related to science and was thus subject to corroboration or conflict Indeed, thanks to Rudwick and his kind, we may rest assured that the future of the history of science is in safe hands. It charts in the most scholarly detail the beginnings of modern geology from the mid-1780s to the mid-1820s It was Cuvier, with his knowledge of comparative anatomy, who recognized that most fossil bones were different from modern ones and postulated that, in the absence of fossil human bones, a long pre-human history was followed by large-scale extinction Many of the scientists discussed their geological ideas in terms of past catastrophes and extinctions, whereas others preferred to think of vast, uneventful stretches of time, as expressed in the implicitly eternalistic words of Hutton:“The result of our present enquiry is that we find no vestige of a beginning, no prospect of an end.” In 1809, Lamarck published his gradualist ‘transformation’ version of evolution, quite different from that proposed by Darwin 40 years later Much of the activity during the earlier years took place in France and adjacent countries, and the book abounds in descriptions of the ideas and interpretations of savants, including Georges Cuvier, Jean-André de Luc, Horace-Bénédict de Saussure and Abraham Werner Nonetheless, it tends to be rather repetitive, because the author describes every nuance of each idea, however implausible, as well as the personal and scientific relationships between the protagonists Now we have our own divergent geotheories, which werent on the horizon 200 years ago One could even say that the sheer scale of all this theorizing was inversely proportional to the amount of data available Rudwick gives Smith his full credit but points out that Alexandre Brongniart and Cuvier were doing almost identical mapping in the Paris basin at the same time and, moreover, treated fossils not only as means to a stratigraphical end, but as palaeobiological ends in themselves Rudwick has amply fulfilled his stated aim of describing the injection of history into a science that had been primarily descriptive or causal Rudwicks text is beautifully written and grips the attention throughout Scientists and theologists were in close debate over these issues, without major argument Some 200 years from now, our own scientific findings may well take just as much explaining The book doesnt go as far as Charles Lyell, Adam Sedgwick or Charles Darwin (who was a highly productive geologist before being side-tracked by evolutionary biology), but Martin Rudwick promises to deal with the next stage of geology in a follow-up volume The book should be obligatory for every geology and history-of-science library, and is a highly recommended companion for every civilized geologist who can carry an extra 2.4 kg in his rucksack There are copious footnotes on every second page, as well as complete sources and references There were occasional flashes of insight, such as Georges Buffons view of Earth as a cooling globe with a hot centre, or Huttons interpretation of granite as once-molten fluid These scientists were beginning to show how describing and classifying geological phenomena could lead to detailed geohistorical reconstruction Things were slower to get going in Britain, where the most familiar names are James Hutton, William Smith and William Buckland This had been hinted at previously, and the ensuing debate centred around whether or not the supposed catastrophic event could be correlated with the biblical flood This was a particularly important point for Buckland, who was keen to combine the broadening geological horizon with his religious perspectives
 A third caveat is that mice on resveratrol didnt exactly mimic people on calorie-restriction diets After six months, all the mice fed high-calorie diets had grown fat Another ate high-calorie food But after a year the mice in the resveratrol group seemed a lot healthier than their high-calorie-fed counterparts But although there are data to prove this in yeast, worms and fruitflies, no analogous data have proved it for humans or mice — despite tantalizing hints But for those desperate to undo the effects of years of overeating, it is a far cry from a human cure But how solid is that foundation? The research is certainly striking But it means that, for now, experts are cautioning against the idea of rushing to an Internet pharmacy to buy resveratrol  But this week, Sinclair comes a step closer to proving that hes on to something David Sinclair believes resveratrol is a miracle drug Even so, Sinclair is forging ahead to answer some of these questions First, the study doesnt attempt to show whether resveratrol reverses the damage caused by the toxic diet, as the mice were on the drug when they started the diet Further studies by the same group will look at whether resveratrol extends lifespan in the healthy mice, too He and his colleagues report in a paper published online in Nature that this compound counteracts the ill effects of a high-fat, high-calorie diet — at least in mice He hypothesizes that resveratrol works through proteins called sirtuins He is a co-founder of Cambridge-based Sirtris Pharmaceuticals, which aims to develop drugs that act on sirtuins Hes been taking it for three years because he hopes it will help him live a healthier life, despite a lack of evidence that it works in humans — or any data on the safety of long-term exposure It is a dicey idea to take lifelong doses of a drug without having a clue about its mechanism of action or its long-term effects on the body. newsad; Finally, although the study itself is robust as published, the analysis involves only 121 mice, many of which are still alive — the experiment isnt truly over until all the mice have died Of course, the mechanism isnt so important if the drug works One group ate regular food Second, there is a dearth of data on how resveratrol works in mice — and no evidence that it works at all in humans Sinclair believes that it triggers the same pathways as those activated by calorie-restriction diets, which have been shown to increase lifespan in some animals (but not in humans, yet) So it is hard to know how well resveratrols benefits will apply in people Thats a potentially revolutionary finding The company said on 4 October that it saw no ill effects of the drug in these volunteers, so it has now begun a clinical trial in 90 patients with diabetes. The drug seemed to prevent these mice from developing a diabetes-like illness and liver damage, and reduced their risk of death by 30%, compared with the mice on high-calorie diets that did not get the drug The equivalent experiment would be to feed a human a relatively healthy diet until middle age, and then force him or her to binge on Big Macs and resveratrol simultaneously The mice stayed fat, for instance, and their cholesterol levels were far higher than those of mice on the standard diet The study was led by Sinclair, of Harvard Medical School in Cambridge, Massachusetts, and Rafael de Cabo of the National Institute on Aging in Baltimore, Maryland The third group ate the high-calorie diet along with a daily dose of resveratrol, a chemical found in many plant species, including red grapes — and thus also red wine Their team divided one-year-old mice into three groups This means either that Sinclair and de Cabo decoupled obesity from its downstream ill-health effects or that resveratrol doesnt really mimic calorie restriction in mammals This summer, Sirtris tested a modified version of resveratrol in 85 healthy men To some scientists, the finding has the whiff of a landmark discovery: it could lay the foundations for a future drug that blocks the toxic effects of obesity in humans Until all these results are in, we dont really have a complete picture of the drugs effects in obese and normal mice
 And although stem cells and RNA interference show long-term promise, their commercial application remains some way over the horizon. And on 28 February, Massachusetts-based Biogen IDEC had to withdraw Tysabri, a treatment for multiple sclerosis, halving the value of the companys own stock and dragging down confidence in the sector as a whole But its the state of the science that dictates market sentiment, Huggett says But there had been high hopes for a more modest revival. “Overall, 2004 was a very good year” for the sector, says Brady Huggett, managing editor of BioWorld. “But things started to taper off as the year came to a close, and thats continued.”  So biotechnology firms are finding it tough to raise money on the stock market right now During 2003 and 2004, global investment in biotechnology — including money raised in public share offerings, as tracked by publisher BioWorld, based in Atlanta, Georgia — was picking up again after a slump in the previous couple of years Huggett says average initial public offerings in the sector have been bringing in about $50 million apiece — not enough to sustain a typical research-based company for long No one expected a repeat of the money rush that anticipated the human genome sequence The first few months of 2005 have deflated investors hopes for a biotech boom, industry analysts say The generally lacklustre performance of stocks so far this year has made many companies shy of making an initial public offering
 All this should be done with an eye to keeping an open dialogue between scientists and the federal officials overseeing immigration As reported on page 6 of this issue, things have improved, although perhaps not as much as many researchers would have liked Before the attack, the United States was a focal point for scientists from around the world who went there to study, conduct research and teach But in its aftermath, a series of restrictive new immigration measures led to lengthy delays for foreign researchers, and many were turned away But more should be done to ensure free scientific exchange between the United States and other countries Finally, scientific organizations should support immigration legislation that would make it easier for foreign scientists trained in US universities to remain after finishing their work In 2004, we warned that these policies were strangling scientific exchange and could have dire consequences for the nations scientific leadership (see Nature 427 , 181 ; 2004 10.1038/427181a ) In the event of another attack on the United States, such lines of communication could help to ameliorate the immigration restrictions that would almost certainly follow It is unlikely that the security checks at the heart of many researchers delays will become more open, but more could be done to communicate with those entering the United States about the status of their applications New statistics are showing a resurgence of foreign students, and researchers are probably following, although numbers reflecting their movement are more difficult to obtain Researchers entering the United States today still find it a hassle, but most feel that it is worth the trouble to come to US laboratories Scientific groups in America should continue to press for better training of embassy staff, and for the hiring of more scientifically aware case-workers The attack of 11 September 2001 changed many things, including the way science is done in America The Department of State has boosted staffing levels at its embassies and consulates, and new computer systems are helping to prevent applications from becoming lost during interagency security reviews in Washington The government has taken other positive steps, abandoning a plan to force foreign scientists to obtain licences to operate lab equipment (see Nature 441 , 679 ; 2006 ), and revising a rule that would have required foreign-born researchers on defence-funded projects to work in segregated areas The United States is a linchpin of the global scientific enterprise, and it is in everybodys interest that it remain open for business. These moves were in response to a vocal and concerted campaign by a coalition of scientific, university and industry organizations that warned policy-makers that such restrictions would not be in the nations best interest They should work with the State Department and the Department of Homeland Security to try to bring some much-needed transparency to the visa process This could lead some to believe that the problem is largely solved Waiting times for those reviews are down from months to weeks: in Beijing, a student visa that might have taken six months can now be granted in just ten days
 After calibrating it against a series of more complex global models, they plugged in a range of values for aerosol cooling, and ran the model to simulate future temperatures as the skies clear (see Strong present-day aerosol cooling implies a hot future ) Andreae acknowledges that there are many uncertainties about his study Andreae, along with German and British colleagues, used a climate model specifically designed to simulate aerosol effects As cars, industries and power plants worldwide become cleaner, atmospheric concentrations of emitted aerosols are expected to drop substantially But as the skies are already starting to brighten (see Nature 435 , 135 ; 2005 10.1038/435135a ), the question has become critical But he points out that it is the best estimate we have so far. “This forces us to accept that pessimistic climate scenarios are much more plausible than had been thought,” he says But how global temperatures will respond depends on how big the masking effect was in the first place — and that is the wild card in the climate game But I object to conclusions based on the assumption that our knowledge is better than it actually is.”  Anderson points out that, for high values of aerosol cooling, Andreaes model breaks down, predicting unrealistically high or infinite temperature rises Calypso, a satellite funded by the United States and France, will provide such data after its launch in August, although scientists warn that it could take 20 years to get a clear picture Even under relatively cautious assumptions about past and present aerosol cooling, the study suggests that global warming could easily exceed the upper extreme predicted by the Intergovernmental Panel on Climate Change (IPCC), as clean-air measures take effect. “Things could get really uncomfortable,” says lead author Meinrat Andreae, an atmospheric researcher at the Max Planck Institute of Chemistry in Mainz, Germany. “The climate system is much more sensitive to human perturbations than has been thought For a present-day cooling of 1.5 watts per square metre, which most climatologists agree is a relatively conservative value, the model implies that temperatures could rise between 6 and 10 °C by 2100 He says this could mean that our understanding of what is driving the climate system is wrong If our model is right, things could become totally uncontrollable in the second half of the century.”  That is quite a big ‘if’, however In the meantime, Andreae says he hopes his results will rouse political debate, especially as the G8 summit looms. “Mankind must fight CO 2 emissions more aggressively,” he says Munich For more than a century, dust and aerosols in the atmosphere have been blocking some of the Suns radiation, shielding us from the worst effects of global warming Or, he suggests, natural climate variability might be much larger than most scientists assume. “The predictions may look more dramatic than what we actually expect,” agrees Olivier Boucher, head of climate chemistry and ecosystems at the Hadley Centre for Climate Prediction and Research in Exeter, UK. “But this is still an alarming hint at the upper bound of what can happen.”  All agree that precise observations about the vertical distribution of aerosols are required Other experts are more cautious. “Climate modellers like playing around with values,” says Theodore Anderson, an atmospheric scientist and aerosol researcher at the University of Washington in Seattle. “It is legitimate to engage in speculative reasoning Such uncertainty has deterred researchers from estimating the effect of losing our aerosol shield That is well in excess of the current IPCC predictions, which suggest a temperature rise of between 1.4 and 5.8 °C over the same time period The problem is that different methods of estimating the cooling effect arrive at vastly different values The question has always been: how much? Now, as cuts in pollution allow the skies to clear, an attempt to quantify the effect on future temperatures has produced an alarming conclusion The uncertainty surrounding the effects of global warming has been widely used to imply that things might not be as bad as projected, says Michael Grubb, an expert on policy responses to climate change at Imperial College, London. “This study is a timely reminder that uncertainty also means things could be a lot worse,” he points out. “Politically, this is a hugely important message.” Trying to work it out from our understanding of how aerosol particles behave in the atmosphere suggests that the amount of solar energy reaching the ground will be reduced by anything from 0 to 4.5 watts per square metre Working it out from a best guess of how sensitive the atmosphere is to greenhouse gases and how much warming we have seen so far gives 2 watts per square metre
 Chronic i.c.v. injection of nesfatin-1 reduces body weight, whereas rats gain body weight after chronic i.c.v. injection of antisense morpholino oligonucleotide against the gene encoding NUCB2 Here we show that nesfatin, corresponding to NEFA/nucleobindin2 (NUCB2), a secreted protein of unknown function, is expressed in the appetite-control hypothalamic nuclei in rats I.c.v. injection of nesfatin-1 decreases food intake in a dose-dependent manner, whereas injection of an antibody neutralizing nesfatin-1 stimulates appetite In contrast, central injection of α-melanocyte-stimulating hormone elevates NUCB2 gene expression in the paraventricular nucleus, and satiety by nesfatin-1 is abolished by an antagonist of the melanocortin-3/4 receptor In contrast, i.c.v. injection of other possible fragments processed from NUCB2 does not promote satiety, and conversion of NUCB2 to nesfatin-1 is necessary to induce feeding suppression Intracerebroventricular (i.c.v.) injection of NUCB2 reduces feeding Nesfatin-1-induced anorexia occurs in Zucker rats with a leptin receptor mutation, and an anti-nesfatin-1 antibody does not block leptin-induced anorexia Rat cerebrospinal fluid contains nesfatin-1, an amino-terminal fragment derived from NUCB2, and its expression is decreased in the hypothalamic paraventricular nucleus under starved conditions The brain hypothalamus contains certain secreted molecules that are important in regulating feeding behaviour  We identify nesfatin-1 as a satiety molecule that is associated with melanocortin signalling in the hypothalamus. A Cys residue was added to the C terminus of each peptide Animal experiments Without anaesthesia, the test substance (5 µl) was injected into the third ventricle of the brain in adult male Wistar rats weighing 200–250 g, as described previously  Antibodies Antibodies were generated in rabbits against amino-acid sequences of rat NUCB2: Ab-L against residues 117–128, Ab24 against residues 24–38, and Ab301 against residues 301–314 Methods Further details are provided in Supplementary Information  Peptides for rat nesfatin-1 and nesfatin-2 were synthesized by Yanaihara Institute, Inc Proteins and substances A cDNA encoding full-length mouse NUCB2 was subcloned into pMAL-c2x to yield a fusion protein with maltose binding protein in Escherichia coli  Statistical analysis was performed by analysis of variance, unless otherwise mentioned. Subtraction-cloning assay With the use of a polymerase chain reaction (PCR)-based subtraction cloning kit , the troglitazone (100 µM)-stimulated genes of SQ-5 cells derived from lung carcinomas, which express leptin and its receptor , were identified The experiments involving i.c.v. bolus injection were started 30 min before the beginning of the dark cycle (lighting from 6:00 to 18:00), and the experiments for IgG injection were started at 10:00 unless otherwise specified The intermediate forms of nesfatin retaining the wild-type motif Lys 83-Arg 84 or the mutant Lys 83-Arg 84 → Ala 83-Ala 84 (mutations generated by the PCR method) were constructed as glutathione S -transferase fusion proteins with a histidine tag in E. coli transfected with the pET41a(+ ) vector Zucker obese rats were purchased from Charles River Laboratory Analysis of in situ hybridization demonstrated that the gene encoding NUCB2 is expressed in the same hypothalamic nuclei as those shown by the immunohistochemistory ( Fig. 1e ) As a prohormone can be processed to generate bioactive fragments , we next estimated the food intake of rats after i.c.v. injection of each of the possible fragments derived from NUCB2 As most hypothalamic secreted molecules also exist in peripheral adipose tissue , we examined whether the genes cloned were expressed in both brain medulloblastoma (HTB185) and 3T3-L1 adipocyte cells As the melanocortin-4 receptor is distributed widely in several brain regions that are plausibly involved in the coordinated control of feeding and energy expenditure , these findings imply the possible involvement of unknown neuronal substances, which are regulated by melanocortin-4 receptor signalling, in mediating nesfatin-1-induced anorexia At the carboxy terminus matching the nesfatin-2/3 fragment, NUCB2 possesses archetypal motifs, namely possible calcium-binding and DNA-binding sites  Because NUCB2 belongs to a homologous gene family with nucleobindin1 (NUCB1) , these two genes might have arisen from a single EF-hand ancestor  Conversely, continuous i.c.v. injection of NUCB2 antisense morpholino oligonucleotide diminished the hypothalamic NUCB2 contents ( Supplementary Fig. 10 ) and resulted in a consistent increase in appetite Conversely, i.c.v. injection of IgG from NUCB2 Ab-L stimulated feeding, compared with that induced by control IgG ( Supplementary Fig. 4 ) Finally, we found that although i.c.v. injection of the intermediate form (residues 1–223) of nesfatin retaining wild-type Lys 83-Arg 84 significantly reduced feeding, injection of the mutant form of nesfatin (Ala 83-Ala 84) did not induce anorexia ( Fig. 2f–h ), indicating that appetite suppression by NUCB2 requires conversion to nesfatin-1 First, we used a computer-based program (Signal Peptide Prediction, http://bioinformatics.leeds.ac.uk/prot_analysis/Signal.html ) to search for a signal peptide in the coding region of each of the 596 genes cloned in this assay However, injection of nesfatin-1 did not affect the expression of the genes encoding POMC, agouti-related peptide, neuropeptide Y or corticotropin-releasing hormone in the arcuate nucleus and PVN ( Supplementary Fig. 12 ), and nesfatin-1 stimulated neither cAMP formation nor calcium influx in cells expressing the melanocortin-3 or -4 receptor ( Supplementary Fig. 13 ) However, the present findings indicate that this C terminus is not involved in feeding regulation Immunohistochemical analysis with nesfatin Ab24 showed that nesfatin-1 was distributed in the hypothalamic nuclei in a similar manner to that observed for NUCB2 Ab-L ( Supplementary Fig. 8 ) and was present in the cytoplasm, but not the nucleus, of the hypothalamic neurons, where it was co-localized with PC-3/1 and PC-2 ( Fig. 1h ) In comparison with rats receiving vehicle injection ( Fig. 3a , b ), rats receiving a continuous i.c.v. injection of nesfatin-1 unfailingly showed decreased food intake and suppressed body weight gain (at day 10, 30.4 ± 0.3 g versus 12.6 ± 0.7 g (± s.e.m.), respectively) In contrast, central injection of α-melanocyte-stimulating hormone stimulated the expression of the PVN gene encoding NUCB2 ( Supplementary Fig. 11 ), and previous injection of SHU9119, an antagonist specific for the melanocortin 3/4 receptor , abolished nesfatin-1-induced satiety ( Fig. 4d , e ) In contrast, neither a synthetic peptide corresponding to nesfatin-2, a fragment corresponding to nesfatin-3 nor a fragment corresponding to nesfatin-2/3 affected appetite ( Fig. 2c , d ) In contrast, nesfatin-1 located in the N terminus of NUCB2 was indispensable to the induction of satiety, and conversion of NUCB2 to nesfatin-1 was essential to induce its activity in vivo  In the next experiments we estimated chronological changes in rat body weight In Zucker rats possessing a leptin receptor mutation , significant nesfatin-1-induced satiety occurred ( Fig. 4a , b ) Initially, body weight gains remained unchanged until 5 days after injection, but significant increases occurred after 6 days ( Fig. 3c , d ) Injection of a synthetic peptide identical to nesfatin-1 decreased food intake in a dose-dependent manner, and the effects continued for 6 h after injection ( Fig. 2a , b ) Leptin and pro-opiomelanocortin (POMC)-derived α-melanocyte-stimulating hormone are key anorectic molecules in the hypothalamus  Nesfatin-1 injection also significantly decreased the weights of subcutaneous, epididymal and mesenteric fats, but not that of the gastrocnemius ( Supplementary Fig. 9 ) Nine genes meeting these criteria were identified, and the expression of one gene among those identified was profoundly stimulated by troglitazone in SQ-5 cells ( Supplementary Fig. 1 ) No significant changes were observed in other hypothalamic nuclei NUCB2 and NUCB1 are secreted proteins but their function remains unknown, although these proteins have been suggested to contribute to bone mineralization and antibody production  NUCB2 is composed of a signal peptide of 24 amino acids and a protein structure containing 396 amino acids  NUCB2 was expressed in the hypothalamic areas ( Fig. 1a–d ), namely the arcuate nucleus, paraventricular nucleus (PVN) and supraoptic nucleus, the lateral hypothalamic area and the zona incerta, which regulate feeding, and also in the nucleus tract solitarius (data not shown) Post-translational processing of a prohormone produces several fragments or peptides through cleavage at specific sites by prohormone convertases (PCs) , and rat NUCB2/nesfatin possesses potential cleavage sites that are flanked by a pair of basic amino acids, Lys-Arg or Arg-Arg ( Supplementary Fig. 5 ) Preincubation of the cognate peptide with NUCB2 Ab-L abolished staining (data not shown) Previous injection of nesfatin Ab24 eliminated anorexia induced by nesfatin-1, but did not block leptin-induced anorexia ( Fig. 4c ), indicating a possible lack of involvement of hypothalamic leptin signalling in the induction of anorexia by nesfatin-1 Sequencing demonstrated that this complementary DNA fragment corresponds to the 5′-untranslated region of the gene encoding DNA binding/EF-hand/acidic protein (NEFA) or NUCB2 Subsequently, we found that food intake was significantly stimulated after injection of nesfatin Ab24-derived IgG, but not after injection of nesfatin Ab301-derived IgG ( Fig. 2e ) Taken together, the present studies indicate that hypothalamic nesfatin-1 signalling might involve the leptin-independent melanocortin signalling system  The C-terminal region also binds other molecules  The homology of the amino-acid sequence of NUCB2 is highly conserved in humans, mice and rats (87.4% homology to humans and 95.7% to mice) The possible processed fragments were designated as follows; nesfatin-1, residues 1–82; nesfatin-2, residues 85–163; and nesfatin-3, residues 166–396 The present findings indicate that nesfatin-1 might be a useful target for the development of drug therapies to treat obese persons. The ProP 1.0 prediction server predicted these sites and showed the highest score for cleavage at the Lys 83-Arg 84 site, which is conserved among different species  The structures of nesfatin-2 and nesfatin-3 are characterized by their possessing putative DNA-binding and leucine-zipper sites that bind nucleosomal DNA , but nesfatin-1 does not preserve these sites There are complex but integrated interconnections among the hypothalamic nuclei in regulating feeding  These results indicate that this protein is a hypothalamic endogenous molecule that induces anorexia This antibody recognizes the whole structure of NUCB2, and its detection was not absorbed by the addition of appetite-regulating peptides ( Supplementary Fig. 3 ) To address this issue, an anti-NUCB2 antibody (termed NUCB2 Ab-L) was used to perform immunohistochemical analyses in rats Troglitazone does not cross the blood–brain barrier to alter feeding behaviour and does not change body weights in rodents ( Supplementary Fig. 2 ), but the present findings encouraged further investigation into whether the protein deduced from this identified gene is present in the hypothalamus Under conditions of starvation for 24 h, NUCB2 gene expression was reduced in the PVN, in which nesfatin-1 concentration was also decreased ( Fig. 1i , j ) We attempted to identify any new appetite-regulating molecules by using a subtraction-cloning assay of peroxisome proliferator-activated receptor-γ activator (troglitazone)-stimulated genes in SQ-5 cells We have identified a novel anorexigenic nesfatin corresponding to NUCB2 in the hypothalamus that produces a secreted fragment, nesfatin-1 We next identified that i.c.v. injection of recombinant protein of NUCB2 decreased food intake ( Fig. 1f , g ), but no apparent behavioural changes including increased locomotion or narcolepsy were noted during the experiments We produced two different types of antibody, nesfatin Ab24 and Ab301, which recognized synthetic nesfatin-1 and nesfatin-3, respectively ( Supplementary Fig. 5 ) We therefore refer to this protein as nesfatin (for NEFA/nucleobindin2-encoded satiety- and fat-influencing protein) When monitored by nesfatin-1 ELISA, elution profiles of cerebrospinal fluid extracts on high-performance liquid chromatography showed an apparent peak corresponding to nesfatin-1 peptide ( Supplementary Figs 6 and 7 ), indicating that nesfatin-1 is a secreted fragment
 A comprehensive environmental analysis will also be conducted to determine the effects of recent studies on the mammals A National Weather Service spokesman, Jordan St A US federal judge ruled on 30 June that the National Weather Service cannot send its Gulfstream jets to take measurements in a densely clouded region above the inner core of tropical storms All Steller research was blocked in May after a 2005 Humane Society lawsuit alleged that the species could be harmed by the research procedures used by the US National Marine Fisheries Service (NMFS) (see Nature 441 , 677 ; 2006 ) An agreement between the Humane Society of the United States and the NMFS was approved in court on 30 June and allows for low-impact studies As part of the agreement, research methods such as hot branding, tooth extractions, and researchers entering rookeries will not be permitted But he adds that the agency still plans to equip the Gulfstream with an advanced Doppler radar system over the next few years, in the hope of flying it on the fringes of storms But it suggested delaying the Astrobiology Field Laboratory until 2018 to allow “an informed decision of its merits” as well as to consider how findings from the Mars Science Laboratory (pictured) might affect its mission Court settlement puts sea lions back under scrutiny US researchers headed into the Pacific Ocean last week to begin studies of threatened Steller sea lions — the first that have been permitted since a court shut down their projects During the next five to seven months, as well as helping to maintain the space station, Reiter will participate in about 20 experiments for ESAs Astrolab mission, ranging from plasma physics to investigating the effects of weightlessness on human physiology ESA astronaut set to boost science on space station European Space Agency (ESA) astronaut Thomas Reiter arrived last week on the International Space Station Flights may resume if the agency negotiates safe flying conditions with the labour union representing civilian members of the flight crews based in Tampa, Florida For now, air surveys and observational studies will be allowed He also claims that the cell line presented in 2004 was a clone, despite a Seoul National University investigation that determined it was not He is pleading innocent on all counts His lawyer, Geon Haeng Lee, explained Hwangs expenditures by saying that confusion arose after Hwang pooled his own personal money with research funds Hurricane jet grounded over tussle with union Some hurricane hunter research flights have been grounded for being too dangerous Hwang admits being responsible for faked data In a court in South Korea last week, Woo Suk Hwang admitted to having overall responsibility for two fraudulent papers on human therapeutic cloning published in 2004 and 2005 in Science  Hwang admits to ordering the fabrication of some data, but he says he believed that the stem cells were real and that he was merely deceived by a junior researcher Hwang was indicted in May on three charges: embezzlement, for misusing government funds given for research; fraud, for using knowingly falsified data to secure funding from private companies; and breaking a bioethics law by paying for human eggs Hwang would work with animal cells, having lost his licence to work with human subjects It has instead requested that they submit more detailed breakdowns on how they plan to use the money It recommended bringing forward the launch date of a long-term sensor network to monitor the martian structure and weather John, says that no plans have yet been made to negotiate with the union Late last month she offered to resign her university post, and has stepped down from her vice-presidency of the International Union of Pure and Applied Chemistry Lee announced two weeks ago that Hwang will begin research again this month with a group of about 30 researchers and private funding Misconduct scandal delays Japans research funding Japanese research funding has been put on hold following a misconduct case involving Kazuko Matsumoto, a chemist at Waseda University in Tokyo National Academy sees red over Mars missions NASA should change its plans for exploring Mars in the coming decade, says a panel convened by the US National Academy of Sciences Partly in response to the scandal, Japans finance ministry has delayed distributing ¥10.6 billion (US$90 million) in grants to about 50 universities and research institutes The agencys current vision “is not optimized” for maximizing the scientific output of future missions, the panel concluded in a 6 July report The decision applies only to the Gulfstream-IV jet, a lightweight plane that can fly at high altitudes The decision comes after Matsumoto acknowledged misappropriating more than ¥14 million in research grants over the past few years The Germans arrival, on the space shuttle Discovery, should free up the crew to spend more time doing science The Gulfstream is more susceptible to turbulence than the heavier WP-3D Orion, which is also used for storm research The panel also called on NASA to step up technological development for future Mars missions, particularly one to bring back rocks from the red planet. This takes the station crew up to three permanent members for the first time since May 2003, after the space shuttle Columbia disaster Waseda University is investigating further allegations that Matsumoto misappropriated more than ¥20 million and fabricated data
 All of us are at fault to some degree And who can disagree that concerted and unified action is urgently needed? This clarion call, from one of the worlds leading naturalists who freely acknowledges his religious roots (even though they are now withered), must command respect As Anthony Burgess observed in his novel The End of the World News (Hutchinson, 1982), we always knew it was going to end badly As part of his programme for human development, Wilson blithely writes that one of the great goals is to “stimulate the mind with the combination of artificial intelligence and artificial emotion”, chosen of course by the wisest of our leaders But who is to say that the very thing he deplores is not itself an inevitable outcome of evolution? Is not the rise of our technological species the next step, with the conversion of the planet to one vast farm and theme park? It is a repellent view, but I am afraid the nebulous plan offered by Wilson will not save the day Certainly his hypothetical pastor is crippled with a fathomless biblical literalism Equally important, its scientistic agenda carries the real risk of imposing tyranny How can this vast inductive enterprise ever provide a coherent method of scientific conservation? More important, will it galvanize human society into collective action? The central problem with Wilsons emergency plan is that it is ultimately a thinly disguised programme to hijack religious energy and divert it into the secular arena How many books written by a scientist open with the phrase “Dear Pastor”? On the surface, this book is important because it is an open invitation to religious communities to bury their differences with the scientific establishment (some of whom expend considerable energy denigrating and insulting religion), join forces and so save the world from catastrophe I fear, however, that it wont, but not for reasons of apathy or ignorance In a striking parody of William Blakes famous lines, he fulminates against how future generations may have to repopulate a devastated world “with tigeroids ... burning artificial bright in forestoids amid insectoids that neither sting not bite” Ironically, Wilson urges us “to unglue city children from their television and computers” by reigniting their interest in the natural world It is a common jibe that the blame for environmental destruction should be laid at the door of reckless supernaturalists whose only concern is the next world It is a glimpse of hell, but then nobody really believes in hell, do they? Maybe Wilsons early mentors in the Southern Baptist Church were flat-Earthers O On cue and nicely resonating with our apocalyptic forebodings, we now seem to be well on course for the meltdown of civilization by environmental destruction Rather, The Creation fails in a much more interesting way Significantly, not once is the pastor invited to reply: he is muzzled, perhaps the inevitable fate of a straw man So other than finding common ground with religion, how is the world to be saved? Wilsons proposal is to embark on a massive, if not heroic, documentation of the biosphere Such people do exist, but so too do those who grapple with the ideas of Thomas Aquinas The failure of his pantheistic agenda lies in the recurrent inability of materialists to understand that the decision to protect the biosphere can only derive from an ethical imperative that is itself independent of the natural world The threat is real, but will one more book make a scrap of difference? If it comes from E There is to be found a new theatre of spiritual energy.” Such a pantheistic agenda has not the remotest chance of working, but it also reveals a monumental misapprehension of what religion is actually trying to do This aims to understand human nature in terms of entirely naturalistic processes underpinned by genetics This seems a noble quest, but even scientifically it is intensely problematic This thesis has long since been exploded, and in any event can be tested by exploring the spiritual foundations of the owners of factory fishing fleets, drivers of sports utility vehicles, agrochemical salesmen, property developers and those who profit from mass tourism This, he believes, will be the catalyst to slow and ultimately reverse the relentless impoverishment of biodiversity Wilson briefly exposes his hand by exclaiming how this vast enterprise to catalogue the worlds diversity will lead to a “transcendent and only dimly foreseeable complexity of future biology Wilson is famous for his holistic programme, loosely described as consilience Wilson is right to rage against the impoverishment of the worlds biodiversity Wilson, it certainly should Wilsons programme is put forward with the best of intentions, yet it is underpinned by an incoherent metaphysics Yet despite the proferred olive branch, Wilsons thesis of cure and reconciliation is deeply problematic
 An Inconvenient Truth was directed by Davis Guggenheim and produced by Participant Productions, a film company set up in 2004 with an explicitly activist agenda And one of the years most talked about films is Werner Herzogs Grizzly Man , a portrait of a man who lived among — and was eventually eaten by — Alaskas grizzly bears and claimed to be protecting them, although government experts say the population is doing well Bush in 2000, is starring in a new documentary that features his presentations on climate change Chivian says the same of the climate-change debate: “What really worries me is that scientists havent done a great job of communicating these issues Doron Weber, who runs the Public Understanding of Science and Technology programme at the Alfred P He says that boom times for documentaries are good for showing the subtleties of science. “A film like Grizzly Man presents a character in the round and presents conflicting ideas,” he says. “Film is such a good medium for this.”  newsad; Another director taking advantage of the medium is Randy Olson His film Flock of Dodos , about the clashes between evolutionary scientists and advocates of intelligent design, had its first screening in Kansas earlier this month Last week, Participant Productions secured a distribution deal with Paramount Pictures that should see An Inconvenient Truth get a US release in May Michael Oppenheimer, a geoscientist and environmental-policy expert at Princeton University, agrees. “I have talked to thousands of politicians and very few of them have been willing to do the homework and get down to the details,” he says. “When Al Gore gets revved up, he is very impressive.”  But it wasnt until Gores slide-show was made into a feature-length documentary, first screened at the Sundance film festival in Utah last month, that his efforts started making headlines around the world Moore, who helped get documentaries into movie theatres with his hit films Bowling for Columbine , about gun control in the United States, and Farenheit 9/11 , about the Bush administrations actions in the wake of the terrorist attacks of 11 September 2001, is now working on a film about the pharmaceutical industry, called Sicko  More recently he has been touring the United States with a slide-show presentation on the dangers that his scientist supporters say is scientifically accurate and compelling. “Hes very effective and right on target, and Ive never seen better visuals,” says Eric Chivian, director of the Center for Health and the Global Environment at Harvard Medical School in Boston, who helped Gore with sections on the effects of global warming on polar bears Olson comes down on the side of evolution, but sends a message that scientists have neglected the communication skills needed to engage with mass audiences, and failed to compete with the public-relations operations of advocates of intelligent design. “Science has backed into this lumbering, conservative corner, with no flexibility to deal with something like intelligent design when it comes up,” says Olson Sloan Foundation in New York, gave an award to Herzogs film Supporters hope that the film will not only revive Gores political career but will take his climate message to a wider audience than his original slide-show could ever have reached The companys other films include Syriana and Good Night and Good Luck , which deal with the global oil industry and the freedom of the press, respectively The environment has long interested Gore, who published a book on the threat of climate change, Earth in the Balance , in 1992 The film is just one of several science-related documentaries hitting the big screen this year Thom Powers, a documentary producer who heads the documentary film programme at the Toronto International Film Festival, says that both science and political documentaries are becoming much more popular. “ March of the Penguins was I think the second-highest grossing documentary of all time, second only to Michael Moores Farenheit 9/11 ,” he says. “Al Gores documentary has a nice confluence of a couple of different interest areas: growing viability of political documentaries, and interest in the environment.”  The trend is growing Washington DC Al Gore, the former US vice-president who lost his fight for the presidency to George W We are trained to talk in technical language to each other.” Many hope that the new wave of science documentaries will help to change that.
 Although Quaero has wisely ruled out trying to compete head-on with Google, focusing instead on research on next-generation web searching, a top-down approach is unlikely to match the flexibility and speed of bottom-up entrepreneurship But such strengths are less well suited to the dynamics of some of todays key industries — particularly information technology Chiracs initiative at least has the merit of acknowledging the fact that European governments need to address the thorny question of their role in tackling the continents industrial RD deficit. Even the United States has long nourished technology development through military contracts and national strategic programmes France would eventually increase this to more than €1 billion annually for dozens of similar projects, he said, in a bid to boost European innovation Frances industrial policies have a decent track record of picking winners: its state-sponsored ‘grandes programmes technologiques’ made the country a world pioneer in high-speed trains and nuclear reactors, and broke US domination of the civilian aerospace industry, creating Airbus and Ariane French domestic politics will also affect the outcome of the new scheme Governments can, and must, help create the conditions for innovation, from ensuring a skilled workforce and adequate research infrastructure, to tax breaks and other incentives He announced a €600-million (US$760-million) plan, to be funded roughly 50–50 by the French government and by European companies, to support six technology projects In contrast, the new scheme is very much a lapin pulled out of a hat by Chirac in the decrepit dusk of two terms as French president, where research and innovation have otherwise been largely neglected It is naive to suppose that whole new industries can arise from entrepreneurship alone Its research ministry, although unhappy at being sidestepped, nonetheless welcomes what it sees as a long-overdue decisive response by member states to the critical lack of private-sector funding of research Last week, French president Jacques Chirac took a step towards addressing that challenge Member states agreed at a 2000 summit in Lisbon to boost total RD spending to 3% of gross domestic product by 2010 — an unrealistic target that the continent will not even begin to move towards unless it sharply boosts private-sector investment Nevertheless, there are reasons to be cautious about this initiatives prospects for success The European Commissions competitiveness ministry will be watching to ensure that the projects do not flout rules on subsidies The European Union has identified targets for industrial research and development (RD) as critical to its future, but is manifestly failing to meet them The largest sum, €250 million, will fund a Franco-German programme called Quaero, led by Thomson, to develop multimedia search engines The other projects are smaller, each receiving less than €100 million The projects will draw together research programmes on various topics, each championed by a single company, but with the work shared out between a network of others, and also involving laboratories at public research agencies and universities The ‘grandes programmes technologiques’ enjoyed national support by successive administrations whatever their political bent These sectors also played to the strengths of Frances centralized technocracy in organizing large national and strategic sectors This logic is all the more compelling in Europe, where the reality is that students and scientists first thoughts before breakfast are not to go into a garage and launch a company on Nasdaq
 A bioethicist at the University of Pennsylvania, Wolpe found himself confronted by angry members of the public during the debate over the fate of brain-damaged patient Terri Schiavo earlier this year After all, she argues, with the public so eager for information about the brain, the least scientists can do is deliver the most accurate picture they can. At the workshop, organized by a consortium of groups including the Dana Foundation, which funds research in neuroscience, they warned that neuroscientists must learn to use such emotive images responsibly, and to be more honest about the limitations of their work But people with certain kinds of brain damage rely more exclusively on reason — and often make what most would see as disastrous errors of judgment But this could violate long-held societal standards, such as the ‘freedom of thought’ guaranteed in the First Amendment to the US Constitution, says Stacey Tovino, a lawyer at the University of Houston Law Center in Texas. “The privacy issues are very difficult,” she notes But this is causing concern about how the pictures might be used. “These images are quite seductive,” says Marcus Raichle, one of the pioneers of brain imaging at the Washington University School of Medicine in St Louis, Missouri. “Its intuitively easy to relate to a picture, and thats both good and bad.”  Because brain images seem to tell a cut-and-dried story, the public often accepts research findings long before the investigators themselves feel they really understand what the results mean But when he showed them computed tomography scans that compared Schiavos atrophied brain with a normal brain, they changed their minds. “People paused, and they said: ‘Maybe Terry isnt there’.” Wolpe explains D Daniel Schacter at Harvard University, for instance, has used functional magnetic resonance imaging (fMRI) to image the brain regions that are activated when we remember things Everyone at last weeks meeting seemed to agree that neuroscientists now have a responsibility to explain the limitations of brain-imaging studies to the public For example, most non-scientists dont understand that the images in research publications are generally composites of data from many individuals, not from a single person For instance, fMRI research supports the idea that we use emotions and reason when we make decisions He found that when we have ‘false memories’ — when we do our best to tell the truth but remember incorrectly — the images show different patterns of brain activation from those seen for true memories (S Illes et al  Imaging studies are almost ten times as popular now as they were a decade ago (J In 2002, the Dana Foundation sponsored a meeting that is widely regarded to have given birth to the field of neuroethics L Last week, scientists and ethicists met in Washington DC to discuss the growing power of brain images to sway public opinion in areas such as medicine, crime and human rights Many neuroimaging studies focus on a small group of people, and their findings arent confirmed by other investigators. “We need to have a new sense of accountability and reproducibility,” says Judy Illes, director of the neuroethics programme at Stanford University Nature Neurosci. 6, 205; 2003) Neuroimaging studies also raise issues relating to fundamental human freedoms Or that the images are not photos of whats actually happening in the brain — they are highly processed representations of data People were outraged that Schiavos husband wanted to remove her feeding tube, Wolpe recalls Researchers are flocking to the field of brain imaging, and they are probing brain activity not only in diseases such as depression, but also in basic processes such as consciousness, decision-making and deception Schacter Nature Neurosci. 7, 664–672; 2004) Schacter says his work is far from definitive, but that probably wont stop criminal investigators adopting the technique as a ‘lie detector’ test. “Theres enormous public pressure to use these things,” adds Wolpe Since then, the science has advanced rapidly — and the ethical problems have grown just as fast Slotnick and D So images of decision-making pathways could be used to label certain people as sociopaths Some delegates went further, arguing that scientists have an additional obligation to be more rigorous in their research The images have been a hit with the public too, because they are easier to understand than complex information about neurons, synapses and neural architecture The issues related to brain imaging are part of a larger debate about the implications of neuroscience research (see Nature 433 , 185 ; 2005 ) Washington DC Images have power — and Paul Root Wolpe knows just how persuasive they can be
 Avoiding the Sun is straightforward and cheap But much still needs to be done But such research is likely to have little effect unless policy-makers are prepared to go further than just educating the public Clearly, while avidly pursuing promising avenues of therapy (see page 735 ), the biomedical community and policy-makers need to tackle cancer prevention with just as much zeal Doll R Encouraging children and adults to take up sport is a start, but policies that encourage people to build exercise into their daily lives — town planning that makes walking to the shops or cycling to work easier and safer, for example — are likely to have a longer-lasting impact Finding a truce between the two would go a long way to reducing the burden of diseases, such as cancer, that result. For example, the Australian governments exhortation to “slip on a shirt, slop on a sunscreen, slap on a hat” has led to melanoma having less of a health impact in Australia than in cloudier countries such as Britain Governments need to help ensure that eating the recommended five portions of fruit and vegetables a day is a realistic aim for everyone In the United States and Europe, for example, around two-thirds of the population is either overweight or obese More recent work has added obesity and physical inactivity to the list of factors that increase cancer risk Natl Cancer Inst. 66, 1191–1308; 1981) Once associated with wealth and excess, obesity now disproportionately affects the poorer sections of society, because high-calorie, low-nutrient, processed food is often much more easily accessible than healthy alternatives Our modern lifestyles are increasingly at odds with the environment in which our physiology originally evolved Peto J Physical activity needs to be tackled too Research into how people form dietary and exercise habits will help to inform intervention campaigns, and research on nutrition will help to determine why a vegetable-rich, low-saturated-fat diet seems to provide protection against cancer Studies on genetic susceptibility could one day help us all to tailor our lifestyles to suit our risk profiles The incidence of smoking-related cancers has dropped sharply since the 1990s — the delayed effects of anti-smoking campaigns started in the 1960s and 1970s The next biggest threat facing the developed world is the growing epidemic of obesity The same cannot be said of factors that affect obesity The success of campaigns to combat melanoma and lung cancer are testaments to the impact that prevention can make Tobacco remains a problem, especially in the developing world, where consumption is climbing Today, tobacco use accounts for 30% of cancers in the United States, obesity accounts for 15% and poor diet for up to 25% Twenty-five years ago, a landmark study by Richard Doll and Richard Peto concluded that 75–80% of cancers diagnosed in the United States in 1970 might theoretically have been prevented by altering environmental factors such as smoking, alcohol consumption and diet (R
 As Stephen Jay Gould has pointed out, if we hope to understand Leonardos true greatness we should abandon the metaphor of a “spaceman from a more advanced universe” (often accompanied by a condescending vision of the past), and look at his achievements within the context of his own time At first sight, his astonishing studies of fossils give the impression that he was far ahead of his time Blood circulation was seen to correspond to the movement of water in rivers (the veins of Earth) towards the sea (its heart) But his aim was to find evidence to support a pre-modern, macrocosmic model of Earth, in which the elements were in constant flux, and the levels of water and mountains were constantly changing By pointing some of them out, the Universal Leonardo project invites the visitor to move back and forth between these two fields — something Leonardo himself seems to have done continually. Details of the exhibitions can be found in an extensive (and clever) website at www.universalleonardo.org , which also makes Leonardos thought processes accessible to a wide audience For Leonardo da Vinci, painting did not mean merely copying the appearance of nature He had tried to postulate the existence of subterranean rivers (arteries) bringing water to the top of mountains, but understandably failed, and the idea of the evaporation of water did not fit in with the macrocosm analogy He laid out in his unpublished notes a number of principles that were not clearly redefined by palaeontologists until the twentieth century, such as the idea that growth rings in a fossil could be used to age it He realized, for example, that the sea — unlike the heart — only received water; it did not pump it He refuted the contemporary idea that fossils formed following Noahs flood, and dismissed the neoplatonic theory that they grew inside rocks His art and science sprang from the same source, providing a unified vision of the world and communicating a sense of wonder that is, according to Plato, the source of all philosophy and original investigation I like to think of his anatomical drawings of the fetus nestled in the protecting warmth of the womb (see Nature 396 , 25 ; 1998 ) as the scientific counterpart of this theme In addition, the Munich exhibition displays 20 drawings of the Madonna and Child by a young Leonardo and his contemporaries Its explore page graphically highlights the links between Leonardos art and science by identifying several themes running through the whole of his work Leonardo accepted this model until late in life, when he saw inconsistencies that forced him to abandon it Leonardos visual understanding meant that his scientific studies often took the form of beautiful drawings Leonardos will to know was undoubtedly one of his strongest impulses, and his relentless questioning of how things work extended to all branches of the natural sciences of his day Leonardos work on palaeontology should also be understood in this context One of the claims that Sigmund Freud made in his 1910 book Leonardo da Vinci and a Memory of his Childhood was that Leonardo had an unusually strong relationship with his mother One-quarter of the London exhibition is built around the macrocosm/microcosm theme, and illustrates it with drawings on hydrodynamics, cartography and anatomy, including some of the organs of animals Rather, it involved understanding natures laws and using them to create a figurative world that enhances our awareness of reality The drawing of the heart of an ox combines supreme beauty in the rendering of the plasticity of the form with penetrating and accurate observation of details, particularly of the coronary blood vessels The exhibition of drawings and manuscript pages at Londons Victoria and Albert Museum describes how Leonardo thought on paper, for example, and the display at the Alte Pinakothek in Munich explores the scientific analyses of one of Leonardos early paintings, the Madonna and Child  The results confirm that Leonardo often changed his mind and modified his compositions at different stages of their execution The scope for seeing connections between art and science in Leonardos work is nearly boundless The theme The Body of Earth, for instance, deals with the view — widespread in ancient and medieval times — that Earth is a macrocosm living according to the same laws as the human body The Universal Leonardo project also allows present-day science to investigate Leonardos works The Universal Leonardo project — an extraordinary collaboration of art and science historians, co-curated by Nature columnist Martin Kemp — does justice to Leonardos broad interests in a series of events across Europe There is no documentary evidence for this, but the bond between mother and child in Leonardos Madonna paintings and drawings appears deeper and stronger than in those by other artists They also highlight the importance of geometry in his conception of form X-ray radiography and infrared photography, for instance, were used to probe below the surface of the Madonna and Child 
 A difficult lesson Gardners early physics career took him from Texas to Illinois and then to Munich, Germany, where he studied the nuclear magnetic resonance of liquid copper alloys A map of Europe, formed in outline by small, raised circles, is faintly visible on the paper All mapped out Although the maps Grauman has developed meet federal requirements, problems remain. “They dont give the blind user the relative location of the states,” he explains Although he also had poor vision in his right eye, “It was correctable enough so I could drive — or as my friends say, ‘aim’ — a car,” he says Although he was away from the lab for a few months, he stopped working for only a couple of days. “I had so many graduate students and postdocs and grants and proposals in the works, I wasnt allowed to be sick,” he smiles Although science had intrigued him from a young age, he couldnt get the support he needed to study physics in his homeland And for some people, such technology doesnt yet go quite far enough (see ‘Breaking down the barriers” ) At some point during his search, Sajjad stumbled on the work of Gardners Science Access Project and knew that this was where he wanted to pursue his passion for physics. “It was crucial for my decision that Gardner was a blind physicist and was developing these tools,” he recalls. “WinTriangle turned out to be the thing I needed.”  WinTriangle, which was produced by the Science Access Project, allows a blind user to write mathematical equations, perform calculations and hear mathematical text Berman and his colleague, Dan Grauman from the National Cancer Institute in Bethesda, Maryland, are sitting in a sunlit kitchen in Columbia, Maryland, to test-drive a gadget known as IVEO — one of the newest assistive technologies for the blind Berman, a blind business and technology consultant who provides services for the visually impaired, sits quietly with his eyes closed and head tilted slightly back as the words continue to stream from the computers speakers. “United Kingdom...Ireland...”  “This is quite neat,” he says But for students with disabilities, having access to the right technology can determine whether they choose to enter science at all But rather than slow the loss of vision in that eye, complications left him prematurely blind. “It was not a pleasant time,” he recalls But there are more people with disabilities in the general workforce (13%), and even the college-educated workforce (9%). “There is a strong under-representation of persons with disabilities in STEM fields, especially at the PhD level,” says Ted Conway, director of an NSF programme researching disabilities education But unlike Gardner, Leaman has no intention of giving up his love for astronomy. “I can do both,” he says. But when the shield turned out to be so practical and convenient, he says, “I knew I wanted to share it with other wheelchair users” By combining IVEOs ability to display tactile maps with the Cornell teams software for converting colour into sound, users will be able to determine the boundaries of a map or graph more easily. “This is about finding a way to make graphical information accessible to the blind and those with print disabilities,” says Gardner. “That is still one of the biggest barriers.”  But not all of the barriers are technological. “Widespread use of these technologies requires both money and cultural adjustments,” he says. “The latter is the hardest to achieve.”  Stern agrees. “Counsellors and teachers at all levels, from preschool through to the very critical high-school years, do not believe that students with disabilities can persist and excel in science and engineering fields,” she says. “One reason is there arent enough role models.” In addition, she says, few students, counsellors, teachers or employers know about assistive technologies Despite being paralysed from the neck down ever since an accident when he was 18, Leaman has pursued a career in astronomy and graduated from the University of Maryland in College Park in 2002 During his time there, Leaman participated in a AAAS programme that places disabled students with an aptitude and passion for science into summer internships with research agencies or companies From that moment on, Gardner began inventing tools that allowed him to continue his lab work Gardner is optimistic about the future, but sees change happening slowly. “I dont want to be too negative,” he says. “I am optimistic about public awareness and new technologies Gardner recently teamed up with Victor Wong, James Ferwerda and Ankur Moitra at Cornell University in Ithaca, New York, who have developed software that translates colour pixels on a computer screen into piano notes Graumans job as an information technologist at the National Cancer Institute includes making sure that maps showing cancer mortality across the United States can be used by everyone He began searching the Internet for educational opportunities in the United States because he knew the 1990 Americans with Disabilities Act had opened new doors for students with disabilities He can still recall the time he was introduced to screen readers, the software that converts what is displayed on a computer screen into either audio or a Braille output that can be read on a special keyboard. “That was one of the better days,” he says He is also in the process of mass-producing the Griffin Shield and negotiating contracts with major wheelchair manufacturers He is currently working on determining the rate at which supernovae occur He never planned to abandon physics in pursuit of his innovations, but there was such an unmet need for the tools that he found himself moving in that direction. “I didnt really want to become an entrepreneur,” he says, “but someone had to.”  In the early 1990s, Gardner was awarded a grant from the National Science Foundation (NSF) to establish the Science Access Project at Oregon Here, physicists write papers using a typesetting language called LaTeX, so David Thompson, a fellow student, wrote a software program to convert LaTeX into WinTriangle. “The concept behind this is so simple,” says Thompson, but the significance for Sajjad is enormous. “Were completing the path of communication of maths between blind and sighted communities,” he explains I believe that things are getting better, but it would be dishonest to say that things are already better.”  One student who has persisted in the face of these challenges is Jesse Leaman In 1973, after six years on the physics faculty at the University of Pennsylvania in Philadelphia, he headed west to Oregon State University in Corvallis In 1988, Gardner had an operation to treat the glaucoma in his right eye In 1998, Leaman spent the summer working in the microgravity department at NASAs Marshall Space Flight Center in Huntsville, Alabama, where he designed educational web pages about the working environment aboard the International Space Station In 2000, the NSF estimated that 365,500 people with disabilities were employed in science, technology, engineering and mathematics (STEM) in the United States — about 7% of the science workforce In addition, there is no easy way to uncover the major features of an image without tedious, pixel-by-pixel exploration In effect, he now has an electronic ‘rear-view mirror’, powered by the chairs battery, which can also be hooked up to a laptop for communication purposes In its simplest form it is a scientific word processor with a specialized set of fonts representing symbols and operations that can be read by a speech synthesizer In the past ten years, the project has developed technologies to overcome the biggest barriers for those with poor vision: reading and writing mathematical and scientific notation, and viewing graphs, tables, charts and diagrams It is fairly common for assistive technologies to be modified or enhanced by their users It is the latest in a long line of products that he has invented to remove barriers that prevent the visually impaired from fully appreciating maths and science It took him months to discover that blind people could use computers. “I had a computer that was just sitting and gathering dust in my office,” he says It was during these internships that Leaman developed what he calls the Griffin Shield, a navigation and communication system for motorized wheelchairs and scooters IVEO is expected to change that. “The beauty of the touchpad is that it will permit the blind user to move east and west, or north and south, and actually ‘see’ whether there are neighbouring states with high cancer mortality rates,” he says IVEO is the brainchild of John Gardner, a solid-state physicist turned entrepreneur who is also blind Leaman designed the Griffin Shield out of necessity and never imagined he would one day establish his own business Leaman kept colliding with people and objects while manoeuvring in hallways and offices, so with the help of NASA technologists, he attached a small video camera to the rear of his wheelchair and an LCD monitor to the front Like many researchers with disabilities, Gardner had to develop his own technologies for doing science and communicating his work because commercial solutions were seldom available. “I have a very strong philosophy that we all ought to be reading the same things,” says Gardner. “When there isnt a way to do it, we make a way.”  Virginia Stern, director of the project on science, technology and disability at the American Association for the Advancement of Science (AAAS) in Washington DC, attributes the advances in assistive technology to the can-do attitude of people with disabilities such as Gardner. “Assistive technology has dramatically changed opportunities for students with disabilities,” she says. “Its been the push of the users, some of whom have developed things because they knew what they needed.”  Gardner grew up blind in the left eye Next year, Leaman will receive his doctorate in astronomy from the University of California, Berkeley, and plans to continue collaborating with astronomers at Goddard Open access Thompson and the Adaptive Technology Laboratory at Harvard are now ironing out some of the glitches in the program and adding features to the converter to make it more robust, such as improving the quality of the voice synthesizer and adding more keyboard shortcuts. “Having the converter makes a huge amount of information available to me,” says Sajjad. “It has made a big difference in terms of levelling the playing field between me and other people.”  WinTriangle is ‘open-source’ software, which lets users adapt and rewrite it to meet their needs Part of Wongs work involves reading maps of the ionosphere in which colours represent variables such as electron density and light intensity. “To be able to visualize a map is a very basic need,” says Wong. “There is no way to handle the image problem right now.”  With the Cornell system, Wong uses a touch-sensitive tablet to explore three-dimensional images with a ‘wireless’ electronic pen. “When you move the pen around on the tablet its the same as looking around on the screen,” explains Wong Sajjad has now moved on and is a first-year doctoral student in theoretical physics at Harvard University in Boston, Massachusetts Sajjad lost his eyesight in 1996 at the age of 16 Since 1998, federal agencies have been required to make their information and technology, including websites, operating systems and kiosks, accessible to people with disabilities Sound investment This is where Gardner comes in That was true for Aqil Sajjad, a physics student from Pakistan, who says that the specialized software WinTriangle, which helps the visually impaired read and write mathematics, was a lifeline The group hopes to combine the audio software with IVEOs tactile technology to solve a particularly challenging information problem The next summer, he worked as an intern in the space science department at NASAs Goddard Space Flight Center in Greenbelt, Maryland The paper lies on a touch-sensitive pad attached to a laptop computer This may be reflected in the low number of disabled researchers Today, Gardner is demonstrating IVEO to Grauman and Berman Universal access to the products of scientific research — from public-health information to data on environmental pollutants — is just one aspect of assistive technology Using voice-activation software called Dragon Naturally Speaking, he ran satellite data through an analysis program to study how the solar wind interacts with Earths electric field When he finally returned to the lab, he faced a new set of challenges. “I didnt know how to be blind,” he explains. “No one knew what to do with me.”  Initially, Gardners students would tape-record journal papers for him and try to describe what their data looked like by taking his finger and tracing the curves in a graph or a picture When using the tablet, Wong finds the pen is almost too sensitive — it is actually better than the naked eye and gives too much detail Wong, who lost his sight in an accident when he was seven, works with a team that studies the ionosphere, the layer of the atmosphere between Earth and space “Russia...Sweden...Denmark.” A mechanized voice calls out the names of European nations as Stan Berman moves his fingers delicately over the raised dots on a piece of thick white paper
 Although the Arab Science and Technology Foundation is doing good work, it is important not to convey the picture that it is the only organization dealing with research in the area In addition, there is a surge in the number of research networks and online journals, particularly in the areas of medicine and clinical research. Sir I agree with your Editorial “Science in the Arab world” ( Nature 441 , 1027 ; 2006 10.1038/4411027a ) that the move towards better funding of research and scientific activities in the Arab world is welcome, even though this move remains disproportionate to the wealth of the region The eastern Mediterranean region of the World Health Organization is very active in this respect There is great interest in research among governmental and non-governmental organizations, in addition to individual efforts
 But ethics is a long way from attaining corresponding status within neuroscience Ethicists worry even more about what would happen if one day the scanning technique could be used to accurately discern peoples inner secrets Even so, the arrival of No Lie MRI and Cephos suggests that fMRI is entering the ‘real world’, whether neuroscientists consider it ready or not For now, neuroscientists have only the most basic grasp of what this says about how the brain processes information Geneticists held their own landmark Asilomar meeting more than thirty years ago to discuss the possible regulation of recombinant DNA How would you feel if you had to tell the truth, and nothing but the truth, for a day? Did your wife really look so good in that dress? Were you honestly late just because the traffic was bad? Did you actually do all the necessary controls for that experiment? Society would be a different place if all our lies, however trivial, were abandoned in favour of blunt honesty In others, where little white lies help life run smoothly, knowing all the facts might be uncomfortable In some areas, such as criminal prosecution, this might be advantageous It is too early to tell if fMRI will ever be able to pinpoint liars in anything but a few, tightly controlled circumstances Many neuroscientists think the claims being made for fMRI are overblown Neuroscientists have reasons for their reluctance to wade into ethics One prominent bioethicist reports that his own lecture on neuroethics was cancelled, falling victim to timetable pressure So it is appropriate that last month, a group of prominent scientists, ethicists and lawyers gathered at the Asilomar conference centre in California to found the Neuroethics Society, which will address these issues Society would, for the first time, hold in its hands a reliable tool with which to finger deceit, and this could have a profound impact on individual privacy and human rights Some will argue that the mere threat of an accurate lie test could be used to extract valuable information — the same argument, in essence, that led to the use of polygraphs in the United States Studies so far have been conducted under such conditions, and do not reflect the many types of lies and the situations they may be used to investigate The community needs to broadcast its doubts about this situation from the rooftops — and prepare for a prolonged, complex and occasionally frustrating engagement with the public on the ethical ramifications of its work. The companies, which plan to launch their services later this year, say their goal is to help exonerate the innocent, and to replace the widely discredited polygraph machines used by US government agencies for screening their staff (see page 918 ) The question of how far such approaches should be taken is just one of a number of pressing ethical issues raised by the rapid recent progress of neuroscience The questions raised are likely to be open-ended, and their arrival in the world outside the laboratory may be some way off These thoughts are brought to the fore by the arrival of two US start-up companies, No Lie MRI and Cephos, which are about to offer functional magnetic resonance imaging (fMRI) brain scans in order to detect lies They warn that there is scant evidence that it can reliably distinguish a lie from the truth in any individual case, especially in the real-life, high-stakes situations in which it might be applied This effort is to be applauded, but there is a lot of work to do before it can engage a rapidly expanding neuroscience community that has been relatively slow to recognize its own responsibility to address potential abuses of knowledge Today, the ethical and social repercussions of genetics are a standard component of undergraduate education Whereas a genetic test can say something definitive about a particular genetic make-up, and therefore about predisposition to disease, for example, an fMRI scan is just an indirect measure of neural activity based on oxygenated blood flow
 An unsuspected attachment mechanism may help these huge spiders to avoid catastrophic falls Here we show that zebra tarantulas ( Aphonopelma seemanni ) from Costa Rica also secrete silk from their feet to provide adhesion during locomotion, enabling these spiders to cling to smooth vertical surfaces Our discovery that silk is produced by the feet provides a new perspective on the origin and diversification of spider silk. Spiders spin silk from specialized structures known as abdominal spinnerets — a defining feature of the creatures — and this is deployed to capture prey, protect themselves, reproduce and disperse Additionally, small distal claws enhance adhesion to rough surfaces by mechanically interlocking with the substrate Alternatively, because the tarantula clade (Theraphosidae) is a species-rich group that includes the largest known spiders , tarsal production of silk may have evolved independently as a key innovation to enhance locomotor ability and avert catastrophic falls As it started to slip down the glass, silk produced by the tarsal spigots on all four pairs of legs arrested the spiders descent and allowed it to remain attached to the vertical surface Both evolutionary hypotheses are consistent with the homology of legs and spinnerets as arthropod appendages  Depending on its distribution across spider phylogeny, tarsal synthesis of silk could represent the ancestral condition, with silk production from abdominal spinnerets evolving later If tarsal silks belong to the same gene family, then comparison of tarsal and spinneret silks should help our understanding of the ancestral function and composition of spider silk. Individual tarsal silk fibres often start as a flattened plaque Investigation of the genes involved in tarsal silk production should resolve whether the original function of spider silk was to increase traction or whether it was later co-opted for that purpose Our discovery of secreted tarsal silk forces a reconsideration of the evolution of spider silks  Regardless of whether tarsal silk production is ancestral or secondarily derived, the silk-producing apparatus of spiders seems to be controlled by developmental modules that can be expressed in a variety of body parts Spider feet have a dry attachment system that relies on van der Waals forces generated by thousands of spatulate hairs  Spinneret silk proteins are encoded by a gene family that has evolved through a series of gene duplications and subsequent modifications for particular tasks  The function and morphology of the tarantulas tarsal silk resembles the adhesive agent produced by the spinnerets of the spider Antrodiaetus unicolor , as well as the attachment (pyriform) silk that many spiders use to cement their draglines to substrates  The spiders feet were positioned such that the silk-producing spigots were in contact with the glass, while the dense setae in adjacent regions were held off the surface These fibrous secretions ( Fig. 2 ) function as silken tethers and, when laid down on glass plates, appear as footprints that consist of dozens of fibres with diameters of 0.2–1.0 micrometres and lengths of 100–2,500 micrometres (for details of analyses, see supplementary information ) This seems to be secreted as a viscous fluid that solidifies, gluing the thread to the substrate We have discovered that the tarantula A. seemanni ( Fig. 1 ) has a third attachment mechanism, which depends on fibres exuded from nozzle-like structures on its feet We induced A. seemanni to walk on vertical glass surfaces in order to observe the contact mechanics of this challenging locomotion When walking up vertical planes, the spider attached only the distal parts of its tarsi to the substrate
 Here we show what these data, when combined with data from earlier Parkfield earthquakes, tell us about earthquake physics and earthquake prediction Obtaining high-quality measurements close to a large earthquake is not easy: one has to be in the right place at the right time with the right instruments Such a convergence happened, for the first time, when the 28 September 2004 Parkfield, California, earthquake occurred on the San Andreas fault in the middle of a dense network of instruments designed to record it The 2004 Parkfield earthquake, with its lack of obvious precursors, demonstrates that reliable short-term earthquake prediction still is not achievable The resulting data reveal aspects of the earthquake process never before seen To reduce the societal impact of earthquakes now, we should focus on developing the next generation of models that can provide better predictions of the strength and location of damaging ground shaking. A better knowledge of the materials and conditions within the fault zone obtained from SAFOD should help to discriminate between these possibilities A significant development of the Parkfield experiment has been the collaboration of federal, state and local officials to develop a protocol for issuing short-term earthquake alerts ; the protocol provided a template for communication between scientists and emergency responders and subsequently served as a prototype for volcanic hazard warning protocols  A variety of sensors were deployed in a dense network designed specifically to record the build-up of strain in the surrounding crust, monitor earthquakes and slip on the fault, and detect any precursors that might foreshadow a large earthquake Additional selected faults in California, which are already contained within sparse monitoring networks, should be densely instrumented Additionally, the Global Positioning System (GPS) data suggest that postseismic effects may persist for a decade, and that ultimately, the slip associated with this earthquake (coseismic plus postseismic) will balance the estimated slip deficit that existed on the fault at the time of the earthquake After the prediction window closed, sans earthquake, an independent evaluation of the Parkfield Earthquake Prediction Experiment was conducted by a Working Group of the National Earthquake Prediction Evaluation Council  Aftershocks and earlier seismicity at depths below 6–7 km seem to be confined to a narrow band (see Supplementary Fig. 4 ) Alinement array data from the 2004 earthquake suggest that near-surface slip will reach 20–50 cm over the next 2–5 yr (ref. 28 ), comparable to what was seen after the 1966 event  ignificant signals were detected Although the ability to predict the time and location of earthquakes remains elusive, predicting their effects, such as the strength and geographical distribution of shaking, is routine practice Although the analysis is far from complete, it is clear even now that the observations have important implications for nearly all areas of seismic hazard analysis and loss reduction Although the search for precursors should not be abandoned, we should thoroughly explore other ways to mitigate losses in earthquakes Altogether, these recordings are providing a picture, at unprecedented resolution, of what occurred before, during and after the 2004 earthquake  An alternative explanation for the boundaries of the Parkfield segment is based on fault zone rheology Analysis of the strong-motion records from the 2004 earthquake should lead to a fuller understanding of how each of these factors contributes to the spatial variability in strong shaking, especially at locations close to the fault rupture As noted, identical foreshocks preceded both the 1934 and 1966 Parkfield earthquakes by 17 min (ref. 16 ) Aseismic slip has been recognized as a potentially important component of the slip budget on strike-slip faults in the San Francisco Bay area and on megathrust faults along subduction plate boundaries in the Pacific Northwest region of the United States and in Japan  At present, with the exception of an ambiguous low-level strain of 10 -8 that occurred during the 24 h before the main shock, there is no evidence of any short-term precursory signal, either seismic or aseismic  Attempts to detect short-term precursory strain changes near several other recent M w = 5.3–7.3 earthquakes in California and Japan have also failed  Because the fault seems straighter at depth, where large Parkfield earthquakes nucleate, than it does at the surface, it is possible that fault geometry is not the controlling factor in the location of the Parkfield segment boundaries  Changes in this recurrence time have been used to infer that slip rates over portions of the fault vary with time  Clusters of microearthquakes that produce nearly identical waveforms repeatedly rupture small, fixed patches of the fault—some with remarkable regularity Complementary arrays of strong-ground-motion sensors were deployed to record shaking near the earthquake rupture zone  Complementary data from in situ studies of the Earths crust, such as SAFOD , laboratory experiments that recreate the conditions of faults in the Earth, and continued seismic monitoring will be needed to constrain the numerical models Consequently, it has been invalidated by the long time interval between the 1966 and 2004 main shocks Earthquake activity over a wide range of smaller magnitudes ( M w = 0 to 5) also occurs at Parkfield Earthquake loss mitigation begins with hazard assessment Earthquake prediction is the Holy Grail of seismology Even microseismicity, detectable at the M = 0 threshold in the epicentral region, was absent during the six days before the main shock  Explaining the large variations in amplitude over distances of just a few kilometres continues to challenge our understanding of earthquake rupture dynamics and our ability to predict ground motions near the rupture ( Fig. 4b and Supplementary Fig Fault geometry, rheological and frictional properties of materials, pore fluids and stress conditions have all been proposed to explain segment boundaries  Fault structure and segment boundaries The similar magnitude and rupture extent of the last six Parkfield earthquakes supports the concept of fault segmentation and the role of segment boundaries in influencing the rupture extent and magnitude of earthquakes Faults that do not slip aseismically may exhibit more irregular behaviour because other large events are needed to balance the slip budget For example, the Parkfield Recurrence Model, used at the outset of the experiment in 1985, assumed a constant fault loading rate and failure threshold and allowed that main shocks could be triggered early by foreshocks, but did not allow for late events  For example, the variability in PGA was greatest close to the rupture ( Fig. 4 ) For instance, does the presence of aseismic slip to the north of and within the Parkfield segment yield unusual earthquake behaviour? Observations of the large amount of postseismic slip following the 2004 earthquake suggest that it may help to balance the slip budget Furthermore, most of the observations available for the Parkfield earthquakes in 1881, 1901 and 1922 are consistent with the hypothesis that these earlier earthquakes were similar in size and general location to the later events  Future hopes for prediction will rest on whether such processes are precursory or simply commonplace How seismic and aseismic slip are distributed over a fault and how much and where aseismic slip occurs during the times between large earthquakes are, however, not well resolved However, such foreshocks did not precede the 1901 or 1922 events and so the Parkfield prediction experiment, which was designed to record potential foreshocks as well as other precursory signals, treated all precursors in a probabilistic manner  However, the complex surface trace geometry may result from deformation associated with the segment boundaries at seismogenic depth However, the experiments primary goal of observing a large earthquake near the rupture has been achieved However, the variability in the spatial distribution of slip for the last three events and the different direction of rupture propagation in the 2004 event invalidates the application of the second class of characteristic behaviour to the Parkfield earthquakes However, with the exception of foreshocks, unambiguous and repeatable instrumental observations of such phenomena remain elusive If events in the second class were further constrained to have the same rupture time history and distribution of slip, then this class of recurrent behaviour would imply low variability in the distribution of strong ground shaking among the recurrences of characteristic events If these factors are found to be important for predicting the distribution of shaking within a few kilometres of the rupture as well, then directing additional resources towards developing detailed maps of these properties would also be effective Implications for future research The magnitude and rupture extent of the 2004 Parkfield earthquake were correctly anticipated, but its time of occurrence clearly was not Improved hazard assessment will require incorporating the observed variability in both earthquake sources and the resulting ground motions into probabilistic seismic hazard analysis In 1985, the USGS issued a long-term prediction that an earthquake of approximately M w = 6 would occur before 1993 on the San Andreas fault near Parkfield  In a time-predictable model, the time between successive events is proportional to the slip of the prior event; in a slip-predictable model, the size of an earthquake is proportional to the time since the prior event  In the first, events have the same faulting mechanism and magnitude, and occur on the same fault segment ; this class of characteristic behaviour is most appropriate for long-term forecasting of earthquakes and is often inferred from paleoseismic investigations In the second class, the events also have the same epicentre and rupture direction  Incorporating realistic variability into hazard assessments will entail sophisticated three-dimensional numerical models that can accurately explore many seismic cycles and include the build-up of strain via plate motions, dynamic stress changes during rupture, and postseismic deformation Innovations in the collection, transmission and storage of Parkfield data included a pioneering effort to provide publicly available, near-real-time earth science data streams over the internet Kagan and Jackson concluded that too few of Nishenkos predicted gap-filling circum-Pacific earthquakes occurred in the first 5 yr.) Although the Parkfield earthquake history supports the use of characteristic events for earthquake forecasting, this topic remains controversial and we must consider whether conclusions drawn from observations at Parkfield will transfer to other seismogenic regions Large earthquakes are also anticipated on known fault segments in China, Japan, Turkey and elsewhere, and international cooperation should be sought to develop comprehensive monitoring in these regions Lindh and Boore suggested a fault-geometry-based explanation for the location of the boundaries of the Parkfield segment: a 5° bend in the fault trace to the northwest and a right-stepover to the southeast appeared to offer geometric obstacles that could limit earthquake rupture Long-term non-randomness of earthquakes The notion that large earthquakes tend to occur as similar-size ‘characteristic’ events on fixed segments of a fault and that these segments are identifiable from geologic and geophysical data arose in the 1980s (refs 3 , 19 and 31 ) and remains central to fault-based Probabilistic Seismic Hazard Analysis (PSHA) Many of these clusters have characteristic recurrence times of months to years that scale with the magnitude of the repeating events Measurements of slip beginning shortly after the 1966 Parkfield earthquake appear to provide some insight into these questions Michael and Jones definition was designed to encompass the Parkfield main shocks through 1966; the 2004 main shock also satisfies their definition Neither of these models is compatible with the sequence of Parkfield earthquake ruptures  Notable precursory signals are not evident in the magnetic field, telluric electric field, apparent resistivity, or creep observations  On the other hand, near-surface soil conditions at the site and heterogeneity in the properties of the Earths crust that influence seismic-wave propagation are known to be important for determining the shaking at locations farther from the rupture On the Parkfield section, the motion of the Pacific plate relative to the North America plate is partly accommodated by repeating M w = 6.0 earthquakes Owing to limited observations of these earlier events, a rigorous definition of the Parkfield main shocks must be limited to their overall size and their location based on rupture along the Parkfield segment  Parkfield-like experiments embedded within broader monitoring networks in other locations can provide similarly valuable data for faults in other tectonic contexts Postseismic slip equal to about 60% of the coseismic slip occurred in the first month after the 2004 event ( Fig. 3f ) Postseismic surface slip of 35–45 cm was observed using alinement arrays following the 1966 Parkfield earthquake  Precursors and earthquake prediction The idea that detectable precursory processes precede earthquakes dates back to at least the seventeenth century  Prediction of damaging ground motion Most of the catastrophic damage in earthquakes occurs close to the earthquake source, but relatively few recordings of strong shaking close to an earthquake have been made Preliminary seismic slip models (see Fig. 3d for example) indicate slip was concentrated in two small regions, near the stations recording the strongest PGA Properties of materials and fluid overpressure adjacent to the fault have been proposed to explain creeping and locked fault segments  PSHA also includes other approaches such as smoothed seismicity models (see ref. 32 ), random events and multiple segment ruptures (see ref. 23 ) Recordings of accelerations greater than 1 g are rare, but they may not be anomalous at locations within a few kilometres of fault ruptures S3 ) Seismic and aseismic slip Over the long term, both seismic and aseismic slip along plate boundaries like the San Andreas fault accommodate the relative motion between the plates Similar to the Parkfield main shocks, models of these events suggest that they may balance their local slip budget with a mix of seismic and aseismic slip  Spatial variations in the intensity of shaking, such as peak ground acceleration and peak ground velocity, are often attributed to four factors: differences in soil conditions among sites, differences in the wave propagation to the sites, complexities of the rupture geometry, and heterogeneity of slip on the fault Statistical models of earthquake recurrence have also been applied to these events Subtle strain changes of a few nanostrain were recorded on several instruments in the 24 h before the earthquake Such changes place important constraints on earthquake nucleation physics but are too small to provide a reliable basis for issuing public warnings that a damaging earthquake is imminent Such models must be able to explain the interaction of aseismic and seismic slip, the segmentation of faults, and the strong spatial variations in the intensity of strong shaking Temporal variations in rupture propagation, however, probably also influenced the radiation of the strongest shaking, as illustrated by the spatial variability in PGA ( Fig. 4 ) and peak ground velocity close to the fault That is, irregularities in the surface trace may reflect the presence of the boundaries at depth rather than being the primary cause of these boundaries The 1857 M w = 7.9 Fort Tejon earthquake ruptured the locked fault southeast of Parkfield and is thought to have initiated near Parkfield  The 1934, 1966 and 2004 Parkfield earthquakes are remarkably similar in size (see Fig. 5 for example) and location of rupture, albeit not in epicentre or rupture propagation direction The 2004 aftershocks relocated with a three-dimensional velocity model do not appear to show these features extending to depth ( Fig. 2 ) The 2004 Parkfield event, however, is the first at this location for which the geodetic data were recorded during and after the earthquake with sufficient temporal and spatial resolution to enable separation of the coseismic and postseismic signals The 40-km-long Parkfield section of the San Andreas fault was recognized two decades ago as a promising earthquake physics laboratory and an intensive experiment was established to record the next segment-rupturing earthquake there and provide the much-needed detailed observations The aftershocks of the 1966 and 2004 earthquakes delineate many of the same fault structures ( Fig. 2 ) The dense instrumentation arrays continue to uncover new processes, such as deep tremor under the locked section of the fault southeast of the Parkfield segment  The departures from perfectly regular occurrence of these earthquakes have been interpreted using physics-based variations upon the characteristic earthquake model The earthquakes at Parkfield, both large and small, provide a fertile laboratory for testing and refining the characteristic earthquake concept by offering information on slip distribution, rupture dynamics and afterslip, and for testing models of earthquake recurrence and interaction, which are central to contemporary earthquake hazard assessment . (The characteristic earthquake model can also be tested using global data sets The extent to which earthquake phenomena can accurately be predicted will ultimately depend on how well the underlying physical conditions and processes are understood The failure of the long-term prediction of the time of the earthquake as well as certain aspects of the 2004 Parkfield earthquake (discussed below), have confounded nearly all simple earthquake models The ground motion near the 2004 earthquake was recorded at eight sites within 1 km of the rupture and at 40 sites between 1 and 10 km from the rupture ( Fig. 4 ), nearly doubling the global data set of strong-motion records within those distances The historical record of earthquakes at Parkfield includes at least six such events since 1857 (ref. 2 ; Supplementary Text 1 , Supplementary Fig. 1 and Supplementary Table 1 ) The history of events at Parkfield and the detailed observations of the 2004 event have revealed variability in intervals between earthquakes, variations in slip distributions of large events, and spatial variations in strong ground motion The instruments at Parkfield continue to operate and provide important data on post-seismic deformation and other processes The large uncertainties in current estimates of strong ground shaking require that societal guidelines, including the Uniform Building Code and Californias Alquist-Priolo Fault Zoning Act , be conservative, thereby driving up the cost of construction and hazard mitigation The local stress drop in these regions of concentrated slip appears to be more than an order of magnitude larger than the average stress drop of 0.2 MPa associated with the very smooth geodetic slip model ( Fig. 3d ) The nature of segment boundaries, however, is controversial The occurrence of the anticipated moment magnitude M w = 6.0 earthquake on 28 September 2004 (origin time 17:15:24 Coordinated Universal Time, utc ; epicentre location 35.815° N, 120.374° W; depth 7.9 km) fulfilled that promise The Parkfield dense instrumentation network, which includes a variety of geophysical sensors, motivated the placement of a scientific borehole, Earthscopes San Andreas Fault Observatory at Depth (SAFOD), at the northwestern end of the Parkfield segment and served as a prototype for the geodetic networks that are part of Earthscopes Plate Boundary Observatory  The Parkfield experiment showed that diligence is required to maintain these specialized networks until a large earthquake occurs, and the detailed observations made at Parkfield demonstrate how valuable such perseverance can be for advancing our understanding of earthquakes. The Parkfield section of the San Andreas fault is bounded on the northwest by a 150-km-long creeping section, where numerous small earthquakes occur, and on the southeast by hundreds of kilometres of locked fault where few earthquakes have been detected in the twentieth century ( Fig. 1 ) The peak horizontal acceleration (PGA) for two of the records are greater than 1.0 g (where g is the acceleration due to gravity) with one of these exceeding the instruments recording capacity of 2.5 g  The primary goal of the Parkfield Earthquake Prediction Experiment was to obtain a detailed understanding of the processes leading up to the anticipated earthquake; a secondary goal was to issue a public warning shortly before the earthquake The reasons for creep to the northwest and locking to the southeast are not clear The region of maximum slip in the 2004 event appears to partially fill a deficit in the distribution of slip that had accumulated beginning with the 1966 earthquake , but some slip-deficient regions apparently remain ( Fig. 3 ) The sequence of earthquakes at Parkfield since 1857 has long been considered a prime example of the recurrence of a characteristic earthquake  The simple setting and apparent regularity of Parkfield earthquakes offered the rationale for the only scientific earthquake prediction officially recognized by the United States government and an opportunity to place instruments in the region before the anticipated earthquake The systems pioneered at Parkfield have become standard elements of seismic monitoring throughout the US and have set the foundation for the installation of the USGS Advanced National Seismic System (ANSS)  The value of the unique long-term record of crustal deformation being collected at Parkfield suggests that the monitoring there should continue The variability in the time between earthquakes implies a coefficient of variability (COV) of about 0.45 which is similar to the COV used in recent forecasts for the San Francisco Bay Area but greater than that proposed in earlier models for the Parkfield sequence  There are other faults, however, with aseismic slip that produce small repeating events and may thus produce characteristic events similar to those observed at Parkfield These experiences demonstrate that reliable short-term earthquake prediction (up to a few weeks in advance) will be very difficult at best These include the Hayward and Calaveras faults in California and partially coupled subduction zones  These records show the wavefield in unprecedented detail and reveal large spatial variations in shaking amplitude This documented absence of clear precursory activity sets stringent bounds on the processes that preceded this earthquake This has significant ramifications for earthquake hazard research This lack of short-term precursors emphasizes the difficulty of reliable short-term earthquake prediction (up to a few weeks before) This limited regularity underlies most of the long-term prediction models proposed for the earthquakes  This segment is adjoined on the northwest by a creeping section where, perhaps, stable sliding precludes large earthquakes and on the southeast by a locked section, which may fail only in infrequent great earthquakes  This suggests that complexities in the seismic source may have been the primary cause of the variations, in which case research with a greater emphasis on understanding the physical processes controlling complexity of the source would be most effective This suggests that long-term earthquake forecasts require models that include higher degrees of variability (for example, see ref. 23 ) This working group recommended that monitoring be continued as a long-term effort to record the next earthquake at Parkfield Thus, the Parkfield earthquakes are consistent with the first class of characteristic earthquake behaviour To apply even the simplest mechanical model for the build-up of strain and its sudden release in earthquakes, one must account for slip on the fault that occurs aseismically To the extent that such variations in shaking are predictable, the precision of seismic hazard maps and building codes could be improved, allowing necessarily limited hazard mitigation funds to be used more effectively To understand earthquakes requires observing them up close and in detail—a difficult task because they are at present largely unpredictable, and so knowing where to put the instrumentation needed to make such observations is a challenge Two classes of characteristic earthquakes have been considered for these events Ultimately, a combination of factors, including deep fault geometry, fault rheology, and stress level, may be necessary to explain why a fault creeps or is locked and what constitutes a segment boundary Various forms of fault interaction have been proposed to explain the variation in recurrence intervals of the earthquakes  We note that the six Parkfield earthquakes since 1857 have occurred with statistically significant (albeit imperfect) regularity in time—more regular than random but not sufficiently periodic to be predictable in any useful way beyond long-term statistical forecasts ( Supplementary Text 2 )
 A large-scale quantum computer might be able to master tasks, such as factorizing large numbers or simulating other quantum systems, that ordinary, classical computers cannot Additionally, spin qubits can be controlled by dint of a phenomenon known as exchange coupling, in which one spin can be used to affect the state of a neighbouring spin All possible single-qubit operations together with the square-root-of-swap on two qubits form a universal set appropriate for quantum computing  Although it turns out that a double dot is less susceptible to such processes than a single dot, Koppens and colleagues further suppress it by increasing the energy barrier for back-hopping by applying a large voltage between the two contacts Any process that can rotate one of the spins so that it is antiparallel can unblock this jam As originally suggested , the idea was that the spin on a quantum dot can act like a valve for the electric current, which would repeatedly open and close when the spin is rotated At that time, high-frequency sources — which came from the newly developed radar technology — were scarce, and microwave excitation remains a challenging business today But quantum computers are delicate beasts, and very sensitive to disturbance from a noisy environment Crucially, spin qubits can be read out through converting spin information to charge information , which can be detected at the single-electron level in quantum dots  Direct suppression of the oscillating field was achieved by applying a voltage to one of the contacts that oscillated with the same frequency, but opposite phase, compared with the undesired electric field Electron spin resonance (ESR) results from the interplay of two magnetic fields Electron spins have the advantage as qubit candidates that they couple very weakly to their environment, by virtue of the small electron magnetic moment ESR was first detected by the Soviet physicist Evgeny Zavoisky in the mid-1940s, and shortly thereafter in the United States and in Britain  First, a static field is used to create an energy difference between an electrons spin-up and spin-down states, the phenomenon known as Zeeman splitting Five widely accepted hardware requirements have been advanced for a practical quantum computer  How can one rotate the spin of a single electron? How can such a tiny rotation, once achieved, be detected? And where, indeed, does one obtain a single electron in the first place? The remarkable small semiconductor structures called quantum dots, whose tally of electrons can be tuned, one by one, down to just one , provide an answer to the third question However, isolation from the environment is not enough for a good qubit (otherwise, we might well be discussing neutrino qubits) In a single quantum dot, if the Zeeman splitting were too small, thermal fluctuations in the contact leads would wash out the difference between the spin-up and spin-down energy states, preventing any reliable measurement of spin rotation In two dots in series, this becomes a spin blockade , in which the Pauli exclusion principle prevents current passing because otherwise electrons with parallel spins would be in the same place — and so in the same quantum state ( Fig. 1 ) Koppens and colleagues rely on the ingenious use of yet another sort of spin-to-charge conversion to detect the spin rotation indirectly Koppens et al . circumvent the ESR frequency problem by measuring not the spin rotation in a single quantum dot directly, but how that rotation allows an electron to hop on to a second dot Koppens et al . set up the conditions for ESR to occur in their quantum-dot system and observe just such an unblocking behaviour Moreover, blank spin qubits can be initialized reliably by illuminating the quantum dot with light from a laser , a technique that also relies on the charge being coupled to the spin, in this case through the relativistic effect of spin–orbit coupling Of these requirements, all but the last have been realized for spin qubits in quantum dots On page 766 of this issue , Koppens et al . supply a response to the first two Prominent among these is the coupling of the electron spin to the surrounding nuclear spins, which reduces the accuracy of spin rotations Rotating only one spin is a remarkable accomplishment by itself, but it is potentially also of great practical significance, because electron spins have been proposed as a way to realize quantum bits — qubits — fundamental to a quantum computer  Second, an oscillating field is applied at right angles to the first Sequences of several subsequent pulses instead of one, as widely used in NMR, might improve the situation, but in the long run one also needs to gain sufficient control over the nuclear spins Surprisingly, the two-qubit square-root-of-swap operation has already been demonstrated in two exchange-coupled single-electron dots, and it is single-qubit operations that have languished as the last item on the to-do list That turns out to be an interesting problem in itself  The ability to rotate a single electron spin in a quantum dot, combined with single-spin read-out and controllable exchange coupling between spins, throws up many questions and challenges The observation of a current is not enough on its own to prove that ESR has caused the rotation of a single spin The oscillating magnetic field that sets up ESR also, unavoidably, brings with it a small electric field The square-root-of-swap is a quantum operation that is rather like swapping the values of two qubits, but stopping midway — something that is impossible to do classically The tool-box for spin-based quantum computing is complete — now its time to use it. These are: a scalable physical system with well-characterized qubits; the ability to determine the initial values of those qubits; long-lived, coherent qubit states; the ability to measure single qubits; and a universal set of quantum operations that can be combined to generate an arbitrary algorithm, for example for factorization or quantum simulation They exploit a phenomenon known as electron spin resonance to rotate a single spin in one of two coupled quantum dots, and detect the effect by measuring variations in electric current flowing through the double dot They observe both a continuous current when the ESR field is turned on constantly, and so-called Rabi oscillations of the current (and thereby the spin) for a pulsed ESR field with varying pulse length This is a consequence of two fundamental physical laws: the Pauli exclusion principle, which prevents two electrons from assuming the same quantum state; and the repulsive Coulomb force between electrons negative charges This is one reason why the analogous process of nuclear magnetic resonance (NMR) is so much more familiar: NMR spectroscopy typically requires a much lower, radio frequency, because the intrinsic magnetic moment of a nucleus (and therefore its Zeeman splitting) is about 2,000 times smaller than that of an electron This leads to a false alarm: electric current in the absence of spin rotation This process is not affected by thermal fluctuations in the leads, so a smaller Zeeman splitting, which requires only radio-frequency excitation for ESR to occur, can be used Through a process known as photon-assisted tunnelling, this field can assist electrons in breaking the spin blockade by, for instance, first hopping back into the source contact, against the applied voltage Thus, for ESR to occur and be clearly detected in a single dot, the Zeeman gap must typically have an energy equivalent to a high, microwave frequency Traditionally, ESR probes macroscopic samples by rotating roughly 10 21 spins simultaneously Unblocking that is caused by the coupling of the electron spin in a quantum dot to the nuclear spins in its host semiconductor at low magnetic fields has already been observed  Using ESR for single-qubit operations was proposed early on , but success has so far proved elusive, because detecting the phenomenon is far from straightforward When such difficulties have been surmounted, the stage is set for first tests of quantum algorithms with a small, but increasing number of spin qubits When the frequency of this second field matches the frequency of the Zeeman energy gap, the electrons spin will rotate

 Here we report a fossil snake with a sacrum supporting a pelvic girdle and robust, functional legs outside the ribcage However, recent developmental and palaeontological discoveries suggest a more complex scenario of limb reduction, still poorly documented in the fossil record  It has commonly been thought that snakes underwent progressive loss of their limbs by gradual diminution of their use  Phylogenetic analysis shows that the new fossil is the most primitive (basal) snake known and that all other limbed fossil snakes are closer to the more advanced macrostomatan snakes, a group including boas, pythons and colubroids The new fossil retains several features associated with a subterranean or surface dwelling life that are also present in primitive extant snake lineages, supporting the hypothesis of a terrestrial rather than marine origin of snakes. The new fossil, from the Upper Cretaceous period of Patagonia, fills an important gap in the evolutionary progression towards limblessness because other known fossil snakes with developed hindlimbs, the marine Haasiophis , Pachyrhachis and Eupodophis , lack a sacral region All multistate characters were treated as unordered Analyses were performed with PAUP* version 4.0b10 (ref. 20 ), with the branch-and-bound search option implemented Bremer support and bootstrap percentages based on 10,000 heuristic replications are given in Fig. 3  Bremer support was calculated with the McClade interface with PAUP Character codings for the fossil snakes Wonambi naracoortensis , Pachyrhachis problematicus and Eupodophis descouensi , considered by some authors as being the most basal snakes , were reviewed in accordance with recently published descriptions  Character descriptions, the data matrix and a list of apomorphies diagnosing each relevant clade are given in Supplementary Information . Characters included in this matrix are intended to address the more inclusive basal snake interrelationships and the affinities of the relevant fossils Najash , Pachyrhachis , Haasiophis , Eupodophis and Wonambi ; and does not attempt to elucidate macrostomatan interrelationships Codings for Dinilysia patagonica are based on observations made by H.Z. on the holotype and new specimens recently discovered  Methods The data matrix used in the phylogenetic analysis is based on two recently published character lists  Recent attempts to reconstruct phylogenetic affinities within the macrostomatan clade show extensive conflicting character delimitations that should be addressed more thoroughly before any new proposal of macrostomatan interrelationships Twenty-one new characters were added to include post-cranial morphology, totalling 119 characters coded for 18 snake taxa We alternatively used a dibamid ancestor as an outgroup with no effects relevant to this study We rooted the analysis with a hypothetical varanoid ancestor (coded according to the conditions found in the terrestrial Varanus , Heloderma and Lanthanotus , and the marine Mosasauroidea)  A discrete basal plate is present, but the dentaries lack a lingual ridge (or subdental shelf) medial to the tooth-bearing region, a primitive condition absent from all known snakes A phylogenetic analysis, including all relevant fossil snakes, shows Najash as the most basal snake ( Fig. 3 ), lying outside the clade consisting of all living snakes A snake with a strongly concave ventral surface of the parasphenoid rostrum, forming a deep and straight gutter; two sacral vertebrae present; single large parazygantral foramen on each side of neural arch; proximal caudal vertebrae with blunt haemapophyses; robust femora with a large trocanter Accessory processes of the prezygapophyses are lacking and parazygantral foramina are present in all trunk vertebrae Additional material Additionally, all three taxa resemble modern snakes in lacking a sacral region and in having a pelvis that is not suspended from the axial skeleton but rather lies within the ribcage  All other mid-Cretaceous snakes are nested within the clade formed by living snakes, with the terrestrial Dinilysia as the sister-group of alethinophidians, whereas the marine Haasiophis , Pachyrhachis and Eupodophis as well as the Pleistocene Wonambi naracoortensis are nested within a poorly resolved macrostomatan clade, supporting a macrostomatan affinity , instead of a basal position as the most primitive snakes  Although no teeth are preserved, their alveoli are transversely expanded instead of anteroposteriorly wide as in macrostomatans Although present, the crista circumfenestralis of Najash (here represented mostly by the crista prootica) is the least developed among all known snakes As in Dinilysia and the anilioids, the otico-occipital portion of the braincase is transversely expanded As in lizards, Dinilysia and Wonambi , the basipterygoid processes are prominent, rather longitudinally oriented structures that fit in an articular facet of the pterygoid instead of contacting only the latter as in the more derived snakes As in Pachyrhachis , it is half the size of the latter two pelvic bones and is spatula-shaped proximally Both cranial (a transversely expanded occipital region and a broad stapedial footplate) and vertebral (a low neural arch) morphological traits of Najash show adaptations to a subterranean life, perhaps as a surface-dwelling species that would occasionally use tunnels produced by burrowers Both ilium and pubis are similar in size and show a rounded, expanded proximal head and a long rod-like body that tapers distally Conversely, synapophyses project laterally beyond the level of the prezygapophysial tip on the slightly smaller posterior trunk vertebrae ( Fig. 1d , e ) and are no longer divided in the more posterior ones Diagnosis Etymology Free lymphapophyses (bifurcated ribs) and chevron bones are lacking From Hebrew Najash , the legged biblical snake; rionegrina , for Río Negro Province, Argentina, where the fossil was found Haemapophyses are present as small button-like nodules on the posterior edge of the centrum of the more posterior caudal vertebrae ( Fig. 1f ), resembling the condition found in anilioids and some macrostomatan snakes Holotype However, the presence of several other features typical of the more advanced macrostomatan snakes such as pythons, boas and colubroids supports the competing hypothesis that these fossils were advanced (macrostomatan) snakes instead, with no special bearing on the origin of snakes  However, the proximal part retained its contact with the two other pelvic elements In contrast with Haasiophis , Pachyrhachis and Eupodophis , the last rib in Najash is ventral to the right femur, reflecting the external position of the hindlimbs with respect to the ribcage ( Fig. 2b ) It retains several primitive features absent in any known fossil or recent snake, including a remarkably primitive pelvis Locality and horizon Mid-trunk vertebrae are broader, with lower and longer, blade-like neural spines, shallow and thin haemal keels extending along the entire ventral surface of the centrum, and synapophyses reaching the level of the prezygapophyseal tip MPCA (Museo Paleontológico ‘Carlos Ameghino’, Cipolletti, Río Negro) 390–398, 400, consists of a large fragment of the left dentary and anterior portion of the corresponding splenial, and a nearly complete and articulated postcranial skeleton composed of several sections bearing a total of 122 articulated and associated vertebrae (109 presacrals, 2 sacrals, 11 caudals), pelvic girdle, two femora, one fibula and the proximal head of the right tibia (Figs 1 and 2 ) Najash , scolecophidians, Dinilysia and anilioids represent the four successive outgroups to the macrostomatan clade in which the first marine snakes were documented Neural spines become reduced to mere ridges and haemal keels broaden significantly Only the right pelvic elements are well preserved and mostly in place Pachyrhachis problematicus , Haasiophis terrasanctus and Eupodophis descouensi , three marine fossil snakes from the Tethyan coasts of Northern Gondwana, were until now the only known snakes with well-developed hindlimbs Preserved elements of the appendicular skeleton include the pelvic girdle, both femora, the proximal articular head of the right tibia, and the right fibula Pubis, ilium and ischium are not sutured or fused together proximally, and the medioventral pubo-ischiac symphysis is lacking Sacral pleurapophyses are long and slightly curved, and their pointed tips are separated, suggesting a loose suspension of the pelvis Squamata Oppel, 1811 Serpentes Linnaeus, 1758 Najash rionegrina gen. et sp. nov Statistical support for this hypothesis is strong Synapophyses are divided into parapophyses and diapophyses, a derived condition shared with all alethinophidian snakes The anterior trunk vertebrae bear relatively high and narrow neural spines, developed hypapophyses, and synapophyses directed posteroventrally The contact between the posteriorly expanded edge of the supraoccipital and the right exoccipital suggests that the exoccipitals did not meet dorsally, a plesiomorphic lizard trait also known in Haasiophis and in some boine snakes  The cotyle of the procoelous vertebrae form a rounded to slightly oval surface that receives a rounded condyle ( Fig. 1d , e ), a derived condition shared with Dinilysia and alethinophidian snakes, including Pachyrhachis and Haasiophis  The crista prootica projects weakly laterally to the stapedial footplate, around its anterodorsal portion, although without overlapping the latter as in all modern snakes The first three caudal vertebrae bear well-defined, distally bifurcated lymphapophyses that project laterally The laterosphenoid is lacking, a plesiomorphic condition found in Dinilysia and scolecophidians (wormsnakes) The left dentary retains two mental foramina ( Fig. 1b , c ) The neural arch is low, as is typical in secretive or fossorial forms, and shares with Dinilysia a prominent ridge on each side and above the interzygantral ridge The posterior half of a non-associated braincase with its right otico-occipital region preserved ( Fig. 1a ) and several associated presacral vertebrae (MPCA 385); several disarticulated cranial and vertebral elements of a larger individual, including an incomplete left dentary, axis, and associated presacral and caudal vertebrae (MPCA 380–383) The presence of fully formed hindlimbs enforced the idea that these were the most primitive (basal) snakes and perfect transitional taxa linking extant snakes to an extinct group of marine lizards, the Mosasauroidea  The preserved posterior portion of the braincase of Najash ( Fig. 1a ) is similar in several respects to that of Dinilysia patagonica and that of the fossorial anilioid snakes (pipesnakes) The recess is located laterally to the contact between the prootic and the supraoccipital, suggesting a dorsal exposure of the prootic between the supratemporal, exoccipital and supraoccipital, a characteristic also present in Dinilysia , Cylindrophis and Anilius  The right ischium is broken in two pieces The right posterodorsal portion of the prootic and posterolateral portion of the parietal form a deep and narrow recess that receives the anterior portion of the missing supratemporal, which was incorporated into the cranial wall as in Dinilysia and the anilioids Cylindrophis and Anilius  The snake reported here was found in the context of a rich early Upper Cretaceous fossil fauna from north Patagonia, Argentina, and represents the earliest limbed snake from a fully terrestrial deposit The stapedial footplate is broad, as in Dinilysia and the fossorial macrostomatan Xenopeltis  The three specimens referred to N. rionegrina are identified as snakes on the basis of the completely enclosed braincase, fused parietals, axis with sutured anterior and fused posterior hypapophyses, large number of presacral vertebrae (109 preserved), zygosphenal and zygapophyseal facets separated by a non-articular area, anterior margin of zygosphenal tectum straight or slightly convex, divided synapophyses, three distally forked lymphapophyses, haemapophyses on posterior tail vertebrae The ventrolateral expansions of both crista interfenestralis and crista tuberalis are broken, but the juxtastapedial recess remains widely open posteriorly because of a poorly developed posterodorsal margin of the crista tuberalis, a plesiomorphic feature also found in scolecophidians, Dinilysia and basal alethinophidian snakes The zygosphene is thick and well developed, as in Dinilysia and macrostomatans; however, unlike the latter, the interzygapophyseal constriction is shallow and a posterior neural arch notch is absent This scenario unequivocally supports the hypothesis of a subterranean or surface-dwelling origin of snakes. Unlike any other snake, Najash retains two sacral vertebrae that separate the trunk region anatomically from the caudal region ( Fig. 2 ) Upper section of the Candeleros Formation (Cenomanian–Turonian ) at ‘La Buitrera’, Río Negro Province, Argentina
 Cell biologists are now capitalizing on the accessibility of the retina to investigate important aspects of developmental angiogenesis, including how it relates to neuronal and glial development, morphogenesis, oxygen sensing and progenitor cells Pathological angiogenesis also occurs in the retina and is a major feature of leading blinding diseases, particularly diabetic retinopathy The retina and its clinical disorders have a pivotal role in angiogenesis research and provide model systems in which to investigate neurovascular relationships and angiogenic diseases. The retina has long been regarded as ‘an approachable part of the brain’ for investigating neurosensory processes A commonly employed retinal angiogenesis model in neonatal mice shares features with human retinopathy of prematurity , and might be useful to test whether Wnt signalling factors can restore peripheral retinal vascularization A description of norrin and frizzled-4 expression in relation to developing retinal blood vessels might clarify why only peripheral vasculature is lost in patients with familial exudative vitreoretinopathy, or why the deeper retinal capillaries are specifically aborted in mice with Wnt-related mutations A different retinal vascular phenotype occurs in mice with a defect in the very-low-density lipoprotein receptor (VLDLR) A key question is how growing vessels sense and respond to varying tissue oxygen levels A partial answer comes from an inherited disorder, von Hippel–Lindau (VHL) disease, in which vascular endothelial tumours, or haemangiomas, arise in the retina and other organs ( Fig. 2b ) A proteomic study of vitreous fluid from patients with diabetic retinopathy detected 56 proteins: 29 of these were vitreous-specific and the balance were plasma derived  A role for HIF-VHL in retinal vascularization is suggested by Vhl expression within the developing retina and by retinal vascular abnormalities in Hif2 α-knockout mice  Achieving this goal will require more comprehensive analyses of retinal and vitreous composition, greater understanding of retinal nutrition by oxygen and other substrates, better animal models, and interactions between experts in angiogenesis, immunology, wound-healing and clinical retinal disorders Additional capillary networks in deeper retinal layers then arise by sprouting from the nascent inner vascular layer ( Fig. 3d ) Although VEGF itself is widely expressed in the developing retina, its various receptors (FLK1, FLT1, and neuropilins 1 and 2) appear in a temporally and spatially distinct fashion ( Fig. 4a ) An alternative explanation for similarly patterned retinal glial and vascular networks is that both arise in response to mechanical forces within a shared structural milieu An elongin–BC complex then polyubiquitinates HIF1α, targeting it to the proteasome for destruction  An outward wave of T cells and other leukocytes adheres to retinal endothelial cells through intercellular adhesion molecule-1 and CD18, and induces loss of capillary segments by Fas ligand-mediated endothelial cell apoptosis  Angiogenic factors in proliferative diabetic retinopathy Pathological retinal neovascularization in patients with diabetes results from an imbalance of pro-angiogenic and anti-angiogenic factors Another clue is provided by TLX, which is an orphan receptor with established roles in neural development As in the brain, angiogenic sprouting is the predominant mechanism of retinal vascularization (reviewed in ref. 3 ), although additional modes of vascular growth, such as intussusception, are not excluded Astrocyte growth roughly follows this radial plan in a process that requires platelet-derived growth factor (PDGF) synthesized by retinal ganglion cells  At present, it is unclear whether haematopoietic stem cells or other types of progenitor cell contribute normally to retinal vascular development At sites of chorioretinal scars from laser treatment, retinal oxygen tension is elevated compared with untreated regions  At this point, it is impossible to know which of these factors is causative, because temporal changes are unknown Blood vessels and glia often use attractive and repulsive guidance cues employed by axons  By contrast, pathological retinal angiogenesis — a key component of irreversible causes of blindness — generates chaotically orientated and physiologically deficient vessels that do not conform to neuronal histology, which can lead to vision-threatening exudation and haemorrhage ( Fig. 2 ) Cellular relationships in vascular guidance and patterning Despite indirect evidence implicating hypoxia as a stimulus for retinal vascularization, oxygen profiles cannot explain the subtle meshwork pattern of retinal blood vessels, and their partial alignment with ganglion cell axons, astrocytes and neuronal elements ( Fig. 1 ) Certainly, an ongoing supply of circulating cells seems unnecessary as vascularization occurs in retinal explants disconnected from the systemic circulation shortly after birth  Changes in vitreous structure might in turn stimulate vessel growth and fibrosis Clearly, as no single factor is causative or permissive for human diabetic retinopathy, it remains a challenge to determine the combinations of molecules or cells that provide the best therapeutic targets Congruent cellular patterns in the retina might therefore result from sequential reciprocal cellular interactions: neuron-derived PDGF stimulates and patterns astrocyte invasion, which in turn induces VEGF-dependent and cadherin-dependent vascular growth and guidance Consistent with this, fine endothelial filipodia at the tips of growing retinal vessels often extend along processes of underlying astrocytes that secrete VEGF ( Fig. 5b, c ) Diabetic retinopathy Diabetic retinopathy remains the most common cause of vision impairment in working-age adults in the United States and Europe, and retinal neovascularization occurs in up to 20% of patients with diabetes  Disruption of homomeric or heteromeric interactions between endothelial and glial cadherins with function-blocking antisera results in a stunted retinal vasculature, which fails to recapitulate the astrocytic pattern and migrates into the normally avascular outer retina  Ectopic norrin restores retinal vessels in norrin-mutant mice , raising the possibility of a new anti-angiogenic pharmacology for retinopathy of prematurity, which is a major cause of infantile blindness ER stress responses occur as a result of nutrient deprivation, excess lipid accumulation and glucose deficiency, and coordinate the balance between cell survival and death signals; these include regulation of VEGF and PDGF expression at the level of mRNA translation  Experimental retinal angiogenesis correlates with HIF1α levels and is inhibited by adenoviral delivery of the Vhl gene  Extension of the superficial vascular plexus follows in the wake of these waves, suggesting that metabolic demand and attendant ‘physiological hypoxia’ drive vascular growth  First, angiogenesis in isolation or in normal development is different from that in the context of multiple systemic and local disease-related derangements, or in humans with diverse genetic and cultural backgrounds; pathological retinal angiogenesis does not simply recapitulate developmental mechanisms First, pathologic retinal angiogenesis occurs in several diseases that are characterized by retinal ischaemia For example, FLK or VEGF receptor 2 (VEGFR-2) activation elicits migration and lamellipodial protrusion in delta-like-4-positive endothelial tip cells at the leading edge of retinal vascularization, whereas it stimulates proliferation in the more proximal stalk cells ( Fig. 4b–d ) For example, interleukin-1α (IL-1α) is increased, but so is the soluble IL-1 receptor that inhibits IL-1 action, so the net effect is uncertain From these simple observations, early investigators posited that an oxygen-sensitive molecule (termed ‘Factor X’) controls retinal vascular development — an idea based on then recent concepts of morphogen gradients  Guidance strategies among neural and endothelial cells have been recently reviewed  He discovered that capillaries grow profusely when adjacent to nascent venules, and more sparsely around arteries  How do these similar cellular distributions arise? Astrocyte precursors enter the retina through the optic nerve and radiate towards the periphery  However, their role in retinal vascular development, if any, is unknown However, VEGF, HIF, PDGF and other peptide growth factors are also part of a common response to many cellular stresses Hyperoxia improves contrast sensitivity and might improve certain features of diabetic retinopathy , but pre-retinal oxygenation is equivalent in cats and dogs with less than 1 year of diabetes versus controls  If astrocytes serve as a template for growing vessels, what guides the astrocytes? One factor might be the pre-existing radially orientated axon bundles of ganglion cells, which are the retinal output neurons that project through the optic nerve to visual centres of the brain ( Fig. 1a, b ) If so, the abnormal location and orientation of pathological retinal neovessels partly represents the application of guidance mechanisms to an already altered (diseased) environment If the stress persists, as in diabetes, the compensatory response might predominate and contribute to the clinical picture of diabetic retinopathy, including neovascularization and oedema due to vascular leakage If the teleologic goal of the organism is to maintain neuron-dependent vision in the presence of injury, then the neovascular lesions could partly compensate for metabolic derangements in neural retina Immune cells entering the eye from the circulation also participate in remodelling of the nascent retinal vasculature In addition to direct effects on vascular cells, inflammatory mediators probably also modify the structure of the vitreous gel that fills the bulk of the eye In addition, defective lipoprotein receptor-related protein 5 is associated with similar retinal vascular defects in mice  In addition, vascularized and avascular compartments are strictly segregated in the retina; this feature is strikingly depicted in the human central retina, or fovea, which is entirely devoid of vessels ( Fig. 1f ) In contrast to the finely graded cellular interactions during development, astrocytic responsiveness to experimentally induced hypoxia is exaggerated, and leads to degeneration and focal disruptions of the glial ensheathment surrounding retinal blood vessels  In particular, during late embryogenesis, centrifugal waves of differentiation and proliferation, and subsequently of synaptic connectivity and electrical activity, begin in the central retina and spread peripherally In particular, in mice expressing only VEGF120, vascular coverage of the retina and arteriolar differentiation are impaired, whereas mice expressing VEGF188 have normal veins but aborted arteriolar specification (VEGF164/164 retinas appear normal) In patients and animals with VHL disease, pVHL mutations might dissociate HIF-induced genetic responses from tissue oxygen, allowing angiogenesis unchecked by oxygen  In recent years, substantial progress has been made towards the twin goals of retinal vascular research: determining mechanisms that induce and pattern the retinal vascular system, and dissecting disease processes that lead to its disintegration In these mice, superficial and deeper retinal blood vessels form as expected, but then ectopic sprouting of small angiomatous growths invades the normally avascular outer retina  In this disease of prematurely born infants receiving oxygen therapy, vascularization fails to reach the retinal periphery ( Fig. 2d ) In this review, we highlight advances in these complementary realms Ingrowth of vessels, perhaps by raising tissue oxygen tension, then promotes astrocytic maturation, as indicated by changes in glial morphology and gene expression Interactions between endothelial and glial processes depend on the cell surface-adhesion molecule R-cadherin Interactions between R-cadherin on marrow-derived precursor cells and retinal cell-surface cadherins are required to target these cells to developing retinal blood vessels , reminiscent of R-cadherin-mediated linkage of retinal vessels to an astrocytic template during normal development  Interestingly, mice deficient in frizzled -4 have retinal vascular defects similar to those seen in norrin mutants, and frizzled -4 mutations occur in patients with familial exudative vitreoretinopathy , which is an autosomal disorder characterized by incomplete peripheral retinal vascularization ( Fig. 2c ) Interestingly, remodelling occurs in perinatal retinal explants, so additional mechanisms of vessel retraction must exist that are independent of systemically supplied oxygen or immune cells  Interestingly, these cells can restore lost capillaries and reduce neuronal loss in a mouse model of retinal vascular and neuronal degeneration  Intraretinal neovascularization in VLDLR-mutant mice resembles that seen in a subset of patients with age-related macular degeneration, in which angiomatous branching from inner retinal vessels extends into the outer retina and subretinal space Investigators have described cystic spaces within the superficial retina, through which vessels and astrocytes migrate during development  Is the retina really hypoxic in diabetes? Given the fundamental roles of blood vessels in supplying nutrients (oxygen, amino acids, glucose and fatty acids) and removing waste products, which tissue abnormalities might pathological retinal angiogenesis attempt to compensate? Most studies have emphasized the role of hypoxia, because clinical retinal angiography shows non-perfused capillaries ( Fig. 2 ); however, the direct empirical evidence for reduced retinal oxygen tension in human diabetic retinopathy is surprisingly limited It is conceivable that endothelial cells and astrocytes behave in the retina as they do ex vivo , generating vascular and glial networks along tension tracks formed as they migrate within, and attach to, this hypocellular and protein-rich compartment It is the ocular equivalent of lower-extremity amputation and, so far, there is no clinically proven non-surgical alternative It is thought that guidance cues from more cell-bound and matrix-bound VEGF164 and VEGF188 provide a molecular track along which growing retinal vessels appropriately configure It reaches the retinal periphery just before birth in humans, and during the first week of life in mice ( Fig. 3a–c ) It then dimerizes with HIF1β, translocates to the nucleus and binds to hypoxia response elements within the promoters of several genes Loss of pericytes occurs in diabetic retinopathy and other ischaemic retinal conditions, and diabetic-like retinopathy develops in mice with reduced PDGF activity and pericyte coverage of retinal blood vessels  Lowering inspired oxygen in neonatal kittens reduces the rate and density of retinal vascularization  Marrow-derived cells have been shown to associate with adult retinal blood vessels after sublethal radiation and marrow reconstitution, although probably as perivascular glia rather than as endothelial cells ( Fig. 6b ); corresponding studies assessing homing of marrow-derived cells during perinatal retinal vascularization have not been reported Mechanical stress generated by cytoskeletal activity in cultured endothelial cells transmits to underlying matrigel via cell-matrix attachments, resulting in curvilinear deformations in the matrix  Microglia, which are phagocytic dendritic cells with immune functions, co-distribute with retinal blood vessels during development and are activated in ischaemic diseases More than 50 years ago, Michaelson pioneered the use of dye-perfusion techniques to reveal embryonic and perinatal retinal vasculature Moreover, it remains unclear which aspects of the neovascular process are directly related to diabetes, which are non-specific wound-healing changes, which if any are ocular-specific or systemically derived, and how the process might differ in juvenile versus adult-onset diabetic patients Moreover, lipid or carbohydrate mediators that probably play a role have received little attention Moreover, mice in which only a single VEGF isoform is expressed exhibit distinct retinal vascular phenotypes consistent with the notion that each isoform acts across limited, but variable, spatial ranges to create the vascular pattern  Moreover, signals initiated by the same receptor can elicit distinct effects in endothelial cells located at different sites in the growing retinal vasculature Most reports emphasize pro-angiogenic stimuli, whereas the natural inhibitory elements have received little attention Neovascularization develops at these sites and can extend beyond the retinal surface into the vitreous cavity, indicating that astrocytes might stabilize already formed vessels and restrict them to appropriate retinal layers No studies have directly demonstrated reduction of retinal oxygen levels in humans with diabetes compared with controls (E Norries disease is characterized by retinal dysplasia and abnormal retinal vascularization, and mice with targeted disruption of the gene that encodes norrin protein lack deep intraretinal vessels  Norrin acts as a secreted activator of canonical Wnt-β-catenin signalling by binding to frizzled-4 (itself a Wnt receptor), possibly in conjunction with lipoprotein receptor-related proteins (Wnt co-receptors)  Norrin-defective and frizzled-4-defective mice also exhibit cochlear vascular defects , reminiscent of sensorineural hearing loss in Norries disease, whereas mice with mutations in frizzled-5 and lipid phosphatase LPP3 (another regulator of the Wnt/β-catenin pathway) exhibit defective placental vasculogenesis Not surprisingly, at this point, more questions than answers remain, but the field is poised to move forward rapidly Notably, the astrocytic plexus across which vessels grow is also disrupted in VEGF120 mice, indicating that VEGF participates in astrocytic patterning  Novel retinal disease mutations and vascular development Further clues to retinal vascular organization, particularly confinement of blood vessels to inner retinal layers, come from investigations of rare diseases Once established, retinal capillaries adjacent to newly formed arterioles are selectively pruned ( Fig. 3e, f ) One study found reduced retinal oxygen partial pressure in cats with 6–8 years of diabetes  Oxygen-dependent Egl9 enzymes hydroxylate a proline residue on hypoxia-inducible factor 1α (HIF1α), which promotes binding of HIF1α with pVHL Pericyte dysfunction might therefore allow a range of vascular changes, including loss of normally growing vessels (by reduction of VEGF and VEGFR), loss of formed vessels (by reduction of VEGF endothelial survival actions) and abnormal angiogenesis (by removal of the inhibitory effect of TGF-α on endothelial proliferation) Pericytes are smooth-muscle cells that are intimately associated with developing blood vessels; in the retina, they are recruited and differentiated from an unknown precursor cell pool in a PDGFB-dependent manner  Pericytes associated with the advancing front of developing retinal vessels promote vascular growth by secreting VEGF , and by inducing VEGFR-1 in endothelial cells through transforming growth factor-β1 (TGF-β1)  Pericyte–endothelial contact might then stabilize vessels by activation of latent TGF-β (ref. 42 ) Perspectives Several caveats should be considered in developing treatments for retinopathy Presumably, relative hyperoxia surrounding arteries negatively regulates VEGF production, and reduces its actions as an endothelial cell survival factor  Progenitor cells in retinal vascularization A population of lineage-negative cells in the bone marrow mobilizes in response to various stimuli and incorporates into growing blood vessels at sites of ischaemic or other damage Recent studies unify these findings within the Wnt signalling system Recent work shows that all retinal cell types, including neurons, glial, microglial and vascular cells, are affected by diabetes, resulting in a neurovascular disorder  Reduction of VEGF synthesis by astrocytes follows ( Fig. 5d, e ), and provides a local feedback mechanism to limit further vascular growth  Relationships between retinal vascular and neural structures are apparent in the shared radial orientation of blood vessels and ganglion cell axons, and in planar capillary plexuses that align precisely with horizontal neural and astrocytic laminae ( Fig. 1 ) Retinal oxygen saturation decreases in patients with diabetes and no retinopathy, implying a mismatch of supply and consumption  Retinal vascular anatomy, which is highly organized and easily visualized, is central to the attractiveness of the retina as an experimental system Retinal vascularization Retinal vascularization begins in the most superficial (or inner) retinal layers at the optic nerve head, and radiates outwards from this central point Second, anti-VEGF therapies, which are already used to treat ocular neovascularization in age-related macular degeneration, raise concerns for diabetic patients; antagonism of VEGF might interfere with myocardial revascularization in patients who are already at high risk for cardiac ischaemia, for example, and loss of the neurotrophic and vasculotrophic actions of VEGF might exacerbate neuronal loss and ischaemia in diabetic eyes Second, the timing and central-to-peripheral direction of retinal vascularization coincide with developmental processes that presumably determine local oxygen tension Similar configurations of retinal neurons, astrocytes and endothelial cells might result from consecutive operation of these processes within a shared microenvironment Similarly, when injected into the eyes of mice shortly after birth, lineage-negative bone marrow cells incorporate into developing retinal vessels, resulting in a mosaic vasculature comprising native and exogenous cells ( Fig. 6a ) Since the seminal discovery of VEGF accumulation in eyes with diabetic retinal neovascularization , changes in numerous other cytokines, chemokines, adhesion molecules, vasoactive hormones and immune cells have been reported ( Table 1 ) Specific components of Wnt signalling might therefore function at different sites of vascular development (see ref. 50 for a discussion) Stefansson, personal communication) Studies of Tlx -knockout mice show that it is necessary for normal growth and differentiation of retinal glia; astrocytes are less dense and more coarsely distributed in Tlx −/−  retinas than in wild-type retinas, and fail to normally express VEGF and R-cadherin  That is, VEGF could increase initially to provide trophic support to neurons through neuronal VEGFRs ( Fig. 4a ), but at the cost of increased vascular permeability The ability to visualize site-specific and stage-specific expression of stem cell markers might resolve this issue The current treatment was first introduced in the 1950s, but the fundamental approach of ablating the peripheral retina has changed little over the past five decades The diabetes epidemic demands more effective and less expensive biologically based treatments for proliferative diabetic retinopathy The endoplasmic reticulum (ER) stress response is a potent reaction to a variety of cellular injuries, including viral infection, growth factor and nutrient deprivation, and hypoxia, which are associated with cell death and vascular responses The evidence for retinal tissue hypoxia in animal models is based largely on the findings of overexpression of peptide growth factors that are regulated by HIF, and retinal HIF activity is increased in diabetic rats  The factors listed in Table 1 undoubtedly act at different stages of the inflammatory/anti-inflammatory process, or relate more to fibrotic processes that occur in diabetic eyes The genetic response to HIF coordinates metabolic and vascular events — including angiogenesis — that generally improve fitness in the face of low oxygen concentrations The interplay between VEGF and other angiogenic and angio-inhibitory factors provides further opportunity to generate complex vascular networks  The meshwork pattern of matrix-tension tracks in vitro is similar to that of growing retinal vessels and their filipodia The more highly diffusible VEGF120 fails to provide such spatial information, resulting in reduced vessel branching  The non-perfused peripheral retina becomes hypoxic and neovascularization can ensue, with complications of haemorrhage, fibrosis and loss of vision The retina therefore provides a model neurovascular system, attracting the interest of both developmental biologists and clinicians The retinal neurovascular degeneration of diabetes includes neuronal and vascular cell apoptosis , and microglial and glial cell activation, which provides intraretinal sources of cytokines and chemokines  The study of diabetic retinopathy and other retinal disorders opens new lines of angiogenesis inquiry, and developmental retinal angiogenesis models are crucial for investigating neurovascular relationships and bringing anti-angiogenic therapies to patients The VHL protein (pVHL) is a tumour suppressor and functions within an oxygen-sensing pathway The vitreous levels of growth factors are instructive, but full understanding of the biological activities of receptors, signalling pathways and interactions is needed to achieve a complete understanding of neovascular retinopathy Therefore, a single growth factor sculpts the developing retinal vasculature in several ways, including spatiotemporal changes in VEGF and VEGFR distribution, differential effects of VEGF isoforms, distinct spatial range of action and guidance functions of VEGF isoforms, and alternate transduction of VEGFR activation on different endothelial cells Therefore, regardless of whether it is due to true tissue hypoxia or, perhaps, neural retinal sensing of cellular ‘malnourishment’ owing to various metabolic aspects of diabetes, ER stress might be a reasonable candidate to help explain certain features of neovascular diabetic retinopathy Therefore, whereas both astrocytes and pericytes promote normal vascularization, glial degeneration and pericyte loss are permissive conditions for pathological angiogenesis in ischaemic retina  Therefore, while substantial indirect evidence argues for retinal hypoxia, current data do not establish a causal relationship between retinal hypoxia due to capillary occlusion and retinal neovascularization in diabetes These complementary approaches have led us from initial theories emphasizing oxygen as a primary determinant of retinal angiogenesis to a large and growing field that explores metabolic, immune, glial, neuronal, gene expression, and perivascular and progenitor cell factors and gives hope to those who suffer from blinding angiogenic diseases. These receptors mediate discrete functions, such as proliferation, migration, guidance, survival and permeability, so that within areas of VEGF expression in the developing retina, its actions might be delimited by the emergence of receptors, as well as by ligand availability and subtype These tension lines seem to function as ‘tracks’ along which endothelial cells then migrate Third, the expression of several angiogenic and angioinhibitory factors is oxygen dependent Third, therapies that address the multifactorial nature of retinopathy will probably be more successful than single-molecule-specific approaches This perspective suggests that in conditions such as diabetic retinopathy, neuronal, glial and pericyte damage might precede ischaemia and angiogenesis, and reflect an underlying pathological process with broad cellular effects (see below) This remodelling correlates with reduced VEGF messenger RNA (mRNA) production and endothelial cell apoptosis in these areas This surgical therapy, while effective in reducing the risk of severe vision loss, is only applied after the onset of neovascularization, does not address the basic biological abnormality that leads to this complication, reduces peripheral and night vision, and is uncomfortable and expensive Three lines of evidence bolstered the idea that oxygen regulates blood vessel growth in the retina TNF-α, endothelin and insulin-like growth factors are increased in plasma, and accumulate in the vitreous cavity as a result of blood–retinal barrier breakdown; therefore, systemic inflammation clearly contributes to the ocular disease Together, these changes constitute a complex inflammatory process that results in an aberrant wound-healing response Under hypoxic conditions, prolyl hydroxylation fails and HIF1α is spared Unfortunately, it is difficult to study this problem because the retina cannot be biopsied in humans to provide tissue samples for analysis, and animal models of diabetes do not develop neovascularization; therefore, inferences extrapolated from retinopathy of prematurity and retinal vein-occlusion models might not accurately predict responses in a chronic human disease Vascular endothelial growth factor (VEGF) is a hypoxia-inducible cytokine that is strongly implicated as the elusive Factor X by virtue of its absolute requirement for retinal vascularization, and its expression in spatial and temporal conjunction with developing retinal blood vessels ( Fig. 4 ) Vascularization subsequently follows along the pre-existing astrocytic meshwork ( Fig. 5a ), suggesting a template function for glial fibres  Vasculogenesis, in which vessels form by concatenation of vascular precursor cells into solid cords that then lumenize, might contribute to growth of the superficial plexus, but definitive evidence for this is lacking  VEGF and its receptors are expressed in a non-overlapping manner during retinal vascularization, providing additional mechanisms for vascular patterning VHL dysfunction appears to be an important step in the growth of angiogenic tumours VLDLR interacts with reelin and apolipoprotein E to guide neurons to their proper cortical laminae during brain development , and it is tempting to speculate that it has a corresponding guidance function for retinal vessels  When injected systemically into adult mice, these cells incorporate into experimentally induced retinal and choroidal neovascularization  Wnt-mediated processes might also relate to observations suggesting that, in humans, vasculogenic growth occurs in the central superficial retina, whereas angiogenic sprouting vascularizes the peripheral and deeper retina (see above) 
 At his lab, she was able to pursue her interests in maths and biology, and to combine theory with experiment But Nowak, who runs Harvard Universitys recently established Program for Evolutionary Dynamics, suggested she do a PhD with him But with the simulations, experiments and data analysis, its very much a team effort Charles got us in contact with Tim Hughes in Australia, who had access to clinical samples Contributing author When Franziska Michor heard about Martin Nowaks plans to apply mathematical modelling techniques to cancer, her interest was piqued Here, Michor talks about how she got involved with the research and about the challenges of the field How did you and Nowak collect your collaborators? Lots of connections and lots of luck How difficult was it to make the decision to pursue mathematical biology? When Martin suggested I do a PhD at Harvard, my undergraduate adviser at the Research Institute of Molecular Pathology in Vienna — Kim Nasmyth — said the time wasnt ripe for maths in biology Its always good to go into the forest and hope to be inspired. Its the best field to be in Michor had done undergraduate work in both molecular biology and maths, and originally planned to pursue experimental work in cancer genetics Most recently, Michor was elected to be a Harvard junior fellow Nowak and Michor gathered a team together and modelled the resistance of cells to chemotherapy in leukaemia People expect you to be brilliant in maths and brilliant in biology — and thats not possible Since then, hes invited me back to talk about my work Then he referred us to Charles Sawyers at the University of California, Los Angeles, an expert in this kind of cancer They showed that a small subset of leukaemia cells — cancerous stem cells — determine the dynamics of treatment ( Nature 435 , 1267 – 1270 ; 2005 ) What do you do to relax? I ride Icelandic horses What is it like to be a molecular biologist working with both mathematicians and clinicians? Its not easy, because they use completely different kinds of language When I met Martin, he was working with Bert Vogelstein at Johns Hopkins University in Baltimore; Bert told Martin to work with a particular type of leukaemia Would you encourage other young scientists to do mathematical biology? Yes, definitely
 But the new Kansas rules are far bolder, says Scott But these topics were reinstated into the high-school syllabus after activists from science and business communities helped elect more moderate members to the board in 2000 (see Nature 406 , 552 ; 2000 10.1038/35020725 ) In 1999, the board voted to remove evolution, cosmology and geology from Kansass curriculum, leaving teachers to decide individually whether or how to teach the subjects In 2002, Ohio passed education standards that mandate teaching that scientists “continue to investigate and critically analyse aspects of evolutionary theory” Now, a newly elected, more conservative board is seeking to augment the evolution curriculum with criticisms of Darwins theory commonly espoused by the intelligent-design movement Science advocates fear that the move paves the way for ‘intelligent design’ — the idea that an intelligent creator shaped living things — to reach the classroom. “This is a religiously motivated strategy,” says Harry McDonald, president of Kansas Citizens for Science in Olathe, which vehemently opposes the new standards. “Religious advocates have decided that they can push their views forward by casting doubt on science.”  The Kansas Board of Educations chairman Steve Abrams, who helped write the amendments, dismisses the charges as “baloney”. “Is it wrong to teach critical analysis and critical thinking?” he asks She believes that the standards are part of a new nationwide strategy by intelligent-design advocates to undermine the way evolution is taught in public schools The board will now send the new standards out for an external review, with a final vote scheduled for later this autumn. The criticisms include gaps in the fossil record and the inability of evolution to explain the first life on Earth The Kansas State Board of Education has decided by six votes to four to include stronger criticism of evolution in its high-school biology curriculum The standards also refer to macroevolution as a “controversial” theory. “These standards are very clearly denigrating evolution,” says Eugenie Scott, executive director of the National Center for Science Education in Oakland, California This is the second time that the board has tried to alter the states standards for the teaching of science
 At early time points, discrete RecA clusters are seen, permitting analysis of single-filament growth from individual nuclei Escherichia coli RecA is essential for the repair of DNA double-strand breaks by homologous recombination  Formation of nascent RecA filaments is independent of ATP hydrolysis but is dependent on the type of nucleotide cofactor and the RecA concentration, suggesting that nucleation involves binding of ∼4–5 ATP–RecA monomers to DNA Growth is bidirectional and, in contrast to nucleation, independent of nucleotide cofactor, suggesting addition of ∼2–7 monomers s -1  Here we report the direct observation of filament assembly on individual double-stranded DNA molecules using fluorescently modified RecA However, many aspects of this process remain unclear, including the rates of nucleation and growth and the involvement of ATP hydrolysis, largely because visualization at the single-filament level is lacking Individual RecA filaments grow at rates of 3–10 nm s -1  Previous studies have indicated a mechanism of filament assembly whereby slow nucleation of RecA protein on DNA is followed by rapid growth  Repair requires the formation of a RecA nucleoprotein filament The nucleoprotein filaments saturate the DNA and extend it ∼1.6-fold These results are in accord with extensive genetic and biochemical studies, and indicate that assembly in vivo is controlled at the nucleation step We anticipate that our approach and conclusions can be extended to the related eukaryotic counterpart, Rad51 (see ref. ), and to regulation by assembly mediators . A three-channel flow cell 4.5 mm wide and 70 μm deep generated three 1.5-mm laminar flow paths Analysis is described in Supplementary Information Bacteriophage λ DNA, ligated to a 3′-biotinylated oligonucleotide complementary to cosL , was attached to a streptavidin-coated 1-μm polystyrene bead (Bangs Laboratories) Finally, after the indicated incubation time in the third channel, the bead–DNA–RecA complex was moved back into the observation channel Illumination was with a mercury lamp and the fluorescence was observed using an FITC filter (Chroma Technology Corp., number 41001) In 5 mM Mg(OAc) 2 , YOYO-1 dissociated from the DNA after several minutes Methods Visualization of RecA nucleoprotein filaments The experimental protocol was similar to that reported previously  The bead–DNA complex in 20 mM Tris-OAc (pH 8.2), 20% sucrose and 30 mM dithiothreitol (DTT), containing 10–20 nM YOYO-1, was trapped at a linear flow rate of 100–130 μm s -1 at 25 °C for nucleation experiments, or 37 °C for growth experiments The bead–λ DNA complex was then moved to the third channel (RecA channel) containing fluorescent RecA (see Supplementary Information ) in 20 mM MES (pH 6.2), 20% sucrose, 30 mM DTT, plus the indicated concentration of NaCl, Mg(OAc) 2 , CaCl 2 , ATP-γS or ATP The presence of YOYO-1 in this protocol had no effect on RecA nucleoprotein filament properties, because its omission did not change nucleation frequency The trapped bead–λ DNA complex was then moved to the second, observation, channel containing 20 mM Tris-OAc (pH 8.2), 20% sucrose, 30 mM DTT, 0.2 mg ml -1 catalase, 0.4 mg ml -1 glucose oxidase, 4.5 mg ml -1 glucose, 5 mM Mg(OAc) 2 , and the indicated concentration of NaCl, ATP or CaCl 2 ; for experiments with CaCl 2 in the observation channel, the scavengers and Mg(OAc) 2 were omitted The YOYO-1 dye allowed measurement of DNA length and verification that a single DNA molecule was captured A cluster that formed with ATP in the middle of the DNA molecule grew with a strong unidirectional bias ( Supplementary Fig. 13 ); however, we found ATP–nucleoprotein filaments that clearly grew in both directions ( Fig. 4a and Supplementary Fig. 13 ) A flow cell is used to generate three separate laminar flow channels ( Fig. 1a ) A pronounced nonlinear dependence on RecA concentration is evident After incubation in the RecA channel for 5 min in the presence of ATP-γS, a complete RecA nucleoprotein filament is visible in the observation channel ( Fig. 1b , panel 3) After incubation to allow for the formation of a RecA filament, the trapped DNA is moved back into the observation channel where the bound fluorescent RecA is visualized directly Also, the nucleation rate is profoundly sensitive to the free RecA concentration, suggesting that 4–5 RecA molecules are required to generate a stable cluster on DNA that is extended in the growth phase Alternatively, when the RecA clusters are stabilized by ATP-γS, addition of ATP–RecA to the filament occurs on clusters that are heterogeneous with respect to the bound nucleotide (ATP-γS) ( Fig. 3c , blue triangle) Although ATP-γS–RecA clusters are stable for long times in the observation channel, filaments formed with ATP completely dissociated in ∼6 min after a lag of ∼10–20 s (our own unpublished observations) Although Ca 2+ decreases the rate of nucleation, the same ∼5-fold difference in rate is maintained when ATP-γS replaces ATP ( Fig. 2b ) Although neither involves ATP hydrolysis, nucleation is affected by the chemical nature of the nucleotide cofactor, whereas growth is insensitive to the nature of the nucleoside triphosphate bound to either the filament or to the free RecA Although our protocol does not permit the monitoring of RecA filament formation in real time due to the high background fluorescence in the RecA channel, snapshots of filament formation on the same DNA molecule can be obtained by incubating the DNA in the RecA channel for a short time (dipping), and then moving the DNA to the observation channel Although our results cannot determine whether growth occurs by addition of RecA monomers, if we assume the simplest case of growth by monomer addition, then growth occurs at rates of ∼2–7 monomers s -1  Although the kinetically preferred substrate is ssDNA, RecA can form filaments on dsDNA that are active in ‘inverse’ DNA strand exchange with complementary ssDNA  Although the same power dependence is maintained, the entire curve is shifted towards higher RecA concentrations, consistent with the slower nucleation rate of ATP–RecA Although the sample size of these completely isolated clusters is too small to provide meaningful statistics on net polarity of assembly, 19% of the RecA filaments nonetheless assembled bidirectionally with ATP Although we believe that visualization of bidirectional growth reflects RecA addition to each cluster end, we could not completely exclude the possibility that bidirectional growth originated from clusters bound in opposite orientations but too close to distinguish experimentally An individual DNA molecule was dipped for 1 min in the ATP-γS–RecA channel until clusters were detected ( Fig. 3a , 0 min) Assembly of the RecA filament on ssDNA occurs with a net 5′→3′ polarity  At high concentrations of salt, the nucleation frequency is strongly limited and growth from an individual cluster can be monitored via successive incubations in the RecA channel ( Figs 3 and 4 ) ATP hydrolysis is not required for either nucleation or growth, corroborating the proposition that only ATP binding is needed for filament assembly, whereas ATP hydrolysis is needed to facilitate dissociation of RecA either from ssDNA to permit contiguous filament formation or from the heteroduplex DNA product upon completion of DNA strand exchange  Because the affinity of RecA for DNA is greater as a complex with ATP-γS than with ATP , this result also supports the idea that nucleation occurs on the DNA molecule Biotinylated bacteriophage λ DNA, attached to streptavidin-coated beads (1 μm), is optically trapped in the capture channel By controlling nucleation, the assembly of RecA on ‘normal’ cellular ssDNA, such as the lagging strand gaps formed during DNA replication, would be restricted; hence, chromosomal crossovers would be limited Consequently, the optimal conditions for monitoring growth from individual ATP clusters are at different salt concentration regimes Ensemble studies showed that (A+T)-rich duplex DNA stimulates nucleoprotein filament assembly, which was attributed to a rate-limiting nucleation of RecA onto one strand of the dsDNA  Ensemble studies suggest that, despite a net growth in the 5′→3′ direction, growth in the opposite direction is possible  Examples of eight partial filaments formed by dipping in the RecA channel for 1 min are shown in Fig. 1d  Figure 1b (panels 1 and 2) shows a λ DNA molecule in the observation channel before and after dissociation of YOYO-1, respectively Finally, given the similarity between bacterial RecA and its eukaryotic counterpart, Rad51 (See Ref. ), we expect that our approach, results and conclusions regarding the control of filament assembly by nucleation apply to mechanistically related processes such as the control of human RAD51 assembly by BRCA2 and other mediators . From 20 to 80 mM NaCl, the average rate of RecA cluster formation decreased from ∼8 to ∼1 min -1 ( Supplementary Fig. 6 ); given that λ DNA is 48,502 base pairs (bp), the average nucleation frequency ranged from ∼1.6 × 10 -4 to 2 × 10 -5 nuclei min -1  bp -1  Furthermore, even though nucleation was seemingly equally likely along the length of the dsDNA at the lowest NaCl concentration ( Supplementary Fig. 7 ), nucleation occurred more frequently and preferentially at (A+T)-rich regions of the λ DNA when the NaCl concentration was elevated ( Supplementary Figs 8–10 ) Given that RecA makes contact with only one of the strands of the duplex , our findings imply that RecA polymerizes predominantly in the direction imposed by the polarity of the bound ssDNA, with growth in the opposite direction occurring but at a slower rate Given that the persistence lengths of dsDNA and RecA nucleoprotein filaments differ greatly , the observed extension is consistent with the polymorphic ∼1.5-fold increase in dsDNA length reported, and indicates that complete RecA filaments are formed Given the sensitivity of the nucleation phase to solution variables, it is most likely that RecA function is controlled in vivo at the nucleation step of filament assembly However, if the ATP–RecA clusters are moved into an observation channel containing ATP-γS, then they are completely stabilized ( Fig. 2a ) However, the difference might be the consequence of ATP-hydrolysis-induced dissociation However, the rates of addition at 5′- versus 3′-ends are undefined However, the salt dependence of growth rates ( Fig. 3c ) permits a comparison of growth from individual clusters, with either ATP-γS or ATP It is evident that multiple RecA clusters have formed on the dsDNA, showing directly that RecA filaments form from multiple nucleation events Notably, the same dependence ( n  = 4.5 ± 0.5) is observed with ATP ( Fig. 2d ) Notably, the very fact that RecA can extend in the 3′→5′ direction suggests that growth can occur at both ends of the filament , albeit at different rates Of the ∼140 clusters analysed, only 21 could be unequivocally examined for bidirectionality Our analysis of the nucleation and growth phases reveals important differences in these processes Our single-filament observations provide visible evidence that RecA stochastically forms multiple nuclei, which are subsequently extended in the growth phase Our single-filament rates are comparable to model-derived estimates from single-DNA extension studies when those are normalized for the number of nuclei on a DNA molecule ( Supplementary Fig. 11 ) Previous measurements, at different conditions, produced comparable values , but, as shown below, nucleation frequency is strongly influenced by reaction conditions Previous studies indicated that filament assembly involves nucleation of RecA onto DNA followed by elongation ( Supplementary Fig. 1 ), but direct visualization of the time-dependent evolution of an individual RecA nucleoprotein filament has been lacking Recombinational DNA repair involves the formation of a RecA nucleoprotein filament typically on single-stranded DNA (ssDNA) for pairing and exchange with homologous double-stranded DNA (dsDNA)  The affinity of RecA for DNA is highly sensitive to salt concentration , suggesting that nucleation is occurring on the DNA The affinity of RecA for DNA is strongly influenced by the nature of the bound nucleotide cofactor  The average number of clusters formed with ATP-γS or ATP, under otherwise identical experimental conditions, is shown in Fig. 2b  The collinearity of the ATP and ATP-γS rates indicates that the nature of the nucleotide bound to RecA protein has no effect on the elongation phase The data show that the growth rate is the same whether the RecA clusters are stabilized by Ca 2+ -ATP or ATP-γS The difference in nucleation rate cannot be attributed to a different degree of saturation of RecA with ATP or ATP-γS due to differences in affinity, because identical rates are obtained when a fourfold higher concentration of ATP is used ( Fig. 2b , orange diamonds) The distribution of growth rates from individual clusters ( Fig. 3b ) is 3.6 ± 1.1 nm s -1 ( n clusters  = 34) at 100 mM NaCl The effect of RecA concentration on nucleus formation is shown in Fig. 2c  The filament is seen to grow at 3–10 nm s -1  The frequency of RecA nucleation is strongly dependent on salt concentration ( Fig. 1e ) The higher growth rate for clusters that can extend in both directions provides a kinetic argument for bidirectional filament growth  The length of the RecA nucleoprotein filament does not change after 20 min of continued flow in the RecA- and ATP-γS-free observation channel ( Fig. 1b , panel 4), even in the presence of NaCl or ATP ( Supplementary Fig. 5 ), indicating that dissociation of the ATP-γS–RecA–dsDNA complex is negligible The nucleoprotein filament is extended relative to naked dsDNA, consistent with the extension induced by RecA  The rate of cluster formation, determined from the linear increase in nucleation frequency with time, is shown as a function of RecA concentration in Fig. 2d  The rates range from 3 to 10 nm s -1 (∼2–7 monomers s -1 ) and follow a linear dependence on NaCl concentration The size distribution for the relative extension of DNA by RecA ( Fig. 1c ) is approximately gaussian, with an average extension of 1.65 ± 0.05 ( n  = 72) The size of the two clusters in the top panel (0 min) increases linearly with observed rates of 3.3 ± 0.1 and 2.7 ± 0.2 nm s -1  The solid line is the fit according to the relationship k obs  =  c [RecA] n , where n represents the minimum number of RecA molecules involved in the cooperative process and c is a constant  The trapped bead–YOYO-1–DNA complex is then moved into a second channel (the observation channel) under conditions that dissociate the dye from DNA Then, the molecule was repeatedly moved into the RecA channel for a fixed time, and back out to the observation channel to follow growth of the initial clusters ( Fig. 3a , 9 min) These studies established that mutant RecA proteins, which suppress loss of recF function, possess enhanced rates of filament nucleation  This conclusion is in accord with extensive studies that have shown that proteins such as ssDNA-binding protein restrict nucleation , whereas mediator proteins such as RecBCD and RecFOR promote nucleation  This conclusion is in agreement with a previous ensemble study and is consistent with the DNA composition-dependence and nucleotide-dependence presented below This conclusion, together with the increased nucleation frequency in (A+T)-rich regions ( Supplementary Figs 7–10 ), further implies that nucleation occurs on the DNA This dye-free DNA is subsequently moved to a third channel (RecA channel) containing the fluorescently modified RecA This growth can proceed via addition of RecA to both ends of the filament This protein was used to monitor RecA filament formation on dsDNA using the following strategy  This simple analysis suggests that 4–5 RecA molecules are needed to form a stable nucleus This simplistic approach suggests that formation of a stable nucleus on dsDNA requires at least four RecA molecules ( n  = 4 ± 0.4) Thus, ATP hydrolysis is not involved in filament growth Thus, the nucleation frequency is not sensitive to ATP hydrolysis but rather is sensitive to the differences in affinity for DNA that are induced by nucleotide cofactors and metal ions  Thus, this heterogeneous extension experiment shows that both ATP and ATP-γS induce RecA nucleoprotein conformations that are indistinguishable with regard to their capacity to add new RecA molecules To address this issue further, we compared the rate of growth of clusters that formed with either ATP or ATP-γS at the DNA end and which could only grow from one end in one direction (towards the bead), with clusters that formed internally on the same DNA and, hence, could potentially grow from both ends To address this issue, we analysed molecules where cluster growth was not complicated by the presence of additional clusters growing at neighbouring positions To address this point, Ca 2+ was substituted for Mg 2+ in the RecA channel, because Ca 2+ reduces the rate of ATP hydrolysis by 96%  To ensure that the single DNA molecule is at full length, trapping is performed using the fluorescent DNA-binding dye YOYO-1 To visualize RecA filament formation directly, we prepared a fluorescently modified RecA protein that retains all biochemical activity ( Supplementary Figs 2–4 ) We found that the growth rate for single-ended filaments is always lower than or equal to the growth rate for most of the double-ended filaments ( Fig. 4b ) When a 5′ or 3′ ssDNA tail is attached to dsDNA, polymerization onto the dsDNA of 3′-tailed dsDNA is slower than for 5′-tailed dsDNA, suggesting that growth on duplex DNA follows the same net 5′→3′ polarity  When ATP–RecA clusters are stabilized in the observation channel by Ca 2+ ( Supplementary Fig. 12 ), the subsequent addition of ATP–RecA occurs on nascent filaments that are homogeneous with respect to the bound nucleotide When we consider a stoichiometry of 3 bp per RecA monomer and a correction factor of 1.6 due to extension of dsDNA by RecA, the data suggest that filament growth occurs at an apparent rate of ∼2 RecA monomers s -1 under these conditions With ATP, RecA nucleation occurred at a ∼5-fold slower rate than with ATP-γS With ATP-γS, RecA nucleates ∼5-fold faster than with ATP (10.2 ± 0.6 min -1 compared with 1.86 ± 0.06 min -1 ), consistent with previous modelling 
 A question yet to be resolved is how the ‘driving’ ion and the ‘driven’ substrate move through an ion-coupled transporter A widely accepted theory proposes that this can be accomplished using two gates, with only one open at a time, just like the locks in a waterway  Another feature is the unwinding of membrane-spanning domains, which was first observed in the calcium pump  Consequently, chemicals that inhibit these proteins — such as cocaine and Prozac — have profound effects on brain function Crystal structures of various transporters from other families hint that nature has found several solutions to alternating the access of the binding pocket to each side of the membrane In contrast, in GAT-1, another member of the family, the neurotransmitter GABA is transported together with sodium and chloride ions  In LeuT Aa , TM1 and TM6 are antiparallel to each other, and have breaks in their helical structure approximately halfway across the membrane ( Fig. 1 ) In the future, the LeuT Aa structure will be useful in designing drugs that specifically inhibit the neurotransmitter transporters In these cases it seems that the carboxyl group is provided by a unique aspartate residue located on transmembrane domain 1 (TM1) In this structure, the binding pocket is occluded — the external and internal gates are closed Indeed, in LeuT Aa , leucine transport is dependent on sodium but not on chloride  Ion-coupled transporters are essential for all forms of life It reveals not only a completely new protein fold, but also a crystal-clear view of the binding pocket — including the driven substrate and the two driving sodium ions ( Fig. 1 ) It shows that one of the two sodium ions bound in the transporters binding pocket comes into direct contact with the leucine molecule being carried across the membrane Nevertheless, direct contact may not occur in all transporters; for instance, not all the substrates of transporters related to LeuT Aa have carboxyl groups Now Yamashita et al . have resolved the structure of LeuT Aa at exceptionally high resolution for a membrane protein (1.65 Å) Obtaining more ‘snapshot’ structures representing different transporter conformations will shed light on the most fundamental question: which conformational changes occur during the transport cycle? Or, in terms of the ‘lock’ model, how is the opening of the external gate coupled to the closing of the internal one, and vice versa? On page 215 of this issue Yamashita et al . report the crystal structure of a bacterial leucine transporter, the first structure of a member of the large Na + /Cl − -dependent neurotransmitter transporter family One is an internal structural repeat in the LeuT Aa monomer, such that TM1–TM5 and TM6–TM10 can be superimposed on each other by rotation around a pseudo twofold axis located in the plane of the membrane Residues on TM3, TM7 and TM8 also contribute to the binding of sodium and leucine So although the overall structure of the neurotransmitter transporters is expected to be similar to that of LeuT Aa , there will be variations So it seems that, at least in this transporter and presumably in all the amino-acid-transporting members of this protein family, the coupling between the driving ion and the driven substrate is as direct as it could be So the ion and the substrate are transported together — although sometimes in opposite directions — such that the energy released as the ion moves down its gradient is used to power the uphill movement of the substrate Some of the best-known family members function in the central nervous system, where they carry neurotransmitters, the brain chemicals used to signal across the synaptic junctions between neurons Some of these residues had already been implicated in ion and/or substrate binding by functional studies of mutants of several of the neurotransmitter transporters (cited in ref. 1 ) Support for this idea comes from crystal structures of transporters, which invariably show a cavity in the transporter closed off from the aqueous space on either or both sides of the membrane The binding pocket of ion-coupled transporters also has binding sites for the ion that powers the transport process The crystal of LeuT Aa also contains a chloride ion (not shown on the figure), but this is not located in the binding pocket The interface of these repeats forms the binding pocket of the transporter ( Fig. 1 ) The sodium ions in the binding pocket are both close to the leucine, with one of them being in direct contact through the carboxyl group ( Fig. 1 , inset) The structure of the functional unit, the LeuT Aa monomer, shows several features known from other transporter structures The transporters clear neurotransmitters from the synaptic cleft, terminating the signal and priming the neurons for the next one Therefore, it appears that the structure reported by Yamashita et al . is a physiologically relevant conformation of the transporter These breaks expose main-chain carbonyl oxygen and nitrogen atoms for hydrogen bonding and ion binding These molecular machines carry their cargoes across membranes to help accumulate foodstuffs in cells, maintain cellular pH levels and facilitate communication between nerve cells This direct coupling is an ingenious solution to minimizing leaks where the ion and/or the substrate might permeate through the transporter independently This is accomplished using the energy stored in the electrochemical ion gradients that are maintained across cell membranes This mechanism has been proposed previously on the basis of indirect evidence from transporters of other families , and it may turn out to be used by many transporters Transporters generally function by exposing their binding sites alternately to either side of the membrane — catching up their cargo on one side and releasing it on the other Transporters must move their substrates (sugars, amino acids, neurotransmitters, and so on) against sometimes huge concentration gradients Two ion pairs, one between the extracellular ends of TM1 and TM10 and the other between the intracellular ends of TM1 and TM8, contribute to these gates ( Fig. 1 ) Yamashita et al . studied LeuT Aa , a leucine transporter from the bacterium Aquifex aeolicus , which is a member of the family of Na + /Cl − -dependent neurotransmitter transporters 
 A good mentor is able tactfully to point out those habits and then help the person find a way to overcome them As deputy director for science and technology at Lawrence Livermore National Laboratory in California, Murray will now have to discern whats going on in the minds of many scientists As her career progressed, Murray came to understand one of a mentors most important roles. “Some people have a hard time getting out of certain habits,” Murray says At Murray Hill, Murray led a scientific-leadership training programme But at Livermore, she hopes to rally scientists around crucial problems, such as nuclear security Cherry Murray, deputy director, Lawrence Livermore National Laboratory, California Managing scientists is often described as “herding cats”, says physicist Cherry Murray Focusing scientists on common problems like that will be much easier than herding cats. Looking back, Murray realizes that she learned one of her most important career lessons when she was a graduate student at the Massachusetts Institute of Technology: be a good mentor Mildred Dresselhaus, a professor at the institute and someone Murray admired, set up a mentoring series for graduate students, which saw them take turns presenting research seminars Scientists enjoy autonomy and problem solving. “They dont want to be told what to do,” she notes She envisions creating a similar project at her new institution. “At Livermore, Id like to continue to teach management,” she says She supervised a few hundred at Bell Labs; at her new post she will oversee several thousand. “Learning whats going on here is my biggest challenge because its so huge,” she says of Livermore That can be a delicate balancing act, Murray says That provided Murray with a ‘safe’ place to learn how to discuss her research and give talks Thats why she was initially reluctant to pursue her first opportunity to head a team of scientists when it was offered to her at Bell Labs in Murray Hill, New Jersey, almost 20 years ago. (see CV ). “I wasnt expecting to become a manager, but my department head left,” Murray says. “I was having such a great time doing science, but I realized I had an opportunity to make decisions and I thought that was important.” Murrays research focuses on experiments at low temperatures, with an emphasis on light scattering and imaging
 A double mechanism prevents hydrolysis of the thioester group, essential for covalent attachment of activated C3 to target surfaces Activation of component C3 (1,641 residues) is central to the three complement pathways and results in inflammation and elimination of self and non-self targets Here we present crystal structures of native C3 and its final major proteolytic fragment C3c Marked conformational changes in the α-chain, including movement of a critical interaction site through a ring formed by the domains of the β-chain, indicate an unprecedented, conformation-dependent mechanism of activation, regulation and biological function of C3. The mammalian complement system is a phylogenetically ancient cascade system that has a major role in innate and adaptive immunity The structures reveal thirteen domains, nine of which were unpredicted, and suggest that the proteins of the α2-macroglobulin family evolved from a core of eight homologous domains A partial model was built automatically by ARP/wARP  Before crystallization, C3 was solubilized by dialysis against 10 mM Tris, pH 7.4 Both termini in the α-chain, generated by C3dg and C3f removal during plasma storage, displayed heterogeneity as observed by reduced gel and matrix-assisted laser desorption/ionization–time of flight (MALDI–TOF) analysis C3 was concentrated to 8 mg ml -1 and precipitated by dialysis against 5 mM MES, pH 6.0 and stored at -80 °C until use to retain haemolytic activity C3 was crystallized in hanging drops in 6% w/v PEG-monomethyl ether 550 and 100 mM sodium acetate at 20 °C C3 was purified by PEG precipitation, plasminogen depletion (Sepharose 4B- l -lysine), anion-exchange chromatography (DEAE Sephacel) and size-exclusion chromatography (Sepharose CL-6B) C3 was purified from frozen human plasma as described previously , with slight modifications C3 was solved by molecular replacement C3c from outdated human plasma (stored for several weeks at 4 °C) was purified by polyethylene glycol (PEG) precipitation, anion-exchange chromatography (DEAE Sephacel), cation-exchange chromatography (CM-Sephadex C50) and size-exclusion chromatography (Sephacryl 300) C3c was concentrated to 20 mg ml -1 and dialysed against 10 mM Tris pH 7.4, 2 mM EDTA and 2 mM benzamidine Crystallization and data collection C3c was crystallized in hanging drops from mother liquor containing 18% w/v PEG-3000 and 200 mM LiNO 3 at 20 °C Crystals displayed space group P 2 1 2 1 2 ( a = 126.9, b = 246.9, c = 87.4 Å), contained two molecules per asymmetric unit and diffracted to 2.4 Å resolution at ESRF beamline ID14-EH4 Crystals exhibited space group I 222 ( a = 117.0, b = 156.3, c = 271.2 Å) with one molecule per asymmetric unit and diffracted to 3.3 Å resolution at ESRF beamline ID14-EH4 Crystals grew to 100 × 100 × 100 µm within 2 weeks Crystals grew to 300 × 100 × 20 µm within 2 weeks Diffraction data were processed using MOSFLM/CCP4 (ref. 17 ) and Denzo/Scalepack  Diffraction data were processed with XDS and XSCALE  For cryo-protection 20% v/v glycerol was added to the mother liquor, and crystals were flash-cooled in liquid nitrogen Heavy-atom derivatives were prepared by soaking crystals in mother liquor containing 1–5 mM of heavy atom compounds for 24 h at 20 °C However, the α6–α6 barrel structure of C3d (18% of C3) was positioned correctly by Phaser  In addition, crystals showed significant variations in cell dimensions In the end, we used nine partial masks created in RAVE to envelope a single molecule for averaging over six copies of the protein molecule in DMMULTI  Initial positioning of C3c, or any of its fragments, was unsuccessful Methods Protein purification C3c was purified using methods as described previously for C3 (ref. 42 ), with slight modifications Phase combination and extension by multi-crystal and non-crystallographic symmetry averaging were crucial to produce an interpretable electron-density map Similar to C3c, 20% v/v glycerol was added as a cryo-protectant; crystals were flash-cooled in liquid nitrogen Structure determination Twenty mercury sites were found and refined in SOLVE for a HgCl 2 derivative with diffraction data from a MAD experiment at mercury-inflection and high-remote energy Subsequently domains of C3c (C345C, MG2 plus MG6, MG5, MG4, MG8, MG3, MG7 and MG1, respectively) were added step-by-step using both Phaser and molecular graphics in O with rigid-body refinement for positioning in Phaser The final refined model of C3 had R and R free values of 23.6% and 29.5% (see Table 1 ; see also Supplementary Fig. 1 and Supplementary Table 1 ). The glycan moiety on Asn 917 was cleaved off with N -glycosidase F (PNGase F) before crystallization The model of C3c was completed using O and refined using REFMAC to a final R -value of 22.3% ( R free of 27.9%) The resulting electron density was of good quality This yielded an 85% complete model that was completed by model building (of CUB, ANA and loops) and refined in CNS and REFMAC  Trace amounts of IgG and IgA were removed by immune absorption Trace amounts of IgG, IgA, IgM, C5 and factor H were removed by immune absorption Twenty-seven platinum sites were found and refined in SOLVE for a K 2 PtCl 4 derivative from data of a SIRAS experiment at the platinum-peak energy and a data set collected from a native crystal Varying pseudo-B centring was observed between crystals with extinctions for ( h + l ) = odd reflections ranging from 10% to 100% (at 100%, crystals exhibited space group B 22 1 2) A double mechanism protects the thioester The highly reactive thioester (formed by the side chains of Cys 988 and Gln 991) is intact in the structure of C3 Activation of C3 The orientation of the TED domain with the thioester pointing inwards seems to be essential for maintaining the protective TED–MG8 interactions in native C3 Additional cleavages in the α-chain of C3b (generating iC3b) mediated by factor I in association with soluble or membrane-bound co-factors prevent further convertase formation and profoundly alter the function of the protein  All domains together form an irregularly shaped C3 and a disc-shaped C3c that lacks the ANA, CUB and TED domains, with strong dipolar surface-charge distributions ( Supplementary Fig. 4 ) Alternatively, the rearrangements occur in a gradual process yielding different arrangements of each molecule Although fully buried, the thioester and its protective pocket are positioned at the TED–MG8 interface close to the protein surface Although loops of ANA and TED come within ∼10 Å, there are no charged residues that could give long-range electrostatic attractions Amplification of complement activity is achieved by association of surface-bound C3b and pro-enzyme factor B , yielding the short-lived ( t 1/2 ≈ 90 s) C3 convertase C3bBb of the alternative pathway ANA has extensive interactions with MG8 At the other side ANA interacts with MG3 ( Fig. 5a ) and thus bridges interactions between MG8 and MG3 of the stable β-ring Because properdin stabilizes the C3bBb convertase complex, it follows that MG8 exposes this binding site, possibly in a β-α-α configuration and a swung out position as in C3c Because the MG6 insert includes the proC3 processing site, it follows that MG6 is formed by two separate chains in mature C3 C3 (187 kDa) emerged over 700 million years ago and belongs to the α2-macroglobulin (α2M) family C3 interacts with a large number of complement factors (for example, proteases, receptors and regulators) and non-complement proteins (for example, viral and bacterial proteins) via distinct binding sites Cleavage of C3 at Ser 726–Arg 727 removes the ANA domain (which becomes the anaphylatoxin C3a) and yields an activated C3b with an exposed and reactive thioester Cleavage of mature C3 is mediated by enzyme complexes (that is, convertases), and generates the anaphylatoxin C3a (9 kDa) and the major fragment C3b (177 kDa) ( Fig. 1c ) Comparison of C3 with other members of the α2M family ( Fig. 3 ) shows that the MG6 insert encompasses the central variable region, which in α2M contains the bait region  Despite a major rearrangement of the N-terminal region, the α6–α6 fold is conserved between TED and C3d ( Supplementary Fig. 3m ) Domain organization C3 consists of two chains—β (residues 1–645) and α (residues 650–1641) (ref. 20 )—that together form 13 domains, whereas C3c consists of three chains (the β-chain and two fragments of the α-chain) that form ten domains ( Fig. 1a–c ; see also Supplementary Fig. 2 ) Eight domains (5.5 of β and 2.5 of α) exhibit a fibronectin-type-3-like core fold ( Supplementary Fig. 2d, e ); however, no sequence homology is apparent among these domains Finally, residues 1496–1641 form a carboxy-terminal C345C domain with a netrin-like fold First, we determined the structure of C3c purified from outdated human plasma Following this, there is an extended loop (residues 730–745) that connects ANA to MG6 Four acidic residues (Asp 730, Glu 731, Glu 736 and Glu 737) of the α′NT are important in the formation of the C3 convertase  From C3 to C3c the α′NT has moved from its position near ANA, through the β-ring and has emerged on the other side in C3c where it lies on the surface of MG7 Furthermore, this MG8 region harbours a binding site for complement protein properdin  Homologous sequences lacking these elements are not known However, in the structure of C3 no direct contacts are observed between the ANA and TED domains However, the α6–α6 helical structure of C3d (18% of C3, in a protein otherwise rich in β-strands) was positioned correctly by Phaser  Implications for convertase formation and regulation Cleavage of C3 at 726–727 yields a novel N-terminal (that is, α′NT) region in C3b Implications for evolutionary events Intertwining of distant parts of the amino-acid sequence owing to inclusion of a domain into a loop is indicative of a gene insertion event In addition, each chain forms six domains by itself In addition, the extended segment 727–767 (that is, α′NT plus the beginning of MG6 α ) is important for binding of several regulators  In analogy to immunoglobulin domains, we refer to them as macroglobulin (MG) domains In C3 these structural elements are hidden and interact with the ANA and TED domains, whereas in C3c they are fully exposed and have changed conformation into a β-strand and two α-helices In contrast, all sequences contain CUB g -, TED- and CUB f -like elements, the hallmark of α2M family members In native C3 the β-α-β configuration in MG8 is probably important; it contributes to interaction with TED (notably, residues Lys 1409 and the highly conserved Glu 1411) In native C3, acidic residues Asp 730, Glu 731, Glu 736 and Glu 737 are shielded by ANA ( Fig. 5a ), which may explain why factor B cannot bind to native C3 In native C3, movement of His 1104 and Glu 1106 towards the thioester is prevented by the MG8–TED interface, thereby blocking the formation of the free thiolate and acyl-imidazole intermediate In phylogenetically distant (insect and nematode) TEPs this sequence is hypervariable  In the exposed position its β-α-β motif is thought to bind the α2M receptor  In the series of activating and deactivating steps (from C3, C3b, iC3b to C3c), when do these rearrangements occur? How do the rearrangements relate to the binding and functioning of the various regulatory factors and receptors? Possibly, most rearrangements occur upon activation, in which case C3b and iC3b will resemble C3c and differ primarily in unravelling of the CUB domain In the structure of C3 His 1104 and Glu 1106 (situated next to a disordered loop) are far from each other and far away from Gln 991 (11.7 Å distance between Gln 991 Cδ and His 1104 Nɛ; Fig. 4b ), and hence the catalytic site for reaction with hydroxyls is not present In the structure of C3d , expressed in Escherichia coli with a Cys988Ala mutation, His 1104 is only 4.1 Å from Gln 991 in the modelled thioester, and the side chains of His 1104 and Glu 1106 form a hydrogen bond, as would be the case when Glu 1106 stabilizes the acyl-imidazole intermediate ( Fig. 4b ) In this case, the conformational changes are retarded by the presence of the anaphylatoxin domain In total, nine out of thirteen domains were unpredicted (MG1–MG7, LNK and CUB) Initial positioning of C3c, or any of its fragments, was unsuccessful Insertion of CUB g /TED/CUB f marks the emergence of the α2M family in host protection, and additional insertion of LNK/RRRR/ANA/α′NT and extension with C345C marks the emergence of the complement system in the innate immune defence more than 700 million years ago  It is shielded from reacting with water ( t 1/2 6 days) or other small nucleophiles by a hydrophobic/aromatic pocket formed by residues Met 1378, Tyr 1425 and Tyr 1460 from MG8 and Phe 1047 from the TED ( Fig. 4a ) Its main functions include host defence against microorganisms, elimination of immune complexes and apoptotic cells, and facilitating adaptive immune responses  Its members, such as the complement factors C3, C4 and C5, the proteinase inhibitor α2M and the insect and nematode thioester-containing proteins (TEPs), have important roles in the immune response in metazoans, considerably pre-dating the emergence of immunoglobulins  Loop 727–745 forms the N-terminal region of the cleaved α-chain, denoted α′, in C3b; we refer to this loop as α′NT MG6 α is followed by a seventh MG domain, MG7 (residues 807–911) MG6 β/α has an insert of 165 residues in loop βC–βC′ and CUB g/f has an insert of 307 residues in loop β5–β6 MG7 and MG8 almost swap places in the overall structure: they rotate and translate by 35° and 7.8 Å, and 62° and 24 Å, respectively MG8 corresponds to the receptor-binding domain in α2M; as expected, the structure of MG8 is homologous to this domain ( Supplementary Fig. 3p ) MG8 undergoes a conformational and a huge positional change from C3 to C3c ( Fig. 2 ) Moreover, we hypothesize that the CUB domain itself is a putative insert into the linker between MG7 and MG8 (and hence the obvious signal of a domain formed by distant parts of the sequence is lacking) Most surprisingly, the α′NT region (residues 727–744) resides on opposite sides in C3 and C3c ( Fig. 5b ) Nascent C3b is able to bind covalently to cell and other target surfaces via the exposed thioester  Notably, critical C3 elements such as the thioester, the anaphylatoxin and the proteolytic cleavage sites lie within these putative inserts Overall, the structural differences between C3 and C3c suggest that the β-ring forms a relatively stable molecular platform for the structurally adaptable α-chain to undergo induced conformational changes Possibly, the rotation of TED is linked to the formation of the free thiolate and acyl-imidazole intermediate that requires ∼15 Å movements in the N-terminal α0–α1 region to establish an active conformation for attachment to a target surface ( Fig. 4b ) Reduced exchange rates for segment 1108–1123 correlate with the disorder–order transition in loop 1107–1112 of C3 versus C3d Residues 1–534 form five MG domains, MG1–MG5 ( Supplementary Fig. 3 ) Residues 535–577 form one half, denoted MG6 β , of the β/α intertwined MG6 domain Residues 578–645 of the β-chain exit from MG6 Residues 746–806 form MG6 α , which complements MG6 β in the formation of MG6 Residues 912–962 and 1269–1330, 63% of C3g and all of C3f, together form one domain that displays a CUB fold; we refer to the two separate parts as CUB g and CUB f , respectively ( Fig. 1e ) Rotation of TED around its N- and C-terminal connections to CUB exposes TED with the intact thioester in C3b projected outwards Second, we determined the structure of full-length C3 purified from fresh human plasma Sequence conservation of the hinge 745-FPES-748 that connects α′NT to MG6, and of the bridging loop 205-YVLP-208 of the β-ring ( Supplementary Fig. 5 ), suggests that this remarkable rearrangement may be part of a general mechanism of α2M protein family members Similar, although much slower, conformational changes occur after spontaneous hydrolysis of the thioester in C3, yielding C3(H 2 O) (refs 31 , 32 ) Structure determination of C3c and C3 We determined the structures of human, native C3 (3.3 Å resolution) and its main proteolytic fragment C3c (2.4 Å resolution), which comprises 72% of C3 Subsequently, domains of C3c were added gradually, yielding 85% of the model, which was completed by model building Surprisingly, one domain is formed by parts of both the β- and α-chains TED is buttressed in this position by interactions with MG2, MG8 and CUB ( Fig. 4c ) The altered reactivity is due to a transformation of the thioester into a free thiolate anion, on Cys 988, and formation of an acyl-imidazole intermediate by Gln 991 and His 1104 that is possibly stabilized by Glu 1106 (refs 18 , 36 ) The ANA domain may serve to keep MG8 in a correct position for interaction with TED and, possibly, to induce a conformation of MG8 that enhances interactions with TED The anchor region, with its internal Cys 1484–Cys 1489 disulphide bond, alters its conformation completely, from an α-helix in C3 to a β-hairpin in C3c ( Fig. 2b ; see also Supplementary Figs 2c and 3q ) The C3 and C3c structures facilitate further structural and mutational studies of the activation and regulation of this central component of the complement system, and create new opportunities for drug development, targeting a wide variety of inflammatory diseases that have been associated with complement activation. The C345C swivels 32° and moves 10.1 Å, resulting in a torque motion acting on the anchor region The cleavage sites yielding C3g, C3d and C3f do not coincide fully with domain boundaries The combination of two putative gene insertions and a gene extension of the C-terminal C345C domain implies the existence of a hypothetical ancestral molecule comprised of eight MG domains, which possibly arose by gene duplication events The domain makes a dramatic swing from the interior of the C3 molecule to the exterior in C3c The domains of the α-chain, however, undergo large rearrangements when the molecule is processed from C3 into C3c The final refined models had R and R free values of 22.3 and 27.9% (C3c) and 23.6 and 29.5% (C3); see Methods and Table 1 ; see also Supplementary Fig. 1 and Supplementary Table 1  The first two cleavages release C3f (2 kDa) and the third cleavage in the remaining iC3b liberates C3c (135 kDa) from the target-bound C3dg (40 kDa) fragment  The function of C3 is regulated by conformational changes induced by sequential proteolytic cleavages ( Fig. 1 ) The insert into the CUB domain is the TED domain with the critical thioester group The mammalian complement system mediates inflammation by generating anaphylatoxins to elicit chemotaxis and cell activation, and by promoting phagocytosis, degranulation and cell lysis The MG6 insert forms the linker domain, the processing site 646-RRRR-649 (present in proC3), the anaphylatoxin domain, scissile bond Arg 726–Ser 727 and the α′NT, which contains four acidic residues important for factor B binding to C3b  The observed domain arrangement supports a simple model for exposing the thioester in the activated state of C3 The occluded position in C3 explains why properdin does not bind to native C3 The occurrence of α6–α6 folds in enzymes indicates perhaps that the TED fold existed separately before it was inserted and became a critical component in the proteins of the α2M family The overall shape of the β-ring is well conserved; the only large change in MG1–MG6 and LNK is a 15° rotation and a 4.3 Å (centre of mass) shift of MG3 ( Fig. 2 ; see also Supplementary Table 2 ) The overall structure of C345C is similar to the recent NMR-solution structure of the C345C domain of C5 (ref. 24 ; see also Supplementary Fig. 3r ) The pivotal complement factor C3 is the convergence point for the classical, lectin and alternative pathways of complement activation  The polypeptide chain that is excised by factor I to yield fragments C3dg and C3f is located between MG7 and an eighth MG domain, MG8 (residues 1331–1474) The remaining part of C3g and C3d (residues 963–1268) together form a thioester-containing domain (TED) The removal of ANA, yielding C3b, weakens the interactions between MG8 and TED, thereby allowing TED to swing out of its nestled position The sequences of the MG domains have diverged to an extent whereby there is no longer any detectable sequence homology The striking differences between C3 and C3c concerning the position of the α′NT region and the arrangement of the α-chain domains raise important questions with respect to formation and regulation of convertases The structure of this domain is similar to the crystal structure of C3a (ref. 21 ), although the amino-terminal α-helical region was not resolved in that structure ( Supplementary Fig. 3h ) The structure was solved by single-isomorphous replacement with anomalous scattering (SIRAS) and two-wavelength anomalous dispersion (MAD) phasing but required multi-crystal averaging with nine partial masks to obtain an interpretable map The subsequent scissile bond Arg 726–Ser 727 sits in a surface-exposed, disordered loop (residues 720–729) The α-chain starts with the anaphylatoxin (ANA) domain (residues 650–726), which when cleaved off forms the C3a fragment The α-chain undergoes major domain rearrangements There are marked conformational differences between C3 and C3c Therefore ANA must protect the thioester in native C3 indirectly Therefore, the ANA domain has a critical role in protecting the thioester in native C3 These large (approximately 1,400–1,800 residue) proteins are characterized by homologous sequence features, including a unique thioester motif and a central, highly variable part that is functionally important  These residues are conserved in the α2M family, except for C5, which lacks the thioester moiety They loop downwards and through the ring, forming three helices in an extended configuration and one β-strand that aligns with the first strand of MG1 This domain is covalently linked to MG8 by the polypeptide chain and to MG7 by a disulphide bond (Cys 851–Cys 1491) in what we refer to as an anchor region (residues 1475–1495) This large positional change corresponds well with what is expected for the equivalent receptor-binding domain in α2M, which alters from hidden to exposed upon encapsulating a proteinase in an α2M multimer  This loop lies next to the critical His 1104 and Glu 1106 residues This provides a second, specific protection mechanism of the native protein against hydrolysis by water and explains why the reactive moiety in C3 is more resistant to water and less resistant to reaction with small amino nucleophiles  This simple rotation is supported by recent hydrogen–deuterium exchange data on C3 and C3(H 2 O), which indicate that segments 956–968 and 1027–1036 buried in C3 become exposed in C3(H 2 O) (ref. 39 ) This situation occurs twice in C3 ( Fig. 1d , e ) This step exposes a hidden thioester and multiple cryptic binding sites in C3b for interacting complement proteins  This structural element is wedged in between domains MG1, MG4 and MG5 This swing moves helix α1 and surrounding β-strands by 40–50 Å Three aromatic residues from the third helix and the β-strand of this linker domain, called LNK, form a small hydrophobic core Together the chain of six MG domains forms 1.5 turns of helical coil as in a key ring (see domains of β-chain in Fig. 1c ) Upon activation by the proteolytic cleavage of C3 into C3b, the protein reacts more readily with hydroxyl groups than amino groups  We solved this structure by molecular replacement
 Asthma is a common disease affecting an increasing number of children throughout the world Here we present experimental evidence that bronchoconstriction leads to patchiness in lung ventilation, as well as a computational model that provides interpretation of the experimental data In asthma, pulmonary airways narrow in response to contraction of surrounding smooth muscle The precise nature of functional changes during an acute asthma attack is unclear The tree structure of the pulmonary airways has been linked to complex behaviour in sudden airway narrowing and avalanche-like reopening  These clusters are generated by interaction of short- and long-range feedback mechanisms, which lead to catastrophic shifts similar to those linked to self-organized patchiness in nature  This work might have implications for the treatment of asthma, and might provide a model for studying diseases of other distributed organs. Using positron emission tomography, we observe that bronchoconstricted asthmatics develop regions of poorly ventilated lung Using the computational model we show that, even for uniform smooth muscle activation of a symmetric bronchial tree, the presence of minimal heterogeneity breaks the symmetry and leads to large clusters of poorly ventilated lung units A series of dynamic PET images, consisting of 15 contiguous, 6.5-mm-thick cross-sectional slices covering 10 cm of the chest, was acquired following an intravenous bolus injection of the positron-emitter nitrogen-13 ( 13 NN, where 13 NN is a molecule of N 2 gas in which one atom is 13 N and the other is 14 N) in saline solution  Airway diameters are iteratively adjusted to converge into steady-state values consistent with both the mechanics of the airway walls and the airflow distribution within the tree Airway radius is estimated from those properties and the peak transmural pressure to which the airway wall is exposed during a breath  Airway wall thickness is adjusted to preserve wall volume during constriction while airway length is kept constant  At the end of a two-minute washout period, the subject was asked to take three consecutive deep breaths; PET imaging was then continued for an additional minute Each airway is surrounded by the lung tissue that it feeds For each branch of the tree, airflow and pressure losses are calculated assuming laminar flow and neglecting the effects of gas compression and dynamic airway calibre fluctuations during breathing For the 8,191 tree branches, recursive equations are formulated to relate internal diameter, length, instantaneous luminal pressure and flow to tissue/airway forces during breathing (see Supplementary Methods ) Mechanical properties of the airway wall are derived from the behaviour of activated smooth muscle fibres submitted to periodic stretching  Methods PET imaging of regional ventilation We studied mild and moderate asthmatics during bronchoconstriction provoked by inhalation of sufficient methacholine aerosol to reduce by 20% the volume exhaled during the first second of forced exhalation from a maximally inflated lung Network model of bronchoconstriction We began with twelve generations of a symmetric dichotomous and fully relaxed airway tree with dimensions equal to those from the fourth to the sixteenth generations of the human airway tree  Quantitative analysis of these images involves modelling the local pulmonary 13 NN tracer kinetics to derive topographic ventilation and perfusion data (including sub-resolution heterogeneity), and to form histograms of ventilation distribution  Spatial heterogeneity of ventilation was assessed as a coefficient of variation (c.v. = mean–normalized standard deviation) The exponents ( m ) of these power law relationships were used to estimate the fractal dimension ( D = 1 - m ; refs 15 , 16 ). The properties at variable levels of smooth muscle activation are linearly scaled from the muscles tension–length relationship at maximal activation  The smallest airways of the model correspond to terminal bronchioles that feed 4,096 independent elastic elements residing within a single elastic thorax The solubility of 13 NN in water and blood is low (partition coefficient ∼0.014) The tissue and pressure forces acting on an airway wall are calculated as a function both of tissue mechanical properties and of average expansion of the terminal units subtended by that airway  Thus, upon arrival at the pulmonary capillary bed during a short breath-hold, 13 NN diffuses into the alveolar gas before it washes out of the lungs during breathing ( Supplementary video S3 and S4 ) Tidal (breath) volume into the first branch of the tree is constrained to be constant To simplify the computations, equations are solved for conditions of cyclic breathing with steady inspiratory flow rate and passive exhalation To test whether the spatial distributions within and outside the clusters were consistent with fractal distributions, we plotted ( Fig. 4 ) the c.v. against the length scale used for the measurement ( N = number of units averaged in the measurement of c.v.) Again unlike ecosystems, this feedback is not a function of physical distance, because it affects all the lung units that remain open Airway expansion interdependence would tend to expand airways near a constricted airway, but regional interdependence would tend to reduce expansion of regions near an expanded region Although all branches of the tree up to the terminal bronchioles constrict, both experimental and theoretical evidence suggest that most of the breathing difficulty in asthma is caused by severe constriction of the terminal bronchioles Although the network model is based on the mechanical interdependence in expansion between airways and their surrounding parenchyma , it neglects the interdependence in expansion between neighbouring airways and between neighbouring regions, and it also neglects heterogeneous lung expansion caused by active effort of chest wall muscles Although these ventilation defects could also be formed by clustered groups of constricted terminal bronchioles, magnetic resonance imaging cannot confirm or refute this hypothesis As in the PET images, the distribution of ventilation inside the clusters is bimodal, including all of the poorly ventilated units as well as a second mode of units ventilating at lower levels than those of units outside the cluster (histograms for conditions (1) and (2) are similar to that in Fig. 2b ) As smooth muscle constricts, reducing the airway lumen, the volume of air flowing into the bronchiole is also reduced At low smooth muscle activation, the ventilation displayed by the model is rather uniform, as expected for a virtually uniform tree structure (see Supplementary Video S6 ) Clearly, additional sources of heterogeneity, such as asymmetry by gravity-oriented gradients in lung expansion, should contribute to the preferential clustering of constricted airways in less expanded, gravity-dependent regions of the lung Clustered bronchoconstriction could also limit the effectiveness of inhaled therapeutic drugs for asthma by promoting delivery to regions least in need of medication Consistent with previous magnetic resonance studies, our PET images show large ventilation defects in these bronchoconstricted asthmatics Differences in regional lung expansion, due to the motions of the diaphragm and the ribcage during inhalation, could also help to break symmetry During an asthma attack, inflammation, secretions, and the shortening of muscle fibres around the bronchial walls all cause narrowing of the airways, which obstructs airflow, causes heterogeneous ventilation, impairs gas exchange and makes breathing difficult During inhalation, tethering forces increase, and this tends to expand the imbedded airways Each terminal bronchiole further subdivides six more times into thin walled alveolar ducts and alveoli, where gas exchange between capillary blood and alveolar gas takes place Equivalent model predictions are obtained when the small heterogeneity is added to any other structural or functional parameter of the model For example, constriction of a large airway reduces flow to all the terminal units fed by that airway, causing a reduction in tissue expansion, which promotes constriction in all branches of the tree beyond that point and down to the terminal bronchioles For illustration purposes, the spatial distribution of ventilation is displayed in a colour scale on a 64 × 64 grid of terminal units at the end of a Mandelbrot-like tree ( Fig. 2a ) Furthermore, the model predicts that the degree of peripheral constriction can be substantially reduced by reducing constriction of central airways ( Fig. 4c ), a finding that could provide an explanation for the effectiveness of novel asthma treatments that target the contractility of large airways  High resolution computerized tomographic images taken after a maximal exhalation also show contiguous regions (of similar size) with trapped gas  Histograms of ventilation for units inside these clusters are bimodal ( Fig. 2b ), and include very poorly ventilated units interspersed with normally ventilating units ( Fig. 2a ), similar to those measured inside the ventilation defects of the bronchoconstricted lung How relevant are these results to the real lung, where the bronchial tree is asymmetric in structure and may have heterogeneous smooth muscle reactivity? Symmetry-breaking in the lung has been proposed as a source of heterogeneity in bronchoconstriction  However, dispersed throughout the ventilation defects are units with normal ventilation levels However, magnetic resonance images of asthmatics show the presence of ‘ventilation defects’ much larger in size than expected for independent and randomly distributed constricted terminal bronchioles—a finding interpreted as the result of obstructing large airways However, once smooth muscle activation reaches a critical level, a cluster of poorly ventilated terminal airways forms abruptly and expands in discrete steps, showing rich bifurcation dynamics as smooth muscle activation is further increased ( Supplementary Fig If airway constriction is limited to terminal units (condition (3)) the ventilation in the network model is still bimodal, but the lack of constriction in the rest of the tree prevents spatial clustering ( Fig. 4c ) If severe constriction of large airways were the sole cause of these large ventilation defects, tracer washout and ventilation would have been unimodal (and low) throughout the defects, whereas reopening of a single constricted airway with deep inhalations would have caused uniform enhancement of tracer removal from the defects If we make the analogy between tissue distension in the lung and ‘resource input’ in ecosystems, the regional bistability shown in the lung model would be analogous to the global bistability proposed for ecosystems undergoing catastrophic shifts  In contrast, the effect of adding a small heterogeneity to the airway tree ( Fig. 4a ) is magnified, and ventilation distribution inside the cluster is consistent with a spatially correlated pattern with D ≈ 1.2 In our model, we observe that short-range synergistic feedback is caused by propagation of constriction up and down the tree as a result of airway–tissue interactions that magnify small regional heterogeneities in the tree and contribute to break the symmetry of the system In the absence of airway tree heterogeneity ( Fig. 4b ) or constriction ( Fig. 4c ), the exponents ( m ) of these relationships are consistent with the fractal dimension, D , expected for a purely random distribution ( D = 1 - m ≈ 1.5, ref. 15 ) In the human lung, air is distributed into more than 130,000 terminal bronchioles by 16 generations of a dichotomous bronchial tree In the lungs, airways are embedded in parenchyma and thus their walls are tethered by alveolar septa, forming a network under tension In the network model described here, equivalent tissue, smooth muscle and gas pressure forces are estimated for each branch of a symmetric human bronchial tree model (see Methods) In the same way that patchiness might indicate a propensity towards catastrophic shifts in ecosystems, self-organized clustering in bronchoconstriction might be the prelude to dangerous respiratory failure in asthma. Indeed, delivering bronchodilation medication to well-ventilated regions could redirect even more ventilation to them, further reducing lung expansion of constricted areas and exacerbating ventilation heterogeneity It follows that the imaging data are not consistent with the exclusive constriction of large airways, but could instead be the result of clusters of constricted small airways It is important to note that the bimodality of ventilation inside the ventilation defects is largely the result of heterogeneity at a small scale (at length scales 13 mm), as previously seen in bronchoconstricted sheep  It is thus clear that constriction of the bronchial tree is necessary for the system to show self-organized clustering It is well established that dynamic airway stretch increases mean airway calibre during breathing and that the absence of large periodic stretches promotes constriction  It should be noted that in this network model, constriction of airways takes place at all levels of the tree but is clearly exaggerated in airways leading to a cluster, and it is highest in those terminal bronchioles leading to poorly ventilated terminal units ( Supplementary Fig Local bistable behaviour and short-range to long-range competing interactions result in the patchy self-organization postulated to precede catastrophic shifts in ecosystems  Long-range competitive feedback in the lung is caused by airflow redistribution away from constricting regions, which increases expanding tissue forces and promotes bronchial dilatation in the rest of the lung, thus protecting it from catastrophic closure Lung units outside the defects have, on average, higher ventilation than units inside the defects, and contain only a small fraction of the lung units with very low ventilation Model simulations involve uniform activation of smooth muscle throughout the airway tree, while tidal (breathing) volume and frequency are kept constant until a steady state is reached More advanced models are required to assess the quantitative relevance of these effects Nonetheless, the effect of the interaction between this distance-independent competitive feedback and the short-range synergistic feedback, as in ecosystems, is to promote the formation of clusters, which show catastrophic (stepwise) increases in size as tidal volume is reduced ( Fig. 3 ) and/or as smooth muscle activation is increased ( Supplementary Video S6 ) Note that unlike in ecosystems, this feedback does not depend on an absolute distance between lung units, but instead relies on a functional proximity through the airway tree (adjacent units on opposite sides of the centre line of the model are far apart because they only share the largest airway of the model) One might expect that constriction of these small airways, if independent and randomly distributed, should present a diffuse pattern of ventilation impairment throughout the lungs Our network model and imaging data suggest that analogous mechanisms are involved in bronchoconstricted asthmatic lungs PET imaging also shows that deep inhalations enhance non-uniform tracer removal from localized regions inside the defects Qualitative magnetic resonance images after a single breath of hyperpolarized helium in mild asthmatics show large ventilation defects (corresponding to hundreds or thousands of terminal units), which reduce in number after administration of a bronchodilator  Quantitative analysis reveals systematic differences between lung units inside and outside the ventilation defects ( Fig. 1c ) Remarkably, for the same level of smooth muscle activation, the fraction of obstructed terminal units under condition (3) (0.08) is substantially less than those observed in conditions (1) (0.34) and (2) (0.35), where constriction of the tree above the terminal bronchioles is allowed S5 ) S7 ) S8 ) S9 ) Similar results are obtained for different seeds that generate random heterogeneity Similarly, slightly higher average constriction of a set of terminal bronchioles fed by a common tree branch reduces average tissue expansion of their common airway, which facilitates its constriction and, consequently, the constriction of other terminal units fed by that common branch Structural or functional heterogeneity in the tree would also explain why the distributions of ventilation inside and outside the clusters seen in the PET imaging studies are broader than those shown in the homogeneous network model Such ventilation defects are usually, but not always, located in gravity-dependent regions of the lung ( Fig. 1a , b and Supplementary Fig The area covered by clusters and the number of poorly ventilated units inside that area are inversely affected by tidal (breathing) volume and are history-dependent ( Fig. 3 and Supplementary Fig The clustered pattern of constriction is not the result of a specific, small random heterogeneity imposed on airway wall thickness The contribution of the branching tree to the ventilation distribution pattern is also revealed by conducting model simulations under three different conditions ( Fig. 4 ): (1) with small heterogeneity and constriction allowed throughout the tree, (2) with constriction allowed throughout the tree but small heterogeneity limited to the terminal units, or (3) with constriction and heterogeneity limited to the terminal units The influence of airway tree structure on the spatial distribution of ventilation also becomes apparent by comparing the spatial pattern of ventilation inside and outside the clusters The model is numerically solved to yield a spatial distribution of ventilation into the trees terminal units during simulated breathing The network model also shows coexistence of ventilated and poorly ventilated terminal units inside a cluster, as well as cluster size reduction with larger tidal volumes The PET images presented here reveal both the presence of a significant number of units with good ventilation inside the ventilation defects, and a reduction in defect size after deep inhalations The relationships between spatial heterogeneity of ventilation (assessed as a coefficient of variation, c.v. = mean–normalized standard deviation) and the length scale ( n ) used for the measurement, obey power laws The simulations also suggest that in severe asthma, when increased respiratory effort and fatigue reduce tidal volume and parenchymal expansion, the remaining open part of the lung will be exposed to catastrophic airway closures—a process that without treatment can rapidly lead to respiratory failure The simulations of this model were conducted while forcing a constant tidal volume into the lung, independent of the constriction level The single terminal airway model describes the local interplay between parenchymal tethering forces, intra- and extra-luminal pressures, and smooth muscle forces on a terminal bronchiole The system is therefore critical in the sense that small variations in its properties create very large effects These mechanisms are also responsible for the regional bistability shown by the model in response to changes in tidal volume, such as the hysteresis in cluster size and location, and in the number of highly constricted terminal units These simulations demonstrate that clusters form only for conditions (1) and (2) This could explain the ineffectiveness of inhaled bronchodilators in some patients, as well as the need to deliver the drug through the vascular system in some cases of severe asthma  This is a reasonable assumption for mild degrees of bronchoconstriction, when the asthmatic is capable of maintaining a normal ventilation level This local interaction yields a multi-valued relationship between driving pressure and airway size that allows two stable states: one where the airway is nearly closed, and airflow, tidal volume and lung tissue tethering forces are greatly reduced, and another state where the airway is kept open by increased lung tissue tethering forces  This lowers the tethering/expanding force, and makes the airway smaller, further decreasing the air flowing into it This value of D falls within the observed range for pulmonary ventilation and perfusion in animals  Thus, the network model provides a functional link between microscopic- and organ-level behaviours that allows comparisons with imaging data beyond those possible with the previously reported single terminal bronchiole model To break the numerical symmetry of this uniform system, we introduce a small random heterogeneity (1% coefficient of variation) to airway wall thickness To elucidate whether clusters of constricted small airways could be consistent with the observed ventilation defects, we used positron emission tomography (PET) to map the topographic distribution of ventilation in bronchoconstricted asthmatics (see Methods) To explore whether the imaging observations could be explained by self-organized clusters of constricted terminal bronchioles, we formulated a network model of ventilation distribution by incorporating into a tree structure a recent model of a single terminal airway  Ventilation histograms for units inside the defects are bimodal and include a substantial fraction ( 0.8) of the very low ventilating units of the lung (units receiving less than 0.5% of the mean lung unit ventilation) Ventilation outside these clusters was virtually uniform and included no units with very low ventilation We conclude that the potential for catastrophic shifts in airway constriction, and the clustered distribution of obstruction, might be involved in sudden and unexplained asthma attacks that are consistently difficult to treat
 Although the focus is on the natural history of the zone, other key issues addressed include radioactive-waste problems, concerns about the various water bodies, and the radiological consequences of the accident Although the rural residents and inhabitants of the major town of Pripyat were evacuated, the exclusion zone is still occupied by many thousands of people And many scientists will be frustrated by the decision not to use references when discussing scientific studies, as there are always some studies of which you are unaware (especially in the Russian-language literature) Chornobyl is actually mugwort, Artemisia vulgaris , not wormwood, which is A. absinthium  Conclusions based on such limited information are inevitably susceptible to criticism For much of the book, Mycio refers to readings of the external dose and to the colours of contamination maps to give an impression of the extent of contamination of each area For scientists with some knowledge of radioecology, however, her attempt to describe some of the issues surrounding radioactive contamination in plain (and sometimes rather colourful!) language has led to a few conclusions being too generalized Her explanations of the basics of radioactivity and the issues relating to the accident and its consequences are mostly sound and easy to understand However, she sometimes refers to single measurements with no indication of the associated error (probably because in many cases it doesnt exist) In Wormwood Forest , Mary Mycio, a journalist with an ethnic Ukrainian background, provides the reader with a vivid impression of what the exclusion zone around the Chernobyl plant is really like It is odd, then, that the book is titled Wormwood Forest and has an associated quote on the cover: “And the name of the star is called wormwood; and the third part of the waters became wormwood; and many men died of the waters because they were made bitter.”  A large part of the book focuses on the wildlife that has flourished in the exclusion zone since the removal of human influence, and describes how the extent of radionuclide contamination varies with species It is very much a personal reflection that successfully debunks many of the more outrageous myths and rumours about the region, and is an interesting and mostly enjoyable read. Many radioecologists might disagree with some of her rather sweeping statements about the importance of processes such as resuspension, fire or the lateral transport of radioactivity Most of them are associated with the continuing activities at the Chernobyl nuclear facilities, but some are rural residents who have returned to live in their previously abandoned villages Mycio describes her encounters with many animals including storks, deer, moose, wild boar and the introduced Przewalskis horses She first visited the zone ten years after the accident, and describes the many people who assisted her on her visits, the local people she met, and the various bureaucratic niceties involved in administering and visiting the zone She often comments on how ‘high’ or ‘low’ the readings are and whether she feels this to be safe or not She uses a similar approach when considering radioactivity in a food product, often referring to the national limits on the number of becquerels used by the Ukrainian and Belarusian authorities Some statements by people quoted in the book seem to be incorrect, although they are at least presented as quotes The author has clearly made a considerable effort to understand the complex social and scientific issues connected with the region and has managed to explain them to the lay reader in a refreshingly clear, yet interesting, style The blend of social comment, personal impressions and science is unusual and makes for an informative read The book starts by correcting a commonly held mistaken impression that Chernobyl takes its name from the Ukrainian word for wormwood, a medicinal herb The Chernobyl nuclear accident in April 1986 was swiftly followed by a large-scale evacuation of an area around the plant, including territory in both Ukraine and Belarus There is great variability in the extent to which different ecosystem components have been contaminated by the dominant long-lived radionuclides radiocaesium, radiostrontium and plutonium, as the author acknowledges These limits are lower than internationally agreed limits and those of many other countries, so it would have been useful to have more information about them to provide context for readers This book is not a key reference source for information on radionuclide contamination of the environment close to the Chernobyl reactor, but then it doesnt claim to be
 Decorations on the bodies of newborns indicate that they were probably important in their community Here we describe two recently discovered infant burials from this period at Krems-Wachtberg in Lower Austria, in which the bodies were covered with red ochre and decorated with ornaments and were therefore probably ritually buried Several adult graves from the Stone Age (Upper Palaeolithic period) have been found but child burials seem to be rare, which has prompted discussion about whether this apparently different treatment of infants could be significant  These findings indicate that even newborns were considered to be full members of these hunter−gatherer communities about 27,000 years ago. A double infant burial was discovered in 2005 (burial 1) and a single infant burial in 2006 (burial 2) Burial 1 was in a 40-cm-long pit and the bodies were overlaid with an adult mammoth scapula, supported by part of a tusk Burial 2 ( Fig. 1b ), located about 1 metre north of burial 1, is of a single individual Each burial was recovered as a block, which was analysed by computer tomography and laser scanning of the surface layers Excavations at Krems-Hundssteig and Krems-Wachtberg (see supplementary information ) have provided detailed information about the spatial organization of these camps From the degree of mineralization of the upper incisors, this infant must have died at 0−3 months after birth In the first campaign at Krems-Wachtberg, an extraordinarily well-preserved living floor, radiocarbon dated at 26,580 ± 160 years before present (specimen Poz-1290) was found It contained items of Gravettian (Upper Palaeolithic) culture, such as lithic artefacts and ornaments, as well as faunal remains, charcoal, ochre and a fired piece of clay bearing a human fingerprint  Moreover, these well-preserved fossils of extremely young individuals will contribute important evidence to the study of the ontogeny of early modern humans. Nothing comparable to these burials of such young Upper Palaeolithic individuals has been found before The auditory ossicles of individual A ( Fig. 1a , bottom) were also recovered The developmental stage of a deciduous incisor of individual B ( Fig. 1a , top) allowed the estimation of the age at death to be perinatal (ninth to tenth lunar month) The equal lengths of both right femora indicate that the newborns were the same age at death; their contemporaneous burial suggests that they were twins The loess sequences around Krems have been of particular interest, with surveys, test trenches and drilling-core analysis yielding insight into settlement patterns between the rivers Danube and Krems The subsidence of the cultural layer above the pits provides evidence that all three infants were buried at the start of the settlement at the site The technology, the structure of the camp, and the evidence of ritual activities (use of red ochre, ornaments and the covering of the twin burial with a mammoth scapula) at Krems-Wachtberg attest to its close affinity with the South Moravian sites Dolní Věstonice and Předmostí  The two skeletons, which were very well preserved, were embedded in red ochre; individual A ( Fig. 1a , bottom) was decorated with more than 30 ivory beads (shown enlarged in Fig. 1c ) The Upper Palaeolithic sites in eastern Austria have been reinvestigated over the past decade They therefore expand the debate about Gravettian ritual(s) and add to the sparse sample of Palaeolithic human remains found so far in Europe 
 A nearly uniform elemental composition shows that the bright dust is distributed globally by winds All these observations could be explained by interaction with acidic water and subsequent evaporation Analysis of six transits implies that the moons positions are within the 10–20-km uncertainty range of astronomical predictions, but further transit observations could improve orbital models And about 1% of soil arguably came from meteorites, resulting in a high abundance of nickel  At the same time, pristine olivine indicates that neither soils nor dust have ever been soaked in water for long periods  Because of the solid-body tides that it raises on Mars, Phobos is losing height and will strike Mars within 40 million years, assuming it remains intact  Before the rovers landed, an array of remote-sensing data was already available, mostly from NASAs recent orbiters sent to Mars But Gusevs interior has turned out to be largely volcanic, strewn with wind-blown dust and basaltic rocks, created by volcanic activity, that have been ejected by impacts But no one imagined that the haematite would exist as blueberry-sized concretions (nodules precipitated from groundwater), or that the concretions would originate within sulphate-rich sedimentary rocks  But only small quantities of transient water are required, not the pools of water thought to have produced sulphate-rich sediments at Meridiani  But the source of the dusts magnetism has remained elusive Deimos, which is smaller and with a much higher orbit, appears only as a dot Dunes and ripples on Mars have been predicted to consist of much coarser particles, 200 µm or more in size, that are driven along the surface — with smaller particles being lofted into suspension by wind turbulence  Early in the mission, one scientist on the Spirit team complained that he felt stuck in a “basalt prison” when he saw the riches available to Opportunity Evidently, the dust is a mixture of basalt and oxidized minerals, but the origin of the latter is unclear Examining the dust morphology would help, but the rovers microscope lacks the magnification to see micrometre-sized dust or its mineral components Fortunately, both spacecraft still descended safely, which for Spirit was critically aided by small rockets that compensated for winds Fortunately, NASAs Phoenix lander, due for launch in 2007, carries both a colour optical microscope and an atomic force microscope that will open up these unseen vistas Golombek et al . assess the accuracy of that information, and conclude that physical characteristics of the martian surface — such as rock abundance, dustiness and topography — were accurately forecast beforehand Greater accuracy in the acceleration rates of both moons would provide better information on the moons futures and histories, as well as on Mars interior (from tidal physics) Haskin et al . now report that rocks at the Spirit site are coated in material enriched in sulphur, oxidized iron, chlorine and bromine ( Fig. 2a ) How the wind interacts with the surface is a topic examined by Sullivan et al .  However, some ripples at Meridiani, inside craters and pits, contain surface sand well below the predicted threshold size Ice deposited in the tropics could form films of low-temperature brines that chemically alter basaltic rocks In a transit, Phobos covers about a quarter of the solar disk In contrast with the predictions for moon transits and landing safety, geological predictions have proved less dependable In contrast, Spirit and Opportunity, NASAs Mars Exploration Rovers, landed successfully on opposite sides of Mars in January 2004, and continue operations today Indeed, the largest gap in our understanding of the martian surface is caused by the absence of comprehensive data on mineral chemistry Indeed, Yen et al . argue this case for the soils generally It is difficult to measure martian atmospheric circulation, but dark and bright streaks downwind from craters indicate wind direction Mars undergoes ice ages that are more extreme than those on Earth: ice migrates from the poles to the tropics as the martian spin axis periodically tips over  Meanwhile, Deimos is drifting away NASAs Mars Science Laboratory, slated for a 2009 or 2011 launch, will have X-ray diffraction capability  Nonetheless, when you look at Mars as a small red speck in the night sky, it seems an incredible feat to land spacecraft on specific parts of it On the basis of compositional analysis of dust captured on magnets, magnetite (Fe 3 O 4 ) is now identified as responsible  Opportunitys site, Meridiani Planum, was correctly predicted to contain abundant haematite (Fe 2 O 3 ; ref. 8 ) Roughly half the spacecraft ever sent have crashed, burnt up or simply missed the planet altogether Salts in the subsurface soil seem to have been separated according to solubility, and the filled cavities and veins of rock interiors are enriched in bromine, an element known to form highly soluble salts Seen from orbit, the crater where Opportunity landed had a bright streak to its southeast Sending probes to Mars is a risky business Six papers in this issue announce new analyses of the scientific data being beamed back to Earth So far, instruments have only measured elemental abundance or partial mineralogy from spectra Spirit landed inside a feature known as Gusev crater ( Fig. 1 ), the aim being to find a dried-up crater lake Sulphur and oxidizing waters have reacted with the basaltic surface, producing sulphates, iron oxides, and presumably a clay or silica component that remains to be characterized Surface observations confirm that the streak derives from bright dust-sized particles, probably deposited from the air during a dust storm The overall picture is that much of the martian surface consists of volcanic soils and that Mars is sulphur-rich, with a geochemistry — like Mars location — lying between that of Earth and of Io, one of Jupiters moons The oxidized iron in the rocks has apparently been extracted from the basaltic mineral olivine [(Mg, Fe) 2 SiO 4 ]; similarly, oxidized iron in soils has been derived from soil olivine  The prediction for average atmospheric density was 8% too high, so parachutes opened late The rovers have been making their own celestial observations, picturing silhouettes of Mars moons as they move across the disk of the Sun  Theory therefore needs revising: near-surface wind turbulence is less effective at suspending particles than predicted  Viewed from the martian tropics, Phobos, the larger moon, rises in the west and scoots across the sky in several hours in a low orbit Where did the soil come from? Some components of the soil ( Fig. 2b ), such as the haematite at Meridiani, are remnants of sedimentary deposits Wind has supplied both rover sites with the major components of bright dust and dark basaltic sand  With definitive mineralogy, we should get answers to such tantalizing questions as how much of the salts come from evaporated seas, from meltwater at the end of ice ages, or — like ancient acid burns — from past reactions of volcanic gases with martian rocks and soils.
 Bead technology is also more scaleable than chromatography columns, although Dynal is concentrating on more analytical or small-scale protein isolation and protein fractionation for different applications in proteomics Dynal has just signed a co-marketing agreement for its Dynabead kits and Tecans Freedom EVO automated platform, and has developed protocols for other platforms such as Beckman Coulters Biomek FX and the KingFisher magnetic separation platform from Thermo Electron of Waltham, Massachusetts. “The main purpose of having magnetic beads is that you can automate the whole process,” says Lars Korsnes, director of research and development at Dynal. “The bead technology has some advantages compared with standard chromatography systems — while its not so easy to put a whole-blood sample into a chromatography column, with magnetic beads you can put the whole sample in.”  Dynabeads, like those from some other suppliers, are superparamagnetic, with no residual magnetism outside an applied magnetic field Magnetic beads have been used for protein separation since the 1980s, but the technology is now being adapted for new proteomic applications and use with automated platforms New owner Invitrogen plans to apply Dynals surface technologies to a wider range of products The beads are also showing promise in the challenging separation of membrane proteins. “There have been some publications where one can bind membrane proteins either before or after lysing the cells,” Korsnes says. “Whether we will develop a special protocol is a question for the future, but the technology is there already.”  Tim Chapman The firm is currently launching a new range of beads with functionalities such as ion-exchange groups, reverse-phase chromatography and hydrophobic chemistries The market leader in paramagnetic beads is Dynal Biotech based in Oslo, Norway, and recently acquired by life-sciences giant Invitrogen in Carlsbad, California They are also uniform in size, shape and surface properties This all helps to prevent the beads clogging up an automated device, Korsnes notes
 A common by-product of RNA replication is the advent of smaller, faster-replicating mutant RNA molecules, which take over the population A further complication is that multicellular organisms consist of building blocks — cells — that are also alive According to the ‘composome’ model, in which micelles or vesicles are formed from amphiphilic compounds — those having one end that is hydrophilic and the other hydrophobic — there is the prospect of constructing a ‘lipid world’ All putative cells, however small, will have a genetic code and a means of transcribing and translating that code An aim in the coming years will be to bridge those gaps — hence the great value of meetings such as this. Approaches to this intriguing problem are discussed in Tibor Gántis The Principles of Life (Oxford Univ Basically, there are two approaches to the ‘minimal cell’: the top-down and the bottom-up Bochum) But living systems are products of evolution, and an answer in very general terms, even if possible, is likely to remain purely phenomenological: going deeper into mechanisms means having to account for the organization of various processes, and such organization has been realized in several different ways by evolution But the idea may prove helpful in attempts to produce more realistic constructions Care should be taken, however, in blindly accepting such a figure Clearly, there is a divide between the top-down and bottom-up approaches, and between theoretical and experimental investigations Eukaryotic cells (such as those from which we are made) are much more complicated than prokaryotes (such as bacteria), and eukaryotes harbour organelles that were once free-living bacteria Even composite systems incorporating gene transcription and translation are now possible in liposomes Even systems missing one or the other component can, of course, advance our understanding Experimental work is increasingly being complemented by computational investigations Following earlier work on liposomes (P For example, although some gene set A and gene set B may not be common to all bacteria, that does not mean that (A and B) are dispensable For example, an artificial stretch of DNA can harbour the gene for T7 RNA polymerase, an enzyme that catalyses the production of RNA from DNA, which in turn induces the expression of green fluorescent protein as an indicator of translation (T For example, it is possible to account for the growth and fission of compartments in simulations of molecular-assembly dynamics (T Given the complexity of this system, it is difficult to believe, either logically or historically, that the simplest living chemical system could have had these components Here, a hereditary component arises from alternative autocatalytic sets of lipids (D Identifying the necessary and sufficient features of life has a long tradition in theoretical biology Igekami, Univ In investigating the origin of life and the simplest possible life forms, one needs to enquire about the composition and working of a minimal cell that has some form of metabolism, genetic replication from a template, and boundary (membrane) production In particular, coupling of compartment formation with some form of template replication (TB) is the subject of many experiments In the future, for example, one would like to see more realistic models of the primordial genome and, conversely, an experimental approach to the lipid world It is difficult to assess the importance of this finding, as there is no example of the particular network modelled It may well mean that (A or B) is essential, because the cell has to solve a problem by using either A or B Kaneko argued that ‘minority control’ is a possible origin of heredity in a bag of genes that constitutes a primordial genome, in that genes with a lower copy number have a more decisive influence on the protocells simulated behaviour Kaneko, Univ Lazcano, Univ Maybe self-association of template and copy strands reduced competition to such an extent that coexistence is guaranteed (G. von Kiedrowksi, Univ Metabolism seems to be the stepchild in the family: what most researchers in the field used to call metabolism is usually a trivial outcome of the fact that both template replication and membrane growth need some material input Mexico) Moya, Univ No such experimental system exists yet; at least one component is always missing On the genetic side, the origin of heredity was demonstrated in a simulated system of cross-catalytic autocatalytic networks (K Only experiments can have the final word on these issues Or perhaps the efficient mutants simply failed to arise owing to the small number of replication cycles (E Osaka; K Press, 2003), and were also debated at a meeting last December *  Remarkably, these approaches converged on the conclusion that genes dealing with RNA biosynthesis are absolutely indispensable in this framework Replication can also happen in liposomes RNA from the phage Qβ (a virus infecting bacteria) can be incorporated in liposomes (T School) Segré, Harvard Med So aiming for a general model of all kinds of living beings would be fruitless; instead, such models have to be tied to particular levels of biological organization Some research to this end takes Buchnera , a symbiotic bacterium that lives inside aphids, as a rewarding example (A Such systems could be called ‘infrabiological’, because they are not quite biological but are similar to living systems in some crucial respects: elementary combinatorics suggests that out of metabolism (M), boundary (B) and template (T) three dual systems can be built — MT, MB, TB Szathmáry) The bottom-up approach aims at constructing artificial chemical supersystems that could be considered alive The snag is, of course, that these systems contain components taken from contemporary cells, and are far from being self-sufficient The top-down approach aims at simplifying existing small organisms, possibly arriving at a minimal genome There was general agreement that a top-down approach will not take us quite to the bottom, to the minimal possible cells in chemical terms This analysis is complemented by an investigation of the duplication and divergence of genes (A This apparently failed to happen in these experiments, but the reason is debatable This input is usually simplified to a conversion reaction from precursors to products This may be linked to the idea of lifes origins in an ‘RNA world’, although such an inference is far from immediate Tokyo) Tokyo) Top-down approaches seem to point to a minimum genome size of slightly more than 200 genes Tsumoto, Mie Univ., Tsu) Valencia) Walde, Univ Yomo) and be replicated by a replicase enzyme provided by the experimenter Yomo, Univ Zurich), protein expression in these entities has become a viable prospect: liposomes are tiny bags with walls made of layers of phospholipids, like the phospholipids that make up cell membranes
 Astrup, A Engl H5N1 preparedness A survey of public-health workers in the United States reveals that more than 40% say they wouldnt show up at work in the event of an influenza pandemic J Med. 354, 1650–1652 (2006) Meteorologists say that storms could not have made the ice N Number Crunch The potential effects on your health of eating chicken nuggets and fries vary depending on the country theyre made in — an effect largely dictated by the cooking oil used, according to a recent survey. 50% of food samples contained levels of trans fatty acids linked to an increased risk of heart disease. 38% was the trans -fatty-acid content of KFC chicken nuggets bought in the Czech Republic, the highest in the survey. newsad; 1% was the trans -fatty-acid content of similar nuggets bought in Spain On the Record “ESA is the only space agency to have science operations under way around four planets: Venus, the Moon, Mars and Saturn.”  David Southwood, director of the European Space Agencys science programmes, gets a bit confused about what constitutes a planet. “It didnt come from a toilet on a plane or anything like that.”  Charles Glass of the Oakland Fire Department in California discusses a mysterious chunk of ice that fell from the sky and left a metre-sized crater in a city park Source: Stender, S., Dyerberg, J Sources: ESA, Associated Press Scorecard Freedom of speech Mark Tushingham, a scientist at Environment Canada, is ordered not to give a public talk about his futuristic novel Hotter Than Hell , in which droughts resulting from global warming cause Canada and the United States to go to war over water resources
 Biol 17, 1521–1530; 2003) Conserv In central Asia, the International Snow Leopard Trust and the Snow Leopard Conservancy provide incentives to local herders for protecting snow leopards In Kenya, a study shows that bomas, traditional corrals with thick walls and internal rooms, are effective at reducing the amount of livestock killed by lions (M In Namibia, the Cheetah Conservation Fund has developed programmes to foster acceptance of this predator, by providing farmland-owners with educational material and encouraging them to take pride in cheetah presence In the eastern Kyrgyz Republic, this has led to the first year with no recorded poaching since the collapse of the Soviet Union O Ogada et al Participating herders in Mongolia, the Kyrgyz Republic and Pakistan agree not to kill snow leopards or their prey, in exchange for access to foreign markets to sell labelled knitwear Ranchers enrolled in the programme can also export beef, certified ‘cheetah friendly’, to the European Union — making cheetah protection both ecologically possible and economically profitable Sir In their plea for bringing Pleistocene wildlife to the New World (“Re-wilding North America”  Nature 436 , 913 – 914 ; 2005 ), Josh Donlan and colleagues do not discuss successful efforts to ensure long-term survival of large carnivores in Africa and Asia The number of cheetahs removed has dropped from 19 to 2.1 per farm per year since 1991 The success of this programme owes much to peer pressure, as the whole community loses the bonus if one person violates the contract These include insurance against damage by carnivores, veterinary care for livestock and income generation from handicrafts This finding has the potential to reduce conflict with humans, which is the main threat to lion survival We believe that these diverse pilot schemes will ensure that large carnivores in Africa and Asia have a good chance of persisting in the wild into the next century.
 A numerical perspective on Nature authors A striking example is the discovery of an erupting submarine volcano, witnessed by de Ronde and his colleagues during the 2004 Ring of Fire expedition to the Mariana arc, and detailed in their paper in Nature this week (see page 494 ) At the Institute of Geological and Nuclear Sciences in New Zealand, Cornel de Ronde leads the offshore minerals programme, conducting research on submarine volcanoes But it can be very rewarding De Ronde spends three to four weeks at sea each year, surveying volcanoes and collecting samples He does 12-hour shifts, often at night in pitching, rolling seas, with lots of noise and little privacy Survey work is tough, he says The field is still in its infancy and, as such, offers its participants the opportunity to witness things never seen before US$600,000 is spent annually by de Rondes volcano research project. 17 authors from the United States, Canada, New Zealand and Japan contributed to the paper describing submarine volcanic activity published in Nature this week. 15 submissions to Nature this year have come from New Zealand (1% of all submissions). 42 days is the longest de Ronde has spent surveying volcanoes at sea.
 A A part of the owls brain known as the optic tectum is arranged to form a map of auditory space, with different neurons responding to sounds coming from different places A team at Fermilabs Tevatron particle accelerator in Batavia, Illinois, studied the quick-switch nature of the B s meson (which is composed of a bottom quark and a strange anti-quark) using a detector known as CDF II to track the decay of the mesons Am Animal Behaviour: Thinking ahead Nature Neurosci. doi:10.1038/nn1781 (2006) Insight into how barn owls (pictured right) track their prey is provided by Eric Knudsen and his colleagues at Stanford University Medical School, California Aphids not only harbour primary bacterial symbionts, which produce essential nutrients, but often also play host to secondary symbionts, which confer fitness benefits As a result, their potential as tools in chemical synthesis has not been fulfilled Atibalentja Int Before studying microbiology I mostly associated bacteria with their negative effects, such as disease Biol. doi:10.1111/j.1420-9101.2006.01216.x (2006) A project in California has unearthed hints that pollinators had a role in the divergence of the local monkey flower ( Mimulus aurantiacus ), which has red blooms near the coast and yellow blooms inland Both findings are described in papers in Cancer Cell  Both types of symbiont are known to be passed to offspring by the mother But the research that most recently caught my eye was carried out in aphids — one of the best-studied model systems for symbiotic interactions between animals and bacteria But this alone cannot explain infection patterns in aphid populations, which suggest an additional mechanism for the transmission of secondary symbionts Cancer Biology: A short-lived recovery J Chem Chem Chemistry: Scent packing J Clin Drug Discovery: Pattern recognition Science 313, 1929–1935 (2006); Cancer Cell doi: 10.1016/j.ccr.2006.09.005 and 10.1016/j.ccr.2006.09.006 (2006) Researchers have compiled a database of drug-associated gene-expression profiles to help in the search for new drugs Dunbar Proc E Each portrait (pictured) is drawn with lines of dots 80 nanometres wide Ecology: Flower arrangement J Ed. 45, 1–4 (2006) Fifty-five thousand pens, all writing at once, have been used to draw the same number of images of Thomas Jefferson in a square centimetre Electrical recordings of the activity of these neurons showed that the stimulus elicited a response in neurons corresponding not to the sounds current location, but to where its source would be about 100 milliseconds later Evol Evol Evolutionary biologists Matthew Streisfeld and Joshua Kohn at the University of California, San Diego, studied the habits of hummingbirds and hawkmoths, which pollinate the flowers Freshwater Res. 56, 125–131; 2005) and a nematode (G Having input their results into a database, they designed software to make it possible to take any new microarray pattern and search the database for similar or opposite patterns In a recent paper, Nancy Moran and Helen Dunbar at the University of Arizona in Tucson solved the riddle In addition, the perfumed molecules deliver higher yields than the stinky versions in a common reaction — the Ugi conversion In owls, it should allow a bird to turn its head to spot the source of a noise — which might become its next meal Instead, the team speculate that this damage triggers sepsis, because gut bacteria leak out Int Invest. 116, 2610–2621 (2006) Some promising cancer therapies work by starving tumours of their blood supply, but what happens after treatment stops? Donald McDonald of the University of California, San Francisco, and his colleagues treated tumours in mice with drugs that inhibit signalling by VEGF, a protein that promotes blood-vessel growth It had been thought that the B. thuringiensis toxin might cause starvation, through damage done to cells lining the insects gut Its creators believe commercial opportunities abound for the method, because it can be easily scaled up J Jo Handelsman of the University of Wisconsin, Madison, and her colleagues found that moths fed antibiotics to sterilize their midguts are immune to B. thuringiensis , implying that the insects natural gut bacteria underpin its potency Journal club Michael Wagner University of Vienna, Austria A microbial ecologist discovers another benefit of sex M Mar Michael Pirrung and Subir Ghorai at the University of California, Riverside, have now synthesized isonitriles with pleasantly fragrant ester groups attached Microbiol. 56, 1697–1702; 2006) Microbiology: A toxins accomplice Proc Moran H My group investigates, among other things, the interactions between amoebae and their bacterial symbionts My interest in such symbioses has since shaped research in my lab Nanotechnology: Sort it out Nature Nanotech. 1, 60–65 (2006) Carbon nanotubes (pictured) can be sorted by size and electronic type thanks to a method developed by chemists in the United States Natl Acad Natl Acad New research suggests that the toxin works by a previously unsuspected mechanism Noel N Particle physics: Predictable flips Preprint at http://arxiv.org/abs/hep-ex/0609040 (2006) High-energy physicists have measured the oscillations of a particle that switches rapidly between matter and antimatter, bringing a 20-year effort to an end Paternal symbiont transfer might be widespread — symbiont cells were recently observed in the sperm of a marine sponge (K Previous work had only managed to set limits on the oscillation rate R Restoring the gut bacteria reversed the effect Sci Sci Scott Armstrong at Childrens Hospital Boston and his colleagues have used it to identify a possible way to counter drug resistance in acute lymphoblastic leukaemia So I was fascinated to learn that many bacteria live in eukaryotes such as humans, increasing the fitness or even securing the survival of their hosts Soc. 128, 11772–11773 (2006) Isonitriles smell almost supernaturally bad, and one scientist has described their odour as “extremely distressing” Syst The authors speculate that the residual basement membrane acts as a scaffold, with new vessels growing through the tracks of the old ones The big draw Angew The database has also been used to reveal how certain compounds work, through similarities between the gene-expression profiles they evoke and those of compounds of known activity The pens are silicon nitride tips attached to cantilevers and fixed side by side into a vast array by Chad Mirkin of Northwestern University in Evanston, Illinois, and his colleagues The process can be repeated to obtain purer samples The researchers added surfactants to separate the tubes by electronic type — sorting those with metallic properties from those that behave like semiconductors The researchers question whether similar synergies exist in some human diseases The researchers say that the inland range of red flowers may increase in future, because the hummingbird population, able to forage year-round in gardens, is thriving The researchers studied how an owl perceives a moving sound, presented through earphones The resulting products, say the labs smelling team, have various mild smells, from old wood to taffy The team proposes expanding the database to feature signatures from cells treated with all approved drugs, and those from cells in which certain genes have been switched off The team suggests this works because a tubes conductivity determines how strongly the surfactants cling to its surface, which, in turn, affects density The technology, developed by Mark Hersams group at Northwestern University in Evanston, Illinois, is based on the centrifuge, in which rapid spinning causes objects of different density to separate These isonitriles retain their useful properties, but lose their stench They calculated that the particle oscillates between matter and antimatter three trillion times per second They found that hummingbirds strongly preferred red flowers to yellow ones, whereas hawkmoths visited yellow flowers more than 99% of the time They observed that secondary symbionts are abundant in the male aphid reproductive system and can stably infect the female during sex (N They used this equipment to perform massively parallel dip-pen nanolithography, in which ink on the tips is transferred to a substrate at nanoscale resolution This concept, reported in Science , has already proved its worth This has a number of possible applications, and its use as a tool to build protein arrays for biological research is being explored This measurement pins down the properties of the particle, and agrees with the predictions of the standard model of particle physics This tissue could be a worthwhile target for future therapies This type of predictive perception has previously been reported in humans Thus, at least for some animals, it seems that sex is not only about reproduction; it is also an opportunity to gain beneficial microorganisms. Todd Golub of the Broad Institute in Cambridge, Massachusetts, and his colleagues used DNA microarrays, which reveal the level of activity of every known gene in a particular tissue, to measure the effects of 164 compounds on human cancer cells Tubes of varying properties tend to be synthesized tangled up together Tumour blood vessels regressed, leaving behind an empty layer of connective tissue known as the basement membrane Unfortunately, only a week after therapy ceased, the tumours had been fully repopulated by active blood vessels USA 103, 12803–12806; 2006) USA doi:10.1073/pnas.0604865103 (2006) Plants engineered to produce the Bacillus thuringiensis toxin kill the insects that feed on them Usher et al
 The Science in Culture “Home from home” ( Nature 441 , 816 ; 2006 ) by Colin Martin should have said that Benjamin Franklin died in Philadelphia, rather than at Passy near Paris.
 A second cause of the row was the Finnish patent offices decision to apply for Patent Cooperation Treaty status, to allow it to conduct searches for those considering filing patents to, for example, the US and Japanese offices And jostling between nations to control the EPO is never far below the surface As is often the case with emerging European institutions, national interests look set to predominate next month, when the members of the convention meet in Munich to discuss whether some of the EPOs growing workload should be distributed to the national offices of its member states At first, the EPO sent some preliminary searches to five national patent offices But behind the EPOs quiet facade, where almost 6,000 patent examiners process tens of thousands of patents each year, conflict is brewing But it proved politically impossible to do so, because the relevant offices were represented on the council. “Everything quickly becomes politicized,” he says. “You can put whatever quality control you want in place — you just cant enforce it.”  The EPO is instead trying to win delegations over to a plan that it hopes will meet concerns that they might lose their expertise But last year, in a move that helped trigger the current dispute, the EPO council decided that its examiners should do both the search and the examination on each application But patent-office watchers are nervous that a move to spread the work could damage patent quality. “Why change a winning team?”, says Christian Stein, chief executive of Ascenion, a Munich-based technology transfer organization in the life sciences that works for some of Germanys best publicly funded laboratories But this arrangement can lead to conflicts of interest for council members, critics say But Wim van der Eijk, EPO head of international relations, charges that those backing decentralization “are trying to reverse history” Decentralizers want more of the action to be devolved, and maintain that their staff can readily match EPO quality EPC signatory countries share the cost of running the EPO and their representatives — who often work for national patent offices — comprise the EPOs administrative council EPO officials claim that quality will suffer: McGinley says that the office would have liked to complain to the administrative council about the quality of searches carried out by two of the five national offices that had earlier shared EPO work Id have thought that outsourcing would be the last thing it needs right now.” In the meantime, users remain bemused. “I see no rationale other than political for splitting the offices work,” says Stein It has substantially succeeded in that aim, and the office is now by far the favoured European venue for patent-seekers from all over the world Its proposed ‘utilization programme’ incorporates things such as training in all aspects of intellectual property, and building computer systems that providse national patent offices with full access to EPO documentation and software, such as that used to do searches London-based patent attorney Richard Jackson of Carpmaels and Ransford, a computing specialist whose customers include University College London, says: “The quality of EPO work is good On the edge Lars Björklund, deputy director-general of the Swedish patent office, argues that countries on the geographical edge of Europe need to maintain their own expertise in intellectual property to support local inventors. “And we could help with the EPOs backlog,” he says One wants some of the EPOs work — currently done at Munich and subsidiary offices in the Hague and Berlin — to be devolved to national patent offices Only then do the EPOs examiners try to establish if the application meets the criteria of patentability — novelty, inventiveness and utility Partly, the struggle reflects the fact that some national offices no longer have enough to do Since then, all hell has been let loose inside the administrative council Some say their main worry is the waiting time that their applications face, as the EPOs backlog builds up (see graph) The 1973 European Patent Convention (EPC), which created the office, sought to save money and improve quality by centralizing patent-granting at the EPO The 31 nations that have joined the offices founding convention no longer see eye-to-eye on the extent to which the European office should supplant national patent offices The council has been unable to choose which nation should hold the EPAs rotating six-year presidency, for example, and has instead split it between French incumbent Alain Pompidou and Alison Brimelow, the British patent official who will take over in 2007 The office is reconciled to negotiations beyond next months meeting before the issue is resolved The other wants want to keep the work centralized. “When the split emerged last year, it was very painful,” says Ciaran McGinley, a principal director at the EPO. “It would be very wrong to dilute the density of expertise we have here.”  The conflict pits France and Germany — two of the original founders, whose languages are used, along with English, in all EPO documentation — against smaller nations, such as Finland, Sweden and Hungary, that dont want to let their own patent expertise wither away The smaller nations also fret that their inventors will suffer if they cant file European patents in their native languages. “There are 200 million citizens in EPO countries who have either English, French or German as their native language, and 300 million who dont,” points out Eero Mantere, vice-president of the Finnish patent office. “We need equality.”  For the researchers whose work leads to the roughly 60,000 patents filed to the EPO each year, this bureaucratic struggle may seem a distant concern There is nothing to stop a European nation from doing this — but none had chosen to do so since the EPO was established in 1973 These days, most universities and companies seeking patent protection for their ideas in Europe go to just one place — the sleek, imposing Munich headquarters of the European Patent Office (EPO) Two camps have emerged on the EPOs administrative council When a patent is filed, a literature search is conducted to find out if a similar invention already exists
 Cyber space Britain has awarded QinetiQ a £1.8-million (US$3.2-million) contract to build a security network to help the government, police, banks and computer companies keep an eye on cyber crime Delaware-based DuPont, through its subsidiary Pioneer Hi-Bred, will join one of Swiss firm Syngentas existing ventures to form GreenLeaf Genetics Instead, the firm says that it is seeking allies and smaller acquisitions to strengthen its drug pipeline Joining forces DuPont and Syngenta are teaming up to cross-license each others transgenic-crop technology Off the block Serono, Europes largest biotechnology company, is no longer up for sale QinetiQ, which runs many of Britains former military research laboratories, was floated on the stock market in February (see Nature 439 , 911; 2006 ). Shares in Serono, whose main product is the multiple-sclerosis drug Rebif, fell back 10% on the news to SFr830 (US$640), down sharply from SFr1,090 in January The combined operation will square off against Monsanto, which is the market leader in genetically modified corn and soya bean seeds The Cyber Security Knowledge Transfer Network will allow the government and the private sector to share up-to-date solutions to computer security problems The Geneva-based company said last November that the investment bank Goldman Sachs was seeking a buyer or partner for it (see Nature 438 , 557 ; 2005 ) — but none came forward with the right offer This will license out both companies technologies to other companies that sell seed directly on to farmers
 Here we show that a previously unrecognized kind of transcription complex is formed during RNA polymerase-catalysed synthesis of the M13 bacteriophage replication primer However, some replication systems have evolved to use cellular DNA-dependent RNA polymerase for primer synthesis  RNA primers for DNA replication are usually synthesized by specialized enzymes, the primases  The complex contains an overextended RNA–DNA hybrid bound in the RNA-polymerase trough that is normally occupied by downstream double-stranded DNA, thus leaving the 3′ end of the RNA available for interaction with DNA polymerase  The main requirement for the replication primer, an exposed RNA 3′ end annealed to the DNA template, is not compatible with known conformations of the transcription elongation complex , raising a question of how the priming is achieved Transcription complexes with similar topology may prime the replication of other bacterial mobile elements and may regulate transcription elongation under conditions that favour the formation of an extended RNA–DNA hybrid. Crosslinking For RNA–DNA crosslinking, stalled complexes were obtained as above, except that CpA was derivatized with an [ N , N -bis-(2-iodoethyl)]aminobenzaldehyde group on the 5′ end Crosslinking was induced by the addition of NaBH 4 to a final concentration of 1 mg ml -1 , and products were analysed as above For RNA–protein crosslinking, pRNA synthesis was initiated with the o -formylphenyl ester of AMP, a lysine-specific reagent, and crosslinking was performed and mapped ( Fig. 3a ) as described . For the competition assay, 500 nM T7gp2 was added to the immobilized complex, reactions were incubated for 10 min at 37 °C and then divided into supernatant and pellet Fractions were analysed for protein content by SDS–PAGE and for RNA content as above Gel filtration Reaction mixtures (50–100 µl) were loaded on a 10-ml Sephacryl S200 column equilibrated with transcription buffer , and 200-µl fractions were collected at a flow rate of 0.5 ml min -1  In experiments with IMP-containing stalled complexes, 3′-dATP was incorporated into the 3′ end of RNAs to reduce the readthrough (this explains why complexes in Fig. 2b contained RNAs 1 nt longer than those in in Fig. 2d ) In vitro synthesis of pRNA was performed essentially as described  Methods Wild-type and mutant RNAPs E. coli holo-RNAP, Thermus aquaticus core RNAPs and T. aquaticus σ A were purified as described previously  Mutant T. aquaticus RNAP lacking the rudder domain was described previously  Mutant T. aquaticus RNAPs lacking the zipper or the lid domains were obtained by genetically substituting the β′ subunit residues 27–42 (zipper) for a Gly–Gly linker or residues 526–539 (lid) for a Gly linker, with the use of a previously described recombinant T. aquaticus RNAP co-expression system  Reactions were stopped with formamide-containing buffer, and products were separated on 15–23% denaturing PAGE and detected by phosphorimaging RNase H (3 units), 1 or 10 units of ExoIII, 100 µM NTPs, 5 mM pyrophosphate or 500 nM GreB were added to the complexes for 10 min at 37 °C To obtain the stalled complexes, synthesis on mutant templates ( Fig. 2d ) was initiated with 50 µM CpA and 10 µM CTP, 10 µM UTP and 10 µM GTP or 300 µM ITP Transcription in vitro Stalled elongation complexes TEC20 and TEC27 were obtained as described elsewhere  When needed, complexes were isolated on Ni 2+ -nitrilotriacetate agarose ( Qiagen ) using His 6 -tagged RNAP  A clash with the β′ lid upon RNA growth beyond 8 or 9 nt alters the trajectory of the hybrid and leads to increased strain A fundamental difference between RNA polymerase (RNAP) and DNA polymerase (DNAP) is that the latter requires a primer to initiate template-dependent nucleic acid synthesis, whereas the former does not An in vitro pRNA synthesis reaction was performed on ori DNA ; the product was fractionated on a gel-filtration column, and fractions were analysed for the presence of radioactively labelled pRNA and Eσ 70  Crosslinking of complexes with 8-nt IMP-containing RNA ( Fig. 2b , lane 10), resulted in a radioactive band that was sensitive to treatment with DNase I (data not shown) and therefore corresponded to RNA–DNA crosslinking Crosslinking of complexes with GMP-containing RNA revealed the presence of an RNA–DNA crosslink for all complexes tested ( Fig. 2b , lanes 2, 4, 6 and 8) EC7 and EC10 were resistant to RNase H ( Fig. 2d , lanes 4 and 8) EC7, EC10 and EC12 responded to the addition of NTPs or pyrophosphate by, respectively, almost quantitative extension ( Fig. 2d , lanes 2, 6 and 10) or shortening ( Fig. 2d , lanes 3, 7, and 11) of original transcripts, whereas EC14 was resistant to both treatments ( Fig. 2d , lanes 14 and 15) Elongation of nascent pRNA might therefore be prevented as a result of the formation of overextended (compared with the eight or nine base pairs found in normal EC) hybrid between the nascent pRNA and the ori DNA Escherichia coli RNAP σ 70 holoenzyme (Eσ 70 ) specifically recognizes an imperfect hairpin formed by the ori of bacteriophage M13 ( Fig. 1a ) and synthesizes a transcript 18–20 nucleotides (nt) long (primer RNA; pRNA) that serves as a primer for DNAP III (refs 2 , 4 , 5 ) Eσ 70 and pRNA were eluted together from the column ( Fig. 1b ), whereas pRNA from deproteinized reaction was eluted much later (indicated by a downward arrow in Fig. 1b ). pRNA in column fractions was sensitive to RNase H ( Fig. 1b ), indicating that ori DNA was also eluted with Eσ 70 and pRNA Filamentous phages as well as many drug resistance plasmids from Gram-positive and Gram-negative bacteria have ori structures that are similar to the M13 ori , indicating that they might use this mechanism of priming Here we characterize primer synthesis from the minus-strand origin ( ori ) of bacteriophage M13 However, the enzyme lacking the lid did not produce pRNA: it transcribed to the end of the template ( Fig. 2c , lane 2) However, unlike the backtracked complex (and similarly to the active complex), the priming complex was resistant to GreB ( Fig. 1e ; compare lanes 3, 8 and 13) However, when 5-BrUTP, which forms three Watson–Crick bonds with adenosine, was used instead of UTP, pRNA synthesis on the mutant template was partly restored (data not shown) In brief, the absence of upstream DNA duplex formation allows overextended RNA–DNA hybrid to form In contrast to the situation during normal transcript elongation, no upstream duplex DNA should form during pRNA synthesis ( Fig. 1a ) In contrast, EC12 and EC14 were sensitive to RNase H ( Fig. 2d , lanes 12 and 16) In contrast, the nascent RNAs in EC20 and EC27 were fully resistant to digestion with RNase H ( Fig. 1e , lanes 5 and 10, respectively). pRNA in the priming complex was also sensitive to E. coli exonuclease III, an enzyme that specifically degrades double-stranded nucleic acids from exposed 3′ ends (data not shown) Instead, a ternary priming complex is formed It is tempting to speculate that direct contacts between RNAP in the priming complex and components of DNA replication machinery might further improve the efficiency of primer recognition ITP suppressed pRNA synthesis; instead, a longer RNA that resulted from transcription to the end of the 50-nt ori template was present ( Fig. 2a , lane 3) Little or no RNA–DNA crosslinking was observed in complexes with IMP-containing RNA longer than 8 nt ( Fig. 2b , lanes 12, 14 and 16), indicating that the RNA–DNA hybrid is eight or nine base pairs long and that the 5′ end of longer RNAs is directed into the RNA exit channel, as expected for ‘normal’ elongation Mapping positioned the 5′ end of pRNA close to, or in contact with, β Lys 1065, a conserved residue located close to the 3′ end of the nascent RNA in normal elongation complexes  No defects in pRNA synthesis were observed with enzymes lacking the rudder or the zipper ( Fig. 2c , lanes 3 and 4) Once the RNA–DNA hybrid reaches a certain critical length, the RNAP catalytic centre disengages from the 3′ end of the RNA and the enzyme slides backwards along the RNA–DNA hybrid forming the priming complex One can therefore expect that the initially active elongation complexes should start resembling the priming complex as the length of the nascent RNA increases beyond eight or nine bases Our principal finding is the demonstration that the formation of an overextended RNA–DNA hybrid leads to the cessation of transcription and the rearrangement of the RNAP elongation complex into a complex with highly unusual topology that satisfies the requirements for priming of DNA synthesis Several viral (T4 and M13) and plasmid (ColEI and F) replicons use bacterial RNAP to synthesize a replication primer The 5′ ends of nascent RNAs contained an activatable alkylating group that can crosslink to DNA (provided that an RNA–DNA hybrid exists) The addition of T7 gp2 to the priming complex resulted in the release of pRNA, which was sensitive to RNase H, indicating that it remained annealed to the minus-strand origin template ( Fig. 3b ) The backsliding differs from the previously described RNAP backtracking that results in the 3′-end-proximal portion of the RNA being threaded through the RNAP secondary channel  The cessation of RNA synthesis during the normal transcription cycle can occur either because of backtracking, when RNAP moves backward, extruding the 3′ end of the nascent RNA into the enzymes secondary channel while maintaining the normal length of the RNA–DNA hybrid (eight or nine base pairs), or because of transcription termination, when the transcription elongation complex (EC) falls apart The complexes were prepared with the use of immobilized RNAP and were washed away from unincorporated substrates  The data presented so far are consistent with an idea that in the absence of a non-template strand, a collision of the 5′ end of the nascent RNA with the β′ lid leads to the formation of overextended hybrid The ExoIII and crosslinking analysis argues that, in the priming complex, pRNA is annealed to the ori DNA throughout its length The formation of the priming complex was confirmed in experiments with immobilized RNAP ( Fig. 1c ) and by crosslinking RNAP β and σ 70 subunits and ori DNA to derivatized 5′ end of the nascent pRNA ( Fig. 1d ) The mechanism(s) that ensure the transfer of the primers 3′ end, which must be annealed to the template DNA, from RNAP to DNAP are not known The position of the 5′ end of the nascent pRNA was determined by mapping a crosslink with the RNAP β subunit ( Fig. 3a ) The priming complex possessed a unique property: it was sensitive to the addition of RNase H, which digested pRNA ( Fig. 1e , lane 15) The priming complex was compared with two well-characterized elongation complexes formed on a T7 A1 promoter-containing DNA: an active elongation complex containing a 20-nt RNA (EC20), and backtracked EC27 complex  The result strongly indicates that, during priming complex formation, the 5′ end of the RNA fails to disengage from the template strand, which results in the formation of an overextended RNA–DNA hybrid The RNA synthesis continues for some time but is ultimately stopped when a critical hybrid length is reached The RNA–DNA hybrid length in the normal transcription elongation complex is thought to be determined by several structural elements of the RNAP β′ subunit—the rudder, the lid and the zipper The sequence of events during pRNA formation is shown schematically in Supplementary Fig. 1  The susceptibility of pRNA to RNase H and exonuclease III (ExoIII) indicates that the 3′ end of the pRNA transcript is annealed to the ori template and is exposed The β′ jaw is part of a trough that interacts with double-stranded DNA downstream of the catalytic centre; T7 gp2 prevents this interaction These elements abut the upstream edge of the hybrid and may direct the nascent RNA to the exit channel This hypothesis predicts that decreasing the strength of pRNA interaction with transcribed portion of ori DNA should decrease the amount of pRNA synthesized, whereas the amount of the read-through transcript should increase Three consecutive GMP residues close to the 5′ end of pRNA might be particularly important for blocking the disengagement of the 5′ end of the pRNA from the template DNA Thus, after pRNA synthesis has been completed, the 5′ end of the nascent transcript, which should have been 18 nt upstream of Lys 1065 during the synthesis of the last phosphodiester bond, moves back to its vicinity Thus, EC12 can be regarded as an intermediate (or a mixture) between active elongation complex and the priming complex Thus, pRNA is not produced by a normal transcription termination event, which should have resulted in release of the nascent RNA from the transcription complex Thus, the strength of base-pairing between RNA and ori DNA controls pRNA production Thus, the strength of base-pairing between the 5′ end-proximal RNA residues and the template DNA controls the formation of the defined 3′ end of pRNA Thus, the ternary priming complex is distinct from known transcription complexes Thus, the β′ jaw is required for the priming complex stability, and the extended RNA–DNA hybrid must be bound in the RNAP downstream trough, with the 5′ end of pRNA near the RNAP active centre and the 3′ end annealed to the DNA template and available for DNAP (see Supplementary Fig. 1 ) To determine which of these elements contributes to the formation of pRNA, mutant RNAPs lacking the rudder, the lid or the zipper were used for pRNA synthesis To localize the position of the RNA–DNA hybrid within the priming complex, we used bacteriophage T7 gp2, a small protein that binds to the β′ downstream jaw domain  To show directly that the 5′ end of pRNA stays annealed to the ori template, chemical crosslinking with artificially stalled ori complexes containing 8, 11, 13 or 15-nt nascent RNAs was performed ( Fig. 2b ) To weaken the interaction, we performed pRNA synthesis in the presence of ITP instead of GTP ( Fig. 2a ) Unlike EC20, but similarly to EC27, the priming complex was unable to extend the nascent RNA even in the presence of high concentrations of NTPs ( Fig. 1e ; compare lanes 2, 7 and 12) or undergo processive pyrophosphorolysis ( Fig. 1e ; compare lanes 4, 9 and 14) We compared artificially stalled ori DNA complexes containing RNAs 7, 10, 12 and 14 nt long We next defined the trajectory of pRNA in the priming complex We speculate that a similar mechanism might be responsible for the formation of extensive RNA–DNA hybrids during RNAP-catalysed priming of replication on double-stranded replicons such as ColE1 (ref. 12 ). When a mutant ori template in which the three G·C base pairs at positions +2, +3 and +4 had been replaced by T·A pairs was used for pRNA synthesis, no pRNA was synthesized and only the full-size transcript was present ( Fig. 2a ; compare lanes 1 and 2)
 Although the processing conditions have yet to be optimized, these mobilities are already greater than those that have been achieved in solution-processed organic TFTs, and they exceed those of a-Si TFTs (≤ 1 cm 2  V -1  s -1 ). Here we demonstrate the solution processing of silicon thin-film transistors (TFTs) using a silane-based liquid precursor However, if high-quality silicon films could be prepared by a solution process, this situation might change drastically In particular, the ability to print semiconductor devices using liquid-phase materials could prove essential for some envisaged applications, such as large-area flexible displays Recent research in this area has largely been focused on organic semiconductors , some of which have mobilities comparable to that of amorphous silicon (a-Si); but issues of reliability remain Solution processing of metal chalcogenide semiconductors to fabricate stable and high-performance transistors has also been reported  The use of solution processes—as opposed to conventional vacuum processes and vapour-phase deposition—for the fabrication of electronic devices has received considerable attention for a wide range of applications , with a view to reducing processing costs This class of materials is being explored as a possible substitute for silicon, given the complex and expensive manufacturing processes required to fabricate devices from the latter Using this precursor, we have prepared polycrystalline silicon (poly-Si) films by both spin-coating and ink-jet printing, from which we fabricate TFTs with mobilities of 108 cm 2  V -1  s -1 and 6.5 cm 2  V -1  s -1 , respectively A 10 vol.% toluene solution of UV-irradiated CPS was ink-jet printed on a glass substrate in a nitrogen-filled dry box After cleaning the substrate surface by 172 nm UV-irradiation at 10 mW cm -2 for 10 min, the liquid silicon material—12 vol.% toluene solution of UV-irradiated CPS—was spin-coated at 2,000 r.p.m. in a nitrogen-filled dry box After maintaining a temperature of 400 °C for 30 min, it was further increased to 540 °C over another 10 min period and held for 2 h to form a 50-nm-thick a-Si film After the gate insulator had been formed, the same steps were applied as for the spin-coated TFTs After the poly-Si had been etched to create islands, a 120-nm-thick SiO 2 gate insulator (Gox in Fig.4d ) was formed by plasma CVD, followed by tantalum sputtering and etching to form gate electrodes Alkali and alkali-earth metal impurities, which negatively affect TFT characteristics, were present at a level of less than 1 p.p.m All experiments were carried out in a nitrogen-filled dry box with a residual oxygen concentration of less than 0.5 p.p.m., and the oxygen level was monitored using a galvanic fuel cell sensor By strictly controlling the oxygen content in the dry box to less than 0.5 p.p.m., we were able to limit the oxygen content of the film to less than 2,000 p.p.m Fabrication of TFTs by ink-jet printing TFTs with the same structure as above were formed using ink-jet printing instead of photolithography to form the channel silicon island Fabrication of TFTs by spin-coating The n-channel TFTs, whose structure is schematically illustrated in Fig. 4d , were fabricated as follows Finally, we made the TFTs accessible for measurement by forming an interlayer insulator, opening contact holes in the insulator to reveal the source and drain regions, and then sputtering aluminium to form electrodes First, an SiO 2 underlayer was formed by plasma CVD on a quartz substrate For comparison, conventional TFTs were fabricated by the same process except that the silicon film was formed by CVD Heat treatment conditions (achieved using a hot plate) for samples a, b and c were 300 °C for 10 min, 300 °C for 120 min and 540 °C for 120 min, respectively Impurity concentrations in the films were investigated using secondary ion mass spectroscopy In TDS, a sample is heated in a vacuum and the gases that are desorbed from the sample are analysed using mass spectroscopy Methods Preparation and analysis of a-Si film A 30 vol.% toluene solution of UV-irradiated CPS was spin-coated onto a quartz substrate to yield an approximately 100-nm-thick a-Si film after heat treatment Next, the amorphous film was converted to a polycrystalline one by irradiating it with 308 nm wavelength excimer laser light at 345 mJ cm -2  Raman scattering spectra of these samples were recorded in order to confirm the a-Si nature of the films at the typical a-Si peak of around 480 cm -1  Since its viscosity is almost the same as that of toluene and its stability is such that it can be kept for months in a dark place at room temperature, the ejection of the solution from the print head was stable and reproducible The carbon content in the resulting film was surprisingly low—only 200 p.p.m.—considering that an organic solvent was used as the starting material The channel width and length of the resulting TFTs were 36 µm and 2 µm, respectively. The channel width and length of the TFTs were both 10 µm The coating-formed silicon film did not present any notable problems or difficulties during the above fabrication steps, as the silicon film was of semiconductor-grade purity and the film processing conditions—etching rate, laser conditions and so on—were nearly the same as those used for CVD-produced silicon film The droplets were converted into a poly-Si island of diameter 30–40 µm by baking at 540 °C (using the same steps as for spin-coated film) followed by 308 nm excimer laser crystallization at 450 mJ cm -2  The island was 300 nm thick at the centre and became thinner towards the periphery of the sample The results confirmed that the film was composed almost entirely of silicon, with only a few trace impurities The source and drain regions were formed by the self-aligned ion implantation of phosphorous ions using the gate electrodes as a mask The spin-coated substrate was immediately placed on a hot plate heated to 200 °C and the temperature was raised to 400 °C within 10 min Thermal desorption spectroscopy (TDS) was used to investigate the process by which polysilane is converted to a-Si This solution was suitable for ejection from a piezo-driven print head  Three droplets, each of weight 10 ng, were deposited in the location where the channel island was to be formed A thicker film generally requires a more intense laser for optimal crystallization A thorough understanding of microdroplets will be needed to realize the ink-jet printing of liquid silicon material for practical applications After purification, the CPS was exposed to 405 nm UV light to induce photo-polymerization After sufficient exposure to the UV source, the liquid was transformed into a white solid, presumably made up of a mixture of hydrogenated polysilanes After this, at around 300 °C, the Si–H bonds break, resulting in a three-dimensional a-Si network Although this solid is insoluble in all common organic solvents, it proved to be soluble in the CPS monomer precursor Among the hydrogenated cyclic silanes we chose cyclopentasilane (CPS), Si 5 H 10 , since it is relatively stable and exhibits a high photoreactivity upon irradiation with ultraviolet (UV) light As shown in Fig. 4a , these TFTs exhibit good electrical characteristics with field-effect mobility (calculated from the transconductance in the saturation region) ranging from 74 to 108 cm 2  V -1  s -1 in 15 transistors randomly selected among a 4-inch substrate As the laser energy increases, the colour of the films changes from light auburn to light yellow, suggesting a conversion from the amorphous to the polycrystalline phase By diluting the solution with an organic solvent and then filtering out those insoluble polysilanes that precipitated as a result of dilution, we obtained the solution that we refer to as liquid silicon material By intentionally maintaining the oxygen level in the dry box at 10 p.p.m. during all processing, we obtained an insulating a-Si film that contained 7% oxygen During exposure, the CPS gradually became cloudy and viscous Figure 1 shows the results of the GPC measurements of the CPS ( Fig. 1a ) and the UV-irradiated CPS ( Fig. 1b ) Finally, we demonstrate the printing applicability of the liquid silicon material by fabricating TFTs using ink-jet formation of poly-Si islands (see Methods) For n ≥ 3, these compounds are liquid at room temperature and decompose to form a-Si when heated to 300 °C or higher Furthermore, the organic diluent such as toluene was carefully deoxidized by leaving it in a dry box for several days before use Given the binding energies of Si–Si (224 kJ mol -1 ) and Si–H (318 kJ mol -1 ) , the Si–Si bonds in the polysilane break first at a temperature lower than 280 °C, followed next by the breaking of the Si–H bonds, where a three-dimensional silicon network starts to form However, a slight failure in controlling the oxygen level in the dry box yielded a silicon film with an oxygen concentration of 8,000 p.p.m. and TFTs with a maximum mobility of 20 cm 2  V -1  s -1  However, film processed at such a low temperature might no longer be described as amorphous silicon and is easily oxidized in the air However, for n 10, boiling points are less than 300 °C and such compounds evaporate before thermal decomposition, which makes solution processing difficult However, the wettability and behaviour of microdroplets are known to differ significantly from those of macroscopic droplets  In addition, in Fig. 1b , a broad peak was also observed around M w = 2,600 In addition, low-hydrogen a-Si films are suitable for excimer laser crystallization, which is the standard crystallization method adopted during the commercial production of LTPS TFTs  In contrast, film that has been spin-coated and baked at a temperature of 300 °C or less contains more than 20% hydrogen and could function somewhat as a semiconductor In order to test the electrical properties of the film, we fabricated simplified bottom gate TFTs using the spin-coated a-Si In sample b, prebaked at 300 °C for 2 h, SiH 2 and SiH 3 desorption is three or four orders of magnitude lower than that of sample a In the actual process, UV irradiation is halted before the CPS completely polymerizes such that polysilanes of various molecular weights are dissolved in unreacted CPS In the poly-Si film that exhibited a mobility of 108 cm 2  V -1  s -1 the oxygen concentration was 1,100 p.p.m It has a boiling point of 194 °C and is soluble in most organic solvents Nevertheless, hydrogenated polysilanes are potentially ideal liquid silicon materials provided a suitable solvent can be found Next, the Si–Si bonds in the polysilane begin to break at a temperature below 280 °C and a fraction of the polysilane is released as SiH 2 and SiH 3  Next, we fabricated TFTs using the coating-formed poly-Si films followed by standard fabrication steps used for conventional LTPS TFTs (see Methods) Oligomeric and polymeric hydrogenated polysilanes, –(SiH 2 ) n –, have received little attention since first being synthesized by the Kipping method , because of their limited solubility in organic solvents Peaks corresponding to CPS and toluene were observed in both the non-irradiated and irradiated samples Sample a, prebaked at 300 °C for 10 min, reveals an SiH 2 and SiH 3 desorption peak at around 280 °C, followed by intensive hydrogen desorption between 300 °C and 400 °C, indicating that the polysilane is not completely converted to a-Si when baked at 300 °C for 10 min Sample c released much less desorption gas than samples a and b, since it had almost completely converted to a-Si during preheating at 540 °C for 2 h Since cyclic silanes are known to undergo ring-opening polymerization , this reaction can be used for the development of liquid silicon materials Since the CPS and polysilanes are fairly oxygen-sensitive , several precautions had to be taken during the preparation and treatment of a liquid precursor Since the films produced from this precursor must be convertible to high purity silicon, potential candidates are limited to carbon- and oxygen-free hydrogenated silicon compounds Since the wettability of the liquid silicon material was not sufficiently well understood to enable control of the shrinking behaviour of an ink droplet, the resulting a-Si island became too thick for laser crystallization Some kind of technical solution must be found in order to strike a balance between a lower process temperature and preventing oxidation Such a thick film contains many dangling bonds and defects near the substrate where crystallization is incomplete Such efforts are expected to establish a novel, low-energy, low-cost and high-throughput process for the fabrication of high-performance TFTs. Such poor mobility is attributed to the low concentration of hydrogen atoms that terminate the dangling bonds in the film Such precautions enabled control of the oxygen content of the film to less than 2,000 p.p.m The a-Si films, formed by coating the liquid silicon material and baking it at 540 °C, were irradiated by a 308 nm XeCl excimer laser at various laser energies The actual laser intensities used for the crystallization of 60 nm spin-coated and 300 nm ink-jet-treated Si film were 345 mJ cm -2 and 450 mJ cm -2 , respectively The coarsely synthesized CPS was distilled repeatedly to remove impurities including oxides before photo-polymerization The formation of thin, uniform a-Si film using an ink-jet process would improve the surface morphology and electrical properties of the poly-Si films The full-width at half-maximum of the crystalline peak in the Raman spectrum decreases sharply as the laser energy increases, reaching a minimum value of 6.3 cm -1 at around 300 mJ cm -2 ; thereafter the peak slightly broadens, reflecting microcrystallization The GPC measurements were also used to control and optimize the molecular weight distribution of the polysilanes which significantly affects the wettability of the precursor solution to a glass substrate The hydrogenated polysilane was also found to dissolve in a mixture of CPS and an organic solvent The ink-jet process for these materials is also being studied The ink-jet-printed (or ‘ink-jetted’) TFT operated with a mobility of 6.5 cm 2  V -1  s -1 and an on/off ratio of three digits ( Fig. 4a ) The latter intensity is not optimized but determined roughly from the sample thickness The maximum mobility of these TFTs was 10 -3 –10 -4  cm 2  V -1  s -1 , which is three or four orders of magnitude smaller than that obtained through conventional plasma enhanced chemical vapour deposition (CVD) techniques The mobility of the spin-coated TFT, 108 cm 2  V -1  s -1 , is definitely that of an LTPS TFT and cannot be obtained with a-Si TFTs The mobility was strongly affected not only by the conditions of laser crystallization but also by the amount of oxygen in the silicon film The nature of the external disk-shaped phase with a smooth surface is still unknown, but is presumably the residual remains of the droplet, formed during the drying and shrinking processes, which was once dispersed over the outer disk region The next step is to form an a-Si film by heating the spin-coated polysilane film in order to induce thermal decomposition The oxygen concentration in the box was maintained strictly below 0.5 p.p.m. during all processes from spin-coating to baking The polymerization process of CPS was investigated using gel permeation chromatography (GPC) The relationship between the preheating condition of polysilane and the amount of relevant gas (H 2 , SiH 2 and SiH 3 ) desorbed during the post-annealing phase of TDS are shown in Fig. 2  The silicon island can be seen in the SEM image of Fig. 4c as the disk-shaped element with a rough surface The TEM image in Fig. 3 clearly shows the crystalline growth as a result of laser irradiation The TFTs resulting from such low-oxygen films exhibited mobility as high as 50–100 cm 2  V -1  s -1 , while no significant correlations were observed between the oxygen concentration and mobility since manufacturing variations such as the laser condition are the dominant factors The transistor of mobility 108 cm 2  V -1  s -1 , whose output characteristics are shown in Fig. 4b , also possesses an on/off ratio of seven digits, 5.0 V in threshold voltage V th and 0.83 V per decade in s-factor (the gate voltage that induces a tenfold increase of drain current in the sub-threshold region) The ultimate goal of this research is to fabricate high-performance silicon TFTs by means of an all-liquid process, whereby all layers are directly patterned with liquid materials This low mobility is attributed to the poor crystallinity and rough surface, while the large off current, which was confirmed to be the current between source and drain rather than a leak current through the gate insulator, is also attributed to the thick silicon film This peak corresponds to polysilanes of various molecular weights, indicating CPS polymerization This solvent mixture plays an important role in controlling the wettability, coating properties, and thickness of the resulting silicon films, all of which are difficult to control when CPS is used alone Though currently inferior to that of conventional spin-coated LTPS TFTs, the performance of our ink-jetted TFT will probably improve with further advances in both the materials and processes employed Three samples were used to study the thermal decomposition of the polysilane, through the use of thermal desorption spectroscopy (TDS; see Methods) Thus the formation process of a-Si is inferred to be as follows: as the spin-coated polysilane film is heated, volatile components such as toluene and CPS evaporate first To this end, we are currently working to develop liquid materials for films other than channel silicon, such as dielectric layers, doped silicon for source and drain regions, and metallic films for electrodes To this end, we have studied the crystallization of the film (before optimization of the low-temperature a-Si process) in order to demonstrate the fundamental potential of this solution processing approach for low-temperature poly-Si (LTPS) TFT applications Typical hydrogenated silicon compounds are either of the straight-chain (Si n H 2 n +2 ) or cyclic (Si n H 2 n ) forms Unlike a-Si film formed from conventional CVD, which contains 5–20% hydrogen, the spin-coated a-Si film baked at 540 °C for 2 h contains 0.3% hydrogen and appreciable quantities of dangling bonds that hinder the mobility Using Raman spectroscopy , this crystallization process was confirmed to be almost identical to that of a-Si fabricated through conventional CVD Using TDS analysis, we estimate the total amount of hydrogen atoms (the atomic ratio of H/Si) in samples a, b and c, before TDS measurement, to be more than 22%, 3% and 0.3%, respectively Using the method developed by Hengge et al. , CPS monomer (a clear and colourless liquid under ambient conditions) was synthesized We have applied photo-induced ring-opening polymerization to obtain pure hydrogenated polysilanes from purified hydrogenated cyclic silanes We have demonstrated that high-quality poly-Si film can be formed by spin-coating or ink-jetting liquid silicon material We have pursued the development of a novel liquid precursor (herein referred to as ‘liquid silicon material’) that can be used in a liquid process to form a silicon film  With such an intense laser source, surface roughness is easily induced, as shown in Fig. 4c 
 An earlier mission design from NASAs Jet Propulsion Laboratory (JPL) in California foundered in 2001 owing to cost and technical difficulty And in setting ground rules for JPLs study, NASA eased a key restriction that was born of political concerns: mission designers were allowed to send their plutonium-powered spacecraft past Earth and Venus to pick up propulsive energy before heading into the outer Solar System And plans for a more ambitious nuclear-powered mission, the Jupiter Icy Moons Orbiter, have also been scrapped — at least for the foreseeable future But a study completed by JPL this summer has broken some of the previous barriers to visiting Europa But sending a spacecraft there is complicated by Europas harsh radiation and the large amount of rocket fuel needed to brake into orbit But the mission could get backing from NASA administrator Mike Griffin, who told a Senate committee in May that “You may look forward, in the next year or maybe even sooner, to a proposal for a Europa mission as part of our science line.”  And international participation could help But the mission may now fit within NASAs target budget for the first time Europa has long been of interest to planetary scientists because of the ocean that is thought to lie beneath its icy crust, which may be a possible habitat for life Expectations are still high that any Europa mission will be done jointly with the European Space Agency (see Nature 434 , 551 ; 2005 10.1038/434551a ) Mission designers at NASA may have found a way to explore Jupiters moon Europa without busting the agencys budget — by flying past Earth first NASA has come under fire from activist groups in the past for launching radioactive material into space Scientists who have been lobbying for a Europa mission after the cancellation of the Jupiter Icy Moons Orbiter (see Nature 433 , 342 ; 2005 10.1038/433342a ) hope the Europa Geophysical Explorer will make it into NASAs budget request as early as next year That may be optimistic, given competing financial demands from the beleaguered space shuttle, the Moon–Mars astronaut programme and other science projects that have run into money troubles That would be long enough to map the subsurface ocean and examine Europas icy face at high resolution from orbit The addition of Venus and Earth ‘gravity assists’ makes the trip to Jupiter longer, but allows a heavier spacecraft, with a substantial scientific payload, to launch on a single rocket The Delta IV rocket in the study would still be an expensive ride — any Europa mission is expected to cost upwards of $1 billion The Europa Geophysical Explorer, as the concept is dubbed, could launch as early as 2012, carrying 150 kilograms of payload, including an ice-penetrating radar, a suite of remote sensing instruments and perhaps a small lander The National Academy of Sciences and other advisory groups have consistently listed Europa among the top destinations for future space missions The spacecraft would take more than six years to reach Jupiter and then spend a year-and-a-half orbiting the planet, including close fly-bys of Europa, Callisto and Ganymede, before ending with a 30-day intensive exploration of Europa This is especially so after the successful cooperation on the Cassini–Huygens mission to Saturn. This would allow work to begin in 2007 Work on the suspended nuclear mission led to progress in building radiation-resistant spacecraft components
 A cortical column comprises some 10,000 neurons, each making thousands of connections And, in a 2003 tour de force with collaborators Minmin Luo and Michale Fee, he achieved the extraordinary feat of recording neuronal activity in the accessory olfactory bulb of awake, behaving mice Answers required new methods of studying the cortical connectivity of several neurons simultaneously, in terms of both anatomy and function Aside from hard-won intracellular recording experiments from a handful of single neurons, and beautiful studies that revealed primarily the dendritic morphology of these cortical neurons, little was known about their local axonal branches — the transmitting end of the neuron — let alone about functional synaptic connections But in vivo evidence for correlated spontaneous firing of ensembles of neurons was missing until Katz perfected a method of multi-electrode recording in conscious, behaving animals Encouraged by Konishi, however, he switched his focus to the mammalian cerebral cortex, devising in his doctoral thesis of 1984 a striking approach for studying subsets of cortical neurons through the long-distance connections they make with other neurons For example, many experiments pointed to a need for correlated neural activity during brain development to fine-tune sets of connections in the cortex that underlie ocular dominance and orientation columns From 1999 until his untimely death from melanoma on 26 November 2005, Katzs science began to come a full circle, as he returned to his original interest in neuroethology He appreciated not only on a scientific level the extreme elegance of the brain circuits that process sensory information, but also on a human level their role in connecting us to each other and permitting us to enjoy the world around us to the full He thus provided new views of cortical circuits, discovering the existence of spontaneously active groups of neurons, known as coactive domains, and probing the emergence of functional horizontal connections within cortical layers 2 and 3 He used the technique of intrinsic signal imaging to reveal a spatial map of odours among structures in the olfactory bulb known as glomeruli, where the first stage of information processing in olfaction occurs He was also an avid fisherman, and we can imagine him even today with a prize albacore or up to his knees in a rushing stream high up in the wilderness, reeling in a trophy trout. His intention was to study the brain circuits underlying birdsong Hubel and Wiesels work had demonstrated that the columnar organization of the visual cortex could be profoundly perturbed by abnormal visual experience during a critical period of development; but how the cortical columns formed in the first place, or what aspect of altered experience perturbed them, remained mysterious In 1981, just as Larry Katz was beginning his postgraduate career, the Nobel Prize in Physiology or Medicine was awarded to David Hubel and Torsten Wiesel for their pioneering studies of the visual cortex In a marvellous conjunction of the best of technology and the best of neuroscience, Katz marshalled his impressive armamentarium to attack the problem of how olfactory signals are processed in the rodent brain Katz arrived in 1981 at Mark Konishis laboratory at the California Institute of Technology in Pasadena with a love of neuroethology — the study of brain and behaviour — and with papers on tadpole and fiddler-crab behaviour, written as an undergraduate at the University of Chicago, under his belt Katz typified a new breed of scientist, able to combine innovation with a willingness to work on problems, such as those of the wiring of the visual system, that seemed too complex to approach experimentally Katz was never afraid to develop or apply new technology when it was needed for the optimal execution of an experiment Katzs choices of scientific problems centred throughout his career on the key senses of hearing and language (birdsong), sight and, most recently, smell Larrys joy for living and aesthetics no doubt accounted for his love of the sleek design of the Alpha Romeo cars that he drove for years, and of the speed and soaring freedom of flying an aeroplane Not content with an anatomical view of the cortex, in the 1990s Katz — now at his own laboratory at Duke University in Durham, North Carolina — pioneered the application of optical imaging of neurons (using fluorescent calcium or voltage indicators) and photostimulation (using caged glutamate) to probe circuit development Quite apart from the beauty of the experiments, the method threw wide a door, opened only a crack by conventional methods, that enabled Katz to examine in exquisite detail the development of horizontal connections between neurons, and show how this development could be influenced by experience Studying this pathway, which is parallel to the main olfactory pathway and functions as the ‘sexual nose’, enabled Katz to reveal for the first time the encoding of responses to pheromones — chemical signals transmitted between members of the same species The tracing method that Katz invented used fluorescent latex microspheres that permitted the retrogradely labelled neurons not only to be visualized in slices in vitro , but to be simultaneously targeted with a microelectrode and injected with dye These were the unresolved questions with which Larry Katz grappled during his tragically short 25-year career, providing many answers and leaving a precious legacy of technological innovation They had deduced that the vertical columns of neurons in this part of the outer, grey-matter layer of the brain, responsible for processing visual stimuli, are organized into sets — orientation columns and ocular dominance columns — according to their responses to visual stimuli This discovery came largely through painstaking microelectrode recordings of single neurons, combined with anatomical tracing of connections from eye to brain that revealed a highly organized stripe-like segregation of inputs representing the two eyes in cortical layer 4, the gateway to the cortex This technique, which Katz perfected as a postdoctoral fellow with Torsten Wiesel at the Rockefeller University, New York, is still popular today, generating images that have graced many journal covers What was missing from this picture was an understanding of how neuronal connections within the other layers of the cerebral cortex are organized
 Almost all current measurements involve measuring the voltage drop across a resistor, using Ohms law, in which the discrete nature of charge does not come into play Here we report a direct observation of these time-correlated single-electron tunnelling oscillations, and show electron counting in the range 5 fA–1 pA However, by sending a direct current through a microelectronic circuit with a chain of islands connected by small tunnel junctions, the individual electrons can be observed one by one Moreover, our current measurement, which is based on electron counting, is self-calibrated, as the measured frequency is related to the current only by a natural constant. The fact that electrical current is carried by individual charges has been known for over 100 years, yet this discreteness has not been directly observed so far The quantum mechanical tunnelling of single charges in this one-dimensional array is time correlated , and consequently the detected signal has the average frequency f = I / e , where I is the current and e is the electron charge This represents a fundamentally new way to measure extremely small currents, without offset or drift A few years later, these oscillations were detected indirectly by phase locking to an external microwave signal  A number of authors have also proposed that it should be possible to turn this relation around, and instead measure the current by monitoring the individual electrons as they pass through a circuit An important property of the electron counter described here is its dynamic current range Another important feature is that the counter is self-calibrated, and does not suffer from problems like offset or drift in the measurement set-up As the charges approach the SET, the source–drain current is modulated by the charge induced on the middle island, resulting in modulation of the reflected radio-frequency power At high currents, the measurement speed is restricted by the bandwidth of the SET At low currents ( 3 fA, according to our simulations ), when there is only one soliton in the array at a time, space correlation—and hence also time correlation—is lost Figure 3a shows time traces of single-electron tunnelling events for three different currents For realistic parameters, this expression gives an accuracy of 1 part in 10 6  For the sample described here, the SET source–drain resistance was R SET = 30 kΩ, while the array resistance was R N = 0.94 MΩ per junction For the SET, on the other hand, sensitivity falls off as the resistance increases From an applications point of view it would be desirable to measure larger currents, and to decrease the input impedance of the ammeter However, P is very strongly dependent on the sensitivity of the SET, which suggests that metrological accuracy can be achieved in an optimized device However, the duality is not complete because the single-electron tunnelling oscillations are lacking coherence However, we have instead chosen to couple the array directly to the middle electrode (island) of the SET as can be seen in Fig. 1 , a configuration known as the resistively coupled or array-coupled SET In a realistic experiment, however, the resolution bandwidth of our measurement set-up, 1/ f noise and instability of the bias at very low currents prevent us from measuring with any accuracy below 5 fA In Fig. 2 , we show the array current–voltage characteristics In general, both electron and Cooper-pair tunnelling can take place in the array, but at this magnetic field the threshold for electron injection is lower than that for Cooper pairs In order to detect the tunnelling charges in real time, we have used an improved version of the conventional single-electron transistor (SET) as a charge sensor, namely, the radio-frequency SET ( Fig. 1 ) In order to measure current by electron counting, three main ingredients are necessary: time correlation of the tunnelling events, a fast and sensitive charge detector, and a very stable current bias In our case, the soliton length is , and the array is in the long limit, N ≫ M  In our experiment, we have used a superconducting array containing N = 50 junctions ( Fig. 1 ) In such an array, excess charge on one island polarizes the neighbouring islands, so that the charges repel each other In the mid-1980s, it was suggested that a small current consisting of individual electrons, tunnelling through a small tunnel junction, could at low temperatures result in an oscillating voltage of amplitude e / C , where C is the capacitance of the tunnel junction In the range from 5 fA to 1 pA, the reflected power spectrum shows a peak ( Fig. 3b ) at a frequency that corresponds to the applied current in the array, f = I / e ( Fig. 4 ) In this experiment, there are obviously other error sources limiting the accuracy, such as bias instability that smears the peak in the spectrum, and background charges that affect both the operation point of the SET and the soliton flow in the array In this way, the full electron charge is detected by the SET In this way, we have detected single-electron tunnelling oscillations in real time In those experiments, however, there was no time correlation, and thus no relation between frequency and current could be demonstrated It was shown theoretically , and observed indirectly , that this type of array exhibits time-correlated tunnelling events Josephson effect, as phase and charge are quantum conjugated variables Monte Carlo simulations show that the narrowest linewidth of the single-electron tunnelling oscillations occurs at approximately 1% of the characteristic e / RC current More recently, single-electron tunnelling events have been observed  Moreover, the sensitivity of the SET is higher in the superconducting state One possible way to do electron counting is to couple the SET capacitively to one of the electrodes inside the array, and thus observe the potential variations of that electrode as the charge solitons pass Our preamplifier, with a noise temperature of 2 K, sets the overall noise level in our measurement system Recent interest in quantum noise in mesoscopic systems has led to the theory of full counting statistics , in which general information about charge transfer can be gained from the higher statistical moments of noise Shortly thereafter, new devices such as the single-electron turnstile and the single-electron pump were invented in order to create a current given by the fundamental relation I = ef  Since then, the single-electron pump has been refined to a very high accuracy  So far, very few experiments have been performed along these lines, but the relatively low bandwidth of the tunnelling process in the array suggests the possibility of measuring the full statistics of the charge transport, and gaining access to higher statistical moments of the current. The capacitance of each junction is C A ≈ 0.42 fF, and the stray capacitance of an electrode inside the array is C 0 ≈ 30 aF The characteristic time for the soliton dynamics is determined by the RC constant of the tunnel junctions in the array The charge is localized, but the potential resulting from the capacitive voltage division in the array is spread over a number of junctions, M  The counting errors caused by the limited sensitivity of the SET can be estimated as P = 0.5erfc( q c / Q N √2) , where Q N is the charge noise within the measurement bandwidth, q c is the charge threshold for a count to be registered, and erfc is the complementary error function The full theory for these so-called single-electron tunnelling oscillations was then developed , based on earlier work on Bloch oscillations and the underlying Coulomb blockade  The measurements presented here are done under a parallel magnetic field B ‖  = 475 mT, at which the array is still superconducting The opposite limit is ultimately set by the e / RC current The peak broadens considerably when the current approaches 10% of the e / RC current, in fair agreement with simulations, assuming a subgap resistance R SG = 100 R N = 94 MΩ The signal is gradually smeared by temperature, but persists even at 300 mK The suppressed superconducting gap Δ  (here Δ / k B ≈ 0.6 K, where k B is Boltzmanns constant) and the high impedance of the array junctions also suppress the tunnelling rates for Cooper pairs, and we expect to see only electrons at this field Then it could also be used to close the quantum metrological triangle relating current, voltage and frequency by fundamental constants This can be achieved by placing small-size resistors in close proximity to the junction or by using a one-dimensional series array of tunnel junctions  This demonstrates time correlation between consecutive tunnelling events This is possible with an electron counter, as it is straightforward to put several devices in parallel, which is not the case with single-electron pumps This is the only device with the required sensitivity and speed: it can detect sub-electron charge changes at frequencies well above 10 MHz This makes the system less sensitive to bias voltage fluctuations, because in the superconducting state the onset of current is rounded, while in the normal state it is quite steep ( Fig. 2 inset) This phenomenon of single-electron tunnelling oscillations is similar to the a.c This potential distribution is often referred to as a charge soliton (or antisoliton, if a charge is missing), as it can move (by tunnelling) throughout the array without changing its form To bring about time correlation in a single tunnel junction, in contrast to uncorrelated shot noise , care must be taken to make the electromagnetic impedance seen by the junction large compared to the Klitzing resistance, R K = h / e 2 ≈ 25.8 kΩ To keep this current low enough for the SET to follow the oscillations, it is important that the array tunnel junctions have a high resistance To obtain different oxide thickness for the array and SET junctions we have therefore used a three-angle shadow evaporation process to deposit aluminium  We have designed the device parameters in order to obtain the desired soliton behaviour and at the same time ensure good performance of the SET When the array is biased above a certain threshold voltage, V t , charges enter from the edge, and as the solitons in the array repel one another, a moving quasi-Wigner lattice of charge solitons is formed When the array is biased slightly above the threshold voltage for electrons, V t e , a small (sub-pA) current starts to flow
 A magnetic board monitors the presence and location of everyone in the lab And Japanese students have to dispose of their rubbish and clean their labs themselves Apart from experiencing a different research environment, doing a working visit to this country has allowed me to experience an entirely different way of life Apart from needing permission from my senzai to take cover in the event of a typhoon, I also need his permission to begin experiments But take some language lessons first — and be prepared to work in a more controlled environment. http://www.jsps.go.jp Every new experimental idea must be checked by the senzai and then the professor I am in Japan, well known as ‘the land of the rising sun’ — although as a visiting fellow from Austria, I have learned that it is also the land of typhoons and earthquakes I applied for a JSPS short-term stipend and eventually got an invitation to work for two months at the pharmaceutical sciences department of the University of Osaka Id advise Western scientists to consider a visit In 2003, the Japan Society for the Promotion of Science (JSPS) brought in 144 European researchers and 117 US researchers for short stays, and only 32 Europeans and 15 US scientists for longer-term stints Japan Society for the Promotion of Science “The typhoon is advancing — you can finish in one hour,” says my senzai (assistant professor) and leaves the lab Life as a scientist here is very different from anywhere else I have worked Most students extend their work to weekends and holidays On Fridays, students and junior researchers present a summary of their weeks activities and deliver exact research plans for the following week Right at the beginning, I received my personal marker to indicate exactly where I spent my time Sleep deprivation often takes its toll in seminars or in front of the computer — but not to worry, there is no shame in dozing off at any time or anywhere The Japanese system places a premium on tight supervision, close collaborative effort — and long hours Western scientists working in Japan are relatively rare Why did I choose Japan? Because I longed for something different and thought that I could find my personal challenge in Asia Working days begin at 9:30 a.m. and usually end at about 10 p.m., with seminars (in Japanese only) sometimes held on Saturdays
 A famous carving, the Tello obelisk, recovered from the archeological site of Chavín de Huántar, also in the Peruvian Andes, shows carvings of tropical forest plants. “The iconography tells us of a connection between these two areas, but until now there was no solid evidence,” says Perry Archeologist Daniel Sandweiss of the University of Maine in Orono recruited Perry and her Smithsonian colleague Dolores Piperno to the Andean project due to their expertise with these residues Finding that goods and people moved between the Andes and the rainforest is not a surprise He stumbled on the 4,000-year-old house during a test excavation In a study that appears on page 76 of this issue, Perry applied these techniques to identify the remains of ground-up corn in soil and tools collected from a 4,000-year-old house buried in the Andean mountains of Peru Linda Perry spends her days at the Smithsonian National Museum of Natural History in Washington DC, gazing down a microscope at corn kernels and other grains Perry also found remnants of arrowroot, used today as a thickening agent Perry began studying the role that plant foods had played in South American history while doing her doctoral work in the Orinoco valley of Venezuela Perry, who majored in biology at Tulane University in New Orleans, says that archaeobotany is perfect for her. “It is a combination of things that I love and that challenge me,” she says. “Trying to put together the fossil record is like assembling a very difficult puzzle.” Sandweiss was following the trail of deposits of a volcanic rock called obsidian in Peru, near the modern-day town of Alca, in search of evidence that ancient peoples mined and used obsidian She would like to continue to chart this connection by “following the arrowroot track down the mountain”, she says Starch grains and silica phytoliths (microscopic chunks of mineral that form inside living plant tissues) are microfossils that are used to identify ancient plant remains The grains —often thousands of years old — reveal information about both the farming and trading patterns of long-gone civilizations The work involved refining techniques for analysing the residues of starch grains on tools used to cut and scrape plant foods They are particularly useful in tropical climates, where macrofossils such as wood and carbonized charcoal are rarely well preserved This plant does not grow at the altitude where the house was located, but would have flourished in the low-lying rainforest regions. “It provides an important link between the Andes and the tropical rainforests,” says Perry This suggests that the Andean people were grinding the corn to make flour While he looked for obsidian and other artefacts, he sent specimens to Washington, where Perry and Piperno carried out starch and phytolith analyses, respectively
 Asthma is an increasing health problem worldwide , but the long-term temporal pattern of clinical symptoms is not understood and predicting asthma episodes is not generally possible  Furthermore, we find that the time series of peak expiratory flows show long-range correlations that change significantly with disease severity, approaching a random process with increased variability in the most severe cases Here we introduce an approach to predict the risk of worsening airflow obstruction by calculating the conditional probability that, given the current airway condition, a severe obstruction will occur within 30 days The characterization of fluctuations in airway function provides a quantitative basis for objective risk prediction of asthma episodes and for evaluating the effectiveness of therapy. Unexpectedly, however, a regular short-acting β 2 -agonist bronchodilator (albuterol) increases this risk Using a nonlinear stochastic model, we show that both the increased variability and the loss of correlations augment the risk of unstable airway function We analyse the time series of peak expiratory flows, a standard measurement of airway function that has been assessed twice daily in a large asthmatic population during a long-term crossover clinical trial  We find that, compared with a placebo, a regular long-acting bronchodilator (salmeterol) that is widely used to improve asthma control decreases the risk of airway obstruction A linear regression line is fitted through the data in each window and the time series are locally detrended by subtracting the regression line from the data As the window moves along the time series in steps of one data point, the first point of the window determines the bin number k and a counter N t ( k ) is incremented Baseline lung function and clinical symptom scores were assessed before the study Because the experimental γ is small ( Table 1 ), a 2 a 1 /20, and hence the contribution of nonlinearity to the correlations of y ( t ) is negligible, which we verified numerically Correlation analysis and conditional probability Correlation analysis was done with a detrended fluctuation function F ( n ) (ref. 11 ) Examples of the distributions and correlations of y ( t ) are shown in Fig. 1b and c, respectively Finite size error introduced by analysing 300 data points is less than 2–3% (ref. 17 ) In addition, a separate counter, N c ( k ), is also incremented if any value of PEF (other than the first) in the window falls below the selected 80% or 60% threshold Methods Subjects The analysis was performed in a PEF time series of 80 non-smoking individuals (mean age, 42.4 yr; s.d., 11.8 yr; range, 19–64 yr) with persistent asthma Nonlinear stochastic model We introduce a nonlinear stochastic block-structured model of the PEF fluctuations Of the original 165 participants, 80 individuals with less than 3% of values missing are included in the analysis Our simulated PEF series using 50,000 values provides results consistent with those extracted from our clinical records PEF, symptoms and ‘as-required’ bronchodilator use were recorded twice daily The calculation is repeated for different values of n , and α is obtained as the slope of a straight line fit to F ( n ) on a log–log plot The conditional probability ( π ) is calculated by first establishing five bins of the PEF values and a window of 60 points corresponding to 1 month The correlation exponent β and the parameters a 0 , a 1 and a 2 may be related to airway closure, persistent inflammatory processes, increased airway smooth muscle sensitivity and airway wall remodelling . The F ( n ) is computed for each window of length n as the root-mean-square of the detrended and integrated PEF time series The input to L is a zero mean gaussian white noise x ( t ) with unit variance The input to L may represent the fluctuations in environmental stimuli (such as pollutants, allergens or viral infections) and internal stimuli (such as acute inflammation, exercise or hyperventilation) The model inputs and parameters could be interpreted as follows The N t and N c for all k are then summed for all individuals corresponding to a given condition and π ( k ) is obtained as the ratio N c ( k )/ N t ( k ) The number of data points needed for detrended fluctuation analysis is crucial because finite size effects can occur with short time series The output u ( t ) of L is a long-range correlated signal with exponent α and is led through N to produce a final output y ( t ) = a 0 + a 1 u ( t ) + a 2 u ( t ) 2  The three treatment periods of 6 months each were randomly sequenced This criterion is necessary to ensure that the correlation analysis can be carried out appropriately To account for the power law correlations in the experimental data, the memory of L is modelled by a transfer function H ( f ) ≈  f β /2 where f is the frequency and the exponent β is related to the correlation exponent by α = (β + 1)/2 To calculate F ( n ), the PEF series is integrated and divided into equally sized non-overlapping windows of length n  To match the mean ( µ ), variance ( σ  2 ) and skewness ( γ ) of the experimental data, we solve for the higher order moments of y and approximate the coefficients as a 2 = σγ (1 + 0.0185 γ 2 )/6, a 1 2 = σ  2 - 2 a 2 2 and a 0 = µ - a 2  To obtain π from the model, we generate a time series of y ( t ) containing 50,000 points and calculate π as described above We assume that the model is a cascade connection of a linear dynamic system ( L ) followed by a second order nonlinear system with no memory ( N ) A possible interpretation of these results is that the PEF time series of normal subjects and individuals with mild and stable asthma show long-range baseline correlations Achieving or maintaining stable asthma with a given treatment thus requires a high average PEF accompanied by strong correlations or a high value of α All individuals show a similar pattern ( Table 1 ) Although CV seems to have a dominant effect on π ( Fig. 4 ), the correlation properties of PEF are also important because, in the absence of correlations ( α = 0.5), π would be identical to regular probability and the curves in Fig. 3 would be independent of PEF As compared with PL, the distribution of PEF in the LA period shifts to higher values consistent with improved airway function ( Fig. 1b ) Asthma is a chronic inflammatory disease of the airways Because the normal fluctuations in airway function are interrupted by these irregular and unrelated events, the baseline correlations are lost and the variability of PEF is increased Both treatments preserve the long-range correlations, but in this individual ( Fig. 1c ), α decreases by 17% in the SA period and increases by 15% in the LA period By contrast, regular long-acting bronchodilators are more effective at stabilizing airway function over extended periods Conversely, in the LA period there is a stronger correlation between past and future values of PEF, strengthening the memory of the system Conversely, the decreased risk in the LA period results primarily from the increased median PEF, the decreased CV, and perhaps also from an increase in α ( Table 1 , Fig. 3 ) Conversely, the variability (coefficient of variation; CV), of the PEF series is significantly higher in the SA than in either the LA or PL period (paired t -tests, P ≤ 0.005), whereas the CV in the LA is lower than in the PL period ( P = 0.001) Currently, short-acting bronchodilators are the first line drug for as-required treatment of asthma symptoms Fluctuations in airway calibre result in episodic symptoms of wheeze, dyspnoea or cough  For any value of PEF, regular long-acting salmeterol significantly decreases the risk as compared with both placebo (paired t -test, P 0.004) and regular short-acting albuterol ( P 0.02) Furthermore, the subjects required significantly more additional ‘on-demand’ reliever (albuterol) in the SA and PL treatment periods than in the LA period ( P 0.05) Here we investigate the temporal pattern and their predictive utility of airway function characterized by peak expiratory flows (PEFs), defined as the maximum flow measured during a single forced expiratory manoeuvre, in 80 asthmatic subjects (Methods) However, the correlation between α and airway function is more complex: the closer α is to the median value of 0.78, the smaller is the change in α (Δα) with treatment ( Fig. 2 ) If PEF is low, however, a high α value is not beneficial because the PEF would tend to remain low In addition, the quantitative approach proposed here can be applied to uncover dynamic patterns in the fluctuations of clinical symptoms of other complex chronic diseases of which asthma is a representative model. In particular, we examine whether the statistical and correlation properties of the time series of PEF recordings can be used to predict the risk of subsequent exaggeration of airway instability In the PL period, α is directly correlated with baseline lung function (linear regression: α = 0.0032PEF pred + 0.532, where PEF pred is the percentage predicted PEF value; P 0.02) and is inversely related to N wheeze in that period ( α = -0.00037 N wheeze + 0.819; P 0.05), but not to asthma symptom scores In the SA period, the number of severe asthma episodes in a given 6-month treatment period ( N episodes ), defined by the need for oral corticosteroid treatment, was more than twice (13) that in the LA (6) and PL (5) periods Loss of asthma control observed with regular short-acting β-adrenergic agonist treatment has been described  Mean skewness is higher in the LA than in the SA and PL periods (signed ranks test, P 0.05) Of greater clinical relevance is the fact that Δ α correlates with the improvement in the clinical asthma score ΔAsc (multiple linear regression adjusting for treatment, SA or LA: coefficient, 0.305; 95% confidence interval, 0.171–0.439; P 0.001) but not with Δ N wheeze  Our approach of estimating the conditional probability of moderate or severe airway obstruction and hence the risk of asthma exacerbations in individuals can have practical benefits for patient management Our results facilitate an understanding of unstable and stable asthma that can lead to a rational optimization of treatment Our study suggests, however, that during regular use (four times daily with a long night time drug-free interval), short-acting bronchodilators do not decrease but even increase the risk of asthma episodes owing to the lack of maintained β-agonist effectiveness Predicting the risk of asthma episodes requires a detailed knowledge of the temporal patterns of the fluctuations in airway function; however, the long-term temporal properties of airway obstruction in asthma has not been studied Regarding the mean values, although α tended to be higher in the LA than in the PL period, it decreased significantly in the SA as compared with the PL period ( P 0.001) Short-term variability of airway resistance and its distribution are sensitive to the asthmatic condition  Similar trends are seen in the SA and LA periods Similarly, individuals had significantly more wheezing episodes ( N wheeze ) in the SA and PL periods than in the LA period ( P = 0.05) Subjects had similar mean daily doses of inhaled corticosteroids in all treatment periods (median ranged between 500 and 548 µg d -1 of beclomethasone or equivalent) Such predictions should be valuable for individuals, as well as for evaluating therapeutic interventions in clinical trials The complex interactions between endogenous and environmental factors result in a highly variable pattern of airway obstruction over time  The composite daily clinical asthma scores averaged and normalized per day (Asc) were significantly lower (paired t -test, P 0.05) in the LA period, implying better asthma control than in the SA and PL periods  a sign of increased instability of airway function The exponent α characterizes the correlation properties of the PEF series: for α = 0.5 the series is uncorrelated, whereas for increasingly higher values of α it shows increasingly stronger long-range correlations The individual time series of the 300 consecutive twice daily PEF values show substantial fluctuations especially in the SA period ( Fig. 1a ) The input to the model is gaussian white noise, and the output of the model is a time series that matches both the distribution ( Fig. 1b ) and the correlation properties ( Fig. 1c ) of PEF The interpretation and prediction of such fluctuations are difficult not only because environmental stimuli are not always recognizable and are difficult to quantify, but also because the correlation between stimuli and symptoms is exceedingly poor  The means of the individual PEF series averaged within each group are significantly higher (paired t -test and signed ranks test, P 0.001) in the LA than in either the SA or PL period, whereas those in the SA are higher than in the PL period The physiological origins of these correlations are currently unknown The predominant view is that this loss is due to β-adrenergic desensitization , but our results suggest alternatively that the short-acting agonist treatment leads to significantly increased variability and loss of predictability of airway function The probability that a moderate airflow obstruction occurs within one month decreases from nearly 100% at low initial values of PEF ( 200 l min -1 ) to between 10 and 30% for high initial values of PEF ( 550 l min -1 ) depending on the treatment period ( Fig. 3 ) The probability that an episode of severe airway obstruction occurs within the same time frame is similar but with lower values The trial compared the effects of a regular short-acting β-agonist treatment (albuterol, 400 µg four times daily; ‘SA period’), and a regular long-acting β-agonist treatment (salmeterol, 50 µg twice daily; ‘LA period’) with those of a matching placebo (PL period) These data indicate markedly less stable airway function in the SA period These findings are in accord with previous observations of diurnal effects of short-acting β 2 -agonist drugs and are probably a consequence of the long night time interval without drugs together with rebound bronchoconstriction These results imply that both α and the CV should be related to the risk of acute asthma episodes with significant airflow obstruction These results indicate that the increased risk in the SA period is a consequence of the decreased α and increased CV of the PEF time series Thus, lower values of α generally reflect more severe airflow obstructions Thus, SA not only fails to increase the mean PEF ( Fig. 1a ), it increases the variability of PEF ( Fig. 1b ) and alters the correlations of PEF to become more random such that past PEF values have less effect on the current or future values To assess the separate effects of the distribution and correlation properties of the PEF series on the risk π , we introduce a nonlinear stochastic model of the PEF fluctuations (Methods) To assess this risk, we calculate the conditional probability ( π ) that a significant deterioration in airway obstruction, defined as PEF 80% (moderate) or PEF 60% (severe) of the age- and height-predicted normal values, occurs within a certain time period given the current value of PEF (Methods) To determine whether the variability of PEF is accompanied by long-range correlations, we calculate the detrended fluctuation function F ( n ) (ref. 11 ) from the PEF series (Methods) Unexpectedly, however, albuterol increases the risk of future moderate or severe airflow obstruction beyond that seen with placebo especially for near normal values of PEF ( Fig. 3b ) Using data from a previously published, randomised, placebo-controlled, double-blind, crossover study , we analyse serial, twice-daily PEFs, together with daily asthma symptom scores, obtained in three 6-month treatment periods We also average the individual probabilities π corresponding to a set of intervals of α in the PL group, which compare well with the model predicted range We also calculate the relationship between π and PEF on an individual basis We find evidence of long-range correlations in all individuals ( Table 1 ), with trends in the LA and SA periods similar to those in Fig. 1c  We find that F ( n ) follows a power law functional form, F ( n ) ≈  n α (where n is the window size), as judged by the linear increase of F ( n ) on a double logarithmic graph in all three treatment periods ( Fig. 1c ) We find that π decreases with increasing α and is highly sensitive to the variance but less sensitive to the skewness of the model output ( Fig. 4 ) We then generate several time series, each containing 50,000 points, for various combinations of model parameters and calculate the corresponding π  When PEF is high, therefore, a high value of α is beneficial because it lowers the risk Whereas α and CV are not significantly correlated, Δ α and ΔCV are highly correlated in the PL period (coefficients: 0.026, 0.014–0.038; P 0.001) With increasing asthma severity, airways become hypersensitive to even apparently insignificant environmental factors such as small amounts of pollutants, allergens or minor viral infections, which may trigger serious and unexpected events such as an acute asthma attack caused by a sudden catastrophic collapse of large airway clusters 
 A pair of skeletons show that Guanlong wucaii (‘crowned dragon of the five-coloured rocks’; Fig. 1 ) was a 3-metre-long predator All tyrannosauroids have some ornamentation along their nasal bones, be it a row of small hornlets as in Appalachiosaurus and Alioramus , a low ridge as in Dilong , or a roughened texture like all the others Both skeletons are relatively complete, and in the smaller one, nearly the whole skeleton is still articulated, making Guanlong the best-preserved tyrannosauroid outside the Tyrannosauridae But in the 1990s, an alternative hypothesis that tyrannosaurids arose among the swift small-bodied coelurosaurs was ultimately supported by analyses that invoked the principles of cladistics. (Because cladistics provides testable hypotheses, this is now accepted as the best approach to evolutionary analysis.) However, as long as older members of the lineage leading to the Tyrannosauridae proper were unknown, it remained questionable as to which anatomical transformations shared by tyrant dinosaurs and the various other coelurosaur groups (tiny compsognathids, ostrich-like ornithomimosaurs, and feathered maniraptorans) were present owing to common ancestry, and because of evolutionary convergence But this newly discovered form has an especially impressive example — a tall, narrow projection with numerous hollow excavations Details of the anatomy of this relatively small species indicate that it is the most ancient known member of the line that led to Tyrannosaurus rex and its giant kin, the Tyrannosauridae or ‘tyrant dinosaurs’ ( Fig. 2 ) Dinosaur research — and indeed a whole swathe of palaeontology — has been revolutionized by recent discoveries in China Early Cretaceous Eotyrannus , however, was smaller (adult length perhaps 4.5 metres), and retained the long slender arms and grasping three-fingered hands of typical coelurosaurs F For most of the twentieth century, palaeontologists followed H From the Wucaiwan locality in Xinjiang come fossils of a new carnivorous dinosaur, described by Xu Xing and colleagues on page 715 of this issue  Guanlongs presence at the beginning of the Late Jurassic, and the record of compsognathids and maniraptorans somewhat later in the same epoch, indicate that the major divergences among the coelurosaurian dinosaurs had already occurred by 160 million years ago If so, the origin of all the primary lines of the coelurosaurs — including the tyrannosauroids — lies even further back In 2004, Xu Xing and colleagues described the Early Cretaceous Dilong , a 1.5-metre-long primitive carnivore with a covering of simple fuzzy ‘protofeathers’ In the past few years, several such fossils have been discovered  Indeed the fact that the smaller of the two Guanlong skeletons has a proportionately much smaller crest is consistent with the display being associated with sexual maturity Indeed, Eshanosaurus , a dinosaur known only from an Early Jurassic lower jaw found in Yunnan, may represent a relatively advanced maniraptoran  Indeed, some aspects of the pelvis are unexpectedly primitive — more typical of Triassic-to-Middle Jurassic theropods than of the more advanced forms (although such features are present in at least one other coelurosaur ) It was dwarfed by other (allosauroid and spinosauroid) predators in its environment, and probably played a secondary predatory role to its larger distant kin Its adult length of 3 metres was smaller than all later tyrannosauroids save for Dilong  Less well studied, however, are the many-coloured badlands of Xinjiang on the far western side of the country Like Eotyrannus , it was probably a secondary predator in its ecosystem, the primary predator apparently being the primitive carnosaur Monolophosaurus Guanlong combines characteristic tyrannosauroid traits (such as U-shaped teeth in the premaxilla in the front of the upper jaw, and nasal bones fused into a single unit) with primitive characters (including relatively blade-like teeth along the sides of the jaws and a powerful three-fingered hand) Most famous are the feathered dinosaurs, early flowering plants, various mammals and other spectacular fossils from the 128- to 110-million-year-old lake deposits in Liaoning Province in the northeast  Narrow mid-line crests seem to have been the fashion for Middle and Late Jurassic theropods, as they are also present in Ceratosaurus , the primitive coelurosaur Proceratosaurus , and Guanlong s possible predator Monolophosaurus (a previous record holder in terms of elaborate cranial crests among carnivorous dinosaurs) Osborn in regarding the tyrannosaurids as the last descendants of Jurassic and Early Cretaceous carnosaurian giants, such as Allosaurus and Acrocanthosaurus  Some, such as the Late Cretaceous Appalachiosaurus ( Fig. 2 , overleaf), were very close to true Tyrannosauridae in terms of size and anatomy, and, like their more specialized relatives, were probably the top carnivores of their communities  The evolution of the dis-tinctive adaptations present in the better-preserved Late Cretaceous forms such as Tyrannosaurus , Gorgosaurus and Tarbosaurus has transformed their skulls, limbs and vertebrae, thereby ‘overwriting’ much of the anatomical traces of their ancestry The evolutionary analysis by Xu et al . incorporates the new information from Guanlong , and confirms that the Tyrannosauroidea arose towards the base of the Coelurosauria The fragile nature of these structures suggests that they served for visual signalling, and so for species recognition and mating displays, rather than as weapons The most spectacular feature of Guanlong is its crest The new ‘crowned dragon’ of Xinjiang is simply the latest discovery on the trail leading back to the origin of the tyrant kings. The newly described species, Guanlong , reveals an even more primitive phase of tyrannosauroid evolution Their morphology (enlarged skulls with enormous, robust teeth; highly reduced arms ending in two-fingered hands; and elongated hindlimbs), and above all their great size (9–13 metres long for the most completely known species), have made them among the most recognizable of fossil groups  These rocks contain fossils dating to the beginning of the Late Jurassic epoch, roughly 161 million to 156 million years ago This distinctiveness, as well as their relatively rich fossil record, both in completeness of skeletons and numbers of individuals, has made the tyrannosaurids the subject of numerous palaeobiological studies  To address this question more thoroughly, fossils of more primitive members of the tyrant line were needed Tyrannosaurids were the dominant group of predators in eastern and central Asia and North America during the last 20 million years of the Late Cretaceous epoch Unfortunately, the uniqueness of the Tyrannosauridae has obscured their origin within the larger evolutionary tree of Theropoda — the clade (group) of carnivorous dinosaurs, including birds Until now, these dinosaurs represented the best record of early members of Tyrannosauroidea, a group composed of the giant two-fingered Tyrannosauridae and all of their closest kin
 ATM activates cell-cycle checkpoints and can induce apoptosis in response to DNA DSBs  ATM deficiency leads to ataxia-telangiectasia, a disease marked by lymphopenia, genomic instability and an increased predisposition to lymphoid malignancies with chromosomal translocations involving lymphocyte antigen receptor loci  Here, we show that ATM also functions directly in the repair of chromosomal DNA DSBs by maintaining DNA ends in repair complexes generated during lymphocyte antigen receptor gene assembly However, defects in these pathways of the DNA damage response cannot fully account for the phenotypes of ATM deficiency The ATM (ataxia-telangiectasia mutated) protein kinase mediates early cellular responses to DNA double-strand breaks (DSBs) generated during metabolic processes or by DNA-damaging agents  When coupled with the cell-cycle checkpoint and pro-apoptotic activities of ATM, these findings provide a molecular explanation for the increase in lymphoid tumours with translocations involving antigen receptor loci associated with ataxia-telangiectasia. All PCR titrations are serial fourfold dilutions Analysis was carried out using a Ziess Axioplan2ie epifluorescence microscope with ISIS image acquisition software. Cell culture v-Abl-transformed pre-B cell lines, derived from mice that contained the Eµ-Bcl2 transgene and different gene mutations, were generated as described in Supplementary Methods  Fluorescence in situ hybridization BACs or PCR fragments were generated for use as probes, as described in Supplementary Methods  Methods Generation of retroviral recombination substrates The pMX-INV, pMX-DEL CJ and pMX-DEL SJ retroviral recombination substrates were generated as described in Supplementary Methods  Mouse whole-chromosome paints were obtained from Applied Spectral Imaging Inc  PCR analysis of hybrid join, coding join and signal join formation in the retroviral recombination substrates was carried out using a single amplification PCR of the IL-2 gene is provided in all cases to control for the quantity of template DNA Probes were labelled with Spectrum-Red or Spectrum-Green Southern and northern blot analyses and PCR These analyses were carried out as described in Supplementary Methods  The 2E and 2F pre-B-cell lines were generated from the same Atm -/- mouse whereas the A72 pre-B-cell line was generated from a separate Atm -/- mouse The A70 and 2A pre-B-cell lines were generated from different Atm +/+ mice These retroviral substrates all contain GFP cDNA (GFP) and human CD4 cDNA downstream of an internal ribosomal entry site (IRES) They differ from each other only with respect to the orientation of the two recombination signals Vβ14 and Vδ5 coding join formation was assayed using a single amplification, whereas Vβ14 and Vδ5 hybrid joins were assayed by sequential nested PCR amplification reactions Vκ6-23 hybrid joins and coding joins were assayed by sequential nested PCR amplification reactions Accordingly, pMX-INV and pMX-DEL CJ rearrangements were assayed by Southern blotting of clones of STI571-recovered cells ( Fig. 4b , Supplementary Fig Alternatively, the coding end accumulation and increase in hybrid joins could reflect a function for ATM in maintaining coding ends in post-cleavage complexes, either by preventing coding end loss or by rapidly reclaiming released coding ends ( Fig. 4f ) Although not absolutely required for V(D)J recombination, ATM can be recruited to RAG-induced DSBs, and the phenotypes of ATM-deficient humans and mice suggest that ATM may serve important functions during antigen receptor gene assembly  Although some endogenous variable region exons are assembled by inversion, most proceed through rearrangements involving deletion of intervening sequences with chromosomal retention of coding joins An increase in Vκ6-23 to Jκ1 hybrid joins was also observed in STI571-treated Atm -/- pre-B-cell lines and in splenic B cells from Atm -/- mice, as compared to their wild-type counterparts ( Fig. 1e and Supplementary Fig Analysis of pMX-INV rearrangements in Atm -/- : INV and Atm +/+ : INV clones, and in independently derived Atm +/+ and Atm -/- pre-B-cell lines, yielded comparable results ( Supplementary Fig ATM could stabilize coding ends in post-cleavage complexes directly or through the activation of downstream targets Because the 5′ and 3′ probe sets are separated by short distances, the homologous chromosome (without pMX-INV) should yield overlapping, or coincident (C), hybridization ( Fig. 3d ) By extension, we hypothesize that this DSB repair function of ATM also leads to the general genomic instability phenotype of ataxia telangiectasia and contributes to the suppression of oncogenic translocations from different types of DNA DSBs induced in a wide variety of cells. Characterization of aberrant pMX-INV and pMX-DEL CJ rearrangements revealed that they were heterogeneous in nature and included large deletions and inversions involving the retroviral substrate, as well as translocations between the retroviral substrate and the IgLκ locus ( Supplementary Figs S17 and S18 ) Compound deficiencies in NHEJ and p53 proteins lead to a marked increase in the incidence of lymphoid tumours with antigen receptor locus translocations, whereas isolated deficiencies in either NHEJ proteins or p53 do not  Coupling normal signal end dissociation with increased coding end dissociation, during rearrangement by inversion, could lead to loss of the intervening sequence, with the remaining two chromosomal ends (coding end and signal end) forming a hybrid join ( Fig. 4f pathway A.1) Decreased normal rearrangement and increased hybrid join formation were also observed in Atm +/+ : INV pre-B cells treated with STI571 and the ATM kinase-specific inhibitor KU-55933 ( Supplementary Fig Dissociated coding ends would accumulate in ATM-deficient cells and may participate in aberrant rearrangements such as translocations ( Fig. 4f , pathway B) DNA cleavage occurs only after the two recombination signals are brought together in a synaptic complex and leads to the formation of a pair of blunt phosphorylated signal ends and a pair of hairpin-sealed coding ends  First, they are not present in cells after recovery from STI571 treatment, demonstrating that they are not due to stably joined products (R lanes, Fig. 3a , b ) FISH analysis of nuclei from STI571-treated Atm -/- : INV-26 cells revealed that 4.2% had a C/NC hybridization pattern ( Fig. 3e , f ) FISH probe sets spanning the pMX-INV integrants in Atm -/- : INV-26 and Atm +/+ : INV-4 were generated and labelled with Spectrum-Red (5′ probe set) or Spectrum-Green (3′ probe set) ( Supplementary Fig Flow cytometric and Southern blotting analyses revealed that the level of normal pMX-INV rearrangement in STI571-treated Atm -/- : INV cells was half that observed for Atm +/+ : INV or Atm +/- : INV cells ( Fig. 1b–d and Supplementary Fig For example, thymic lymphomas with chromosomal translocations involving the T-cell receptor (TCR) α/δ locus in Atm -/- mice are dependent on RAG expression  Furthermore, increased hybrid joins involving Vβ14 and Vδ5 were found in thymocytes from Atm -/- mice ( Supplementary Fig Furthermore, whole-chromosome paint analyses revealed reciprocal translocations between chromosome 6 (which contains the IgLκ locus) and chromosomes harbouring pMX-DEL CJ , as well as other chromosomes ( Fig. 4a and Supplementary Fig Here we demonstrate that ATM functions in the repair of chromosomal DNA DSBs generated during V(D)J recombination Here we show that, in addition to checkpoint activation, ATM is also directly involved in the repair of RAG-induced DSBs How can the selective increase in hybrid join formation during rearrangement by inversion in ATM-deficient cells be explained? We considered the possibility that this may be due to a requirement for ATM in maintaining the stability of post-cleavage DNA end complexes However, analysis of STI571-recovered Atm -/- : DEL SJ clones revealed that aberrant pMX-DEL SJ rearrangements are rare and occur at a frequency similar to that observed in STI571-recovered Atm +/+ : DEL SJ clones ( Fig. 4c and Supplementary Fig However, the increase in hybrid join formation during rearrangement by inversion cannot be solely attributed to a defect in NHEJ, because these activities are normally required for efficient hybrid join formation in cells expressing full-length RAG proteins  However, this activity would have to be specific for rearrangements by inversion, as increased hybrid joins were not observed in ATM-deficient cells during rearrangements by deletion Hybrid join sequences were diverse, including nucleotide loss and the addition of both palindromic and non-templated nucleotides ( Supplementary Fig Hybrid joins involving endogenous Vβ gene segments that rearrange by deletion could not be detected by PCR in either Atm -/- or Atm +/+ thymocytes (data not shown) If the NC hybridization pattern is due to dissociated broken DNA ends, passage of these cells into the S phase should lead to the generation of replicated chromosomal breaks, as was observed for DSBs generated during immunoglobulin class switch recombination in proliferating ATM-deficient B cells  If this notion is correct, it would be expected that any DNA end(s) may be lost from post-cleavage complexes in ATM-deficient cells In agreement, PCR and flow cytometric analyses revealed comparably low levels of pMX-DEL CJ hybrid joins in STI571-treated Atm +/+ : DEL CJ and Atm -/- : DEL CJ pre-B cells ( Fig. 2c and Supplementary Fig In contrast to coding ends in Atm -/- : DEL CJ cells, signal end accumulation was not observed during pMX-DEL SJ rearrangement in Atm -/- : DEL SJ pre-B cells ( Fig. 4d , e ) In contrast to pMX-INV rearrangements, pMX-DEL CJ hybrid joins were not detected by Southern blot analyses of STI571-treated Atm -/- : DEL CJ pre-B cells ( Fig. 2b ) In contrast to SCID cells, this band becomes smaller and diffuse in size in Atm -/- cells over time, suggestive of hairpin opening and exonucleolytic processing ( Fig. 3a , b ) In contrast, during rearrangement by deletion, loss of the intervening sequence leaves two chromosomal coding ends, which would form a coding join ( Fig. 2a ) In this regard, loss of the intervening sequences (GFP cDNA) during pMX-INV rearrangement would leave the 5′ signal end and 3′ coding end that, if joined, would form a chromosomal hybrid join, whereas loss of this intervening sequence during pMX-DEL CJ rearrangement would leave 5′ and 3′ coding ends that would form a chromosomal coding join (Figs 1a and 2a ) In this regard, RAG has been shown to bind avidly to signal end pairs, forming stable signal end complexes after cleavage in vitro , and thus may perform the same function during chromosomal V(D)J recombination in vivo  In this regard, truncated RAG proteins can catalyse hybrid join formation by transposition; thus, ATM could modulate the transposition capability of full-length RAG proteins in vivo  Indeed, a band of the expected size for an unrepaired 3′ coding end from pMX-INV was observed in a significant fraction of STI571-treated Atm -/- : INV pre-B cells (3′ CE band, Figs 1a and 3a , c ) Indeed, metaphase FISH analysis of Atm -/- : INV and Atm -/- : DEL CJ clones released from STI571 treatment (hereafter referred to as STI571-recovered cells) revealed that approximately 2% contained replicated chromosomal breaks spanning the retroviral integrant ( Supplementary Fig It is also possible that an unpaired coding end may be able to disrupt a signal end complex exclusively during rearrangements by inversion, leading to the formation of a hybrid join ( Fig. 4f , pathway A.2) It is possible that signal ends do not accumulate in ATM-deficient cells because they are rapidly resolved as aberrant rearrangements after their loss from post-cleavage complexes It is possible that the accumulation of coding ends and increase in hybrid joins result from defects in distinct ATM-dependent pathways Like pMX-DEL CJ , pMX-DEL SJ underwent robust rearrangement in Atm -/- : DEL SJ cells, forming a high frequency of precise signal joins ( Fig. 4d and Supplementary Fig. 19b ) Metaphase FISH analyses of STI571-recovered Atm -/- : DEL CJ clones revealed that approximately 3% had karyotypic abnormalities, including replicated chromosomal breaks, translocations and complex rearrangements occurring at the pMX-DEL CJ integration site ( Fig. 4a and Supplementary Figs S14 and S15 ) Moreover, a band consistent in size with an unrepaired 3′ coding end from pMX-DEL CJ was observed in STI571-treated Atm -/- : DEL CJ , but not Atm +/+ : DEL CJ , pre-B cells ( Fig. 3b , c ) Notably, 10–14% of the STI571-recovered Atm -/- : INV-26 and Atm -/- : DEL CJ -50 clones had aberrant rearrangements, whereas only 1% of the STI571-recovered Atm +/+ : INV-4 and Atm +/+ : DEL CJ -119 clones had such events ( Fig. 4c and Supplementary Fig Notably, the kinetics and level of hybrid join and coding join formation were similar in Atm -/- : INV cells, demonstrating that, in the absence of ATM, hybrid join formation is a frequent outcome of pMX-INV rearrangement ( Fig. 1c , d and Supplementary Fig One of the hallmarks of ataxia-telangiectasia is the generation of aberrant rearrangements during V(D)J recombination, such as translocations, large chromosomal deletions and inversions  Our findings provide a potential molecular explanation for the increased incidence of lymphoid tumours with antigen receptor locus translocations in ataxia-telangiectasia Polymerase chain reaction (PCR) analyses confirmed an approximate 60-fold increase in hybrid join formation in STI571-treated Atm -/- : INV cells, as compared to Atm +/+ : INV cells ( Supplementary Fig Pre-B-cell lines were transduced with the pMX-RSS-GFP/IRES-hCD4 retroviral recombination substrate, hereafter referred to as pMX-INV ( Fig. 1a ) . pMX-INV has a single pair of recombination signals that flank an anti-sense green fluorescent protein (GFP) cDNA and mediate recombination by inversion Pre-B-cell lines with pMX-INV integrants at diverse genomic sites ( Atm +/+ : INV , Atm +/- : INV and Atm -/- : INV ) were isolated by flow cytometric cell sorting for the retrovirally encoded hCD4 ( Supplementary Fig S1 )  S10a ) S10b, c and data not shown) S11a, b ) S11c ) S14 ) S14 ) S15 ) S16a and data not shown) S16b, c ) S16b, c ) S19a ) S19a ). pMX-DEL SJ is identical to pMX-DEL CJ except that the recombination signals have been inverted such that rearrangement, which occurs by deletion, leaves the signal join in the chromosome ( Supplementary Fig S19c ) S2 ) S3a, b ) S3a–c ) S3b ) S3d, e ) S4 ) S5 )  S6 ) S7 ) S8 ) S9 ) Second, a band of similar size is observed in STI571-treated pre-B cells derived from severe combined immunodeficient (SCID) mice, which have a defect in coding join formation and accumulate hairpin-sealed coding ends ( Fig. 3a )  Several lines of evidence demonstrate that these bands represent unrepaired 3′ coding ends Significant differences in cell viability or changes in the fraction of hCD4-expressing cells were not observed during the course of STI571 treatment ( Supplementary Fig Significant signal end accumulation was observed during pMX-DEL SJ rearrangement in Ku70 -/- pre-B cells (data not shown) Similar defects are not observed in mice deficient in p53 or Chk2 proteins, which, upon activation by ATM, enforce the G1/S checkpoint and ultimately promote apoptosis if DNA DSBs are not repaired  Similar results were observed upon analyses of G1 nuclei from Atm -/- : DEL CJ and Atm +/+ : DEL C J clones ( Supplementary Figs S12 and S13 ) Southern blot analysis of STI571-treated Atm -/- : INV pre-B cells, but not Atm +/+ : INV pre-B cells, revealed a novel band of the size expected for joining of the 3′ coding end and 5′ signal end of pMX-INV (HJ band, Fig. 1c ) Southern blot analysis of these cells revealed that 15% had unrepaired pMX-INV 3′ coding ends (data not shown) Such replicated chromosomal breaks were not observed in STI571-recovered parental Atm -/- cells or in Atm +/+ : INV and Atm +/+ : DEL CJ clones ( Supplementary Fig The accumulation of unrepaired coding ends in ATM-deficient cells could reflect a requirement for ATM in the recruitment and/or function of NHEJ proteins, as has been suggested for the repair of some DSBs generated by DNA-damaging agents  The chromosome with pMX-INV could yield non-coincident (NC) probe set hybridization if DNA ends have dissociated from post-cleavage complexes; otherwise this chromosome should yield coincident probe set hybridization The difference in the fraction of nuclei with C/NC hybridization and those with 3′ coding ends could be due, in part, to DNA ends that have dissociated at distances not resolved by FISH The exons encoding the variable region of lymphocyte antigen receptors are assembled through the process of V(D)J recombination  The fraction of clones with normal or hybrid join rearrangements was in agreement with pMX-INV and pMX-DEL CJ rearrangement in bulk pre-B-cell populations ( Supplementary Fig The full spectrum of aberrant rearrangements in ATM-deficient cells may not be detected through cytogenetic analyses such as those described above The joining of a signal end to the coding end generated by cleavage at the other recombination signal results in a hybrid join  The parental Atm -/- pre-B-cell line, which does not contain a pMX-INV integrant, yielded only the C/C probe hybridization pattern, and the Atm +/+ : INV-4 clone yielded only 1 nucleus (of 450) with a C/NC hybridization pattern ( Fig. 3e , f and Supplementary Fig The signal end and coding end pairs are processed and joined by non-homologous end-joining (NHEJ) DSB repair proteins to generate a signal join and coding join, respectively  Therefore, we reasoned that two distinct hybridization patterns would be found, C/C or C/NC ( Fig. 3d ) These abnormalities were rarely observed in untreated Atm -/- : DEL CJ or STI571-recovered Atm +/+ : DEL CJ clones ( Supplementary Figs S14 and S15 ) These findings demonstrate that, unlike coding ends, ATM function is not required to maintain signal ends in post-cleavage complexes Third, a ligation-mediated PCR product of the expected size for a 3′ coding end was observed only in STI571-treated Atm -/- : INV and Atm -/- : DEL CJ cells, with the identity of this product verified by sequence analyses ( Supplementary Fig This band was not present in STI571-treated Atm +/+ : INV cells, but was in Atm +/+ : INV cells treated with STI571 and the ATM kinase inhibitor KU-55933 ( Fig. 3a and Supplementary Fig This reaction occurs only in developing lymphocytes at the G1 phase of the cell cycle, and is initiated when the recombinase-activating gene-1 and -2 protein complex (hereafter referred to as RAG) introduces DNA DSBs at the border of two gene segments and their flanking recombination signals  Thus, ATM deficiency leads to an increase in hybrid join formation during rearrangements that occur by inversion, but not during those that occur by deletion Thus, increased hybrid join formation is a general feature of rearrangements that occur by inversion in Atm -/- B and T cells Thus, normal rearrangement places the GFP cDNA in the sense orientation, allowing for GFP expression ( Fig. 1a , b ) Thus, the generation of these oncogenic lesions requires both defects in DSB repair (NHEJ deficiency) and defects in DSB-induced checkpoints/apoptosis (p53 deficiency)  Thus, the singular deficiency of ATM would result in compound defects in both DSB-induced checkpoints/apoptosis and DSB repair, resulting in a predisposition to lymphomas with chromosomal translocations involving antigen receptor loci Thus, to determine whether hybrid join formation is a general feature of V(D)J recombination in Atm -/- cells, we generated the pMX-DEL CJ substrate ( Fig. 2a ). pMX-DEL CJ differs from pMX-INV only by the inversion of the 5′ recombination signal and its immediate flanking sequences and, therefore, undergoes rearrangement by deletion with chromosomal retention of the coding join ( Fig. 2a ) To address whether ATM is required to maintain signal end complexes, we generated the pMX-DEL SJ retroviral recombination substrate ( Supplementary Fig To assess directly whether coding ends are lost from post-cleavage complexes in ATM-deficient cells, we carried out fluorescence in situ hybridization (FISH) on G1 nuclei from STI571-treated pre-B cells To elucidate potential ATM functions, we developed an experimental approach in which RAG-generated DNA DSBs can be induced, and their repair tracked, in G1-arrested wild-type and ATM-deficient cells To this end, pre-B-cell clones with single pMX-INV integrants were isolated ( Atm -/- : INV-26 and Atm +/+ : INV-4 ) ( Supplementary Figs S5 and S10a ) Together, these findings demonstrate that ATM deficiency leads to reduced levels of normal pMX-INV rearrangement that can not be attributed to defects in ATM-mediated G1/S checkpoint enforcement or apoptosis Together, these findings demonstrate that coding ends can become dissociated from post-cleavage complexes generated during V(D)J recombination in G1-phase ATM-deficient cells Together, these findings demonstrate that the accumulation of unrepaired coding ends is a common outcome of V(D)J recombination in ATM-deficient cells, and that these coding ends are subject to hairpin opening and exonucleolytic processing Together, these findings suggest that ATM has additional undefined functions in the response to DNA DSBs generated during V(D)J recombination Treatment of pre-B-cell lines with the Abl kinase inhibitor, STI571, leads to a rapid induction of RAG gene expression and a block in the G1-to-S transition that does not depend on RAG-induced DNA DSBs ( Supplementary Fig Viral (v)-Abl kinase-transformed pre-B-cell lines were generated from multiple Atm +/+ , Atm +/- and Atm -/- mice expressing an Eµ-Bcl2 transgene We took several approaches to assay for similar aberrant rearrangements involving retroviral recombination substrates in STI571-recovered Atm -/- pre-B cells
 Alternatively, PINK1 may phosphorylate parkin and directly influence its activity Although the specific tissues affected by loss of PINK1 function differ in flies and humans, the fact that each of the tissues affected by PINK1 mutations in the fruitfly has mitochondrial defects strongly suggests that the neurodegeneration in humans with PINK1 mutations is also caused by mitochondrial dysfunction Although there is substantial evidence in vitro that parkin can work as a ubiquitin ligase, few of the reported substrates of parkin have been validated in vivo Another model to explain the current findings is that PINK1-induced mitochondrial impairment leads to secondary dysfunction of the UPS, which can be ameliorated by over-expression of parkin Both papers also show that PINK1 – parkin double mutants have symptoms that are indistinguishable from those seen in the single mutants Both papers show that fruitflies bearing mutations in the fly version of PINK1 display degeneration of flight muscles and defective sperm formation By contrast, the DJ-1 -mutant fruitflies are quite different from parkin and PINK1 mutants, suggesting that DJ-1 influences different pathways Chemicals that inhibit the mitochondrial ‘complex I’ can reproduce many features of Parkinsons disease in experimental systems  Finally, it remains possible that parkin has a functional role in mitochondria that does not involve its ubiquitin-ligase activity For example, the products of two of the genes mutated in Parkinsons disease — parkin and ubiquitin carboxy-terminal hydrolase L1 — are components of the ubiquitin–proteasome system (UPS) that degrades damaged or misfolded proteins Furthermore, there is evidence that parkin can regulate the biogenesis of mitochondria  Future experiments to delineate the PINK1–parkin pathway should clarify the mechanisms underlying neuro-degeneration in Parkinsons disease and shed light on some very basic questions of mitochondrial biology. However, a problem with the latter model is that most data suggest that PINK1 protein resides primarily in mitochondria and that parkin lies outside mitochondria However, a small fraction of cases (probably less than 10%) is caused by single-gene mutations However, PINK1 overexpression does not detectably influence the characteristics of the parkin mutants In this issue, Clark et al . ( page 1162 ) and Park et al . ( page 1157 ) provide clues to the basis of degeneration in Parkinsons disease by linking two causative mechanisms that were previously thought to be separate In this regard, there is evidence that parkin mutations are associated with complex I defects and that complex I defects can inhibit the UPS in animal models of Parkinsons disease  Indeed, the strikingly similar characteristics of the PINK1 - and parkin -mutant fruitflies, including flight-muscle degeneration, sperm-formation defects and mitochondrial abnormalities, alone argue that these two genes act in a common pathway Interestingly, the similarities between the PINK1 - and parkin -mutant fruitflies parallel a recent clinical study showing that in humans PINK1 and parkin mutations can produce similar symptoms  Mitochondrial defects were also observed in parkin-deficient mice and humans  Moreover, both papers show that overexpression of parkin compensates for a lack of PINK1, preventing the effects of the PINK1 mutation Moreover, duplication or triplication of the normal alpha-synuclein gene causes Parkinsons disease, and overexpression of alpha-synuclein inhibits UPS function Most cases of typical ‘sporadic’ Parkinsons disease are believed to result from a lifetime of environmental exposures superimposed on an individuals genetic susceptibilities Nevertheless, it remains possible that the localization of either parkin or PINK1 changes upon stress, and there are several reports, including that from Park et al . , that have argued that at least some parkin associates with mitochondria Of course, things are rarely so simple, and the first inkling that things were not quite as they seemed came from studies showing that overexpression of parkin in cultured cells delays toxin-induced mitochondrial dysfunction and that fruitflies that lack the parkin gene have prominent mitochondrial abnormalities in many tissues  Other single-gene mutations point to Parkinsons disease being associated with defects in mitochondria — the organelles that carry out respiration in the cell Park et al . also report that the PINK1 -mutant flies show loss of dopamine neurons — a type of neuron known to degenerate in Parkinsons disease — with an accompanying mitochondrial swelling Parkin, a component of the UPS, is thought to act as a ubiquitin E3 ligase, an enzyme that directs proteins destined for destruction to the proteasome by tagging them with a ubiquitin group Parkinsons disease was first described in 1817, but our understanding of what causes the neurodegeneration that underlies its devastating symptoms is still rudimentary So, it looked as though there was the beginning of a nice, neat parcelling of two distinct mechanisms that cause Parkinsons disease: UPS dysfunction and mitochondrial impairment Such poor understanding hinders the development of therapies, which currently dont seem to modify disease progression, even if they can mitigate for a time some of the movement difficulties that characterize this condition The DJ-1 protein has a role in the oxidative stress response; under oxidative conditions, some of the cellular DJ-1 moves to mitochondria where its function remains to be elucidated The mitochondrial hypothesis of Parkinsons disease was put on even firmer footing with the discoveries of causative mutations in the DJ-1 and PINK1 genes The PINK1 protein is found primarily in mitochondria, and it is predicted to be a kinase (an enzyme that adds phosphate groups to other proteins), although its substrates are unknown  The real surprise and importance of these papers is the finding that parkin seems to act downstream from PINK1 in a common pathway that influences mitochondrial integrity These provide insights into the cellular pathways involved in neurodegeneration  This finding is interesting, but not unexpected Together, this evidence strongly implicates dysfunction of UPS in the development of Parkinsons disease Using a combination of biochemical and imaging approaches, these researchers further report that mitochondrial defects accompany both of these abnormalities What is the nature of the pathway regulated by PINK1 and parkin? The simplest inter-pretation of the data is that PINK1 decreases parkin abundance by reducing the level of parkin messenger RNA or protein Why would loss of this protein cause mitochondrial dysfunction? Now Clark et al . and Park et al . raise additional questions about what parkin is — or isnt — doing to cause Parkinsons disease, although the primary focus of these papers is the PINK1 gene
 After the earthquakes, the phase gradually returns to the background value at a rate of less than 0.1° per day At the time of each of seven earthquakes in Southern California, we observe transient changes of up to 24° in the phase of the water level response to the dilatational volumetric strain of the semidiurnal tidal components of wells at the Piñon Flat Observatory in Southern California At the time of the earthquakes, the permeability at the site increases by a factor as high as three Distant earthquakes may even increase the permeability in faults  Earthquakes have been observed to affect hydrological systems in a variety of ways—water well levels can change dramatically, streams can become fuller and spring discharges can increase at the time of earthquakes  Here we use the response of water well levels to solid Earth tides to measure permeability over a 20-year period Most of these hydrological observations can be explained by some form of permeability increase  Such permeability increases are of interest to hydrologists and oil reservoir engineers as they affect fluid flow and might determine long-term evolution of hydrological and oil-bearing systems The permeability increase depends roughly linearly on the amplitude of seismic-wave peak ground velocity in the range of 0.21–2.1 cm s -1  They may also be interesting to seismologists, as the resulting pore pressure changes can affect earthquakes by changing normal stresses on faults . We interpret the changes in phase response as due to changes in permeability We use a model of axisymmetric flow driven by an imposed head oscillation through a single, laterally extensive, confined, homogeneous and isotropic aquifer to relate the phase response to aquifer properties  Additional factors in the response in the most general case also include the well geometry, the period of the oscillation and inertial effects As a check, we performed a second analysis in the frequency domain by dividing the Fourier transform of the observed tide and a synthetic tide, and taking the result at the frequency of the largest semidiurnal tide ( M 2 ) Because none of the other parameters are likely to change during an earthquake, changes in transmissivity are interpretable as changes in permeability Flow model In estimating aquifer properties, we follow ref. 9 in modelling the tidal response as a result of flow in a single, laterally extensive, confined, homogeneous and isotropic aquifer In an isotropic system, the far-field tidal head oscillation is proportional to the volumetric strain In reality, it is unlikely that the aquifer is either homogeneous or isotropic Methods Tidal response The phase and amplitude tidal responses were estimated using two separate methods which yielded nearly identical results Once the diffusion time is known, we can calculate the leakage following ref. 3  Storage is the strain change per unit imposed head and is a measure of compressibility The amplitude A and phase η responses for the long periods of tidal oscillations are : A = ( E 2 + F 2 ) - 1 2 (2) η = -tan -1 ( F / E ) (3) where E ≈ 1 - ω  r c 2 2 T Kei ( α ),  F ≈  ω  r c 2 2 T Ker ( α ),  α = ωS T 1 2 r w (4) and T is the transmissivity, S the dimensionless storage coefficient, Ker and Kei the zeroth-order Kelvin functions, r w is the radius of the well (8.8 cm for CIB, 9.1 cm for CIC), r c is the inner radius of the casing (7.9 cm for both wells) and ω  is the frequency of the tide The diffusion time of the leakage is known from the recovery time of water level drops after earthquakes The inertial effects are negligible for the long periods of the Earth tides  The measurements in Fig. 3 were derived using a least-squares fit of the observed water level data to the predicted tides based on a high-precision ephemeris (see Supplementary Information ) The most important omitted effect is the coupling of shear stresses to pore pressure by anisotropic fractures  The other two factors are independently well constrained The permeability changes are robust and the results are indistinguishable from the time-domain calculation The relationship between transmissivity and permeability is: k = µ ρgd T (5) where k is the permeability, µ is the dynamic viscosity, ρ  is the density, g is the gravitational acceleration and d is aquifer thickness The relative measurements we make using the Hsieh model should be robust to these complications The semi-confined aquifer leaks, so this correction is necessary to account for the small amount of pore pressure diffusion to the free surface The storage shows only small ( 40%) changes as a function of time The values used are µ = 10 -3  Pa s, ρ  = 10 3  kg m -3 , g = 9.8 m s -2 and d = 150 m. The well response depends on the flow of water through the porous medium and therefore is sensitive to the aquifer transmissivity and storage This complication would introduce a phase shift to all of our measurements and therefore bias our permeability estimates; however, the imposed phase shift should not change over time This result is a direct consequence of the lack of large variations in the amplitude response Transmissivity is the rate of water transmission through a unit width of aquifer under a unit hydraulic gradient and is directly proportional to permeability We corrected for the water table effect on the phase shift by adding 15° to the observed lags We use the measured phase and the amplitude responses η and A with equations (2) and (3) to solve for storage and transmissivity A commonly reported hydrological response to earthquakes is a drop in water level  A key, unresolved problem is the relationship between these drops and the permeability enhancement recorded by the tidal phase change As can be seen in Fig. 4 , the resulting permeability changes followed the linear trend previously defined by the other data points As discussed above, the smallest lags (closest to zero) imply the highest permeabilities in the system Assuming c to be 3 km s -1 , R CIB ≈ 3.0 × 10 -10  m 2 and R CIC ≈ 8.4 × 10 -10  m 2  Because of this difference, we are not surprised that the tidal response changes reveal a much more systematic relationship to PGV than is observed for water level changes in these wells Both are cased to 61 m and neither is pumped But all earthquakes produced a decrease in the phase lag Each transient change is characterized by a step in the phase response at the time of the earthquake followed by a gradual recovery of the phase to its pre-earthquake value Figure 1 shows the long-term water-level changes in these wells, driven in part by local precipitation; the inset shows the oscillations from the Earth tides Figure 4 plots the inferred changes in permeability at the time of the earthquakes against the PGV First, we have demonstrated the utility of a simple, non-invasive method for monitoring permeability in confined aquifers or reservoirs For PGV values above 0.2 cm s -1 , the data show a linear relationship between the permeability change and the ground shaking: Δ k = R v c (1) where Δ k is the change in permeability at the time of the earthquake, v is PGV in the vertical and c is the phase velocity of the seismic waves For the hydraulic diffusivities that we infer from the PFO wells and the semidiurnal tidal period, this distance is of the order of 200 m Fourth, and most speculatively, the fractures and flow resulting from such permeability-enhancement processes in faults might be a stage in the dynamic triggering of earthquakes . If the permeability is low, then the water level oscillations lag significantly behind the solid Earth tidal strain as it takes some time for water to flow into the well If the permeability of the aquifer is high, then the oscillations in the well are nearly in phase with the imposed tidal strain In between the extremes, there is a finite phase lag of the tidal oscillations in the well relative to the imposed tidal strain In this study we consider water level data ( Fig. 1 ) from two water wells in fractured granodiorite at Piñon Flat Observatory (PFO) in southern California (33.610° N, 116.457° W)  It is also the first definitive relationship between measured permeability increases and other measured stresses in the field It is the first direct measurement of well-defined permeability increases in a natural setting before and after multiple earthquakes at the same site Negative phases imply greater delay, so we refer to less negative phase shifts as smaller phase lags On the other hand, persistent water level drops can record localized changes Permeability in a fractured rock system was increased significantly by the small stresses in seismic waves from regional earthquakes Regardless of the detailed hydrological model, a phase lag decrease corresponds to an increase in permeability, which is unlikely to be produced by local compression and is extremely unlikely to be caused by both extension and compression Second, the data indicate that relatively small dynamic stresses can double or triple permeability and therefore suggests a possible method for active permeability enhancement in economically useful geothermal, natural gas and oil reservoirs  The amplitude changes are relatively easily mapped into small storage changes and, unlike the phase, they are nearly insensitive to the permeability changes The change in static stress field and the dynamic stress from the seismic waves are both candidates The dashed lines in Fig. 1 show the times of earthquakes ( Fig. 2 ) that produced large shaking (see legend of Fig. 1 ) The dynamic, rather than static, strains are the probable cause, and we use the vertical peak ground velocity (PGV) as a proxy for the dynamic strain field ( Fig. 2 ) The measurements led to a new and, to us, surprising conclusion The observed changes at the times of the earthquakes imply that some earthquake-induced stress affected these well–aquifer systems The parameter R is a property of the well–aquifer system and is different for each well The peak dynamic stress σ  can be estimated from the PGV using the relationship σ  = µv / c where v is PGV, c is the phase velocity (as above) and µ is the shear modulus (∼3 × 10 10  Pa), giving values in the range of 0.02 to 0.21 MPa for PGV in the range 0.2 to 2.1 cm s -1 ( Fig. 2 ). (Previous studies in intact laboratory samples had suggested that stresses of the order of 100 MPa were necessary to cause the large changes in the permeability that we observe.) The increases are systematic and even predictable The phase change is the difference between two measurements made before and after each earthquake over 200-h windows (see Supplementary Figs S3 and S4 ) The phase lags provide a means of measuring permeability The phases recover linearly with time, though with different rates for the two wells: 0.08° per day for CIB and 0.04° per day for CIC The pressure in confined aquifers continually oscillates in response to the solid Earth tide The ratio v / c is approximately the imposed strain on the system , so R measures the permeability response to strain The static stress change for areal strain has the same sign as the first motion on seismograms, and for these earthquakes the first motions at PFO include both extension and compression The tidal phase averages the properties over an effective volume extending a distance of the order of from the well, where κ is the hydrologic diffusivity (equal to the ratio of transmissivity and storage) and τ  is the tidal period The two wells are 300 m apart, which is consistent with differing responses The volumetric strain of the Earth tide increases the pore pressure in the confined aquifer The wells (CIB and CIC) are 300 m apart, and were drilled in 1981 to depths of 211 m and 137 m, respectively There is a roughly linear relationship between the PGV and the permeability change at each well for the range of measured PGVs Therefore, a pressure gradient is generated and the water flows in and out of the well, producing oscillations in water level These Piñon Flat wells show water level drops for four of our study earthquakes Third, the large variations of permeability over time indicate that natural permeability is not a fixed quantity, but rather an ever-evolving, dynamically controlled parameter This example provided a good opportunity to test equation (1)  This is supported by calculations of static fields at PFO, which also show compression for Northridge and Anza 2001, but extension for all other earthquakes ( Supplementary Table S1 ) This result has potentially far-reaching consequences To the best of our knowledge, the tidal responses measured here provide the first published long-term monitoring of permeability in a natural system Transient changes in the phase response are plainly seen in Fig. 3 at the times of all the earthquakes (dotted lines) We also evaluated the amplitude of the tidal response, which shows much smaller variations, especially in well CIC (see Supplementary Information ) We derived this relationship before the 2005 Anza earthquake, which generated the largest shaking at PFO yet recorded We measure the PGV directly from seismic records at PFO We measure the phase shift of the water level relative to the dilatational strain for the semidiurnal tides (See Methods and Supplementary Information ) We note that the tidal phase and the water level are sensitive to different regions of the well–aquifer system We quantitatively interpret aquifer phase lags as permeability (see the Methods section), following the methods of refs 9 and 3  We use the response of wells to solid Earth tidal strains as a probe of the in situ permeability to provide a long-term, continuous record of permeability evolution 
 But the molecular underpinnings of the avascular phenotype have until now remained obscure and are all the more remarkable given the presence in the cornea of vascular endothelial growth factor (VEGF)-A, a potent stimulator of angiogenesis, and the proximity of the cornea to vascularized tissues Corneal avascularity—the absence of blood vessels in the cornea—is required for optical clarity and optimal vision, and has led to the cornea being widely used for validating pro- and anti-angiogenic therapeutic strategies for many disorders  Here we show that the cornea expresses soluble VEGF receptor-1 (sVEGFR-1; also known as sflt-1) and that suppression of this endogenous VEGF-A trap by neutralizing antibodies, RNA interference or Cre-lox-mediated gene disruption abolishes corneal avascularity in mice Manatees, the only known creatures uniformly to have vascularized corneas , do not express sflt-1, whereas the avascular corneas of dugongs, also members of the order Sirenia, elephants, the closest extant terrestrial phylogenetic relatives of manatees, and other marine mammals (dolphins and whales) contain sflt-1, indicating that it has a crucial, evolutionarily conserved role The recognition that sflt-1 is essential for preserving the avascular ambit of the cornea can rationally guide its use as a platform for angiogenic modulators, supports its use in treating neovascular diseases, and might provide insight into the immunological privilege of the cornea. The spontaneously vascularized corneas of corn1 and Pax6 +/- mice and Pax6 +/- patients with aniridia are deficient in sflt-1, and recombinant sflt-1 administration restores corneal avascularity in corn1 and Pax6 +/- mice [competing interests: ] Alternatively, it might be a vestigial residue of an evolutionary requirement to provide blood to the eye that later required biochemical compensation in the form of sflt-1 expression to support improved vision Although hypoxia can increase VEGF-A production, free VEGF-A was not significantly elevated in hypoxic corneas (11 ± 23% greater than non-hypoxic corneas; n   =  9; P   =  0.78) Although it is unknown why these mice do not express sflt-1 in the cornea, it is notable that both strains have abnormalities in their corneal epithelium , the predominant source of sflt-1. sflt-1/Fc injection significantly reduced the area of corneal vascularization in corn1 and Pax6 +/- mice compared with both IgG/Fc treated and untreated corneas ( Fig. 4b, c ), both implying that sflt-1 has a significant role in maintaining corneal homeostasis and suggesting that it might be possible to rescue corneal vascularization in a clinical setting Although mutations in destrin, the protein that is altered in corn1 mice, have not been reported in humans, Pax6 mutations are present in patients with aniridia, who also have vascularized corneas  Although neither mbflt-1 nor VEGFR-2 is expressed in the normal cornea ( Fig. 1g , Supplementary Fig. 10 ), such heterodimerization might modulate pathological vascularization of the cornea Although the absence of blood vessels in the cornea was known to the ancients, such as Susruta and Galen , millennia ago, it was only in the last century that angiostatic substances were postulated to underpin corneal avascularity  Apart from trapping VEGF-A, sflt-1 can heterodimerize with mbflt-1 and VEGFR-2 (ref. 11 ) Apart from VEGF-A, sflt-1 also binds VEGF-B and placenta growth factor (PlGF) Because of its avascularity and ease of accessibility, the cornea has been a proving ground for anti-angiogenic strategies for more than 30 years  Because the anti-flt-1 antibody would theoretically block ligand-binding by both mbflt-1 and sflt-1 (although the former is undetectable in the cornea), we tested this antibody in flt-1 tyrosine kinase -/- ( flt-1 tk -/- ) mice, which are deficient in signalling induced by ligation of the flt-1 receptor  But none of these molecules is required for corneal avascularity, because mice deficient in any of them retain normal corneal phenotypes  By contrast, elevation of VEGF-A without concomitant induction of sflt-1, which was modelled by injection of recombinant VEGF-A, was reversed by administration of recombinant sflt-1/Fc but not of isotype control IgG/Fc ( Supplementary Fig. 8 ), confirming its specificity Consistent with its proposed function as a trap for secreted VEGF-A, sflt-1 was present extracellularly ( Supplementary Fig. 2 ) Corneal injection of p 2 shRNA-sflt-1 also induced corneal vascularization in wild-type mice ( n   =  10; Supplementary Fig. 7a ), making it unlikely that off-target effects, which are sequence-specific and not target-specific, were responsible for loss of corneal avascularity Corneal vascularization was induced by pshRNA-sflt-1, but not pshRNA-mbflt-1, within 3 days of injection ( n   =  36, P   0.0001) ( Fig. 3d–f ). pshRNA–sflt-1 also induced corneal vascularization in mice that had been systemically depleted of macrophages and neutrophils by treatment with clodronate liposomes and anti-Gr-1 antibodies ( Supplementary Fig. 6a–c ), indicating that corneal vascularization was not induced by infiltration of inflammatory cells and their delivery of VEGF-A Corneal vascularization was induced by pshRNA–sflt-1, but not pshRNA–mbflt-1, in flt-1 tk -/- mice ( n   =  8; P   =  0.029) just as in the wild type, indicating that sflt-1 and not flt-1-TM is required for corneal avascularity Corneas of corn1 and Pax6 +/- mice, unlike those of their background strains, were deficient in sflt-1 ( Fig. 4a ) Corneas treated with anti-flt-1 antibodies contained more free VEGF-A than did control-treated corneas ( Supplementary Fig. 4c ), indicating that sequestration of VEGF-A by sflt-1 maintains corneal avascularity Despite profound hypoxia, these corneas remained avascular ( n   =  20) Direct evidence for this assertion was obtained by showing that corneal vascularization induced by pshRNA–sflt-1 in wild-type mice was prevented by a neutralizing anti-VEGF-A antibody but not by isotype-control antibodies ( n   =  10; P   =  0.008) Expression of Cre was accompanied by significantly reduced sflt-1 and increased free VEGF-A ( Supplementary Fig. 5c, d ) Expression of these ligands in mouse corneas was much less than that of VEGF-A (data not shown) Eyes that were treated with blocking antibody consistently developed corneal vascularization from the limbus within 1 day, whereas those treated with control antibody did not ( n   =  14, P   0.001) ( Supplementary Fig. 4a, b ) First, we injected a neutralizing antibody against flt-1 into the cornea, with fellow eyes receiving isotype control antibodies Florida manatees ( Trichechus manatus latirostris ) are the only organisms that have been reported uniformly to have spontaneously vascularized corneas  Furthermore, pshRNA–sflt-1 did not elevate VEGF-A mRNA ( Supplementary Fig. 6d ) Furthermore, they illuminate its potential as a therapeutic target in conditions where inducing angiogenesis in an sflt-1-rich microenvironment might be beneficial, for example, preeclampsia, wound healing, stroke and heart disease. Genetic, transcriptional and protein-targeting suppression of sflt-1 all induced corneal vascularization, showing that sflt-1 is the pre-eminent molecular defender of corneal avascularity However, the molecular foundations of corneal avascularity remain unclear In our studies we found, surprisingly, that the cornea contained VEGF-A, but nearly all of it was bound ( Fig. 1b ) In the last decade, many anti-angiogenic molecules such as angiostatin, endostatin, interleukin-1 receptor antagonist, pigment epithelium-derived factor, and thrombospondins have been found in the cornea (reviewed in ref. 5 ), leading to recognition of their actions as tumour suppressors, atherosclerotic plaque growth inhibitors, or modulators of wound healing Injections into the cornea of a plasmid that encoded Cre recombinase (pCre), but not of pNull, induced corneal vascularization in flt-1 loxP/loxP mice ( n   =  10; P   0.001) within 2 days ( Supplementary Fig. 5a,b ) Interestingly, neither manatee expressed sflt-1 in the cornea, whereas the avascular corneas of dugongs ( Dugong dugon ), which also belong to the order Sirenia, and of Asian ( Elephas maximus ) and African ( Loxodanta africana ) elephants, the closest extant terrestrial phylogenetic relatives of manatees, did express sflt-1 in the cornea ( Fig. 4e–g ) Interestingly, the corneas of patients with aniridia ( n   =  5) were deficient in sflt-1 compared with normal human corneas ( n   =  7; Fig. 4d ) Interferon (IFN)-mediated responses can allow pshRNAs to inhibit gene expression nonspecifically; however, pshRNA–sflt-1 induced corneal vascularization in mice deficient in IFN(alpha, beta and omega)receptor-1 ( Ifnar1 -/- ) or IFN(gamma) ( Ifng -/- ) ( n   =  8) just as in wild-type mice, indicating that corneal vascularization was not attributable to IFN response effectors Like sflt-1, the transmembrane domain of flt-1 (flt-1-TM) also can trap VEGF-A, at least during development  Like wild-type mice, flt-1 tk -/- mice ( n   60), which retain expression of sflt-1 and flt-1-TM, have avascular corneas Moreover, pshRNA–sflt-1, but not pshRNA–mbflt-1, induced corneal vascularization in both Vegfb -/- ( n   =  8, P   =  0.029) and Plgf -/- ( n   =  16; P   0.0001) mice, supporting the contention that corneal vascularization results from desequestration of VEGF-A from sflt-1 Neither NLS–enzyme induced corneal vascularization in wild-type mice ( n   =  8; Fig. 2g, h ) Neither plasmid could induce corneal vascularization in wild-type mice ( n   =  8) NLS–Cre, but not NLS–β-galactosidase, induced corneal vascularization in flt-1 loxP/loxP mice ( n   =  11; P   0.001) within 2 days ( Fig. 2e, f ) lability, such as matrix metalloproteinase-induced release, have been identified in a model of tumour angiogenesis  Our data also provide insights into the relative immunological privilege of the cornea, as corneal avascularity is crucial to the high success rate of corneal allografts  Our findings unveil a new role for sflt-1 in the evolutionary establishment of optimal vision resulting from and requiring optical clarity Subconjunctival injection of anti-flt-1 antibodies, which eliminates the confounding effect of corneal trauma, also elicited corneal vascularization ( n   =  10, P   =  0.008; Supplementary Fig. 4d, e ) The absence of corneal sflt-1 and potentially suboptimal vision might result from a non-deleterious mutation in manatees, as they live primarily in turbid waters The anti-flt-1 antibody, but not control antibodies, also induced corneal vascularization in flt-1 tk -/- eyes ( n   =  8, P   =  0.029), indicating that the vascular phenotype resulted from suppression of sflt-1 function and not from interference with flt-1 signalling The avascular corneas of other marine mammals such as dolphins (bottlenose: Tursiops truncatus ; Risso’s: Grampus griseus ) and whales (Cuvier’s beaked: Ziphius cavirostris ; fin: Balaenoptera physalus ; melon-headed: Peponocephala electra ) also contained sflt-1 ( Fig. 4h, i ) The control was a plasmid that expressed an shRNA targeted against a sequence in the unique C-�terminus region of mbflt-1 but that is not present in sflt-1 (pshRNA–mbflt-1). pshRNA–sflt-1, but not pshRNA–mbflt-1, substantially reduced sflt-1 mRNA and protein, indicating that knockdown was achieved through RNAi ( Fig. 3a, b ), and increased free VEGF-A ( Fig. 3c ), corroborating the thesis that sflt-1 sequesters VEGF-A to maintain physiological avascularity The cornea has long been used as a readout platform to assay anti-angiogenic therapy in oncology, cardiovascular biology and other fields The cornea is ideal for understanding the ability of tissues to demarcate vascular ingrowth and identifying the efficacy of therapies against known angiogenic stimuli The cornea remains avascular even in states of hypoxia such as those induced by eyelid closure during sleep or coma, and in a variety of ischaemic and occlusive disease states The correlation between sflt-1 expression and corneal avascularity in diverse mammals supports the idea that sflt-1 has an evolutionarily conserved role in conferring corneal avascularity The final strategy specifically knocked down sflt-1 using RNA interference (RNAi) The presence of many anti-angiogenic molecules in the cornea indicates that avascularity, which is essential for optical transparency and clear vision, might be maintained by multiply redundant mechanisms The recognition that sflt-1 is dominant in maintaining corneal avascularity directly affects the degree to which this tissue can be generalized in individual models The search for inhibitors of angiogenesis to treat atherosclerosis, cancer, diabetic kidney and retina damage, macular degeneration, and rheumatoid arthritis often relies on testing in the cornea for initial efficacy, owing to the absence of blood vessels in the cornea despite it being surrounded by the highly vascular conjunctiva ( Fig. 1a ) The second strategy was genomic deletion: we suppressed sflt-1 by conditional Cre-lox-mediated gene ablation because flt-1 deletion is lethal  The teleological basis of the vascularized manatee cornea is intriguing The utilization of sflt-1 to regulate the bioavailability of VEGF-A is conserved in other systems such as cyclic vascularization and embryonic sprouting , and disturbances in this regulation underlie preeclampsia  Therefore the finding that neutralization or knockdown of sflt-1 alone abolishes corneal avascularity is surprising, but consistent with the presence of VEGF-A in the normal cornea These data confer an important protective role upon sflt-1 in maintaining corneal avascularity during physiological hypoxia These findings also support the use of sflt-1 in preventing or treating neovascularization This contained seven translationally silent wobble position mutations that rendered expressed sflt-1 refractory to pshRNA–sflt-1. psflt-1*, but not psflt-1, prevented suppression of sflt-1 and the development of corneal vascularization in eyes that had been treated with pshRNA–sflt-1 ( n   =  10, P   =  0.008; Supplementary Fig. 7b ) This functional control definitively established that the angiogenic phenotype was due to RNAi-mediated knockdown of sflt-1 This has led to a view of multiply redundant mechanisms of corneal avascularity This was attributed to an increase of 86 ± 34% in sflt-1 in hypoxic corneas ( n   =  17; P   =  0.05), consistent with the presence of a hypoxia-responsive element in the flt-1 gene  To avoid injection trauma, we delivered a cell-permeable, enzymatically active Cre containing a nuclear localization sequence (NLS–Cre; refs 19 , 20 ) to the cornea by topical eye drops ( Fig. 2a–d ) To confirm that corneal vascularization induced by pshRNA–sflt-1 was mechanistically linked to sflt-1 knockdown, we developed a plasmid coding for a ‘hardened-target’ version of sflt-1 (psflt-1*) To investigate whether other off-target effects might be responsible for corneal vascularization induced by pshRNA–sflt-1, we created p 2 shRNA–sflt-1, which was targeted against a different sequence in the unique C-�terminus region of sflt-1 To understand the paradoxical presence of this potent pro-angiogenic molecule in an avascular tissue, we hypothesized that it was counterbalanced by the expression of sflt-1, an alternatively spliced, secreted isoform of the cell-surface receptor membrane-bound flt-1 (mbflt-1). sflt-1 lacks the transmembrane (tm) and tyrosine kinase (tk) domains of mbflt-1 and can act as a ‘manacle’ for VEGF-A (ref. 11 ) Unlike dolphin and elephant corneas ( Fig. 4i ), manatee corneas expressed mbflt-1 ( Supplementary Fig. 9 ), indicating that a splicing switch might account for their vascularized state Unlike dugongs, which are strictly marine, manatees are believed to be physiologically dependent on fresh water, and corneal vascularization could protect against, or perhaps result from, irritations due to this hypotonic environment We also observed this phenotype in the Antillean manatee ( Trichechus manatus manatus ; unpublished data) We confirmed this by showing that concomitantly treating corneas with neutralizing anti-VEGF-A antibodies, but not with isotype-control antibodies, prevented corneal vascularization induced by the anti-flt-1 antibody ( n   =  8, P   =  0.029) We examined the spontaneously vascularized corneas of corn1 and Pax6 +/- mice for the presence of sflt-1 We examined VEGF-A and sflt-1 levels in the corneas of mice exposed to 8% O 2 (comparable to corneal hypoxia during sleep) for 24 h We found that sflt-1 mRNA and protein exist in the cornea ( Fig. 1c-g , Supplementary Fig. 1 ); by contrast, mbflt-1 was found in the conjunctiva but not in the cornea ( Fig. 1g ) We injected into the cornea a plasmid that expressed a short hairpin RNA (shRNA) targeted against a sequence in the unique carboxyl-terminus region of sflt-1 (pshRNA–sflt-1) We speculate that VEGF-A is produced and held in a sequestered state by the cornea as a readily available store because this exposed tissue is susceptible to injuries that might require an angiogenic response We used immunoprecipitation to confirm that sflt-1 and VEGF-A interact in vivo ( Fig. 1h ) and corroborated it by immunostaining ( Supplementary Fig. 3 ) We used three independent strategies to test whether sflt-1 preserved corneal avascularity in mice
 A challenge I had always thought particularly daunting was developing a catalytic system to join an electrophilic alkyl group to a nucleophilic carbon centre in a second alkyl group, with control over the symmetry of the product A group led by the University of Tokyos Takehiko Kitamori tethered a sheet of rat cardiomyocytes to a microfluidic chip After Pluto and 2005 FY9, 2003 EL61 is the third brightest trans-Neptunian object — orbiting the Sun at a greater distance, on average, than Neptune Alan DAndrea of the Dana Farber Cancer Institute in Boston, Massachusetts, and his colleagues focused on a mechanism that exploits the protein PCNA to prevent DNA replication stalling at a point of damage Am Am Arp and G Astronomy: Spin cycle Astrophys Biol. doi:10.1038/nchembio775 (2006) Hard to find, but valuable: this is the nature of a small molecule that specifically binds to just one protein But Kitamori says that to be viable in applications such as drug delivery, the bioactuator needs to be longer lasting C Cancer: Location, location, location Dev Cell 10, 303–315 (2006) Abnormal chromosome structure is a hallmark of cancer and certain birth defects Cell biology: Fever pitch J Cell biology: Saved by cleavage Nature Cell Biol. doi:10.1038/ncb1378 (2006) One of the cells mechanisms for coping with DNA damage is regulated by a self-destructing enzyme, say researchers Chem Chem Chemical biology: Small yet perfectly formed Nature Chem Climate science: Go with the airflow Geophys Computational chemistry: Molecular map-making J DAndreas group identified an enzyme, USP1, that curbs the risk when the chances of damage are low by stripping ubiquitin from the protein Developmental biology: Telling up from down Cell 124, 1011–1023; 1025–1037 (2006) Cells need to know which way is up to coordinate growth, division and migration, and biologists are curious to know how they make this distinction Dubbed a ‘magnetic wall’, the reflector preserves the electrical phase of reflected microwaves, but reverses the magnetic phase Each chromosome normally has one kinetochore Each rotation of the body takes less than four hours, and the authors believe that this rapid spinning squeezes the icy object into an ellipsoid at least 1,960 kilometres long and as little as 500 kilometres wide Febrile seizures have been linked to mutations in one subunit of the GABA A receptor, a protein complex that is a key ion channel in the nervous system First, the alkyl–transition metal complexes mostly used as the starting material are unstable and so decay into metal hydrides Fu J Gary Karpen of the Lawrence Berkeley National Laboratory, California, and his colleagues studied a protein called CID that helps to form the kinetochore, a structure needed for chromosomes to be pulled into daughter cells during cell division Gregory Fu and his colleagues have recently described efficient nickel-catalysed couplings of a racemic alkyl halide with organozinc nucleophiles, and they achieve superb enantiocontrol (F I was excited to learn that this is now possible In synthetic chemistry, even the conceptually simple task of creating a chemical bond can be a formidable challenge Inclusion of the data yielded a much more accurate model of Isabels observed track Irradiation with DNA-damaging ultraviolet light caused USP1 to cleave, and therefore inactivate, itself It generates enough force, at a few micronewtons per cell, to drive fluids in the chips channels It is a metamaterial made from undulating copper strips 0.8 millimetres wide and arranged in a ‘fish-scale’ pattern It is the contraction and expansion of layers of these cells that makes the heart beat Its light spectrum suggests that its surface is covered in methane or water ices J. 639, 1238–1251 (2006) Discovered among the icy debris at the outskirts of the Solar System, the Kuiper belt object 2003 EL61 is the fastest-spinning body in our neighbourhood that is greater than 100 kilometres across Journal club David MacMillan California Institute of Technology, Pasadena Bond with a chemist over the search for asymmetry in reactions Lett. 33, L04804 (2006) The flow of warm, dry air from the Sahara to the Atlantic Ocean is thought to inhibit the formation of tropical storms Lett. 88, 091119 (2006) Mirrors dont just reverse right and left — they also invert the phase of light waves that bounce off them Liguang Wu of the Goddard Earth and Technology Center in Baltimore, Maryland, and his team used satellite data to build atmospheric temperature and humidity profiles Many organic molecules are chiral; that is, not superimposable on their mirror image Microfluidics: In a heartbeat Lab Chip 6, 362–368 (2006) Researchers in Japan looking for a new way to power microdevices have turned to one of natures most dynamic inventions: the heart More precisely, they reverse the phase of the electrical component of an electromagnetic wave, but leave the magnetic component intact Neurosci. 26, 2590–2597 (2006) A problem in protein transport could underlie some cases of febrile seizures, the fever-triggered convulsions that afflict over 6% of children worldwide Nikolay Zheludev of the University of Southampton, UK, and his colleagues have now made a mirror that does the opposite Now, NASA researchers have shown that careful modelling of this airflow, known as the Saharan air layer, can improve simulations of storms forming off the coast of western Africa Now, researchers have uncovered a mechanism that could trigger such problems O On the chip, the cardiomyocyte sheet is used as a pump actuator One way to speed this process up, suggest David Beratan, Weitao Yang and their colleagues at Duke University in Durham, North Carolina, is to convert a discrete set of combinations of atoms into a continuous ‘molecular space’ in which atoms — and their contributions to the property of interest — can be gradually turned ‘on’ and ‘off’ Optics: Mirror image Appl Phys Res Robert Macdonald of the Vanderbilt University Medical Center in Nashville, Tennessee, and his colleagues show that the amount of the GABA A receptor at the surface of mammalian cells drops abnormally within minutes of the thermometer jumping from body temperature (37°C) to a feverish 40°C Second, the alkyl halides that act as reactants are themselves chiral and are a racemic, or 50:50, mixture of enantiomers Significant advances have been made using new catalysis concepts, but many key problems remain unsolved So chemists strive for ways to preferentially produce just one enantiomer So say David Rabinowitz of Yale University in New Haven, Connecticut, and his colleagues Soc. 127, 10482–10483; 2005) Soc. 128, 3228–3232 (2006) Designing a molecule with tailor-made properties is laborious when it involves testing many possible structures Such molecules can be used to elucidate the cellular function of the protein, or in therapeutic treatments Symmetry in particular can be problematic The cells are powered chemically, with glucose and oxygen The chromosomes were then pulled to pieces during cell division The configurations in which such a molecule exists, known as enantiomers, often differ in behaviour, especially in biological systems The design of such ‘enantio-selective’ reactions is central to synthetic chemistry The method is ground-breaking as a proof of concept, and I predict that it will be widely used. The nearest positions to these peaks that correspond to discrete molecules represent the candidates of interest The researchers used the technique to find the optimal electronic polarizabilities for simple small molecules; but the generality of the approach remains to be seen The team has discovered the first small molecule that binds to the oestrogen-binding G-protein-coupled receptor GPR30, but not to the two oestrogen receptors ERα and ERβ (crystals of oestrogen pictured right) The teams show that a protein they dub ‘tip of new pole’ (TipN) marks one pole of the dividing cell, and then moves to the new poles of each progeny cell There are two complicating issues They also showed that USP1 can bow out of the system, leaving PCNA ubiquitinated, when there is a strong possibility of DNA damage They then simulated the formation of Hurricane Isabel (pictured), which hit the United States in 2003, with and without this detailed data describing the Saharan air layer They used computational methods and cell-based assays to find the molecule, which they hope to use to define the role of GPR30 in vivo and to develop new contraceptive and anti-cancer agents This could be how a rapid rise in body temperature triggers the seizures, the authors propose This smooth terrain can be explored with well developed mathematical tools to search for peaks, corresponding to maxima of the desired property Thus Eric Prossnitz of the University of New Mexico in Albuquerque and his co-workers are set to reap the rewards for their hard work Thus, we must engineer a process that simultaneously destroys chiral information in the reactants and creates asymmetry in the product TipN works by directing construction of a flagellum at one end of the cell Two groups of researchers, led by Christine Jacobs-Wagner of Yale University in New Haven, Connecticut, and Patrick Viollier at Case Western Reserve University in Cleveland, Ohio, studied the process in the crescent-shaped bacterium Caulobacter crescentus , which divides asymmetrically to create two different daughter cells When a ubiquitin molecule is attached to PCNA, damage-tolerant DNA polymerases are recruited — but this is risky because the polymerases are not faithful replicators Working in the fruitfly Drosophila melanogaster (eye-antenna disc pictured right), the team found that abnormally high levels of CID (shown in green) resulted in the protein sticking to extra locations on the chromosomes, causing additional kinetochores to form
 A hover-car glided past And here had seemed something so hopeful And the 4000 model was the second in a series, an update of the 3000 model — it should be even better. (The Inspiron-3000 had apparently inspired its original inventors to greater heights — a self-sustaining system of continual and exponential improvement As a would-be inventor, Martin understood that the key to success was inspiration Before I was no one Days passed Each machine gave the inspiration to improve itself.) A light flashed Ears and eyes on overdrive, he heard the gentle hum of a far-off space-launch and his eyes recorded a gliding hover-car pass by For a moment, he was taken aback. “No — dont use it He explained as quickly as he could before rushing to his desk to jot down notes He felt split between worlds — the visions and reality He fitted it on smoothly He grabbed at inspiration, plucking ideas from the ether He had done all these things He needed ideas He saw the visions, the ideas, the possibilities. “Take it off,” said Martin. “You take it off!”  “No He seemed alone He seemed split between two worlds: magnificent papers were strewn across a dingy, messy room He seemed to teeter on a knife-edge. “Im tired of losing,” he said. “Take the damn thing off!” said Jim. “No!”  “Take it off! For Gods sake, save yourself! Take it off!”  “No.”  “Please.”  Martin wavered He sparkled to life, his senses awake as he tore the packaging apart to reveal the gem inside He struggled, unsure of himself. “Why dont you try it for yourself? You want to, dont you? Youll understand then.” A serene, creepy voice He was obsessed and only quietly, from a distance, it seemed, he heard a banging. “Open up! Its me, Jim.”  No one answered. “Open up!”  “Coming...coming,” said Martin. “Yeah, wait — one minute He was, as he had said, a genius — a god — yet he seemed so animal-like: a sad shadow come full circle from failure to success, and now he was sliding back He wavered. “Ive made another one,” said Martin. “Ive got two.”  A pause Hed drunk and done drugs and turned his modest, beautiful home into a dirty, smelly pigsty His life had been reduced to begging and borrowing His voice rang with doubt. “But look — LOOK!” said Martin. “All these works: beautiful, beautiful works! The Inspirons made something of me — dont you get it? — its made me a genius Im coming — one minute.” As he opened the door, Martin still had the Inspiron placed tightly on his head In front of him stood his friend. “Whats that on your head?” he said. “Ill explain it all later,” said Martin. “But look, Ive been working hard.”  “Really?” said Jim It inspired you. “You see, the Inspiron will make me great!” said Martin. “The most famous writer and inventor and scientist and philosopher ever! Theres nothing Im not capable of! Ill be a new Shakespeare! Plato! Einstein!”  Jim laughed at the ridiculousness of it, but he halted as he saw the look in Martins eyes It made you better and better It was perfectly shaped It wasnt like a drug — it wasnt a question of belief Its dangerous Its surface was metallic and shone silver in the bright sun Jim placed the Inspiron slowly on his head Jim was tempted Martin ate and drank nothing Martin drifted, agile and omnipotent, across the world Martin never worked Martin pressed the buttons on his TV remote and purchased the Inspiron-4000 Maybe — wait!”  In the distance there was the gentle hum of a far-off space-launch None was forthcoming Now Im a god! Worship me!”  His dark eyes welled up with tears and a desperate frown spread across his face Papers, food, cans of beer accumulated as remnants of his torn-up life Snatching at paper he wrote and wrote — great, great works So Martin Williams sat at his desk and thought: a bare featureless landscape lay before him...a daunting nothingness, the blank page stared back at him Take it off Take it off,” he repeated Teetering on the knife-edge, the humans struggled against the Inspiron and the talent that it could give them. The Inspiron actually made you better: an addition to the brain, an add-on, updating old technology The Inspiron was a powerful device The Inspiron, which attached directly to the cerebral cortex, was well-known for providing inspiration to many thousands of budding thinkers — inventors, painters, scientists The Inspiron-4000 gleamed in the sunlight The pieces were everywhere The world faded The world stood still Then he realized what hed heard Through the magic of teleportation, the Inspiron-4000 materialized in Martins lounge Time and again he sat down at his desk, only to shrink away from the blank page before him Uninspired Visions appeared like dreams, tangible yet slippery, he gripped at them with his mind “From ordinary to extraordinary, this machine will make you Shakespeare! Plato! Einstein! Buy it now and awake the genius within! The Inspiron-4000 thinks so you dont have to.”  The holographic TV blurted the advert out at a speed too quick to understand at first, but moments later comprehension dawned
 At the boundary between the Palaeocene and Eocene epochs, about 55 million years ago, the Earth experienced a strong global warming event, the Palaeocene–Eocene thermal maximum  Here we report a distinct carbonate-poor red clay layer in deep-sea cores from Walvis ridge , which we term the Elmo horizon It is coincident with carbon isotope depletion events in other ocean basins, suggesting that it represents a second global thermal maximum Possible triggering mechanisms for this event include crossing a threshold temperature as the Earth warmed gradually , comet impact , explosive volcanism or ocean current reorganization and erosion at continental slopes , whereas orbital forcing has been excluded  The Elmo horizon has similar geochemical and biotic characteristics as the Palaeocene–Eocene thermal maximum, but of smaller magnitude The leading hypothesis to explain the extreme greenhouse conditions prevalent during this period is the dissociation of 1,400 to 2,800 gigatonnes of methane from ocean clathrates , resulting in a large negative carbon isotope excursion and severe carbonate dissolution in marine sediments Using orbital tuning, we estimate deposition of the Elmo horizon at about 2 million years after the Palaeocene–Eocene thermal maximum We show that both events correspond to maxima in the ∼405-kyr and ∼100-kyr eccentricity cycles that post-date prolonged minima in the 2.25-Myr eccentricity cycle, implying that they are indeed astronomically paced. A regression analysis between the CaCO 3 wt% and the MS g -1 (converted to the MS-MST scale) was applied ( Supplementary Fig. 2 ) to obtain the estimated CaCO 3 wt% scale ( Fig. 1 ) All samples were freeze-dried and analysed for magnetic susceptibility per gram sediment (MS g -1 ) using an AGICO KLY-3 device Analytical precision and accuracy were determined by comparison with an international standard (BCR-71) and in-house standards (F-TURB, MM-91) Analytical precision was determined by replicate analyses and by comparison to international (IAEA-CO1 and NBS19) and in-house (NAXOS) carbonate standards, showing standard deviations of 0.06‰ and 0.1‰ for δ 13 C and δ 18 O, respectively Calibration to the international carbonate standard NBS19 revealed an analytical precision better than 0.03‰ and 0.05‰ for δ 13 C and δ 18 O, respectively. Every fourth sample (but all within the Elmo horizon) was used for calcium carbonate analyses Isotope values were calibrated to the PeeDee Belemnite (PDB) scale Methods Sampling and CaCO 3 wt% analyses Discrete sediment samples were collected at a 0.5–1-cm spacing across the Elmo horizon in holes 1262A, 1263C and 1266C Several samples prepared for palynological studies revealed that no significant amount of organic carbon was present, with an uncertainty smaller than the analytical precision Specimens were hand picked from the 300 µm fraction and cleaned in ethanol in an ultrasonic bath for 30 s Stable isotope measurements of individual planktonic and benthic foraminiferal specimens were carried out using a CARBO-KIEL automated carbonate preparation device linked on-line to a Finnigan MAT252 mass spectrometer Stable isotopes Bulk stable isotope measurements were carried out for all sites with an average spacing of 4 cm, but in 0.5–1-cm resolution through the Elmo horizon The CaCO 3 wt% was based on the amount of total carbon combusted with the Fison NA 1500 CNS analyser The isotope measurements were carried out using an ISOCARB common bath carbonate preparation device linked on-line to a VG SIRA24 mass spectrometer The relative standard deviations, analytical precision and accuracy were better than 3% These records were compared to the split core point magnetic susceptibility (PMS) and whole core MS of the multiple sensor track (MS-MST) measurements obtained during Leg 208  We converted all MS data to the MS-MST scale by performing linear regression analyses between MS g -1 and PMS ( Supplementary Fig. 2 ) and the conversion of PMS to MS-MST using the equation MST = (PMS × 2.0683) + 7.8257 ( R 2 = 0.99)  A definite tuning of the early Eocene to astronomical computations is complicated, because the precision of the orbital solution more than 45 Myr ago is limited  A second uncertainty derives from the chaotic behaviour of the inner planets related to the resonant argument θ = ( s 4 - s 3 ) - 2( g 4 - g 3 ), where g 3 , g 4 are related to the precession of the perihelion and s 3 , s 4 to the precession of the node of Earth and Mars  Above ETM2 (H1) an increasing number of low-amplitude carbon transients occurred, of which the first, H2 , seems to correspond with the two thin brown layers one 100-kyr cycle above the Elmo horizon (number 0 in Fig. 3 ), suggesting that the threshold for dissociation of clathrates was low during the early Eocene climatic optimum , enabling even the short eccentricity cycles to trigger minor methane releases. All this suggests that the Elmo horizon characterizes a second pronounced early Eocene thermal maximum (ETM2; Fig. 1 ), similar to the PETM in both orbital and biogeochemical aspects, but of approximately half its amplitude in carbon isotope excursion, rise in sea surface temperature, and carbonate dissolution Analysis of the CaCO 3 content (expressed in weight per cent: wt%) of the deepest Site 1262 (palaeodepth , 3,600 m), intermediate Site 1266 (palaeodepth, 2,600 m) and shallowest Site 1263 (palaeodepth, 1,500 m) reveal that the increase in MS is linearly related to a drop in CaCO 3 wt% ( Supplementary Fig. 2 ) Application of the empirical temperature–δ 18 O relationship indicates furthermore that the ∼1‰ δ 18 O A.soldadoensis change within the Elmo horizon reflects a sea surface temperature rise of at least 3–4 °C, about half of the mid- to high-latitude sea surface temperature changes estimated for the PETM  As a result, the Elmo horizon correlates with the short eccentricity maximum at ∼53.235 Myr ago (La2004) or ∼53.620 Myr ago (R7), and the onset of the PETM carbon isotope excursion correlates with the long eccentricity maximum centred at ∼55.270 Myr ago (La2004) or ∼55.675 Myr ago (R7) At 50 Myr ago, the absolute uncertainty in time is about 20 kyr (ref. 20 ), but this did not lead to an astronomically tuned timescale owing to large uncertainties in radiometric age constraints for this time interval  Because of these uncertainties, only a floating tuning could be realized (see also Supplementary Information ) Benthic foraminifera species richness is low and assemblages are dominated by diminutive Nuttallides truempyi and Abyssamina spp. species in the Elmo horizon Biotic phenomena similar to those characterizing the Palaeocene–Eocene thermal maximum (PETM) have been locally recorded in the upper Palaeocene to lower Eocene, indicating the possibility of additional hyperthermal events, though of smaller magnitude  Both components were extracted and could be unambiguously correlated between the records of these sites ( Fig. 3 ) First, we emphasize that MS maxima ( L * minima) correlate to eccentricity maxima based on the distinct amplification of the precession-related lithological changes during the long- and short-term MS maxima ( Supplementary Fig. 4 ) Four long-term maxima in MS (minima in L *) occur between the Elmo horizon and PETM From Site 1263, we analysed the stable isotopic composition of individual specimens ( 300 µm size fraction) of the surface-dwelling planktonic foraminifer Acarinina soldadoensis and the benthic foraminifers Cibicidoides spp. and Anomalinoides spp. ( Fig. 2 ) Hence, the large drop in CaCO 3 wt% in the Walvis ridge cores probably indicates a major global ocean lysocline shoaling, but in contrast to the PETM , the calcite compensation depth appears to have remained below the palaeodepth of Site 1262 Hence, we suggest that the extreme seasonal contrast at both hemispheres during eccentricity maxima increased intermediate seawater temperatures, thereby triggering the release of oceanic methane hydrates High-resolution bulk carbon isotope records (δ 13 C bulk ) of Sites 1262, 1265, 1266 and 1267 reveal a negative excursion of 1.0–1.2‰ from below the first decline in CaCO 3 wt% into the Elmo ( Fig. 1 ) If there were 11 climate precession cycles in the PETM interval , then its carbon isotope excursion corresponds to a maximum (minimum) in the long-term MS ( L *) cycle, similar to the Elmo In addition, according to their tuning the interval between the PETM carbon isotope excursion and C24n/C24r should span ∼1.5 Myr, which is significantly shorter than the five ∼405-kyr cycles (∼ 2 Myr) that we found In this respect, the critical conjunction of short, long and very long eccentricity cycles and the long-term late Palaeocene to early Eocene warming trend may have favoured the build-up of a significant methane hydrate reservoir before its release during both events, thereby excluding unique mechanisms for explaining the PETM  Its position just below C24n/C24r and within NP11 suggests that this excursion correlates to the ∼1‰ depletion characterizing the H1 event in the North Atlantic (DSDP Site 550 and ODP Site 1051), the Southern Ocean (ODP Site 690) and the Pacific Ocean (DSDP Site 577) (see Supplementary Information ) Magnetobiostratigraphic results on Site 1262 (see Supplementary Information ) reveal that the Elmo horizon at 117.1–117.2 m composite depth (m.c.d.) is slightly older than the chron C24r/C24n reversal boundary (115–116 m.c.d.) ( Supplementary Fig. 1 ) and occurs within the lower part of NP11 Moreover, the palaeosol carbonate isotope record from the Bighorn basin also shows a strong negative δ 13 C excursion just below C24n/C24r , indicating that the carbon isotope excursion is global and recorded in both marine and terrestrial basins ( Supplementary Fig. 6 ) One objective of Ocean Drilling Program (ODP) Leg 208 on the Walvis ridge (subtropical southeastern Atlantic Ocean) was to search for hyperthermal events within the lower Cenozoic greenhouse climate record Orbital tuning suggested that these transients were controlled by maxima in the short-term eccentricity cycles, whereas the PETM carbon isotope excursion allegedly occurred near a minimum in the ∼405-kyr eccentricity cycle, excluding orbital forcing as a triggering mechanism for the latter  Second, we correlated the (on average less amplified) ∼100-kyr cycles within the second (II; Fig. 3 ) ∼405-kyr cycle to the minimum in the ∼2.25-Myr cycle at 53.5 Myr ago (La2004) or 54.0 Myr ago (R7) ( Supplementary Fig. 5 ) Several short, negative carbon isotope shifts of up to 1‰ at deep-sea sites resemble the much larger-amplitude carbon isotope excursion at the PETM  Spectral analysis was applied on the colour reflectance ( L *) of Site 1267, and L * and MS of Site 1262 (see Supplementary Information ) The (smoothed) carbon isotope record of A. soldadoensis (δ 13 C A.soldadoensis ) resembles the pattern of the bulk record, but shows a significantly larger negative excursion (∼2.5‰) The bulk carbonate oxygen isotope record (δ 18 O bulk ) of Site 1263 shows a negative excursion of ∼1.6‰ ( Fig. 2 ) The CaCO 3 wt% declines from 90–95 below, to ∼40 within, the red clay The carbon isotope shift is much smaller in the benthic foraminiferal record than in A. soldadoensis , but the (∼1‰) trend through the carbonate-rich intervals equals that of the bulk and planktonic isotope records The Elmo horizon corresponds to a fifth long-term MS maximum ( L * minimum) and a short-term MS maximum ( L * minimum) cycle –15 cm thick, and characterized by elevated magnetic susceptibility (MS) values at all sites ( Fig. 1 ) The Elmo horizon, however, has yet not been recognized at other locations, although the H1 event is accompanied by high MS values at Sites 550 and 690  The few measured benthic isotope values of the Elmo horizon, representing Anomalinoides spp. specimens ( Cibicidoides spp. 300 µm are absent in the Elmo horizon), are similar to those from outside the clay layer, indicating that these are probably derived from bioturbated specimens The less extreme signal of ETM2 may reflect the inability of the methane hydrate reservoir to return to pre-PETM dimensions, especially under the warm conditions that prevailed in the interval spanning the two events  The linkage of both events to a similar orbital configuration disagrees with Cramer et al. , who related the PETM to a minimum and H1 (ETM2 equivalent) to a maximum in a ∼405-kyr cycle, thereby promoting the comet impact hypothesis  The maximum oxygen isotope shift in A. soldadoensis (δ 18 O A.soldadoensis ) across the Elmo horizon is comparable to that of the δ 18 O bulk record The planktonic foraminiferal data show a much larger inter-specimen variability within each sample (especially within the Elmo horizon) than the benthic data The post-Elmo interval mirrors the typical PETM signature with an exponential recovery to pre-excursion δ 13 C bulk values The presence of light-coloured burrows within the red clay layer documents bioturbation, and could explain the scatter in the planktonic isotope values, and the less strong δ 13 C bulk excursion relative to δ 13 C A.soldadoensis  The red clay layer associated with the PETM ends in a long-term MS minimum ( L * maximum) The spectra of all records revealed the dominance of the long (∼405-kyr) and short (∼100-kyr) eccentricity cycles ( Supplementary Fig. 3 ) The uppermost Palaeocene and lower Eocene are composed of foraminifer-bearing nannofossil ooze, with a few chert layers and two deep-red clay layers marking the PETM and a younger distinctive horizon, named Elmo The δ 13 C bulk negative shift of 1.4–1.6‰ in the Elmo horizon at Site 1263 is, with exception of the PETM carbon isotope excursion, of an unusually large magnitude for the early Palaeogene  The δ 13 C bulk of Site 1263 shows the largest depletion (1.4–1.6‰), suggesting that the red clay layer at this site with the highest sedimentation rate is stratigraphically the most complete and/or least affected by the dissolution of primary calcite and the presence of reworked or secondary calcite There is only a ∼0.6‰ shift in the benthic oxygen isotope record, either because no in situ large benthic foraminifera are present in the Elmo horizon or changes in bottom water temperatures were minor These discrepancies can probably be attributed to large uncertainties in their approach of using low-amplitude bulk carbon isotope transient excursions and counts of poorly expressed lithological cycles from incomplete successions  This causes a large uncertainty in the determination of the time when the relatively stable ∼2.4-Myr beat in eccentricity evolved from the ∼1.2-Myr period when ( s 4 - s 3 ) - ( g 4 - g 3 ) = 0 (that is, ∼2.25 Myr in the nominal La2004 and R7 solutions between 53–57 Myr ago) This observation is crucial, because it implies that the carbon isotope shifts associated with the PETM and Elmo horizon also correspond to maxima in the long and short eccentricity cycles ( Fig. 3 ) This possibility does not rule out that the magnitude of the excursion in the deep sea could have been damped owing to the larger carbon mass of this reservoir This problem limits an accurate age determination of successive minima in this very long eccentricity cycle and the related intervals of reduced amplitude changes in the short eccentricity cycle, and explains the offset between the ∼2.25-Myr cycles of the nominal La2004 and R7 solutions in the studied time interval ( Fig. 3 ) This resulted in the first complete early Palaeogene deep-sea record accumulated at relatively high sedimentation rates  This suggests that large-sized benthic foraminifera were absent during deposition of the Elmo horizon, as commonly observed for the PETM  This tuning implies that both events occurred briefly after a period of low-amplitude, short eccentricity changes associated with a minimum in the very long-term orbital perturbation of ∼2.25 Myr To unravel the orbital relationship between the Elmo horizon and PETM, we studied the cyclic sedimentary patterns of the interlying interval in continuous spliced cores derived from advanced piston core holes only Tuning is in principle possible for the 405-kyr eccentricity cycle, because of its longer duration of stability ( Fig. 3 ) Using this first order calibration, we tuned all long and short eccentricity cycles, implying that all cycles should be shifted one ∼405-kyr cycle older in R7 than in the nominal La2004 solution ( Fig. 3 ) We recovered continuous, undisturbed lower Palaeogene successions at five sites along a 2-km water depth transect in multiple (mostly advanced piston core) holes
 An estimated 3% of the worlds population — more than 170 million people — are infected by the hepatitis C virus (HCV) As always, Nature carries sole responsibility for all editorial content and peer review. Current medical treatment options are limited, and 10,000 to 20,000 deaths a year in the United States are from hepatitis C Despite the discovery of the virus by molecular biological methods more than 15 years ago, and the sequencing of its entire genome, our knowledge of the virus and the nature of the protective immune responses is limited Indeed, chronic HCV infection is the most common cause of liver transplantation Most infections become chronic: a condition that is incurable in many patients, leading to cirrhosis, end-stage liver disease and hepatocellular carcinoma Nevertheless, great strides have been made over the past few years, and much has been learned about the viral life cycle, immune response factors that confer protection, and the mechanisms by which the virus is able to evade the host immune response New drugs are on the horizon and a protective vaccine may be within reach Researchers have been hampered by the lack of a robust cell-culture system yielding infectious virus until very recently, and the absence of a non-primate animal model This Insight brings together leading experts in hepatitis C to provide a snapshot of the field and discuss imminent developments We are pleased to acknowledge the financial support of Vertex Pharmaceuticals and Gilead Sciences, which together contributed towards the production of this Insight
 A fellow of the Royal Society and recipient of many honours, among them the Hughes Medal and Royal Medal of the Royal Society, ‘Dick’ Dalitz never lost his appetite for physics A theorist who always endeavoured to work close to experiment, his contributions over 60 years shed vital light on the nature of the fundamental forces and the constituents of matter After brief periods at Cornell University in Ithaca, New York, and back at Birmingham, in 1956 Dalitz accepted a professorship at the Enrico Fermi Institute in Chicago After completing his thesis, which was on transitions between spin states in the oxygen nucleus, Dalitz was finally able to concentrate on particle physics and study of the tau After two years, he ran short of funds and, with a small child to support, moved to a one-year post as assistant to Nevill Mott at the University of Bristol At Oxford, Dalitz continued his work on the resonant states that were being discovered in ever-larger numbers — often through the use of Dalitz plots At Oxford, Dalitz established a flourishing research programme to study the quark model, and attracted many senior physicists and students to it At the time, most physicists considered quarks as merely a mathematical tool Awarded a travelling scholarship, he moved in 1946 with his wife Valda to England, to study for a PhD under Nicholas Kemmer at Trinity College, Cambridge Boldly, Dalitz pursued the possibility that they might be real dynamical objects, and, in a remarkable paper presented in Tokyo in 1965, showed how different combinations of three tightly bound ‘up’ and ‘down’ quarks explained many properties of the proton and neutron Born in the small wheat-belt town of Dimboola, northwest of Melbourne, Australia, Dalitz gained degrees in both mathematics and physics at the University of Melbourne D Dalitz first heard of colour in a talk by Gell-Mann and recognized that it resolved some profound problems associated with the quark model Dalitz was interested in the difference between the tau and another strange particle, the theta, which seemed to be the taus identical twin except for the fact that it decayed into two pions, whereas the tau decayed into three Dalitz was invited by Rudolf Peierls to the University of Birmingham in 1949, where his encounters with Freeman Dyson proved most useful for his mastery of the quantum-electrodynamical methods that Richard Feynman was then developing to describe electromagnetic interactions Dalitzs interest in the quark model continued all his working life He died on 13 January 2006, and is survived by his wife, son and three daughters. He further proposed that the quark model could describe not only these ground states, but also the multitude of higher-energy resonant states He remained an active member of the theoretical-physics department at Oxford after his retirement in 1990, always keen to encourage students to share in his passion for physics He started to think particularly about the nature of one of these, the ‘tau meson’, or K + , as it is now known In 1963, Dalitz was persuaded by Peierls to return to Britain and join him at the University of Oxford as a Royal Society research professor and, from 1964, a fellow of All Souls College In 1992, with Gary Goldstein, he developed a method still in use today, to determine the detailed properties of the ‘top’ quark, the last of the six types of quark to be found In retrospect, Dalitz considered this year at Bristol vital to his subsequent research: there he first learned from the group of Cecil Powell about elementary particle physics and the ‘strange’ particles (so named because they left unusual tracks in the emulsions used to detect them) produced in cosmic-ray collisions Lee and C Murray Gell-Mann dubbed this the ‘eightfold way’, and proposed that the pattern could be explained if the resonances were combinations of fundamental building-blocks of fractional electric charge — quarks, as he named them N Richard Henry Dalitz was a giant in the field of particle physics The quark model was the foundation of quantum chromodynamics (QCD), the comprehensive theory of the strong nuclear force that depicts quarks as being held together by the exchange of gluons — analogues of the photons of the electromagnetic force — which are coupled to a new ‘colour’ charge The result was two seminal contributions that bear his name: the study of the decay of the neutral pion (one of the lightest mesons, a class of particles now identified as quark–antiquark pairings) to a photon and an electron–positron, or ‘Dalitz’, pair; and the development of the ‘Dalitz plot’ The subsequent realization by T The success of this model once colour was included set the scene for the subsequent development of QCD Their work, and work worldwide, has shown that all particles found then and since fit well with quark-model predictions There he benefited from the teaching of Paul Dirac, whose lecture course on quantum mechanics he attended twice These states could be grouped according to their mass, spin and parity into families of eight and ten This allowed so-called resonances — transient states that flag their existence through their decay to final-state particles of definite total energy — to be readily visible This encompasses the original strange particles, whose unusual properties are now attributed to the presence of at least one ‘strange’ quark in their make-up that hampers their decay, as well as states that contain the heavier quarks ‘charm’ and ‘bottom’ This plot presents the kinematic variables of the three-body final state of a reaction in two dimensions Using his plot, he was able to establish that the tau, like the theta, has zero spin, so that the two particles could not be identical if parity holds. (Parity is the idea that reactions proceed the same way when all spatial coordinates are reversed.) Indeed, this ‘tau–theta’ puzzle was the first indication that parity did not hold for interactions involving the weak nuclear force Working with Riccardo Levi-Setti, he developed what became a lifetime interest, often pursued in collaboration with Avraham Gal, in the recently discovered hypernuclei, in which a strange particle takes the place of a proton or neutron Yang that this could indeed be the case won them the 1957 Nobel Prize in Physics
 Although the Department of Justice did not release its brief, it had apparently made a strong argument against the absurd notion that projections of the future must be proven accurate in advance Attempts by the USNAs lead authors and contributors (including myself) to get this notice removed or modified have failed, leaving in place an unfair criticism of the assessments widely accepted findings. In addition, the OSTP guidelines did not exist or apply at the time that the USNA was released In August 2003 a conservative advocacy group, the Competitive Enterprise Institute, filed a suit claiming violations of the act against President George Bush and John Marburger, director of the White House Office of Science and Technology Policy (OSTP) In November 2003, just as the Department of Justice was preparing to file its response, the parties accepted a ruling of “dismissal with prejudice”, meaning that the lawsuit could not be refiled Press, Cambridge, 2000) — which therefore violated the act because one of the two scenarios had to be in error Sir Your News story “Salt sellers challenge US health agency using data-quality act” ( Nature 433 671; 2005 ), suggests that a lawsuit filed by the Salt Institute represents “the first time that a petitioner has actually sued under the Data Quality Act” The most important claim was that reports by the US National Assessment of the potential consequences of climate change (USNA) used results from two different global climate models to construct scenarios of future climate (see National Assessment Synthesis Team, Climate Change Impacts on the United States , Cambridge Univ The OSTP nonetheless ordered that a notice be added to USNA web pages, indicating that the reports “were not subjected to OSTPs Information Quality Act Guidelines” This implies that the USNA report was not properly reviewed and would not meet the OSTP guidelines This is misleading at best, as the report was subjected to a four-stage review that was more comprehensive than called for by the act This is not the case, although the ruling that the Salt Institute is appealing was the first verdict given in a case brought under the federal Data Quality Act
 A Cuban proposal for dengue research, for example, won a $700,000 award from the Bill Melinda Gates Foundation after international peer review After university, large numbers of young scientists are sent abroad for training — once to its Communist allies, more recently to Europe and Latin America — and Cuba ensures, by fair means or foul, that they return home afterwards to work At various times, other Latin American nations such as Venezuela and Argentina have sought to build up science and technology by supporting a mixture of pure and applied research, a model similar to that established in wealthier countries But one aspect of Cubas scientific success is often overlooked But the approach has many drawbacks But the award has been held up for a year, lest the illustrious Microsoft founder, his wife and their fellow trustees be dragged off to the penitentiary for breaching the embargo But there is a more specific issue here Castros government maintains strict control on the movement of its citizens Cuba took a different approach: research there is ruthlessly applied Cubas scientists have no funds for basic research, but they largely back their governments approach, in part because they have seen how it transformed health services in their country Cubas state-sponsored science is structured like a corporate research laboratory, except that its output consists of social outcomes, rather than commercial products Despite a floundering economy, restrictions on free speech and the incessant hostility of its powerful neighbour to the north, Cuba has developed a considerable research capability — perhaps more so than any other developing country outside southeast Asia If a project looks likely to earn foreign currency or meet the governments social objectives, it is backed to the hilt In preparation for that day, both Havana and Washington should be acting now to wind down such cold-war artefacts as Cubas travel restrictions and the US trade embargo. It is questionable, in any case, whether such restrictions serve any useful purpose for Cubas government, given the obvious commitment of the scientists in question to their countrys future Just as questionable is the purpose served by the continuing US trade embargo on Cuba, which continues to isolate scientists and others on the island from their colleagues in the United States, including a large group of Cuban origin Nature has consistently opposed scientific embargos, and strongly believes in research collaboration as a means of building bridges between nations that lack normal diplomatic relations Now it boasts a biotechnology industry that has produced effective drugs and vaccines of its own, a large and fairly influential scientific work-force, and a fledgling pharmaceutical industry with its sights set on export markets One concerns the constraints that it places on the movement of researchers Restrictions on free political expression in Cuba are also inconsistent with the declaration Scientists fare better than most, and are frequently allowed to attend conferences or spend time working in foreign laboratories Some of the reasons for Cubas success are straightforward The agricultural sector, in which small farmers benefit from partnerships with agricultural researchers, is also quite successful (see Cuban science: ¿Vive la revolución? ) The embargo damages Cuban science and scientific collaboration in various ways The government has invested heavily in elementary and secondary education, and has attained developed-world standards of literacy and numeracy in its population This draconian approach to dealing with the threat of a brain drain is in breach of the Universal Declaration of Human Rights, adopted by the United Nations in 1948 Whatever one thinks of its leader, Fidel Castro, it is worth asking how Cuba did it, and what lessons other countries might draw from it When Castro came to power in 1959, Cuba had almost no scientific infrastructure When Castro dies, Cuba faces a period of volatility that could endanger key national assets, such as its science Yet if they stay away for longer than permitted, they lose the right to return freely
 A nocturnal predator, the marten is presumed to have acquired its infections after feeding on a diseased bird A WHO press release responding to this report states: “To date, only domestic poultry are known to have played a role in the transmission cycle of the virus from animals to humans.” But given the potential contribution of these carnivore hosts to both virus transmission and its adaptation to mammals, we believe the time for increased surveillance and precaution is here. Accordingly, we recommend increasing surveillance in areas where H5N1 virus is endemic, to include testing for H5N1 virus infections in felids and other carnivores showing unusual morbidity or mortality Also in 2004, there was a second outbreak of H5N1 virus infection at another zoo in Thailand, again involving consumption of virus-infected chicken Although our preliminary data from experimentally infected cats do not reveal important mutations in excreted viruses, at least within the haemagglutinin gene (the ‘H’ in H5N1), such mutations cannot be ruled out Although the above data shed some light on the epidemiology, major gaps in our knowledge still remain An incomplete picture What scientific data on H5N1 virus infection in cats are currently available? There are so far three publications reporting experimental studies, all conducted at the Erasmus Medical Centre in Rotterdam, The Netherlands Another recent paper of ours shows that H5N1 virus attaches abundantly to the cells lining the lungs of domestic cats, but not to those in upper parts of the respiratory tract Apart from the role that cats may play in H5N1 virus transmission to other species, they also may be involved in helping the virus to adapt to efficient human-to-human transmission As recently as 28 February 2006, a World Health Organization (WHO) press release stated: “There is no present evidence that domestic cats play a role in the transmission cycle of H5N1 viruses.” A March press release from the World Organisation for Animal Health (OIE) stated: “The OIE stresses that as of today, all the natural cases in felines have not led to any change in the epidemiology of the disease that has fundamentally remained a bird disease, nor have they led to any recognized virus change in epidemiology or mutation leading to an increased virulence of the virus for felines or other mammals.”  There are now several observations indicating a greater role for domestic cats than these cautious statements suggest At this zoo, two tigers and two leopards died suddenly after feeding on fresh chicken carcasses Clinical signs were observed several days earlier in cats infected by direct respiratory and oral routes, than by cat-to-cat transmission Consequently, these data indicate a possible role for cats in the epidemiology of H5N1 virus in poultry, humans and other species Despite the uncertainties, we believe that the potential role of cats should be considered in official guidelines for controlling the spread of H5N1 virus infection Despite these unexpected events, the possible role of cats in the epidemiology of H5N1 virus infection has been largely overlooked by the human- and animal-health communities Excretion lasted from three days post-infection until the end of the experiment on day seven, when the cats were killed Finally, we now know that H5N1 virus has the ability to infect an unprecedented range of hosts, including carnivores First, it has become evident that fatal infections among cats are common in countries such as Indonesia, Thailand and Iraq, where the virus seems to be endemic in poultry For example, veterinarians conducting an epidemiology programme with the participation of the Food and Agricultural Organization (FAO), recently reported a high incidence of sudden death among cats during fatal poultry outbreaks in several villages in Indonesia Given the high number of infected cats in these areas, and considering their ability to excrete virus into their surroundings in sufficient quantities that transmission between cats takes place under both natural and experimental conditions (see below), cats could be more than a dead-end host for H5N1 virus H5N1 virus is basically an avian pathogen, and although humans can be infected, evidence for further spread of the virus among humans is rare Here we recommend that new precautions are taken by nations and agencies fighting avian flu to minimize the risk of cats becoming infected and spreading the highly pathogenic virus to poultry, humans and other species In addition to felids, we can expect other domestic and wild carnivores, such as dogs, foxes, mustelids and seals, to be vulnerable to infection with H5N1 virus and to contribute to its epidemiology In areas where H5N1 virus has been detected in either poultry or wild birds, we recommend taking steps to prevent contact between cats and infected birds or their droppings, and to quarantine and test cats suspected of such contacts, or cats showing clinical signs suggestive of H5N1 influenza In most urban areas and in temperate climate zones, where most felids are domestic cats, prevention of contact could be achieved by keeping cats indoors In other parts of the world, such measures may be more difficult, if not impossible, to implement In some cats, virus excretion started before clinical signs were noted In the absence of these data, it is difficult to assess the overall risk posed by infected cats In the few suspected cases , it seems that close physical contact, for example between mother and child without the use of precautions such as gloves, nose-mouth masks, or antiviral treatment, was responsible It is sufficiently well-known to have been given an onomatopoeic name in the local Javanese dialect — ‘aargh-plop’   Laboratory cats infected with H5N1 virus by the respiratory tract (three in total), by feeding on virus-infected chicks (three), or through close contact between infected and non-infected cats (two) all excreted virus from the pharynx, nose and rectum Most important, we do not know the minimal infectious dose for cats by either the oral or the respiratory route, how long cats excrete virus from the digestive and respiratory tracts, whether cats can excrete virus without developing clinical signs, and whether virus transmission from cats to poultry, humans and other species is possible Most international guidelines currently lack such considerations One of the cats died at day six One of the cats had eaten a chicken carcass on a farm where there was an H5N1 virus outbreak Only last month, H5N1 virus infection was detected in Germany in yet another mammalian species: a stone marten, belonging to the family Mustelidae Post-mortem examination demonstrated multiplication of the virus not only in the respiratory tract , but also in a number of other organs  Second, veterinarians in Iraq combating H5N1 virus outbreaks in poultry in collaboration with the FAO also report widespread and high mortality in cats, confirmed to have been caused by this virus Some of the above findings, such as infection by feeding on virus-infected chicken carcasses, transmission of H5N1 virus between cats and infection of extra-respiratory tissues, were also observed in the H5N1 virus outbreaks in tigers and leopards and in a naturally infected domestic cat  Subsequent experiments in The Netherlands, by some of us, have experimetally confirmed the severity of H5N1 virus infections in cats — with all eight cats exposed to the virus going on to develop the disease The amount of excreted virus recorded from cats was much lower than the levels excreted by chickens The available evidence, albeit incomplete, suggests that cats are more than collateral damage in avian flus deadly global spread and may play a greater role in the epidemiology of the virus than previously thought The disease in cats is well-recognized by poultry keepers and is considered to be linked to the poultry disease The first report of domestic cats dying from H5N1 virus infections was in February 2004, when 14 out of 15 cats in a household near Bangkok, Thailand, became weak, started vomiting and coughed up blood before dying The jurys out The 2004 outbreak in domestic cats showed striking similarities with an incident that occurred three months previously at a zoo in Suphanburi, Thailand, during a local outbreak of H5N1 virus infection in poultry The presence of H5N1 virus was confirmed in three of the cats following necropsies at Kasetsart University in Bangkok, Thailand  The presence of virus in most tissues was associated with cell death and inflammation The probable cause of death was diagnosed as severe pneumonia due to H5N1 virus infection  The signs included raised body temperature, decreased activity, conjunctivitis and laboured breathing There are increasing numbers of reports from Asia and Europe of domestic cats dying from avian influenza H5N1 virus These reports were surprising because both domestic cats and wild felids were considered to be resistant to disease from influenza A virus infection, of which H5N1 is a subtype Third, dead or moribund cats were found to be infected with H5N1 virus soon after the virus was detected in wild birds in Germany This pattern of H5N1 virus attachment closely mirrors that in the human respiratory tract, identifying the cat as a suitable model for viral pneumonia caused by H5N1 in humans This suggests not only that H5N1 virus can be transmitted from wild birds to cats, but also that unusual mortality of cats in areas at risk of H5N1 virus infection may act as an early warning signal for the virus This suggests that the virus reached these tissues directly from the guts — a novel route of entry for influenza virus in mammals This time, a total of 147 tigers died or were killed  Time for action Collectively, the data so far show that domestic cats can become infected by contact with domestic or wild birds and possibly their droppings, develop severe to fatal disease, excrete the virus from the respiratory and digestive tracts, and transmit the infection to other cats Viral infection in the nervous tissues of the intestinal wall was found only in cats fed on virus-infected chicks We have previously suggested that cats may provide the virus with an opportunity to adapt to efficient transmission within and among mammalian species, including humans, thereby increasing the risk of a human influenza pandemic 
 Consistently, Irf7 -/- mice are more vulnerable than Myd88 -/- mice to viral infection, and this correlates with a marked decrease in serum IFN levels, indicating the importance of the IRF-7-dependent induction of systemic IFN responses for innate antiviral immunity Furthermore, robust induction of IFN production by activation of the TLR9 subfamily in plasmacytoid dendritic cells is entirely dependent on IRF-7, and this MyD88–IRF-7 pathway governs the induction of CD8 + T-cell responses The type-I interferon (IFN-α/β) response is critical to immunity against viruses and can be triggered in many cell types by cytosolic detection of viral infection, or in differentiated plasmacytoid dendritic cells by the Toll-like receptor 9 (TLR9) subfamily, which generates signals via the adaptor MyD88 to elicit robust IFN induction  Thus, all elements of IFN responses, whether the systemic production of IFN in innate immunity or the local action of IFN from plasmacytoid dendritic cells in adaptive immunity, are under the control of IRF-7. Using mice deficient in the Irf7 gene ( Irf7 -/- mice), we show that the transcription factor IRF-7 is essential for the induction of IFN-α/β genes via the virus-activated, MyD88-independent pathway and the TLR-activated, MyD88-dependent pathway Viral induction of MyD88-independent IFN-α/β genes is severely impaired in Irf7 -/- fibroblasts Akira, respectively All the mice were maintained under specific pathogen-free conditions in the animal facility of the University of Tokyo and used after backcrossing with C57BL/6 mice eight to ten times An Irf7 gene-targeting construct that replaces exons 2 and 3 (corresponding to amino acids 7–109; 383 base pairs) with a phosphoglycerate kinase promoter-driven β-geo-positive selection cassette ( pgk-β-geo ) was transfected into E14-1 ES cells An oligonucleotide probe containing the NF-κB-binding site of the IFN-β gene promoter was used Antigen-specific CD8 + T-cell response The visualization of ovalbumin-specific CD8 + T cells by major histocompatibility complex (MHC) class I tetramer was carried out as described previously  B220 - /CD11c + cDCs and B220 + /CD11c int pDCs (where superscript ‘int’ indicates intermediate) were sorted using FACS Diva ( BD Bioscience ) Briefly, mice were intraperitoneally injected with 0.5 mg of whole ovalbumin ( Sigma-Aldrich ) and 50 µg of anti-CD40 ( clone FGK45 ; Alexis ) with or without 25 µg of MALP2 ( Alexis ) or 50 µg of CpG-A complexed to DOTAP Cells were then analysed using a BD Biosciences FACSCalibur flow cytometer  Cytokine concentration in the supernatants was measured using an enzyme-linked immunosorbent assay (ELISA) Data were normalized by the level of β-actin expression in each individual sample Dendritic cells were infected with HSV-1 (10 M.O.I.) or VSV (10 M.O.I.) ELISA kits for mouse IL-12 p40 and IL-6 were obtained from TECHNE Corp  EMSA and immunoblot analysis Electrophoretic mobility shift assay (EMSA) and immunoblot analyses were performed as described previously  For the in vivo studies, mice were intravenously infected with 1 × 10 7 plaque-forming units of HSV-1 or intraperitoneally infected with 1 × 10 5 plaque-forming units of EMCV, and sera were collected 12 h after infection For the pDC depletion experiment, mice were injected intraperitoneally with 1 mg of purified 120G8 antibody or control rat IgG ( Jackson ImmunoResearch ) at day 1 and day 0 before immunization. Ifnar1 -/- mice were purchased from BK Universal Group  Immunoblotting was performed with anti-phospho-SAPK/JNK , anti-SAPK/JNK , anti-phospho-p38 MAPK , or anti-p38 MAPK antibodies ( Cell Signalling Technology ) Levels of IFN-α were monitored by ELISA Measurement of cytokine production Cells were seeded onto 96-well plates at 2 × 10 5 cells ml -1 and stimulated for 24 h with various reagents as follows: poly(U) (5 µg ml -1 , Sigma ); LPS from Salmonella minnesota Re-595 (100 ng ml -1 , Sigma ); poly(I:C) (100 µg ml -1 , Amersham ); CpG-A (3 µM); and CpG-B (3 µM) MEFs were infected with HSV-1 (1 multiplicity of infection (M.O.I.)), VSV (1 M.O.I.) or EMCV (0.1 M.O.I.) Methods Generation of Irf7 -/- mice Genomic DNA containing the Irf7 gene was isolated from a 129/Sv mouse genomic library Mice from these independent clones displayed identical phenotypes Other mutant mice The generation of Irf1 -/- , Irf3 -/- and Irf9 -/- mice has been described previously  Poly(U) was complexed with DOTAP ( Roche Diagnostics ) according to the manufacturers instruction Preparation of dendritic cells Spleens were digested with 1 mg ml -1 collagenase A ( Roche Biochemicals ) and 20 mM EDTA, and subjected to negative selection of T and B cells with anti-CD5 and anti-CD19 antibodies ( eBioscience ), and anti-rat IgG-coated Dynabeads ( Dynal ) Primers for IFN-α1 were used as follows: 5′-GCCTTGACACTCCTGGTACAAATGAG-3′ (sense) and 5′-CAGCACATTGGCAGAGGAAGACAG-3′ (anti-sense) Primers for β-actin and IFN-β have been described previously  Quantitative real-time RT–PCR analysis was performed using LightCycler and SYBRGreen system ( Roche ) Reagents Synthesized oligodeoxynucleotides were purchased from Hokkaido System Science Recovered cells were incubated with anti-B220 and anti-CD11c antibodies ( BD Biosciences ) RNA analysis Total RNA was prepared as described previously  Six days later, spleens of the mice were removed and homogenized into single-cell suspensions Smad3 -/- and Myd88 -/- mice were provided by K The anti-IRF-7 polyclonal antibody was raised against the peptide STVGPATENREEVSLS by rabbit immunization The cells were triply stained with fluorescein isothiocyanate-conjugated anti-CD8α antibody, APC-conjugated CD44 antibody and phycoerythrin-conjugated K b /ovalbumin tetramer according to the manufacturers instructions (MBL) The ELISA kit for mouse IFN-α was purchased from PBL Biomedical Laboratories  The pDC-specific monoclonal antibody (120G8; ref. 29 ) and IFN-β were provided by G The sequences of oligodeoxynucleotides are as follows: CpG-A (D19; ref. 20 ), ggTGCATCGATGCAgggggG; CpG-B (oligodeoxynucleotide 1668; ref. 24 ), tccatgacgttcctgatgct To prepare bone-marrow-derived dendritic cells, bone marrow cells were cultured with 100 ng ml -1 human Flt3L ( PeproTech ) for 6 days Trinchieri and Toray industries , respectively Upper-case and lower-case letters indicate bases with phosphodiester- and phosphorothioate-modified backbones, respectively Viral infections Virus stocks were grown and virus titres quantified as described previously  We microinjected two independent homologous recombinants into C57BL/6 blastocysts and intercrossed heterozygous F 1 progenies to obtain Irf7 -/- mice We performed supershift with the anti-RelA antibody ( Santa Cruz ) Yokote and S Although IRF-3 also participates in this classical pathway (refs 7 , 9–12 ; see also Fig. 1b and Supplementary Fig. 2c ), it contributes little in the absence of IRF-7, presumably because IRF-3 needs to interact with IRF-7 for its full function he IFN signal is dispensable for an early phase of IFN-α mRNA induction in pDCs (ref. 23 ; see also Supplementary Fig. 3h ), prolonged activation of the TLR9–MyD88 signalling pathway and IFN-dependent IRF-7 induction are required for the robust production of IFN-α Although there is much circumstantial evidence for the potential role of IRF-7 in the MyD88-dependent induction of IFN-α/β genes as a result of TLR activation in pDCs , it is still unclear to what extent IRF-7 participates in the robust IFN production mechanism characteristic for this cell type As reported previously , the production of IFN-α as a result of infection by these viruses is completely dependent on MyD88 in splenic pDCs ( Fig. 1d ; see also Supplementary Fig. 3b, c ) As shown in Fig. 1b , IFN-α messenger RNA induction was abolished in Irf7 -/- MEFs, as revealed by quantitative polymerase chain reaction with reverse transcription (RT–PCR) (see also Supplementary Fig. 2a ) As shown in Fig. 1c , the induction of IFN-α and -β mRNA upon viral infection was impaired in Irf7 -/- pDCs, but was normal in Irf3 -/- pDCs As shown in Fig. 2a , robust induction of IFN-α/β mRNA expression was observed upon CpG-A stimulation of pDCs, but not conventional DCs (cDCs), from wild-type mice, and this induction was abolished in pDCs from Irf7 -/- mice ( Fig. 2a ; see also Supplementary Fig. 3d ) despite the normal expression of TLR9 mRNA ( Supplementary Fig. 3e ) As shown in Fig. 2b , the CpG-A-induced production of IFN-α was abolished in Irf7 -/- and Myd88 -/- pDCs, whereas it was normal in Irf3 -/- pDCs (see also Supplementary Fig. 3f ) As shown in Fig. 2d , activation of NF-κB, JNK and p38 occurs normally in Irf7 -/- dendritic cells when stimulated by CpG-B (oligodeoxynucleotide 1668; ref. 24 ) As shown in Fig. 3a , c , IFN-α induction is markedly inhibited in the sera of Irf7 -/- mice infected with either of these viral types, whereas it remained high in both Irf3 -/- and Myd88 -/- mice, highlighting the major contribution of the classical MyD88-independent, IRF-7-dependent pathway to systemic IFN induction against viral infection As shown in Fig. 4a , induction was severely impaired in both Irf7 -/- and Myd88 -/- mice when CpG-A was used as the adjuvant As such, depending on the nature of the virus or viral load, both pathways may need to cooperate to ensure a robust antiviral response As such, the TLR9/7–MyD88–IRF-7 pathway for IFN-α/β gene induction genetically defined here is distinct from IFN-β gene induction through the activation of other TLRs, such as TLR4, wherein activation of IRF-3 by TRIF (Toll/IL-1 receptor-domain-containing adaptor inducing IFN-β) and TRAM (TRIF-related adaptor molecule) has a critical part (ref. 2 ; see also Supplementary Fig. 4a ) Because TLR9 signalling is the focus of much attention in the context of the regulation of adaptive immune responses , we next examined the role of the MyD88–IRF-7 pathway in the induction of the antigen-specific CD8 + T-cell response by immunizing mice with soluble ovalbumin and TLR agonists  Because TLR9-dependent activation of NF-κB, stress-activated protein kinase (SAPK)/JNK and p38 mitogen-activated protein (MAP) kinase is dependent on the canonical MyD88–TRAF6 pathway and IRF-7 interacts with both MyD88 and TRAF6 (refs 18 , 19 ), we asked whether IRF-7 is also required for the activation of these pathways Consistently, induction of pro-inflammatory cytokines such as interleukin-12 (IL-12) and IL-6 is not inhibited in Irf3 -/- and Irf7 -/- dendritic cells ( Fig. 2e ) Consistently, Irf7 -/- mice are more vulnerable than Irf3 -/- and Myd88 -/- mice to these viral infections ( Fig. 3b , d ) Consistently, robust IFN-α production is abolished in Irf7 -/- pDCs but not in Irf3 -/- pDCs ( Fig. 1d ; see also Supplementary Fig. 3b ) Consistently, total IFN activity in the supernatant of Irf7 -/- MEFs was markedly reduced ( Supplementary Fig. 2c ) Essentially the same results were obtained with in vitro cultured bone-marrow-derived pDCs (data not shown) Furthermore, the CpG-A-dependent, ovalbumin-specific CD8 + T-cell response was also impaired by pre-treatment of wild-type mice with 120G8, an antibody that allows selective depletion of pDCs (ref. 29 ; see also Fig. 4b ) Furthermore, the in vivo roles of IRF-7 in the regulation of innate and adaptive immunity remain unknown However, it must be emphasized that this functional dichotomy may not be applicable to every case of the immune response However, the actual contribution of IRF-7 to the transcriptional activation of IFN-α/β genes in distinct cell types upon viral infection or TLR activation is still not clarified In any case, our results clearly demonstrate that IRF-7 governs the entire IFN response In contrast, induction of IFN-α/β mRNA expression occurred normally in Irf3 -/- pDCs ( Fig. 2a ) In contrast, MEFs lacking Myd88 retained the ability to induce IFN-α/β mRNAs in response to these three viruses ( Fig. 1b ) In fact, IRF-7 mRNA is expressed in unstimulated pDCs and other cell types ( Supplementary Fig. 3g ) It has been shown that although IFN production is dependent on the TLR9–MyD88 pathway in HSV-1-infected splenic pDCs, this pathway is not essential for the in vivo innate immune response against this virus  It is worth noting that robust production of IFN-α was abolished in Ifnar1 -/- and Irf9 -/- pDCs ( Fig. 2c ), both of which are defective in the IFN-signal-dependent induction of Irf7  It is worth noting that the CD8 + T-cell response was normal in Irf7 -/- mice when the adjuvant used was a mycoplasmal lipopeptide (MALP2) that activates TLR2 (and TLR6) but does not induce high-level IFN production, indicating the operation of the MyD88-dependent, IRF-7-independent gene activation programme for this TLR-induced T-cell response (ref. 28 ; see also Fig. 4a ) More recently, we reported that another IRF member, IRF-5, also interacts with and is activated by MyD88, and that IRF-5 is essential for pro-inflammatory cytokine induction  On the other hand, CpG-A-dependent antibody responses against 2,4,6-trinitrophenol-keyhole limpet haemocyanin remained unaffected in Irf7 -/- mice ( Supplementary Fig. 4b ), which is congruent with the above results showing the normal induction of pro-inflammatory cytokines in Irf7 -/- dendritic cells Other transcription factors, such as IRF-1, IRF-5 and Smad3, are also implicated in IFN gene induction but they seem to be dispensable, because IFN-α production induced by CpG-A was normal in pDCs from mice lacking either of these factors ( Fig. 2c ; see also ref. 22 ) Our study points to the differential contribution of the MyD88-independent systemic IFN response by the classical pathway compared with the MyD88-dependent local IFN response by the TLR pathway for innate antiviral immunity and CD8 + T-cell adaptive immunity, respectively Perhaps more interestingly, the mechanism of how the robust IFN production is achieved in pDCs but not in cDCs in response to the same TLR stimuli remains enigmatic, and this is an interesting future issue to be addressed. Plasmacytoid dendritic cells (pDCs; also referred to as IFN-producing dendritic cells) stand out as high producers of IFN-α/β after activation of TLR9 and its subfamily member TLR7(8)  Similarly, the induction of IFN-β mRNA was markedly inhibited in Irf7 -/- MEFs, and the residual mRNA induction was abrogated in MEFs from mice with an additional deficiency for the Irf3 gene ( Irf7 -/- / Irf3 -/- MEFs or double knockout MEFs , Fig. 1b ; see also Supplementary Fig. 2b ) Taken together, these results indicate that IRF-7 is essential and IRF-3 is dispensable for the MyD88-dependent induction of IFN-α/β genes via the TLR9 subfamily The detailed mechanism of IRF-7 activation by TLR9 signalling remains to be clarified, although our previous study suggests the involvement of the IRAK kinases for IRF-7 phosphorylation  The induction of IFN-α/β production is primarily controlled at the transcriptional level, wherein IRF-7 of the IRF family of transcription factors has been the focus of attention  The mutant mice developed normally and no overt differences were observed in haematopoietic cell populations ( Supplementary Fig. 1a–c ) The robust production of IFN-α observed upon stimulation with the synthetic RNA polyuridylic acid (poly(U)), which activates the TLR9 subfamily TLR7(8) , was also abolished in Irf7 -/- and Myd88 -/- pDCs, but was normal in Irf3 -/- pDCs ( Fig. 2b ) These previous reports and our current observations suggest that the classical IFN-α/β induction pathway operational in many cell types (see Fig. 1b and Supplementary Fig. 3c )—which is less effective compared with the MyD88–IRF-7-dependent pathway activated by the TLR9 subfamily in pDCs—constitutes a critical part of the innate antiviral defence, wherein IRF-7 has the essential role These results collectively demonstrate the selective and essential role of the MyD88–IRF-7 pathway in pDCs in the TLR9-mediated triggering of the CD8 + T-cell response, which is mediated by IFN production  These results indicate that the pathway for robust IFN production in pDCs is distinct from the classical pathway and is subject to the MyD88-dependent induction of IFN-α/β gene transcription, which is also mediated by IRF-7 These results indicate the operation of the MyD88-independent but IRF-7-dependent pathway for IFN-α/β gene induction This pathway, which we refer to hereafter as the ‘classical pathway’, has been extensively studied in the context of innate antiviral response, wherein molecules such as double-stranded RNA-activated protein kinase (PKR ), retinoic-acid-inducible gene-I (RIG-I; ref. 9 ), IκB kinase ɛ and TANK-binding kinase 1 (IKK-ɛ and TBK1, respectively; refs 10 , 11 ), and the adaptor Fas-associated death domain (FADD ) are involved Thus, similar to the induction of IFN genes by viruses in MEFs , a positive feedback mechanism also constitutes an essential aspect in pDCs; that is, activation of basally expressed IRF-7 initially induces IFN production at a low level, which subsequently enhances IFN-signal-dependent IRF-7 expression to sustain IFN gene transcription Together, these results suggest that the function of CTTP in the activation of the NF-κB/MAP kinase and IRF-5 pathways is independent of IRF-7, which selectively regulates the IFN limb of the MyD88-dependent cytokine gene induction programme in TLR signalling We first examined IFN-α/β induction in mouse embryonic fibroblasts (MEFs) infected by one of three distinct viruses: herpes simplex virus type 1 (HSV-1), encephalomyocarditis virus (EMCV) and vesicular stomatitis virus (VSV) We generated Irf7 -/- mice by the standard homologous recombination protocol, and their nullizygosity was confirmed by DNA and RNA blot and immunoblot analyses ( Fig. 1a ) We next examined the induction of IFN-α/β mRNA expression in spleen-derived dendritic cell subsets by stimulation with CpG-A, an oligodeoxynucleotide containing the unmethylated CpG motif (D19; ref. 20 ) that activates TLR9, resulting in robust IFN-α production  We next examined the role of IRF-7 in the in vivo IFN response against infections by DNA and RNA viruses We previously proposed the presence of a cytoplasmic transductional-transcriptional processor (CTTP), in which MyD88 forms a multi-molecular complex with IRF-7, TRAF6 and IRAK4 (ref. 18 ) We then purified splenic pDCs from wild-type and mutant mice by cell sorting ( 95% purity; see also Supplementary Fig. 3a ), and infected them with HSV-1 and VSV, which activate TLR9 and TLR7(8) (the TLR9 subfamily), respectively 
 Also, in basic research, intuition (misbehaviour no. 15) is an important, and perhaps in the end a researchers best, guide to distinguishing between data and noise Finally, Martinson and his colleagues consider “changing the design, methodology or results of a study in response to pressure from a funding source” as a single misbehaviour (misbehaviour no. 10) For instance, in basic science, there are no specific regulations other than keeping research records (misbehaviour no. 16) for a particular time period However, that is not the case In clinical research, by contrast, intuition should never be used for deciding what data can or cannot be included in an experiment In clinical research, on the other hand, good laboratory practice requires certain types of record-keeping, the omission of which is not just careless but potentially sanctionable, as it would place an investigator out of compliance with Federal regulations In their Commentary article on the integrity of science, “Scientists behaving badly” ( Nature 435 , 737 – 738 ; 2005 ), Brian C Indeed, every subject counts, and excluding subjects without appropriate documentation would be a serious and sanctionable matter Martinson and colleagues use a survey that blends responses from investigators doing basic discovery science with those doing clinical research, as if the accepted and acceptable practices in these two areas did not differ markedly Sir The US Office of Science and Technology Policy wisely states, in its definition of misconduct, that there must be a significant departure from the accepted practices of the relevant research community They ignore the fact that changing research design and methodology — although never the results — is precisely what investigators are supposed to do, to satisfy the criticisms of scientific review groups and the funding agencies that they represent.
 Comparison with the long-bone histology of large-bodied sauropods suggests that the island dwarf species evolved through a decrease in growth rate from its larger ancestor. Cortical histology of femora and tibiae indicates that size differences within the specimens are due to different ontogenetic stages, from juveniles to fully grown individuals Here we describe a new diminutive species of basal macronarian sauropod, Europasaurus holgeri gen. et sp. nov., and on the basis of bone histology we show it to have been a dwarf species Morphological overlap between partial skeletons and isolated bones links all material to the same new taxon Sauropod dinosaurs were the largest animals ever to inhabit the land, with truly gigantic forms in at least three lineages  Small species with an adult body mass less than five tonnes are very rare , and small sauropod bones generally represent juveniles The fossils, including excellent skull material, come from Kimmeridgian marine beds of northern Germany , and record more than 11 individuals of sauropods 1.7 to 6.2 m in total body length The little dinosaurs must have lived on one of the large islands around the Lower Saxony basin  A slightly larger individual (body length 3.7 m; DFMMh/FV 495) was sampled from its tibia and femur Because of the distal position of the sample, the cortex is relatively thinner than in the other specimens ( Fig. 2c ) Because only one cycle of purely lamellar bone was laid down, the animal must have died soon after reaching full size Both bones have the same histology of laminar fibrolamellar bone interrupted by growth marks ( Fig. 2b ), the spacing of which diminishes towards the outer bone surface, indicating a decrease in growth rate Cranial and postcranial elements of at least ten individuals, preserved as isolated bones to partially articulated skeletons, including young juveniles (estimated body length 1.7 m) to adults (body length 6.2 m) DFMMh/FV: Dinosaurier-Freilichtmuseum Münchehagen/Verein zur Förderung der Niedersächsischen Paläontologie (e.V.), Germany DFMMh/FV 291: disarticulated left premaxilla; right maxilla; right quadratojugal; occipital region; left laterosphenoid–orbitosphenoid complex; right surangular; right angular; left dentary; teeth; cervical and sacral vertebrae; and cervical and dorsal ribs of one individual (see Fig. 1 and Supplementary Information ) Diagnosis Etymology Europasaurus also differs from Camarasaurus in its short nasal–frontal contact; rectangular parietal in posterior view; and undivided presacral neural spines Europasaurus differs from almost all known neosauropods in its diminutive adult body size Europasaurus differs from Brachiosaurus in the shorter muzzle, quadratojugal contacting squamosal; participation of jugal in ventral margin of skull; short nasal–frontal contact; and humerus flat anteromedially with proximal and distal epiphyses not aligned Europasaurus differs from Camarasaurus in the wing-shaped posterior process of the postorbital being slightly longer and wider than the anterior process, whereas it is much shorter in Camarasaurus  Europasaurus differs from Lusotitan atalaiensis in the shape of the ilium and the astragalus, and from the potentially valid ‘ Cetiosaurus ’  humerocristatus in its shorter and less prominent deltopectoral crest Europasaurus holgeri gen. et sp. nov. shows the following unambiguous autapomorphies (see also Supplementary Information ): nasal process of premaxillary projecting anterodorsally; medial notch on posterior dorsal margin of cervical vertebral centra; scapular acromion with a prominent posterior projection; and transverse width of astragalus twice its dorsoventral height and anteroposterior length Four size-related trends in the cortical histology of the Europasaurus long bones indicate that the fossils represent a growth series from juveniles to subadults to fully grown adults : (1) only medium-sized and larger individuals have growth marks (annuli and LAGs) that diminish in spacing towards the outer surface, recording a decreasing growth rate; (2) only the largest individual was fully grown; (3) vascularization decreases from the smallest to the largest individuals, which is coupled with increased organization of the vascular network; and (4) haversian remodelling increases with increasing body size, from none in the four smallest specimens to many secondary osteons in the largest Fusion of cranial bones suggests that Telmatosaurus was fully grown , but the ontogenetic status of Magyarosaurus remains uncertain in the absence of histological or bone fusion evidence Holotype Horizon and locality However, the vascular canals in the outermost cortex are large and open to the bone surface, indicating active growth at the time of death In the inner part, the laminar fibrolamellar bone is heavily remodelled by secondary osteons with little primary bone remaining In the next-largest individual (body length 3.5 m; DFMMh/FV 001), the primary osteons in the fibrolamellar complex are mature with a narrow central vascular canal It also indicates that the diminutive body size of Europasaurus is derived It differs in having isolated secondary osteons in the inner cortex Late Jurassic, middle Kimmeridgian marine carbonate rock, bed 93 of section at Langenberg quarry , Lower Saxony basin, Oker near Goslar, Niedersachsen, northern Germany (see Supplementary Information ) Notably, there are two cyclical growth marks (annuli) in the fibrolamellar bone of the outer cortex Only a thin veneer of lamellar bone lines the vascular canals (incipient primary osteons) Palaeogeography suggests insular dwarfing as the explanation for the diminutive body size of Europasaurus  Phylogenetic analysis (see Supplementary Information ) indicates that Europasaurus holgeri gen. et sp. nov. is a macronarian that is more derived than Camarasaurus , and is the sistergroup of Brachiosauridae and all (more-derived) Titanosauromorpha Previous hypotheses about island dwarfs among dinosaurs have focused on the Cretaceous of southeastern Europe , in particular on the sauropod Magyarosaurus dacus and the hadrosaur Telmatosaurus transylvanicus from the latest Cretaceous of the Hateg basin in Romania  Referred material Sauropoda Marsh, 1878 Neosauropoda Bonaparte, 1986 Macronaria Wilson and Sereno, 1998 Europasaurus holgeri gen. et sp. nov Six individuals that represent the full body-length range known for Europasaurus were sampled histologically from one or two long bones each Such islands would not have been able to support large-bodied sauropods The ancestor of Europasaurus would have dwarfed rapidly on immigrating to the island, or as a response to shrinking land masses caused by rising sea levels The bone cortex of the smallest individual (body length 1.75 m; DFMMh/FV 009) is primary bone of the fibrolamellar complex with a reticular vascular network that grades into a laminar network ( Fig. 2a ) The bone matrix consists of fibrous tissue with plump osteocyte lacunae The bones selected were femora and tibiae, and the bone tissues examined were those of the cortex (see Supplementary Information ) The development of growth marks in the long bone cortex of Europasaurus suggests that it grew more slowly than larger less-derived neosauropod dinosaurs, including Camarasaurus  The generic name means ‘reptile from Europe’, after Europe and the Greek sauros for lizard; holgeri after Holger Lüdtke, who discovered the first bones The inner cortex lacks any indication of secondary remodelling, except for large erosional cavities The largest individual (body length 6.2 m; DFMMh/FV 415) was sampled from a distal femur fragment The largest palaeo-islands surrounding the locality in the Lower Saxony basin had areas of 200,000 km 2 (calculated from ref. 8 ) The next-largest individual (body length 2 m; DFMMh/FV 291.9) differs from the previous one in that the fibrolamellar bone is of the laminar type, the vascular network being organized into a predominantly circumferential pattern The next-largest individual (body length 4.6 m; DFMMh/FV 153) has the same primary bone histology as the previous ones, preserving five growth marks with decreasing spacing The outer cortex has three closely spaced lines of arrested growth (LAGs) The vascular canals have a lining of lamellar bone, forming primary osteons There are no growth marks in the cortical bone These features indicate a rapidly growing juvenile  This histology is typical of an external fundamental system (ESF), and indicates that the individual was fully grown  This is a reversal of the accelerated growth in the evolution of giant body size in sauropod and theropod dinosaurs . Thus, an evolutionary decrease in growth rate was important in the dwarfing of Europasaurus  Vascular canals are longitudinal, and the tissue is predominantly lamellar Vascularity decreases outwards, with the last cycle being nearly avascular and consisting of lamellar bone only
 Although these waivers benefit the scientists who submit, part of the solution should also come from developing countries themselves For this reason, many journals waive fees for scientists from developing countries who submit to them I echo the Salvador Declaration on Open Access for Developing Countries ( www.icml9.org/meetings/openaccess/public/documents/declaration.htm ) and I urge governments of these countries to consider the cost of publication as part of the cost of the research. Nonetheless, in these same countries, funds are not sufficient to pay the publishing charges made by some publications, including open access journals Sir Open access to the literature allows scientists in the developing world to read original research papers for free, which contributes to scientific advancement The support from funders must include provision for submission fees, so that government agencies that support research projects take responsibility for their investment
 A small residual attractive interaction binds these quasi-electrons in pairs, which in turn collapse to a single quantum state in the process known as Bose–Einstein condensation Although this theory of superconductivity, known as the Bardeen–Cooper–Schrieffer (BCS) model, gets everything right for conventional superconductors, it explains hardly anything in high-temperature superconductors But quantum stripes are more radical and controversial But the exact rules that govern quantum emergence are poorly understood; uncovering them is a core business of modern physics Classically, the cat must be either dead or alive, but quantum mechanically it is in a super-position of dead and alive states Conventional superconductors — those operating only at temperatures very close to absolute zero — demonstrate only a minimal form of quantum emergence Domains in which the electrons come to a complete standstill separate these ‘rivers of charge’ ( Fig. 1b ) Electronic stripes must also undergo coherent vibrations, but these cannot be seen directly For one side or the other to win the war, a way of sending a sortie for direct reconnaissance of quantum stripes must be found. Here, every quantum configuration takes the role of a classical ‘dead or alive’ state ( Fig. 1c ) Here, strong interactions and quantum motions work together to form patterns of electrons moving in serried ranks In 1995, it was discovered that small changes in the crystal structure of high-temperature superconductors can cause superconductivity to disappear, with a peculiar ‘static stripe phase’ taking over ( Fig. 1 ) In such materials, interactions between electrons diminish at low temperature, and the macroscopic electron system turns into a near-ideal (non-interacting) quantum gas of ‘quasi’-electrons In the quantum state, the cat fluctuates back and forth between alive and dead states In this issue, however, Reznik et al . ( page 1170 ) present further evidence in support of quantum stripes Members of the quantum-stripe faction hold that stripes are, in fact, always present On the other hand, there is no a priori need for electrons in crystals to behave in aesthetically pleasing ways; the epicycles could still be the truth One way to do this is to observe the change in kinetic energy of neutrons that scatter off the material inelastically Reznik and colleagues observe just such a phenomenon in a copper oxide with static stripes Reznik et al . present a new indicator of quantum stripes by exploiting the motions of the ions that form the copper oxide lattice Since 1995, such neutron-scattering experiments have added to the body of evidence supporting the case for quantum stripes  Since 1995, the ‘stripe wars’ have been raging in the demesne of high-temperature superconductivity So how can we nail down quantum stripes experimentally? Consider Erwin Schrödingers oft-cited cat hidden in a sealed box ( Fig. 1c ) So is the end of hostilities in sight? It is an everyday experience that, in a many-body system, collective behaviours emerge that are utterly unrelated to the behaviours of the objects that make it up So is this the turning point in the stripe wars? Although quantum stripes are more elusive than nuclear submarines — all signals of them have so far been indirect — the strength of the idea is that this single hypothesis explains a world of strange behaviours So, although taken seriously, quantum stripes have not been seen as a proven fact So, by taking snapshots quickly enough, one can see either a dead or a live cat Supposedly, they form highly organized patterns called quantum stripes — but only on the picosecond timescale, so the patterns average away over longer periods through the electrons constant quantum dance The discovery 20 years ago of this unusually sturdy form of superconductivity raised the curtain on a drama of wider relevance: the huge numbers of strongly interacting electrons in the copper oxide layers were plainly showing an unknown kind of collective quantum physics (for an overview, see ref. 2 ) The dispute has lasted so long only because it has proved very hard to nail down such genuine quantum behaviour The drawback is that these studies relied on information about the direction of the electron spins that was open to alternative interpretations, including some compatible with the conventional BCS picture (see ref. 6 and references therein) The evolution of a nations economy over time, for example, is difficult to predict from the often conflicting motivations of the constituent human members The existence of static stripes, initially contentious, is now generally accepted The fluctuation time of the quantum stripes is in the picosecond (10 −12 second) range, and the problem for the experimentalist is how to grab a picture of complicated spatial electron patterns in so little time The key is that these anomalies will occur on a timescale that is shorter than the quantum fluctuation time of the delocalized quantum stripes The quantum stripes will therefore seem to come to a standstill when viewed through the phonons, and the phonon anomaly should persist even when there is no sign of static stripes The same principles apply in quantum physics The same scheme works equally well with superpositions of countless many-electron configurations These motions give rise to quantized lattice vibrations, known as phonons, that can be easily observed, again by inelastic neutron scattering They show that the collective vibrations of the atomic lattice of certain superconducting copper oxides behave in a manner that is hard to explain — unless one assumes that motions characteristic of the presence of quantum stripes are shaking the ion lattice This fierce conflict, fought with the highest-calibre weapons of experimental physics, has its antecedent in a hotly contested claim about the way electrons behave in the copper oxide materials notoriously used as high-temperature superconductors This fluctuation takes a finite time This is exactly what Reznik et al . observe : even in the best superconductors, which show no sign of static stripes, the anomaly is blurred, but it is still clearly discernible Viewed from that angle, the defenders of the conventional BCS model might seem like medieval defenders of a geocentric cosmos, forced by observations to add ever more epicycles to their already baroque universe When a material superconducts, the stripes do not disappear; rather, a quantum-mechanical superposition of countless disordered stripe states forms ( Fig. 1a ), in such a way that the overall state corresponds to that of a superconducting quantum liquid (for a mathematical proof of principle, see ref. 4 ) When the phonons and the stripe vibrations enter resonance, however, they are expected to interact strongly and cause a characteristic anomaly in the spectrum of the phonons
 A tweak to those fields is now being proposed, based on findings by plasma physicist Todd Evans and his team at General Atomics in San Diego, California But it comes at a cost: the technique would probably require expensive superconducting coils to be placed near or inside the containment vessel, where space is limited and punishing radiation wears out equipment quickly By modifying a reactor machine at General Atomics, called the DIII-D tokamak, the team made the rigid magnetic fields a little fuzzy — allowing excess plasma to gently leak away rather than bursting out. “In a sense, its a beautiful concept,” Evans says E Evans et al  Evanss group successfully demonstrated a technique for preventing dangerous, lightning-like plasma discharges that could damage key parts of the reactor It will also compete with other ideas in the field that could help prevent violent disruptions in the machine or extend the time it can hold fusing plasmas It will work by using a web of carefully constructed magnetic fields to suspend a plasma gas, which is heated to hundreds of millions of degrees ITER researchers are now mulling over how to work such a breakthrough into the design, which originated more than 20 years ago and has already been through several iterations ITER will cost roughly US$6 billion to build — and aims to be the first fusion reactor to produce more power than it consumes Just as scientists and engineers from seven nations put the finishing touches to their design for a multi-billion-dollar experiment, an idea comes along that could improve it Nature Phys. doi:10.1038/nphys312; 2006), could help ITER to succeed more quickly The change will have to wind its way through several review committees before receiving final sign-off by designers in the countries funding it: the United States, the European Union, Japan, the Russian Federation, India, China and South Korea The dilemma facing those working on the international fusion reactor, known as ITER, is whether or not to incorporate the change The idea, which has been published in Nature Physics (T These are caused when plasma builds up in the weakest areas of the magnetic field that contains it. “Think of squeezing a balloon of water — the balloon bulges out through your fingers,” says Evans Trying to get scientists and engineers to decide which changes to include in the final design and which to save for ‘upgrades’ isnt going to be easy, says Ned Sauthoff, a physicist at Princeton Plasma Physics Laboratory in New Jersey and head of ITERs US team. “ITER is not just a physics experiment, its also an experiment in large-scale project management.”  newsad; In the meantime supporters of the new concept will continue to conduct experiments, says Philippe Ghendrih, a theoretical physicist at the French Atomic Energy Commission in Cadarache, where further work is being done to integrate the idea into existing ITER designs. “If several other tokamaks can demonstrate the effect, then it will be easier to convince the engineers.”  A final design review will probably begin in the autumn, and should take about a year.
 A swirl of icy cloud in the south Atlantic is shown in blue, and North Africa is shaded red After an initial test phase, MSG-2 will enter seven years of operational service above the Gulf of Guinea, and will be renamed Meteosat-9. Combining the results should reveal how cloud variation affects the heat that Earth loses to space, for example The second Meteosat Second Generation satellite (MSG-2) will take images at infrared and visible wavelengths every 15 minutes, which will allow meteorologists to track changes in weather systems. newsad; It will also measure the net balance between incoming radiation from the Sun and outgoing radiation from Earth much more accurately than satellites in lower orbits This false-colour infrared image of Earth comes from Europes newest weather satellite, which was lofted into geostationary orbit on 21-December 2005
 A fundamental question about the pathogenesis of spontaneous autoimmune diabetes is whether there are primary autoantigens Female mice with only the altered insulin did not develop insulin autoantibodies, insulitis or autoimmune diabetes, in contrast with mice containing at least one copy of the native insulin gene For type 1 diabetes it is clear that multiple islet molecules are the target of autoimmunity in man and animal models  Here we show that the proinsulin/insulin molecules have a sequence that is a primary target of the autoimmunity that causes diabetes of the non-obese diabetic (NOD) mouse It is not clear whether any of the target molecules are essential for the destruction of islet beta cells This mutation abrogated the T-cell stimulation of a series of the major insulin autoreactive NOD T-cell clones  We created insulin 1 and insulin 2 gene knockouts combined with a mutated proinsulin transgene (in which residue 16 on the B chain was changed to alanine) in NOD mice We suggest that proinsulin is a primary autoantigen of the NOD mouse, and speculate that organ-restricted autoimmune disorders with marked major histocompatibility complex (MHC) restriction of disease are likely to have specific primary autoantigens. A value of 0.01 or greater is considered positive Adoptive transfer experiments Splenocytes (3 × 10 7 ) from native insulin-negative NOD mice or standard NOD mice were injected intraperitoneally into 8-week-old NOD.SCID mice and the mice were followed for the development of hyperglycaemia All mice were housed in a pathogen-free animal colony at Barbara Davis Center for Childhood Diabetes using an approved protocol from the University of Colorado Health Sciences Center Animal Care and Use Committee An Olympus BX51 microscope connected to a high-resolution digital camera ( Pixera ) and the software Image-Pro Plus ( Media Cybernetics, Inc. ) was used Both strains were further backcrossed into NOD/Bdc mice. 129S1/SvImJ genomic regions flanking each insulin gene locus are less than 18 cM for the insulin 1 region-fixed mice and less than 19 cM for the insulin 2 region mice; the central 129 regions without the knockouts spanned these regions Diabetes Glucose was measured weekly with the FreeStyle blood glucose monitoring system ( TheraSense ), and the mice were considered diabetic after two consecutive blood glucose values of more than 250 mg dl -1  Female mice were studied Female mice were used for the study For the scoring of insulitis, each islet was scored as no insulitis, peri-islet insulitis and intra-islet insulitis by a reader blinded to the categories of the mice Histology The pancreata and salivary glands obtained from the mice were fixed in 10% formalin, then embedded in paraffin Immunodeficient NOD mice (NOD.SCID) for the adaptive transfer experiment were purchased from the Jackson Laboratory  Insulin autoantibody (IAA) assay IAAs were measured with a 96-well filtration plate micro-IAA assay as described previously and expressed as an index Jami into NOD/Bdc mice with the use of speed congenic techniques  Methods Mice Insulin 1 and insulin 2 knockout NOD mice were established by breeding the original insulin knockouts provided by J Mutated preproinsulin-transgenic NOD mice were produced by the microinjection of mutated preproinsulin 2 complementary DNA constructs ligated to the pRIP7 (rat insulin 7) promoter directly into fertilized NOD oocytes as described previously  Pancreas and islet areas were measured in a randomly selected 10–15 views at a final magnification of ×400 Paraffin-embedded tissue sections were stained with haematoxylin and eosin, and parallel sections were also stained with polyclonal guinea-pig anti-insulin or anti-glucagon antibodies ( Linco Research Inc. ), followed by incubation with a peroxidase-labelled anti-guinea-pig IgG antibody ( Kirkegaard Perry Laboratories ) Statistical tests used PRISM software ( Graphpad ). Statistics The peaks of insulin autoantibodies were analysed with Students t -tests Subsequently, islet area and insulin-positive area were measured at ×1,000 magnification Survival curves were analysed with the log-rank test The insulin-positive area divided by the pancreatic area was calculated as (insulin-positive area at ×1,000/islet area at ×1,000)/(islet area at ×400/pancreatic area at ×400) The original insulin knockout mice were produced in 129S1/SvImJ embryonal cell lines  The presence of insulitis was analysed with the Fisher exact test To calculate the insulin-positive area we modified the method of measurement of beta-cell mass in ref. 28  To rule out potential effects of 129S1/SvImJ genes in linkage with the insulin gene, the mice, which have the 129S1/SvImJ gene at insulin 1 (position 49 cM at chromosome 19) or insulin 2 (position 69.1 cM at chromosome 7) locus on the NOD background, were produced with the use of speed congenic methods We bred 129S1/SvImJ mice with NOD/Bdc mice, and NOD diabetogenic loci (idd 1–14) were fixed by backcross 3 Absence of insulitis in the presence of sialitis indicates that this influence might be organ-specific An alanine scan of insulin B:9–23 indicated that changing the native tyrosine to alanine at insulin B chain position 16 (B16) abrogated the response of B:9–23-reactive CD4 T-cell clones  As expected, all diabetic mice ( n = 15 of 15; three shown in Fig. 3 representing different genotypes) with at least one insulin 1 or insulin 2 gene and with or without the mutated transgene showed insulitis As shown in Fig. 1 , female mice lacking both native insulin genes ( ins1 -/- and ins2 -/- ) failed to produce insulin autoantibodies As shown in Fig. 4a , none of the mice lacking the native sequences of both insulin 1 and insulin 2 developed diabetes, which is consistent with their lack of insulitis As the authors discussed, small numbers of insulin-reactive T cells that are not detected by their in vitro assay might mediate the incomplete prevention of autoimmune diabetes , such as those recognizing insulin 1 At a minimum, the induction of this deletional tolerance might be a preventive pathway synergistic to the harnessing of regulatory T-cell responses. Breeding a knockout of the insulin 2 gene (produced by J Expression of proinsulin in transgenic lymphoid organs or modulating the immune response to insulin can greatly decrease the development of diabetes  Figure 2 illustrates the histology of native insulin gene double knockout female NOD mice killed at the ages of 26 weeks ( Fig. 2a–c ; transgene founder strain B) or 23 weeks ( Fig. 2d ; transgene founder strain F) Figure 3 illustrates the histology of female mice expressing native insulin that were killed after 10 weeks of age Figure 4 shows that fixing the control (non-knockout) chromosomal region surrounding the insulin genes (speed congenics backcross no. 6 for the insulin 1 region, backcross no. 4 for the insulin 2 region) on the NOD background did not alter the development of diabetes ( Fig. 4b , insulin 1 region; Fig. 4c , insulin 2 region) However, there is evidence that glutamic acid decarboxylase 65 (GAD65), insulinoma antigen 2 (IA-2), IA-2β/phogrin and heat shock protein 60 (hsp60) are not essential autoantigens of the spontaneous NOD mouse, in that mice develop diabetes despite the removal of the antigen or antigen-responding T cells  If primary autoantigenic targets exist for specific autoimmune disorders with specific MHC genotypes, we believe it likely that deletional therapies may allow potent disease prevention In addition, all transgenic founder strains with the mutated preproinsulin gene showed progression to diabetes ( Fig. 4d ) and insulitis (not shown), with founder strain F having a modest decrease in progression to diabetes and the highest thymic expression of insulin messenger RNA (mRNA data not shown), which might affect autoreactive or regulatory T-cell development with the modified B:9–23 insulin (B16:alanine) or other proinsulin epitopes of the transgene In addition, in the presence of the native insulin genes the transgene does not prevent autoimmunity (see below) In addition, it has been reported that a CD8 T-cell clone recognized insulin B:15–23 and the alternative mutation of tyrosine to alanine at B16 results in the failure to bind to the K d class I MHC molecule  In contrast, mice with the insulin 1 gene, despite lacking the insulin 2 gene, developed insulin autoantibodies ( P 0.0001; peak insulin autoantibodies) In contrast, sialitis was present at 26 weeks ( Fig. 2c ) and 23 weeks (not shown), indicating that as expected insulin knockouts do not prevent all autoimmunity of NOD mice but do prevent islet-specific autoimmunity In contrast, similar breeding of the insulin 1 knockout into the NOD mouse prevents most progression to diabetes but does not decrease the expression of insulin autoantibodies; most of these mice develop insulitis and a smaller subset progress to overt diabetes In contrast, the presence of insulin 1 restored the development of diabetes (75% of mice were diabetic at 25 weeks, by life-table analysis; Fig. 4a ) Insulin 1 differs from insulin 2 by two amino acids at positions 9 and 29 on the B chain It has recently been reported that inducing recessive tolerance with a proinsulin 2 construct with an MHC class II invariant chain promoter in NOD mice greatly decreases the development of diabetes It is extremely unlikely that the insertion of the transgene disrupted a gene important for autoimmunity, given the presence of two founder strains with the same phenotype Jami) into NOD mice results in an accelerated development of diabetes and an enhanced production of insulin autoantibodies  Mice have two insulin genes, insulin 1 on chromosome 19, and insulin 2 on chromosome 7 Most CD4 T cells infiltrating NOD islets react to insulin, and more than 90% recognize insulin B chain 9–23 peptide amino acids (insulin B:9–23) (ref. 7 ) Multiple studies indicate that both insulin 1 and insulin 2, which differ by only 2 of 51 amino acids, can be the target of autoimmunity Mutated preproinsulin-transgenic mice were produced directly in NOD mice None of the 27 insulin 1 - insulin 2 - islets had insulitis, in contrast to mice with native insulin genes (insulin 1 + insulin 2 - : 18 islets with no insulitis (14%), 22 with peri-islet insulitis, 88 with intra-islet insulitis; insulin 1 - insulin 2 + : 99 with no insulitis (50%), 47 with peri-islet insulitis, 54 with intra-islet insulitis; insulin 1 + insulin 2 + : 10 with no insulitis (23%), 16 with peri-islet insulitis, 18 with intra-islet insulitis; P 0.001) One hypothesis to account for these potent MHC associations and beta-cell-specific destruction is to posit that the immune response for a given genotype (with immune dysregulation and environmental factors) is dependent on an antigen whose targeting is essential for disease Our studies indicate that insulin peptide B:9–23 might be an essential target of the immune destruction of the NOD mouse, although it is possible that the processing of other epitopes in the proinsulin molecule might be affected by the single amino-acid mutation at position B16, and there is the caveat that mutated proinsulin (B16:alanine) transgene expression might not be permissive for islet autoimmunity Our studies provide evidence that the development of insulin autoantibodies, insulitis and diabetes is dependent on native insulin gene sequences Risk of type 1A diabetes varies by more than 1,000-fold depending on the HLA (human leukocyte antigen) DQ genotypes in man Similarly, almost all non-diabetic mice killed after 20 weeks of age ( n = 25 of 26, three shown in Fig. 3 representing different genotypes) showed insulitis ( P 0.01 versus double knockouts for insulin) Splenocytes were obtained from mice between 9 and 26 weeks of age, a time at which accelerated transfer of diabetes is observed for standard NOD mice Such deletional therapies may be more robust than regulatory experimental manipulations, which usually do not abrogate insulitis  T-cell clones reacting with multiple antigens of the islets, including novel molecules induced to be expressed within islets, are able to transfer diabetes, providing strong evidence that multiple actual and potential islet targets exist The authors concluded that insulin is a key but not essential antigen for diabetes of the NOD mouse The long period to diabetes induction by splenocytes from mice lacking native insulin genes, when transferred into mice with native-insulin-containing islets, indicates the possible development of pathogenic T-cell responses after splenocyte transfer The mutation (alanine rather than tyrosine at B16) was chosen to preserve insulins metabolic activity but to abrogate T-cell reactivity to B:9–23 (refs 1 , 3 , 7 –9 ) The NOD transgenic strains were combined with NOD insulin gene knockouts and prospectively evaluated for the production of insulin autoantibodies, insulitis and diabetes, relative to the presence or absence of the insulin 1 gene The objective of the current study is to determine whether a complete lack of native insulin with B:9–23 sequence would abrogate the development of anti-islet autoimmunity The pancreas was normal, with insulin-staining cells comprising 0.75% and 1.8%, respectively, of the pancreatic area (standard NOD mice less than 10 weeks of age ( n = 10) showed an insulin-staining area ranging from 0.74% to 1.56% (median 1.2%)) The protection in terms of diabetes was incomplete despite low levels or absence of insulin-reactive T cells after immunization with proinsulin 1 and 2 and low levels or absence of anti-insulin autoantibodies The recipient mice expressed native insulin 1 and insulin 2 in their islets, but this experiment does not prove that normal insulin or insulin B:9–23 is the major target of the transferred cells immunoreactive insulin (not shown)), with ‘early’ (for NOD) development of metabolic diabetes in the absence of insulitis (less than 10 weeks of age), whereas two other founder strains prevented this metabolic diabetes (strains B and F) and were used to analyse the development of immune-mediated diabetes in the absence of native insulin sequences There is at present considerable evidence that insulin is an important target molecule, despite evidence for many additional relevant targets  There was no insulitis at 26 weeks ( Fig. 2a , b ) and 23 weeks ( Fig. 2d ) in the mice lacking native insulin These splenocytes from the insulin gene double-knockout NOD mouse induced diabetes 2–4 months after transfer into the NOD.SCID mice They did not use a proinsulin 1 construct; instead they showed cross-reactivity between insulin 1 and insulin 2 by in vitro assay To determine whether functional ‘diabetogenic’ splenocytes could be detected in the insulin knockout mice, we harvested spleen cells from insulin gene double-knockout and wild-type NOD mice and transferred them into immunodeficient (severe combined immunodeficiency; SCID) NOD recipients To exclude the possibility that the prevention of diabetes was related to the chromosomal region from 129 mice of the knockouts bred into the NOD or of the mutated preproinsulin transgene, we analysed the progression to diabetes of multiple control crosses To prevent diabetes in such mice lacking both native insulin genes (‘metabolic diabetes’) we developed preproinsulin-transgenic strains directly in NOD mice with a mutated sequence Type 1A diabetes is characterized by specific destruction of the cells within the pancreas that produce insulin , and alleles of class II MHC genes are major determinants of disease in both humans and animal models  We proposed that both the preproinsulin 1 and 2 B chain 9–23 sequences, differing only at position 9 (serine for insulin 2, proline for insulin 1), would be redundantly important for the development of diabetes in NOD mice and therefore produced NOD mice lacking both native insulin genes Whereas 75% of recipients were diabetic by 8 weeks after the transfer of wild-type splenocytes, recipients of splenocytes from insulin gene double-knockout NOD mice had a marked delay in developing diabetes ( Fig. 4e ; P 0.02)
 Here, we validate experimentally a biochemical systems theoretical model of sphingolipid metabolism in yeast  Mathematical models have become a necessary tool for organizing the rapidly increasing amounts of large-scale data on biochemical pathways and for advanced evaluation of their structure and regulation Most of these models have addressed specific pathways using either stoichiometric or flux-balance analysis , or fully kinetic Michaelis–Menten representations , metabolic control analysis , or biochemical systems theory  Simulations of metabolic fluxes, enzyme deletion and the effects of inositol (a key regulator of phospholipid metabolism) led to predictions that show significant concordance with experimental results generated post hoc So far, the predictions of kinetic models have rarely been tested using direct experimentation The model also allowed the simulation of the effects of acute perturbations in fatty-acid precursors of sphingolipids, a situation that is not amenable to direct experimentation The results demonstrate that modelling now allows testable predictions as well as the design and evaluation of hypothetical ‘thought experiments’ that may generate new metabolomic approaches. A fraction of total extract from each sample was reserved for phosphate determination, and the remaining samples were then analysed by a Surveyor / TSQ 7000 liquid chromatography/mass spectrometry system  A single colony from a YPD plate of each strain was inoculated into 5 ml of YPD and incubated at 30 °C Cell pellets were snap-frozen in a methanol/dry ice bath and stored at -80 °C Fresh YPD was used to dilute 24-h cultures to an absorbance of 0.8 at 600 nm (A 600 = 0.8) and this was used to inoculate an appropriate amount of medium for the labelling experiment (1 ml medium per sample point + 1–2 ml extra) for overnight growth to mid-log phase in a shaker water bath at 30 °C and 220 r.p.m Individual lipids were quantified by scraping the band and counting with liquid scintillation Internal standards were added to frozen pellets and sphingolipids were extracted in a one-phase neutral organic solvent (isopropanol:water:ethyl acetate 30:10:60 v:v:v) as described  Lipid extraction Lipids were extracted as previously described  Lipid measurements from TLC were normalized by total lipid phosphate, which was determined with a standard curve analysis and colorimetric assay of ashed phosphate as previously described  Lipid separation and quantification Lipid samples were resuspended in 50 µl of 16:16:5 chloroform:methanol:water and 25 µl was applied to a Whatman silica gel TLC plate , which was pre-treated with acetone Lipids were qualitatively defined by parent ion scanning for known fragments characteristic for a specific sphingolipid class including sphingoid bases, sphingoid base phosphates and ceramides, as described  Liquid chromatography/mass spectrometry analysis of yeast sphingolipids Cells were cultured to mid-log phase in SC media Media used were YPD with 2% w/v glucose and synthetic minimal complete (SC) Methods Yeast strains and culture media The S. cerevisiae strains used were JK9-3dα ( MATα trp1 leu2-3 his4 ura3 ade2rme1 ) (ref. 22 ) for wild type and SGP3 ( MATα leu2-3 , 112 trp1 ura3-52 his3 ade8 ras1 :: HIS3 ) for wild type of the lyase deletion strain JS16 ( MATα leu2-3 , 112 trp1 ura3-52 his3 ade8 ras1 :: HIS3 bst1Δ :: NEO ) (ref. 9 ) Modelling Software used for model development included Maple 7 for the computation of kinetic parameters and development of the generalized mass action (GMA) equations, and PLAS (ref. 26 ) for the numerical integration and analysis of the differential equations. Myo-inositol was added to a final concentration of 75 mM, and samples were taken at the indicated times and collected by centrifugation at 2,800 g  Samples of 1 ml were taken at desired time points and immediately placed on ice with 100 µl 10% tricarboxylic acid (TCA) Samples were quantitatively analysed on the basis of calibration curves generated with synthetic standards Sphingolipid labelling Cells were resuspended in SC medium and allowed to equilibrate for 30 min in a shaker water bath at 30 °C and 220 r.p.m. before labelling with 1 µCi ml -1 of [9,10 3 H]-palmitate (53 Ci mmol -1 ) The mass of each species was normalized by organic phosphate determination The plate was resolved using 9:7:2 chloroform:methanol:4.2 M ammonium hydroxide, sprayed with EN 3 HANCE and radiographed on BioMax film  A square pulse was used to increase the total concentration of each precursor to 1.5 times the basal mass level for one minute, followed by an immediate return to the initial value Additionally, the availability of mutant yeast strains for many genes of sphingolipid enzymes facilitates experimental verification of model predictions Also, because ceramide is a bioactive lipid, the results raise the intriguing hypothesis that acute and significant changes in ceramide may contribute to the cellular response to inositol Although it is not proof of correctness, this non-intuitive result suggests that the model functions adequately even for rather tangential aspects of sphingolipid metabolism As a more complex application, we tested the responses of sphingolipids to large perturbations in overall lipid metabolism by simulating the addition of inositol, a well-studied and important regulator of (glycerol-) lipid metabolism in yeast  As an example, we simulated the effects of changes in endogenous palmitoyl-CoA on the flux through the de novo pathway As seen, DHS increased early on and then decreased at later time points, whereas the complex sphingolipids increased steadily over the entire time course, as predicted by the model Complex sphingolipids exhibited a delayed increase that was sustained throughout the time course Details can be found in Supplementary Text 3  Each precursor value was perturbed separately ( Supplementary Text 5 ), and the resulting lipid profiles were compared Figure 2b shows the corresponding experimental results First, the current model provides a comprehensive, functional integration of experimental data ( Supplementary Tables S1 and S2 ) that facilitates the understanding of the organization and regulation of sphingolipid metabolism in yeast Furthermore, steady-state analysis of the model revealed that the basal PHS level in the lyase knockout should be ∼20% greater than in wild type (data not shown), which fit well with reported experimental data  In the corresponding experiment, wild type and DPL1 knockout strains were labelled with [ 3 H]-palmitate, and the radioactivity was measured in individual sphingolipid species Interestingly, we found a biphasic response for ceramide with an initial decrease followed by a return to baseline Levels of DHS in the wild type and lyase knockout followed a similar shape, but the wild type had slightly lower levels at each time point Loewen et al. showed recently that addition of 75 µM inositol markedly increased phosphatidylinositol (PI) and slightly lowered most other phospholipids, including phosphatidic acid, which was proposed to act as a bioactive lipid in regulating transcription responses to inositol Moreover, all primary metabolites, enzymes and their genes, and some of the regulatory signals, are known in this organism , thus allowing the crucial initial step of model design through the proper mapping of the metabolic pathways as shown in Fig. 1 (and listed in detail in Supplementary Tables S1 and S2 ) Once the model was assembled and proofed, it was critical to probe for parameters that could unduly influence the model One important difference between the perturbations of external (exogenous) palmitate versus internal (malonyl CoA) palmitate was the maximum amplitude of palmitoyl-CoA produced by each, as well as the resulting flux through the sphingoid backbones Overall, the extended model was deemed ready for testable predictions and validation Recent recognition of sphingolipids, such as sphingosine, ceramide and sphingosine-1-phosphate, as bioactive molecules has increased interest in understanding sphingolipid metabolism and its regulation Samples were taken at various time points, lipids were extracted and separated by thin-layer chromatography (TLC), and individual bands were quantified by liquid scintillation (see Methods) Second, the simulations show significant agreement with experimental results, thus establishing the utility of the model Specifically, the loss was fitted with a standard decay function and used in the model as cellular substrate uptake (see Supplementary Text 4 ) Sphingolipids have only one known route of ultimate breakdown, namely through the lyase encoded by DPL1 (ref. 15 ); this prompted an investigation of the effects of deleting this gene Such understanding is impeded, however, by the complexity and multitude of interconnected reactions that characterize the sphingolipid pathway , thus highlighting the need for mathematical modelling  Taken together, the model may serve as a rigorous foundation for a larger assemblage of information on yeast lipid metabolism and as a nidus for meaningful integration of metabolomic data. Taken together, these results suggest that the availability of the acyl-CoA substrate is very important for the first enzymatic reactions of de novo sphingolipid synthesis The autoradiographs ( Supplementary Fig. 5 ) show prominent bands for the LCB-Ps at the 5-min time point in the knockout, but not in the wild type The concordance between model and experimental results suggested the possibility of predicting the outcome of experiments that are otherwise difficult to perform or control The details of model design, including the rationale for using biochemical systems theory (BST), incorporation of complex sphingolipids, and fatty-acid synthesis and elongation, are presented and discussed in the Supplementary Text 1 and 2  The external palmitate perturbation produced an increase in palmitoyl-CoA of 4.9 × 10 -3  µM compared with 2.94 × 10 -8  µM from the malonyl-CoA (data not shown) The first contains some of the central metabolites of sphingolipid metabolism, indicating a capacity for responsiveness that is expected in signal transduction systems The first simulation followed the dynamics of incorporation of [ 3 H]-palmitate into sphingolipids (bulk concentration of palmitate of 0.182 µM, specific activity of 53 Ci mmol -1 ) over a time course of 60 min ( Fig. 2a ) The flux of radioactive tracer through the sphingolipid pathway was simulated with a novel mathematical method specifically developed for this purpose ( Supplementary Text 5 ) The fluxes of dihydroceramide and phytoceramide exhibited a similar shape in both simulated perturbations, but were reduced in amplitude by about two-thirds for the malonyl-CoA precursor ( Fig. 4a versus 4b ) The levels of complex sphingolipids were very close for wild type and knockout strains, and increased steadily in the first 20 min, before reaching a plateau ( Fig. 2f and Supplementary Fig. 5 ) cted by the model to be similar ( Fig. 2c , e ) The levels of the LCB-Ps were appreciably elevated in the knockout but not the wild type, where they were below detection limits ( Fig. 2d ) The model predicted the levels of long-chain base phosphates (LCB-P)—the substrates of the lyase—to be significantly higher in the knockout than in the wild type at the early time points, but eventually to return to wild-type levels by clearance through the action of the LCB-P phosphatases ( Fig. 2c ) The remaining high sensitivities can be explained and fall into two distinct groups ( Supplementary Fig. 3 ) The result was a significant increase in complex sphingolipids accompanied by a marked decrease in ceramide levels ( Fig. 3a ) The results from this study support the three main goals of biochemical pathway modelling The second group possesses the highest sensitivities and comprises metabolites on the periphery of the pathway where the model representation is coarser and more susceptible to perturbations The simulation showed an immediate increase in labelled dihydrosphingosine (DHS), which then gradually declined The simulation with the BST model was performed by eliminating the appropriate flux term to mimic the mutant, and then following the palmitate tracer in the wild type and the DPL1 knockout The simulations showed that after changing the levels of either palmitate ( Fig. 4a ) or malonyl-CoA ( Fig. 4b ), the tracer quickly dissipated through the upstream metabolites (the sphingoid bases and ceramides) of the metabolic pathway whereas it accumulated and decreased more slowly in the downstream metabolites and, in particular, the complex sphingolipids The validation experiments typically tracked sphingolipid fluxes, using radiolabelled precursors The vast majority of sensitivities are small in magnitude ( Supplementary Table S3 ), indicating attenuation or modest amplification of most perturbations These bands decreased within 40 min, as in the simulation These three principal reservoirs of acyl-CoAs maintain a low free concentration of acyl-CoA in rapid equilibrium with the large pool of bound acyl-CoA Third, the model may be used to predict results of hypothetical experiments that are otherwise difficult, or even impossible, to perform but that yield insights that are critical for understanding the functionality of the system This agrees with the miniscule amounts of dihydrosphingosine-1-phosphate (DHS-1-P) and phytosphingosine-1-phosphate (PHS-1-P) (0.0046% of total phospholipids) previously reported  This equilibrium, in turn, allows large amounts of palmitoyl-CoA to be readily available for specific processes such as β-oxidation, glycerolipid synthesis and protein acylation, but without the need to maintain high concentrations of free acyl-CoA, which can be toxic and can inhibit key enzymes such as Acc1p (refs 20 , 21 ) This part of the pathway is complicated because changes in the levels of palmitoyl-CoA may result from changes in either external palmitate or changes in the rate of synthesis of endogenous palmitate through changes in malonyl-CoA This significant influence on sphingolipid production by the availability of acyl-CoA substrate can be explained by the fact that the free in vivo levels of long-chain acyl-CoA esters in yeast are maintained at nanomolar concentrations by the acyl binding protein (Acb1p), the sterol carrier protein 2 and the fatty-acid binding protein  This suggests a greater influence of external palmitate, as opposed to endogenous palmitoyl-CoA, on de novo sphingolipid synthesis This was achieved by performing sensitivity analysis, and the results showed that the system is robust at steady state Thus, the dynamic model predictions were accurate To allow comparisons of experimental and simulated results, we quantified the loss of radioactive tracer from the medium over the time course of the experiment To test the veracity of this simulation, we measured ceramide levels by mass spectrometry under similar conditions as reported and, indeed, found the same biphasic behaviour ( Fig. 3b ) Tritiated palmitate (0.182 µM) was added to the medium of mid-log-phase yeast We selected yeast as our target organism for modelling because sphingolipid metabolism is largely conserved among eukaryotes We simulated the effects of the external inositol by increasing the basal mass of PI in the model three times and followed the changes in ceramides and complex sphingolipids We speculated that the increased PI should increase synthesis of complex sphingolipids through IPC1 , which utilizes PI as a substrate and hence consumes ceramide and reduces its levels
 Caenorhabditis elegans homologues of the retinoblastoma (Rb) tumour suppressor complex specify cell lineage during development  Furthermore, particular gene inactivations that disrupt RNAi reverse the cell lineage transformations of Rb pathway mutants Here we show that mutations in Rb pathway components enhance RNA interference (RNAi) and cause somatic cells to express genes and elaborate perinuclear structures normally limited to germline-specific P granules Rb may act by a similar mechanism to transform mammalian cells. These findings suggest that mutations in Rb pathway components cause cells to revert to patterns of gene expression normally restricted to germ cells Behavioural test For the aldicarb resistance test, young adult animals were transplanted to agar plates containing 1.0 mM of the acetylcholinesterase inhibitor aldicarb, and the percentage of animals paralysed over a time course of 140 min was measured For the levamisole resistance test, young adult nematodes were incubated in M9 solution with 1.0 mM of the nicotinic agonist levamisole, and the percentage of twitching animals was counted 3 min later. Immunofluorescence staining L1 larvae were permeablized using a freeze–crack method by freezing between a polylysine-coated slide and a coverslip followed by rapid removal of the coverslip Larvae were stained using monoclonal (1:20 dilution) or affinity purified polyclonal (1:2,000 dilution) anti-PGL-1 antibodies (gifts from S Methods Strains The strains and alleles used were: N2 Bristol (wild type); let-23(sy1) II, let-60(n1700) IV, lin-1(e1777) IV, lin-15(n765) X; the doubly mutants let-23(sy1) II; lin-15(n765) X and lin-8(n2374) II; lin-36(n766) III RNAi-defective mutants used were mut-16(ne322) I, rrf-1(pk1417) I, mut-7(pk204) III, rde-4(ne299) III, mut-14(pk738) V, rde-1(ne300) V RNAi-enhanced mutants used were rrf-3(pk1426) II, eri-1(mg366) III Slides were immediately immersed in ice-cold 100% methanol for 10 min followed by ice-cold 100% acetone for 5 min Strome) followed by TRITC-conjugated donkey anti-mouse IgM (1:200 dilution; Jackson Immunoresearch ) or Alexa Fluor-conjugated goat anti-rabbit IgG (1:1,000 dilution; Molecular Probes ) SynMuv A mutants include lin-8(n2731) II, lin-8(n111) II, lin-38(n751) II, lin-56(n2728) II, lin-15A(n433) X, lin-15A(n767) X SynMuv B mutants include lin-35(n745) I, lin-53(n833) I, dpl-1(n2994) II, dpl-1(n3663) II, hpl-2(ok917) III, lin-9(n112) III, lin-13(ok838) III, lin-36(n766) III, lin-37(n758) III, tam-1(cc567) V, lin-15B(n744) X A mutation in mes-4 also suppresses the lethality and ectopic P granule phenotypes of mep-1 and let-418 (ref. 11 ), and mes-4 is required for germline co-suppression  A mutation in the C. elegans gene lin-15 causes enhanced sensitivity to RNAi ( Fig. 1a ) A related model that incorporates precedents for Rb control of cell cycle and endoreduplication is that the Rb pathway chromatin factors inhibit the endoreduplication of particular target loci such as the ones that generate the abundant P granule components in the germ line. mes-4 , zfp-1 , gfl-1 , pqn-28 , ZK1123.3 and M03C11.3 may be these amplified targets in the normal germ line All these dsRNA induce stronger loss-of-function phenotypes in lin-15(n765) animals ( Fig. 1a and Table 1 ) An increased level of RNAi in the C. elegans germ line is suggested by the silencing of transgenes and transposons specifically in the germ line and by the activation of transgenes and transposition by mutations that attenuate germline RNAi  Animals defective in both the synMuv A and synMuv B pathways display multiple vulva structures due to cell lineage changes, whereas animals defective in only one of the synMuv pathways have normal cell lineages in these tissues  Because mutations in the Rb pathway affect the cell divisions of vulval cells as well as enhance RNAi, we asked whether genes implicated as possible components in the RNAi pathway mediate the cell lineage defects of Rb pathway mutants Because these proteins may form a biochemical complex, they probably regulate the choice between germ line and soma via the same molecular mechanism C. elegans P granules are normally assembled in the germline blastomeres from maternally expressed gene products, and are segregated exclusively to the germline lineage during early development C. elegans RNAi gene inactivations that in turn attenuate RNAi have been identified  Consistent with a role in transcriptional gene silencing, the hpl-2 mutation causes transgene de-silencing  Consistent with the activity of these genes normally in the germ line, inactivation of these genes causes decreased brood size or sterility  Consistent with the enhanced RNAi phenotype of Rb pathway mutants, target messenger RNA abundance is markedly decreased in these mutants Consistent with this model, mes-4 RNAi suppresses the transgene silencing ( Fig. 2b ), vulval cell lineage defect ( Fig. 3a ) and somatic misexpression of PGL-1 ( Fig. 3b ) in the lin-35 ( Rb ) mutant Consistent with this model, Rb pathway mutations cause silencing of a repetitive gfp transgene in somatic cells ( Fig. 2b ) similar to germline-specific transgene silencing normally observed in the wild type  Conversely, activation of these Rb-regulated genes may confer more totipotent cell fates, which could be useful in inducing cells to recapitulate developmental pathways. Conversely, mutants with ectopic pseudovulvae, such as lin-8(n2374); lin-36(n766) or the Ras gain-of-function mutant let-60(n1700) have wild-type RNAi response ( Fig. 1a ) Double mutants between lin-35 and the RNAi-defective genes rde-1 , rde-4 and mut-7 , and between lin-15b and mut-16 , are unresponsive to nsf-1 dsRNA; they are RNAi defective, like the single rde-1 , rde-4, mut-7, or mut-16 mutants ( Supplementary Table S1 ) Drosophila homologues of MES-4 interact with SWI/SNF and NuRD complexes and antagonize Polycomb complexes  Five of the six multivulvae-suppressing clones are annotated as chromatin factors that directly interact with each other and with synMuv B pathway proteins in other species GAS41 interacts with the SWI/SNF complex that contains mSIN3 histone deacetylase, the orthologue of PQN-28, and is a direct target of the oncogene Myb  Gene microarrays have revealed increased expression in Drosophila Rb mutant cells of genes annotated to function in oocyte development, including the polar granule RNA helicase vasa  Germ lines are more protected than somatic cells from foreign genetic elements, such as transposons and viruses  However, although animals with a mutation in the RNA-dependent RNA polymerase (RdRP) gene rrf-1 are unresponsive to unc-22 and nsf-1 dsRNAs, lin-15b; rrf-1 double mutant animals are responsive to both dsRNAs ( Supplementary Table S2 ) However, mes-4 has an additional function in X chromosome inactivation and could be more pleiotropic  However, PGL-1 is also misexpressed in the soma of the hpl-2 mutant, suggesting that this mutant does not just release RNAi factors from chromatin to enhance RNAi However, RNAi of these genes does not induce significant movement defects observed in the corresponding mutants, suggesting partial gene inactivation or inactivation only in a particular subset of neurons If Rb pathway mutations cause amplification of particular chromatin regions, gene dosage studies of tumours could reveal those target genes, such as the MLL, GAS41 and AF10 genes In a control RNAi screen of a hand-picked library of 434 clones encoding a variety of known RNAi, RNA-binding and RNA-processing factors, only pqn-28 ( SIN3 )—the only one out of the six multivulvae-suppressing clones in this library—suppressed the multivulvae phenotype of lin-35(n745); lin-8(n2731) animals In C. elegans , mutants lacking the HP1 orthologue hpl-2 display an enhanced RNAi phenotype as well as vulval cell lineage defects when combined with a synMuv A mutation, showing that hpl-2 is a synMuv B gene with enhanced RNAi (ref. 28 ) ( Fig. 1a , b ) In contrast, ectopic PGL-1 is not detected or is present at much lower levels in the soma of the synMuv B mutants that do not enhance RNAi— lin-53(n833) or lin-37(n758) —or the synMuv A mutants (data not shown). pgl-1 is also misexpressed in the somatic cells of the synMuv B NuRD component mutants let-418 ( Mi2 ) and mep-1 (ref. 11 ) In lin-35 ( Rb ), dpl-1 ( DP ), hpl-2 ( HP1 ), lin-15B , lin-9 and lin-13 mutants, but not in wild-type animals, dsRNA targeting gfp silences neuronally expressed tub-1::gfp ( Fig. 1b ) In Rb pathway mutants, germline-specific RNAi components may be de-repressed in somatic cells, which in turn enhances RNAi In support of an endoreduplication model, five RNAi regulatory genes including ZK1127.3 are clustered in one genomic region (ZK1127.3, ZK1127.7, ZK1127.4, ZK1127.9/6, ZK1127.5), and gfl-1 (M04B2.3) clusters with its neighbour, the synMuv B gene mep-1 (M04B2.1); these clusters may correspond to domains of amplification regulated by the Rb pathway chromatin remodelling factors In the absence of Rb and its associated chromatin remodelling complex, including HP1, RNAi factors such as DCR-1 and Argonaute proteins may become available to mediate RNAi in the cytoplasm, leading to enhanced RNAi In the absence of Rb, these genome regions may be amplified in soma to activate biogenesis of P granules; RNAi of the mes-4 complex genes may interfere with these amplifications or with the assembly of P granules and other germline components from these amplified gene products In the hypodermis, where ectopic P granules are manifest in the Rb mutant, inappropriate activity of the MES-4 complex may promote the expression of vulva-specific genes in the adjacent vulval precursor cells  In the lin-35 ( Rb ) mutant, PGL-1 is ectopically expressed in intestine, hypoderm and particular cells near the nerve ring, where it accumulates into perinuclear structures that closely resemble the normally germline-restricted P granules ( Fig. 2a ) In the lin-35 mutant, but not wild type, feeding RNAi targeting endogenous neuronal genes, such as egl-8 , egl-30 , unc-17 and unc-2 , causes resistance to the acetylcholinesterase inhibitor aldicarb, similar to mutations in these loci ( Table 1 ; see also Supplementary Fig In three independent experiments, unc-22 RNAi in wild-type animals caused a 50% reduction in the level of unc-22 mRNA, whereas in the lin-35 mutant, unc-22 mRNA was reduced by 70–80% ( Supplementary Fig Inactivation of mut-16 by RNAi restores somatic GFP expression in the lin-35 or lin-15B mutants ( Fig. 2b ), and RNAi in Rb pathway mutants requires the germline RNAi factor MUT-7 ( Supplementary Table S1 ) Inactivation of the mammalian homologues of the four multivulvae-suppressing genes that have good mammalian homologues— mes-4 , pqn-28 , gfl-1 and zfp-1 —for example by specific siRNAs or pharmaceuticals, might reverse the cell cycle defects and genome instability of Rb mutant tumours and cell lines atic to germline cell transformation, and that some gene inactivations that disrupt RNAi can reverse the cell lineage transformations of Rb pathway mutants Loss-of-function mutations or RNAi inactivation of six other Rb pathway genes— lin-35 ( Rb ), dpl-1 ( DP ), lin-53 , lin-9 , lin-13 and hpl-2 ( HP1 ); where homologous mammalian genes are denoted in parentheses—markedly enhance RNAi ( Fig. 1a ; see also Supplementary Fig Mammalian AF10 binds the GFL-1 orthologue GAS41 Mammalian SIN3 interacts directly with Rb chromatin complexes  MES-4 coats the autosomes in the C. elegans germ line; the MES-2, MES-3 and MES-6 proteins antagonize the binding of MES-4 to the X chromosome to mediate the silencing of the X chromosome in the C. elegans germ line  MES-4 is homologous to the human MLL protein that is the fusion partner to AF10, the orthologue of ZFP-1, in leukaemic translocations  Myb co-purifies with Rb and E2F in the Drosophila dREAM complex, and seven out of eight dREAM subunits are orthologues of C. elegans synMuv B genes  Neither RNAi of dcr-1 nor null mutations in other genes necessary for RNAi, such as rde-1 and rde-4 , restore the wild-type vulval cell lineage in the Rb pathway mutants ( Fig. 3a ; see also Supplementary Table S1 ), suggesting that excessive RNAi is not the cause of the cell lineage transformations of Rb pathway mutants Neurons are generally refractory to RNAi  None of these 36 gene inactivations suppressed the multivulvae phenotype of the Ras gain-of-function mutant let-60(n1700) or the ETS transcription factor loss-of-function mutant lin-1(e1777) ( Fig. 3a and data not shown), showing that these clones are not general multivulvae suppressors or Ras pathway genes Null or strong alleles of three other synMuv B genes, lin-36 , tam-1 and lin-37 , do not enhance RNAi ( Fig. 1a ), suggesting that some synMuv B genes can affect vulval cell lineages without enhancing RNAi of these tester genes One model for the relaxed requirement for rrf-1 in the Rb pathway mutants is ectopic expression in somatic tissues of the germline-specific EGO-1 RdRP, making rrf-1 and ego-1 redundant genes Other members of the C. elegans Rb pathway also negatively regulate RNAi P granule components continue to be expressed only in the developing germline where they are assembled into complex structures at the nuclear pores  PGL-1 is required for germline co-suppression , suggesting that the somatic PGL-1 expression in Rb pathway mutants could also be necessary for the enhanced RNAi Rb pathway mutations may also enhance RNAi by inactivating a chromatin silencing pathway that competes with the RNAi machinery for shared silencing components Rb pathway null mutants and eri-1 (or rrf-3 ) null mutants are hypersensitive to RNAi of distinct sets of target genes ( Table 1 ) RdRPs enhance RNAi by allowing siRNAs from the primary response to dsRNAs to prime further replication on target mRNAs, which in turn amplify the response  RNAi is enhanced in lin-15B(n744) but not in the strong loss-of-function lin-15A(n767) or lin-15A(n433) alleles ( Fig. 1a ). lin-15B is a class B synthetic multivulva (synMuv B) gene  RNAi is particularly enhanced in the nervous system of Rb pathway mutants S1 ) S2 ) S3 ) Similar PGL-1-containing structures are also expressed in the somatic cells of lin-13 , dpl-1 , hpl-2 , lin-15B and lin-9 mutants (data not shown) Similarly, the RNA helicase DDX1 is amplified in Rb tumours and neuroblastomas, and is a marker for stem cell fate in the mouse  Six gene inactivations suppress the multivulvae phenotype of three Rb pathway synMuv A and synMuv B double mutants: lin-15AB(n765) , lin-35(n745); lin-8(n2731) , and lin-36(n766); lin-8(n2374)  Strains carrying mutations in both eri-1 and lin-15b were synergistically sensitive to RNAi Strong or null alleles of the four known synMuv A genes, lin-15A , lin-8 , lin-56 , and lin-38 do not enhance RNAi ( Fig. 1a ) SynMuv B genes function redundantly with synthetic multivulva A (synMuv A) genes, such as lin-15A , to antagonize Ras signalling in the specification of vulval cell lineages  The dREAM complex binds to particular chromosomal domains on the Drosophila polytene chromosomes, suggesting that, similar to the Polycomb complex, an antagonism between Rb-repressing and MES-4-activating complexes may take place at particular chromatin loci  The Drosophila homologue of ZFP-1, dAF10, binds to HP1, an orthologue of C. elegans HPL-2 (ref. 18 ) The enhanced RNAi of Rb pathway mutants depends on many of the canonical RNAi pathway genes, with one exception that gave an indication of how the Rb pathway may enhance RNAi The enhanced RNAi of synMuv B pathway mutants is not dependent on whether the animals have ectopic pseudovulvae: for example, the lin-15AB(n765); let-23(sy1) double mutant has enhanced RNAi but is vulvaless due to a defect in the receptor tyrosine kinase let-23 (ref. 3 ) ( Fig. 1a ) The expression of germline components in somatic cells and a release of RNAi factors from their role specifying heterochromatin regions may conspire to activate RNAi in Rb pathway mutants The fact that the somatic PGL-1 in Rb pathway mutants accumulates in perinuclear structures as in germline cells suggests that additional P granule components and germline-specific factors are also ectopically expressed to allow the assembly of P granules  The induction of movement defects by feeding nematodes bacteria that express dsRNA targeting the muscle gene unc-22 is enhanced in Rb pathway mutants The lin-15 locus comprises two genes, lin-15A and lin-15B , that are inactivated by the n765 mutation (ref. 3 ) The loss of Rb pathway function may activate latent programmes of gene expression characteristic of more primitive, less differentiated cells The mammalian cell cycle transformations induced by Rb inactivation may also be triggered by expression of germ line or other stem-cell-like programmes in somatic cells The methylated histone-binding protein HP1 associates with RNAi components on yeast and fly heterochromatin The model of misexpression of RNAi components in Rb pathway mutants is supported by the somatic expression of normally germline-specific P-granule-like structures in the Rb pathway mutants ( Fig. 2a ). pgl-1 encodes an essential RNA-binding component of P granules that mark the C. elegans germ plasm in wild type  The P granules are homologous to polar granules in Drosophila ; both are composed of homologous helicases and RNA-binding proteins, as well as a number of mRNAs that specify germline fates and somatic patterning  The Rb pathway and eri-1 have distinct responses to injected short interfering RNAs (siRNAs): whereas an eri-1 mutant is more responsive to injection of unc-22 siRNA (23 base pairs long) than wild type, lin-35 and lin-15B mutants are not more responsive ( Table 1 ), suggesting that the Rb pathway acts at a step upstream of siRNA production The Rb pathway regulates RNAi synergistically with other negative regulators of RNAi, such as the 3′ exonuclease ERI-1 (ref. 5 ) and the RNA-dependent RNA polymerase RRF-3 (ref. 6 ) that both act in the same pathway  The release from negative regulation of RNAi in strains carrying mutations in both the Rb and eri-1 / rrf-3 pathways increases the intensity of RNAi in the C. elegans nervous system The RRF-1 RdRP is essential for RNAi of somatic genes , whereas the EGO-1 RdRP is enriched in the germ line and is required for RNAi of genes expressed in the germ line  Their perinuclear localization may reflect a nuclear transport function for the RNAs that accumulate in the P granules These double mutants allow RNAi to be used for the functional genomic dissection of neuronal functions (see the accompanying paper (ref. 7 )) as well as for the identification of neural components in physiological circuits, such as the regulation of metabolism, feeding and ageing These six gene inactivations are mes-4 (SET domain, trithorax class gene), pqn-28 (SIN3 component), gfl-1 (chromatin protein, orthologue of mammalian glioma-amplified sequence 41 (GAS41)), zfp-1 (PHD domain chromatin protein, orthologue of mammalian AF10 ) , M03C11.3 (weakly homologous to a chromatin-associated protein) and ZK1127.3 (novel protein) ( Fig. 3a and data not shown) This class of genes encodes homologues of the mammalian tumour suppressor Rb and Rb complex components LIN-53 (mammalian RbAp48) (ref. 1 ) and DPL-1 (mammalian DP) , as well as nuclear proteins that function in the Rb pathway, such as LIN-13, LIN-9, LIN-36 and TAM-1 (ref. 4 ) This model is favoured by the observation that mammalian homologues of mes-4 , zfp-1 , gfl-1 and pqn-28 are amplified in some tumours that may also carry Rb mutations  Thus, a high hit rate was specific to the RNAi-attenuating clones Two of the other five multivulvae-suppressing clones— gfl-1 ( GAS41 ) and ZK1127.3—also reverse the transgene silencing of Rb pathway mutants, but none of the other five suppresses somatic P granule formation as markedly as mes-4 RNAi (data not shown) We suggest that in the absence of the antagonistic Rb pathway complex, a MES-4 chromatin remodelling complex that includes the five other proteins identified above is inappropriately active in the soma to activate the expression of P granule genes like pgl-1  We tested four double-stranded (ds)RNAs that induce weaker RNAi phenotypes in wild-type animals than the corresponding loss-of-function mutant phenotype We tested whether any of 36 viable RNAi-suppressing gene inactivations could also suppress the multivulvae phenotype of Rb pathway and other multivulvae mutants
 A single particle confined in an asymmetric potential demonstrates an anticipated ratchet effect by drifting along the ‘easy’ ratchet direction when subjected to non-equilibrium fluctuations  Here we demonstrate that the inter-particle interactions in a chain of repelling particles captured by a ratchet potential can, in a controllable way, lead to multiple drift reversals, with the drift sign alternating from positive to negative as the number of particles per ratchet period changes from odd to even This drastic change in the drift behaviour between single- and multi-particle systems can shed some light on the different behaviour of ratchets and biomembranes in two drift regimes: diluted (single particles) and concentrated (interacting particles). This well-known effect can, however, be dramatically changed if the potential captures several interacting particles To demonstrate experimentally the validity of this very general prediction, we performed transport measurements on a.c.-driven vortices trapped in a superconductor by an array of nanometre-scale asymmetric traps We found that the direction of the vortex drift does undergo multiple reversals as the vortex density is increased, in excellent agreement with the model predictions A phase diagram of vortex motion was obtained by detailed measurements of the root-mean-square and d.c. voltages ( V rms and V dc respectively) across the sample ( Fig. 3c ) A second particle will find a stable position at trap 2, then raising its energy above E 1 ( E 1 (1) E 2 (1)) A simple way to understand this interesting effect is to consider each local well in a ratchet period as being characterized by the effective energies E 1 (‘strong’ well) and E 2 (‘weak’ well) After transition, this particle ‘overpopulates’ the target well, which then releases another particle to the next ratchet period All lengths are in units of the ratchet period a  As a first demonstration of the ratchet mechanism in this system, we excite the particles with an a.c. square-wave drive with an amplitude just above the threshold force (defined as F thresh = min( F c+ , F c- )) of the corresponding chain and a very low frequency (adiabatic drive) As illustrated in Fig. 1c , the motion of the weakly pinned particle across the inner energy barrier triggers the whole ratchet mechanism (see also the Supplementary Videos ) As we have recently demonstrated, such a configuration provides efficient rectification of vortex motion at low fields  At lower temperatures, vortices become smaller and interact more strongly with the antidots  At some vortex densities (rational multiples of the first matching field, H 1 = Φ 0 / a p 2 = 0.92 mT, where the number of vortices matches the number of double-traps), vortices assemble in a very stable lattice commensurate with the pinning array  At temperatures very close to T c , vortices are bigger than the antidots, which then become less effective pinning centres By increasing n even further, the rise in the effective energies proceeds following a brick-wall tiling pattern, with the particles populating each trap alternately Consequently, one must be cautious when modelling vortices as hard particles Contrary to what intuition could perhaps tell us, particles in a ratchet potential can, under special conditions, move preferentially along the direction where the potential barriers are steeper, that is, along the ‘hard’ direction Drift inversions have also been observed in mixtures of interacting brownian particles and in chaotic underdamped ratchets at zero thermal noise  Figure 1a shows density plots of the effective asymmetry in the critical forces for drifting the particles to the positive ( F c+ ) and to the negative ( F c- ) direction, α eff = 1 - F c+ / F c-  Finally, we stress that our findings have a very general character and are also relevant to other ratchet systems of interacting particles, like charged colloidal suspensions in ratchet-like microtubules and ions in the selectivity filter of ion channels in cell membranes . For n = 0, the strong trap yields a lower energy than the weak one ( E 1 (0) E 2 (0)) For n = 1 the particles are more easily driven to the usual positive direction ( α eff 0) and, except for Ũ p1 1 (where the potential cannot trap the chain effectively), α eff varies only with β  For n = 1, the particle occupies the strong well, raising its effective energy enough to surpass the energy of the (empty) trap 2 ( E 1 (1) E 2 (0)) From the first up to the fifth matching fields, the direction of net vortex motion changes its sign alternately, resembling the sign inversions of the chain drift in our 1D model ( Fig. 2 ) Hence, the vortex dynamics is essentially deterministic Here we show that, in a system of strongly interacting particles in a ratchet potential, the drift direction undergoes controllable multiple sign inversions as a function of particle density Hereafter we adopt m = 1 and η = 16, which corresponds to strongly overdamped dynamics However, for n 1, α eff has a much richer dependence on the ratchet potential parameters, assuming either positive or negative values with comparable intensity In a large range of the potential parameters multiple reversals were also observed (compare Supplementary Fig In a system of many weakly interacting particles, this effect can, however, be strongly reduced when the particle density is increased  In general, the results are very similar to those presented in Figs 1 and 2  In the pinned vortex solid (PVS) phase, the applied current is not high enough to drive vortices out of their equilibrium positions In theory, an inversion in the drift direction of a single-particle brownian ratchet is predicted to occur for non-zero thermal noise when the excitation frequency exceeds a certain critical value, which is usually high and very sensitive to the model parameters  In this region, particles distribute evenly between the weak and strong pinning sites for even n , whereas for odd n the strong traps capture one particle more than the weak ones ( Fig. 1b ) In this sense, decreasing the temperature plays the role of increasing the pinning strength In this sense, these particles are the most weakly pinned ones It is also noteworthy that vortices are collective excitations; their cores can be deformed and merged into one another at extreme conditions Nonetheless, the agreement of the experimental results with the model predictions is quite good, which suggests that the model is able to capture the main physics of the observed vortex ratchet effects One single reversal was observed to take place gradually as the number of vortices increased above the corresponding saturation of the dots (three vortices per dot) Our experiment is carried out as follows: an oscillating driving force (generated by a sinusoidal transverse electrical current) is applied along the direction of broken symmetry, and the vortex motion in this direction is probed by measuring the transverse voltage ( Fig. 3a ) Our sample is an Al film (with critical temperature T c = 1.437 K) patterned by electron-beam lithography with a square array (with period a p = 1.5 µm) of neighbouring big and small antidots placed close to each other, thus generating an asymmetric double-well vortex trap with broken symmetry along the y direction only ( Fig. 3b ) Particles that are the closest to the inner energy barrier are the natural candidates to undergo such transitions Particularly, there is a large region of the phase diagrams ( β 0.56 and moderate pinning strengths) where α eff is always positive for odd n and negative for even n  Rather, owing to the strong enhancement of the current density between the antidots ( Fig. 3b ), vortices tend to move in 1D channels along the antidot rows Rather, they are ruled deterministically by the internal degrees of freedom of the system, providing a simple way to tune the drift direction of ratchet devices S1 ) S2 ) Sign reversal in a vortex ratchet has been reported previously for an array of triangular magnetic dots  The dynamics of the chain is studied by molecular dynamics simulations of the Langevin equations, m x¨ i = - η xdot; i - ∑  j ∇ V int ( x i - x j ) - ∇ U p ( x ) + F + Γ  i (2) where m is the mass of the particles, η the friction coefficient, F the external drive, and Γ  i the gaussian thermal noise  The moving vortex phase is dominated by ratchet dynamics exhibiting multiple drift reversals The multiple sign reversals observed in our experiment cannot be explained by the inverted ratchet effect of interstitial vortices The plots are presented in the Ũ p1 – β plane ( Ũ p1 = U p1 / E 0 determines the potential strength relative to inter-particle interactions and β = U p1 / U p2 determines the potential asymmetry) for occupation number n = 1, 2, 3 and 4 particles per ratchet period and for zero noise ( T = 0) The result demonstrates remarkable sign reversals every time n approaches an integer value The sign of α eff determines the preferential drift direction—positive (‘easy’) direction for α eff 0 and negative (‘hard’) direction for α eff 0—whereas its magnitude is a measure of the ratchet efficiency The temperature does however play an important role in determining the pinning efficiency of an antidot The vortex density can be varied continuously by applying an external magnetic field H and, as shown in Fig. 3a , their dynamics can be probed by measuring the voltage–current characteristics of the sample Thermal fluctuations are negligible in our sample, because the pinning energy is typically much higher than kT ( U p ≈ 10 2 - 10 3 kT , for T / T c = 0.98 - 0.88) These channels should however saturate at a high enough vortex concentration, the excess vortices being forced to move along the interstitial positions These inversions do not require thermal or chaotic noise, or high excitation frequencies or a mixture of particles These multiple sign reversals provide a new tool for controlling and manipulating the motion of magnetic flux quanta in superconductors These special configurations enhance the critical current, producing the sharp re-entrances of the PVS phase at integer and half-integer matching fields This effect can be crucial in the design of artificial ratchet-based devices capable of shuttling or separating—for instance, colloidal suspensions and DNA molecules  This produces a net rectified motion with positive direction for odd n and negative direction for even n  This was interpreted as the effect of interstitial vortices moving in an inverted ratchet potential produced by the interactions with the trapped vortices Thus, for n even, there is necessarily a smaller energy input required to move one particle from trap 2 (across the small inner energy barrier) to trap 1 (as E 1 ( n 1 ) E 2 ( n 2 = n 1 )), whereas for odd n a transition from 1 to 2 is favoured (as E 1 ( n 1 ) E 2 ( n 2 = n 1 - 1)) To evaluate further the generality of our findings, we performed similar calculations for other friction values down to η = 2, which corresponds to the (regular) underdamped regime To study in more detail the dependence of rectification on n , we calculated the net velocity of the chain as a function of n and Ũ p1 for a constant sinusoidal a.c. bias ( Fig. 2 ) To test these predictions experimentally, we performed transport measurements of a.c.-driven vortices in a nanostructured superconducting film with an array of asymmetrical pinning sites Vortices are whirlpools of current carrying one quantum of magnetic flux ( Φ 0 = 2.07 × 10 -15  Wb) that repel each other and are attracted by microholes (termed antidots) in a superconductor  We consider a one-dimensional (1D) system of particles interacting via the pair potential V int ( r ) = - E 0 ln( r ), with r the pair separation and E 0 the relevant energy scale, in the double-well ratchet potential U p ( x ) = - U p1 e -sin 2 (π x )/2 sin 2 (π R ) - U p2 e -sin 2 (π( x - d ))/2 sin 2 (π R ) (1) where U p1 and U p2 determine the depth of the stronger and weaker wells, respectively, which are separated by a distance d = 0.36 and have width R = 0.15, and x is the position We have also tested these predictions for the well-known double-sine potential (sketches of this and the double-well potentials are provided in Supplementary Fig When the drive inverts its sign, no motion is detected
 Cyclic AMP is a ubiquitous second messenger that transduces signals from a variety of cell surface receptors to regulate diverse cellular functions, including secretion, metabolism and gene transcription Here we introduce a new ratiometric evanescent-wave-microscopy approach to measure cAMP concentration beneath the plasma membrane, and show that insulin-secreting β-cells respond to glucagon and GLP-1 with marked cAMP oscillations In pancreatic β-cells, cAMP potentiates Ca 2+ -dependent exocytosis and mediates the stimulation of insulin release exerted by the hormones glucagon and glucagon-like peptide-1 (GLP-1) (refs 4 , 5 –6 ) Moreover, cAMP oscillations are capable of inducing rapid on–off Ca 2+ responses, but only sustained elevation of cAMP concentration induces nuclear translocation of the catalytic subunit of the cAMP-dependent protein kinase Our results establish a new signalling mode for cAMP and indicate that temporal encoding of cAMP signals might constitute a basis for differential regulation of downstream cellular targets. Simultaneous measurements of intracellular Ca 2+ concentration revealed that the two messengers are interlinked and reinforce each other Whereas Ca 2+ signals have been extensively characterized and shown to involve oscillations important for the temporal control of insulin secretion , the kinetics of receptor-triggered cAMP signals is unknown After plating on coverslips, the cells were transfected with Lipofectamine 2000 ( Invitrogen ) in accordance with the manufacturers protocol Cell culture and transfection Insulin-secreting INS-1 cells (passage 90–120; ref. 28 ) and the more glucose-reponsive subclone INS-1E (ref. 29 ; used for the experiment in Fig. 1b ), were cultured in RPMI 1640 medium ( Invitrogen ) containing 11 mM glucose and supplemented with 10% fetal calf serum ( Invitrogen ), 1 mM sodium pyruvate, 2 mM glutamine, 50 µM mercaptoethanol, 100 U ml -1 penicillin and 100 µg ml -1 streptomycin Cα-Cys 4 -transfected cells were labelled by incubation at 37 °C for 20 min with 0.5 µM FlAsH-EDT 2 ( Lumio Green labelling reagent ; Invitrogen ) Cα-Cys 4 was made by ligating Cα cDNA into the pENTR4 Gateway entry vector ( Invitrogen ) followed by site-specific recombination into the pcDNA6.2-cLumio vector ( Invitrogen ) Cα-YFP was generated by fusing the full-length coding sequence of mouse PKA Cα to the N terminus of YFP Excitation and emission wavelengths were selected with the following filters: CFP, 458 nm/10 nm half-bandwidth and 485/25 nm; YFP 514.5/10 and 550/30 nm; Fura red 514.5/10 and 630 nm long-pass; FlAsH 488/10 and 530/50 nm Exposure times were from 100 to 400 ms and images were acquired every 2–5 s Imaging At 12–24 h after transfection the cells were transferred to buffer containing 138 mM NaCl, 4.8 mM KCl, 1.3 mM CaCl 2 , 1.2 mM MgCl 2 , 3 mM glucose and 25 mM HEPES, pH 7.40 It was ascertained that background FlAsH labelling was unaffected by continuous [cAMP] i elevation in non-transfected cells, although it probably contributed to an understimation of the cAMP-induced change in the FlAsH nuclear/cytoplasmic fluorescence ratio in cells expressing Cα-Cys 4 . [Ca 2+ ] i imaging of Fura-2-loaded cells was performed as described previously  Methods cDNA constructs ΔRIIβ-CFP-CAAX was created by ligating a cDNA fragment encoding residues 81–416 of rat PKA RIIβ to the amino terminus of CFP, which was targeted to the plasma membrane with a polybasic sequence and a CAAX motif from human Ki-Ras Statistical differences were evaluated with Students t -test or Fishers exact test ( Fig. 1h ). Statistics Results are reported as means ± s.e.m The same setup was used for epifluorescence imaging These cells were then rinsed with buffer, incubated for 10–15 min in 250 µM EDT and again rinsed with buffer to reduce non-specific labelling Translocation of the cAMP reporter was measured using a custom-built evanescent wave microscope equipped with a 60 × objective with a numerical aperture of 1.45 ( Nikon ) and an Orca-ER camera ( Hamamatsu ) controlled by MetaFluor software ( Molecular Devices ) Where indicated, the cells were loaded with the Ca 2+ indicators Fura-2 or Fura red by incubation for 30 or 40 min at 37 °C with their acetoxymethyl esters at 1 or 5 µM, respectively A truncated form of the regulatory subunit of the cAMP-dependent protein kinase (PKA) was labelled with cyan fluorescent protein (CFP) and targeted to the plasma membrane with a polybasic sequence and a farnesylation motif (ΔRIIβ-CFP-CAAX; Supplementary Fig Accordingly, INS-1 β-cells responded to 1–10 nM GLP-1 with pronounced oscillations of [Ca 2+ ] i (average amplitude 562 ± 52 nM, frequency range 0.19–2.52 min -1 , n = 31 cells; Fig. 2a ) After removal of the drugs, R CFP/YFP returned to the prestimulatory level with t 1/2 = 14 ± 3 s ( n = 14; IBMX) and 27 ± 3 s ( n = 7; forskolin) Although the initial [cAMP] i elevation preceded that of [Ca 2+ ] i on the addition of GLP-1, there was no detectable time difference during the subsequent oscillations ( Fig. 2d ) An increase in the GLP-1 concentration typically resulted in dose-dependent sustained [cAMP] i elevation ( Fig. 1g ), and at hormone concentrations of 3–10 nM, oscillations occurred in less than 40% of the cells ( n = 35; Fig. 1f , h ) Application of noradrenaline under resting conditions resulted in a modest decrease in R CFP/YFP , showing that the biosensor detects even small changes in basal [cAMP] i and that R CFP/YFP in non-stimulated cells was as high as 7.4 ± 1.3% ( n = 6) or 7.5 ± 0.9% ( n = 6) of that reached after treatment with 10 nM GLP-1 or 100 µM IBMX, respectively ( Supplementary Fig As expected, continuous stimulation with 100 µM IBMX resulted in stable elevation of [cAMP] i ( Fig. 3a ), whereas application of IBMX in pulses generated regular [cAMP] i oscillations ( Fig. 3b ) As shown in Fig. 2c , elevations of [cAMP] i coincided with those of [Ca 2+ ] i ( n = 3) and this coordination was confirmed by cross-correlation analysis ( Supplementary Fig Because of its high affinity for ΔRIIβ-CFP-CAAX, co-expressed PKA catalytic subunit (Cα) labelled with yellow fluorescent protein (YFP) also located to the plasma membrane Because the YFP-tagged PKA catalytic subunit is too large to enter the nucleus, we assessed cAMP-induced PKA nuclear translocation by tagging the Cα subunit with a small tetracysteine motif (Cα-Cys 4 ; Supplementary Fig Both stimulation protocols promoted the appearance of [Ca 2+ ] i oscillations, and with pulsatile stimulation the [Ca 2+ ] i signals coincided precisely with the presence of IBMX ( n = 37; Fig. 3c , d ) Depending on the particular isoforms of adenylyl cyclases and phosphodiesterases expressed, elevation of [Ca 2+ ] i can either increase or decrease [cAMP] i  Direct bath application of 10 µM cAMP in cells permeabilized with staphylococcal α-toxin resulted in even faster Cα-YFP translocation, with t 1/2 = 11.7 ± 0.9 s ( n = 11; Supplementary Fig Epifluorescence imaging of FlAsH-labelled Cα-Cys 4 revealed cytoplasmic distribution with markedly less nuclear fluorescence in non-stimulated cells and translocation of the construct into the nucleus after elevation of [cAMP] i ( Supplementary Fig From the rapid and pronounced changes in [cAMP] i induced by IBMX, GLP-1 and noradrenaline we conclude that there are high rates of cAMP production and degradation beneath the plasma membrane Glucagon was also less efficient than GLP-1 in elevating [cAMP] i  High turnover of cAMP is favourable for establishing spatial gradients or oscillations of [cAMP] i  Holoenzyme dissociation as [cAMP] i increases could then be monitored as Cα-YFP redistribution to the cytoplasm ( Supplementary Fig In contrast, [cAMP] i oscillations generated by pulsatile IBMX (1 min stimulation and 3 min wash) failed to induce nuclear translocation of PKA (0.68 ± 0.02, n = 63) even after more than 100 min when the cells had been exposed to an equivalent total dose of IBMX In pancreatic β-cells, the gut-derived peptide hormone GLP-1 is an important stimulator of insulin secretion, cell development, growth and survival  Increasing the glucose concentration from 3 mM to 20 mM had a negligible effect on [cAMP] i by its own, but markedly enhanced the response to GLP-1 ( Fig. 1b ; the response at 20 mM glucose was 198 ± 29% of that at 3 mM glucose; n = 7; P 0.02), which is consistent with the previously described synergism between glucose and GLP-1 on cAMP production  Indeed, INS-1 β-cells stimulated with 0.3–1.0 nM GLP-1 frequently responded with [cAMP] i oscillations from the baseline or a slightly elevated level (43 of 51 cells; Fig. 1d–h ; Supplementary Fig Inhibition of phosphodiesterases with 100 µM 3-isobutyl-1-methylxanthine (IBMX) or activation of adenylyl cyclases with 5 µM forskolin in INS-1 β-cells expressing the biosensor did not affect evanescent-wave-excited ΔRIIβ-CFP-CAAX fluorescence, but induced a prompt loss of membrane Cα-YFP fluorescence that was rapidly reversed after washout of the drugs ( Fig. 1a ) Interactions between Ca 2+ and cAMP at multiple levels have been proposed to cause [cAMP] i oscillations in some systems  It exerts its action through binding to G-protein-coupled receptors and the activation of adenylyl cyclases It is also well known that the formation and breakdown of cAMP can be affected by [Ca 2+ ] i through direct or indirect effects on adenylyl cyclases and phosphodiesterases  Next, we investigated [cAMP] i changes induced by physiological stimuli Noradrenaline also reversed the elevation of [cAMP] i induced by 100 µM IBMX ( Supplementary Fig On the basis of the present findings, we suggest that brief transients of [cAMP] i are important in the selective regulation of rapid local cytoplasmic events, such as ion channel activity and exocytosis, whereas prolonged [cAMP] i elevation is required for long-term effects such as PKA-mediated activation of the nuclear transcription factors involved in regulating cell survival and proliferation. Oscillatory cAMP signalling involving the excretion of cAMP and the activation of an extracellular cAMP receptor is previously known from the slime mould Dictyostelium , and spontaneous cAMP transients in Xenopus frog embryonal neurons were recently reported  Our present data provide the first demonstration that activation of hormone receptors can evoke [cAMP] i oscillations S1 ) S1 ) S2 ) S2 ) S3 ) S3 ) S4 ) S4 ) S5 ) S6 ) S6 ) that can be specifically labelled with the membrane-permeable fluorescent biarsenical dye FlAsH (ref. 27 ) Similar experiments with 0.3–30 nM glucagon demonstrated that this hormone also could elicit oscillatory [cAMP] i responses, although in a much smaller proportion of the cells (11 of 50 cells; Supplementary Fig Stimulation of rat insulinoma cells by using 10 nM GLP-1 resulted in a rapid and pronounced increase in [cAMP] i ( t 1/2 = 24 ± 3 s; n = 20) that was reversed when the hormone was removed ( Fig. 1b ) The [cAMP] i oscillations induced by 1 nM GLP-1 immediately disappeared when extracellular Ca 2+ was removed and the Ca 2+ chelator EGTA was added at 2 mM ( Fig. 2b ; n = 3) The average t 1/2 of 59 ± 3 s ( n = 9, P 0.001) was consistent with retarded cAMP hydrolysis in the presence of the phosphodiesterase inhibitor The GLP-1-induced [cAMP] i elevation was rapidly reversed on inhibition of adenylyl cyclases by 10 µM of the α 2 -adrenergic receptor agonist noradrenaline (88 ± 2% suppression; t 1/2 = 12 ± 2 s; n = 6; P 0.001; Fig. 1c ) The maximal average amplitudes of [cAMP] i elevation were 0.39 ± 0.09 ratio units ( n = 6) for glucagon and 0.72 ± 0.18 units ( n = 4) for GLP-1, with half-maximal responses achieved at 1.51 ± 0.34 nM glucagon and 0.65 ± 0.15 nM GLP-1 ( P 0.05 for difference in half-maximal concentration; Fig. 1i ) The oscillatory patterns varied between different cells with frequencies ranging from 0.16 to 1.5 min -1 and amplitudes from 0.08 to 1.7 normalized R CFP/YFP units The ratio of nuclear to cytoplasmic fluorescence increased from 0.66 ± 0.02 ( n = 77) in non-stimulated cells to 0.90 ± 0.03 ( n = 65; P 0.001) after 25 min of stable [cAMP] i elevation induced by 100 µM IBMX ( Fig. 3e , f ) The response kinetics, measured as time to half-maximal change ( t 1/2 ) of R CFP/YFP , averaged 23 ± 2 s (mean ± s.e.m; n = 23) and 20 ± 3 s ( n = 15) after stimulation with IBMX and forskolin, respectively The specificity of probe dissociation was verified by exposing intact cells to membrane-permeable cyclic nucleotide analogues The strikingly higher efficiency of stable compared with oscillatory [cAMP] i elevation to induce the nuclear translocation of PKA was confirmed in experiments with continuous stimulation with 25 µM IBMX (0.89 ± 0.05, n = 20, P 0.001), providing a time-average dose identical to 100 µM pulsatile IBMX These EC 50 values are almost identical to those previously obtained with conventional radiotracer techniques . cAMP-generating stimuli are known to induce intracellular Ca 2+ concentration ([Ca 2+ ] i ) signals in insulin-secreting β-cells by the PKA-mediated modulation of K ATP channels, voltage-gated Ca 2+ channels and Ins(1,4,5)P 3 receptors  This effect was reversible with restoration of the oscillations when Ca 2+ was reintroduced This is significant because signalling with oscillations might help to improve low-level signal detection and achieve specificity in downstream effects, as has been described for Ca 2+ (refs 19 , 25 ) This synchronization and the mutual reinforcement of cAMP and Ca 2+ signals should constitute an exquisite trigger of exocytosis and might explain how GLP-1 selectively enhances the pulsatile component of insulin secretion in healthy and diabetic subjects  Thus, [cAMP] i and [Ca 2+ ] i signals are temporally coordinated in insulin-secreting cells Thus, hormone receptor activation in β-cells can evoke cAMP oscillations beneath the plasma membrane To compensate for fluorescence changes that might occur independently of [cAMP] i , such as changes in cell morphology or adhesion, we calculated the ratio between the ΔRIIβ-CFP-CAAX and Cα-YFP signals ( R CFP/YFP ) and normalized the prestimulatory level to 1 ( Fig. 1a ) To investigate the kinetics of hormone-evoked cAMP signals in β-cells we developed a fluorescent biosensor that reports cAMP concentration beneath the plasma membrane ([cAMP] i ) To investigate whether the [cAMP] i oscillations in β-cells are synchronized with [Ca 2+ ] i signals we performed simultaneous measurements of [Ca 2+ ] i and [cAMP] i  To test whether different temporal patterns of cAMP signals might contribute to the selective regulation of downstream events we evaluated the effects of stable and oscillatory cAMP signals on two well-established cAMP-dependent responses, the generation of [Ca 2+ ] i oscillations (see above) and the translocation of the PKA catalytic subunit to the nucleus  Whereas 10 mM 8-bromo-cGMP lacked effect, the same concentration of 8-bromo-cAMP induced a stable 82 ± 9% ( n = 5) increase in R CFP/YFP ( Supplementary Fig With the use of evanescent wave microscopy , such translocation results in large fluorescence changes that can be measured with minimal photobleaching and phototoxic effects and a signal-to-noise ratio superior to that of other fluorescence microscopy approaches 
 Anxiety and fear are normal emotional responses to threatening situations Both of these genes are involved in oxidative stress metabolism, linking this pathway with anxiety-related behaviour. Here we report, using a combination of behavioural analysis of six inbred mouse strains with quantitative gene expression profiling of several brain regions, the identification of 17 genes with expression patterns that correlate with anxiety-like behavioural phenotypes However, the availability of different inbred strains of mice offers an excellent model system in which to study the genetics of certain behavioural phenotypes  In human anxiety disorders—such as panic disorder, obsessive–compulsive disorder, post-traumatic stress disorder, social phobia, specific phobias and generalized anxiety disorder—these responses are exaggerated Local overexpression of these genes in the mouse brain resulted in increased anxiety-like behaviour, while local inhibition of glyoxalase 1 expression by RNA interference decreased the anxiety-like behaviour The molecular mechanisms involved in the regulation of normal and pathological anxiety are mostly unknown To determine if two of the genes, glyoxalase 1 and glutathione reductase 1, have a causal role in the genesis of anxiety, we performed genetic manipulation using lentivirus-mediated gene transfer A few animals died after the injections, and the final number of animals used for further experiments are detailed in the Supplementary Methods  A total of 50 129S6/SvEvTac and 50 C57BL/6J male mice were obtained from Taconic Farms or the Jackson Laboratory, respectively, at five weeks of age, and housed five mice per cage AB6F 1 animals were bred at the Salk Institute using parental animals derived from the Jackson Laboratory After one week of acclimatization, mice were injected bilaterally with 1 µl (1.1 × 10 6 transducing units) of either HA– Glo1 , HA– Gsr , GFP, siGlo1 or sihp53 virus (ten animals of both strains per construct) into the cingulate cortex using a stereotaxic frame All animal procedures were approved by the Salk Institute for Biological Studies institutional animal care and use committee All dissections were performed between 11.00–17.00 h on a Petri dish filled with ice using a dissection microscope Animals were singly housed for one week before behavioural testing or dissections Bed nucleus of the stria terminalis, hippocampus, hypothalamus, periaqueductal grey and pituitary gland samples were labelled using10 µg of total RNA as the starting material Behavioural testing Anxiety-related behaviour was measured using the light–dark box test and the open-field test (see the Supplementary Methods for details) Data analysis See the Supplementary Methods for further details concerning the analysis of differentially expressed genes and the determination of reproducibility between measurements, as well as the regression analysis between the behavioural results and enzyme activity levels Different animals were used for behavioural testing and gene expression profiling in order to measure baseline gene expression differences Enzyme activity assays Eight-week-old mice were killed by decapitation and their cortex, hippocampus and striatum dissected under a dissection microscope, frozen on dry ice, and stored at -80 °C For the overexpression experiment, a variant of Glo1 from the A/J strain was cloned For the siRNA experiment, lentiviral vectors were constructed that expressed siRNA against Glo1 (siGlo1) or human p53 (sihp53) from the human H1-RNA promoter as described before (O.S. and I.M.V., unpublished results and ref. 23 ) ( Supplementary Fig. 3a ) Four weeks after injection, mice were separated into individual cages Further details about virus production are given in the Supplementary Methods  Hippocampus samples were directly frozen on dry ice and stored at -80 °C Labelling of samples, hybridization and scanning were performed as described  Lentivirus-mediated gene transfer Plasmids were constructed for the production of lentiviral vectors that expressed either Glo1 or Gsr with a carboxy-terminal HA-tag, or GFP, in the overexpression experiment Methods Animals Seven-week-old male mice were obtained from the Jackson Laboratory ( A/J, BALB/cByJ, C3H/HeJ, C57BL/6J, DBA/2J, FVB/NJ and B6AF1/J ) or from Taconic Farms ( 129S6/SvEvTac ) Mice were allowed to recover for a week, after which time they were killed and their brains were collected for the immunohistochemical or in situ hybridization analysis (see the Supplementary Methods for details) Microarray experiments Gene expression levels were measured using the Murine Genome U74Av2 arrays ( Affymetrix ) Only samples with an absorbance ratio at 260 nm/280 nm ( A 260 / A 280 ) greater than 2.0 in TE buffer were used for further experiments Owing to the small size of amygdala and cingulate cortex, samples from these tissues were labelled using 50 ng of total RNA as the starting material, using two rounds of complementary DNA synthesis and in vitro transcription (IVT) Quantitative RT–PCR PCR reactions were done using the SYBR Green master mix ( Applied Biosystems ) in an ABI Prism SDS 7900 HT machine ( Applied Biosystems ) as described in the Supplementary Methods  Software tools Further details on the TeraGenomics microarray analysis tool are available at http://www.teragenomics.com  The Bullfrog software can be downloaded from http://www.barlow-lockhartbrainmapnimhgrant.org/ . The dissected brain regions for gene expression analysis included the amygdala, cingulate cortex, hypothalamus, hippocampus, pituitary, periaqueductal grey and bed nucleus of the stria terminalis The enzyme activity levels of Alad, Glo1 and Gsr were determined as described in the Supplementary Methods  The extraction of total RNA from the tissues was performed using the TRIzol reagent ( Invitrogen ) according to the manufacturers instructions The open-field behavioural test was conducted five weeks and seven weeks after injection in the case of the overexpression experiment, and five weeks after injection in the case of the siRNA experiment The smaller brain structures were collected in RNA Later buffer ( Ambion ), and samples from 2–5 animals were pooled and stored at -80 °C The stereotaxic coordinates were: 1.4 mm rostral to bregma, 0.5 mm lateral to midline, and 1.5 mm ventral from the dural surface Tissue collection and RNA preparation Animals were killed by cervical dislocation Two-round labelling was performed using the MessageAmp kit ( Ambion ) according to the manufacturers instructions, with the exception that the second IVT was done using the Enzo BioArray high yield RNA transcript labelling kit ( Enzo Life Sciences ) We sequenced the cDNA of Glo1 and Gsr in order to find single nucleotide polymorphisms between the strains (see the Supplementary Methods and Supplementary Information ) A control vector was used that expressed an siRNA against the human p53 gene (sihp53) , which has been shown not to affect the expression of mouse p53 ( Supplementary Fig. 4 ; O.S. and I.M.V., unpublished results) ggested Glo1 might be a biological marker for trait anxiety in bidirectionally crossed mouse lines  After testing, mice were allowed to recover for a week, killed, and their brains removed for immunohistochemical and in situ hybridization analysis As expected, there was a statistically significant correlation between the open-field behaviour and the Glo1 ( P = 0.0005) and Gsr ( P = 0.009) enzyme activities, as measured by regression analysis over A/J, C57BL/6J, their F 1 offspring and BALB/cByJ mice ( Fig. 2b and c ), suggesting that these two enzymes are very strong candidates for regulating anxiety-related behaviours Based on this information, we selected seven brain regions (the amygdala, bed nucleus of the stria terminalis, cingulate cortex, hippocampus, hypothalamus, periaqueductal grey and pituitary gland) thought to regulate aspects of anxiety-related behaviour, and used oligonucleotide arrays (Affymetrix U74Av2) to assess the expression levels of ∼10,000 genes in those regions Different inbred mouse strains have different physical and behavioural phenotypes that are heritable and stable  Enzyme activity assays were available for three of them Five weeks later, animals were tested using the open-field test For example, some of them might correlate with the phenotype by chance, so we addressed this question using functional and genetic studies For most of the genes, the differences in gene expression observed by microarray analysis were confirmed by qPCR Furthermore, erythrocytes from patients with anxiety disorders (such as panic disorder or obsessive–compulsive disorder) may have higher levels of antioxidant enzymes (glutathione peroxidase and superoxide dismutase) , suggesting that free radicals may have a role in the pathogenesis of anxiety disorders Glo1 uses GSH as a cofactor to detoxify cytotoxic methylglyoxal However, overexpression of Glo1 in the C57BL/6J background did not increase the anxiety-related behaviour compared to GFP controls ( P = 0.212; Fig. 2e ) In addition to the correlation analysis described above, we analysed the data with a standard implementation of a linear mixed-effects model to assess the correlation between expression and anxiety-related behaviour ( Table 1 and Supplementary Table 2 ) In both open-field and light–dark box tests, F 1 animals derived from the A/J and C57BL/6J crosses showed intermediate levels of anxiety-like behaviour compared to the parental strains ( Fig. 2a ) In contrast, although not completely ruling out an association between locomotor activity and anxiety-like behaviour, the strain order for locomotor activity, estimated as the distance travelled in the dark compartment of the light–dark box, was different from the strain order for anxiety-like behaviour ( Supplementary Information ) In contrast, both Glo1 and Gsr enzyme activities matched the pattern found in both the microarray and qPCR analyses, with highest activities in the most anxious and lowest activities in the least anxious strains In fact, several of our candidate genes reside within chromosomal regions with identified QTLs for anxiety-related behaviour ( Supplementary Table 2 ) Injected animals were tested in the open-field test ( Fig. 2d–e and data not shown) It is possible that not all of these differentially expressed genes are involved with the regulation of anxiety It seemed that Alad mRNA levels in FVB/NJ animals were overestimated by the microarrays, as Alad expression and Alad activity did not correlate with anxiety-like behaviour across the strains Likewise, C57BL/6J mice injected with siGlo1 virus spent 38% more time in the middle of the chamber compared with control animals injected with the sihp53 virus ( P = 0.0002; Fig. 2f ), indicating that inhibition of Glo1 expression in the cingulate cortex reduces levels of anxiety-like behaviour Nineteen probe sets were identified ( Table 1 , Fig. 1b and Supplementary Table 2 ), corresponding to 17 candidate genes (probe sets 93268_at and 93269_at both represented glyoxalase 1 ( Glo1 ), and probe sets 96215_f_at and 98525_f_at both represented erythroid differentiation regulator 1 ( Erdr1 )) Notably, five of the 17 candidate genes were enzymes One microlitre of either Glo1 - or Gsr -containing virus, or a green fluorescent protein (GFP)-containing control virus, was injected bilaterally in the region of the cingulate cortex of C57BL/6J and 129S6/SvEvTac mice to overexpress the corresponding genes in vivo  Only growth hormone (probe set 92783_at) did not show a statistically significant association using this method Our expression-based approach is expected to complement traditional QTL (quantitative trait loci) mapping: genes with expression levels that are correlated with the trait of interest and physically reside in close proximity to a QTL for the trait are good candidates for genes directly responsible for the QTL  Overexpression of Glo1 in the cingulate cortex of the anxious 129S6/SvEvTac strain further enhanced the anxiety-related phenotype Oxidative stress has also been implicated in the pathogenesis of other neuropsychiatric diseases, including schizophrenia and major depressive disorder , and Glo1 is linked to diabetes , Alzheimers disease , autism and the regulation of theta oscillations during sleep  Reproducibility between replicates was high ( Supplementary Table 1 ), and the estimated false positive rate was low (0.013%; see the Supplementary Methods for details) Several methods have been used to show that the amygdala, septohippocampal system, medial hypothalamus, central periaqueductal grey, and frontal and cingulate cortices are important brain structures involved in the regulation of anxiety and fear  Several methods to test levels of anxiety-like behaviour in mice have been developed and pharmacologically ‘validated’; that is, shown to be specifically responsive to agents with proven anxiolytic or anxiogenic effects  Similarly, 129S6/SvEvTac mice overexpressing Gsr in the cingulate cortex were more anxious than GFP-expressing controls, although the effect was on the border of statistical significance ( P = 0.054; Fig. 2d ) Some of the identified genes showed differential expression across several brain regions, while the majority of the genes were differentially expressed between strains in only a single brain region ( Table 1 ) Strain characterization with both tests was consistent (Pearson coefficient of correlation between the ‘open-field time spent in the middle of the chamber’ and the ‘light–dark box time spent in the light compartment’ was high, r = 0.84), and showed that A/J, DBA/2J and 129S6/SvEvTac were the most anxious strains and FVB/NJ the least anxious strain ( Fig. 1a ), as reported previously  The 129S6/SvEvTac and C57BL/6J strains of mice were injected with either a virus expressing siGlo1 or sihp53 The 129S6/SvEvTac mice injected with siGlo1 virus spent 49% more time in the middle of the chamber compared with control animals injected with the sihp53 virus ( P = 0.036; Fig. 2f ) The behaviour of C3H/HeJ and C57BL6/J animals was intermediate ( Fig. 1a ) The behaviours of the three groups ( Glo1 -, Gsr - and GFP-expressing animals) were significantly different at five weeks after injection in 129S6/SvEvTac mice ( P = 0.047), and at seven weeks after injection in C57BL/6J mice ( P = 0.040), as shown by a Kruskal–Wallis non-parametric analysis of variance (ANOVA) The Glo1 -expressing mice spent 12% more time near the walls in the open-field chamber compared to the GFP-expressing controls ( P = 0.016; Fig. 2d ) The lentiviral approach was favoured over other viral vectors because lentiviral vectors efficiently transduce central nervous system cells and are not cytotoxic  The less-anxious C57BL/6J mice injected with the Gsr lentivirus also showed an increase in anxious behaviour, spending 16% more time near the walls in the open-field chamber compared to GFP-expressing controls ( P = 0.003; Fig. 2e ) The newly identified genes should further our understanding of the specific genes, pathways and mechanisms that are important for the regulation of normal and pathological anxiety in mice and humans. The results of our lentivirus experiments show that overexpression of either Glo1 or Gsr in the cingulate cortex increases, while inhibition of Glo1 expression by siRNA decreases, the level of anxiety-like behaviour of mice Therefore, we performed a correlation analysis to identify a subset of genes with expression levels that correlate with anxiety-related phenotypes across all strains (see the Supplementary Methods for details) Therefore, we sought to determine the role of these candidate genes in influencing anxiety-related behaviour in a complex genetic background These probe sets cover genes that are differentially expressed between the phenotypic extremes, but may not necessarily correlate with anxiety-like phenotypes across all six inbred strains These results strongly support the hypothesis that changes in the expression levels of Glo1 and Gsr in the brain lead to a significant effect on anxiety-related behaviour, and establish a causal role for these genes, which are both part of a pathway that regulates oxidative stress, in the genesis of anxiety-like behaviour These strains were selected because they are widely used in neurobiological research, with C57BL/6J representing a non-anxious strain and 129S6/SvEvTac representing an anxious strain This effect was evident as early as five weeks after injection This was particularly intriguing given that reduced glutathione (GSH), the levels of which are maintained by Gsr, is a major antioxidant in the brain To ensure that our experimental methodology and data analysis methods minimized the number of false positives and maximized the reliability of the results, we carefully compared at least two independent replicate samples for each brain region from each strain  To further investigate the role of Glo1 and Gsr in anxiety, we prepared lentiviral vectors to overexpress these genes in vivo ( Supplementary Fig. 3a ) To further prove that the expression level of these genes modulates anxious behaviour, we tested whether inhibition of Glo1 gene expression led to a decrease in anxiety-like behaviour using lentiviral vectors that expressed an siRNA (small interfering RNA) against Glo1 (siGlo1) To independently confirm the differences, we performed quantitative polymerase chain reaction with reverse transcription (quantitative RT–PCR; qPCR) for 11 of the 17 candidate genes ( Supplementary Fig. 2 ) Two genes—cadherin 2 ( Cdh2 ) and epoxide hydrolase 1 ( Ephx1 )—did not show clear differential expression between the strains by qPCR We analysed the offspring of two different F 1 crosses of the non-anxious C57BL/6J strain and an anxious A/J strain (AB6F 1 and B6AF 1 ), in addition to BALB/cByJ inbred mice as this strain was shown to be very anxious We combined gene expression profiling and behavioural testing of multiple highly characterized strains in search of candidate genes for anxiety-like behaviour We confirmed transgene expression associated with stereotaxic injection by in situ hybridization ( Supplementary Fig. 3b–c ) We confirmed transgene expression associated with stereotaxic injection by visualizing GFP expression associated with lentiviral infection ( Supplementary Fig. 3d ) We have shown that gene expression profiles of specific brain regions of anxious and non-anxious mice differ significantly We hypothesized that if Glo1 and Gsr exert a strong influence on the phenotype, the activity levels of the enzymes should correlate with the anxiety-related phenotype We identified eight probe sets in the hippocampus, 12 in hypothalamus, 33 in pituitary, seven in bed nucleus of the stria terminalis, 19 in periaqueductal grey, 12 in amygdala and 12 in cingulate cortex We identified oligonucleotide probe sets that showed statistically significant differences in expression levels between two of the most anxious (A/J and DBA/2J) and the two least anxious (FVB/NJ and C57BL/6J) mouse strains in at least one brain region (see the Supplementary Methods for details) We identified several strong candidates and performed follow-up functional studies to demonstrate directly that altered expression levels of the identified genes affected anxiety-like behaviour in mice ( Supplementary Fig. 1 ) We measured the activities of delta-aminolevulinate dehydratase (Alad), glyoxalase 1 (Glo1) and glutathione reductase 1 (Gsr) from brain homogenates containing combined tissue of hippocampus, striatum and cortex ( Supplementary Fig. 2 ) We used two such tests to measure anxiety-like behaviour in six inbred mouse strains—the light–dark box test and the open-field test (described in the Supplementary Methods )
 A tiny amount of oxygen — as is present under most technological growth conditions, but not in the ultra-clean, high-vacuum environment used in the authors experiments — might efficiently block the diffusion path of gold on the silicon surface Analogously, the indirect conclusion from the fact that Hannon and colleagues observe an effect under highly controlled, low-vacuum conditions that is not observed under less severely controlled conditions could be that a little added oxygen impurity — although not too much — is beneficial for silicon nanowire growth At that time, manufacturers of integrated circuits were concerned that silicon crystals contained some oxygen atoms from the crystal-growth process, and pushed the manufacturers of silicon wafers to eliminate these remnants At the heart of the success of microelectronic gadgets, from laptop computers to mobile phones and iPods, is the fact that silicon-based electronic devices keep getting smaller But first, some background But Hannon et al . show that, under the ultra-clean, high-vacuum conditions of their special electron microscope, larger droplets grow at the expense of smaller ones But if the trend to miniaturization of these features is to continue — say, to scales below 10 nanometres — a new basic unit for electronics, other than the conventional silicon wafer, is required But it was not until 1992 that the first electronic device on the nanoscale, based on gallium arsenide semiconductor nanowires, came to fruition  Even tiny variations in the size of the gold nucleation droplets would lead to unacceptable variations in the length and diameter of the silicon nanowires Hannon et al . argue convincingly that the mode of transport is surface diffusion, which requires not only a high diffusivity of gold on the silicon surface, but also a high solubility of gold on the surface or in a thin surface layer ( Fig. 1 ) If the nanowire lies on the surface of a silicon single-crystal wafer, growth occurs ‘epitaxially’, that is, with the same crystal orientation as the underlying silicon In a paper published online today, Hannon et al . report in situ observations under an electron microscope of the growth of silicon nanowires in ultra-clean conditions *  In the most advanced of such devices currently in production, the smallest features that regulate the flow of current are less than 100 nanometres in size In this way, Hannon and colleagues results could resemble the oxygen-in-silicon story of the 1970s In this, a tiny liquid droplet of a metal, such as gold, absorbs silicon from a gaseous precursor, such as silane (SiH 4 ) or disilane (Si 2 H 6 ), with such efficiency that the gold–silicon alloy droplet becomes supersaturated with silicon It turns out that oxygen in fact precipitates onto small regions of the wafers, creating traps for detrimental metallic impurities in a process known as gettering  It was subsequently observed that wafers with negligible oxygen content produced less reliable electronic devices Molecular-beam epitaxy usually requires an ultra-clean environment, and here the transport of silicon as well as that of gold occurs through diffusion on the silicon surface, not through the gas  Ostwald ripening would make the growth of ordered arrays of millions of essentially identical silicon nanowires — a prerequisite for nanoelectronic applications — exceedingly difficult Several candidate materials exist: carbon nanotubes, molecular switches and nanoscale silicon wires are examples That would be an unexpected and useful message: sometimes extremely clean is just too clean. The droplet remains at the tip of the nanowire, which grows steadily outwards from it The droplets at the tips of semiconductor nanowires that grow in parallel have generally been considered to be independent The fundamentals of this technique for the growth of silicon and other semiconductors were understood more than 40 years ago for creating objects with diameters larger than 100 nanometres The idea of using nanowires of conventional semi-conductors such as silicon or gallium arsenide as building-blocks of nanoelectronic or nanophotonic devices was introduced into mainstream research at the end of the 1990s (see, for example, ref. 2 ) Their observations might cast doubt on the suitability of such nanowires for mass production There is, however, an escape clause mentioned by the authors that is also in agreement with our own preliminary experimental results These silicon nanowires are generally grown by the vapour–liquid– solid (VLS) method These smaller droplets then shrink away, preventing any further nanowire growth from them They might, on the other hand, simply be telling us that the particular experimental conditions under which these nanowires were made were just too clean This cannot occur through gaseous diffusion above the silicon wafer because of the extremely low vapour pressure of gold; equally, the transport of gold atoms through the bulk of the silicon is also negligible This effect, known as Ostwald ripening — sometimes jokingly referred to as the capitalistic principle — is named after Wilhelm Ostwald, 1909 chemistry Nobel laureate, who explained the effect as resulting from a decrease in total surface energy that occurs when atoms are transferred by diffusion processes from smaller to larger crystals . (For a mathematical treatment of the effect, see refs 7 , 8 .) Such an energy-minimizing diffusion transfer requires the efficient transport of atoms between neighbouring gold droplets This is a technique based on the VLS method, but in which silicon is supplied not as a gas but as a directed beam of atoms This supersaturation causes a single, cylindrical silicon crystal — the nanowire — to nucleate, with the diameter of the nanowire being determined by the size of the initial gold droplet This would fit with what we know about the growth of silicon nanowires by molecular-beam epitaxy This would render the gold droplets independent of each other, as has been assumed for the past 40 years Today, the oxygen content of silicon wafers is exactly specified for the best possible gettering performance
 ACE activates the hormone angiotensin, which helps to maintain blood pressure and promotes the growth of the heart in response to exercise Already, in unpublished work, ACE inhibitors have been shown to reduce muscle wasting in mice Although he expected genes to modulate some individual responses to diet and exercise, he also anticipated that regular workouts would improve fitness indicators such as lung efficiency and blood cholesterol for everybody Although some metabolism genes have been identified that may play a role, the most strongly linked gene so far is Titin  And athletes who have inherited ACE D from both parents experience about three times more heart growth in response to exercise than those who have inherited two ACE I genes  And London-based drug company Ark Therapeutics is currently running final-stage clinical trials on the use of the ACE inhibitor imidapril to treat severe muscle wasting in cancer patients And overall, the HERITAGE data show that the risk of cardiovascular disease and type 2 diabetes falls in those who exercise regularly, Rankinen says And some of these now seem likely to prove their worth in the clinic As the lower levels of ACE associated with ACE I improve endurance, Hugh Montgomery, a cardiovascular geneticist at University College London, wondered whether ACE I might also be advantageous to those suffering serious illness Because the variation was much less extreme within pairs of identical twins, Bouchard concluded that the effect was largely dictated by genes  Bouchards attempts to track fitness genes began in the mid-1980s at Laval University in Quebec, Canada But 5% of the subjects had virtually no change, and another 5% had improved by more than twice the average amount But the HERITAGE data show that training does not inevitably increase levels of HDL cholesterol But this isnt vindication for couch potatoes Conventional wisdom has it that regular exercise reduces the risk of heart disease by raising blood levels of high-density lipoprotein (HDL) cholesterol, a complex that helps prevent cholesterol from forming fatty deposits on blood-vessel walls Does this all mean that exercise could actually be bad for those of us with the ‘wrong genes’? Not at all, insists Rankinen. “We found not a single ‘universal non-responder’,” he says Even those who could not raise their V O 2 max through exercise were still getting some other health benefit such as higher HDL cholesterol levels or lower blood pressure Everyones health improves in some way or other from exercise, but just how it improves is largely dependent on genes Fitness genetics may be feeding ideas into the clinic, but could genetic destiny become a new excuse for couch potatoes? “If they think their performance is limited by their genes, people tend to give up,” says Montgomery. “People are afraid of trying and failing — its part of the human condition.” Nevertheless, his advice to those who long to be fitter is to do serious exercise come what may For everyone, it seems, there is at least some benefit. He and his colleagues focused on the maximum amount of oxygen absorbed by the body from a lungful of air — a standard measure of aerobic fitness, usually abbreviated as V O 2 max  He found that children with potentially deadly meningitis were more likely to require intensive care or to die if they had two copies of the ACE D gene rather than two copies of ACE I  His study of some 300 young sibling males, published in May last year, hints that three of these genes may help to determine a persons physical strength  His team also found that premature babies with ACE I fare better . “Our work on athletes is feeding back into the clinic,” says Montgomery. “How efficiently we use oxygen is decisive when we are desperately sick.”  It may eventually be possible to help such patients with drugs that slow down ACE activity In a few people there was even a small rise in these numbers  In fact, in about one-third of exercisers, the level of the complex fell In other words, everyone improved on some score In the end, the number of fitness-linked genes is expected to be large It is unclear to what extent fitness parameters such as V O 2 max are indicative of long-term health prospects, but even presumed health indicators such as cholesterol, a factor in heart disease, did not follow the expected pattern of more exercise is better It may be that some forms of the gene allow the heart to pump larger volumes of blood than others  It turns out that an enzyme that boosts HDL cholesterol is found in ‘slow-twitch’ muscle fibre, the type that takes longer to fatigue and so makes distance running easier Looking at certain measures of fitness, some people actually fare worse after exercise, whereas others show little or no improvement Meanwhile, Gaston Beunen, a sports scientist at the Catholic University of Leuven in Belgium, is looking at the half-dozen or so key genes that contribute to the synthesis of myostatin, a protein that blocks new muscle growth Much of this variability seems to be attributable to genes Now based — together with Bouchard — at the Pennington Biomedical Research Center in Baton Rouge, Louisiana, the studys main data set comes from some 740 sedentary adults who were subjected to an intense exercise regime in the lab Now, the growing field of fitness genetics is attempting to tease those genetic components apart, and the studies are generating fresh insights into the benefits of exercise as well as unexpected pay-offs for medicine One common gene variant, known as ACE D , makes more ACE than the other common version, ACE I  One gene drawing a lot of attention encodes an enzyme called ACE, or angiotensin-converting enzyme One way to begin to untangle these apparently contradictory effects is to go after the genes involved Paul Williams, a health researcher at the Lawrence Berkeley National Laboratory in Berkeley, California, for instance, suspects that a gene related to the synthesis of HDL cholesterol might be involved Physical attractions Other teams are also on the hunt for fitness genes Similarly, most people had lower exercising heart rates and blood pressure after the training programme — an indication of improved fitness — but the extent of the reduction was extremely variable So far, more than 100 appear in the literature, most of which have been identified in the past four years , although in many cases more work is needed to confirm the link Some 20 years later, it has become clear from the work of Bouchard and others that this is not the case Survival of the fittest The studys main aim was to determine how exercise reduces risk factors for cardiovascular disease and diabetes, but Bouchard and researchers at the four other collaborating institutions also took blood samples for genetic analysis. “We were trying to find as many genes as possible that influence fitness and performance,” Bouchard says Ten years ago, he found that people who have an easier time taking up running after leading sedentary lives also started out with higher levels of HDL cholesterol in their blood — and increased those levels more quickly — than those who find running difficult  That initial study was fairly small, so Bouchard extended the work in 1992 by helping to set up a multicentre research effort called the HERITAGE Family Study, which is still running today The average increase in V O 2 max after the training programme was 19% The I variant, in contrast, is more common among élite athletes in endurance sports such as long-distance running and swimming, which require more efficient metabolic use of energy and oxygen  The researchers found more variation between than within families, suggesting at least a portion of a persons ability to benefit from exercise is inherited. “We concluded that just about half of the difference in trainability was heritable,” says Tuomo Rankinen, the studys project manager The researchers monitored changes in the participants blood pressure, heart rate, blood chemistry and V O 2 max over 20 weeks The resulting reams of data and frozen blood samples are still being analysed, but the results so far confirm Bouchards earlier studies They also seem to perform better in sports that rely on sheer strength and power, such as weight-lifting or sprinting They found that most people can get more oxygen out of each breath after training but that a minority were no better off, regardless of how efficient their lungs were at the start This could ultimately reveal a great deal about how exercise produces health benefits, and may lead to treatments for diseases of metabolism and physiology This is considered one of the key benefits of taking up sports such as running This produces protein fibres that contribute to the elasticity of heart muscle cells To this end, scientists at the HERITAGE study are scanning the genomes of participants for gene variants that occur more frequently in association with different fitness responses When Claude Bouchard set out to see whether genes play a role in physical fitness, he assumed, like most people, that exercise training makes everyone fitter Williams is now beginning a large-scale genetic study to see whether differences in that enzyme are associated with differences in lifestyle choice
 And vibrations from the earthquake itself were enough to send many people running inland. “There has been some progress in getting a warning system, but not a huge amount,” says Alverson. But international organizations report that responses to these warnings were patchy But warnings were still delivered much more rapidly than they had been in December In the event, the magnitude-8.7 earthquake didnt generate a large tsunami It explicitly advised evacuating coasts within 1,000 kilometres of the epicentre It was four-and-a-half hours before the PTWC sent a message to the Tsunami Bulletin Board — which goes by e-mail to international tsunami scientists and organizations — mentioning press reports of the disastrous tsunami One, issued 15 minutes after the event, stated that a quake of magnitude 8.0 had occurred, with no risk of tsunamis to Pacific nations Shortly after that quake it issued two bulletins — but only to members of the Pacific warning system That was just as well, because when it struck, only a handful of the 25 countries in the interim warning system had provided names and numbers for national points of contact. “The earthquake happened before our deadline for receiving contact points,” says Keith Alverson, head of UNESCOs Global Ocean Observing System in Paris. (See Box 1 ) Under the interim system, the US Pacific Tsunami Warning Center (PTWC) in Hawaii and the Japan Meteorological Agency will provide alerts on all seismic activity in the Indian Ocean region to round-the-clock contact points in the surrounding countries The authorities in some coastal areas did issue prompt alerts and evacuated coastal areas The centres team then also attempted to contact colleagues in Indonesia and Thailand, both members of the Pacific system The embassies, in turn, informed local emergency management agencies. “The PTWC now pays particular attention to the Indian Ocean; last time they werent looking at it,” says Peter Pissierssens, head of ocean services at the Intergovermental Oceanographic Commission in Paris The latest earthquake struck off the coast of Sumatra on 28 March, just days before an interim tsunami warning system for the Indian Ocean was due to come into force on 1 April The PTWC also alerted the US Department of State, which sent messages to US embassies in the Indian Ocean region The PTWC itself responded much more quickly and decisively than in December The reaction was very different this time The second, issued 45 minutes later, upgraded the quake to magnitude 8.5 and stated that there was “the possibility of a tsunami near the epicentre” The system, agreed in March (see Nature 434 , 261 ; 2005 10.1038/434261b ), is intended as a stopgap until 2006, when agreement is due on the details of a full-blown warning system based on tide gauges and seafloor pressure monitors Twenty minutes after the earthquake, the PTWC sent out a bulletin simultaneously to Pacific centres and to the bulletin board, warning that the event had “the potential to generate a widely destructive tsunami in the ocean or seas near the earthquake” Warnings about the risk of a tsunami after the recent earthquake in Indonesia spread faster and more widely than they did for last Decembers calamitous event, officials in the region say
 A simple genetic test identifies those at risk and screening is routine. “Its not right that they should be discriminated against,” says Lev After challenges, the consortium narrowed the patents scope to cover the diagnosis of a particular mutation in Ashkenazi Jews And various geneticists challenged Myriads patents Ashkenazi Jewish women with this mutation frequently develop breast cancer But very few patent holders demand licence fees from public health clinics Dorit Lev, head of the Israel Association of Medical Geneticists, says that the situation is unacceptable If they are, they will have to pay the same high royalties for BRCA2 testing that US doctors have to demand from all patients — the US patent office has granted broad versions of both the BRCA1 and BRCA2 patents In January, a European patent that Myriad filed on the related BRCA1 gene was revoked, because critics revealed errors in the DNA sequence as first registered (see Nature 433 , 344 ; 2005 10.1038/433344a ) It was submitted in 1996, granted in 2003, and originally covered all possible research and diagnostic tools involving the gene Munich Europes rules for gene patenting are under attack for allowing racial discrimination On 29 June, the European Patent Office (EPO) upheld a patent that will mean Ashkenazi Jews have to pay for screening for a particular breast-cancer gene The BRCA2 sequence seems to be correct, but the consortium has refocused its BRCA2 patent on the point where its claims of intellectual ownership are strongest — a mutation that seems to be found exclusively in Ashkenazi Jews The EPO decision means that European patients will be asked whether they are Ashkenazi The Munich-based EPO has granted patents on hundreds of individual genes The only option for opponents is to press for changes to the grounds on which the EPO grants patents. “This is a moral not a legal issue and we are now thinking about challenging the political basis of the European rules,” says Mary Rice, spokeswoman for the Vienna-based European Society of Human Genetics. The patent, on the BRCA2 gene, was filed by Myriad Genetics of Salt Lake City in Utah, although the company has since transferred ownership to a consortium that includes the University of Utah Research Foundation Those challengers are unhappy with last weeks result. “We are thinking about whether to appeal again, but given the general rules of the EPO, the basis on which we might be successful is not obvious,” says Gert Matthijs of the Centre for Human Genetics at Belgiums Catholic University of Leuven When Myriad bucked that trend, many European clinics decided to ignore its royalty requests
 But efficiency requires specialization and a large scale, and for many workers this results in the removal of the elements of a job that make it fulfilling But if the goal is a sustainable and desirable future for all of humanity, then ‘enough’ has a clear meaning and imperative Finally, it is not enough for the system to be sustainable and desirable for a small élite, while leaving most people in sustainable misery For example, economic development that causes environmental and social destruction that outweighs its gains is not real development at all Given the increasingly well known dependence of human well-being on ecosystem services and natural capital, this implies that maintaining our ecological life-support system and the biodiversity that allows it to function is a key sub-goal He provides three detailed contemporary examples where the logic of sufficiency has been implemented and the systems have managed to survive and do well, while still embedded in the larger efficiency- and growth-crazed society How much is enough? This is a question that is almost never asked in conventional discussions about the economy and society If our goal is sustainable human well-being, we have to measure and include all the things that contribute to that goal If the purpose is ‘more’ then, obviously, there can never be enough In each of these chapter-length examples, Princen details what can be achieved in terms of quality of life and sustainability by breaking with the idea that more is always better It is also not enough for the system to be desirable in some of its aspects, but terrible in others It is not enough for the system to be merely sustainable, as an atrocious system might be sustainable indefinitely Likewise, it is not enough for the system to be merely desirable, as desirability now may lead to misery later Nature is not merely a luxury good One convenient way to summarize these contributions is to group them into four basic types of capital that are necessary to support the real, human-welfare-producing system: built capital, human capital, social capital and natural capital Our challenge is to clearly articulate and agree on the vision of a sustainable and desirable future for humanity Princen argues that if we adopt a “logic of sufficiency” rather than efficiency, the larger culture can also achieve these goals Princen contrasts this with a proposed sufficiency principle, which places ‘good’ above ‘ever better’ and aims to provide a rationale for quality and sustainability Princens unique contribution to this discussion is his detailed and engaging history of the efficiency principle and its role in supporting the paradigm of unlimited economic growth The core problem is that we have forgotten that economic growth is a means to an end, not an end in itself The examples also provide an existence proof for the sufficiency principle — solutions do exist The first is the northern California Pacific Lumber Companys sustainable timber-harvesting policies; the second is the protected and restricted lobster fishery at Monhegan Island, Maine; the third is Toronto Islands policy of restricted car access The logic of efficiency can just as easily be used in the service of sustainability as in the service of growth The tacit assumptions are that there is never enough, that growth must continue indefinitely, and that, as Robert Heilbroner once put it: “the flow of goods and services consumed by everyone constitutes the ultimate aim and end of economic life” Then we can clearly define what is sufficient to meet that goal, but we can also be efficient in achieving it. There is much to like in this book, but it sets up a false dichotomy between efficiency and sufficiency, and ultimately misses the core issue — it is alternative goals, not just alternative rationalities, that lead to different results These assumptions are now so ingrained that to question them seems blasphemous, but a little research shows that they are fairly recent (post-Second World War) and are ultimately counterproductive in a finite (and full) world These not only include conventional economic goods and services, but also contributions from nature, from family, friends and other social relationships at many scales, and from health, education and fulfilling employment Thomas Princen, associate professor of international natural resources and environmental policy at the University of Michigan, has added his voice to the growing chorus recognizing the ultimate futility of unlimited economic growth on a finite planet Those elements include creativity, control and responsibility Ultimately, to answer the question ‘How much is enough?’, one needs to specify ‘for what purpose — towards what goal?’ What, then, is the end? What is the shared goal of humanity? There is a growing consensus that this goal is (or should be) a sustainable and desirable present and future for all of humanity With its roots in factory management, efficiency has grown to encompass all aspects of modern life, Princen says
 But plants also take up considerable quantities of silica from soil solution, which is recycled into the soil from falling litter in a separate soil–plant silica cycle that can be significant in comparison with weathering input and hydrologic output  Here we analyse soil water in basaltic soils across the Hawaiian islands to assess the relative contributions of weathering and biogenic silica cycling by using the distinct signatures of the two processes in germanium/silicon ratios Our data imply that most of the silica released to Hawaiian stream water has passed through the biogenic silica pool, whereas direct mineral–water reactions account for a smaller fraction of the stream silica flux Rates of mineral dissolution can be enhanced by biological processes  Silicon has a crucial role in many biogeochemical processes—for example, as a nutrient for marine and terrestrial biota, in buffering soil acidification and in the regulation of atmospheric carbon dioxide Traditionally, silica fluxes to soil solutions and stream waters are thought to be controlled by the weathering and subsequent dissolution of silicate minerals  We expect that other systems exhibiting strong Si depletion of the mineral soils and/or high Si uptake rates by biomass will also have strong biological control on silica cycling and export. After 48 h of equilibration the samples were centrifuged at 5,000 r.p.m After digestion, the sample was centrifuged and the acid was decanted from the opal After several rinses with deionized water, the opal was digested at room temperature in 2 M NaOH Care was taken to make sure that the sample was wetted, and the sample was left uncovered for 10 min Dry leaf sample (0.5 g) was placed in a 100-ml Teflon digestion vessel with 9 ml of HNO 3 and 1 ml of H 2 O 2  In time-series extraction studies we found that [Si] sol reached constant values within several hours It was then capped, placed in the microwave, and heated to 180 °C for 10 min Methods Water samples Stream water samples were filtered through 0.22-µm filters, spiked with a 70 Ge tracer solution, and analysed by hydride-generation inductively coupled plasma (ICP) mass spectrometry on a Finnigan Element 2 at Cornell University  Phytolith extraction Opal phytoliths were extracted from leaf samples by closed-vessel microwave digestion in a Milestone Ethos Plus system Silica concentrations were determined by ICP optical emission spectroscopy Soil samples were taken as continuous channel samples from hand-dug soil pits; individual samples therefore represent a depth range of 4–30 cm Soil water samples were prepared by mixing distilled water with homogenized soil samples to field capacity The digested sample was diluted and analysed for Ge and Si at Boston University by procedures similar to those described above. The supernatant was filtered at 0.22 µm, then spiked and analysed as above This standard method provides an appropriate mimic for field conditions because most soil water is held at or below field capacity and is then flushed by occasional rainfall events Uncertainties in both Ge and Si measurements were less than 5% With the exception of short periods of saturated flow, nearly all water in soil is subject to unsaturated flow for long periods before leaching A best fit to a linearized projection of the stream data in Fig. 1 yields an estimate (± s.e.) of Ge/Si = 0.25 ± 0.02 at [Si] = 1,800 µM (see Supplementary Information ), and we take these values as representative of component 1 (phytolith-derived Si) for modelling purposes A substantial fraction of root activity and nutrient uptake takes place in this shallow rooting zone at the Hawaiian sites , and high concentrations of dissolved silica might act as a buffer to otherwise high and potentially toxic dissolved aluminium concentrations in the rooting zone  According to this model, mineral stability controls the concentrations of dissolved silica in equilibrium with clay assemblages; mineral weathering rates define the available flux of Si; and the degree of dilution of solutions generated in the weathering environment sets overall stream [Si] According to this scheme, which we term the Murnane, Stallard, Froelich (MSF) model, incongruent dissolution of primary minerals yields a solution with high Si concentration, [Si], and low Ge/Si (component 1), whereas dissolution of secondary, Ge-enriched clays yields a low-[Si], high-Ge/Si solution (component 2) Allophane is the dominant secondary mineral in soils from 20 to 150 kyr, whereas the oldest sites (1,400 and 4,100 kyr) contain kaolin minerals, gibbsite and sesquioxides  Although data on the rates of uptake of Si from soils by vegetation are not yet available, it is very likely that the internal cycle of Si is much faster than the rate of external input Although mineral dissolution reactions must ultimately control the availability of silica in the environment, in Hawaii the biological cycle of silica seems to be the dominant control on the rate of silica loss from watersheds At sites at least 20 kyr old, soil solutions from deeper than 15 cm range from 6 to 45 µM Si, near the value expected for kaolinite–gibbsite equilibrium (about 30 µM) At the young sites (less than 20 kyr old), where primary minerals and glass are still present and undergoing weathering, (Ge/Si) sol is mostly less than or equal to (Ge/Si) basalt , which is consistent with the production of a Ge-depleted solution during primary mineral weathering Below 15 cm, (Ge/Si) sol in the old soils almost always exceeds the fresh basalt value (2.6 µmol mol -1 ), ranging from near 3 × 10 -6 to 14 × 10 -6  By controlling the activity of dissolved Si in soils and streams, plants might exert widespread influence on weathering rates and terrestrial silica fluxes. Combined stream and soil water data suggest [Si] sol = 25 µM for component 2 (weathering-derived Si), with a Ge/Si ratio of 2.6 × 10 -6  Combined stream, soil water and phytolith data suggest a value of 0.2 ± 0.1 for component 1. [Si] for this component must be at least 1,600 µM (observed in soil solutions from the Olaa site) but cannot exceed the solubility of phytoliths (about 1,800 µM (ref. 21 )) Conversely, inadequate sampling of high discharge events with low [Si] and high Ge/Si could bias the mean values towards a biogenic source Cybotium , Dicrauopteris and Diplazium ferns contain significant amounts of phytolith Si, whereas the dominant canopy species Metrosideros polymorpha does not Dissolved Ge–Si relationships from most rivers from a variety of climatic and geological settings are similar, and comprise trends that have been explained as mixing between silica derived from weathering of primary minerals and silica derived from weathering of secondary clays  Export fluxes from the four watersheds with long-term data used here are 150–5,400 mol Si ha -1  yr -1  Ge and Si data from Hawaiian streams unaffected by coal burning or hydrothermal inputs define an apparent mixing relationship ( Fig. 1 ) Ge/Si in fresh Hawaiian basalts (tholeitic and alkaline) fall in a relatively narrow range of (2.3–2.9) × 10 -6 (mol/mol) (ref. 17 ) Ge/Si ratios in soil solutions should reflect the soil mineral phases undergoing dissolution or transformation  Ge/Si ratios in streams unaffected by pollution or hydrothermal inputs are always lower than Ge/Si in the silicate bedrock that they drain  Ge/Si ratios in the soil waters are lowest in near-surface organic horizons or those immediately below, and are much higher in underlying mineral soils ( Fig. 2b ). (Ge/Si) sol 1 × 10 -6 are found only in the upper 10 cm at all sites (and only in the upper 5 cm at the young sites), and are associated with relatively high [Si] sol  Ge/Si values in the phytoliths were low, from 0.04 × 10 -6 to 0.37 × 10 -6 , similar to the low (Ge/Si) sol values from the surface soils and to component 1 of the stream model ( Fig. 1 ) Germanium/silicon ratios have been used to trace silica sources in rivers and the oceans  Given the constraints described above, we can apply a mixing model to determine the relative importance of the two Si sources to four Hawaiian streams gauged by the US Geological Survey, which were sampled by Mortlock and Froelich  Given the high [Si] of this component, a concentration-weighted calculation requires that only 2.8–9% of the stream water flux is derived from this shallow source Hawaii should not be unique in this way, because other highly weathered tropical systems share the characteristics of strong Si depletion of the mineral soils and high biomass production and turnover, creating a potentially large pool of reactive biogenic silica relative to low availability of mineral-derived Si Hawaiian soils are generally silica-depleted, leaving the biogenic Si pool with an important role in the overall silica cycle High-(Ge/Si) sol , low-[Si] sol soil waters found below 15 cm depth at the older sites are consistent with the prediction of the MSF model: a ‘component 2’ composition resulting from the dissolution of Ge-enriched secondary aluminosilicates High-[Si], low-(Ge/Si) values in the surface soil water samples are consistent with a biogenic input of Si (refs 5 , 6 ) High-Ge/Si, low-[Si] solutions (component 2) should occur in the upper parts of weathered soil profiles that have lost their primary minerals and in which the dissolution of secondary clays with high Ge/Si is important However, except in the top 5-cm organic horizon, (Ge/Si) sol values are too high to account for the low-Ge/Si component 1 required by stream data However, in near-surface samples, [Si] sol is very high and can approach experimentally determined values of phytolith solubility  However, the recognition of an active terrestrial biological cycle of Si raises questions about the pathways of silica from weathering to streams In contrast to the predictions of the MSF model, a ‘component 1’ composition with Ge/Si 0.5 × 10 -6 and high [Si] is found only in near-surface (organic) horizons in both young and old soil profiles In the young soils, (Ge/Si) sol below 10 cm range from 1.1 × 10 -6 to 5.6 × 10 -6 , bracketing the value of fresh basalt In young (about 0.3 kyr old) sites, [Si] sol is mostly 200–600 µM, a value consistent with active weathering of fresh glass and primary minerals throughout the soil profiles Major element geochemistry, soil mineralogy and solid-phase Ge/Si ratios have been characterized by previous studies Many plants sequester silica in biogenic phytoliths (opal-A structures), and soils can accumulate significant quantities of biogenic opal-A  Older soils (at least 20 kyr old) have experienced significant Si loss, and have high Ge/Si (about 6 × 10 -6 to 20 × 10 -6 ) Our data imply that most of the silica released to Hawaiian stream water has passed through the biogenic silica pool, whereas direct mineral–water reactions account for a smaller fraction of the stream Si flux Primary basaltic weathering does not provide this low-Ge/Si component Secondary minerals (clays) formed in the soil environment are the major complementary reservoir higher in Ge/Si (refs 12–14 ) Silica export fluxes from the rooting zone (20–30 cm depth) have been measured for our soil sites, and range from 400–9,400 mol Si ha -1  yr -1 (ref. 23 ), so the production of dissolved Si from shallow soils seems capable of supporting our inferred biogenic fraction of watershed Si losses Silica supply to Hawaiian soils is controlled by weathering of the local basaltic substrate and mineral aerosols, which contribute significant amounts of Si to older soils  Soil solution, [Si] sol , values more typical of concentrations in streams (100 µM or more) are only present in the upper 15 cm ( Fig. 2a ) Soil solutions were extracted by the saturation paste method and analysed for Si and Ge (details are given in Methods) The chronosequence ranges from 0.3 to 4,100 kyr substrate age, but has common rock type, present-day climate and vegetation  The data can be modelled as a two-component mixture in which component 1 has Ge/Si ≈ 0.2 × 10 -6 and [Si] 600 µM, and component 2 has Ge/Si ≈ 2.6 × 10 -6 and [Si] ≤ 25 µM ( Fig. 1 ) The data we have presented here argue for a strong biological imprint on the silica cycle in a mesic tropical, volcanic system The discharge-weighted mean Ge/Si values from the four streams range from 0.49 to 0.93 and indicate that component 1 comprises 68–90% of Si carried by stream water The export of silica from the watersheds cannot routinely exceed the supply The highest values are found at the oldest site, and are associated with very low [Si] sol values: 10 µM or less The MSF model assumes direct mineralogical control on stream silica (and germanium) The MSF model predicts that the low-Ge/Si, high-[Si] component 1 is produced during the incongruent dissolution of primary minerals in the lower part of soil profiles, near the interface with fresh material, and/or in the upper parts of young soils that are not yet depleted of silica and retain primary minerals The plant cycle of Si maintains high dissolved [Si] in soil waters in the upper portion of soils at highly weathered sites that would otherwise have [Si] values at least an order of magnitude lower This biogenic component is the only one we have identified that can provide the low-Ge/Si, high-[Si] component required to explain the data from Hawaiian streams Under these conditions the biogenic Si pool will be important in the silica cycle  We expect that some other terrestrial ecosystems, including grasslands that are rich in biogenic silica and have high turnover rates , also have a strong biological control on Si cycling and export We extracted phytoliths from leaf samples across the soil chronosequence (see details in Methods section) We note that a lower [Si] sol value for either of components 1 or 2 (with higher [Ge]) could still provide a good fit to the data ( Fig. 1 ) but would increase the estimated biogenic silica fraction We propose that silica is extensively recycled between the upper soil profile and plants, as are other nutrients, and dissolved silica in the shallow soils acquires a low Ge/Si ratio typical of phytolith silica We suggest that amorphous biogenic silica in the near-surface soil is much more labile than Si present in clays in underlying mineral horizons, or even in primary mineral assemblages  We tested the predictions of the above model by measuring [Ge] and [Si] in soil waters from seven depth profiles along a chronosequence of basaltic soils across the Hawaiian islands What is the impact of this internal plant cycle on stream Si fluxes? Is stream export largely unaffected by this process, or does the ‘internal’ plant cycle have a significant role in controlling silica export from watersheds? The Hawaiian islands offer an opportunity to test the predictions of the MSF model and to investigate the impact of biogenic silica cycling on stream export Young soils (about 0.3 kyr old) retain primary minerals and volcanic glass, have experienced little Si loss, and have Ge/Si ratios close to that of fresh basalt 
 A direct response may just add fuel to controversies And when you have the chance, try to patiently explain why what you are doing is interesting and exciting, and may even be useful one day. Critics, who are often prepared to devote immense energies to their efforts, can thrive on the resulting he said, she said situation It is hard to answer unfair charges of élitism without sounding élitist to non-experts Keep doing what you are doing Responding to this kind of criticism can be very difficult Scientists in this type of situation would do well to heed the advice in Nature s Editorial Sir Your Editorial “To build bridges, or to burn them” and News Feature “In the name of nature” raise important points about criticism of science and how scientists should best respond ( Nature 443 , 481 ; 2006 and Nature 443 , 498 – 501 ; 2006 ) The critics feel passionately that they are right, and that their viewpoints have been unfairly neglected by the establishment The News Feature concerns radical environmentalists and animal-rights activists, but the problem covers a wider area, often involving more enlightened criticism of science from outside the scientific establishment and even, sometimes, from within They are sometimes able to generate astonishing amounts of publicity They bring into the public arena technical claims that few can properly evaluate They strike a populist note We all know examples from our own fields or from the media
 Cdc20 and Cdh1 are the activating subunits of the anaphase-promoting complex (APC), an E3 ubiquitin ligase that drives cells into anaphase by inducing degradation of cyclin B and the anaphase inhibitor securin  Dissociation of Rae1 and Nup98 from APC Cdh1 coincides with the release of the mitotic checkpoint protein BubR1 from Cdc20 -activated APC (APC Cdc20 ) at the metaphase to anaphase transition Here we show that in mitosis timely destruction of securin by APC is regulated by the nucleocytoplasmic transport factors Rae1 and Nup98  To prevent chromosome missegregation, APC activity directed against these mitotic regulators must be inhibited until all chromosomes are properly attached to the mitotic spindle  Together, our results suggest that Rae1 and Nup98 are temporal regulators of APC Cdh1 that maintain euploidy by preventing unscheduled degradation of securin. We find that Rae1 and Nup98 form a complex with Cdh1-activated APC (APC Cdh1 ) in early mitosis and specifically inhibit APC Cdh1 -mediated ubiquitination of securin We show that combined Rae1 and Nup98 haploinsufficiency in mice results in premature separation of sister chromatids, severe aneuploidy and untimely degradation of securin After two washes with XB buffer , activated APC beads were suspended in XB buffer containing 0.2 µM E1 , 1 µM E2-C , 1.5 mg ml -1 of ubiquitin , ATP-regenerating system (ERS), 0.02 mg ml -1 of ubiquitin-aldehyde , 2.4 µg ml -1 of MG132 (all from Boston Biochem ), 10 mM dithiothreitol, 1 mg ml -1 of reduced and carboxymethylated bovine serum albumin (rcm-BSA), purified recombinant proteins (see below) at final concentrations of 1 µM, and 0.5 µl of in vitro translated [ 35 S]methionine-labelled substrate (either human securin–GFP or human cyclin B) Aliquots of 3 µl of APC beads were each loaded with 2.5 µl of in vitro translated Cdh1 or Cdc20 for 1 h at room temperature Antibodies against Cdc20 ( sc-8358 , sc-5296 ), Cdc16 ( sc-6395 ), Cdc27 ( sc-9972 ) and Cyclin B ( sc-245 ) were from Santa Cruz  Antibodies against Cdc27, Cdc2 and Mad2 were from BD Biosciences  Antibodies against Cdh1 ( DCS-266 ) and securin ( DCS-280.2 ) were from Novus Biologicals  Antibodies against Rae1 and Bub3 (ref. 6 ), BubR1 (ref. 19 ) and Nup98 (ref. 18 ) have been described Antibody against aurora A was a gift from J Antibody against histone H3 phosphorylated at Ser 10 was from Upstate Biotech  Antibody against β-actin ( AC-151 ) was from Sigma  At 23 h, nocodazole was added to a final concentration of 100 ng ml -1  Cell synchronizations We synchronized MEFs by growing highly confluent MEF cultures (at P4) in DMEM medium plus 0.1% fetal bovine serum (FBS) for 14 h Cells were then reseeded into DMEM plus 20% FBS and collected at 0, 22, 26, 28, 30 and 32 h Chen Co-immunoprecipitation, immunoblotting and antibodies Co-immunoprecipitation and immunoblotting were done as described  Details are given in the Supplementary Methods  For 15 reactions, 1.5 ml of extract (10 × 10 6 HeLa cells lysed in 50 mM Tris-HCl (pH 7.7), 150 mM KCl, 0.1% Triton X-100 and protease inhibitor cocktail ( Roche )) was incubated with 10 µg of antibody against Cdc27 (sc-9972) coupled to 45 µl of protein-G–Sepharose G1 phase HeLa cells were prepared by growth in DMEM plus 0.1% FBS for 18 h, followed by release in DMEM plus 20% FBS for 8 h G2 phase HeLa cells were prepared by synchronizing cells at the G1/S border (with a standard double thymidine block) and then releasing them in DMEM plus 20% FBS for 8 h HeLa extracts were prepared as described  Human Nup98 and Nup98Δ(192–221) were cloned into pGEX4T3 containing a TEV protease cleavage site and mouse Rae1 into pGEX4T3 In experiments where we transiently transfected HeLa cells before synchronization, the synchronization procedure was started at 24 h after transfection (which was done with Lipofectamine 2000) In vitro ubiquitination assays In vitro ubiquitination was carried out with APC immunopurified from G1 HeLa extract MEFs were infected and grown in medium with 5 µg ml -1 puromycin at 48 h after infection. pAltermax–UbcH10(C114S), securin–YFP and securin(ΔD-box/ΔKen-box)–YFP plasmids were transfected into MEFs with Lipofectamine 2000 Methods Karyotyping Metaphase spreads from MEFs and splenocytes were prepared and analysed for aneuploidy and PMSCS as described  Mitotic HeLa cells were prepared by consecutive growth in DMEM plus 0.1% FBS for 14 h, DMEM plus 20% FBS for 16 h, and DMEM plus 20% FBS and 100 ng ml -1 nocodazole for 8 h Proteins tagged with glutathione S -transferase were expressed in BL21(DE3) bacteria at 15 °C and purified from bacterial lysate with glutathione–agarose. Reactions were incubated for 75 min at room temperature (on a rocking platform) and analysed by SDS–PAGE (7.5% gels) and autoradiography The final volume for each reaction was 8 µl The in vitro transcription–translation reactions were done with APC-depleted reticulocyte lysate  Time-lapse live microscopy Time-lapse live microscopy was used to analyse spindle assembly checkpoint control, timing of mitosis, chromosome segregation and degradation of securin and securin(ΔD-box/ΔKen-box) tagged with yellow fluorescent protein (YFP) To re-establish Nup98 expression, HA-tagged Nup98 (ref. 3 ) was cloned into a pMSCVpuro retroviral vector and retrovirus was prepared A marked decrease in Cdc27 and Cdh1 binding to Nup98 occurred in the first 10 min after nocodazole release, a period when cellular securin started to decline ( Fig. 2g ) A possible explanation for the ability of Rae1 and Nup98 to prevent ubiquitin-mediated degradation of securin is that these two proteins function as inhibitors of the mitotic APC A similar decrease was observed in Cdc27 and Cdc20 binding to BubR1 Active APC Cdc20 is thought to promote anaphase by triggering destruction of both cyclin B and securin  All other mitotic regulators that we tested, including cyclin B, were present in normal amounts in mitotic Rae1 +/- / Nup98 +/- MEFs ( Fig. 1a and Supplementary Fig. 4 ) Although Nup98, Cdh1 and Cdc27 precipitated with wild-type HA–Rae1 from mitotic extracts, none of these proteins precipitated with HA–Rae1(D294A) ( Fig. 2i ) An explanation for the small amounts of securin in Rae1 +/- / Nup98 +/- MEFs could be premature ubiquitin-mediated degradation of this protein APC immunopurified from G1 HeLa extracts and activated with Cdh1 was inhibited in its ability to ubiquitinate a securin–GFP substrate in the presence of recombinant Rae1 and Nup98, but not in the presence of Rae1 and Nup98Δ(192–221), Rae1 alone or Nup98 alone ( Fig. 3a ) Because Rae1 interacts with Nup98 not only during interphase but also in mitosis , we investigated whether Rae1 and Nup98 cooperate in regulating proper chromosome segregation Because securin can be ubiquitinated by both APC Cdc20 and APC Cdh1 (refs 10 , 13 ), we tested Cdc20 and Cdh1 for their ability to interact with Rae1 and Nup98 Because securin is essential for accurate chromosome segregation , it seems likely that its premature degradation promotes PMSCS and chromosome missegregation in Rae1 and Nup98 double haploinsufficient cells Because the release of BubR1, and its co-inhibitors Bub3 and Mad2, activates APC Cdc20 and drives metaphase-to-anaphase progression , it is tempting to speculate that the dissociation of Rae1–Nup98 from APC Cdh1 also contributes to this progression By contrast, Cdc20-activated APC was not inhibited in its ability to ubiquitinate the securin–GFP substrate in the presence of Rae1 and Nup98 ( Fig. 3b ) By contrast, Cdh1, which evidently also binds to APC in early mitosis ( Fig. 2e ), co-immunoprecipitated with both Rae1 and Nup98 from mitotic HeLa extracts ( Fig. 2a , b ) By contrast, only 9% of Rae1 +/- splenocytes and no Nup98 +/- or wild-type splenocytes were aneuploid ( Table 1a ) Cdc20, which binds to APC in early mitosis, did not co-immunoprecipitate with Rae1 and Nup98 from mitotic HeLa extracts ( Fig. 2a , b ) Cell extracts were prepared and co-immunoprecipitations with antibody against Nup98 were done to determine how much Nup98 was bound to APC Cdh1 at each time point Chromosome counts showed that 32% of Rae1 +/- / Nup98 +/- splenocytes were aneuploid Collectively, these data suggest that, in mitosis, Rae1 and Nup98 function to prevent unscheduled ubiquitin-mediated degradation of the anaphase inhibitor securin Consistent with these data, Rae1 and Nup98 did not co-immunoprecipitate with Cdc20, whereas Mad2, a known inhibitor of the activator, did ( Fig. 2d ) Consistent with these data, we found that the percentage of aneuploid metaphases was much higher in passage 5 (P5) Rae1 +/- / Nup98 +/- murine embryonic fibroblasts (MEFs) than in P5 Rae1 +/- MEFs, which in turn had a higher percentage than Nup98 +/- and wild-type MEFs ( Table 1b ) Consistent with this idea, securin promptly increased in Rae1 +/- / Nup98 +/- MEFs treated with the proteasome inhibitor MG132 ( Fig. 1c ) Conversely, all three proteins associated with full-length HA-tagged Nup98 Conversely, APC Cdh1 activated by release of Rae1–Nup98 might have a more important role in the destruction of securin. Dissociation of Rae1–Nup98 from APC Cdh1 coincides with dissociation of BubR1 from APC Cdc20  Experiments in gene knockout mice have shown that Rae1 is a regulator of chromosome segregation , but the mechanism by which Rae1 regulates this process remains unclear Extensive depletion of Rae1 in HeLa cells causes defects in spindle assembly , but we observed no such defects in Rae1 +/- , Nup98 +/- and Rae1 +/- / Nup98 +/- MEFs (data not shown) Finally, we investigated whether the Rae1–Nup98 complex can inhibit APC Cdh1 -mediated ubiquitination of securin in vitro  First, we expressed HA–Nup98Δ(192–221), a Nup98 deletion mutant lacking the Rae1-binding domain , in HeLa cells and precipitated it with antibody against HA from mitotic extracts Furthermore, in mitosis Rae1 +/- / Nup98 +/- MEFs did not degrade a securin mutant that lacks both the D- and Ken-box sequences required for ubiquitin-mediated protein destruction ( Fig. 1e and Supplementary Fig. 5 ) Furthermore, the inhibitory effect of Rae1 and Nup98 seemed to be substrate-specific as ubiquitination of cyclin B by Cdh1-activated APC was equally efficient in the presence or absence of Rae1 and Nup98 ( Fig. 3c ) Furthermore, the percentage of anaphases with lagging chromosomes was considerably higher in Rae1 +/- / Nup98 +/- MEFs than in Rae1 +/- , Nup98 +/- or wild-type MEFs ( Supplementary Fig. 2b, c ) Furthermore, there were no significant differences in timing of mitosis among wild-type, Rae1 +/- , Nup98 +/- and Rae1 +/- / Nup98 +/- MEFs in the absence of nocodazole ( Supplementary Fig. 3b ) However, our observation that prometaphase-arrested MEFs with small amounts of BubR1 undergo premature degradation of cyclin B, but not securin ( Supplementary Information ), suggests that APC Cdc20 may be primarily responsible for cyclin B destruction In addition, the same results were obtained when we used antibody against Rae1 instead of against Nup98 for co-immunoprecipitation ( Fig. 2g ) In parallel, co-immunoprecipitations were done with antibody against BubR1 to determine how much of this inhibitor was bound to APC Cdc20  In the reverse experiment, Rae1 and Nup98 co-immunoprecipitated with Cdh1 ( Fig. 2f ) Indeed, the APC subunits Cdc27 and APC6 co-immunoprecipitated with both Rae1 and Nup98 from mitotic HeLa extracts ( Fig. 2a , b ) Notably, neither Rae1 nor Nup98 co-immunoprecipitated with Cdh1 when G1 or G2 HeLa extracts were used instead of mitotic extracts ( Fig. 2f ) Our results indicate that Rae1–Nup98 complexes bind to this early pool of APC Cdh1 to inhibit ubiquitin-mediated degradation of securin until a later stage of mitosis Precisely timed ubiquitin-mediated proteolysis of mitotic regulators by APC Cdc20 and APC Cdh1 governs the orderly passage of cells through mitosis  Previous studies have suggested that, at the onset of mitosis, formation of APC Cdh1 is inhibited by phosphorylation of Cdh1 (refs 15 , 16 ) Rae1 and Nup98 also co-immunoprecipitated with Cdc27 ( Fig. 2c ) Second, we expressed HA–Rae1(D294A), a Rae1 point mutant that cannot bind Nup98 (ref. 3 ), in HeLa cells and precipitated it from mitotic extracts Securin also increased when we inhibited ubiquitin-mediated destruction of mitotic APC substrates by expressing the dominant-negative ubiquitin carrier protein UbcH10(C114S) ( Fig. 1d ) Securin increased again when Rae1 +/- / Nup98 +/- MEFs were transduced with a retrovirus carrying a haemagglutinin A (HA)-tagged Nup98 complementary DNA ( Fig. 1b ) The amounts of Cdc27 and Cdh1 co-precipitating with endogenous Nup98 from mitotic extracts of cells expressing HA–Nup98(154–221) were much lower than those from mitotic extracts of control cells ( Fig. 2j ) The duration of the mitotic arrest was much shorter for Rae1 +/- / Nup98 +/- than for wild-type MEFs, but this reduction was unlikely to be the basis of the severe chromosomal instability in Rae1 +/- / Nup98 +/- MEFs because Rae1 +/- MEFs showed a similar reduction The fractions of total cellular Cdc27 that co-immunoprecipitated with Rae1 and Nup98 were modest but similar to those co-immunoprecipitating with the established APC Cdc20 inhibitors BubR1 and Bub3 ( Fig. 2c ) The messenger RNA export factor Rae1 (also named Gle2 or Mnrp41) binds to a small motif, called GLEBS, in the nucleoporin Nup98 (ref. 3 ) The percentage of metaphase spreads with PMSCS was also much higher in Rae1 +/- / Nup98 +/- MEFs than in MEFs of the other genotypes The range of abnormal chromosome numbers was considerably wider in Rae1 +/- / Nup98 +/- splenocytes than in Rae1 +/- cells These data show that Rae1 and Nup98 synergize in regulating proper chromosome segregation These results suggest that binding of Rae1 and Nup98 to APC Cdh1 functions to inhibit ubiquitination of securin Third, we disrupted Rae1–Nup98 complex formation in HeLa cells by overexpressing HA–Nup98(154–221), a Nup98 segment containing the GLEBS motif for Rae1 binding  This mechanism does not completely prevent formation of APC Cdh1 complexes in early mitosis, however, because Cdc27 co-immunoprecipitates with Cdh1 from prometaphase extracts ( Fig. 2e ) This motif is conserved in the mitotic checkpoint proteins Bub1 and BubR1, where it forms the binding site for Bub3 (ref. 4 )  the idea that Rae1 and Nup98 might be members of a family of mitotic regulators that includes Bub3, BubR1 and Bub1 Thus, Rae1 and Nup98 exist in a physical complex with APC Cdh1 in mitosis Thus, the release of Nup98 and Rae1 from APC Cdh1 in mitosis coincides with the release of BubR1 from APC Cdc20  To investigate further the molecular basis for the severe chromosomal instability induced by combined loss of Rae1 and Nup98 , we determined whether the amounts of known regulators of chromosome segregation were altered in nocodazole-arrested MEFs To investigate when during mitosis Rae1 and Nup98 dissociate from APC Cdh1 , prometaphase-arrested HeLa cells were released by removal of nocodazole and collected at various times To test this possibility, we assessed whether Rae1 and Nup98 physically interact with APC in mitosis Together, these data indicate that Rae1 and Nup98 interact with APC Cdh1 as a complex We collected splenocytes from the mice at 5 months of age and prepared metaphase spreads for karyotype analyses We found that HA–Nup98Δ(192–221) failed to co-immunoprecipitate not only Rae1, but also Cdh1 and Cdc27 ( Fig. 2h ) We found that securin was consistently present in much smaller amounts in Rae1 +/- / Nup98 +/- MEFs than in Nup98 +/- , Rae1 +/- and wild-type MEFs ( Fig. 1a ) We intercrossed Rae1 and Nup98 single heterozygous mice to produce double heterozygous mice that expressed small amounts of both Rae1 and Nup98 ( Supplementary Fig. 1 ) We next tested whether Rae1 and Nup98 bind as a complex to APC Cdh1  We observed premature separation of sister chromatids (PMSCS), a hallmark of premature APC activation, in 17% of the mitotic figures from Rae1 +/- / Nup98 +/- splenocytes as compared with 0% of the mitotic figures from Rae1 +/- , Nup98 +/- and wild-type splenocytes ( Table 1a and Supplementary Fig. 2a ) We reasoned that if Rae1 and Nup98 bind to the APC to prevent unscheduled E3 ubiquitin ligase activity, the APC-activating subunits are also likely to be part of this protein complex When challenged with the microtubule-depolymerizing drug nocodazole, Rae1 +/- / Nup98 +/- MEFs arrested in mitosis, indicating that their spindle assembly checkpoint was functionally competent ( Supplementary Fig. 3a )
 According to Yang, English children have a different language from adults, not because they occasionally speak imperfect English, but because they occasionally speak perfect Chinese (or Eskimo, French, German, Swahili...) But he fails to bring to the readers attention the work of numerous labs demonstrating that the general intelligence of those with Williams syndrome is actually in the mild range, and that their linguistic ability is seriously delayed in childhood, follows an abnormal developmental trajectory, and reveals semantic, grammatical and pragmatic deficits in adolescence and adulthood But Yang gives the theory a new slant: he argues that children learn their mother tongue by unlearning all the other languages of the world Clearly nature and nurture both play vital roles in human development, and most scholars have now rejected the old either/or controversy in favour of theories that invoke complex interactions between the two Despite the allelic difference of FOXP2 in humans, its function is similar across many species — the rapid coordination of intricately timed motor sequences Engagingly written, with fascinating examples conveying the authors enthusiasm for his topic, Yangs book vacillates between targeting parents, students and academic peers For instance, Yang mentions work on a genetic disorder called Williams syndrome, claiming that moderate to severe mental retardation coexists with unimpaired linguistic ability For some, consistent regularities in the physical and social environments to which children are exposed play a critical role; for others, the environment simply acts as a trigger for the functioning of our genetic endowment Gradually, through competition between grammars, the child hones in on the mother tongue: “every instance of language learning is just a bunch of parameters fighting for supremacy” He claims that childhood errors never violate the principles and parameters of the worlds languages, and can be explained by translating them into other languages He doesnt mention competing theories, so the naive parent or student would be forgiven for thinking that the whole scientific community concurs on how language is acquired However, the debate remains as to whether nature or nurture plays the greater role in shaping the developing brains acquisition of a native tongue In fact, it is questionable whether FOXP2 is directly involved in language at all In my view, readers of the book would have benefited from being able to contrast chomskyan theory with at least one other In The Infinite Gift , Charles Yang navigates between these two positions, endorsing without question Noam Chomskys nativist theory, which holds that the abstract human capacity for language is prespecified in our genes Inspired by Darwin and using some compelling examples, Yang asserts that language learning and historical change can both be explained by the mechanism of natural selection Instead, we are presented with supporting experimental work emanating solely from Chomskys disciples Let me conclude by drawing attention to Yangs justification of his allegiance to a nativist theory; as he says, “we cannot poke around the childs brain” On the topic of genes, Yang claims that “the uniquely human ability for language must ultimately reside in some uniquely human genes” Only with time does the infant brain become specialized and localized for different functions Rather, it is indirectly involved in rapid speech perception and production, and is expressed in humans, apes, mice and birds Such an assertion is rather outdated, as we can now examine online processing in infant brains by using high-density evoked related potentials, near-infrared spectroscopy, and other non-invasive methods Such studies are likely to open exciting windows on how the developing brain acquires language. The gene is first expressed in many different cerebral regions, but over developmental time its expression is increasingly confined to the cerebellum These have already shown that the infant cortex starts out highly interconnected, with widespread activity occurring for different inputs This is partly because we lack testable theories of the precise processes by which genes and environment interact, and partly because many in the field have entrenched philosophical views about what it is to have human language To support his assertion that there are critical periods for language learning, Yang calls upon examples of feral children Yang argues that, during the early years, children engage in variational learning, whereby several languages simultaneously form part of the childs ongoing hypotheses Yangs nativist approach seems more dynamic than that of many of Chomskys disciples, placing more emphasis on learning by the child Yet a growing body of cross-linguistic work based on construction grammar has been emerging from evolutionary anthropology, offering the richest hypothesis-driven data sampling of early child language currently available Yet elsewhere he recognizes that FOXP2 , the so-called language gene, is also involved in other cognitive functions and the development of body parts Yet in her book Wild Boy (Sceptre, 2003), Jill Dawson made a convincing case regarding the wild boy of Aveyron that it was not the lack of input at appropriate ages that impeded language acquisition, but the fact that the boy was severely autistic (perhaps also explaining why he was abandoned in the first place)
 And always, it directed people to look at their denominational virtwebs, where they would get the true picture And from there things got very confusing And not only a sale to the Presbyterians, but to the Seventh-Day Adventists, too And seeing is believing, even if youve been home-schooled and never heard of evolution except as a naughty word As soon as any question was seen to contradict a specified tenet, our PAD logically dismissed it — and everyone knows a PADs logic is flawless Fortunately, his remarks had triggered their PADs, which were already fast at work drowning him out with a flood of dazzling answers, backed up by well-documented evidence and memorable sound bites. Halfway through my product-design talk, the biologist interrupted, as though suddenly possessed, and began telling the others they were making a big mistake I brought the denominational leaders back to the purpose of the meeting when I showed them what our Personal Advice Device could do I let him fire away with his toughest questions. “How do you explain the stark differences between animals across impassible barriers, as between Australia and other lands? Why do islands always have organisms most like the nearest mainland? Why do we find clear evidence of common ancestry when we compare the DNA of an evolutionary sequence of animals, so that we can trace how genetic insertions, including retroviruses, appear and then accumulate in later forms of life?”  The Adventists were set up for PADs and got answers in their heads I showed the others on the large virtweb display what our PAD does compared with the others It also showed an alternative, God-honouring explanation for the putative evidence It chooses what it wants to believe.”  Thats when the biologist piped up and said something about our spoiling the whole point of genuine choice: young people shouldnt be made to choose between faith and science. “Of course not,” his leaders said. “Not as long as youre talking about Christian science.”  “Were seeing the Christian Science people next week,” said James It suggested that several of the questions were based on false preconceptions It was a good thing I came along with the sales staff for this one It was that Presbyterian biologist who almost blew the sale Its not just a matter of helping people make good decisions by showing them their best options — it actually does the rationalizing for them, too More than their pastors More than their spouses Nobody could argue with his facts Of course James had done his usual great job of setting the hook Of course, we restricted access to the problem virtwebs. “So,” I concluded, “it really operates exactly as the human mind does People have come to trust their PADs implicitly Presto — theyre looking at a sequence of hominid photos with increasing cranial capacities over time The Presbyterian biologist got into an in-house discussion with his leaders about whether the particular means God used to create our bodies should be the issue. “It certainly is the issue,” the Presbyterian president said. “It shouldnt be,” said the biologist, “because the more genetics or history our bodies share with other animals, the greater the wonder at what we humans uniquely experience: morality, humour, literature, science, faith.”  “Dr Adams,” said the president, “you were invited here to ask your questions and youve done that.”  “But I have more,” said Adams. “Do we really want to credit all these attributes merely to something special about our bodies, as if the material world is all there is? Isnt that what were doing when we emphasize the special way our bodies were made? Isnt that what were doing when we pit God against evolution?”  Some of the denominational leaders began to show a hint of worry The Presbyterians had brought their biologist to give me the chance to demonstrate how our PAD works The result: anti-evolution leaders were voted out by an informed electorate. “If our projections hold, 80% of American teens and adults are going to own a PAD within three years Theres no choice about that, but what you can still choose, courtesy of our latest design and your specs, is whether your PAD will be your enemy or your friend. “Weve designed a friendly PAD This is as close to real human thinking as any PAD has ever come.”  Now at this point, I thought we were still going according to plan This was bound to happen, with all the preachers telling their people theres no evidence that primitive hominids ever existed. “That might have been fine in the day when, to check out that claim, a person would have had to sit down at a PC and hunt around for hours — who has time for that? But now for those who have PADs, questions like that get answered with just a few thoughts and a quick menu selection on their retinas Those two denominations alone could deliver 18 million customers, guaranteed What human being can compete with this advice from a mind programmed to think according to our individual tastes, but immeasurably smarter, continuously updated from a world of information according to our present needs? So heres how I explained why our product is the solution to their evolution issue — and if you pay close attention, youll know how to handle the Mennonites next week. “If you want to look at the future of your denomination,” I said, “you only have to look at how the Southern Baptists were transformed from criticizing evolution in the schools to promoting it
 And it leaves open big questions about whether researchers should be obliged to make their data available (see Plotting a course ). “We roughly agree with the substance of their findings,” says Gerald North, the committees chair and a climate scientist at Texas AM University in College Station As for the reports effect on the policy debate, Mann says: “Hopefully this is the beginning of us, as a community, putting that silliness behind us.” But it criticizes the way that the plot was used to publicize climate-change concerns But the mistakes had a relatively minor impact on the overall finding, says Peter Bloomfield, a statistician at North Carolina State University in Raleigh, who was involved in the latest report. “This study was the first of its kind, and they had to make choices at various stages about how the data were processed,” he says, adding that he “would not be embarrassed” to have been involved in the work But, he adds, claims for the earlier period covered by the study, from AD 900 to 1600, are less certain Climate groups have claimed it as evidence of dangerous global warming; sceptics, especially in the United States and Canada, have questioned the studys merit and statistical methodology E E For example, the growth of bristle-cone pine trees, which played an important role in the Mann study, depends on temperature, but also rainfall Geophys In an effort to quell the controversy, the chairman of the House Committee on Science, Representative Sherwood Boehlert (Republican, New York), commissioned the academy to examine the earlier work In its report, released on 22 June, the NAS committee more-or-less endorses the work behind the graph In particular, he says, the committee has a “high level of confidence” that the second half of the twentieth century was warmer than any other period in the past four centuries In two papers published in 1998 and 1999, Manns team examined tree rings, ice cores and other ‘proxies’ of past climate, and used them to reconstruct the Northern Hemispheres temperature over the past millennium (M Lett. 26, 759–762; 1999) Mann et al  Mann et al  Nature 392 , 779 – 787 ; 1998 and M Now the US National Academy of Sciences (NAS) has weighed in with a report on the ‘hockey-stick’ plot, which it hopes will finally lay the controversy to rest Overall, the committee thought the temperature reconstructions from that era had only a two-to-one chance of being right Panel members were less sanguine, however, about whether the original work should have loomed so large in the executive summary of the IPCCs 2001 report. “The IPCC used it as a visual prominently in the report,” says Kurt Cuffey, a panel member and geographer at the University of California, Berkeley. “I think that sent a very misleading message about how resolved this part of the scientific research was.”  newsad; “No individual paper tells the whole story,” agrees North. “Its very dangerous to pull one fresh paper out from the literature.”  Mann says that he is “very happy” with the committees findings, and agrees with the core assertion that more must be done to reduce uncertainties in earlier periods. “We have very little long-term information on the Southern Hemisphere and large parts of the ocean,” he says Res Shortly after it appeared in the report, two Canadians, economist Ross McKitrick and mineral-exploration consultant Stephen McIntyre, attacked the methodology behind the graph, claiming that it was based on insufficient data and flawed statistical analysis The academy essentially upholds Manns findings, although the panel concluded that systematic uncertainties in climate records from before 1600 were not communicated as clearly as they could have been The analysis was complex because the proxies were geographically dispersed and contained uncertainties that are often difficult to gauge The graph arose from the work of Michael Mann, a climatologist now at Pennsylvania State University in University Park, and two colleagues The graph purports to chart global temperatures over the past millennium; a sharp rise at the current end is the ‘blade’ that makes the otherwise flattish line look like a hockey stick The NAS also confirmed some problems with the statistics The plot soon became known as the hockey stick, and was featured prominently in the executive summary for policy-makers in the 2001 report on global warming from the Intergovernmental Panel on Climate Change (IPCC) The researchers concluded in their 1999 paper that “the 1990s are likely the warmest decade, and 1998 the warmest year, in at least a millennium”, and included a graph showing a sharp upturn in temperature from about 1900 onwards This earlier period is particularly important because global-warming sceptics claim that the current warming trend is a rebound from a ‘little ice age’ around 1600 US politicians amplified their complaints, most prominently Representative Joe Barton (Republican, Texas), who in 2005 wrote to Mann demanding he share his data with critics and congressional overseers Washington DC Its probably the most politicized graph in science — an icon of the case for climate change to some, and of flawed science in the service of that case to others — and it has coloured the climate-change debate for nearly a decade
 Astrocytes are the most abundant and functionally diverse glial population in the vertebrate central nervous system (CNS)  Here we show multiple functions of Stem cell leukaemia (Scl , also known as Tal1 ), which encodes a basic helix–loop–helix (bHLH) transcription factor, in the regulation of both astrocyte versus oligodendrocyte cell fate acquisition and V2b versus V2a interneuron cell fate acquisition in the p2 domain of the developing vertebrate spinal cord However, the mechanisms underlying astrocyte specification are poorly understood Indeed, astrocyte development is generally thought to take place in a position-independent manner  It is unknown whether a comparable process determines embryonic astrocyte identity It is well established that cellular diversification of neurons in the embryo is generated by position-dependent extrinsic signals and combinatorial interactions of transcription factors that direct specific cell fates by suppressing alternative fates  Our findings demonstrate a regionally restricted transcriptional programme necessary for astrocyte and V2b interneuron development, with striking parallels to the involvement of SCL in haematopoiesis They further indicate that acquisition of embryonic glial subtype identity might be regulated by genetic interactions between SCL and the transcription factor Olig2 in the ventral neural tube. Antibodies and IHC with antigen retrieval and probes used in ISH are described in Supplementary Methods  Because the NesCre line is subject to mosaic expression, it was important to use NesCre ×  Scl fl /+ males mated to Scl fl/fl females to achieve ablation in NesCre ×  Scl fl/fl progeny  Cell counts and statistical measures Histograms show cell numbers per histological section (means ± s.e.m.) derived from counts from six anterior–posterior spinal cord levels from at least two embryos of any given genotype (for details of genotype and n , see the text) Confocal micrographs were collected on a Zeiss LSM510 microscope  Detailed instructions are available from the authors on request Electroporation in E2 chick embryos was performed as described in Supplementary Methods , and the results shown are representative of more than five independent experiments In each case, ectopic expression was confirmed in adjacent sections by in situ hybridization (ISH) or immunohistochemistry (IHC) In some cases, ISH was followed by IHC for assessing Scl expression with respect to other markers Methods Transgenic mice and neural-tube electroporation in ovo Mice with targeted mutation of Scl and Olig2 loci have been described  Standard photomicrographic images were collected on a Nikon E600 microscope and Nikon or SPOT digital cameras  The level of significance was determined by Students t -test. Tissue preparation, analysis and imaging Embryos were fixed in 4% paraformaldehyde in PBS pH 7.0, embedded in optimal cutting temperature (OCT) compound ( Sakura Finetek ) and cryosectioned at 10–14 µm After V2 interneuron production, p2 progenitors give rise to a wave of ASPs  Although SCL overexpression is sufficient to promote astrocyte development throughout the embryonic neural tube, it differs from transcription factors with pan-glial roles in the embryo (for example, Sox9 (ref. 24 )) because it is normally expressed in a highly restricted CNS domain, most probably regulated by Shh and other organizing signals An early indication of pattern formation in the neural tube is the restricted expression of homeodomain and bHLH proteins in discrete domains along the dorsal–ventral axis Analysis of SCL fusions to VP16 or the engrailed repressor domain indicates that SCL acts as a transcriptional activator in the ventral neural tube ( Supplementary Fig. 3 ) As a consequence, GATA3 + cells failed to develop and we observed that Gata2 levels were nearly undetectable As LMO4 and LMO2 (and GATA2/3 and NLI) are coexpressed with SCL in the pMN/p2 region (Y.M. and D.H.R., unpublished observations), we tested the potential role of SCL–LMO interactions within a nucleoprotein complex by expressing a mutant of SCL (F238-G) that fails to recruit LMO2 (refs 28 , 29 ) As shown in Fig. 2g , we observed repression of endogenous Olig2 and ectopic development of S-100-expressing cells at the level of the pMN domain itself, and that Scl induced FGRR3 and ID3 ( Fig. 2h , i ) Astrocyte-specific expression of the clusterin, cystatin3 and brain glycogen phosphorylase genes has been reported in the mouse brain , and forced expression of Scl resulted in robust induction of these markers ( Supplementary Fig. 1d ) and S-100/S-100β-expressing cells ( Fig. 2j–m ) throughout the chick neural tube, including dorsal progenitors Astrocytes have traditionally been viewed as a neural cell population with structural and supportive roles such as the supply of essential substrates to neurons and participation in the blood–brain barrier  At 10.5 d.p.c., Scl is expressed principally in haematopoietic progenitors of the liver and throughout the anterior–posterior axis of developing spinal cord and hindbrain ( Fig. 1b ) At 14.5 d.p.c., OLPs typically have migrated from the ventral VZ, but only sparsely populate dorsal regions of wild-type spinal cord ( Fig. 2d , e ) At 14.5 d.p.c., Scl VZ expression was detected in p2 ( Fig. 1f ) and coincided with Fgfr3 , Id3 and S-100 ( Fig. 1g–i ) Because Nestin-cre expression can be mosaic , our data do not rule out an absolute requirement for Scl in the regulation of Gata2  Conversely, forced expression of SCL in the chick neural tube repressed Olig2 ( Fig. 3c ) and the development of motor neurons; moreover, such effects were pMN-specific because the p3 marker Nkx2.2 was unaffected Despite an enhanced understanding of the functional diversity of astroglia, it is generally believed that they develop in a uniform manner During CNS development, extrinsic signals from organizing centres, such as the floorplate and roofplate, instruct naive progenitor cells in the ventricular zone to adopt cellular identities unique to their position in the embryo ( Fig. 1a ) Early astrocyte populations have been identified by the expression of Fgfr3 (ref. 22 ) and Id3 (ref. 23 ); moreover, S-100 has been shown to mark ASPs localized to the p2 region of the 14.5-d.p.c. mouse spinal cord  Electroporation of Olig2 repressed Scl ( Fig. 3d ), and ectopic ventral cells expressing Scl , Gata2 and Gata3 were observed in Olig2 -/- embryos at 10.5 d.p.c. ( Fig. 3e ) Expression of a tethered SCL–E47 heterodimer recapitulated the full activity of SCL alone, including Olig2 repression, the induction of astrocytes ( Fig. 3f ) and V2b interneurons (not shown) Expression of Olig2 is specific to the pMN domain until a gestational age of 12.5 days post coitum (d.p.c.) in the mouse, and Olig2 function is essential for the development of motor neurons and OLPs  Expression starts at 10.5 d.p.c. in the spinal cord and is specific to the p2 domain , dorsal to the Olig2-expressing pMN ( Fig. 1c ) For example, most studies of astrocyte differentiation have concentrated on the involvement of transcriptional mechanisms and signalling pathways with common roles throughout the CNS  From 10 d.p.c. onwards, we observed efficient ablation of Scl expression at forelimb levels of the spinal cord ( Fig. 1k ) Further, they reveal striking parallels between SCL regulatory interactions in astrocyte and haematopoietic development Glial acidic fibrillary protein (GFAP) is inappropriate for an analysis of astrogenesis in the murine neural tube because its expression does not begin until about 15.5–18.5 d.p.c. However, regulation of the production of V2 interneurons subtypes is as yet incompletely understood In addition, a marked decrease in expression levels of Fgfr3 and Id3 at 14.5 d.p.c. ( Fig. 2b , c ) and 16.5 d.p.c. ( Supplementary Fig. 1c ) was observed In contrast, specification of embryonic oligodendrocyte precursors (OLPs) has much in common with motor neurons In contrast, the finding of a localized astrogenic transcriptional programme in p2 would contravene current assumptions that astrocyte development occurs by default and that it is homogeneous throughout the CNS In contrast, we observed increased numbers of Olig2 + cells that were dorsally located in 14.5 d.p.c. Δ Scl mice ( Fig. 2d ) In the absence of Olig function, progenitor cells that occupy the pMN location instead adopt p2 identity and produce V2 interneurons and astrocyte precursors (ASPs)  In the adult mouse brain, Scl is expressed in the subventricular zone, a source of persistent neural progenitors, and the corpus callosum (Y.M. and D.H.R., unpublished observations), which is consistent with additional roles for SCL during astrogenesis in late-developing neural populations It is now recognized that certain astrocytic cells have stem cell properties , whereas others directly modulate the development and activity of the synapse  It is possible that Olig2 represses astrocyte fate by directing an alternative fate It is possible that the heterogeneous origins of precursors might contribute to the ultimate functional and molecular diversity of astrocytes in the vertebrate CNS. Loss of V2b interneurons in Δ Scl mutants was not associated with cell death (data not shown) and the number of V2a interneurons was significantly increased ( Fig. 3a ), indicating a possible fate switch (see Supplementary Fig. 2 ) Mice carrying a floxed Scl were intercrossed with the NesCre line, which carries bacteriophage P1 cre recombinase under the control of nestin regulatory sequences , for the purpose of generating NesCre ×  Scl fl / fl progeny (hereafter called Δ Scl ) One such domain, the ‘pMN’, gives rise to motor neurons and OLPs in successive waves under the control of Sonic hedgehog (Shh) signalling ( Fig. 1a ) Our findings demonstrate critical roles for SCL in the development of astrocytes that are localized to the p2 domain of the neural tube and V2b interneurons Our results provide evidence that SCL engages in cross-antagonistic interactions with Olig2 to regulate cell fate, and indicate that bHLH ‘code’ might couple the acquisition of both glial and neuronal subtype identity in the ventral neural tube ( Fig. 4 ) Rare Scl /S-100 + cells were detected, indicating that some cells might escape NesCre excision ( Supplementary Fig. 1b ) Scl , which encodes a bHLH protein essential for haematopoietic stem cell specification and differentiation of the red-cell and megakaryocytic lineages , is expressed in close association with GATA2 and GATA3 in V2b interneurons  SCL both regulates the fidelity of late p2 progenitors and links V2b interneuron/astrocyte progeny production by a common transcriptional mechanism, which is dependent on DNA binding and requires interactions with LMO proteins, as previously shown for late SCL functions in the development of erythrocytes and megakaryocytes  Scl messenger RNA transcripts in situ were observed predominantly in cycling neural precursors in the lateral aspect of the ventricular zone (VZ) ( Fig. 1d ), and partly overlapped Lhx3, a marker of V2a/b interneurons, in p2 ( Fig. 1e ) Similar results were obtained with the OLP marker Pdgfra ( Fig. 2e ) Strikingly, we observed a dorsal expansion of Olig2 expression ( Fig. 3b ) and increased numbers of Hb9 + MNs in Δ Scl mutants ( Fig. 3b ) Taken together, our findings show that SCL function is necessary and sufficient for p2-associated astrocyte development and that it represses the production of OLPs The findings of enhanced astrocyte generation by negative-HLH proteins or in the absence of proneural bHLH function , in particular, have led to the proposal that astrocytes develop ‘by default’   The requirement for SCL in both V2b/astrocyte specification and haematopoietic development raises the possibility of shared transcriptional pathways These data indicate Scl expression in precursors for V2 interneurons and a subset of VZ cells that could represent immature astrocytes These findings indicate that SCL-mediated antagonism of Olig2 expression might occur at the transcriptional level and is most probably indirect (see Supplementary Fig. 3 ) These results raised the possibility of interactions between SCL and Olig2 in the ventral neural tube This activity was dependent on DNA binding by SCL ( Fig. 3f ) This mutant is inactive in the chick neural tube assay ( Fig. 3f ), providing strong evidence that SCL functions in this context in a complex with E proteins and an LMO protein (either LMO2 or LMO4) Thus, our findings identify a position-restricted astrogenic transcriptional mechanism in the embryo Thus, Scl function is necessary and sufficient for V2b interneuron development and is required for the maintenance of normal levels of Gata2  To determine whether SCL function is sufficient for specification of astroglia we used forced expression of mouse Scl in the chick neural tube ( Fig. 2f ) To study requirements for Scl function, we used tissue-specific ablation because Scl -/- animals die in the embryonic period  To test whether SCL regulates the fate of V2 interneurons, we overexpressed full-length mouse Scl in embryonic day (E)2 chicken spinal cord in ovo  Understanding the molecular basis of this binary cell fate choice (oligodendrocyte versus astrocyte) in the neural tube would address fundamental questions in glial biology V2 interneurons, which establish communication between motor neurons in different spinal cord segments, are further divided into V2a (Chx10-positive or Chx10 + ) and V2b (GATA2/3-positive or GATA2/3 + ) groups  We conclude that SCL and Olig2 participate in cross-antagonistic interactions that regulate cell fate specification We next determined whether decreases in ASP in Δ Scl mice were coupled to increased production of OLPs We observed a significant decrease in p2-associated S-100/S-100β-expressing cells in Δ Scl mice at 14.5 d.p.c. compared with controls ( Fig. 2a , Supplementary Fig. 1a ) We observed ectopic production of GATA3 + V2b interneurons and suppression of endogenous CHX10 + V2a interneurons on the electroporated side ( Fig. 1j ) With regard to gliogenesis, such a mechanism is necessary to regulate the size of initial OLP and ASP pools and, by extension, the timing and scope of early neuron–glial interactions Within the haematopoietic system, SCL functions in heterodimeric association with E proteins (such as E47) and acts with GATA proteins, LMO2 and its partner NLI (ldb), either with or without direct DNA binding through its basic region 
 Economically driven management systems often seem to lack the qualities of care and close monitoring that are needed in looking after the rare, vulnerable and endemic Good interpretation of scientific values and respect for our living heritage also encourage local investment (in the larger sense of the word) in the environment How we manage our environment may be a more fruitful question to ask than why However, there is little evidence that economically sound management systems in themselves engender sustainable utilization Revenue from state-run protected areas must be both administered transparently and captured locally: these were rated the most important lessons for sustainability at a 1994 conference on development of protected area strategies for African, Caribbean and Pacific countries Similarly, local ‘ownership’ of natural resources and disincentives to cheat may be prerequisites for their long-term sustainable use, as the exemplary state of the Falkland Island fisheries reminds us Sir It is true that we can divide the environment up into services that can be priced as discussed in your News Feature “Dollars and sense” ( Nature 437 , 614 – 616 ; 2005 ), even the most sacred They are surely as important as economic returns in promoting long-term sustainable use of ecosystem services and the protection of biodiversity. We are frequently reminded of this by bulletins on the state of the worlds native forests or by the collapse in several UK offshore fisheries
 An initial public offering (IPO) for SunPower, a solar-panel maker spun off by California-based Cypress Semiconductor in November, raised $139 million But its not all rosy for alternative-energy suppliers Companies working with hydrogen or fuel cells “continue to disappoint”, Wilder says Many of the smaller ones, he adds, are now “running out of money” Stocks in companies with interests in alternative energy sources breezed into the new year, with investors particularly excited by the prospects for solar power The sector is also benefiting from a general sense that the uncertainty about oil and gas supplies that dogged major nations in 2005 wont dissipate any time soon — leaving people more positive about energy sources that were once considered to be on the fringe. “Solar stocks are taking off,” says Robert Wilder, whose company, WilderShares in Encinitas, California, maintains the ECO index The WilderHill Clean Energy Index (ECO on the American Stock Exchange) moved forward on the back of news about successful share offerings in a couple of solar-panel companies Then last month, an IPO for Chinas Suntech Power netted $455 million — not bad at a time when many young companies are struggling to get initial public offerings off the ground. “Solar-panel companies are growing at 30–40% each year, and they are typically selling everything they can produce,” Wilder says This week, WilderHill and London-based New Energy Finance will launch a new market index tracking more non-US companies than ECO, reflecting the strength of demand for energy from renewable sources in Europe and Asia.
 Although identifying priority regions is an important first step in solving this problem, it does not indicate how limited resources should be allocated between regions Approaches such as biodiversity hotspots , endemic bird areas and ecoregions are used by international organizations to prioritize conservation efforts globally  Here we formulate how to allocate optimally conservation resources between regions identified as priorities for conservation—the ‘conservation resource allocation problem’ One of the most pressing issues facing the global conservation community is how to distribute limited resources between regions identified as priorities for biodiversity conservation  Our conservation resource allocation approach can be applied at any spatial scale Stochastic dynamic programming is used to find the optimal schedule of resource allocation for small problems but is intractable for large problems owing to the “curse of dimensionality”   We also show the importance of both correctly formulating the problem and using information on how investment returns change through time We demonstrate the approach with an example of optimal resource allocation among five priority regions in Wallacea and Sundaland, the transition zone between Asia and Australasia. We identify two easy-to-use and easy-to-interpret heuristics that closely approximate the optimal solution Although we recognize that funds for conservation can be directed towards many kinds of activity (for example, restoration programs, the purchase of forestry concessions and species recovery programs), we focus on the acquisition of land for reservation In principle, any relationship between area and endemic species conserved could be used Methods The first step in formulating the conservation resource allocation problem is to define a quantifiable objective Once the optimal solution is obtained, we forward-simulate the resulting acquisition schedule 10,000 times for each parameter set to calculate the expected number of species conserved Our decisions are thus constrained by a fixed annual budget Our objective is to maximize the number of endemic species remaining across all regions when habitat conversion ceases because there is no unreserved or unconverted land (see Supplementary Methods ‘Problem formulation’) Owing to an exponentially increasing state space, however, ‘the curse of dimensionality’ limits SDP to problems with few regions The maximize short-term gain heuristic selects parcels for reservation that result in the greatest increase in the number of endemic species conserved The minimize short-term loss heuristic is also myopic: it selects parcels that will minimize the expected loss of species from the system in the next time step (see Supplementary Methods (i) ). The next step in formulating the problem is determining what actions are possible, in this case what fraction of the budget to allocate to each region each year The solutions found using SDP are optimal in the face of uncertainty  Therefore, our conservation returns in each region diminish with increasing investment This heuristic ignores threat and is myopic, considering only the short-term future when selecting the next parcel to reserve and not all possible futures as the SDP algorithm does Threat is modelled by assuming that a constant proportion of available parcels in each region are converted each year To incorporate the uncertainty associated with parcel loss (see Supplementary Methods (iii) ), conversion is represented as a stochastic process with a binomial distribution We assume that each land parcel can be classified as reserved, available for reservation or converted (anthropogenically altered and assumed no longer suitable habitat for the endemic species of the region) We assume that, for each region, the number of endemic species conserved per unit area is a monotonically decreasing function of the area reserved We compare these results to a random acquisition process We estimate the cost of reservation in each region using statistical models (see Supplementary Methods (iv) ) We model this relationship using a species–area curve (see Supplementary Methods (ii) ) We use SDP and two myopic heuristics to determine how many parcels to reserve in each region each year After investment in Sulawesi ceases, the heuristic that maximizes short-term gain recommends roughly equal investment in Sumatra, Borneo and Java, and investment is scheduled last for Malaysia ( Fig. 4a ) Allocation of conservation resources, like any problem in decision theory, requires a broad goal, a specific objective, a set of constraints, a set of possible actions that form a strategy, and an understanding of the system dynamics provided by equations that link the actions and constraints to the objective (see Methods) Although these simple rankings are not widely different from the results of our decision theory approach, there are discrepancies, which would occur more frequently for problems involving more regions Applying SDP to problems with more than a few regions is computationally intractable, so we investigate whether myopic heuristics (‘rules of thumb’ that look only one time-step ahead) can approximate the optimal solution Both heuristics perform well, but the heuristic that minimizes short-term loss is most similar to the optimal SDP solution and outperforms the other heuristic for most parameter sets ( Fig. 3 ) By contrast, ranking the five regions based on individual criteria does not provide an obvious schedule for resource allocation ( Table 1 ) Conservation organizations allocate resources to areas that have been identified as priorities for conservation investment  First, we have not accounted for the spatial variability within the priority regions and, consequently, the particular parcels where resources should be allocated are not identified For example, if priority is determined only by endemic species richness, ignoring cost and threat, then Borneos priority is overestimated For example, the rankings could mean that investment should be directed towards Sulawesi until its species are conserved or, alternatively, that investments should be in proportion to the relative number of endemic species occurring in these regions For this initial case study, the heuristic that minimizes short-term loss most closely approximates the optimal solution ( Fig. 1 ) Fourth, we have used endemic bird species as a surrogate for biodiversity and assumed that numbers of endemic species reserved follows a species–area relationship Here, the goal is to maximize biodiversity conservation through the creation of reserves, given ongoing habitat destruction and the constraint of a fixed budget However, if there is uncertainty regarding our ability to invest in a region for the whole planning period, for example if funding ceases unexpectedly, then maximizing short-term gains is likely to result in the greatest number of species conserved If the annual budget is increased, land parcels are reserved at a faster rate If the objective is to maximize the total number of species conserved, then this objective is unlikely to be achieved if regions are prioritized only on the basis of species richness In addition, these rankings do not indicate the fraction of funds to allocate between the regions (nor whether funds should be allocated totally to a particular region or distributed between them) In such circumstances, resource allocation should minimize short-term loss It is also not clear how these criteria should be combined to provide an allocation schedule that will maximize the protection of biodiversity Last, we have assumed that the amount of resources invested in a region is directly proportional to the probability of species persisting Likewise, if the relative cost of investing in different regions is not taken into account, resources may be directed to expensive regions when the same amount of resources might have conserved more species if invested in regions with lower land-acquisition and management costs Minimizing short-term loss most closely approximates the optimal allocation schedule and maximizing short-term gain is close to optimal despite ignoring threat, although it underperforms if threat levels are very different On the basis of only endemic bird richness, the rankings would recommend that investment should occur first in Sulawesi, second in Borneo, third in Java, fourth in Sumatra, and last in Malaysia Once all species occurring in Sumatra are conserved, investment is scheduled for Borneo Only after this should investment proceed in Sumatra, Borneo and Java Our decision theory approach recommends initially investing all resources in Sulawesi and no other place until all the species occurring in Sulawesi are conserved Our problem formulation has five main simplifications Responsible conservation organizations and international agencies should consider embracing a decision theoretic approach when scheduling the allocation of conservation resources. Second, our economic model is very simple Similar confusion can arise if we prioritize only on threat or cost Some international organizations rank these regions in terms of their priority for funding, but the approaches used to derive these rankings are not solutions of a properly formulated problem  Species richness, or endemic species richness, is typically used to estimate the biodiversity value of a region  The approach can also be applied at any spatial scale, from global level problems to those at a local level The best strategy—how much money to spend in each region each year—depends on endemic species richness, forest conversion rates (and the uncertainty associated with these rates), land cost and initial conditions (area of land currently reserved, converted or otherwise; see Table 1 and Supplementary Table ) The efficient allocation of conservation resources will be achieved only if the problem includes data on biodiversity, threat and cost, and is rigorously formulated The heuristic that maximizes short-term gain allocates funding to both regions simultaneously, in proportion to the marginal returns from investment ( Fig. 2 ) The heuristic that maximizes short-term gain performs best when the threat levels of the two regions are similar, and performs poorly when the regions have very different threat levels but similar endemic species richness ( Fig. 3a ) The heuristic that minimizes short-term loss performs slightly worse than the optimal solution when both the relative level of threat and the endemic species richness of the two regions are very similar ( Fig. 3b ) The relative cost of conservation in different regions is ignored in the identification of priority regions despite evidence that its inclusion improves the cost-effectiveness of conservation prioritization  The SDP algorithm finds the optimal allocation decision each year given the current state of the system and possible events in the future  The simple heuristics that we explore were developed to solve a properly formulated problem, perform surprisingly well relative to the optimal SDP solution, and are superior to simple ranking approaches The three ranking criteria suggest that Sulawesi is the highest priority for conservation investment and Malaysia is the lowest The two heuristics that we propose as approximations are ‘maximize short-term gain’ and ‘minimize short-term loss’ (see Methods) There is a need for computationally feasible and understandable algorithms that can deliver near-optimal solutions for large conservation resource allocation problems These assumptions can be relaxed within the framework that we present These priority regions are identified using information on relative biodiversity values, past or present threats to these values, and current levels of protection  Third, we have not accounted for the temporally heterogeneous nature of land availability for reservation  This case study is used to illustrate our resource allocation approach, which can be applied to any number of priority regions for which a schedule for resource allocation is required This decision theoretic formulation provides an explicit and transparent statement of the problem, which addresses the essential features of conservation resource allocation: biodiversity values, threats, costs, investment returns and data uncertainty This is because regions that are highly threatened but marginally less species-rich may lose many species before being considered for conservation investment This mitigates forest conversion and, consequently, the difference between the approaches in the number of species conserved is reduced To explore the sensitivity of our results to the parameters, we assess each approach using different combinations of relative threat and relative endemic species richness for two hypothetical regions To illustrate our conservation resource allocation approach, we first compare the allocation of resources between two regions, Borneo and Sumatra, using the parameters in Table 1  Under extreme uncertainty, maximizing short-term gain is the most risk-averse approach as it provides a buffer against an uncertain investment future We argue that conservation investments should be evaluated as any investment is evaluated: that is, with a clearly defined objective and an assessment of how well the returns from the investment meet this objective We compare the performance of these heuristics to priority setting approaches based on simple rankings, using a case study from Southeast Asia We compare the results of the algorithms with rankings based on endemic species richness, threat and cost ( Table 1 and Fig. 4 ) We find an optimal resource allocation schedule using stochastic dynamic programming (SDP)  We find that the optimal schedule is to allocate all resources to Sumatra for over a decade We have formulated the conservation resource allocation problem in a clear and transparent manner that involves defining an objective, identifying management actions, acknowledging constraints and incorporating uncertainty We next evaluate the performance of the heuristic algorithms, which we have shown to be close to optimal, for five priority regions from Southeast Asia We recommend that conservation organizations maximize short-term gain, unless the regions of concern have similar endemic species richness and very different levels of threat When the relative cost of land acquisition in each region is varied, the results are similar to those in Fig. 3 once the axes are adjusted to a species gain per dollar basis When we modify the problem to include a random probability of investment ceasing, the optimal allocation schedule more closely reflects the heuristic that maximizes short-term gain
 About 10% of the euryarchaeotes in the photic zone contained the proteorhodopsin gene adjacent to their small-subunit ribosomal RNA Although euryarchaeotes were distributed throughout the water column, their proteorhodopsins were found only in the photic zone Bacteria in this environment were recently shown to contain photoproteins called proteorhodopsins, thought to contribute to cellular energy metabolism by catalysing light-driven proton translocation across the cell membrane  Here we report the presence and distribution of proteorhodopsin genes in Archaea affiliated with the order Thermoplasmatales, in the oceans upper water column Planktonic Bacteria, Archaea and Eukarya reside and compete in the oceans photic zone under the pervasive influence of light So far, proteorhodopsin genes have been well documented only in proteobacteria and a few other bacterial groups The archaeal proteorhodopsins were also found in other genomic regions, in the same or in different microbial lineages The cosmopolitan phylogenetic distribution of proteorhodopsins reflects their significant light-dependent fitness contributions, which drive the photoproteins lateral acquisition and retention, but constrain its dispersal to the photic zone. The genomic context and phylogenetic relationships of the archaeal and proteobacterial proteorhodopsins indicate its probable lateral transfer between planktonic Bacteria and Archaea Clones were spotted on Hybond-N + nylon filters ( Amersham Biosciences ) by Amplicon Express (Pullman, Washington) Fosmid clones were fully sequenced with the TOPO Shotgun Subcloning kit ( Invitrogen ) combined with sequence assembly with Sequencher v. 4.5 ( Gene Codes Corporation ) and annotation with FGENESB ( Softberry ) and Artemis v. 6 ( The Wellcome Trust Sanger Institute ) Hybridization was performed at 60 °C with polymerase chain reaction (PCR)-generated DNA probes with the use of AlkPhos Direct Labelling and ECF Chemifluorescent Detection kits ( Amersham Biosciences ) Large-insert genomic DNA fosmid clone libraries were prepared by using the vector pCC1FOS ( Epicentre ) as described previously  Methods Seawater samples collected at 22° 45′ N, 158° 00′ W (100 km north of Oahu, Hawaii) in October 2002 were passed through a 1.6-µm prefilter and retained on a 0.22-µm filter  PCR amplification of proteorhodopsin genes was done either with primer pair ArPRfor1 (5′-GACTATGTGGGTATTTCC-3′) and ArPRrev1 (5′-GCCGAATGCGGTCTTATTGACCAAATC-3′) or with primer pair o-PR2 (5′-WWNMGNTAYGTNGAYTGG-3′) and o-PR3 (5′-GGRTADATNGCCCANCC-3′)  PCR amplification of SSU rRNA genes was performed with primers Ar20F (5′-TTCCGGTTGATCCYGCCR-3′) and U1390R (5′-GACGGGCGGTGTGTRC-3′) PCR products made with degenerate primers were cloned with the TOPO TA Cloning for Sequencing kit ( Invitrogen ) before being sequenced PCR products were sequenced directly with an ABI PRISM BigDye Terminator v3.1 Cycle Sequencing kit ( Applied Biosystems ) Sequences were aligned with the use of ClustalX v. 1.83 (ftp://ftp-igbmc.u-strasbg.fr/pub/ClustalX/) and SeaView ( http://pbil.univ-lyon1.fr/software/seaview.html ), and phylogenetic analyses were performed with PAUP 4.0 ( Sinauer Associates ) and Tree-Puzzle v. 5.2 ( http://www.tree-puzzle.de/ ). A few genome fragments from these planktonic euryarchaeotes have now been characterized , but little else is known about their genetic makeup, physiology or ecology A fosmid clone (HF70_39H11) was identified that encoded a proteorhodopsin protein adjacent to a euryarchaeal-like LysE homologue on one end, and a euryarchaeal-like lysyl-tRNA synthetase on the other ( Fig. 2 ) A total of 9,216 fosmid clones from each depth (330 Mb of cloned DNA per depth) were hybridized with a planktonic euryarchaeal SSU rRNA gene probe and an archaeal proteorhodopsin gene probe (see Methods) About 96% of all archaeal rRNA genes recovered in the upper water column were affiliated with group II euryarchaeotes ( Fig. 3 ) Although planktonic Bacteria harbouring proteorhodopsins may not be photosynthetic sensu stricto with respect to carbon fixation, they probably gain a competitive advantage by using these photoproteins to generate a light-driven chemiosmotic potential Among the haloarchaea, multiple rhodopsins with diversified functions can exist within a single cell Apparently, lateral gene dispersal mechanisms, coupled with strong selection for proteorhodopsin in the light, have contributed to the distribution of these photoproteins among various members of all three of lifes domains Archaeal proteorhodopsins were also PCR amplified and sequenced, and compared with previously characterized rhodopsins ( Fig. 1b and Supplementary Fig Archaeal SSU rRNA genes identified in fosmid clones from each depth were sequenced to determine their phylogenetic affiliation Assuming that carotenoid biosynthesis is present, just one gene enabling this enzymatic step, and another encoding an opsin, are sufficient to generate a functional rhodopsin Because all available data suggest that planktonic euryarchaeote genomes contain only a single SSU rRNA, this gene linkage seems to occur in about 10% of all the euryarchaeotes detected in the photic zone (8 of a total of 82 clones; Fig. 3 ) Biochemical and biophysical characterization of heterologously expressed proteorhodopsins indicates their potential functional role in light-activated proton translocation across bacterial membranes  Clone HF70_59C08 also contained genes encoding 22 ribosomal proteins, a preprotein translocase SecY subunit, and the SSU rRNA For example, the haloarchaeon Haloarcula marismortui genome encodes six rhodopsins: one proton-pumping bacteriorhodopsin, one chloride-pumping halorhodopsin, two sensory rhodopsins, and two opsins of unknown function ( Fig. 1a ) Fosmid clones encoding both euryarchaeal SSU rRNA and proteorhodopsin ( Fig. 3 ) all shared near-identical SSU rRNAs (minimum 99.7% nucleotide sequence identity) and proteorhodopsins (minimum 95% amino acid sequence identity) Group II euryarchaeotes are typically more abundant than crenarchaeotes in ocean surface waters , and blooms of these microorganisms have been observed in surface waters of Monterey Bay and the North Sea during summer  Heterologous expression of the HF70_59C08 proteorhodopsin in Escherichia coli confirmed that the archaeal photoprotein binds retinal covalently, and preliminary experiments indicate its potential function as a light-driven transmembrane proton pump in vivo (A.M., N.U.F. and E.F.D., unpublished observations) In a survey of the genomic diversity of marine picoplankton, we randomly sequenced both ends of large-insert DNA clones recovered from marine picoplankton in the North Pacific Subtropical Gyre  In addition, terminal sequences of euryarchaeal rRNA-containing fosmids shared near-complete synteny with the two fully sequenced clones (HF70_39H11 and HF70_59C08) In contrast, while euryarchaeal SSU rRNA genes were well represented in the subphotic zone (200 m and below), archaeal-type proteorhodopsins were virtually absent ( Fig. 4 ) Microbial rhodopsin-based photosystems are relatively simple and are encoded by very few genes Nine of the sequenced proteorhodopsins, including those from the fully sequenced fosmid clones, clearly originated from group II euryarchaeotes on the basis of the genetic linkage of the proteorhodopsin gene with archaeal SSU rRNA ( Fig. 3 ) Pelagic crenarchaeotes comprise a large fraction of the prokaryotic plankton in coastal waters and the subphotic zone , and seem to be major participants in chemoautotrophic ammonia oxidation in the ocean  Pelagic euryarchaeotes comprise at least three separate phylogenetic groups based on small-subunit (SSU) rRNA sequence analyses Phylogenetic analyses of all these genes clearly identified both fosmids as deriving from marine group II euryarchaeotes ( Fig. 3 and Supplementary Fig Planktonic euryarchaeotes in the subphotic zone would presumably gain no competitive advantage from proteorhodopsin, so it is not surprising that they either have not acquired the photoprotein gene, or have not retained it Prokaryotic rhodopsins were originally thought to exist exclusively in halophilic Archaea, but recent environmental genomic studies have revealed the existence, distribution and variability of a new class of such photoproteins, called proteorhodopsins, in members of the domain Bacteria ( Fig. 1a ) Prokaryotic rhodopsins, first discovered in extremely halophilic Archaea (haloarchaea), are membrane proteins that bind retinal and respond to light stimuli Proteorhodospins therefore represent a category of ‘cosmopolitan genes’  whose broad phylogenetic distribution is driven in part by lateral gene transfer, which further influences the recipient lineages evolution and speciation  S1 ) S2 ) S3 ) S3 ) S3 ) S4 ), with most clustering in proteobacterial clades Several archaeal clones lacked proteorhodopsin, but otherwise appeared syntenic with proteorhodopsin-containing clones based on SSU rRNA gene presence and aligned terminal sequences ( Fig. 2 ) Several different groups of Archaea are commonly found in marine plankton  So far, proton-pumping proteorhodopsins have been clearly documented only in marine proteobacteria , including the recently cultivated and ubiquitous marine bacterium Pelagibacter ubique  Substantial numbers of euryarchaeal SSU rRNA genes and archaeal-type proteorhodopsin genes were observed in the photic zone, in roughly equal proportions ( Fig. 4 ) The archaeal proteorhodopsins formed a phylogenetic clade separate from other known proteobacterial proteorhodopsins ( Fig. 1b ) and had a G + C content of 49–51%, significantly higher than that of most other previously reported proteorhodopsin genes The coherent phylogenetic clustering of the linked SSU rRNA and proteorhodopsins on these genome fragments ( Fig. 2 ), and the absence of their linkage in closely related, co-occurring strains (Figs 2 and 3 ), indicate that this arrangement might have been acquired only recently The gene content of these fosmids also suggested a euryarchaeal origin, and indicated that some archaeal-like proteorhodopsins are found in alternative genomic contexts unlinked to the SSU rRNA gene ( Supplementary Fig The genetic simplicity of these photosystems, their ability to assemble and function properly in the membranes of divergent microbial groups, and their potential to contribute to cellular energy metabolism, all are indicative of their likely predisposition for genetic mobility The known functional repertoire of these photoproteins now includes energy-conserving transmembrane proton pumps (bacteriorhodopsins, proteorhodopsins and xanthorhodopsins), transmembrane chloride pumps (halorhodopsins) and light sensors (sensory rhodopsins)  The most abundant clade, so-called planktonic marine ‘group II euryarchaeotes’, is peripherally related to the Thermoplasmatales  The presence of a bacterial-like proteorhodopsin on a planktonic archaeal genome fragment was unexpected, because no proteorhodopsin-like genes have previously been reported in Archaea The remaining archaeal-like proteorhodopsin genes (unlinked to the SSU rRNA) seem to reside in different regions of the euryarchaeal genome, as indicated by photoproteins existing in different genetic contexts on euryarchaeal fosmids (HF70_19B12 and HF10_3D09; Fig. 1b ) that lack the SSU rRNA gene ( Supplementary Tables S3 and S4 , and Supplementary Fig The retinal chromophore can be generated in one enzymatic step by the oxidative cleavage of a carotenoid  The spatial distribution of such promiscuous genes, including those encoding proteorhodopsin, appears more reflective of their functional properties in relation to the environment than of the specific organisms that harbour them. The two clones formed a pseudocontig ( Fig. 2 ) sharing 16 kilobase pairs of sequence overlap having 97% DNA sequence identity and complete gene synteny, except for one hypothetical gene unique to each ( Supplementary Tables S1 and S2 ) These phylotypes, derived primarily from the subphotic zone, represent lineages of group II euryarchaeotes related to the proteorhodopsin-containing genotypes but apparently lacking proteorhodopsin anywhere in their genomes ( Fig. 4 ) This group shares a minimum of 88% SSU rRNA sequence identity with the proteorhodopsin-containing types, indicating substantial genetic heterogeneity within group II euryarchaeotes Two fosmid clones containing the novel proteorhodopsin (HF70_39H11 and HF70_59C08) were fully sequenced and compared (see Methods) Two other fully sequenced fosmids contained archaeal-like proteorhodopsins that fell into either the other high G + C clade (HF70_19B12), or the medium G + C clade (HF10_3D09) ( Fig. 1b and Supplementary Fig Very few closely related homologues of the archaeal proteorhodopsins were found in the recently reported Sargasso Sea shotgun sequence data set , where 90% of all proteorhodopsin gene fragments screened had a G + C content of 35–45% ( Supplementary Fig We screened the large-insert DNA clone libraries prepared from various depths to determine the evolutionary relatedness and environmental distribution of planktonic euryarchaeotes and archaeal proteorhodopsins in the water column
 Nature 429 , 292 – 294 ( 2004 ). 10.1038/nature02550 In this Letter to Nature , the chlorophyll a data presented in Fig. 1d–f and in Table S1 of the Supplementary Information are an order of magnitude too low owing to a calculation mistake This error does not alter the conclusions of our paper.
 However, at a more primary level, interest in miniaturized analytical systems has been stimulated by the fact that physical processes can be more easily controlled and harnessed when instrumental dimensions are reduced to the micrometre scale Much development has been driven by a need to perform rapid measurements on small sample volumes Recent years have seen considerable progress in the development of microfabricated systems for use in the chemical and biological sciences Such systems define new operational paradigms and provide predictions about how molecular synthesis might be revolutionized in the fields of high-throughput synthesis and chemical production. A good example of this approach was reported by Strook et al ., who used bas-relief, herringbone grooves on a channel bed to induce chaotic mixing at Reynolds numbers between 1 and 100 (ref. 12 ) A recent example of this concept was provided by Chambers et al ., who reported effective scale-out of a steel microfluidic reactor for direct fluorination  A significant problem encountered in single-phase microfluidic systems is that of achieving rapid and efficient mixing of fluids while minimizing dispersion A step towards integrated, parallel-reaction systems was presented by Kikutani et al .  A tangible effect of reactor miniaturization is that fluid properties become increasingly controlled by viscous forces rather than inertial forces (see page 374 ) A wide variety of other reactivities have been demonstrated in microfluidic reactor systems, including catalytic hydrogenations and dehydrogenations , Suzuki couplings , Grubbs metathesis and photochemical reactions  Accordingly, nanoparticles with narrow size distributions can be extracted, but because the starting point for all such methods is a polydisperse sample, product yields are low Accordingly, the development of microfluidic technologies to efficiently process small volumes of reagents within monolithic devices would represent a significant advance Accordingly, the reasons to pursue solution-phase chemistries for library generation are undeniable Additionally, Fernandez-Suarez et al . reported automated sequential solution-phase combinatorial synthesis to perform a 2×2 synthesis using the Knoevenagel condensation of 1,3-diketones and aldehydes  Additionally, reagents can be rapidly and efficiently mixed to ensure homogeneous reaction environments, while allowing for additional reagents to be added at predefined times After almost a decade of intensive study on the utility of microfluidic systems in chemical production, a few observations can be made After incubation, sample is then deposited onto a matrix-assisted laser desorption/ionization (MALDI) plate and analysed by MALDI-mass spectrometry (MALDI-MS) to assess reaction progress All are directly facilitated by system downscaling and associated improvements in mass and thermal transfer Although characterized by instantaneous volumes in the nanolitre range, microfluidic systems can be configured to achieve such a goal Although elegant, it is doubtful whether such an approach will ever find application in the synthesis of large libraries due to an associated increase in the complexity of the required fluidic circuitry Although many diverse effects manifest themselves upon moving from macroscale to microscale environments, some critical features are worthy of discussion Although operation within laminar-flow regimes can provide rapid mixing if diffusional distances are kept small, in many situations practical limitations (such as minimum feature dimensions) mean that basic flow lamination is inefficient at generating high degrees of mixing within short times Although simple to implement, PCR in conventional thermal cyclers is slow and inefficient due to large thermal masses associated with instrumentation Although such gains are indisputable, it is less clear how microfluidics will ultimately affect synthesis in both research and industrial environments Although the above studies provide persuasive arguments for using microfluidic systems in high-throughput synthesis, it is apparent that application is defined by the ability to develop both complex and efficient world-to-chip interfaces, which allow easy coupling between multiple reagent reservoirs and the microfluidic device  Although the optimization timescale is limited by the speed of MALDI-MS, the system is simple to implement and able to process reactions on a scale of less than 1 µg per reaction Although the required volumes are relatively small, the challenge associated with producing radiolabelled chemicals relates to production of highly pure materials within very short timescales (due to the half-life of [ 18 F]fluorine being 110 min) Although there are some examples in commercial production, industry has been slow to embrace microfluidic innovations An early demonstration of the use of microfluidics in small-molecule compound-library generation was reported by Mitchell et al ., who used distributive mixing of laminar reagent streams to synthesise α-dialkylacetamide libraries  An elegant approach to scale-out has also been described by Kikutani et al .  An elegant example of an integrated monolithic device for DNA amplification was reported by Liu et al .  An excellent example of such facility was described by Knight et al ., who reported a continuous-flow mixer incorporating a hydrodynamic focusing geometry with mixing times of less than 10 µs and sample consumption rates of nanolitres per second  An ideal recipe for nanoparticle synthesis must ensure that nucleation of solute molecules (to form seed particles) occurs on a timescale that is short compared with the characteristic growth time (in which the seeds capture dissolved solutes) An integrated microfluidic device consisting of mixer elements, fluidic valves and pumps, microchannels, chambers, heaters, and microarray sensors allows for sequential sample preparation (such as cell pre-concentration, purification and cell lysis), PCR, DNA hybridization and electrochemical detection As can been seen in Fig. 2 , droplets can be made to form spontaneously when multiple laminar streams of aqueous reagents are injected into an immiscible carrier fluid  As these and many others have been discussed elsewhere , only a small number of recent and illustrative examples are described herein As we have seen, the use of such systems as a basic tool in addressing high-throughput screening and kinetic studies of complex chemical and biological systems defines a totally new approach At present, reports of microfluidic systems for combinatorial chemistry have, at best, proved principle Because both mass and thermal transfer are rapid, temperatures may be defined with precision or varied on short timescales Because droplets can be trapped and manipulated by electrical fields generated by electrode arrays, droplets containing suspensions of nanoparticles and polymers can be induced to form complex particle structures Because mixing can only be accomplished by diffusion, rather than through the fast convective processes that dominate in turbulent systems, the only route to mixing is diffusion across fluidic interfaces ( Fig. 1a ) Because the transformation of a carbon–hydrogen bond to a carbon–fluorine bond using fluorine is highly exothermic (Δ H =−430 kJ mol −1 ), safety issues relating to temperature control are of vital importance, especially on a large scale Before a reaction between two reagents can occur, intimate contact between the component molecules must be realized through mixing Both features have significant advantages over macroscale systems and offer potential solutions to a number of key problems faced in contemporary synthesis Bottom-up approaches have attracted interest owing to their versatility and ease of use, but for many applications deviations about the mean particle diameter must be 1% to achieve the desired selectivity By encapsulating a palladium catalyst in a copolymer matrix attached to the microchannel surface, the metal remains active while irrevocably bound in the solid phase Chaotic advection in microfluidic systems can be achieved by introducing obstacles within channels or on channel surfaces, or by modifying channel geometries Concurrent operation of ten such reactors mimics a small pilot plant operation, running under the same conditions as the laboratory synthesis Consequently, although mixing via diffusion is inefficient for reactors with characteristic dimensions greater than 1 mm, when diffusion distances drop below 100 µm mixing times can, in theory, become very small Consequently, approaches to parallel, solution-phase synthesis in microfluidic reactors have been investigated Consequently, mixing is rapid and reagent transport occurs with no dispersion Continuous-flow PCR (in which a sample is moved continuously through multiple reaction zones held at specific temperatures) has been shown to provide for ultra-fast DNA amplification Conversely, the control of fluidic reagent streams within microfluidic systems allows reactions to be performed within chemical regimes (in which mixing is rapid and reaction timescales are defined by inherent reaction kinetics), whereas operation in a continuous- or segmented-flow format allows compartmentalization and/or spatial identification of multiple reactions  Creation of chaotic flow at low Reynolds numbers has also been established through the use of grooves on channel surfaces ( Fig. 1e ) Crucially, although microfluidic systems have been shown to be highly effective at generating conditions in which variables such as reagent concentration , temperature and pH can be controlled with precision, extraction of the available information is normally non-ideal Deacetylation reactions were performed in high-throughput by creating droplet reactors surrounded by a fluorinated carrier fluid, and merging these with a substrate flow Despite advances in experimental and mechanistic organic chemistry during the past century, it is noteworthy that the basic experimental techniques and associated equipment have remained largely unchanged Despite the challenges of information extraction, some recent reports demonstrate developments in high-throughput chemistry and screening Detailed evaluation of detection methods for small-volume environments are provided elsewhere , however, effective detection within microfluidic environments is clearly defined by a close interrelationship of factors such as detector sensitivity, response times, detection limits and information content Diffusive mixing efficiencies for continuous-flow systems can be measured using the Fourier number, and indicate that mixing timescales increase with the characteristic dimensions of the reactor Droplet systems could be configured to contain a gene and a transcription/translation system that includes all the required ingredients for in vitro protein expression Droplets with volumes between 500 and 2,000 nl were floated on the surface of a perfluorinated oil Early research has been successful in demonstrating that many fundamental synthetic transformations can be performed with improved space–time yields, selectivities, reaction residence times and conversions with microfluidics compared with traditional methods Effective and rapid PCR in volumes ranging from 1 pl to 50 µl has been performed using various heating mechanisms, including infrared-mediated thermal cycling , microwave heating , Joule heating and resistive heating  Enabling nanomaterial synthesis As I have highlighted, much of the interest in using microfluidic systems for synthetic applications lies in their ability to perform rapid and controllable mixing Even at this early stage in the development of microfluidic reaction systems, it is clear that advantages engendered by miniaturization may affect molecular synthesis similarly to the way that the integrated circuit has defined the computer revolution over the past 50 years Ever since Wöhlers laboratory synthesis of urea in 1828 (ref. 1 ), the chemists toolkit has predominantly consisted of macroscopic components fabricated from glass Examples include round-bottomed flasks, test tubes, distillation columns, reflux condensers and retorts Extracting information at the microscale Compared with the macroscale, microfluidic systems engender significant advantages in terms of speed, throughput, yield, selectivity and control Finally, in a mixed chemical/diffusional regime the greatest interaction between chemical reactions and fluid dynamics occurs, and the product distribution depends on both chemical factors (such as reaction kinetics) and diffusional factors (such as the mixing efficiency) Finally, it should be noted that microfluidic systems can be used to create higher-order nanostructures that are inaccessible via conventional methods Finally, it should be noted that, recently, much interest has focused on the creation of highly integrated microfluidic systems for complex biological processing Flow and mixing on the microscale A primary reason why microfluidic systems provide unusual environments in which to perform synthesis is the dependency of fluid-flow characteristics on scale For example, a system generating product at a concentration of 10% at a flow rate of 200 µl min −1 will yield 1.2 ml of product in 1 hour For example, it is expected that the use of high-performance microfluidics will undoubtedly impact the field of catalysis For example, Krishnan et al . have presented an elegant microfluidic system for PCR that relies on the control of thermal convection in a Rayleigh–Bénard cell to provide thermal cycling conditions  For example, striped multilayer particles could be generated from ternary mixtures of gold, fluorescent latex and silica particles, and core–shell particles could be synthesized by encapsulation of dried supraparticles or droplets of aqueous suspension inside polymer shells For example, typical microfluidic devices exhibit high thermal-transfer efficiencies by virtue of reduced thermal masses and high surface-to-volume ratios, and therefore allow exothermic and/or high temperature reactions to be performed in an efficient and controllable (isothermal) manner For example, we have seen that segmented flow within microfluidic channels allows generation of picolitre-sized droplets (of variable chemical composition) at frequencies in excess of 100 Hz For example, zig-zag channels ( Fig. 1b ) can generate chaotic advection at high Reynolds numbers by recirculation around turns , whereas three-dimensional serpentine channels ( Fig. 1c, d ) consisting of repeating segments in orthogonal planes can generate chaotic flows at low to intermediate Reynolds numbers  For microfluidic systems, such as blood capillaries, Reynolds numbers (Re) are typically 10 2  Fortunately, progress is being made in this crucial area, with contemporary examples of highly-integrated microsystems demonstrating that complex biological processing (such as Sanger DNA sequencing) can be performed at higher speeds and with superior efficiencies than previously achievable ( Fig. 5 ) Further utility of microfluidic systems in making compound libraries has been shown by Garcia-Egido et al ., who prepared a series of 2-aminothiazoles by means of a Hantzsch reaction of ring-substituted 2-bromoacetophenones and 1-substituted-2-thioureas  However successful (in terms of yield, purity or speed) these systems are at generating a product, their use in production applications is determined by the ease with which they can be used to generate significant volumes of product in short times However, application of such systems in industrial environments requires a better understanding of other parameters, such as scalability, facile process control, safety, profitability and operational flexibility  However, few — if any — studies have successfully exploited this feature, with analytical throughput being defined by the speed at which the detection system can operate However, in the case of fast reactions in which two or more reagents are initially present in separate streams, reaction rarely occurs uniformly throughout the whole volume However, rapid mixing with low reagent consumption is achievable using chaotic advection However, the fact that spatial organization of fluid streams allows mixing to be performed in an extremely rapid and controllable fashion is common to all approaches However, the use of microfabricated systems in real-world applications (such as medical diagnostics) is yet to become reality and will ultimately be defined by the ability to create highly integrated microfluidic systems that can handle and process complex biological fluids, and be manufactured at low cost However, via rapid reaction screening, an almost comparable performance was achieved at a temperature of −35 ° C and a reaction time of 26 s If these conditions are not met, the size of critical nuclei and growth rates will vary according to location, and result in a distribution of particle sizes Importantly, although the maximum throughput for the ten-layered pile-up reactor was ten times larger than that of a single microfluidic device, the reaction yield was maintained at 80% Importantly, no impurities or cross-contamination were observed Importantly, the system affords millisecond time control and also allows the stages of a multistep reaction to be initiated at precise times Importantly, the system is easy to maintain, operates continuously, requires single-source fluid delivery and operates under safe conditions Importantly, the use of micromachining methods has also engendered new approaches to PCR Importantly, the use of twisting channel geometries is effective in generating chaotic mixing within droplets, by folding, stretching and reorienting fluid In a similar manner, Leung et al . reported ultra-fast screening of reaction conditions within a continuous-flow micromixer using confocal Raman microscopy  In addition to homogeneous reactions, the large surface-to-volume ratios characteristic of microfluidic reactors provide unique environments for performing heterogeneous chemistry In addition to the possibility of cross-contamination, detection systems are limited to those that can effectively probe small volumes In addition, Chan et al . have reported the use of microfluidic-droplet reactors for the high-temperature synthesis of CdSe nanoparticles , whereas Yen et al . have used gas–liquid segmented-flow reactors containing multiple temperature zones for the synthesis of high quality CdSe quantum dots ( Fig. 4 ) In addition, Lee et al . recently reported a highly integrated microfluidic system for the direct synthesis of molecular imaging probes used in positron emission tomography (PET)  In all of these studies, enhanced mixing and reduced residence-time distributions fuelled the improvements in yield and size distribution In both studies, the extraction of chemical information in short times, using minimal reagent volumes provides a direct route to rapid synthetic-process optimization, which is not possible in macroscale environments In conclusion, molecular synthesis in both chemistry and biology has focused, and will continue to focus, on high-throughput experimentation on small samples In each case, the modification acts to enhance stretching, folding and breaking of the flow In general, it is fair to say that microfluidic approaches for PCR have delivered, in terms of the expected advantages with respect to macroscale systems In its simplest manifestation, this occurs by uniting pure fluid-component streams In many respects, microfluidic systems provide an ideal medium for nanoparticle production In many ways, the secondary and critical phase has already begun, whereby microfluidic tools are developed and refined to address and solve fundamental questions In other words, although microfluidic reactors generate high-quality chemical information, detection protocols are often inefficient in extracting all available information In reality, sequential systems are limited in terms of application to high-throughput synthesis In recent years, developments in genomics and proteomics have generated many potential drug targets, each requiring small-molecule modulators In the chemical regime, mixing is fast compared with the reaction rate (and is complete before a significant amount of product is generated) In the diffusional regime, reaction is fast, with the rate being limited by the mixing speed In this case, the reaction rate is independent of the rate constant, and the formation of secondary products in this situation is greatest In this way, high-quality cadmium sulphide , cadmium selenide , palladium , silver , gold , copper , titania and CdSe–ZnS core–shell nanoparticles have all been synthesized directly Indeed, a number of the current generation of commercial thermal cyclers for PCR have embraced the basic tenets of miniaturization Indeed, because microfluidic reaction systems can be used to good effect in a number of the stages involved in a chemical process (for example, in compound screening, laboratory-scale process development and production), the extensive implementation of microfluidic factories for chemical production may ultimately be defined by their acceptance as de facto tools in these upstream processes, which will, in turn, make them a more natural choice as an industrial tool Indeed, many early applications of microfluidics focused on biological reactions  Indeed, studies by Chambers et al . have reported direct fluorination of a range of substrates, including diketones and ketoesters  Indeed, the effect of mixing on the extent of a reaction and product distribution is crucial in reactor design Interestingly, the mannosylation of 2,3,4-tri-O-benzyl-methyl mannoside was achieved in optimal yield at a temperature of −60 ° C and a reaction time of 213 s It is generally recognized that first-order irreversible reactions are not affected by local turbulent mixing, but by the residence time of the system, and conversions can therefore be easily calculated  Localization of reagents within discrete droplets is an effective way of eliminating this phenomenon Microfluidic factories Most applications of microfluidic systems in synthesis have focused on the implementation of individual reaction units to demonstrate enhanced performance characteristics compared with macroscale systems Microfluidic reactors for DNA amplification The use of microfluidic systems in synthesis is not confined to small-molecule or nanoparticle synthesis Microfluidic systems have been created to allow efficient biphasic reactions between elemental fluorine and a range of organic substrates Microfluidics may just provide such tools. Millman et al . recently reported the synthesis of anisotropic particles in static-microdroplet reactors  More recent studies have also used surface-charge patterning to create electrokinetic mixing in low Reynolds number regimes  More recently, this concept has been extended to create integrated systems for performing reverse transcription and PCR within a single microdevice  Moreover, a reaction productivity of a few grams per hour scale could be maintained, comparing well with many fine-chemical processes Moreover, as discussed, perhaps the biggest challenge is the efficient extraction and utilization of the vast amounts of information produced Moreover, Lagally et al . have described the refinement of an integrated genetic-analysis microsystem for PCR and capillary electrophoresis  Moreover, nucleation and growth should occur in an environment in which chemical state functions are precisely controlled  Moreover, reaction rates of solid-phase reactions are appreciably slower than the corresponding solution-phase processes Moreover, the widespread adoption of continuous-flow modalities for PCR has been facilitated through the use of microfabricated systems Most notably, for an n by m (compound) combinatorial system in which n and m are greater than 2, a three-dimensional channel network is necessary Most studies that have used microfluidics in synthesis have either demonstrated the transferral of unit operations from conventional to chip-based formats, or have verified the reality of performance enhancements predicted by theory Nanomaterials exhibit optical and electronic properties that depend on their size and shape, and are seen as tailored precursors for functional materials in biological sensing and optoelectronics  Nevertheless, at this scale diffusion provides a driver for both rapid and controlled mixing of fluids Nevertheless, manipulation and processing of samples with instantaneous volumes ranging from a few picolitres to hundreds of nanolitres provides a significant challenge for analyte detection and identification, and in many ways defines the principal limitations of current microfluidic systems Nonetheless, these developments define new paradigms for high-throughput molecular synthesis and provide some of the most credible predictions about how the true power of combinatorial synthesis may be harnessed in molecular discovery Of equal importance is the effect of these ratios on diffusion-mediated mass and heat transfer in reactive processes Of particular note are those that use flow instabilities between two immiscible fluids  One of the most visible examples of this progression has been the development of segmented-flow droplet reactors Originally described by Kopp et al . , this approach has yielded the fastest reaction times to date, as the small-volume fluid elements can be heated or cooled to the required temperature within a few milliseconds Other examples in which microfluidic environments have been shown to provide for efficient temperature and thus reaction control include continuous-flow reactors for multicomponent reactions , Swern oxidations , diazotizations , nitrations , Andrussow reactions, Reimer–Tiemann formylations and carbonylations  Outlook The success of microfluidic systems in molecular synthesis is due largely to the exploitation of atypical fluid behaviour in small-volume environments Parallel solution-phase synthesis is typically complex and inefficient, requiring multiple reactors and large reagent volumes Passive mixers have found the widest use in synthetic applications due to their simplicity and operational flexibility Passive mixers rely on geometric properties of the channel or fluidic streams to maximize the area over which diffusion can occur, whereas active mixers rely on time-dependent perturbations of the fluid flow to achieve mixing Perhaps the most interesting demonstration of this feature has been the use of microfluidic reactors to synthesize nanomaterials of defined size and anisotropy Progress in disciplines such as genomics, proteomics, drug-discovery and high-throughput screening requires new and robust tools that will enable the extraction of enormous amounts of information and, in turn, provide the basis of a better understanding of chemical and biological phenomena Put simply, chaotic advection enhances mixing in laminar-flow systems, because it acts to continuously stretch and refold concentrated solute volumes, thereby creating an exponential decrease in striation thickness  Put simply, efficient attachment and detachment to and from the support are crucial for successful library generation, increasing the number, time, cost and complexity of process steps and the amounts of required reagents Ratner et al . have reported the use of a microfluidic reaction system to systematically study glycosylation reactions through control of reaction times and temperatures  Reaction-condition screening was achieved by screening more than 40 reagents to evaluate reactivity, and then repeating the screen with a more focused reagent set while varying reaction conditions (such as reaction time, solvent and concentration) Reactions went to completion within 2 min, and space-time yields were five orders of magnitude higher than equivalent laboratory-scale reactions Reactions were performed in a serial (time-encoded) or parallel (mass-encoded) fashion, and real-time product identification and quantitation was achieved through integration of the microfluidic reactor with time-of-flight mass spectrometry Recent studies have addressed the issue of further minimizing particle size distributions through the development of segmented-flow reactors Recent studies have demonstrated that microfluidic reactors drastically outperform macroscale systems in the direct production of nanoparticles Resulting plugs form, flow into receiving tubing, are stopped, and are isolated by sealing Several recent studies have exploited the formation of droplets in microfluidic systems to perform a variety of analytical processes  Shestopalov et al . demonstrated a two-step chemical synthesis of colloidal CdS and CdS–CdSe core–shell nanoparticles in a droplet-based microreactor  Significantly, product was generated in high enough yield to be used in in vivo PET studies Simulation of large-scale flows was achieved using a pile-up reactor in which ten glass microchannel circuits were integrated (via thermal bonding) to form a single glass structure Subsequent development of this concept allowed the rapid and automated synthesis and analysis of a 7×3 pyrazole library  Such a combination afforded unprecedented control over the reaction, and real-time identification of the small-molecule products Such features, combined with the ability to combine, split and sort droplets, are likely to transform the application of microfluidic systems, and suggest that they would be of use in high-throughput synthesis (due to high sample throughput) and kinetic measurements (due to low sample requirements and negligible dispersion)  Synthetic routes involve the particle growth on an atom-by-atom basis, and have been used to create spherical, cubic, tubular and tetrahedral crystallites of well-defined size and shape  Synthetic unit operations High surface-to-volume ratios are key in defining fluid-flow characteristics at the microscale The ability to controllably and rapidly create a homogenous reactant mixture at the commencement of a reaction is desirable The approach is also suitable for large-volume chemical synthesis via scale-out, and, importantly, opens up the opportunity for performing a range of catalytic processes at high speed and with negligible catalyst leaching The batch nature of conventional solution-phase methods (which use arrays of microwells) is unsuitable for efficient process optimization and high-throughput processing The catalytic oxidation of isopropyl alcohol to acetone using tetra- n -propylammonium perruthenate and N -methylmorpholine- N -oxide was assessed as a function of reagent concentrations and residence times The chief implication of this behaviour is that a reaction mixture sampled after initiation of mixing is formed from an ensemble of volume elements that have spent varying times on-chip The composition of the reaction effluent was easily determined, and information relating to catalyst/co-oxidant ratios, catalyst turnovers and reaction endpoints extracted The fact that fluid properties become increasingly controlled by viscous forces as reaction volumes are reduced dictates that mixing can only be accomplished through diffusion The formed droplets define picolitre volumes, and because each droplet is isolated from channel surfaces and other droplets, each one acts as an individual reaction vessel The microdevice contains microfabricated heaters, temperature sensors and membrane valves to provide controlled sample manipulation and processing of DNA within 200-nl PCR chambers The most investigated biological reaction in microfluidic systems is DNA amplification via the polymerase chain reaction (PCR) The power of such a discovery platform is such that it should be able to screen catalysts at rates up to five orders of magnitude faster than is possible at present The primary concern when creating a monolithic system lies in the complex channel topology required to perform reactions in a parallel fashion The rate of reaction is no longer defined by inherent kinetics, but is limited by diffusional rates The relationship between the reaction rate and the rate of mixing can be reduced to one of three general categories; the chemical regime, the diffusional regime and the mixed chemical/diffusional regime The selection of catalytically-active enzymes can then be performed using molecular biology to generate new catalysts and analytical techniques with which to screen them The system was configured so as to allow multiple reagent streams to be introduced sequentially under hydrodynamic flow The vast majority have used solid-supported chemistry to generate compound libraries There are a number of reasons why traditional synthetic chemistry is performed in the aforementioned equipment, but is there any advantage to performing synthetic chemistry in volumes 5–9 orders of magnitude smaller than those associated with bench-top chemistry? As shown below, the application of techniques cultivated in semiconductor industries have allowed the creation of a new instrumental platform able to efficiently manipulate, process and analyse molecular reactions on the micrometre to nanometre scale Therefore, 100 reactors operating in parallel will produce 120 ml h −1 , a rate comparable to that of many fine chemical processes These critical dependencies indicate that bottom-up approaches for nanomaterial synthesis must provide for fine control of the physical dimensions of the final product These demands have prescribed massive investment into synthetic technologies that can produce drug candidates on short timescales These include the ability to probe ultra-fast chemical reactions (with minimal sample consumption), which is beyond the reach of current technologies  They can all be broadly classified as being either passive or active This behaviour has a direct consequence on mixing within microfluidic systems This dictates the development and integration of sensitive detection systems that can process significant amounts of information per unit time This enzyme-catalysed reaction allows any nucleic-acid sequence to be generated in abundance in vitro , and has become a fundamental tool in molecular biology  This is beyond the tolerance of standard macroscale syntheses, and it is almost always necessary to use some form of post-treatment (including chromatography, sedimentation, precipitation and photocorrosion) to extract the desired particle size  This is due in part to limited long-term data on the performance and control of microfluidic reactors in operational environments, and also to cultural factors, such as the widespread investment in and deployment of batch reactors This means that thousands of individual reactions can be processed in very short times This represents a situation in which flow is considered essentially laminar, and contrasts with macroscale conduits (Re10 3 ) in which flow regimes are almost always turbulent This simple calculation is based on typical examples of reactions with low to moderate yield, and demonstrates that fine-scale processes can be simulated on chip arrays that are within the bounds of current technological development This state of affairs defines the initial phase in the lifecycle of microfluidic technology This yields a residence-time distribution that may cause significant variation in the yield, efficiency and product distribution of a reaction This, combined with manipulation of variables such as temperature, concentration gradients and pressure, dictates that continuous-flow processing on the microscale can be used to synthesize species of specific yet variable characteristics Thus, for fast reactions yielding a single product, yield is regarded as a direct measure of the degree of mixing To achieve this, two glass substrates were lithographically structured to define two fluidic layers ( Fig. 3 ) To address these variations, a diverse range of microfluidic systems have been designed for the rapid mixing of fluids  To address this issue, many microfabricated devices for PCR have been reported, with performance gains achieved through a reduction in the thermal mass of the system To prove principle, a 2×2 parallel-reaction scheme was transferred to a chip-based format To this end, Kobayashi et al . recently reported enhanced efficiencies of gas-liquid-solid hydrogenation reactions in microchannels  Under most circumstances, channel walls impart shear forces on the contained fluid, so under applied hydrodynamic pressure a parabolic velocity profile is established over the cross-section with fluid velocity zero at channel walls and maximum at the centre Unfortunately, the dependence on solid-support technologies has severely limited our ability to perform high-throughput molecule discovery  Using a highly integrated microfluidic ( Fig. 6 ), [ 18 F]fluoride concentration, water evaporation, radiofluorination, solvent exchange and hydrolytic deprotection were performed rapidly and with high radio-chemical yield to synthesize 2-deoxy-2-[ 18 F]fluoro- D -glucose Using an array of parallel microchannels coupled by a simple manifold interface to reagent flows, high-purity fluorinated products could be generated at rates of 30 g day −1  Using simple flow regimes whereby component streams are mixed at low Reynolds numbers and in continuous flow, variations in reaction residence times, temperatures and reagent concentrations are used to control average particle size, while sample size distributions are minimized through a reduction in residence-time distributions and precise control of chemical state functions Using such an approach, optimal temperature/concentration/flow rate protocols were established by in-line high-performance liquid chromatography (HPLC) analysis of the chip effluent Using the system, DNA amplification and product sizing could be performed within 10 min, and its utility established through pathogen detection, and genotyping directly from whole Escherichia coli and Staphylococcus aureus cells Using this approach, a 2×2 combinatorial amide formation reaction was performed with product yields in excess of 90% Using this approach, various substrates (including double bonds, tri-substituted olefins, and triple bonds) were reduced using an annular-flow system Variation of the cross-sectional dimensions of microchannels can be used to regulate droplet volumes, and flow-rate variation allows control of reagent concentrations  Various continuous-flow and batch microfluidic reactors have used these basic ideas to good effect and demonstrated performance characteristics superior to macroscale systems Very recently, Hatakeyama et al . also illustrated rapid optimization of organic reactions within a capillary-based microdroplet reactor 
 However, Pielke finds no discernible trend in hurricane damage in the United States after correction for inflation and demographic trends, and Landsea finds no trend in US landfall-based hurricane power dissipation back to the turn of the last century. In my original Article , I showed that there has been a significant upward trend in a measure of tropical-cyclone power dissipation over the past 30 years  It is important to note that this measure is integrated over the life of the storm, and that the upward increase is evident in all major ocean basins prone to tropical cyclones A simple calculation based on the observed root-mean-square variability of hurricane activity indicates that this is indeed the case, and probably explains why Pielke and Landsea find no trends in US landfall data Although Atlantic hurricanes do most of their destruction within 6–12 hours after landfall, they last for an average of 180 hours; moreover, only a fraction of hurricanes ever affect the US coastline As it happens, including the 2004 and 2005 Atlantic storms and correctly dropping the end-points restores much of the recent upswing evident in my original Fig. 1 and leaves the western Pacific series, correctly truncated to 2003, virtually unchanged As this trend is large and universal — having about the same value in all the major ocean basins, despite different measurement techniques — and as it is well correlated with sea surface temperature (SST), which is relatively well measured, I stand by my conclusions about the trends in tropical-cyclone power dissipation But I agree that there is a pressing need for a storm-by-storm reanalysis of tropical cyclones, not only in the North Atlantic, but also in the western North Pacific, where aircraft reconnaissance records also extend back to the 1940s. But the detectability of an El Niño signal in US hurricane damage is marginal, explaining only 3–4% of the variance  But this is a short-term and US-centric view But, as I discussed , the existing theory and modelling on which this assertion is based suggest that the predicted ∼2 °C increase in tropical SST would increase wind speeds by 10% and, accounting for increased storm lifetime, increase power dissipation by 40–50% However, by chance it had little effect on the western Pacific time series, which entails about three times as many events I cannot discount the second of Pielkes conjectures, but the reason for the disparity may be more prosaic I had fitted a polynomial to that correction, as I felt that a continuous rather than discrete correction was more defensible I maintain that current levels of tropical storminess are unprecedented in the historical record and that a global-warming signal is now emerging in records of hurricane activity In correcting for biases in the original Atlantic tropical-cyclone data, I relied on a bias correction applied by Landsea , presented as a table It is therefore possible that the real trend is detectable in the power dissipation but not in landfalling statistics Landsea believes that this had the effect of overcorrecting the most intense storms in the pre-1970 record, and I accept his revision to my analysis (Fig. 1b of ref. 3 ) Landsea correctly points out that in applying a smoothing to the time series, I neglected to drop the end-points of the series, so that these end-points remain unsmoothed Landsea starts by saying that increasing SST has the potential for “slightly” increasing the intensity of tropical cyclones Moreover, this error has comparatively little effect on the high correlation between PDI and SST that I reported  Pielke argues that because El Niño can be detected in hurricane damage, a trend related to PDI should also be evident, if it exists Pielke suggests that this apparent disparity could be explained if the power-dissipation trend I find is an artefact of the data and/or analysis methods, or if the trend is accurate but not a good predictor of damage The Atlantic hurricane-intensity record by itself is not long enough to infer any connection between hurricanes and either global warming or multi-decadal cycles, but the high correlation between hurricane activity and tropical SST is remarkable (and largely unaffected by the corrections discussed), and the SST record is long enough to show the influence of global warming The existing theory and modelling work are limited, however, in that they do not account for changes in environmental conditions, such as wind shear, and so only provide a loose guide as to what to expect The failure of any trend in landfall statistics to emerge from the noise is itself significant, and supports Pielkes view that demographic trends will be more important than climate change in coming years There is large variability in wind speed over the life of each storm and large storm-to-storm random variability: detecting a temporal trend in the presence of this variability requires separation of the signal from the noise This count is highly correlated with both tropical Atlantic SST and Northern Hemispheric mean surface temperature through the entire record, casting doubt on whether the recent multi-decadal variability in tropical SST and hurricane activity is due purely to natural causes, as Landsea implies  This has the effect of exaggerating the recent upswing in Atlantic activity This is especially evident when one looks at global activity and not just the 12% of storms that occur in the Atlantic This is hardly slight This means that the power-dissipation index (PDI) I used, which is accumulated over all storms and over their entire lives, contains about 100 times more data than an index related to wind speeds of hurricanes at landfall This probably once again reflects the difficulty of detecting trends in sparse time series in which the amplitude of random fluctuations is large compared with the signal To detect correlations with hurricane activity, tropical cyclones in the North Atlantic can be counted, assuming that detection of the presence of a storm by ships and islands is reliable (although intensity estimation is dubious before the mid-1940s) Tropical Atlantic SST explains far more of the variance of both total Atlantic tropical-cyclone numbers and average tropical-cyclone intensity than does El Niño; but curiously, SST is even less correlated with a measure of US landfalling storm activity than El Niño When global tropical-cyclone activity is considered, and not just the 12% that occurs in the Atlantic region, a trend in landfalling intensity is already apparent; even in the Atlantic the signal, if it exists, is similar to the PDI trend, and if it continues should emerge from the noise in a few decades With 100 times more data, my index has a signal-to-noise ratio that is ten times that of an index based on landfalling wind speeds
 Conditioned media obtained from distinct tumour types with unique patterns of metastatic spread redirected fibronectin expression and cluster formation, thereby transforming the metastatic profile Here we demonstrate that bone marrow-derived haematopoietic progenitor cells that express vascular endothelial growth factor receptor 1 (VEGFR1; also known as Flt1) home to tumour-specific pre-metastatic sites and form cellular clusters before the arrival of tumour cells Preventing VEGFR1 function using antibodies or by the removal of VEGFR1 + cells from the bone marrow of wild-type mice abrogates the formation of these pre-metastatic clusters and prevents tumour metastasis, whereas reconstitution with selected Id3 (inhibitor of differentiation 3)-competent VEGFR1 + cells establishes cluster formation and tumour metastasis in Id3 knockout mice The cellular and molecular mechanisms by which a tumour cell undergoes metastasis to a predetermined location are largely unknown These findings demonstrate a requirement for VEGFR1 + haematopoietic progenitors in the regulation of metastasis, and suggest that expression patterns of fibronectin and VEGFR1 + VLA-4 + clusters dictate organ-specific tumour spread. We also show that VEGFR1 + cells express VLA-4 (also known as integrin α 4 β 1 ), and that tumour-specific growth factors upregulate fibronectin—a VLA-4 ligand—in resident fibroblasts, providing a permissive niche for incoming tumour cells A double immunofluorescence protocol was performed as described in the Supplementary Methods  After 4 weeks, mice were injected intradermally in the flank with either 2 × 10 6 LLC or B16 cells ( American Type Culture Collection ) After boundary delineation, the area under the pixelation histogram was calculated, comparing total staining area to total tissue area Antibody targeting Wild-type mice were inoculated with 2 × 10 6 LLC or B16 cells Cells were allowed to migrate for 18 h with conditioned media or corresponding control media in the lower compartment, with the analysis of cell counts assessed every 6 h using a haemocytometer and trypan blue Conditioned media (300 µl) was injected intraperitoneally daily for nine days into wild-type mice that had received Rosa26 bone marrow transplants four weeks earlier Conditioned media assays Conditioned media was filtered (0.22-µm filter) from serum-free media cultured on B16 (MCM) or LLC (LCM) cells for 18 h, as described  Data were analysed by Students t -test and one way analysis of variance (ANOVA) using the GraphPad Prism statistical program Double immunofluorescence Tissues in OCT were post-fixed with acetone Error bars depict s.e.m. Fibronectin gene expression was quantified and normalized to glyceraldehyde-3-phosphate dehydrogenase ( Gapdh ) expression by polymerase chain reaction with reverse transcription (RT–PCR) using TaqMan gene expression assays ( Applied Biosystems ) as described previously Chemokine assays Conditioned media, serum-free media and plasma obtained from mice with day 14 tumours were analysed for VEGF and PlGF concentrations by an enzyme-linked immunosorbent assay (ELISA; Quantikine , RD Systems ) according to the manufacturers instructions Flow cytometry Flow cytometry was performed on an entire right lung after perfusion with PBS by right-ventricular injection For blockade of VEGFR1 function, mice were injected intraperitoneally every 48 h, between day 7–22, with rat anti-mouse VEGFR1 antibody (MF-1, IgG1, 400 µg, ImClone Systems ) or VEGFR2 antibody (DC101, IgG1, 800 µg, ImClone Systems ) or both, or with IgG control antibody, and then killed on day 24 For tumour redirection studies, intraperitoneal injections of MCM (300 µl) commenced two days before intradermal LLC implantation and then daily over the next 21 days GFP visualization Tissues were immediately frozen in OCT compound ( Tissue-Tek ) without fixation Human specimens Human specimens include: tumour tissue, adjacent normal tissue (beyond tumour margins), distant normal tissue and lymph nodes Immunohistochemistry Tissues were fixed and embedded in OCT or paraffin as previously described  Lungs were perfused with PBS before embedding in OCT Matched control groups with and without tumour were given serum-free media Methods Bone marrow transplantation Wild-type C57Bl/6 mice were lethally irradiated (950 rads) and transplanted with 1 × 10 6 β-gal + bone marrow cells (from Rosa26 mice) or 1 × 10 6 GFP + bone marrow cells (from EGFP-transgenic mice, C57Bl/6-TgN(ActbEGFP)1Osb/J ; Jackson Laboratory )  Migration assays Migration of VEGFR1 + cells in response to conditioned media was measured in a transwell assay P values 0.05 were considered significant Quantitative analysis of fibronectin expression Lung tissue was homogenized with a tissue homogenizer in TriZol reagent, and RNA was extracted as described previously  Quantitative immunohistochemistry Using both IPLab and Adobe Photoshop 7.0, random ×100 objective fields were analysed by selecting a standardized colour range for β-gal or immunohistochemical staining Selective bone marrow transplantation Mice irradiated as described above received a bone marrow transplant from purified cell populations obtained as described in the Supplementary Methods . β-Galactosidase staining Tissues and femoral bones were fixed in 4% paraformaldehyde for 4 h Serial sections ( cryostat , Leica ) were mounted with Vectashield containing DAPI (4,6-diamidino-2-phenylindole), and visualized with an ultraviolet fluorescent microscope ( Nikon Eclipse E800 ) with a Retiga camera ( QImaging ) through IPLab version 3.65a imaging software ( Scanalytics ) Statistical analyses Results are expressed as mean ± s.e.m The following antibodies were used: VEGFR1 clone MF-1 ( ImClone Systems ) or Flt1 clone C-17 ( Santa Cruz Biotechnology ); CD31 SC-1506 ( Santa Cruz Biotechnology ); VEGFR2 DC101 ( ImClone Systems ); MMP9 D19557 ( Oncogene ); Id3 C-20 ( Santa Cruz Biotechnology ); Fibronectin TV-1 ( Chemicon ); CD11b CBRM1/5 ( eBioscience ); CD34 RAM34 ( BD Pharmigen ); c-Kit ACK2 ( eBioscience ); PDGFRα APA5 ( BD Pharmingen ); αV ( Chemicon ); CD133 13A4 ( eBioscience ); α4/VLA-4 PS-2 ( Southern Biotech ); α5 (CD49e, 5H10-27); α6/CD49f GoH3 ( BD Pharmingen ); β1 9EG7 ( BD Pharmingen ); β2 M18/2 ( BD Pharmingen ); β4 ( Santa Cruz Biotechnology ); β7 M293 ( BD Pharmingen ); SDF-1 79018.111 ( RD Systems ); and CXCR4 2B11 ( BD Pharmingen ) The samples were stained in 5-bromo-4-chloro-3-indolyl-β- d -galactoside (X-gal) solution at 37 °C, as described , for 36 h and then embedded  The tissue was minced into small pieces, filtered with 100- and 40-µm filters ( BD Biosciences ) to form a single-cell suspension as previously described  Tissue samples were obtained and handled in accordance with an approved Institutional Review Board application Tissues were embedded as described above and stained with antibodies to human VEGFR1 FB5 ( ImClone Systems ) or Flt1 ( Calbiochem ) Tissues were stained for fibronectin TV-1 ( Chemicon ) and β-gal VEGFR1 + cells were isolated as above, and 1 × 10 5 cells suspended in serum-free media placed in the upper compartment of 5-µm-pore transwells ( Costar, Corning ) Wild-type mice were injected with MCM (300 µl) daily for seven days before tail vein injection of B16 tumour cells, and then daily until killed either one or four days after intravenous tumour administration After irradiation, but before tumour implantation, we observed minimal β-gal + BMDCs (mean ± s.e.m., 0.01% ± 0.01 of cells β-gal + per ×100 objective field) or GFP + BMDCs in the lungs. ( Fig. 1a , b , left panels) After primary tumour implantation, CD117-positive progenitor cells arrived in the lung before GFP-tagged tumour cells by flow cytometry ( Supplementary Fig. 1c ), recapitulating the recruitment of BMDCs described above Although a few tumour cells may have been undetectable using these methodologies, further experiments in mice given B16-melanoma-conditioned media (MCM) showed that this conditioning alone mobilized BMDCs that were capable of forming a pre-metastatic niche Animals were inoculated with either Lewis lung carcinoma (LLC) cells, which metastasize to the lungs and occasionally the liver, or B16 melanoma cells, which possess a more widely disseminated metastatic potential Anti-VEGFR1 antibody treatment eliminated the initiating clusters and completely prevented metastasis ( Fig. 4b , left middle panel; Supplementary Fig. 3 ; P 0.01 by ANOVA), whereas anti-VEGFR2 antibody did not prevent the formation of VEGFR1 + clusters but limited metastatic progression (15 ± 11 micrometastases per ×100 objective field; Fig. 4b , right middle panel and inset; Supplementary Fig. 3 ) As a result of the niche-specific directional cues from fibronectin, VEGFR1 + HPCs, expressing VLA-4 and Id3, can traverse established endothelium to form a pre-metastatic niche before the arrival of CXCR4 + tumour cells and VEGFR2 + endothelial cells Based on the current dogma, metastatic predisposition is believed to reflect inherent molecular differences in tumour cells themselves and the potential influence by surrounding stromal cells, which include the vasculature, connective tissue and immune cells  Before day 8, minimal GFP + BMDCs were observed in this tissue; however, from day 12, BMDCs began migrating into the lung ( Fig. 1c , graph and left flow cytometry panel) BMDC clusters are recruited to pre-metastasic human tissue To validate the mouse data showing tumour-specific formation of VEGFR1 + cellular clusters, we analysed human tissues from patients with malignancy BMDC clusters occur in a spontaneous tumour model We compared these findings to those in a spontaneous tumour model using c-Myc transgenic mice BMDCs colonize pre-metastatic sites before tumour cells We analysed the fate of β-galactosidase-positive (β-gal + ) and green fluorescent protein-positive (GFP + ) BMDCs following intradermal primary tumour injection in mice Bone marrow-derived cells (BMDCs) contribute to malignant transformation , tumour vascularization and neoplastic cell migration  By 120 days, VEGFR1 + clusters persisted in established lymphomas (67.8 ± 9.5 versus 0.7 ± 0.5 in c-Myc mice versus littermates, P 0.001; Fig. 2d , right panel and inset) By day 14 after tumour implantation, but before the arrival of tumour cells, the extravasation and cluster formation of β-gal + BMDCs (3.2% ± 1.2, P 0.05 by Students t -test) or GFP + BMDCs were detected near terminal bronchioles and distal alveoli, both common sites for future tumour metastasis ( Fig. 1a , b , left middle panels and insets) By day 24 after LLC tumour cell implantation, control mice that received wild-type bone marrow showed prominent lung metastases and established blood vessels ( Fig. 4a , left panel and inset) By day 24, widespread metastases were evident in untreated mice with LLC tumours in the lung ( Fig. 4b , left panel) or B16 tumours in the spleen ( Supplementary Fig. 2 , left panel and inset) Clusters induced by either tumour type expressed VEGFR1 ( Fig. 2a , right panel), and GFP + BMDC clusters coexpressed VEGFR1 ( Fig. 2b , left panel), compared with little VEGFR1 in the lung after irradiation alone ( Fig. 2a , left panel and inset) Co-localization of DsRed-tagged tumour cells with GFP + BMDC clusters was 93% at both time points, indicating that BMDCs assist tumour cell adhesion and proliferation Collectively, these results suggest that targeting the VEGFR1 + cell cluster can prevent tumour cell adhesion, proliferation and metastatic spread Considering these results, we questioned whether cytokines such as PlGF present in MCM were capable of redirecting LLC metastases to non-conventional metastatic sites for this tumour Decreased mobilization of HPCs may explain the reduced metastatic phenotype seen in these animals  During the angiogenic switch, these cells proliferate and mobilize to the bloodstream along with bone marrow-derived endothelial progenitor cells that express VEGFR2 (also known as Flk1), and contribute to the vascularization and growth of specific primary tumours  Early VEGFR1 + bone marrow clusters lacked expression of VEGFR2 and CD31 (also known as PECAM1; Supplementary Fig. 1d , left and left middle panels, respectively) Fibronectin upregulation supports adhesion of VLA-4 + BMDCs We next investigated the potential of tissue-specific ligands to support the adhesion and formation of BMDC clusters Following cluster formation, α 4 β 7 and α 6 β 4 integrins were prominently expressed within the metastatic niche (data not shown) Following the implantation of LLC tumour cells, but before the homing of the VLA-4 + VEGFR1 + BMDCs, increased fibronectin expression was observed from day 3 ( Fig. 5e , middle panel; Fig. 5f ) to day 14 ( Fig. 5e , right panel; Fig. 5f ) in the vicinity of the future metastatic niche, compared with the baseline level of fibronectin expression in wild-type lung ( Fig. 5e , left panel; Fig. 5f ) Four days after tumour injection, the frequency and size of the lung nodules were augmented by MCM (207 ± 5.6 versus 14 ± 1.7, P 0.01; Fig. 1d , right panel inset) Functional role for VEGFR1 + BMDCs in directing metastasis We assessed the potential of purified VEGFR1 + bone marrow cells to initiate pre-metastatic clusters by selectively transplanting these progenitors into irradiated mice Further characterization revealed that subsets of VEGFR1 + BMDCs coexpressed the stem/progenitor cell antigens CD133 ( Fig. 2b , right panel), CD34 ( Supplementary Fig. 1b and Supplementary Table ) and CD117 (also known as c-Kit; Fig. 2c ), suggesting that these cells may comprise phenotypically marked VEGFR1 + HPCs and precursor cells Furthermore, identification of haematopoietic clusters in human tissues before evidence of tumour spread demonstrates the applicability of targeting VEGFR1 and VLA-4 to identify and prevent metastasis in the clinical setting Furthermore, in the low-metastatic-variant of LLC, levels of both VEGF and PlGF were much lower in the conditioned media (L-LCM) and plasma compared with its more aggressive counterpart ( Fig. 6c , Supplementary Fig. 5c ) Furthermore, melanoma cells, consistent with their more aggressive metastatic nature, induced more clusters than LLC cells ( P 0.01) Furthermore, resident fibroblast-like stromal cells ( Fig. 5e , left panel inset), which proliferate in response to primary tumour ( Fig. 5e , right panel inset), may contribute to the localized deposition of fibronectin However, in MCM and melanoma-derived plasma we specifically detected higher levels of placental growth factor (PlGF), which signals though VEGFR1 alone, as compared with LCM- and LLC-derived plasma ( Fig. 6c , Supplementary Fig. 5c ) However, mice transplanted with purified VEGFR1 + cells formed numerous micrometastases throughout the lungs (25 ± 9 micrometastases per ×100 objective field; Fig. 4a , middle panel) with aberrant vasculature ( Fig. 4a , middle panel inset) Id3 expression was also seen within the clusters ( Fig. 5c , and inset showing coexpression with VEGFR1) Id3 may facilitate the mobilization of VEGFR1 + cells to the pre-metastatic niche In a transwell assay, LCM and MCM enhanced the migration of VEGFR1 + BMDCs most effectively when compared with the other growth factor conditions (LCM 55% ± 0.4, MCM 68.1% ± 5, media 10.8% ± 1.7, P 0.001 by ANOVA; Fig. 6d ) In addition, expression of specific integrins is regulated by Id genes, and may be responsible for BMDC and stromal cell interactions, motility and recruitment  In addition, metalloproteinase expression can be enhanced through α 4 β 1 signalling after fibronectin binding  In contrast, bone marrow depleted of VEGFR1 + cells failed to produce pre-metastatic clusters ( Fig. 4a , right panel; P 0.01 by analysis of variance (ANOVA)) In contrast, preculturing VEGFR1 + HPCs with either anti-VEGFR1 or anti-VLA-4 antibodies blocked this binding affinity and expansion ( Supplementary Fig. 4a , middle and right panels) In contrast, the B16 melanoma tumour cells induced the formation of BMDC clusters in multiple tissues such as the lung (103.8 ± 6.9), liver (41.8 ± 2.4), testis (36.6 ± 3.1), spleen (25 ± 3.2) and kidney (20.6 ± 1.8), which are all common metastatic sites for this tumour ( Fig. 1e , right panel) In patients without malignancy, lymph nodes and lung tissue did not show VEGFR1 + clusters ( Fig. 3b , d , insets) In these models, we found reduced cluster formation ( Supplementary Fig. 3a–c ) and metastatic spread three weeks after tumour implantation Individual DsRed-tagged tumour cells, associated with pre-existing BMDC clusters, were visible by day 18 ( Fig. 1b , right middle panel) and progressed to micrometastases by day 23 ( Fig. 1a , b , right panels). β-gal + BMDCs were maintained within well-established tumour metastases ( Fig. 1a , right panel and inset) Intradermal injection of LLC cells resulted in BMDC cluster formation limited to the lung (47.5 ± 2.6 clusters per ×100 objective field) and liver (10.8 ± 1.1) with no clusters in other organs ( Fig. 1e , left panel) Many tumours have a predilection for metastasis to specific organs MCM caused enhanced fibroblast proliferation (data not shown) and fibronectin expression with cluster formation in a wide range of organs, as shown for intestine ( Fig. 6a , b ; Supplementary Fig. 5b ) in comparison to media ( Supplementary Fig. 5b , inset) MCM given before intradermal LLC implantation, and daily thereafter, resulted in the redirection of LLC metastasis from lung to those sites frequently observed in melanoma including kidney, spleen, intestine and oviduct ( Fig. 6e ) MCM increased the number of tumour cells in the lung one day after tumour injection compared with media alone (141.3 ± 10.2 versus 2.7 ± 0.6 tumour cells per section of lung tissue, P 0.01) MCM stimulated fibronectin expression to a greater extent in liver than LCM ( Supplementary Fig. 5b ) Melanoma cells also induced fibronectin expression in the lung in a similar fashion to that of LLC cells ( Supplementary Fig. 3d ) MMP9 was expressed in pre-metastatic clusters, and this upregulation of MMP9 expression may be a result of integrin binding and activation in VEGFR1 + HPCs ( Fig. 5b ) More than 95% of tumour cells co-clustered with GFP + BMDCs (97% ± 1.1; Fig. 1b , right panels) Moreover, blocking either VEGFR1 or VLA-4 inhibits the binding and establishment of the haematopoietic cell clusters and tumour cells Moreover, increased fibronectin expression was notable in multiple tissues exposed to MCM, such as the intestine and oviduct, consistent with the more aggressive metastatic nature of B16 cells (fibronectin expression: P 0.05 days 3–5 and P 0.001 days 7–9 (by ANOVA) in oviducts ( Fig. 6a ) and intestines ( Fig. 6b ) with MCM treatment compared with mice treated with LLC-conditioned media (LCM) or wild-type mice) Much focus has been placed on the role of inflammatory cells in aiding in tumour adherence and invasion into distant organs  No tumour cells were detected by flow cytometry or microscopy earlier than day 16, and increasing numbers of tumour cells were identified over time ( Fig. 1b , right panels; Fig. 1c ; Supplementary Fig. 1a ) Notably, the LLC metastatic lesions were associated with GFP + BMDCs ( Fig. 5d , lower inset) On day 16, established β-gal + cell clusters dictated the contours of future metastatic lesions ( Fig. 1a , right middle panel) On day 40 of life, prominent VEGFR1 + clusters were detected exclusively in the lymph nodes of these animals before the onset of lymphoma (145.1 ± 16.4 clusters per ×100 objective field; Fig. 2d , middle panel and inset), with no observed clusters in wild-type littermates (0.4 ± 0.3, P 0.001; Fig. 2d , left panel) Our data suggest that differences in tumour-secreted humoral factors promote metastatic spread in specific distant organs Our results demonstrate that tumour-specific chemokines and/or cytokines present in conditioned media, along with the VEGFR1 + cellular clusters, are another determinant in the multidimensional programme driving metastatic spread Our results introduce the concept that tumour metastasis is initiated by a well-defined sequence of events dependent on cellular ‘bookmarking’ through site-specific delivery of VEGFR1 + cells to form permissive niches within target organs Previously, we identified haematopoietic progenitor cells (HPCs) expressing VEGFR1 that reside within specified niches of the bone marrow Proteinases including matrix metalloproteinase 9 (MMP9), produced by haematopoietic cells, can serve to break down basement membranes, thus altering the local microenvironments by releasing soluble Kit-ligand and VEGF-A to support newly introduced cells that express c-Kit  Recruited BMDCs consist of haematopoietic progenitors We characterized the cellular and molecular composition of incorporated BMDC clusters Restoration of the pre-metastatic niche and metastasis with the introduction of wild-type VEGFR1 + cells into Id3 knockout mice suggests that the expression of Id3 induces expression of the necessary elements, including MMP9, integrins and possibly chemokines, to provide a road map for the homing of VEGFR1 + cells essential for the establishment of the pre-metastatic niche Similarly, but more rapidly than primary LLC cells, the intraperitoneal injection of LCM generated fibronectin expression, possibly from resident fibroblasts, and BMDC cluster formation ( Supplementary Fig. 5a ) compared with media alone ( Supplementary Fig. 5a , insets) Simultaneously, HPCs exit the bone marrow into the peripheral circulation as previously described  Sites of BMDC clusters are tumour-type specific We examined whether the type of tumour cell dictated BMDC distribution to specific pre-metastatic sites Specific tumour cell types, which express CXCR4, may also migrate in this fashion in response to local chemokine gradients  The interaction of VLA-4 (integrin α 4 β 1 ) with its ligand fibronectin is essential for the migration of haematopoietic cells within the bone marrow and of circulating leukocytes  The lymphoma cells, which surrounded the VEGFR1 + HPCs, did not express VEGFR1 ( Fig. 2d , right panel inset) The pre-metastatic niche, however, is distinct, introducing an undifferentiated state as seen with the VEGFR1 + HPC population The precise cellular and molecular mechanisms that dictate metastasis of a specific tumour to a predetermined metastatic location are not known The SDF-1/CXCR4 chemokine axis participates in homing and retention of HPCs within the bone marrow  The two antibodies combined blocked cluster formation to an extent similar to anti-VEGFR1 therapy; however, we did observe an isolated LLC lesion in the lung of one animal ( Supplementary Fig. 3b , inset) The VEGFR1 + HPCs identified in this study show characteristics common to physiological pathways of inflammation by providing the necessary adhesion molecules, proteinases, chemokines and growth conditions to create a conducive microenvironment for engraftment of tumour cells  There is a degree of maturational heterogeneity, with the myelomonocytic marker CD11b present on certain incorporated cells (data not shown) There were increased cellular clusters in common sites of metastasis before tumour spread, suggesting the potential of this tissue as a future site for metastasis ( Fig. 3 , showing axillary lymph node (21 ± 5 clusters per ×100 objective field), lung (19 ± 4) and gastro-oesophageal junction (25 ± 4)) Therefore, factors provided by the primary tumour induce BMDCs to enter the bloodstream and mobilize to organ-specific pre-metastatic sites, and this migration precedes the arrival of tumour cells Therefore, the aim of this study was to determine the role of VEGFR1 + HPCs in the temporal and functional generation of metastasis These and other tumour-associated cells enhance primary tumour neo-angiogenesis and growth, yet their precise contribution to metastasis is unclear  These clusters, with MMP9 production altering the microenvironment and enhanced expression of SDF-1 creating a chemokine gradient, permit the attraction of tumour cells and their incorporation into the niche, thereby developing a complete metastatic lesion These data suggest that SDF-1 may provide one pathway for attracting CXCR4 + tumour cells to the pre-metastatic niche These findings expand upon previous work demonstrating that VEGFR1-mediated induction of MMP9 directed metastasis to the lungs  These findings further emphasize the functional role of VEGFR1 + BMDCs in the establishment of clusters and metastasis These GFP + cells increased in number, and were joined by DsRed-tagged tumour cells by day 18 ( Fig. 1c , graph and right flow diagram) These myelomonocytic VEGFR1 + cells localize to perivascular sites, thus stabilizing tumour neo-vessels  These results suggest that the VEGFR1 + HPCs initiating the pre-metastatic cluster can attract tumour cells This approach allows for selective targeting of the BMDCs, as the tumour cells do not express either VEGFR1 or VEGFR2 This concept will have a tremendous impact on tumour staging, and may alter the landscape of adjuvant chemotherapy. This is the first direct evidence that a non-neoplastic cell population can portend a future metastatic site Thus bone marrow-derived VEGFR1 + HPCs initiate and maintain the pre-metastatic niche To address whether disruption of VEGFR1 + cellular cluster formation could block the metastasis of well-established tumours, mice inoculated with LLC or B16 tumour cells were treated with monoclonal antibodies against VEGFR1 and/or VEGFR2 To confirm the functional roles of these proteins in establishing the pre-metastatic niche, we either inhibited the expression of VLA-4 (with anti-integrin α4 antibodies) or studied VEGFR1 + cell cluster formation in MMP9 and Id3 knockout mice To formally examine the potential of wild-type VEGFR1 + cells to restore the metastatic defect in Id3 knockout mice, Id3-competent GFP + VEGFR1 + HPCs were injected intravenously into Id3 knockout tumour-bearing mice To further define the timing of tumour cell arrival, a flow cytometric study of the lungs was undertaken Tumour-derived conditioned media dictate metastatic patterns To delineate the mechanism of the organ-specific metastatic potential of LLC and B16 cells, we collected culture-derived conditioned media Using a transwell migration assay, tumour cells manifested enhanced mobility in response to bone marrow-derived VEGFR1 + cells (29.6 ± 1.4 tumour cells per ×200 objective field) as compared to cells that do not express VEGFR1 (11.2 ± 0.4) and media alone (9.9 ± 0.9, P 0.001 by ANOVA; Supplementary Fig. 4b ) VEGFR1 + cells promote tumour adherence and growth To confirm that VEGFR1 + progenitors promote the chemoattraction and attachment of circulating tumour cells, we isolated and red fluorescence-labelled (PKH26-Gl) VEGFR1 + cells from mice with malignancy ( Supplementary Fig. 4 ) VEGFR1 + cellular clusters expressed the haematopoietic progenitor marker c-Kit ( Fig. 3e , f , insets) VEGFR1 + clusters were observed in both primary tumours and metastatic tissue ( Fig. 3 , showing breast carcinoma in an axillary lymph node, lung carcinoma and oesophageal carcinoma) VEGFR1 + HPCs alone re-established cluster formation and micrometastases by day 21 after tumour implantation ( Fig. 5d , and upper inset; Supplementary Fig. 3c ) VEGFR2-positive circulating endothelial progenitor cells migrated to fully formed BMDC clusters ( Supplementary Fig. 1d , right panel), and coincided with the arrival of tumour cells ( Supplementary Fig. 1e , graph) VLA-4, MMP9 and Id3 mediate the pre-metastatic niche We investigated the cellular and molecular mechanisms by which migratory HPCs, through interaction with the microenvironment, form permissive pre-metastatic niches We also found impaired mobilization of VEGFR1 + HPCs into the circulation of Id3 knockout mice compared to wild type (654 versus 3,283 VEGFR1 + CD11b + cells µl -1 ) in response to tumour inoculation ( P 0.01 by Students t -test; Supplementary Table ) We also observed CXCR4 expression in B16 melanoma and LLC tumours ( Supplementary Fig. 4d ) We analysed LCM and MCM for variations in growth factors to account for the distinct metastatic potentials and profiles of LLC and B16 ( Fig. 6c ) We assessed whether VEGFR1 + cells express integrins, which may facilitate the interaction of this cell type with the pre-metastatic niche We found high levels of VEGF in both conditioned media, more than in plasma from tumour-bearing mice ( Supplementary Fig. 5c ) We found that VEGFR1 + HPCs at the pre-metastatic cluster express VLA-4 ( Fig. 5a , and inset showing coexpression with VEGFR1), suggesting that VLA-4 allows for the adhesion of the BMDCs that form the pre-metastatic niche We introduced DsRed-tagged B16 tumour cells intravenously into mice with pre-established GFP + BMDC clusters in the lung after challenge with MCM ( Fig. 1d , right panel) or media alone ( Fig. 1d , left panel) We previously showed that upregulation of Id gene expression is critical for the mobilization of progenitors that aid the growth of primary tumours  We show that inhibition by a VEGFR1 antibody or depletion of VEGFR1 + cells from the bone marrow prevents the formation of pre-metastatic clusters and, therefore, metastases Within days following tumour implantation, fibronectin becomes upregulated in certain locations by resident fibroblast and fibroblast-like cells within target organs that are conventional sites of metastasis, corresponding to the particular primary tumour Within one hour of in vitro co-incubation with green fluorescence-labelled (PKH2-GL) B16 or LLC cells, the HPCs aggregated, proliferated (150% increase) and promoted the attachment and proliferation of the tumour cells Within the fully formed pre-metastatic cluster containing VEGFR1 + cells, fibroblasts and fibronectin ( Fig. 1a , left middle panel), SDF-1 (also known as CXCL12) became highly expressed ( Supplementary Fig. 4c )
 Bever and Wang suggest that our data can be explained equally well by heterokaryosis, proposing a model that relies on the assumption that fusions of hyphae of genetically non-identical individuals contribute to the creation and maintenance of a multigenomic status of AM fungal cells However, we do not believe that this assumption is supported by existing biological evidence. Pawlowska and Taylor reply - To challenge the hypothesis of multigenomic structure of arbuscular mycorrhizal (AM) fungi , we presented three lines of evidence consistent with the homokaryotic organization of within-individual genetic variation, including distribution of polymorphic genetic markers among and within field isolates of an AM fungus, and distribution of ribosomal DNA variants among individually microdissected nuclei  A recent, considerably smaller genome-size estimate in G. intraradices indicates that the sizes of glomeromycotan genomes may not differ markedly from those in other fungi  Bever and Wang cite this estimate as support for heterokaryosis in AM fungi Bever and Wang contest our evidence of the containment of the entire intrasporal rDNA variation in each individually microdissected nucleus, which they claim is not definitive as the nuclei could still vary in the number of copies of each of the rDNA types But Bever and Wangs formula for heterokaryon formation and maintenance requires fusions of hyphae among genetically distinct mycelia Encounters among non-identical vegetative mycelia initiate a battery of antagonistic responses However, even very small fungal genomes contain arrays of duplicated genes, including rRNA-coding and protein-coding genes  However, the quantitative issue of copy number is not relevant to a qualitative distinction between heterokaryosis and homokaryosis In our simulation model of heterokaryosis , we therefore explicitly excluded the possibility that vegetative hyphal fusions among genetically differentiated individuals could contribute to the creation and maintenance of multigenomic individuals of AM fungi In the vegetative mode, genetic compatibility at several loci is required for a successful fusion, which effectively limits fusions of hyphae to those within an individual mycelium or among genetically identical mycelia derived from the same isolate  On the basis of our results and of reports of exceptionally large genome sizes in AM fungi , we speculated that these fungi may have duplicated or polyploid genomes Several studies of self versus non-self recognition in fungi have revealed sophisticated mechanisms that prevent fusion of genetically differentiated individuals unless the partners are in the sexual mode, which has never been observed in Glomerales Such vegetative incompatibility responses have also been reported in AM fungi during encounters between genetically differentiated isolates of Glomus mosseae , indicating that AM fungi have self-recognition mechanisms that are equally sophisticated and operate like those in other fungi The model of heterokaryosis proposed for AM fungi , which we tested by using data from microdissection, made no claims about the number of copies of different rDNA types, but stipulated that different rDNA sequences should be distributed among different nuclei within an individual; we found no evidence to support this idea The nucleolar organizer regions, which harbour tandemly repeated rRNA gene copies, are dynamic, and the number of rRNA genes may change even during the lifespan of a single cell  Thus, the evidence of small haploid genomes in AM fungi does not invalidate our conclusion that the intracellular genetic variation observed in these fungi is contained in each of the hundreds of nuclei that populate their cells and spores. To support their idea of hyphal fusion in AM fungi, Bever and Wang cite studies that present data on successful fusions among hyphae only within an individual mycelium and among mycelia derived from spores representing the same isolate — the studies contain no results that support fusions of genetically different individuals
 Nature 437 , 369 – 375 ( 2005 ) Mislabelling of a histological section caused the wrong micrograph of a wild-type control to be inserted in Fig. 5b (bottom panel, middle column) of this Article: as published, this is identical to the control bone picture shown in Fig. 3c (top left panel) The mix-up with the control figure does not affect the validity of the data or our original conclusions. The panel that should have been shown in Fig. 5b (see below) is from the Rag2 -mutant mouse; the figure legend remains the same
 A deal struck last month between Monsantos two fiercest rivals will, they hope, presage a second era characterized by a more even spread of market share and the production of multiple traits ‘stacked’ into single plants About one-third of Americas $2.8-billion corn-seed market is supplied through independent companies, and Monsanto has scored major success by licensing its transgenic technology to them But perhaps the most significant development is the increasing spread of multi-trait crops Clive James, a prominent plant scientist and chair of the ISAAA, predicts that the total planted area of GM crops will grow from 90 million hectares this year to at least 200 million hectares in ten years time GM seed now produces about 60% of the worlds soya beans and 16% of its corn GreenLeaf will make multiple traits available to seed companies, says Wulfkuhle GreenLeafs challenge is to break this dominance If transgenic rice takes off in Asia, he suggests, that alone could add 250 million hectares or more It also sells direct and licenses genes to rivals, including Pioneer — with the result that up to four-fifths of all transgenic corn and soya beans contain Monsanto traits Its initial emphasis will be on corn for North America, which accounts for more than half of the total area of genetically modified (GM) crops planted worldwide, according to the ISAAA, a Philippines-based organization that promotes the technology in developing countries James also expects to see the commercial arrival of traits that are more useful to farmers in poor countries Monsanto, based in St Louis, Missouri, still dominates the sector — but that could be about to change Most of these seeds currently have two traits, although future plants could incorporate resistance to weedkillers and to drought with insecticides, for example, and with specific nutritional benefits One such trait will be higher-yield herbicide resistance based on Pioneers Optimum GAT technology, which makes plants resistant to the weedkiller glyphosate and will be ready in 2009 Plant strains with stacked traits will follow as new traits become available over the next few years. “GreenLeaf will allow us to present a broader suite of products,” says Pioneers president, Dean Oestreich Syngenta, based in Basel, Switzerland, and Pioneer Hi-Bred of Des Moine, Iowa — a subsidiary of DuPont — last month formed a 50–50 venture which, they believe, will give Monsanto a run for its money That would answer critics who say early traits only addressed the demands of the worlds richer farmers. The agricultural biotechnology industry is ten years old, and the story of its first decade has largely been about one company selling crops with single transgenic traits The approach is a change of direction for Pioneer, the worlds oldest and largest seed company, which until now has sought to sell its transgenic seed directly to farmers The technology has yet to make substantial inroads in wheat or rice and, although genetic modification has spread rapidly (see graph), consumer resistance has held it back in places The venture, GreenLeaf Genetics, is based in Omaha, Nebraska, and plans to license traits from both Syngenta and Pioneer to the host of small, long-established local companies that supply many farmers with corn (maize) and soya-bean seeds. “For the farmer, this means hell be able to get the benefit of technology from both of these companies from his local seed company,” says Ron Wulfkuhle, GreenLeafs president There is no cultivation of GM crops in Japan or Britain, very little in the rest of Europe, and the only transgenic crop grown in China is cotton
 Consistent with previous reports , we observe that the Ran system also affects spindle pole formation and chromosome congression in vivo  Here we examine the Ran–importin-β system in cells by conventional and fluorescence lifetime microscopy using a biosensor, termed Rango, that increases its fluorescence resonance energy transfer signal when released from importin-β by RanGTP However, the existence and function of a RanGTP gradient during mitosis in cells is unclear In cells, the Ran–importin-β–cargo gradient kinetically promotes spindle formation but is largely dispensable once the spindle has been established In vitro experiments and modelling show that this localized increase of free cargoes corresponds to changes in RanGTP concentration sufficient to stabilize microtubules in extracts Our results demonstrate that conserved Ran-regulated pathways are involved in multiple, parallel processes required for spindle function, but that their relative contribution differs in chromatin- versus centrosome/kinetochore-driven spindle assembly systems. Rango is predominantly free in mitotic cells, but is further liberated around mitotic chromatin The common principle underlying these diverse functions throughout the cell cycle is thought to be anisotropy of the distribution of RanGTP (the RanGTP gradient), driven by the chromatin-associated guanine nucleotide exchange factor RCC1 (refs 1 , 4 , 5 ) The RanGTPase cycle provides directionality to nucleocytoplasmic transport, regulating interactions between cargoes and nuclear transport receptors of the importin-β family  The Ran–importin-β system also functions in mitotic spindle assembly and nuclear pore and nuclear envelope formation  Additional details are given in the Supplementary Methods  Additional details are provided in the Supplementary Methods  Cell culture and transfection BHK21 cells and HeLa cells were purchased from ATCC. tsBN2 cells were a gift of T Cells were maintained in Opti-MEM ( Gibco, Invitrogen ) with 4% fetal bovine serum at 37 °C, 5% CO 2 , except for tsBN2 cells, which were kept at 33 °C, 5% CO 2  Confocal microscopy was performed with a Zeiss LSM 510 META laser scanning confocal microscope Dasso Details are given in the Supplementary Methods  Details are given in the Supplementary Methods  Details are given in the Supplementary Methods  Fluorescence lifetime and confocal microscopy Data sets of spatially resolved, time-correlated single photon counting (TCSPC) were acquired on an inverted Zeiss LSM510 Axiovert 200M microscope equipped with a TCSPC controller ( Becker Hickl SPC-730 ) For cell transfection, Fugene 6 ( Roche Diagnostics ) was used according to the manufacturers protocol Fractional occupancy of Rango titrated with importin-β Rango–importin-β fractional occupancy ( Fig. 1c ) was calculated as follows: K d = βC / C βC K d = ( β T - C βC )( C T - C βC )/ C βC where C βC is the concentration of the importin-β–cargo complex (fractional occupancy), β is the concentration of free importin-β, β T is the total concentration of importin-β, C is the concentration of free importin-β cargo, C T is the total concentration of importin-β cargo and K d is the dissociation constant, resulting in C βC = 0.5( C T + β T + K d –  ( C T + β T + K d ) 2 –4 β T C T )  Live cell epifluorescence imaging Live cell epifluorescence ratio imaging was performed with a Nikon E600 microscope equipped with a Hamamatsu C4742-98 CCD camera as described previously  Methods Cloning and protein expression A description of all the clones used in this study and details of protein expression are given in the Supplementary Methods  Microinjection and immunofluorescence Cells were microinjected using an Olympus IX71 microscope equipped with a FemtoJet microinjector ( Eppendorf ), and analysed by immunofluorescence to visualize microtubules and DNA using an Olympus BX51 microscope equipped with a Hamamatsu CA 742-98 CCD camera  Nishimoto and M Spectrophotometry Emission spectra were analysed with a Fluorolog 2 spectrofluorimeter controlled by Datamax 2.2 ( Jobin Yvon Spex ) and the Grams 3.04 II software package ( Galactic Industries ) Statistical analyses Statistical analyses were performed with Excel ( Microsoft ) and with GraphPad Prism version 4.00 for Windows, GraphPad Software ( http://www.graphpad.com ). Xenopus laevis egg extracts Assays for the detection of the Rango I FRET / I CFP signal during mitotic spindle assembly in X. laevis egg extracts were performed as described previously with rhodamine-tubulin and 2 µM Rango in the extract instead of YIC A further increase in RanGTP (2–5 µM Ran(Q69L)) induced formation of relatively large microtubule asters, whereas even higher concentrations (10–30 µM Ran(Q69L)) induced formation of structures with shorter radiating microtubules and more focused centres ( Fig. 3d ) Alternatively, reactions induced by high RanGTP concentrations in the cytoplasmic extracts may mimic conditions of limited diffusion (for example, at the chromatin–cytoplasm interface) Although the FRET values varied considerably between cells (see Supplementary Fig Although the gradient in the Xenopus extract dropped over a greater distance, and was thus significantly less steep than in HeLa cells (3–4 µm), in both systems it reached to the spindle poles (indicated by asterisks in Fig. 3a , b ) As expected, the Rango FRET signal decreased with an increase in its fractional occupancy by importin-β, and the average τ  donor increased from 2.35 ns to 2.85 ns at 23 °C, and from 2.08 ns to 2.60 ns at 30 °C ( Fig. 1c ) As the decrease of the quantum yield due to FRET is accurately reported by a decrease of the donor lifetime ( τ  donor ), FLIM offers a concentration- and cross-bleed-independent FRET detection method that can be used to quantify molecule interactions in vitro and in living cells  At the same time, we measured changes in the fluorescence lifetime of the Rango cerulean donor using fluorescence lifetime imaging microscopy (FLIM; Fig. 1c ) Elevated levels of free Rango were observed in Xenopus extract spindles in an area extending 15–20 µm from the chromatin ( Fig. 4a ), as seen previously with an importin-α1-based importin-β sensor (YIC)  Furthermore, these data suggest that the Ran–importin-β system is poised to respond to small increases in RanGTP concentration from the physiological set point found in the mitotic cytoplasm to regulate microtubule dynamics and organization Furthermore, they demonstrate the presence of a significant RanGTP-regulated free cargo gradient extending from mitotic chromatin Furthermore, variations in the cargo dissociation constant (in a range between 0.5 and 50 nM) are expected to have only very minor effects on the importin-β occupancy in the mitotic cytoplasm ( Supplementary Fig However, in contrast to the situation for extracts, once a bipolar spindle is established in cells, the RanGTP gradient and the Ran–importin-β cargo regulation appears to be largely dispensable for spindle integrity However, it agrees qualitatively with computer simulations of a minimal Ran system that have been used to calculate free RanGTP concentrations and with our attempts to model importin-β–cargo interactions in cells or extracts ( Fig. 3c ; see also Supplementary Fig However, microinjection of low concentrations of wheat germ agglutinin (WGA) partially blocked nuclear transport, causing some Rango to be retained in the cytoplasm, where it displayed lower FRET levels indicative of importin-β binding ( Fig. 1e ) However, spindles remained intact when metaphase cells were injected with importin-β 71–876 , a potent dominant-negative inhibitor of chromatin-induced microtubule dynamics and spindle assembly in Xenopus extracts  However, when the RanGTP concentration was increased by the addition of 1 µM Ran(Q69L), decreasing Rango occupancy by 8 ± 5% ( N = 5), bundled microtubules formed In all mitotic HeLa cells in which a gradient could be recorded (36 out of 46 cells; Supplementary Fig In contrast to a sensor based on the IBB of importin-α1 (ref. 11 ), Rango displayed little toxicity in somatic cells and did not affect cell cycle progression (data not shown) In extracts prepared from human HeLa cells, the Rango probe also dynamically reported on the levels of importin-β binding and RanGTP-mediated cargo release ( Supplementary Fig In the absence of exogenous Ran and importin-β, only 52 ± 5% ( N = 5) of Rango was bound to importin-β, and yet the high fraction of free cargoes in the extract did not promote microtubule polymerization ( Fig. 3d ) Instead, the most prominent phenotype induced by injection of either importin-β 71–876 or importin-α1 66–529 in early mitosis was a delay at the prometaphase to metaphase transition, frequently associated with monoastral microtubule arrays ( Fig. 4d , e ; see also Supplementary Fig Introduction of the Ran-insensitive importin-β 71–876 caused the Rango probe to localize to both the cytoplasm and the nucleus, and the average τ  donor throughout the cell increased to 2.51 ± 0.05 ns ( N = 7), similar to the lifetime of a FRET-deficient cerulean control protein (2.59 ± 0.05 ns, N = 15), indicating that the increase in Rango sensor lifetime reflected a loss of FRET due to importin-β binding ( Fig. 1d ; see also Supplementary Fig Microinjection of Ran(Q69L) induced the formation of ectopic microtubule asters in the cytoplasm of some cells ( Fig. 4b , arrows; see also Supplementary Fig Notably, in addition to a delay in prometaphase, injection of full-length importin-β also induced split spindle poles ( Fig. 4c ; see also Supplementary Table 1 ), consistent with a model that Ran and importin-β may function in the regulation of centrosomes  Notably, in both HeLa cells and Xenopus egg extracts, the steepness of the Ran-regulated gradient seems to be adjusted to the enormous differences in the spindle size ( Fig. 3a , b ) On the basis of our results, we propose that the mitotic cytoplasm operates near a physiological threshold in which positive and negative regulators are at equilibrium Our results suggest that the RanGTP gradient provides a significant kinetic advantage during the early stages of spindle assembly in primarily centrosome-driven somatic cells Rango contains the importin-β-binding domain (IBB) of human snurportin 1 (ref. 9 ) flanked by yellow fluorescent protein (EYFP) at the amino terminus and cerulean CFP at the carboxy terminus Rango introduced into cells by either transient expression or microinjection was efficiently imported into nuclei, where the average τ  donor was 2.21 ± 0.07 ns (mean ± s.d., N = 10), indicating that nuclear Rango was almost exclusively free ( Fig. 1d ) Rango localized throughout the cytoplasm and was largely excluded from mitotic chromosomes ( Fig. 2a ) Rhodamine-tubulin was used to label microtubules in both cases ( Fig. 3a ) S1 ) S2 ) S3 ) S4 ), confirming our FLIM analysis S5 ), the average difference of τ  donor between chromatin and mitotic cytoplasm was 0.08 ± 0.03 ns, corresponding to a 13 ± 5% decrease in Rango–importin-β binding around chromatin S5 ), we detected a region of significantly higher FRET (shorter τ  donor ) surrounding the chromatin ( τ  donor = 2.21 ± 0.06 ns ( N = 36), corresponding to a Rango–importin-β occupancy of 18 ± 9%) and the FRET signal gradually decreased towards the cell periphery ( τ  donor = 2.29 ± 0.07 ns, 31 ± 12% occupancy; Fig. 2 ) S8 ) S8 and data not shown) S9 and Supplementary Table 1 )  extracts ( Fig. 3d ) Such a system would be poised to break the threshold in response to small local changes in RanGTP concentration and, for example, influence microtubule stability around chromatin in prophase cells The dimensions of the cargo gradient were analysed by linescan analysis ( Fig. 3b , Methods) The existence of significant concentrations of free importin-β cargoes throughout the mitotic cytoplasm is inconsistent with simple models that propose complete binding and inhibition of importin-β-regulated activities in the mitotic cytoplasm  The induction of large monoastral microtubule structures indicates that the normal progression from a radial to bipolar microtubule arrangement during prophase requires an intact cargo gradient in cells The observed gradient did not result from concentration-induced errors in our FLIM measurements, as a modified version of Rango (k-Rango)—which was fused to the DNA-binding domain of the human centromere protein CENP-B —displayed a similar FLIM profile despite a very different localization pattern ( Fig. 2a , b ) The ratio of I FRET to I CFP decreased significantly in the presence of importin-β, and this effect was completely reversed by RanGTP, which induced the dissociation of Rango from importin-β ( Fig. 1b ) The strong nuclear accumulation of Rango prevented us from analysing its behaviour in the interphase cytoplasm under normal conditions These results show that the cargo liberation observed around mitotic HeLa chromosomes is quantitatively similar to the increase in free cargoes sufficient to stimulate microtubule polymerization in extracts These results were also qualitatively confirmed by acceptor photobleaching experiments ( Supplementary Figs S6 and S7 ) This behaviour may allow the Ran–importin-β pathway to locally regulate its targets and to signal both chromatin- and centrosome-driven events in mitosis. This conclusion is consistent with modelling studies and suggests that Ran-gradient-regulated stabilization of microtubules around chromatin supports a search and capture mechanism of microtubule–kinetochore attachment This indicates that in cells, mitotic spindles are built and maintained by multiple, parallel pathways, and demonstrates that centrosome/kinetochore- and chromatin-driven systems differentially use Ran and importin-β to promote mitotic spindle assembly This organization permits relative differences in cargo occupancy to influence events between the spindle poles and chromatin in both systems This result implies the existence of a class of activity for which regulation in the extracts requires a much higher RanGTP concentration than does a Rango-like cargo Thus, our FRET analyses indicate that at equilibrium, high RanGTP concentrations and/or limited importin-β cargo-binding sites exist in the mitotic cytoplasm Thus, Rango enables the RanGTP-dependent disassembly of importin-β–cargo complexes in the nucleus of interphase cells to be visualized To assess directly the functional significance of the Ran–importin-β system during mitosis in somatic cells, we microinjected a panel of dominant-negative proteins to inhibit the Rango gradient in HeLa cells in either prophase or metaphase To compare embryonic and somatic systems under identical detection conditions, we acquired epifluorescence ratio images in metaphase Xenopus egg extracts containing Rango and in HeLa cells microinjected with Rango To investigate whether the observed increase in Ran-regulated cargo liberation around chromatin might regulate microtubule dynamics in mitosis, we performed titration experiments with RanGTP and importin-β in Xenopus egg extracts, monitoring, in parallel, the interaction of Rango with importin-β and changes in microtubule morphology ( Fig. 3c , d ) To measure quantitative differences in Rango binding to importin-β during mitosis, FLIM data were recorded in mitotic HeLa cells transfected with Rango, and Rangos fractional occupancy was estimated based on our in vitro calibration data ( Fig. 1c ) To quantify the importin-β–cargo interaction using Rango, we measured I FRET / I CFP ratio changes in a spectrofluorimeter upon addition of increasing concentrations of importin-β, and plotted the calculated fractional occupancy of the sensor based on Rangos experimentally determined apparent dissociation constant for importin-β of 2 nM ( Fig. 1c ; see also Supplementary Fig To visualize the spatial distribution of the Ran system in living cells, we developed a fluorescence resonance energy transfer (FRET) biosensor termed Rango (Ran-regulated importin-β cargo) that increases its FRET signal when liberated from importin-β by RanGTP ( Fig. 1a ) Upon excitation at 435 nm, Rango exhibited higher emission intensity at the YFP acceptor peak ( I FRET at 525 nm) than at the CFP donor wavelength ( I CFP at 474 nm), indicative of FRET ( Fig. 1b ) We also performed acceptor bleach experiments using confocal laser scanning microscopy that showed that Rango is mostly free in the nucleus ( Supplementary Fig Whereas the Rango FRET signal plateaued at 10 µM of added Ran(Q69L), the number of microtubule asters more than doubled with further increases of Ran(Q69L) to 15–30 µM
 Active SREPB is liberated from its membrane anchor by cleavage, and it is this cleavage that is controlled by sterol levels Although SREBP resides in the ER membrane, the two protein-cleaving enzymes that liberate the active fragment occur in another compartment, the Golgi Although we dont know what signal regulates Scp1-mediated cleavage of Sre1, it is reasonable to suppose that it is a sterol — perhaps ergosterol (the end result of the sterol pathway in S. pombe ), but possibly some other sterol generated in the pathway, or a derivative of one of the pathway molecules And perhaps a second oxygen-dependent signal works together with sterols to regulate Sre1 cleavage But the surprises came when Espenshade and colleagues explored the molecular details of the S. pombe feedback pathway But the underlying mechanism for this is quite unexpected Cholesterol-bound SCAP no longer exits the ER, and so cholesterol inhibits production of active SREBP ( Fig. 1a ), thereby governing its own synthesis Consistent with this, loss of either Scp1 or Sre1 through mutation had no effect on the growth of S. pombe , whereas in mammals loss of the SREPB pathway renders cells totally dependent on added sterols Finally, the cleavage of Sre1 is massively stimulated by lowering the oxygen concentration, indicating that the relevant perturbation indeed causes the proposed physiological response First, S. pombe cells that lack Sre1 or Scp1 cannot survive in anaerobic conditions Freshly made, full-length SREPB is anchored in the membrane of a cellular compartment called the endoplasmic reticulum (ER) — tethered like a pit bull on a chain, and unable to reach its targets in the nucleus Furthermore, the presence of Sre1 and Scp1 enables the cells to adapt to low-oxygen conditions in ways that would be predicted if these proteins were involved in oxygen sensing — for instance by increasing the cells capacity for the oxygen-dependent reactions of ergosterol synthesis Genes regulated by Sre1 include those encoding: enzymes in the late, oxygen-dependent parts of the sterol-synthesis pathway; enzymes required for the biosynthesis of haem (an oxygen-binding molecule); and several other oxygen-related factors, including some that are needed for yeast cells to survive low oxygen levels Genome sequencing studies show that Schizosaccharomyces pombe (fission yeast) also has versions of SREBP and SCAP, called Sre1 and Scp1, respectively Given that this fungal species synthesizes cholesterols cousin ergosterol, this is perhaps to be expected However, the transcriptional targets of Sre1 are quite distinct Instead, Espenshade and colleagues analysis indicated that the relevant regulatory function pertains to oxygen Is this a broadly used mode of oxygen sensing in nature? Does it occur in many fungi, and thus provide an Achilles heel that can be exploited to develop new antifungal drugs? What is the range of molecules sensed by the many SCAP counterparts found in nature? The emerging picture is that these membrane proteins may be widely used sensors of intramembrane signals that affect any aspect of biology in which lipid molecules are involved. Over the past few years, a molecular drama has been unfolding in our understanding of how cholesterol synthesis is regulated in mammals Perhaps the only unsurprising feature of this transcriptional regulation is that it centres on a transcription-factor protein: SREBP (for ‘sterol-regulatory-element-binding protein’) SCAP also has a membrane-embedded motif that directly binds cholesterol SCAP binds to SREBP and carries it out of the ER by entering the vesicular pathway that shuttles between the ER and the Golgi Synthesis of sterols is absolutely dependent on oxygen Testing of candidate genes, combined with microarray techniques to analyse gene expression more broadly, showed that the early, rate-limiting reactions of sterol synthesis — those regulated by mammalian SREBP — were completely unaffected by changing levels of active Sre1 Thanks to heroic work led by Brown and Goldstein , we now have a clear idea of how cholesterol-regulated gene transcription occurs The authors found that Sre1 is cleaved to a soluble form and that this cleavage is regulated by sterol in an Scp1-dependent manner, just as in mammals The authors go on to show that several predictions of their oxygen-sensing model are borne out The mechanism uses an evolutionarily conserved and medically relevant pathway for sterol regulation in an unexpected way The overarching idea is simple: when cells need more cholesterol, they increase the levels of enzymes that make it, by increasing the expression of the enzyme-encoding genes The SREBP molecule contains a portion that carries out transcription (‘TF’ in Fig. 1a ), connected to a transmembrane domain There seems to be great flexibility in the kinds of molecules that can be sensed by the sterol-sensing motif found in SCAP and related proteins , so it may be best to await the next chapter in this new use of the SREPB pathway These mutant cells do survive, however, if allowed to express the cleaved form of Sre1 (the ‘TF’) by molecular-biological trickery This ground-breaking study raises some fascinating questions This ‘traffic control’ is effected by the protein SCAP (for ‘SREBP-cleavage-activating protein’) Thus, it seems that sterol-regulated cleavage of Sre1 is used to signal oxygen availability ( Fig. 1b ) Thus, the choice of sterol synthesis as a fiduciary indicator of oxygen levels is a good one, and one that probably exists in more than one yeast species Whatever the specific signals, this ‘rewiring’ of the SREBP pathway makes a lovely kind of sense When sterol levels are high, the movement of SREBP to the Golgi (and hence cleavage) is blocked When sterol levels are sufficiently low, SREPB is carried from the ER to the Golgi, where cleavage — and thus activation — occurs Writing in Cell , Espenshade and colleagues describe a previously unknown strategy by which cells sense oxygen levels
 A new report proposes that enabling local communities to manage natural resources is the key to tackling poverty But Lash fears his plans may have been derailed by US ambassador John Bolton, who has requested revisions that could water the goals down. But the report includes few such successes. “If you tried to find 50 more you couldnt,” says Lash During the past decade, for example, communities in Fiji have reversed a decline in marine catches by confining fishing to restricted areas If ecosystem services are not taken into account, he says, aid agencies go on supporting such schemes as fisheries that raise incomes in the short term but reduce community resources as fish stocks shrink In KwaZulu-Natal, South Africa, for example, scientists helped local women design experiments to assess the ecological impact of different clam-harvesting strategies. “The point is for scientists to help communities gather the information they need to manage their marine resources better, rather than telling them what to do,” says Bill Aalbersberg, an applied ecologist at the University of the South Pacific in Fiji, who helped communities monitor the impact of no-catch zones In northern Tanzania, land reforms helped villagers band together to succeed where overseas agencies had failed, reforesting around 3,500 square kilometres of badly degraded land that now provides fuel and food In response, development experts are calling for a more scientific approach to deciding how aid money should be spent It follows a global environmental survey that concluded, in March, that ecosystems around the world are in decline and will continue to be so unless their value is factored into financial thinking (see Nature 434 , 547 ; 2005 10.1038/434547a ) It says it is working with environmental organizations such as the WWF to ensure that the work it supports involves local stewardship of natural resources Lash hopes that the report will influence the UNs Millennium Development Goals, a set of targets agreed in 2000 Marine and agricultural resources around the world are being depleted as small-scale farmers struggle to feed their families. “Development strategies represent the priorities of capital cities and finance ministers,” says Jonathan Lash, president of the World Resources Institute in Washington DC, the environmental think-tank that wrote the report Most people who have trained in economics are not trained in science.”  Scientific input, say the few researchers who have taken part, can help people see if changes are working and test out future options One solution, suggests the report, is for development agencies to focus on wealth created when people work together to manage local ecosystems Organizations such as the World Bank do not consider the ‘ecosystem services’ that underpin the successful case studies, he says. “Thats a correct and important point,” says Jeffrey Sachs, director of the Earth Institute at Columbia University in New York Sachs adds that development agencies fail to involve researchers in schemes that focus on ecosystem services. “There is lots of good science available, but very little is tapped for public policy,” he says. “We have two cultures Some development agencies say they are taking the message on board Support is growing for the idea of linking aid with environmental protection The goals, which have been criticized for treating poverty and the environment as separate issues, are to be discussed in New York next week The UK Department for International Development, for example, last year appointed a chief science adviser and announced plans to increase its research budget by more than £50 million (US$90 million) to £135 million in 2007 The Wealth of the Poor , backed by the United Nations (UN) and the World Bank, says that governments have ignored the 750 million rural people who make up three-quarters of the poor, and that development in areas such as China and India has largely bypassed rural areas
 A clichéd alcoholic A drop from Mishimas seppuku A micro siren wailed. “Game-playing is forbidden in the museum,” a quiet digitalized voice declared. “Cease activity A single strand of hair with its root intact A smile played on her lips. “Whaddya got?” Leo Yoshida slurred A splatter of Hemingway All those writers who had left pieces of themselves And by the time they did, theyd be well into their second season with a whole new cast And Emily had been an odd creature, practically autistic And not only writers! The second season could be tortured artists Archives and special collections Because what she had taken was organic Branwell could be turned into a female But Branwell Brontë! Hed had been a second-rate artist Desperation seeped from her second-best suit Dimly, she wondered how shed been capable of this act ETF in six months.”  “I cant believe theyre still legal out there! Theyve lost their licence in Asia Major and Australasia,” Leo spluttered. “Tried and true,” Mercury wrinkled her nose. “You know their motto. ‘No one need ever outlive their pet again!’ Listen, Ive sent across the specs already Filled with papers with pieces of skin, hair, even blood Find four more writers to make this show work Frida Kahlo Guess who?”  “Shakespeare? Uhhh, the Crime and Punishment guy? I dunno.”  “Is your barrier secure, Leo?”  “You know Im always clean,” he leered. “My old man made us split up because of the merger, but Ive always had a soft spot for you.”  Mercury rolled her eyes, but she couldnt stop smiling He must have turned off his sim program. “Whats your estimated time of fruition?”  “Ive rented an off-Net portable speed-Queen Her thudding heart His companion, a young woman with jewel lights in her scalp, tried to hop out the patterns of their game, but she stumbled. “Miss, again!” the young man gloated How will I find the other nostalgia writers?” Leo moaned. “Include me as a consultant I can groom her as a novelty personality.”  “No! Ill have a contract for you in a few minutes I took a hair from a mourning brooch at their shrine in Yorkshire.”  “Whose facilities are you using?” Leo asked, suddenly all business Ideas are my forte,” Mercury bared her teeth If she kept her wits shed leave this mausoleum unnoticed and be on a life trajectory far beyond the stunning boredom of an under-published literary historian Image and sound were not to grade, but Mercury was certain her ex was in the middle of a sim-high It could fly It wasnt too late to introduce hormone therapy It would be the biggest credit-making artistic freak show in the history of entertainment. “Ive sent the contract!” Leos eyes shone. “Merc, Merc, what can I have delivered so you can start celebrating now?”  “Mmmm,” Mercury closed her eyes Ive already begun ripening the perfect candidate Mercury Lam Meinharts thudding heart almost burst through her chest Mercury smiled Mercury tapped her finger against her lips Mmmmmm More tortured No need to throw out the clone with the amniotic fluid No one would notice a thing Non-compliance will result in loss of leisure credits.”  “Delete!” the young woman cursed. “This was a requirement for Victorian Lit. class!”  “Come on,” the young man mumbled. “We can go on a sim-tour instead.”  As Mercury turned around, her heart slowly began beating again Nostalgia angle Oh so heady... “Ive always wondered what hydroponic oysters tasted like.”  There was no denying it One of the sisters Otherwise, Im walking with my Brontë She could see her credit ratings breaking through the ‘class-free’ barrier. “Brontë,” she whispered. “I got a Brontë!”  “Whozat?” Leo asked. “Gates!” Mercury swore. “Didnt you attend Required Lit. lectures? Im cloning Charlotte or Emily Brontë She couldnt risk going to Yorkshire to steal another piece of their lives She loved oysters. The Brontë was a male. “Gates! Gates!” Mercury swept the data from her desk The copies still werent exact replicas and the technique hadnt eradicated every dysregulation, but a few abnormal traits would only make the artists more interesting The soft noise of her polyform shoes Their ‘development’ could be broadcast on the Nets and betting pools could be arranged Theres no way for them to detect the theft, she reminded herself They could be groomed in special holo environs to replicate their original circumstances This was what it felt like to ‘have the splice of life’ To be free from eating Soygen 3 for perpetuity! This thought alone brought tears of joy to her eyes Treasure hordes, they were Van Gogh Were ripe for it here, Merc Werent the mandatory gene tweaks meant to eliminate all abhorrent behaviour? “Miss —”  Mercury felt faint. “Miss, Miss!”  Mercury, partially digested Soygen rising in her gorge, turned around. “Ha-haaaa!” a young man crowed What time was it in Hong Kong? She was sure Leo didnt care. “Remember my pitch? A reality show, but high art?”  “Oh, yah You always had good ideas.”  “More than an idea You have five minutes to exit the facility
 Also, scaling theory for planetary turbulence And I worked with Jonathan Aurnou at the University of California, Los Angeles, on scaling issues First Author When we look at the giant planets through an optical telescope, they seem to be solid masses Heimpel takes time away from his modelling to explain the idea to Nature  Hes a physicist at the Max Planck Institute for Solar System Research in Katlenburg-Lindau, Germany How did you manage to scale the model up? A good computing system and better code How do you feel about the model now? It seems kind of nice that you can reproduce some of the main features of the planets. How does this build on earlier work? There have been previous models trying to relate how surface flow relates to the deep interior I had some ideas on how to set up the models parameters In fact, they feature a huge amount of movement — from winds on the surface to magnetic forces emanating from the deep interior Moritz Heimpel, a physicist at the University of Alberta in Canada, has a long-standing interest in these planetary dynamics On page 193 , he uses a computer model to describe how the winds that form the distinctive bands on Jupiters surface are powered by forces from within the planet That seems like an impossible task The giant planets provide a natural laboratory for the fluid dynamics of other planetary bodies Then you try to scale that up to planetary size These worked well for Jupiters equator This model has to do with explaining how those bands come about and why they are stable We cant directly see whats going on in Earths core, but if you look at the giant planets, such as Jupiter or Saturn, you can see the fluid dynamics occurring right on the surface What hasnt been done before is to model how the multiple high-latitude jets come about What was the challenge in capturing that phenomenon? When you think about fluid dynamics on a small scale, you think about things like a creek with little whorls of current What were the individual contributions from the team members? Johannes Wicht developed the computer code Why Jupiter? Im interested in the core of Earth and how it generates a magnetic field Why this particular problem? You can look at Jupiter with your telescope and see the bands
 Golden touch Isaac Newtons long-lost notes on alchemy have been found — but scholars are struggling to turn the written code into something they can read Hard to swallow A study finds that processed duck meat exported from China to Japan in 2003 contained bird flu virus, giving rise to fears that it could be a threat to human health. Making a splash as the largest freshwater fish on record, conservationists were keen for the behemoth to be set free Now it is the comets turn to be afraid.”  UCL space researcher Andrew Coates gets a little carried away describing NASAs Deep Impact mission, in which a probe crashed into the Tempel 1 comet (see News in brief ). “The guidance offered in this article on how to anticipate, model and minimize a botulinum toxin attack can be valuable for biodefence.”  Bruce Alberts, president of the US National Academy of Sciences, justifies publishing a paper modelling a bioterrorist attack with botulinum toxin. “If something bad happens as a result of this, its the Department of Health and Human Services who will have to deal with it, not the academy.”  US health department spokesman Marc Wolfson explains the agencys objections to the botulinum paper On the Record “We used to be afraid of comets Sadly, it had already cashed its chips — cooked and eaten by its proud captors Scorecard Poisson distribution Thai fishermen have landed a whopper: a giant catfish tipping the scales at 293 kilograms The dinosaurs should have been afraid of comets
 Appropriately for something introduced at the dawn of quantum mechanics, the fine-structure constant is denoted by the Greek letter alpha (α) But if the expected improvements in the atomic approach materialize, the electron g −2 will be freed to check out new physics But the cunning of the α hunters justifies cautious optimism. But this emerging sensitivity to physics beyond electromagnetism is creating new opportunities But why is this important — and why is even this accuracy not enough? Electromagnetism dominates most phenomena at scales larger than the subatomic (which is ruled by nuclear forces) but shorter than the astronomical (the realm of gravity) Can the accuracy of a be improved indefinitely? This is unlikely using the electron g −2 Could measurements of the electron help clarify what has or hasnt been seen? To probe the putative new force the muon might have sensed, the accuracy of the electron g −2 measurements should be improved by a factor of at least a dozen Elementary particles borrow energy from the vacuum to pop up and disappear again through quantum fluctuations Excitingly, atomic studies — the original source of information on α — are currently seeing a renaissance, and could produce sufficiently precise values For now, only the first four terms of the Taylor expansion of g −2 are known (this is a mathematical expression consisting of a series of terms that, added together, come closer and closer to the true value of a quantity) For the past quarter-century, the world record for the most accurate value of α has been held by amazing experiments performed on a single electron trapped in a vacuum permeated by electric and magnetic fields  For the point-like electron, relativity theory demands that g =2 Gabrielse and colleagues measurement is, for the first time, sensitive not only to elec-tromagnetic forces but also to tiny, strong nuclear effects Getting that far took six decades and spawned a rich tool-box of mathematical methods and tricks that has benefited other branches of science How does the colour of a rose relate to the hardness of oak? To physicists, both result from electromagnetism, an interaction whose strength is encoded in one pure number — the fine-structure constant Improving our knowledge of the fine-structure constant by another order of magnitude with an independent method is a daunting task In fact, quantum electrodynamics, the theory of electron interactions with light, was born through efforts to understand its value In the 1970s, more precise values came from solid-state systems, through the discovery of electrical phenomena such as the Josephson and the quantum Hall effects ( Fig. 1 ) In this cavity, cooled to 100 millikelvin, a single electron can be trapped and screened even from some of the vacuum fluctuations It was once believed to be a simple fraction, 1/137, a circumstance that provoked theorists to search for some deeper meaning to it Its value was initially best determined by measuring atomic transitions Nevertheless, this could be the first evidence of particles that are too massive to have been seen in our laboratories, but that were perhaps crucial in the design of the Universe Not least among these is the field of symbolic computation, which aims to harness the power and patience of computers to tackle huge algebraic equations Of course, an independent value for α would be needed to interpret the result Studied closer, the denominator turned out not to be an integer Such is the tranquillity of its setting that individual quantum levels of the electron motion and spin can be discerned The dream of the theorist is an exact expression for g −2 in terms of α, but that seems as elusive as deriving α itself The electron has a heavier cousin, the muon, whose g −2 has recently been measured The electron interacts with such virtual particles, mainly photons, and its g -factor is increased slightly by an amount that depends on a The electron, as a charged and rotating particle, is a tiny magnet with a strength — its magnetic moment — given by μ = g ( e /2 m ) s , where e , s and m are the electrons charge, spin and mass The new laser-based tools of optical lattices and frequency combs, recognized with the 2005 Nobel Prize in Physics, have been applied to trap rubidium atoms and thus determine α with an error of seven parts in a billion The physical vacuum, far from being nothing, vibrates with activity The proportionality coefficient g would be 1 for a classical spinning ball The result disagrees with our understanding of fundamental interactions by a tantalizing 2.8 standard deviations: too much to ignore, but not enough to claim a discovery of something new wiggling in the vacuum This deviation, known as g minus two ( g −2) is among the most precisely calculated quantities in physics This is about nine times cruder than Gabrielse and colleagues value  This is an impressive achievement, but also hints at obstacles ahead: the uncertainty inherent in nuclear forces will eventually limit how well a can be read off from g −2 This is not yet the whole story This theoretical progress has gone hand in hand with experimental breakthroughs Thus, α can be measured in many ways, using any system of well-understood electromagnetic nature Transitions among the lowest-lying states have now allowed Gabrielse and colleagues to determine the g -factor to an accuracy of one part in a trillion (ref. 2 ) and, when compared with the theoretical expression, improve our knowledge of α (ref. 1 ) When Arnold Sommerfeld first used α in 1915, he named it the fine-structure constant because it described subtle features of the radiation spectrum of the hydrogen atom Whereas particle physicists have consistently strived to build higher-energy accelerators, Gabrielse and Peil at Harvard University succeeded in constructing a cyclotron with the lowest energy so far  Writing in Physical Review Letters , Gabrielse and colleagues use a measurement of the electrons magnetic moment reported in a companion paper to find that α =1/137.035999710(96), the most accurate value yet
 A quantum replicator need not be an atomic system that clones itself At some stage, quantum life could have co-opted large organic molecules for back-up memory Biologists have always regarded reproduction — one of the defining characteristics of life — as being about replicating structures, whether they be DNA molecules or entire cells But so long as they cling to that, the origin of life will remain mysterious But the concept has turned out to be something of a blind alley, and further progress with pre-biotic chemical synthesis has been frustratingly slow But to get life started all you need is to replicate information But what about the software? When Schrödinger asked, ‘What is life?’ he could already glimpse the central signifi-cance of the cells information storage and replication processes, even though the role of DNA and the genetic code was yet to be discovered Elucidating this chemical pathway has been a tantalizing goal, spurred on by the famous Miller–Urey experiment of 1952, in which amino acids were made by sparking electri-city through a mixture of water and common gases Even if we cant reconstruct the precise details of lifes emergence, knowing the general principles would be a huge advance Eventually the organic stuff would literally have taken on a life of its own Furthermore, quantum systems can make use of phenomena such as superposition, entanglement and tunnelling to enhance their performance How complexity emerges in quantum systems is a subject still in its infancy, but the principles involved could be illuminated by applying algorithmic complexity theory to quantum information theory How, then, did organic life arise? Information can readily be passed from one medium to another In a series of lectures, Erwin Schrödinger described how he believed that quantum mechanics, or some variant of it, would soon solve the riddle of life In the nineteenth century, many scientists thought they knew the answer to Schrödingers rhetorical question Indeed, there is a quantum no-cloning theorem that forbids the replication of wavefunctions Information can be processed at the quantum level orders of magnitude more rapidly than it can be processed classically, which is why the race is on to build a quantum computer It might even be a frigid location such as an interstellar grain Life is, after all, just a state of matter, albeit a weird one Life must have a chemical basis: organic molecules provide the hardware for biology Life, they maintained, was some sort of magic matter Molecular biologists are content with ball-and-stick models based on classical concepts Most research on biogenesis has followed that tradition, by assuming that chemistry was a bridge — and a long one at that — linking matter with life One of the most influential physics books of the twentieth century was actually about biology Proving a quantum-mechanical theorem that puts a bound on the probability that such-and-such a system can replicate to a certain accuracy, and evolve to a particular level of complexity, might answer astrobiologys burning question: was the origin of known life a freak accident, or the expected outcome of intrinsically bio-friendly laws of physics? Momentous implications would flow from the answer, as the issue addresses one of the deepest questions of existence: is life a cosmic phenomenon, or are we alone in the vastness of the Universe? Quantum mechanics thus provides an automatic discretization of genetic information Rather, the information content of an atomic system must be copied more or less intact — not necessarily in one step, but maybe after a sequence of interactions Replicating a single bit of information is one thing; generating and replicating long concatenations of bits is quite another Sixty years on, Schrödingers expect-ation has not been fulfilled Something is missing from the account so far — complexity The belief that there is a chemical recipe for life led to the hope that, if only we knew what it was, we could mix up the right stuff in a test tube and make life in the lab The continued use of the term ‘organic chemistry’ is a hangover from that era The loss in processing speed would have been offset against the greater complexity, versatility and stability of organic molecules, which in turn would have enabled organic life to invade many environments The origin of life remains one of the great outstanding mysteries of science These lectures were published in 1944 under the title What is life? and are credited by some as ushering in the age of molecular biology This information might well be in binary form, making use of the spin orientation of an electron or atom for example Throw in a selection mechanism and the great darwinian game could begin To take up Schrödingers suggestion, a radical solution to the problem, ‘What is life?’ could be that quantum mechanics enabled life to emerge directly from the atomic world, without the need for complex intermediate chemistry Today, the cell is regarded not as magic matter but as a computer — an information-processing and replicating system of astonishing precision What is this atomic Adam, this quantum replicator that begets life? I confess I havent a clue about the best environment in which to find such a thing, although I know it would not be in a traditional primordial-soup setting When life is viewed in terms of information processing, the problem takes on a different complexion When Schrödinger published his book, quantum physicists were flushed with the success of explaining the nature of matter Wherever it was, once a population of information replicators became established, quantum uncertainty provided an inbuilt mechanism for variation
 Arising from: N Gedney et al  However, we have concerns about this data set and the methods used to construct it, in addition to those already raised , which we believe may undermine their conclusions. Nature 439 , 835 – 838 ( 2006 ) ; Gedney et al . reply Gedney et al . attribute an increase in the twentieth-century continental runoff to the suppression of plant transpiration by CO 2 -induced stomatal closure, by replicating a continental runoff data set  A fundamental requirement of a runoff data set used in an attribution study, such as that by Gedney et al . , is that it is representative of the observed runoff conditions around the world A wavelet-based runoff reconstruction methodology is used to infill any missing data and extend records forwards (to 1994) and backwards (to 1875) where necessary Based on the start and end dates of the runoff records , extrapolation from 10–20 years of observed runoff data to the centennial scale has been applied to at least 34% of the stations Considering the serious concerns about the continental runoff data set underlying the results of Gedney et al . , their conclusion that an increase in twentieth-century continental runoff is attributable to the suppression of plant transpiration by CO 2 -induced stomatal closure is called into question Gedney et al . analyse continental runoff records based on “observations from at least 20% of the total river basin area”, which could be taken to mean that up to 80% of the continental runoff is reconstructed, not observed, for some periods of their analysis In addition to previous concerns about the use of runoff stations subject to confounding anthropogenic influences, such as reservoirs, and aspects of the runoff reconstruction methodology, it seems that the runoff reconstruction methodology is based on the best correlation against one of ten unspecified reference stations  Key to this is a discussion of the percentage of continental runoff that is reconstructed (infilled or extrapolated), which is not presented  The concerns outlined above and previously about the reconstruction methodology call into question the degree to which the runoff data set used is representative of those conditions The continental runoff data set covers the period 1875–1994 and the start and end dates of runoff observations are listed for each of 221 constituent stations The sensitivity of the final reconstructed runoff to the choice of these reference stations is not properly addressed  There is no discussion about whether these reference stations are spatially and temporally representative of the full range of runoff regimes being reconstructed around the world and not subject to confounding anthropogenic influences This highlights the need for the development of a quality-controlled, freely available, global runoff data set, which can be used with confidence (or at least informed caution) in future studies. This is likely to be an underestimate, because not all stations have complete records between these dates Without knowing the degree to which the runoff data set is reconstructed and therefore representative, conclusions based on replication of that runoff data in a modelling (attribution, for example) analysis are speculative
 A door to understanding ABA perception has been opened A simple search of protein databases reveals only one distant FCA homologue in the Arabidopsis genome Alternatively, the FCA and ABAP1 proteins provide an opportunity to elucidate the structure of an ABA-binding pocket, which may reveal important sub-domains and structural constraints for ABA binding As a result, premature polyadenylation of the truncated FCA precursor mRNA is abolished As Arabidopsis plants can flower early in response to drought, which increases ABA production, the ABA–FCA response may be overridden during this response  But genes that encode ABA-binding receptor proteins have remained unidentified But we dont yet know whether these mRNA-processing proteins, which affect ABA action, are components of an FCA-like ABA stress-response pathway Consistent with this model, the authors report that ABA causes a delay in flowering in Arabidopsis  Despite their importance, the genes that encode the cellular receptors for this hormone have not been identified Further questions arise with each advance Furthermore, ABA inhibition of flowering was not affected in two dominant ABA-insensitive mutants, abi1-1 and abi2-1 , in which most of the stress-related ABA responses are impaired Genetic screens with various twists have elucidated ABA signal-transduction mechanisms that act downstream of ABA sensing  In the new work, Razem et al . report that the FCA–FY complex dissociates when ABA binds to FCA, making the complex non-functional ( Fig. 1 ) In this negative feedback loop, polyadenylation of the truncated FCA precursor mRNA results in a shortened mRNA, and thus in non-functional FCA protein ( Fig. 1 ) Indeed, ABA-binding studies of Arabidopsis FCA in which the protein lacked specific structural regions show that ABA-binding activity lies in the carboxy-terminal half of FCA, which does share homology with ABAP1 (ref. 1 ) Instead, their ability to survive lack of water, extreme temperatures and such stresses as high salt levels relies heavily on a plant hormone called abscisic acid (ABA) Interestingly, the RNA-recognition motif in FCA is absent in the barley ABAP1 protein  It also increasingly demands the attention of politicians, given that in arid regions across the globe more than 80% of the available fresh water is consumed by agriculture  It also reduces the amount of functional FCA protein through a negative feedback loop by adding a premature polyadenylation tail to a truncated form of the FCA precursor mRNA  Many avenues of research have shown that ABA is a key player in such stress resistance On page 290 of this issue, however, Razem et al . describe the characterization of a protein that binds to messenger RNAand that also binds ABA and controls ABA-dependent flowering in the model plant Arabidopsis  Plant scientists will need to keep on trekking to illuminate how their immobile lab subjects perceive abscisic acid when faced with drought, cold and salinity. Possible modulation mechanisms during drought stress could be investigated by analysing the newly revealed direct ABA regulation of FCA mRNA (full-length versus truncated) and the strong ABA-induced increase in levels of FLC mRNA Razem and colleagues have used an alternative, biochemical approach Razem et al . show that ABA causes a dramatic increase in FLC mRNA, which in turn would delay the transition to flowering Razem et al . went on to show that in plants with a loss-of-function mutation in FCA, the ABA-induced closing of stomatal pores and inhibition of seed germination — two classical ABA responses — were not impaired Research on ABA signalling is also revealing the robustness of an intricate signal-transduction network Responses mediated by this hormone lead to the induction of complex tolerance mechanisms to drought, cold, salinity and wounding, including the control of closure of the stomatal pores in leaves to reduce water loss  Several reports have established a link between RNA-processing proteins and ABA signalling  The Arabidopsis FCA protein is homologous to the barley ABAP1 protein in its carboxy-terminal half and, like ABAP1, it has a high affinity for active ABA analogues . (Its dissociation constant, K d , is 19 nM.) The FCA protein is a component of the so-called autonomous flowering pathway, which reduces the activity of the flowering repressor Flowering Locus C , or FLC ( Fig. 1 , overleaf)  The binding of ABA to FCA and ABAP1 is apparently a further example of newly emerging mechanisms by which plant growth regulators mediate their responses The FCA–FY complex negatively regulates expression of the flowering repressor FLC  The hunt could be on to characterize homologues to the ABA-binding carboxy terminus of FCA and barley ABAP1 The question of how plants cope with the recurring stresses of drought, cold and salinity not only engages plant scientists, agronomists, ecologists and climatologists The WW domain allows FCA to interact with the protein FY, which is an mRNA processing factor  Their work shows that an RNA-binding protein called FCA binds to ABA and is regulated by it, and that FCA is involved in a less well-studied function of ABA — the inhibition of flowering They isolated a barley protein that has ABA-binding activity, named ABAP1 (ref. 5 ), and investigated whether a homologue of ABAP1 functions in an ABA response in Arabidopsis  This can limit traditional ‘forward’ genetic approaches , because a mutation in one pathway may be side-stepped to a degree by using another route that transmits the signal This might be because plant genomes have large numbers of homologous — closely related — genes that probably have overlapping functions, or because an ABA receptor is essential, such that plants with mutations in the receptor gene would not survive Thus, ABA causes accumulation of full-length FCA mRNA Thus, other ABA receptors are needed to explain the classical ABA signalling responses to stress Two structural regions of the FCA protein are of particular relevance: a protein-interaction region known as a WW domain, and an RNA-recognition motif  When plants experience drought or cold, they cannot get themselves a glass of water or move to a warmer place
 Among them were the schools former director, Walter Gropius, and the head of its metal workshop, László Moholy-Nagy, whose art will be on display next month at the Tate Modern in London As secretary of the Zoological Society of London he had an apartment at the zoo, which he used partly as a showroom for modernist design Bauhaus design was one of the groups chief passions, and Gropius looked to Huxley and his friends with hope and admiration But it was also politically important to the group to display thriving animals such as penguins in a highly unnatural setting, to show that humans too could prosper in new environments. “The most unlikely animals seem to thrive under what would seem the most unnatural conditions,” zoologist Peter Chalmers Mitchell observed, if they have “freedom from enemies, regular food and general hygiene” By taking snapshots (as opposed to posed photos), he sought to replace static classical art with dynamic images of active people Francé founded the science of bionics to pursue this end, calling it ‘bio-technique’ G He also tried to highlight the activity of places and objects He argued that a “prehistoric animal shell is constructed in such a wonderful way that we could immediately adapt it to a fine bakelite or other moulded plastic form” He defined architecture “as an organic component of living” and argued that “architecture will be brought to its fullest realization only when the deepest knowledge of human life in the biological whole is available.”  It was while living in London that Moholy-Nagy revolutionized the art of photography by capturing forces of life in action He read the work of Huxley and his friends and used it to generate his own principles, techniques and processes that could be applied to human design He used light and shade in a photograph of a laboratory tube, for example, to evoke a sense of gas moving within the glass pipe Here, scientists, artists, architects, environmentalists and the science-fiction writer H His artwork can be seen alongside that of fellow modernist Josef Albers in the exhibition “Albers and Moholy-Nagy: From the Bauhaus to the New World” at Tate Modern in London from 9 March to 4 June. His investigations into architecture and photography were also informed by the life sciences In the mid 1930s, faculty members from the Bauhaus design school in Germany fled Nazi harassment and moved to London Moholy-Nagy followed suit and told designers to use nature as a “constructional model” and to look for “prototypes in nature” to determine functional design Moholy-Nagy, meanwhile, had found a major source of inspiration in Raoul Francé, a biologist and author who argued that humans should learn to copy natures own inventions Moholy-Nagys 1935 film In the Cradle of the Deep documents the growth of lobsters and the fishermans struggle to search them out One of these was the ecologist Julian Huxley The gorilla house and the penguin pool, along with a series of other buildings, were therefore built in the Bauhaus style The point of the film was to show designers that observing the life of animals can teach us about how form follows function The radical designers, who sought to unify arts and crafts with industrial universalism, found new allies and patrons in a community of biologists in London who adapted Bauhaus architecture and art as part of their scientific vision for the future The same would hold for workers and the poor, who desperately needed to be liberated from their ‘natural’ condition of criminal and filthy slums The zoo became the testing ground for these architectural ideas The zoologist Solly Zuckerman believed that the difference between humans and animals was “almost certainly one of degree only”, and he saw the life of primates as “a crude picture of a social level from which emerged our earliest human ancestors” To Huxley, nothing less than the evolutionary survival of the human species was at stake Traditional architecture and design reinforced an unfortunate dualism between people and nature, Huxley believed, whereas the Bauhaus approach promised a harmonious reunion Visitors to the zoo could observe their own primitive desires in animals, Zuckerman argued, so it was of moral importance to place the animals in a model home for healthy living Wells regularly met for discussions about how to save humankind from environmental, economic and social destruction
 Consequently, few general hypotheses have been advanced to explain the large differences between species in the magnitude of population fluctuations  Here we use population time series for 23 bird species to estimate parameters of a stochastic density-dependent age-structured model One reason for this is that the detection of density regulation in population time series is complicated by time lags induced by the life history of species that make it difficult to separate the relative contributions of intrinsic and extrinsic factors to the population dynamics Theoretical studies have shown that variation in density regulation strongly influences population dynamics , yet our understanding of factors influencing the strength of density dependence in natural populations still is limited  These results indicate that the relationships between demographic and life-history traits in birds translate into distinct population dynamical patterns that are apparent only on a scale of generations. We show that both the strength of total density dependence in the life history and the magnitude of environmental stochasticity, including transient fluctuations in age structure, increase with generation time Age at maturity α refers to the age at which regular breeding of females first occurred Because demographic stochasticity has the largest influence on the population dynamics of small passerines with estimated values of σ  d 2 about 0.50 (ref. 22 ), we included only time series of passerines with mean values of more than 50 individuals Calculation of variance in the noise For a stationary time series such as equation (2) the autocovariances C ( τ ) = cov( N t , N t + τ  ), τ  = 0, 1, …, are determined by the Yule–Walker equations C ( j ) - ∑  i = 1 α   b i C ( j - i ) = σ  ω  2  for  j = 0 0 for  j 0 where the variance in the noise σ  ω  2 is estimated by maximum likelihood and C (0) = σ  N 2  Demographic data were extracted from studies of individual species (see Supplementary Information ) Estimates of population parameters based on time series analyses are strongly influenced by the precision in the population estimates  Estimation of parameters As described in ref. 16 , the maximum-likelihood estimates of the autoregression coefficients b i in equation (2) are found by inverting the Yule–Walker equations for the time series Generation time T was calculated as T = α + [ s /(1 - s )], where s is the expected adult survival rate Methods Data This study is based on 23 time series longer than 15 years No estimates of the demographic variance σ  d 2 were available for many of the species Survival estimates were based either on capture–recapture analysis or calculated as the return rate of individually known adults from one breeding season to another The average population size Nmacr; should be much larger than σ  d 2 / σ  e 2 to avoid the influence of demographic stochasticity , where σ  e 2 is the environmental variance These estimators are biased because population size at a given time enters the regression as both a dependent variable and an independent variable  This bias can be estimated and corrected by using computer simulations  Those simulations also can be used for significance testing and calculation of confidence intervals of the estimates  Using the fact that C ( τ ) = C (- τ ), this is a set of linear equations that can be solved with respect to the variance in the stationary distribution C (0) as well as C (1), C (2), … We calculate the residual variance of a first-order process with the same stationary variance as in equation (2) , namely σ  ɛ  2 = C (0)(1 - b 1 2 ), provided that for this first-order process | b 1 | 1. We therefore included only studies in which uncertainties in population estimates are negligible compared with the environmental variance; that is, studies based on total counts of nests or colour-ringed birds  Although the effects of density dependence and environmental fluctuations may be small in long-lived species on a yearly basis , their accumulated influence on the population growth rate over one generation may still be large Although this relationship was strongly influenced by the two long-lived seabird species southern fulmar ( Fulmarus glacialoides ) and lesser snow-petrel ( Pagodroma nivea ), a significant relationship was still present after excluding those two species from the analyses involving T (correlation coefficient = 0.47, n = 21, P = 0.034) and adult survival rate (correlation coefficient = 0.57, n = 21, P = 0.007), whereas no significant effect was present for clutch size (correlation coefficient = -0.20, n = 21, P 0.1) An increase in strength of density dependence with longevity when the censuses were taken at intervals of one generation has also been previously recorded in British birds  Analyses of density dependence in natural populations are usually based on autoregression of population time series in which regression coefficients are assumed to represent both direct and delayed density dependence  As a consequence, the stationary variance in the time series σ  N 2 was also independent of life history (the absolute value of the correlation coefficients between σ  N 2 and T , clutch size, s and α were all less than 0.10; P 0.7) As expected from this, we find that several features of population dynamics measured on a time scale of generations can be predicted from life-history characteristics Because many bird species are long-lived it will be necessary for the progress of basic ecology to secure continuity of long-term demographical studies Comparative studies have shown that density dependence strongly influences population dynamics, and especially that of small passerine birds  Consequently, the rate of return to equilibrium measured in generations decreases with generation time T (correlation coefficient of log 10 -transformed values = -0.73, P 0.001, n = 23) Coulson, unpublished observations) Despite large differences between species in sensitivity of population growth rate per generation to changes in population density and environmental effects ( Figs 2d and 3b ), the lack of trend in Fig. 3a indicates that life histories might have evolved to produce comparable environmental variance in both short-lived and long-lived species, with similar impacts on their rates of population growth in the long run  Finally, deviations of the adult population at time t from equilibrium, x ( t ) = N ( t ) - K , are expected to be small or moderate For instance, in a species with α 1, with no density dependence in subadult or adult survival rates, b 1 equals the adult annual survival rate s  For instance, in long-lived seabirds competition for breeding space or food can cause density dependence in their population dynamics  For population viability analyses of rare or endangered species, in which it is often not feasible to obtain detailed demographic data, the development of empirical scaling relationships between stochastic population parameters such as demographic and environmental variances and generation time may provide useful information for extinction risk assessment as well as conservation and restoration planning. For simplicity we assume that the expected adult annual survival and fecundity rates are independent of age Furthermore, it is assumed that density dependence is exerted by the adult fraction of the population on any combination of juvenile and adult vital rates, which encompasses general features of the dynamics of many bird populations  Furthermore, the environmental variance for this process per generation ( σ  ɛ  2 T ) was closely related to life-history characters; that is, σ  ε 2 T decreased with clutch size (correlation coefficient of log 10 -transformed values = -0.71, P 0.001, n = 21; no longer significant after removing the two extreme values, correlation coefficient = -0.25, n = 19, P 0.3) but increased with adult survival rate (correlation coefficient of log 10 -transformed values = 0.70, P 0.001, n = 21; correlation coefficient = 0.63, n = 19, P = 0.004 after omitting the two outliers) Here we use the general definition of density dependence in equation (1) to model the stochastic density-dependent population dynamics of different bird species However, on the basis of the general definition of density dependence ( equation (1) ), there is a relationship between total density dependence in the life history and the autoregression coefficients: (1 - s ) D = 1 - ∑  i = 1 α   b i (3) Using this theoretical framework, we find a large interspecific variation in the density dependence in bird population dynamics However, previous comparative analyses have shown that many avian demographic traits such as clutch size and age at maturity scale closely with adult life span  However, these autoregression coefficients b i do not directly reveal the strength of delayed density dependence because they depend on both life-history parameters and density dependence in the vital rates  In a simple deterministic model with no age structure, de Kroon et al. defined the strength of density dependence γ as the negative elasticity of the population growth rate λ with respect to changes in population size N , evaluated at the carrying capacity K , γ = -(∂ ln  λ /∂ ln  N ) K  In contrast, interspecific differences in avian demographic stochasticity per generation are independent of life-history variation  In contrast, there was a highly significant linear increase in log 10 ( σ  ɛ  2 T ) ( Fig. 3b ; correlation coefficient = 0.82, P 0.001, n = 21; correlation coefficient = 0.56, n = 19, P = 0.013 after omitting the southern fulmar and lesser snow-petrel) In our data set log 10 σ  ɛ  2 was independent of log 10 T ( Fig. 3a , correlation coefficient = 0.24, P 0.3, n = 23) In our data set the mean of the autoregression coefficients b i for species with age at maturity α ≥ 2 decreased with time lag ( Fig. 1 ), indicating that the effects of the previous years population sizes on current population size decreased with time In our data set, the coefficient of variation in the time series is generally less than 30%, which has been shown to fit our theoretical approach well In the Soay sheep ( Ovis aries ) lagged responses in life history were shown to be important for explaining temporal variation in population fluctuations  Increasing evidence suggests that density dependence also occurs frequently in long-lived species Lande et al. extended this approach to show that in a generalized life-history model structured by age and dependent on density, total density dependence in the life history, D , should be defined as the negative elasticity of the population growth rate per generation, λ T , with respect to the change in the size of the adult population when fluctuating around the carrying capacity, so that D = - T ∂ ln  λ ∂ ln  N K (1) where T is the generation time N On the basis of these assumptions, we obtain a linearized autoregressive model with time delays from 1 to α years, namely x ( t ) = ∑  i = 1 α   b i x ( t - i ) + ω ( t ) (2) where ω ( t ) is a noise term with a mean of zero and variance σ  ω  2 , describing environmental stochasticity, including transient fluctuations in age structure and autocorrelations due to long-term fluctuations in the biotic or abiotic environment Our analyses reveal that the magnitude of annual fluctuations in size of age-structured bird populations cannot be predicted from estimates of generation time or from a knowledge of life-history traits such as clutch size and adult survival rate Our results indicate that understanding population dynamical patterns in birds might require accounting for generation time Similarly, environmental fluctuations strongly influence variation in population size and age structure of many long-lived species and often generate lagged effects in the population dynamics  Similarly, in a species that matures at 1 year, if b 1 = 0 the population autocorrelations for all time lags will be zero, corresponding to a white-noise process for the population size, N ( t ), that indicates strong density dependence The strength of density dependence varied from γ = 0.04 in the South Polar skua ( Catharacta maccormicki ) to γ = 0.61 in the Eurasian sparrowhawk ( Accipiter nisus ), resulting in differences in return times to equilibrium from about 1.7 to 22.5 years The strength of total density dependence in the life history, D , increased with generation time T ( Fig. 2d ; correlation coefficient = 0.92, n = 23, P 0.001) and adult survival rate ( Fig. 2f ; correlation coefficient = 0.62, n = 23, P = 0.002) but decreased with clutch size ( Fig. 2e ; correlation coefficient = -0.45, n = 23, P = 0.03) The variance of this white noise process for species with age at maturity larger than 1 year should be approximately equal to the environmental variance (R.L., S.E., B.-E.S., and T These density-dependent effects were independent of generation time ( Fig. 2a ; correlation coefficient = -0.15, P 0.5) as well as clutch size ( Fig. 2b ; correlation coefficient = 0.40, P = 0.06) and adult survival rate ( Fig. 2c ; correlation coefficient = -0.09, P 0.69) This approach neglects the basic fact that the life history can produce time lags in the population dynamics that will wrongly be interpreted as delayed density dependence  This definition facilitates a comparison of the strength of density dependence between species with different life-history characteristics This implies that the effect on the population growth rate per generation of a change in population size was larger for long-lived species than for short-lived species This indicates that environmental stochasticity per generation might be greater for long-lived species than for species with short life expectancies Thus, the rate of return to equilibrium then becomes γ = D / T  To compare the residual variation in the population process we must account for interspecific variation in age at maturity that will cause differences in the lag-structure of the population dynamics  We first estimate (see Methods) the variance in the stationary distribution of the population sizes σ  N 2 in our model ( equation (2) ) and then calculate the variance in the noise of a first-order process with a single time lag of one year, σ  ɛ  2 , that will give the same stationary variance in population size as in the full model
 And the European Commission has no mandate to fund basic research, its aim being to promote industrial competitiveness and improve quality of life in Europe And the fledgling ERCs scientific council has agreed on a first funding stream, open to any scientist embarking on an independent research career But two decisions last week moved the much-heralded European Research Council (ERC) closer to reality But, she says, the planned two-stage selection process will ease the pain of any oversubscription By then, Kafatos hopes, the ERC will have proved its value to politicians, and future Framework programmes would receive at least that much money Foot on the ladder The ERCs funding is less than had been hoped for when the concept began to gain momentum in 2002. “But it is not crumbs,” says Kafatos He doesnt think oversubscription will be a problem. “Scientists will exercise self-evaluation,” he says. “Knowing that only frontier research is going to be funded, only those who have really excellent proposals will apply.” In the first stage, applicants must summarize their projects and give information about the research team that would carry them out In the meantime, the ERC will open its Starting Grant scheme in its first year, aimed at scientists who are within ten years of completing their PhDs and seeking their first post as an independent investigator. “There are many countries where young scientists are kept dependent for far too long on their professors,” says Kafatos. “This programme will allow them independence earlier.”  Julia Fischer, an animal-behaviour specialist at the German Primate Centre in Göttingen, agrees. “There is a big difference between countries,” she says. “In the United Kingdom it is easier to get on the career ladder than in Germany, for example.” Fischer is on the board of the Young Academy, which comprises 50 top young scientists in German-speaking countries Individual investigators may apply for grants of up to €1 million, and there is just one criterion for selection: excellence in cutting-edge research. “ERC grants will be like the National Institutes of Healths R01 investigator grants,” says Fotis Kafatos, a biologist at Imperial College London and chairman of the ERCs scientific council. “Individuals can put in an application at any time.”  European scientists are famously frustrated by the complicated requirements of European Union (EU) Framework research programmes Many have advocated an ERC for decades, arguing that it would raise the quality of research and provide a new source of funding for scientists in countries where national funds are paltry Mounting pressure from scientists eventually prompted a pragmatic solution, and the ERC is now part of the EUs next Framework Programme, FP7, which will run from 2007 to 2013 Munich Ten years ago, few would have imagined a European Union-wide fund for basic research, distributed without restrictions on scientific creed or country On 30 May, the council of ministers approved a budget of €50.5 billion for that programme and agreed on how it would be broken down, including the ERCs share One of the biggest concerns facing the ERC is the danger of oversubscription Soon after that, a second stream of funding will be opened to investigators in all disciplines The annual budget will start at €300 million, rising to €1.5 billion in the seventh and last year The council will establish at least 15 panels, organized by subject, to handle the final decisions The European Council of Ministers has approved a budget of €7.5 billion (US$9.7 billion) over seven years The idea that the notoriously bureaucratic European Commission would finance such a fund, with no strings attached, would have stretched credibility too far The panels will choose external referees to review the full proposals The plan must be ratified on 15 June by the European parliament, but is expected to pass with no major changes The question was always: who would pay? National research agencies have legal and psychological difficulties with putting part of their funds into an international pot The winners in this round will be invited within six weeks to submit a full application There are well over a million full-time researchers in EU countries. “We have no idea how many scientists across the EU would in fact be eligible for the starting-investigators programme, or how many will apply,” admits Helga Nowotny, a social scientist at the Vienna Centre for Urban Knowledge Management and vice-chair of the ERCs scientific council These generally require multidisciplinary, multinational research groups working towards a defined industrial or social goal This differs from the selection procedures of the Framework programmes, where the commission selects evaluators from a list of scientists who have volunteered for the job. “That is not a good system,” says Nowotny. newsad; The scientific council is now consulting organizations such as national granting agencies and academies to identify panel members. “Only those with strong scientific reputations will be selected to join panels,” says Kafatos
 A few scientists are taking a different tack and trying to harvest the potential of embryonic stem cells — particularly their immortality and flexibility — without destroying embryos to get them Adult stem cells are less likely to cause tumours than embryonic stem cells, and less likely to be rejected by the immune system Adult-derived stem cells are the only form of stem-cell therapy to make it to the clinic so far All 21 lines were cultured using feeder cells from mice, so they may be too contaminated for use in humans All have the basic ability to grow in culture and to transform into different cell types And researchers cant use disease-specific cell lines, which come from embryos with conditions such as cystic fibrosis: the Reproductive Genetics Institute in Chicago claims to have derived 36 such lines, but not one is approved for federally funded research And this week EU ministers agreed to continue funding in FP7 Another problem is that the cell lines have aged in the past five years and accumulated genetic mutations Bush restricted federal funding to work on human embryonic stem-cell lines already in existence But academic and biotech groups are gearing up to generate lines that satisfy Good Manufacturing Practice (GMP), a system for pharmaceutical products But adult stem cells are limited in other ways — most notably supply But Geron, based in Menlo Park, California, claims to have derived clinical-grade cells using two US-approved lines that were initially cultured using mouse cells But some grow faster than others, and some are more stable in long-term culture. “Some differentiate more easily into particular tissues,” adds Hovatta. “Many lines differentiate very nicely into nerve cells, for example, while others can turn into pancreatic cells, which are always rather tricky But tampering with human embryos in this way may not address everyones ethical concerns But why arent scientists happy with those? About half of the available lines grow slowly, making them virtually unusable, says Renee Reijo Pera of the University of California, San Francisco Clinical trials in sight A big problem with the early human embryonic stem-cell lines is that they were not designed to be safe for use in humans Diminishing returns In August 2001, US President George W Do scientists really need so many lines to choose from? “Well, theyre not all quite the same,” says Outi Hovatta of the Karolinska Institute. “Weve found that around 1,000 of the 30,000 genes we have checked in our cell lines are expressed differently.” Each cell line has characteristics of its own, she says Drive for alternatives In the emotionally charged stem-cell debate, to be against embryonic stem-cell research is often portrayed as being for disease Estimates from China At least six laboratories in China are thought to have succeeded in deriving human embryonic stem-cell lines Estimates of the number of Chinese lines range from 10 to almost 70 Europes framework funding A major research collaboration dedicated to human embryonic stem cells and funded by Europes Sixth Framework Programme (FP6) kicks off next month Facilities that can derive and bank GMP lines are being built around the world For example, experiments in mice have shown that a single cell taken from a blastocyst, without destroying it, can be used to derive a cell line For example, stem cells from bone marrow (pictured) have been used for more than 30 years to treat blood disorders Government funding for such research has significantly increased in the past five years, but there are no proper guidelines, and it is hard to monitor achievements. “Theres a lot going on that you dont really know about,” says Jack Price of Kings College London, who led a stem-cell team to China in 2004 He says that based on published evidence the most likely figure is “more than 10, but less than 15” Isolating sufficient quantities of certain tissues, such as brain samples, could also pose a major technical hurdle It may also be possible to elevate existing lines to GMP status It will make them available to researchers worldwide Lingsong Li, who heads the Peking University Stem Cell Research Center, is cautious Of 64 lines said to be available, some failed in culture and some were retracted by donors, leaving 21 approved lines Regulatory agencies have not yet said what standards cell lines would need to meet to be used in humans Several FP6 programmes on specific disorders and 11 new projects have just received ethical approval for work on human embryonic stem cells (pictured) So when opponents to loosening restrictions on US funding of embryonic stem-cell research took to the Senate floor last week, they were keen to emphasize their support for research that doesnt involve the destruction of embryos (see pages 329 and 335 ) Some adult stem cells can be grown in the lab, but not indefinitely Some senators exaggerated the promise of adult-derived stem cells, but they have real potential, as do other alternatives to embryonic stem cells Sweden steams ahead At least 55 human embryonic stem-cell lines have been derived in Sweden: 30 at Cellartis in Gothenburg and 25 at the Karolinska Institute in Stockholm The company will apply for approval to start US clinical trials in 2007, using glial cells derived from human embryonic stem cells to treat spinal injuries. The main problem with older lines is that they have been cultured with animal products The project will study how stem cells differentiate into neurons, and will fully characterize 52 human lines The project, ESTOOLS, got €12 million (US$15 million) from FP6, which has been matched by the collaboration, comprising 20 labs in 10 different countries Then there are the feeder cells that form the matrix on which stem cells grow There are also unexplained differences in how cell lines behave — for example, some differentiate more easily into certain cell types than others There are frozen stocks, but many were created using protocols that are outdated, meaning thawed cells can be difficult to culture This week, Singapore-based biotech company ESI announced that it has derived four safe lines (produced in Australia) — with four more in the pipeline
 Gamma-ray bursts (GRBs) come in two classes : long ( 2 s), soft-spectrum bursts and short, hard events Here we report the detection of the X-ray afterglow from—and the localization of—the short burst GRB 050509B In contrast, no short GRB had been accurately ( 10″) and rapidly (minutes) located Its position on the sky is near a luminous, non-star-forming elliptical galaxy at a redshift of 0.225, which is the location one would expect if the origin of this GRB is through the merger of neutron-star or black-hole binaries Most progress has been made on understanding the long GRBs, which are typically observed at high redshift ( z ≈ 1) and found in subluminous star-forming host galaxies The X-ray afterglow was weak and faded below the detection limit within a few hours; no optical afterglow was detected to stringent limits, explaining the past difficulty in localizing short GRBs. They are likely to be produced in core-collapse explosions of massive stars  A Chandra target-of-opportunity observation of the XRT error circle was performed on 11 May at 4:00  ut for 50 ks, with no sources detected in the XRT error circle A location at large radius would be consistent with the binary merger model for short GRBs  A more critical factor to define the low X-ray flux may be the small energy injection involved, as the prompt emission for GRB 050509B is also the weakest of the BAT GRBs Alternatively, the binary may have formed in a globular cluster; globular clusters have a broader radial distribution than field stars in ellipticals, which could explain the large projected radius of the GRB Although caution is always prudent for a posteriori statistics, the association with this galaxy seems unlikely to be coincidental Although there is less direct evidence that close neutron star–neutron star binaries can form easily in globular clusters, the double-neutron-star system PSR B2127 + 11C in the Galactic globular cluster M15 is an example of such a binary , and has a merger lifetime of ∼2 × 10 8  yr Another interesting aspect of the localization of GRB 050509B is that the burst is faint and yet has a bright galaxy in its error circle As Chandra observations have shown , giant ellipticals, especially those dominant in their cluster, have large populations of low-mass X-ray binaries containing accreting neutron stars and black holes As is true of most giant ellipticals in clusters, 2MASX J12361286 + 2858580 has no indications of ultraviolet or optical line emission  Before Swifts observations, it was predicted that short GRBs would have faint optical afterglows, particularly so if they occurred in low-density regions like those around evolved stars For BATSE bursts, studies were done of the post-burst emission by summing large numbers of GRB lightcurves  For typical shock parameters, the early X-ray afterglow emission is probably below the cooling frequency ; in this regime, the weak afterglow is consistent with the low-density medium around an evolved compact binary progenitor Further, a high fraction (gsims;50%) of the low-mass X-ray binaries in ellipticals are located in globular clusters because close binary systems containing at least one compact object can easily be formed dynamically in globular clusters Ground-processed data revealed an uncatalogued X-ray source near the centre of the BAT error circle containing 11 photons (5.7 σ  significance due to near-zero background in image) in the first 1,640 s of integration time However, the centre of the XRT error circle lies only 9.8″ away from the centre of the large E1 elliptical galaxy 2MASX J12361286 + 2858580 (ref. 10 ) at a redshift of 0.225 (ref. 11 ), which is located in the cluster NSC J123610 + 285901 (refs 12 , 13 ) If the redshift is 0.225, then the afterglow is 100 times less luminous than that of typical long-burst afterglows and the isotropic energy is ∼10 -4 that of typical long GRBs (about the same as the lowest-luminosity, unusual GRB 980425) If we ignore the effects of the galactic potential, a neutron star–neutron star binary moving at 1,000 km s -1 would travel 100 kpc in 10 8  yr In addition, the isotropic energy of 1.1 × 10 48 k  erg (15–150 keV, z = 0.225, where the k -correction factor is typically 1 to 10) is 10 2 times higher than that of the 27 December 2004 giant flare from SGR 1806 - 20 (refs 18 , 19 ) In fact, of all galaxy types, large ellipticals (particularly cluster dominants) are the most likely place to find double compact binary systems, owing to their large populations of globular clusters It is improbable that we will find a massive-star core collapse or young magnetar in this galaxy It is likely that the X-ray afterglow will remain a key to understanding short bursts It is possible the burst occurred in one of these Moreover, galaxies this luminous are relatively rare; the comoving number density of galaxies at least this luminous is ∼5 × 10 -5  Mpc -3 ; the probability of lying within 10″ of a randomly located one at z ≤ 0.225 is ∼10 -4  Neutron star–neutron star binaries often obtain significant kick velocities (100–1,000 km s -1 ) from the supernova that creates each neutron star  No new optical/ultraviolet sources were found in the XRT error circle to V-band magnitude 19.7 for t 300 min No optical afterglow was detected to stringent limits (R-band magnitude 25 at 25 h; ref. 7 ) Note that this is the first GRB of ∼80 with accurate optical localizations to be near a bright elliptical on the sky On 9 May 2005 at 04:00:19.23  ut , the BAT triggered and located GRB 050509B on board  On the other hand, 2MASX J12361286 + 2858580 is a very propitious site for a neutron star–neutron star or neutron star–black hole merger Our Chandra image shows that this is the central dominant galaxy in one of two merging subclusters in this bimodal cluster Our UVOT images clearly detect the galaxy in the optical, but not in the ultraviolet (UVM2 220-nm and UVW2 188-nm filters), as expected for an elliptical galaxy—implying little or no contribution from young, hot stars Swift has provided the first accurate localization of a short GRB Swift slewed promptly and XRT started acquiring data 62 s after the burst ( T + 62 s, where T is the BAT trigger time) The 15–150 keV fluence is (9.5 ± 2.5) × 10 -9  erg cm -2 , which is the lowest imaged by BAT so far and is just below the short GRB fluence range detected by BATSE (adjusted for the different energy ranges of the two instruments) The 3 σ  upper limit at 188 nm gives a limit to the star-formation rate of 0.2 M circdot;  yr -1 , where M circdot; is the mass of the Sun The BAT location is shown in Fig. 1 (large red circle) and the light curves in Fig. 2  The burst has a ratio of 50–100 keV to 25–25 keV fluences of 1.4 ± 0.5, which is consistent with, but in the soft portion of, the short/hard population detected by the first extensive GRB survey made with the Burst and Transient Source Experiment (BATSE) The centre of the XRT error circle is in the outer regions of the elliptical galaxy, although the circle extends nearly to the galaxy centre The detection of GRB 050509B near an elliptical galaxy is an important observation for short bursts because the association with a large elliptical galaxy is evidence against a collapsar origin, whereas an association with a star-forming galaxy would have left the question unanswered The event is a single short spike with duration of 40 ± 4 ms The fact that the X-rays are fading as early as 62 s puts a limit on the initial Lorentz factor of for z = 0.225 ( n -2 is ambient density in units of 10 -2  cm -3 , and E is the isotropic energy in units of 10 48  erg), showing that short GRBs are highly relativistic events The galaxy type for the suggested host galaxy is very different from those found for long GRBs; their hosts are typically subluminous and blue and show strong emission lines associated with star formation  The light curve combining BAT, XRT and Chandra data are shown in Fig. 3  The likely association between GRB 050509B and 2MASX J12361286 + 2858580 is difficult to understand if the GRB resulted from any mechanism involving recent star formation The new observations are from the Swift satellite, which features the hard X-ray wide-field Burst Alert Telescope (BAT), and rapid spacecraft slewing to point the narrow-field X-ray Telescope (XRT) and the Ultraviolet-optical Telescope (UVOT) at the burst The post-burst emission was found to be weaker for short bursts than for long events, consistent with the GRB 050509B The probability of a random location being within 10″ of a galaxy with an apparent magnitude at least this bright is ∼10 -3  The projected distance of the centre of the XRT position from the centre of the galaxy is about 35 kpc; the range over the error circle is about 2–70 kpc The UVOT observed the field starting at T + 60 s The X-ray afterglow from this short GRB can constrain outflow parameters The X-ray emission for GRB 050509B is faint, being the weakest afterglow of any of the 15 GRBs that XRT has promptly observed (a factor of ∼200 weaker than the XRT average) The XRT position is shown with respect to the Digitized Sky Survey (DSS) field in Fig. 1  There are five previous short GRBs with fluences one to three orders of magnitude larger than GRB 050509B that have had their arcminute-sized error boxes searched for bright galaxies  There are galaxies in each error box of brightness comparable to or less than 2MASX J12361286 + 2858580, but none much brighter—as one might expect for these brighter GRBs There may be more than one origin of short GRBs, but this particular short event has a high probability of being unrelated to star formation and of being caused by a binary merger. This does not contradict a merger model for short GRBs, because, although giant elliptical galaxies are a rich environment for mergers, most would occur in the more numerous, fainter, star-forming galaxies This is a luminous giant elliptical galaxy; its 2 Micron All Sky Survey (2MASS) magnitude of K = 14.1 corresponds to a luminosity of 4 × 10 11   L circdot; ≈ 3 L *, where L circdot; is the luminosity of the Sun and L * is the luminosity of a typical galaxy, assuming standard cosmology This prediction is consistent with the lack of optical detection to stringent limits for GRB 050509B, although we bear in mind that this burst is weak compared to other short GRBs Thus star-forming galaxies harbour both massive stars and evolved binaries, whereas ellipticals have almost no star formation and are highly deficient in short-lived massive stars Thus, it is unlikely that this burst was an SGR-type flare Thus, the neutron star–neutron star binary might have reached this distance before merging, even if it started from a more central location When the XRT error circle is plotted on the R-band image we obtained with the Very Large Telescope (VLT), several faint objects are seen in the error circle, some of which are extended and could be high-redshift galaxies 
 A final question to ask is: “What should I start doing, stop doing and keep on doing?” When you have collected feedback from a number of people, use your scientific know-how to look for patterns in the responses As you study and adopt new skills, be sure to close the loop by getting back to your original feedback providers Continue to monitor your progress, and celebrate your successes. Even for a career anchored in scientific excellence, mastery of a discipline only accounts for a third of what is needed for success If someone suggests that you work on your interpersonal skills, ask for specific examples to help frame a ‘before’ and ‘after’ picture If you have ever lamented your lack of budgeting experience, felt inept when negotiating a pay rise or found yourself in the political cross-fire of lab heads, then organizational savvy is the place to focus your energy If, on the other hand, you are perceived as being aloof, or you have doubts about the strength of your communication skills, then personal effectiveness is where you should focus Incorporate some of their good practice into your own repertoire Next, devise a strategy for adopting new behaviour Organizational savvy covers general business skills as well as the ability to navigate the politics of a particular work culture Personal effectiveness covers the myriad ‘soft’ skills that, left unpractised, can derail the career of even the most accomplished professional Role models are everywhere; start by observing a few Soft skills Youre a skilled researcher, steeped in the rigours of scientific enquiry and successful at your work Start by getting feedback from people who work closely with you and are familiar with your style and contributions because they can serve as honest critics Supplement these efforts with relevant coursework such as classes in active listening or budgeting for non-financial professionals You will also need organizational savvy and personal effectiveness Your career, one might assume, will be smooth sailing? Not necessarily
 Here we use radiotelemetry to show that band membership benefits these insects by greatly reducing the probability that they will become victims of predators It is likely that migratory banding has evolved because it gives substantial protection to individuals within the group. Mormon crickets and juvenile locusts form huge migratory bands — millions of individuals march in unison across the landscape and devastate vast agricultural areas, but little is known about why these bands form By contrast, we observed no mortality among individuals in the band during the same period, including among those crickets moved to control for any transportation effect (Life Table Survival analysis, Gehans generalized Wilcoxon test: P was 0.0118, 0.0047 and 0.0026 for three replicates, respectively; Fig. 2b ) In a replicated mark–recapture experiment, we compared the survival of individual mormon crickets in naturally occurring migratory bands with that of individuals transplanted from the band to nearby sites; mormon-cricket bands had previously travelled through these sites, but they were empty at the time of the experiment Individuals were located using small radiotransmitters ( Fig. 2a ), which enabled us to establish their fate with accuracy (for methods, see supplementary information ) Insects that had been translocated from the band suffered 50–60% mortality due to predation over just two days in three replicate experiments ( Fig. 2b ) Intraspecific competition in mormon-cricket bands mediates a food-stress-induced reversal of courtship roles at high population densities  Mormon crickets are also notoriously cannibalistic and likely to attack immobile conspecifics  Our results indicate that band formation confers a major anti-predator benefit, but what are the costs? Although difficult to quantify, intraspecific competition for resources is assumed to be a cost of group living and can account for group movement to exploit new resources  Predation was evident from recovered radiotransmitters that had been partially chewed ( Fig. 2a , inset) and often had body parts still attached; they were retrieved from trees and burrows, suggesting that birds and rodents are likely predators  Protection against predators through mechanisms such as enhanced early detection, predator confusion and dilution of risk (the ‘selfish herd’ effect) has been proposed to account for the evolution and maintenance of large aggregations in animals  The anti-predator benefits of migratory-band formation have previously been assumed to be negligible , but have never been quantified — largely because of the difficulty of tracking individuals within bands and the rarity of witnessing predation events  The evolution and maintenance of migratory-band formation requires the fitness benefits of group living to outweigh its costs  The mormon cricket, Anabrus simplex, is a flightless katydid , native to western North America, which forms spectacular migratory bands These can be more than 16 kilometres long and several kilometres wide, with each square metre containing dozens of insects that walk up to 2 km a day ( Fig. 1 ) They also support a general anti-predator role for outbreaks such as those in periodical cicadas, where synchronized, mass emergence reduces predation on individuals by sating local predators . Two radiotransmitters were never recovered, presumably because of predator damage or removal from our detection range We have used radiotelemetry to overcome these problems Without discounting other hypotheses , our results indicate that aggregation and constant movement protect band members from predators while reducing costs due to competition for resources and cannibalism
 Nature 436 , 677 – 680 ( 2005 ) In Fig. 4a of this Letter, in which the spectra of two BPD dimmers are compared, the scaling on the two y axes should have been shifted relative to one another in order to illustrate the point made in the text The corrected Fig. 4a is shown here.
 A flat-panel display, for example, has transistors distributed over its whole surface that switch the miniature pixels forming the image on and off A known method for promoting local crystal nucleation is to stamp a substrate with an extremely thin layer of molecules, known as a self-assembled monolayer, that is terminated by a chemical group with a particular affinity for the atoms or molecules of the desired crystal material  A viable way around the large-area problem could thus consist of providing semiconductor material only at those places that have to bear transistors An electrical potential applied at a third electrode, the gate, controls whether current is allowed over this bridge or not At the heart of every transistor is a channel of semiconductor material that bridges two electrodes Bao and colleagues have just presented us with a new baby. Because the transistors in large-area applications are distributed over the surface, a high-quality semiconductor film is in fact not required over the entire area Briseno et al . come up with an original solution to achieve precisely this Briseno et al . use a different method that is less dependent on chemical affinity But most importantly for device applications, the authors grow organic semiconductor crystals directly onto metal electrodes — forming a basic transistor — and show that these electrodes are functional after the process But other applications require transistors to be sparsely distributed over large areas, and cant afford to be limited by wafer size But the recrystallization process requires high temperatures, so, although it can be applied with success to, say, a glass substrate, it is delicate and difficult to scale the process up to an industrial level for substrates such as plastic foil that cannot withstand elevated temperatures Considerable work is still needed to turn this technique into a truly viable semiconductor technology Decades of research have been invested in improving the quality of these amorphous semiconductors to levels acceptable for the display industry Fabricating transistors with sufficient performance and high yield over large areas on foreign substrates is enormously challenging Finally, thermodynamics teaches us that many controllable parameters influence the energy barrier against the nucleation of crystals First, pure crystals of so-called conjugated molecules — organic molecules that have alternate single and double covalent bonds — are known to be pretty good semiconductors  For example, most organic semiconductors are intrinsically ambipolar , meaning that they allow the movement of both electrons and so-called holes — positive charges equivalent to the absence of an electron In particular, the control of crystal size and orientation will require further attention, as will the reproducibility and control of the quality of the electrical contacts between the semiconductor and the electrodes In the future, substrates might also include flexible and less brittle materials such as plastic foils  Instead, large-area applications use foreign, non-semiconductor substrates, such as metals, ceramics or glass, that can be manufactured as large sheets Larger screens require the distribution of transistors over larger areas, and using single-crystal semiconductor wafers as substrates is simply not economical in this case Most conventional semiconductors, including silicon, can be forced to grow as defect-free films only if the growth substrate provides a perfect template for their crystal structure On page 913 of this issue, Zhenan Bao and colleagues (Briseno et al .) describe a method for nucleating and growing single-crystal organic semiconductors over electrodes on an arbitrary substrate, and so producing extended arrays of high-performance electronic transistors One particular improvement involves recrystallizing the amorphous film into a polycrystalline film consisting of small, single-crystal grains, each with a particular crystal orientation, separated by thin boundary regions Roughness is known to increase surface energy, and the nucleation and growth of crystals can then be steered to occur selectively on the rougher areas Second, because these molecules are bound into a crystal through weak van der Waals forces, rather than through stronger covalent bonds, the energy needed to form crystals from them is moderate Silicon transistors can be processed on two very different types of substrate So far, the family of technologies for use in electronics on flexible foil has numbered thin-film organic semiconductors, thin-film metal-oxide semiconductors , and the twin silicons, amorphous and polycrystalline, among its members Such crystals can therefore be formed at low temperatures, between room temperature and a few hundred degrees Celsius, that are compatible with the processing of large-area substrates The authors show that the method can be used to grow many different semiconducting conjugated molecular crystals The first is a thin, single-crystal, nearly defect-free silicon substrate called a wafer The most successful semiconductor for such switching applications, omnipresent in todays electronics, is silicon The properties of polycrystalline materials are less ideal than those of monocrystalline materials, but are in many respects better than those of amorphous materials The single-crystal technique might, uniquely, allow devices that are difficult to realize using thin polycrystalline or amorphous films of the same materials to be integrated onto foil Their method represents a step towards practical applications of high-quality, but fragile, single crystals of organic semiconductors, and could show the way to high-performance electronic devices that extend over large and flexible surfaces Their process hinges on a unique combination of the properties of organic semiconductors and the science of crystal nucleation and growth These can be used to determine the location of the nucleation and growth of crystals on a surface These include molecules that are notoriously difficult to grow as films on substrates, such as rubrene , and some with high vapour pressure, such as anthracene, that evaporate spontaneously in the high-vacuum environments in which thin-film deposition processes are generally conducted They start by stamping an organic layer of significant roughness onto the substrate This property has been difficult to exploit with thin organic semiconductor films, and single crystals might open new avenues towards this end Transistors are minuscule switches that lie at the heart of all electronic devices — computers, memory sticks, displays, you name it Wafer-based technologies are continuously scaling to larger transistor counts and density per chip, allowing ever increasing computing power and ever higher memory density Wafers are limited in size, but can be processed in sophisticated ways to bear a mind-boggling density of nanoscale transistors: a wafer 300 millimetres in diameter can hold hundreds or thousands of chips, each one containing up to a billion transistors When deposited on an arbitrary substrate, they tend to form amorphous, defect-infested films
 Although the development of web-based tools that can recognize text-based plagiarism will eventually help detection, more can be done before that point And earlier this year, the National Natural Science Foundation of China reported that plagiarism accounted for about one-third of its misconduct cases in the past six years Copying text, even when supplying new data, is not acceptable without clear reference to the process Editors have an obligation to act if concerns are raised about improper attribution Editors should nudge investigations that drag, and draw attention to incidents where no satisfactory progress is made Human nature hasnt changed recently, but reusing with the intent to deceive seems to be on the rise, both in the literature and in grant proposals If authors do not supply satisfactory explanations, their employers and funding agencies must be notified Internet connectivity, online repositories and sophisticated search tools provide almost irresistible accessibility to the polished thoughts of others It is the responsibility of institutions, who have a legal mandate, to initiate a formal investigation Journals should proceed promptly to correct the literature where discovery of misconduct necessitates it Just how prevalent is plagiarism? At a meeting devoted to the topic at New York University last month, Alan Price of the Office of Research Integrity (ORI), which primarily handles complaints in biomedicine, reported that in the past 16 years, only 5–12% of its misconduct cases each year involved plagiarism Mentors must counter the ever-rising promotion and funding pressures that reward prolific publication rather than support creative quests Nature will play its part where necessary, as will other Nature titles Oblique reference to a method in a previous publication in an attempt to hide the papers intellectual precedents is still deceitful and a form of plagiarism On the other hand, James Kroll, head of administrative investigations at the US National Science Foundation, revealed that more than 60% of its misconduct findings concern plagiarism One duplicate figure in a paper is one too many, if attribution to the original paper or grant is not noted One might hope that such public humiliation will act as a deterrent to those inclined to pass off anothers work as their own. Plagiarized text or figures should be clearly indicated as such within the original content So they need more rigorous instruction than their predecessors regarding the ethical standards expected of them Some common-sense guidelines need stressing at the bench, long before the data or grant application are written up Students trained today have grown up in an environment where access is taken for granted and attribution only loosely enforced The evidence shows that an act of misconduct is usually part of a pattern of behaviour rather than an isolated incident, says Richard Smith, former editor of the British Medical Journal  The replacement of pen and paper with software makes it far easier to slip in large sections of text This is defined by the ORI as “the appropriation of another persons ideas, processes, results, or words without giving appropriate credit” Timeliness can be difficult if institutes are reluctant to taint their reputations with negative findings, or if international boundaries are crossed Where plagiarism is found, the authors previous publications must be examined
 AIDS 17, 1256–1258; 2003) But Ho says that the health department made the call to alert the public about the virus after consulting with the US Centers for Disease Control and Prevention in Atlanta, Georgia But others questioned whether the information released about the virus justified the public announcement But the Aaron Diamonds involvement has also drawn criticism But these viruses did not cause a widespread epidemic of HIV ‘superstrains’. “I dont think the health department needed to hang its public-health campaign on a single anecdotal virus,” says John Moore, a virologist at Weill Medical College at Cornell University in Ithaca, New York C Chan et al  Doctors at New Yorks Department of Health and Mental Hygiene believe that he developed AIDS between 2 and 20 months after he was infected; the disease usually takes about a decade to develop Ho adds that his group is presenting its data in the first available scientifically appropriate forum — the retrovirus conference. “Im saddened by people who are trying to turn this into a personal attack rather than keeping focused on the case and its public-health ramifications,” Ho says In 2003, for example, researchers in British Columbia, Canada, reported two cases of HIV that seem similar to the New York virus In December last year, a man from New York City tested positive for HIV and quickly showed signs of AIDS More data on the strain are scheduled to be released at the 12th Conference on Retroviruses and Opportunistic Infections in Boston this week Officials at the health department say that this multiple drug resistance and the rapid progression to AIDS led them to warn the public of the possible spread of the strain. “This case is a wake-up call,” the citys health commissioner Thomas Frieden told a press conference on 11 February Similar cases have been reported before, critics say, but have not led to epidemics Some have even suggested that the centre pushed for the announcement to build interest in the retrovirus conference, whose programme committee is chaired by David Ho, the Aaron Diamonds scientific director. “Theres a lot of suspicion because theres a confluence of issues, including the fact that the conference is around the corner, and David Ho is its chair,” says Richard Jefferys, basic-science project director at the New York-based Treatment Action Group Some scientists and doctors have praised the decision to publicize the case The Canadian patients were also infected with multidrug-resistant HIV that rapidly progressed to AIDS (K The health department also defended its action. “We had the necessary information and we were confident — and remain confident — that the situation was of great public-health significance,” says an official. The infected patient had unprotected sex with many men while using the drug. “My hope is that this news will bring the reality to the public, and we will see less risky behaviour,” says Jay Levy, a virologist at the University of California, San Francisco The patients virus also resists treatment by the three important classes of HIV-fighting drugs The virus is being studied by researchers at the Aaron Diamond AIDS Research Center at Rockefeller University in New York They hope that it will warn the public about the dangers of having sex while under the influence of the drug crystal methamphetamine, or crystal meth W Washington A decision by New York health officials to announce the detection of an unusually aggressive case of AIDS has led to criticism from some researchers and activists
 A functional mRNA polyadenylation signal is required for transcription termination by RNA polymerase II Genes Dev. 2, 440–452 (1988). In this Letter to Nature , reference 5 should be: Connelly, S L Manley, J Nature 432 , 517 – 522 ( 2004 )
 Although a number of microRNAs have been isolated from the mammalian brain, neither the specific microRNAs that regulate synapse function nor their target mRNAs have been identified Exposure of neurons to extracellular stimuli such as brain-derived neurotrophic factor relieves miR-134 inhibition of Limk1 translation and in this way may contribute to synaptic development, maturation and/or plasticity. Here we show that a brain-specific microRNA, miR-134 , is localized to the synapto-dendritic compartment of rat hippocampal neurons and negatively regulates the size of dendritic spines—postsynaptic sites of excitatory synaptic transmission In the mammalian nervous system, the spatiotemporal control of mRNA translation has an important role in synaptic development and plasticity MicroRNAs are small, non-coding RNAs that control the translation of target messenger RNAs, thereby regulating critical aspects of plant and animal development This effect is mediated by miR-134 inhibition of the translation of an mRNA encoding a protein kinase, Limk1 , that controls spine development All other steps were the same as for mRNAs Annealed 3′-end labelled (Alexa-546) sense and unmodified antisense strands of miR-134 ( IBA ) were used at 100 ng µl -1  At least 20 dendrites per experimental condition of a total of three independent experiments were measured At least ten individual neurons were measured for each experimental condition Cell culture, transfection and stimulation Cultures of dissociated primary cortical and hippocampal neurons were prepared as described  Cells were imaged 20 min after injection, and randomly selected images were analysed by three independent observers in a blind manner Coupled oligonucleotides were heated at 65 °C for 15 min before adding to cells at the indicated concentrations for 4 h For BDNF stimulation, neurons were starved overnight in the presence of UO126 (1 µM) and then treated with BDNF ( Preprotech , 100 ng ml -1 ) for 4 h before cell harvest For Limk1 expression constructs, the Limk1 cDNA (gift of K For northern blots, 30 µg of total RNA was resolved on 15% urea/polyacrylamide gels and transferred to Hybond N + membrane ( Amersham ) For radio-immunoprecipitation, a mouse monoclonal anti-Limk1 antibody ( Pharmingen ) was used For Sholl analysis, a series of concentric circles of 10-µm increments was manually drawn around the cell body, and the number of dendritic intersections at each individual circle was counted For the detection of small RNAs, a digoxigenin tail was added to antisense-locked nucleic acid (LNA) oligonucleotides ( Exiqon ) with the DIG tailing kit ( Roche ) For the miR-134 expression construct, a genomic sequence spanning 150 base pairs 3′and 5′ of the miR-134 sequence ( Supplementary Fig Hippocampal neurons were maintained in Neurobasal plus B27 supplement; cortical neurons in Basal Medium Eagle plus 5% FBS Image analysis For spine analysis, neurons were transfected at 8 DIV or 15 DIV with indicated expression plasmids in combination with EGFP and processed for confocal microscopy at 18 DIV Immunocytochemistry Hippocampal neurons (18 DIV) were immunostained as described , using a mouse monoclonal anti-Limk1 ( Pharmingen ) or a rabbit anti-synapsin ( Chemicon ) antibody as primary antibody In situ hybridization In situ hybridization of endogenous mRNAs and GFP reporter mRNAs was as described  Limk1 RNA was labelled by in vitro transcription in the presence of Alexa-488-5′ UTP ( Molecular Probes ) and used at 200 ng µl -1  Luciferase assay Cortical neurons were transfected at 4 DIV or 12 DIV, and luciferase assays were performed 2 days later with the Dual-Luciferase Reporter Assay System ( Promega ). Methods DNA constructs The rat Limk1 3′ UTR (1,171 base pairs) was amplified by polymerase chain reaction (PCR) from rat brain cDNA (P15) Microinjection Mature hippocampal neurons were microinjected using an AIS2 microinjection system ( Cellbiology Trading ) attached to a Zeiss Axiovert 200M  Microinjection needles with a tip size between 0.2 and 0.3 µm were used ( P-87 , Sutter Instruments ) with a holding pressure of 40 hPa and an injection pressure of 80 hPa Mizuno) was cloned into pcDNA3 ( Promega ) together with rat Limk1 3′ UTR (wild type or m191) Mutation of the miR-134 binding site (m191) was achieved using the Quick Change site directed mutagenesis kit ( Stratagene ) Neuronal transfections were performed with LipofectAmine 2000 ( Invitrogen ) Neurons were harvested for western analysis 48 h after transduction Northern blotting and RNase protection assays RNA was isolated from synaptoneurosomes or cultured neurons by phenol/chloroform extraction using RNA Stat-60 ( Tel-Test ) PCR products were cloned into pGL3 basic ( Promega ), pBSK ( Stratagene ) or myr-d1GFP (gift of B Penetratin (80 µm, Qbiogene ) was added and the mixture was incubated at 65 °C followed by 1 h at 37 °C Peptide-mediated delivery Double-stranded small RNA or 2′-O-methylated DNA oligonucleotides containing a 5′ thiol group (80 µm, IDT) were reduced with TCEP (80 µm, Sigma ) at room temperature for 15 min Preparation of synaptoneurosomes and radio-immunoprecipitation Synaptoneurosomes were prepared from P15 long-Evans rat pups (Charles River) as described  Quantitative real-time PCR Quantitative real-time PCR was performed on a Taq-Man ( Perkin Elmer Life Sciences ) using the SYBR-green-containing PCR kit ( PE Applied Biosystems ) as described  RNase protection assays were performed with the mirVana miRNA detection kit ( Ambion ) as per the manufacturers recommendations S1c ) was PCR-amplified and cloned into pcDNA3 Sabatini) for constructs used in luciferase assay, in vitro transcription, or local reporter assay, respectively See Supplementary Information for further details See Supplementary Information for further details See Supplementary Information for further details on spine analysis Tailed LNA oligonucleotides were purified and used for overnight hybridization at 42 °C The obtained values were background corrected and normalized to the respective signal in the red channel To quantify dendritic GFP levels in the local reporter assay, random dendrites were selected based on dsRed staining and plot profiles of the GFP intensity of the same dendrites were derived using ImageJ (NIH) A future challenge will be to identify the full complement of dendritic miRNAs as well as their target mRNAs, and to determine their role in synaptic development. A number of miRNAs have been isolated from the vertebrate nervous system , and a recent study has demonstrated a crucial role for the miRNA pathway in early zebrafish brain development  A potential role for miRNAs in synaptic function is particularly intriguing given the evidence that selected mRNAs in neurons are transported to sites of synaptic contact that are quite distant from the cell body  A recent bioinformatics approach predicted several additional neuronal mRNAs that may also represent miR-134 targets  A similar developmental expression profile was also observed in dissociated hippocampal neurons that were allowed to mature over time in culture ( Fig. 1c ) A similar reduction in dendritic spine size was observed when synthetic miR-134 was introduced into neurons at a later stage (15 DIV) and for shorter times (72 h, Supplementary Fig. 3d ) A substantial fraction of the dendritic miR-134 was found to partially co-localize with synapsin immunostaining, indicating that miR-134 is present near synaptic sites on dendrites ( Fig. 1d , lower panel and inset at higher magnification) Alternatively, miR-134 function in neurons was suppressed by introducing a 2′-O-methylated antisense oligonucleotide that interferes with endogenous miR-134 activity in a sequence-specific manner  Although these studies provide evidence that miR-134 acts to repress Limk1 mRNA translation, they do not distinguish whether the inhibition occurs within the cell body and/or dendrites Among these potential miR-134 target mRNAs, Limk1 was of particular interest An analysis of dendritic spines in cultured hippocampal neurons (cultured for a total of 18 days, transfected at day 8: 8 + 10 days in vitro (DIV)) overexpressing miR-134 showed a significantly decreased spine volume as compared to the spines of neurons transfected with empty vector or overexpressing the unrelated let-7c miRNA ( Fig. 2a (bottom panel), b (bottom panel), e and Supplementary Fig. 3a–c ) As BDNF promotes dendritic spine growth and regulates synaptic function, at least in part, by activating dendritic protein synthesis , we reasoned that mRNAs for which translation is regulated by BDNF might also represent miR-134 targets BDNF treatment did not lead to a further increase in the expression of the m191 reporter gene BDNF treatment significantly increased synthesis of Limk1 protein within isolated synaptoneurosomes as indicated by an increase in 35 S-methionine-labelled protein in Limk1 immunoprecipitates Because hippocampal neurons at 15 DIV have already developed the vast majority of their spines, these findings suggest that miR-134 may perturb the morphology of pre-existing spines Biochemical and genetic studies have revealed important functions for specific miRNAs in a variety of cellular processes, including differentiation, apoptosis and metabolism  Both Limk1 constructs had no effect on dendritic spine length ( Fig. 5a , lower right) Both miR-134 and the Limk1 3′ UTR, in contrast to the non-dendritic Gapdh and histone H3 mRNAs, were found to be present within dendrites in a granular pattern ( Fig. 3b , upper two panels and data not shown) Both northern blotting and an RNase protection assay (RPA) revealed that the expression of microRNA-134 (miR-134) is restricted to the brain, similar to the expression pattern of the previously characterized miR-124a ( Fig. 1a and Supplementary Fig. 1a, b ) By contrast, an antisense oligonucleotide directed against let-7c (2′-O-Me-let-7c) had no effect on Limk1 reporter gene activity Consistent with this idea, we found that the m191 mutant Limk1 mRNA efficiently rescued both the spine volume and width decrease imposed by miR-134 overexpression, whereas the wild-type Limk1 mRNA was not as effective at rescuing the decrease in spine volume and width ( Fig. 5a , upper and lower left panels) Dendritic spines are actin-rich protrusions from the dendritic shaft and represent the major sites of excitatory synaptic contact  Discussion We have identified a dendritically localized miRNA that regulates the expression of the synaptic Limk1 protein, thereby controlling dendritic spine size During their transport and once they have arrived at synaptic sites, the translation of dendritic mRNAs may be suppressed until extracellular factors such as those released upon synaptic stimulation activate the translation of these dormant mRNAs  Expression analysis also supports a role for miRNAs in later stages of neuronal maturation and synapse development  Expression of the m191 luciferase reporter mRNA was derepressed relative to the wild-type reporter in the absence of BDNF treatment, presumably due to the failure of endogenous miR-134 to bind to the m191 reporter gene ( Fig. 6b ) Fluorescently labelled miR-134 was introduced into hippocampal neurons by micro-injection together with a fluorescent Limk1 3′ UTR that contains the miR-134 binding site For this analysis, we focused on a set of 48 genes that we recently identified in a screen for mRNAs for which translation is enhanced in neurons upon treatment with BDNF  Further analysis revealed that this decrease in spine volume was mainly a consequence of a reduction in spine width (- 16.9 ± 5.8%, n = 3, P = 0.02) as opposed to a change in spine length (- 3.5 ± 7.1%, n = 3, P = 0.23, Fig. 2f ) Furthermore, efficient co-localization of miR-134 and Limk1 mRNA required the presence of an intact miR-134 binding site within the Limk1 3′ UTR ( Fig. 3b , bar graph) GFP expression was monitored by confocal microscopy, and the intensity of the GFP signal was determined in the dendrites of many neurons at varying distances from the cell body ( Fig. 4e ) Given that BDNF has important roles at multiple steps of synaptic development , it is possible that miR-134 regulates distinct sets of target genes involved in the formation, maturation or plasticity of synapses Given the dendritic localization of endogenous Limk1 mRNA and miR-134, these findings suggest that miR-134 partially inhibits Limk1 mRNA translation locally within dendrites. miR-134 regulates spine size through Limk1 Because both overexpression of miR-134 and disruption of Limk1 function lead to decreased spine size , we next investigated whether miR-134-mediated repression of Limk1 mRNA translation might be an explanation for the observed reduction in dendritic spine size upon miR-134 overexpression Highly orchestrated programmes of gene expression act to shape the developing nervous system However, the observation that there is still residual BDNF induction of reporter mRNA translation when miR-134 cannot bind to the Limk1 3′ UTR suggests an involvement of additional miR-134-independent mechanism(s) in BDNF-induced Limk1 translation Immunohistochemistry revealed that in neurons, overexpressed Limk1 protein was targeted to synaptic sites within spines ( Fig. 5c ), consistent with the possibility that an increased level of Limk1 protein within spines might be responsible for the rescue of the spine morphology phenotype In addition to miR-134, other neuronal miRNAs have been predicted to bind the Limk1 3′ UTR  In addition, the observed difference between the effect of the wild-type and m191 mutant Limk1 mRNA on spine width was not due to intrinsic differences in the ability of the two mRNAs to be translated, because in the absence of miR-134, Limk1 protein levels were equivalent in 293Tcells transfected with the wild-type and mutant Limk1 constructs ( Fig. 5b ) In contrast to the effect of miR-134 overexpression, sequence-specific inhibition of endogenous miR-134 function using a 2′-O-methylated antisense oligonucleotide (2′-O-Me-134) led to small but statistically significant increases in spine volume and width (7.6 ± 3.7%, n = 3, P = 0.03) when compared to neurons transfected with an unrelated 2′-O-Me-control oligonucleotide ( Fig. 2c (bottom panel), d (bottom panel), e, f) In contrast to the effect on Limk1 mRNA translation, mutation of the miR-134 binding site did not affect dendritic targeting of a Gfp – Limk1 reporter RNA ( Supplementary Fig. 5c ) In contrast, co-expression of the wild-type Limk1 mRNA, which is still subject to miR-134-mediated translational inhibition, might be expected to prove less effective in the rescue of the dendritic spine phenotype caused by miR-134 overexpression In mammalian cells, miRNAs are thought to regulate the expression of target mRNAs predominantly through the inhibition of productive translation  In support of this idea, miR-134 overexpression in both 293T cells and primary neurons was found to decrease specifically the activity of a luciferase reporter gene fused to the wild-type Limk1 3′ UTR, whereas expression of the unrelated let-7c miRNA had no significant effect on the expression of this reporter construct ( Fig. 4a and Supplementary Fig. 6a, b ) In the absence of synaptic activity, miR-134 may recruit a silencing complex that has a key role in repressing Limk1 mRNA translation Instead, we speculate that BDNF alters the activity of other translational regulators within the miR-134-containing complex It is tempting to speculate that miRNAs act locally at individual synapses, thereby contributing to synapse-specific modifications that occur during synaptic plasticity Limk1 regulates actin filament dynamics through inhibition of ADF/cofilin , and Limk1 knockout mice show abnormalities in dendritic spine structure similar to those observed upon miR-134 overexpression  Local translation of these previously dormant mRNAs has been hypothesized to have a key role in synaptic development and plasticity  MicroRNAs (miRNAs) act by binding to target mRNAs and initiating either cleavage or a reduction in the translational efficiency of the target mRNA, depending on the degree of sequence complementarity  Moreover, membrane depolarization of cortical neurons induced a significant increase in the level of the miR-134 precursor ( Supplementary Fig. 1c ) Moreover, miR-134- and Limk1 3′ UTR-positive granules were co-localized within dendrites ( Fig. 3b , lower panel) Neither miR-134 overexpression nor the use of 2′-O-methylated oligonucleotides had any measurable effect on spine density or overall dendritic complexity ( Supplementary Fig. 3e, f ) No significant effects on spine length were observed in the presence of 2′-O-Me-134 (2.6 ± 5.6%, n = 3, P = 0.25) Our preliminary finding that miR-134 moves to the polysome-associated mRNA pool upon BDNF stimulation (G.S. and M.E.G., unpublished observations) suggests that miR-134 itself may not dissociate from the Limk1 mRNA upon exposure of neurons to BDNF Peptide-mediated delivery of miR-134 into neurons led to a dose-dependent decrease in the level of endogenous Limk1 protein, whereas delivery of its inhibitor 2′-O-Me-134 led to an increase in protein level ( Fig. 4c , d ), suggesting that miR-134 inhibits translation of the endogenous Limk1 mRNA Quantification of the two signal intensities (miR-134-specific versus the mismatch probe) along the length of multiple dendrites confirmed significantly higher levels of miR-134-specific signal within dendrites as compared to that obtained with the mismatch control ( Supplementary Fig. 1e ) or the U6 small nuclear (sn)RNA (data not shown) Results from a previous study using a similar construct demonstrated that GFP expressed from the reporter gene allows for the study of local protein synthesis within intact dendrites  Taken together, these data suggest that endogenous miR-134 inhibits Limk1 mRNA translation in neurons by binding to a single site present in the Limk1 3′ UTR Taken together, these results suggest that Limk1 is a downstream effector of miR-134 in the control of dendritic spine development. miR-134 functions in BDNF-stimulated Limk1 synthesis Dendritic mRNAs are transported to the synapto-dendritic compartment within RNA granules Taken together, these results suggested a potential role for miR-134 in dendritic and/or synaptic development The dendritic localization of endogenous Limk1 mRNA was further confirmed by ISH in cultured neurons and by subcellular fractionation ( Supplementary Fig. 5a, b ) The discovery of small, non-coding RNAs has greatly expanded our understanding of the cellular mechanisms that regulate gene expression at the post-transcriptional level The effect of miR-134 on translation of the luciferase mRNA is dependent on the presence of the miR-134 cognate binding site within the 3′ UTR, as expression of a luciferase reporter containing the mutant m191 Limk1 3′ UTR (that is, with a mutated miR-134 binding site) was unaffected by the presence of exogenous miR-134 ( Fig. 4a , white bars) The efficacy of these approaches was confirmed in neurons using a previously described miRNA sensor assay ( Supplementary Fig. 2b )  The inhibition of endogenous miR-134 in neurons by 2′-O-Me-134 led to a statistically significant increase in the expression of the luciferase reporter fused to the wild-type Limk1 3′ UTR ( Fig. 4b , black bars), but had no significant effect on expression of the m191 mutant reporter that is incapable of binding miR-134 ( Fig. 4b , white bars) The myr-d1GFP reporter was fused to either wild-type or m191 mutant Limk1 3′ UTR and introduced into hippocampal neurons The presence of miR-134 in synaptic compartments was also corroborated by subcellular fractionation experiments; miR-134 was enriched in synaptoneurosome preparations ( Fig. 1e ), which represent membrane preparations highly enriched for synaptic terminals  The presence of miR-134 within dendrites near synapses suggested a possible functional role for this miRNA at post-synaptic sites. miR-134 regulates dendritic spine morphology To investigate a possible function of miR-134 at the synapse, we examined the effects of modulating miR-134 activity on dendritic spine development The size of dendritic spines is a good correlate of the strength of excitatory synapses  The steady-state levels of the reporter gene mRNA were unaffected by miR-134 overexpression, suggesting that the observed effect of miR-134 on luciferase expression does not reflect a change in the stability of the luciferase mRNA ( Supplementary Fig. 6c ) Therefore, the combinatorial action of multiple miRNAs on the Limk1 3′ UTR might explain our observation that miR-134 only partially inhibits Limk1 mRNA translation ( Fig. 4 ) These findings suggest that miR-134 represses Limk1 mRNA translation and that BDNF treatment relieves this repression This analysis revealed that the average expression of the wild-type Limk1 reporter was significantly reduced (by 18–28%) along the entire length of the dendrites compared to that of the m191 reporter ( Fig. 4f ) This increase was sensitive to treatment with rapamycin, an inhibitor of the mTOR kinase pathway, which we and others have shown to mediate BDNF signalling to the translational machinery ( Fig. 6a )  This then limits the synthesis of new Limk1 protein and restricts the growth of dendritic spines This tight regulation is mediated by a variety of transcriptional and post-transcriptional events that control the expression of individual gene products  Three of the BDNF-regulated mRNAs (discs large homologue 2 ( DLG2 ), Neurod2 and Lim-domain-containing protein kinase 1 ( Limk1 )) were found to contain conserved 3′ UTR sequence elements that were partially complementary to mouse miR-134 ( Fig. 3a and data not shown) To achieve miR-134 overexpression, we designed a vector that permits efficient expression of exogenous miR-134 ( Supplementary Fig. 2a ) To address this issue, we generated a GFP-based protein synthesis reporter ( myr-d1Gfp ) with limited diffusion and a shortened half-life (1 h) To investigate the effect of miR-134 on BDNF-induced Limk1 translation more directly, we introduced synthetic miR-134 into neurons that express little endogenous miR-134 (4 DIV, Fig. 1c ) Towards this end, synaptoneurosomes prepared from P15 rat brain were incubated with 35 S-methionine to label newly synthesized proteins, and the amount of newly synthesized Limk1 protein was monitored by radio-immunoprecipitation Towards this end, we examined the effect of BDNF treatment on the translation of a Limk1 3′ UTR luciferase reporter mRNA in neurons at a time when endogenous miR-134 is highly expressed (14 DIV) Towards this end, we expressed miR-134 in hippocampal neurons together with constructs expressing either a wild-type Limk1 mRNA or mutant m191 Limk1 mRNA, and monitored dendritic spine size ( Fig. 5a ) Towards this end, we scanned the 3′ untranslated regions (UTRs) of mRNAs for potential miR-134 binding sites Unlike miR-124a, however, miR-134 levels in the hippocampus gradually increase with development, reaching maximum levels at postnatal day 13 (P13), the time at which synaptic maturation occurs ( Fig. 1b ) Unlike the mismatch control probe, hybridization with the miR-134-specific probe revealed the presence of miR-134 within dendrites, where it is present in a punctate pattern ( Fig. 1d and Supplementary Fig. 1d ) Upon synaptic stimulation, the release of BDNF may trigger activation of the TrkB/mTOR signalling pathway, which inactivates the miR-134-associated silencing complex by an as-yet-unknown mechanism, leading to enhanced Limk1 protein synthesis and spine growth Using an electrophoretic mobility shift assay, we demonstrated that Limk1 mRNA and miR-134 interact in vitro ( Supplementary Fig. 4 ) We asked whether the suppression of Limk1 translation by miR-134 is relieved by extracellular stimuli such as BDNF We conclude that miR-134 acts as a negative regulator of dendritic spine volume in hippocampal neurons, raising the possibility that miR-134 may be involved in the regulation of synapse development and/or function. miR-134 inhibits translation of Limk1 mRNA To gain insight into the mechanisms by which miR-134 regulates dendritic spine morphology, we sought to identify miR-134 target mRNAs We first assessed whether the translation of Limk1 mRNA is regulated by BDNF We found that miR-134 partially interferes with BDNF induction of the wild-type, but not the m191 mutant, reporter mRNA ( Fig. 6c ) We hypothesize that the association of Limk1 mRNA with miR-134 keeps the Limk1 mRNA in a dormant state while it is being transported within dendrites to synaptic sites ( Fig. 6d ) We next asked whether the ability of BDNF to induce Limk1 mRNA translation reflects the ability of BDNF to relieve miR-134-dependent repression of Limk1 translation We next determined whether the Limk1 mRNA co-localized with miR-134 within dendrites of live neurons We propose that miRNA regulation of the translation of a variety of neuronal mRNAs will be found to contribute in an important way to synaptic function  We reasoned that if the effect of miR-134 on spine morphology occurs through suppression of endogenous Limk1 mRNA translation, ectopically expressed Limk1 mRNA that is incapable of interacting with miR-134 (m191) should be able to rescue the spine defect We therefore hypothesized that miR-134 binding to the Limk1 mRNA might act to inhibit Limk1 translation We used an in situ hybridization (ISH) protocol to examine the subcellular localization of the miR-134 RNA within cultured hippocampal neurons When cells were transfected with luciferase mRNA fused to the wild-type Limk1 3′ UTR, BDNF led to a statistically significant induction of translation of the reporter mRNA ( Fig. 6b ) Whether miRNAs might inhibit the translation of synaptically localized mRNAs in neurons until their translation is activated by neurotrophic factors or neuronal activity remains to be investigated. miR-134 expression during synapse development To identify miRNAs that might function in dendritic and/or synaptic development, we investigated the expression and localization of candidate miRNAs that had been previously isolated from mouse brain  Within dendrites, and at synapses, the translation of these mRNAs may be inhibited until neurons are exposed to appropriate extracellular stimuli such as a neurotrophic factor (for example, brain-derived neurotrophic factor (BDNF)) or neurotransmitter release at the synapse
 According to Granger Morgan, a technology policy expert at Carnegie Mellon University in Pittsburgh and chairman of the EPA science advisory board, the agency needs to prepare better plans for specific emergency situations, so that it can respond appropriately After the terrorist attacks of 11 September 2001, the US Environmental Protection Agency (EPA) took some flak for declaring, perhaps prematurely, that the air was safe in the vicinity of the World Trade Center in New York All of this has been done within the agencys existing and rather overstretched budget As the EPAs own inspector-general declared in 2003: “EPA needs to be prepared to assert its opinion and judgment on matters that impact human health and the environment, regardless of who else is involved or may share responsibility But the public deserves much more than statements such as one issued on 17 September, to the effect that neither the EPA nor the Centers for Disease Control and Prevention in Atlanta, Georgia, will come forward to offer any guidance on the reinhabitation of New Orleans For what was once the worlds foremost environmental agency, this simply isnt good enough Hundreds of measurements have been carefully posted on its website ( http://www.epa.gov/katrina ) It has more than 1,000 employees working in the ravaged track of the storm, and is doing its best to advise members of public about how best to protect themselves from contaminants It is saying nothing on the advisability of returning to the ruined city, arguing instead that its job is just to run tests and pass on data to local officials, who will make of them what they will Levels of metals or pesticides in the sediment left behind as the floodwater receded are being compared with exposures that are safe for a few days, or even less Members of the science advisory board are unhappy with the tests that were carried out in the first days, when the city was still under water Most of the data currently being collected by the agency on the ground in New Orleans pertain only to short-term risks Naturally, the political pressure to repopulate the area is intense Now the agency, which is charged with protecting public health and the environment, is abdicating its responsibility to issue clear public guidance on possible health hazards in New Orleans, flooded last month by Hurricane Katrina People are moving back into New Orleans now, pushing their way into mud-caked buildings, sleeping in rotting, oily houses, and scrubbing mould off the walls without wearing protection — or, in at least one case, with respirators gamely strapped on upside-down People who want to find out whether the levels of contaminants near their homes are dangerous in the longer term will have to do their own research Tests were done for many regulated chemicals, but those for more obvious threats, such as disease-causing microbes, were not The agency can hardly be accused of sitting around twiddling its thumbs in New Orleans The EPAs own scientific advisory board, as well as the usual welter of environmental groups, are rightly calling on the agency to do its job properly, and give the American people more solid information about the environmental risks posed by episodes such as the flooding after Hurricane Katrina (see Advisers knock Katrina health tests ) There is nothing to suggest that the city should be declared uninhabitable Ultimately, the public, Congress, and others expect EPA to monitor and resolve environmental issues.” In the wake of Katrina, the need for the agency to fulfil that role is clearer than ever.
 Although this much charge is adequate for many proposed applications , other groups in Britain, the United States and Japan are working with considerable success to stabilize the energy gain at higher charge levels using more precise control of the laser and gas conditions But further simulations seemed to imply that radiation pressure from the standing field pattern produced with a single counter-propagating secondary laser could be sufficient But simulations indicated that it was the second lasers wake, rather than its radiation pressure, that caused injection  But thanks to work such as that of Faure and colleagues , the widespread use of compact plasma accelerators for medicine, industry and research may be much closer than we think. But when a second pulse is added, propagating in the opposite direction to the first, a temporary standing wave is formed with fixed maxima and minima, known as antinodes and nodes ( Fig. 2 ) Catching these waves by paddling would have been impossible without becoming caught up in the waves white water ( Fig. 1 ) Faure and colleagues advance is to stabilize the energy gain of the accelerator by introducing an equivalent of a jet ski for the electrons In the early 1990s, off the north shore of Maui, Hawaii, Laird Hamilton and Buzzy Kerbox invented the sport of tow-in surfing, using jet skis to propel themselves into particularly large or fast waves Instead, they just oscillate back and forth, as do water molecules in an ocean wave far from the beach Interestingly, they succeed with the simplest of the schemes proposed so far It is indeed this last and simplest scheme that has worked to such positive effect It was thought that two lasers of frequencies differing by an amount matched to the resonant frequency of electrons in the plasma would be needed to create a slow plasma wave that would push electrons into the main wake Monoenergetic beams of ions have now been produced by laser irradiation of specially designed foil targets , rather than of gaseous targets as used for electron production Much in the manner of a speedboat passing through water, this pulse creates a wake as it displaces plasma electrons from its path On page 737 of this issue, Faure and colleagues describe a similar technique to inject electrons into a plasma wave created in the wake of a propagating laser pulse Remarkably, the resulting electron beams are almost monoenergetic Several groups have attempted variations on the original idea, but Faure et al . are the first to demonstrate high-quality beam injection That distance is nearly 1,000 times shorter than the length of a comparable conventional accelerator driven by radio-frequency waves That energy frontier is still a long way off for laser-plasma technology The approach does have limitations The authors result is an improvement on the principle of the laser wakefield accelerator, which was used in 2004 to produce electron beams of a single defined energy  The charge that can be accelerated in a single bunch amounts to just tens of picocoulombs, which is ten times less than the quantities typically accelerated without a stabilizing second laser The end result is a compact electron accelerator of astonishing stability that could one day find applications in fields from radiation therapy to radiography and femtosecond chemistry The first idea was to cross two lasers at 90° and use the transverse radiation pressure of the second laser to inject electrons into the main lasers wake The large electric forces associated with the wake capture white-water electrons and accelerate them to energies of up to 200 megaelectronvolts (MeV) over a distance of just 2 mm The laser wakefield accelerator works by first using a single intense laser pulse to ionize a passive gas such as helium, forming a plasma of charged electrons and ions The location of the overlap of the two lasers determines where along the plasma axis electrons first catch the wave, so the length of their ride, and hence their energy gain, can be easily controlled by adjusting the timing between the two lasers The radiation pressure caused by the momentum of the light pushes electrons at the antinodes of the standing wave towards the nodes The rapidity with which barriers have continued to fall in the two years since the breakthrough for monoenergetic acceleration of electrons in laser wakefields is astounding The result is a high-quality electron beam with a single, well-defined energy that can be varied from 50 to 250 MeV The simultaneous use of counter-propagating and co-propagating secondary lasers for injection was then proposed  The wake can gain such a large amplitude that it breaks, forming the plasma equivalent of white water — electrons that move with the wave, rather than just supporting it as it propagates They are also of high quality in the sense that their emittance, a quantity associated with a beams angular divergence, is small This idea of using a second laser pulse to slingshot electrons into a plasma wake dates back to 1996 (ref. 6 ) — not long after Hamilton and Kerbox were experimenting with jet skis to sling themselves into ocean waves This means that no plasma electrons move fast enough to ride the waves This slight extra push is enough to force some electrons into the wake of the first laser, where they become surfers at nearly the speed of light This takes the form of a second laser beam that controls precisely the way the electrons surf the plasma wave To achieve this result, the authors first adjusted the parameters of the plasma and initial laser pulse to keep the amplitude of the plasma waves just below the threshold for wave breaking Until the latest work, however, the beams produced by a laser wakefield accelerator were not stable: small changes in laser or gas conditions could lead to variations in the final beam energy of as much as 50% Work is also progressing towards showing that the plasma mechanisms can be scaled to higher energies , and particularly to the stringent requirements of a high-energy collider
 In 2000, the USNational Institute of General Medical Science in Bethesda, Maryland, launched an initiative to determine the structures of about 10,000 proteins representing different structural (‘fold’) families over the next decade L.B. One of several participating centres is the Genomics Institute of the Novartis Research Foundation in San Diego, a member of the Joint Center for Structural Genomics (JCSG) Scott Lesley (pictured below, left), who heads the institutes proteomics unit, says his group has processed 50,000 protein samples from more than 20,000 unique expression clones Similar efforts are underway in other countries Structural genomics, or structural proteomics, aims to provide three-dimensional information for all proteins Such pathways include using different expression systems (vectors and cells), making point mutations in the cDNA to increase the likelihood it will be expressed, and trying different tags. “All the bacterial expression and purification is done in parallel and the majority is automated by custom instrumentation,” says Lesley The JCSG has already deposited 239 structures in the protein database — mainly from the bacterium Thermotoga maritima , the mouse, and the yeast Saccharomyces cerevisiae — representing at least 19 new fold families. “Most of the tools are in place, and we can increase both output and success rate by implementing salvage approaches in high throughput,” says Lesley The pipeline starts with a small screen protocol that uses samples in a 96-well format to evaluate how the targets behave at different steps in the procedure. “Those that are not behaving well after expression, purification or crystalization are set aside and then run through one of several salvage pathways,” says Lesley The Protein Structure Factory in Germany, an initiative of the German Human Genome Project and structural biologists from the Berlin area, targets human proteins for structure determination. “Our current focus is to determine the structures of particular protein–protein or protein–ligand complexes,” says Christoph Scheich of the Max Planck Institute for Molecular Genetics in Berlin The studies will result in a public resource linking amino-acid sequence, structural and functional information, eventually allowing scientists to make the three-dimensional atomic structures of most proteins easily obtainable from their corresponding sequences The targets that perform well are applied to a large-scale purification protocol to yield 10–20 mg of protein There are structural proteomics projects in both the public and private sectors around the world, including Germany, Japan and the United States This information can be used to ascribe function to a protein and to reveal or invalidate drug targets
 A big jump in development is needed A few recommendations Although my knowledge of the situation in Muslim nations is based on my personal experience in the region, I would not dare to make such negative statements on my own were they not confirmed by Muslim scientists According to a 2004 report by the Gulf Centre for Strategic Studies in Cairo, each year the Arab countries lose 50% of their newly qualified physicians, 23% of engineers and 15% of scientists, mainly to Britain, the United States and Canada  According to a series of highly self-critical reports assembled by Arab scholars, and released by the United Nations , countries in the Arab world are finding it hard to improve the situation After many discussions with people from the region — scientists, administrators and politicians — my main message would be that unless drastic changes occur, it will fall further behind the rest of the world, despite its great culture, its human capabilities and its relative wealth An excessively bureaucratic system often stifles innovation An outstanding example is CERN, which helped to bring together European states after the Second World War And there are pronounced differences between the 57 Islamic countries that make up the Organization of the Islamic Conference (OIC) that are discussed in more detail elsewhere in this issue Another factor is poor integration within the international scientific community As commentators from that region have noted , they continue to fall behind not only the developed countries in the West but also emerging nations in east Asia At an Arab League summit of 22 nations in Khartoum, Sudan, in March, members agreed to collaborate more closely to increase science funding and encourage public–private research partnerships Because of my experience with CERN, I was asked to chair the SESAME council, the governing body of the organization Believing that oil money can simply buy Western technology, wealthy Arab states do little beyond consuming science and technology products Both carried out their research outside Islamic countries Building scientific infrastructure from the ground up is important for establishing procedures of competitive evaluation and for learning how to set priorities But there is not enough time to repeat the European experiment in the Islamic world But to flourish, science and technology need a cultural base that can only be acquired by science education and by undertaking research programmes Can a similar leap forward occur in the Muslim world? Lack of funding is a major obstacle but not the only reason for the appalling status of science in the wider Muslim world Certainly for poorer nations, lack of resources is a problem, and they may view science as a luxury they cannot afford Excellence in scientific research can only truly be achieved by competing at the international level Finally, science can be an excellent tool for building trust and promoting peace First, the importance of research in contributing to the overall welfare of Muslim societies needs to be recognized, which in the short term will require a return to patronage at a high political level Governments mostly exacerbate the problems of low investment because they lack the strategies to foster science and to prioritize research projects He suggested that the increasing revenues from oil production should be used to fund science and technology development How to leap forward? Above all, the mentality of political leaders must change to show more of a commitment to science If Muslim countries were to follow a similarly slow path to modernization, they would be doomed to insignificance in the global economy In 2000, under the auspices of UNESCO (the United Nations Educational, Scientific and Cultural Organization), an international laboratory for synchrotron radiation for the Middle East and the Mediterranean regions, SESAME, was founded to promote science and technology in the region, to improve international cooperation and to bring nations together in peace In addition, some 45% of Arab students studying abroad do not go back to their countries after graduating In general, there was a shift, starting around 1100, from a rational and tolerant attitude to a more conservative school of thinking that denounced philosophy and rationalism In May 2002, the OICs Standing Committee on Scientific and Technological Cooperation (COMSTECH) proposed that the Islamic Development Bank come forward with at least US$1 million annually to upgrade some selected research institutes In short, not all of the criticisms or recommendations expressed here can be applied to every Muslim nation In the case of SESAME, Israelis and Palestinians, Turks and Cypriots sit around the same table with colleagues from other countries discussing their common problems peacefully In the meantime, the Arab world is suffering an emigration of intellectuals to the West In the past decade, Taiwan and South Korea have shown a breathtaking expansion of science and technology coupled with rapid economic growth Inward investment is crucial because the infrastructure for research within individual countries is meagre and legal frameworks for innovation are largely non-existent It is difficult to convince sponsors from other parts of the world to help the Muslim world if their own efforts are not stronger Many proposals have been made by individual Muslim leaders or organizations to support science and technology Many reasons have been given for the unsatisfactory situation in science and technology at present — including conflicts and economic sanctions — but no excuses will help Muslim science had a golden age between the eighth and thirteenth centuries (see The golden age , and timeline, page 23 ) and then declined National networks for research, including better electronic communication systems, can greatly improve cooperation between scientists Nevertheless, all Islamic countries can do more to support science and technology Nowadays, knowledge has become a major driving force of world economics Omar Hassan al-Bashir, president of Sudan, opened the summit with a call to put science at the heart of nations strategic plans One of the biggest challenges facing Muslim countries is that science is too often viewed as a commodity that can be separated from the thought processes that led to it Only two scientists from Islamic states have won Nobel prizes: Abdus Salam, a Pakistani (for physics in 1979) and Ahmed Zewail, an Egyptian (for chemistry in 1999) Participating in centres of excellence supported by regional or international organizations can foster such integration, but only if there is solid commitment from the countries involved Political leaders in many Islamic nations simply fail to appreciate the importance of scientific research to their countries development Political leaders need to provide sufficient resources for basic scientific research, which should be considered as investments rather than expenditures Promotions in institutions are often based on trustworthiness rather than merit Rebuilding links with expatriate scientists and encouraging them to return is vital, as is support for scholarships to study abroad and to bring back the skills required at home Salaries are so low in some countries that people have to find additional income Scientific progress in academia in Muslim countries is often hampered by isolation and a relatively immature university system Scientists from not-so-friendly countries work together in solving difficult scientific and technical challenges Second, Muslim nations need to strengthen international links, in addition to purely national or bilateral cooperative projects SESAME was created according to the model of CERN, the European Laboratory for Particle Physics near Geneva Socio-economic development cannot depend solely on natural resources Sometimes the initiatives are full of good intentions, but the results are too often disappointing Spending on research and development in the Islamic world is an order of magnitude below the global average That is how I got a chance to understand at first hand the problems of the Middle East, and the different mentalities and ways of operating That this is possible has been shown by countries such as Taiwan and South Korea, and more recently by China The competition in other parts of the world is progressing fast The laboratory is in Jordan, close to Amman The older developed countries of Europe took some 150 years to evolve from an agriculture-based society into an industrialized one There are external reasons for the decline of Muslim science, including the Mongol invasion in the thirteenth century, but internal factors, such as growing isolation, growth of authoritative regimes, discouragement of innovation and restrictions on freedom of expression, were probably more decisive There has to be a rapid leap forward to catch up with the industrialized world There is much to gain, and little to lose, by embracing such ideas. These are the reasons why organizations such as CERN and SESAME have been established by UNESCO under the slogan “science for peace” They dont just exchange papers, but spend day and night shifts together Third, individual scientists need better security — in jobs, salaries and pensions This effort requires, above all, a return to the patronage of the past, when science had support at the highest echelons of Muslim society This figure compares with a world average of 2.36% This is not to ignore the real poverty of many Islamic nations, or the positive steps taken by some countries, such as Jordan, Pakistan, Iran and Turkey, which may still inspire others to action This is one objective of the SESAME training programme, supported by the International Atomic Energy Agency in Vienna This is particularly true for large and costly facilities or projects, because such cooperation involves not only scientists but administrators and politicians, sometimes at the highest level This is possible, as some examples prove — the strong support of science and education by King Abdullah II in Jordan and by President Pervez Musharraf in Pakistan To date, none of these statements has led to the concrete actions hoped for Todays Muslim societies have generated few scientists of international repute, despite accounting for roughly one-fifth of the globes population Unfortunately, most of these have had little effect When I have presented my thoughts to people from these countries I have found support for many of the recommendations offered below World Bank Development Indicators for 1996 to 2003 reveal that Muslim countries on average spend less than 0.4% of their gross national product on research 
 A problem with this approach is that it is difficult to identify rare proteins, because cell extracts are dominated by a few very abundant proteins Beckman Coulter has developed a number of innovations for protein fractionation to address this problem. “We first selectively remove the most abundant proteins from a sample,” says Jerry Feitelson, marketing manager for the company But how to choose the targets to put through the pipeline? For those who want to focus on targets relevant to a disease-related process, it is important to catalogue where, when and to what extent a protein is expressed Currently the main method for determining the protein complement of a given cell or tissue uses two-dimensional (2D) gel electrophoresis or liquid chromatography to resolve the proteins in the sample, and mass spectrometry to then identify the individual proteins Detailed protein maps can be constructed for easy comparison between two samples using the Proteome Lab software suite High-throughput protein-purification pipelines are becoming part of many proteomics efforts Interesting proteins can then be further analysed by cutting out the corresponding band, for example, and putting it into a mass spectrometer L.B. Pall Corporation has also introduced the Enchant Life Sciences kits for albumin depletion and immunoglobulin G purification So removing them increases the chances of identifying proteins that are not highly expressed and are probably more interesting to researchers The enriched material can then be collected and further fractionated with the Beckman Coulter ProteomeLab PF 2D protein fractionation system The instrument divides proteins in two dimensions: first, in a 2D gel, samples are separated by isoelectric focusing and size, and then automatically injected into a liquid-chromatography column The process is fully automated. “One run takes ten hours, so you can do two in one day,” says Feitelson The ProteomeLab IgY-12 partitioning kits selectively remove the 12 most abundant proteins — albumins and immunoglobulins — from human/primate serum or plasma The technology uses antibodies bound to inert beads, which are then packed in liquid-chromatography columns or, for smaller samples, spin columns. “The advantages of our reagents are the greater capacity, increased specificity and the ability to bind across species,” says Feitelson These proteins make up 95% of the total protein expressed by cells
 And although publishers enthusiasm has faded a little, plenty of new titles continue to appear And it is the writers who do it best whose books will endure to become part of the popular science canon, however that is eventually defined As a result, the prospective reader is faced with a bewildering choice of topics, authors and treatments Books still lend themselves to this better than any other medium Building up these explanations in words often takes scores, even hundreds, of pages But consideration of those widely thought to be the best science writers — Jared Diamond, say, or Richard Dawkins — prompts two suggestions for what is distinctive about the best current popular science But from another point of view, the key entities in the popular science exposition become characters in an explanatory narrative But hundreds of less celebrated titles remain in print But if so, it is story-telling of a very particular kind But the general run of popular science books can be compared with the best on another key feature But there are other outstanding examples that offer multidisciplinary stimulation, such as Nick Lanes Power, Sex, Suicide (Oxford University Press, 2005) about the role of mitochondria in the history of life, or Stephen Mithens The Singing Neanderthals (Weidenfeld Nicolson, 2005), which speculates on the origins of music and language Describing this kind of writing as defining the entities that underlie phenomena makes it sound rather like science Diamonds Guns, Germs and Steel and his more recent Collapse (Viking/Allen Lane, 2005) occupy one pinnacle of this kind of writing Few authors, perhaps, can command this range of ideas and data Forty years later, it is still true If some of the millions who enjoyed Bill Brysons huge bestseller A Brief History of Nearly Everything (Doubleday, 2003) look for another science title, how should they choose? Guidance is hard to find In some hands, this creates an opportunity to forge a synthesis that offers a unique and genuine contribution to scholarship — albeit one that inevitably attracts as many brickbats as bouquets from academics more committed to their specialism Individual new titles tend to be reviewed in the press by enthusiasts, rather than critics Lists of best science books typically put historic landmarks such as Newtons Principia or Darwins On the Origin of Species alongside contemporary efforts, which is hardly helpful as they are quite different from present-day popular science books in style, audience and intent Norton, 1997) Norton, 1999) reinvent science in text of exemplary logic, clarity and accessibility Richard Dawkins in Climbing Mount Improbable (Penguin, 1996), Matt Ridley in The Origins of Virtue (Viking, 1996) and Brian Greene in The Elegant Universe (W Science books often allow the authors to range beyond their own discipline Science journalists share with fashion writers a tendency to be cheerleaders for their subject, and science book reviewers often betray an assumption that any half-way competent science popularization is a Good Thing See page 821 , for a round-up of this years best science books. So are there any qualities to look for beyond the conventional attributes of good books, such as literary style or good story-telling? Books are complicated things, so there is no single answer So perhaps it does all come down to story-telling The author needs great control over the different elements, and must carefully signal to the reader where they have been and where they are going The problem is even more conspicuous now, because the intervening decades have seen such an outpouring of science writing The science publishing boom of the 1980s and 1990s was marked by blockbuster titles such as Stephen Hawkings A Brief History of Time (Bantam, 1988), Stephen Pinkers The Language Instinct (William Morrow, 1994) and Jared Diamonds Guns, Germs and Steel (W They take great pains to introduce the entities — be they genes or superstrings — that will bear the burden of the explanation, describing exactly what they can do, or what their properties and capacities are, and then showing how putting this into action produces the phenomena for which they are supposed to account This is, of course, central to science anyway, but there is an art to recreating them on the page in intelligible form W W We may well be in a golden age of science writing, but without some critical aids to navigation, the really good stuff may not find the readers it deserves What makes the recent boom in science writing important is that so many authors have got so good at constructing explanations You can see all this in action in the extended exposition of the properties of genes in Dawkins The Blind Watchmaker (Longman, 1986), for example, or of the elementary constituents of everything in Greenes account of string theory in The Elegant Universe  “There is no serious or stringent idea available of what makes a book a worthy example of popularization,” grumbled the British literary critic Martin Green when he tried to make sense of the science books he found in the early 1960s
 Although the recent outbreaks do not bode well for the eradication of polio, Thapa says he is more concerned about the situation in India. “It is the largest polio-endemic country and has been a source of wild poliovirus for other countries in the past.”  Officials suspect the virus travelled to southeast Asia through Saudi Arabia, a popular destination for Indonesian workers and Muslim pilgrims. “As long as there is polio is in the world and a lot of travel, we expect the virus to be imported,” says Rana. An outbreak in Yemen has sparked fears of an epidemic in the poorly immunized Middle Eastern nation And the virus has now reached southeast Asia, with four cases confirmed in Indonesia last week But officials are taking no chances and are giving supplementary immunization to 5.2 million children under the age of five in West Java and surrounding provinces Genetic analysis shows that the virus appearing in both areas is similar to the one that caused a 2003 outbreak in Nigeria Health officials are using a polio vaccine specifically targeted at the virus responsible for the outbreak, which they say provides greater immunity with fewer doses. “We believe it is the best tool in the face of an epidemic,” says Wahdan In April, the WHO confirmed 22 cases in Yemen, and health officials anticipate further infections because of low immunization rates among the nations children. “We expect there will be many times this number,” says Mohamed Wahdan, the WHOs Eastern Mediterranean polio adviser In Indonesia, health officials are confident the virus can be restricted to the small villages in West Java where the four cases were reported. “The immunization level in Indonesia has been good, with 95% coverage of children,” says Bardan Rana, the WHOs immunization officer in the country Middle Eastern nations have been on high alert for polio since December 2004 and many have already started preventative vaccination programmes. “Unfortunately, the virus spread ahead of the campaign in Yemen,” says Wahdan. “We hope to be ahead of the virus in other regions.”  This month, Yemen will initiate a house-to-house campaign to vaccinate all its 3 million children under 5 years of age Polio has not been seen in Yemen and Indonesia for a decade Polio vaccines were rejected in northern Nigerian states after Muslim clerics claimed they had been contaminated with HIV and contraceptives Sixteen ‘polio-free’ countries have reported cases since 2003. “The recent outbreaks can be traced back to that boycott,” says Arun Thapa, an adviser on polio eradication in southeast Asia for the World Health Organization (WHO), based in New Delhi Sydney Polio is spreading to countries previously considered free of the disease, following a vaccine boycott in Nigeria in 2003
 Further, their members have full-time commitments and so would find it difficult to attend such working parties at short notice Having worked in and with UK biological learned societies for a couple of decades, including a term as a member of the Council for the Association of Learned and Professional Society Publishers, I can testify that the vast majority simply do not have the resources to implement this suggestion However, even this would not be applicable to all cases: for instance, the example you cite of the MMR vaccine would not be covered as The Lancet is produced by a publishing house and not a learned society. Sir The call, made in your Editorial “Responding to uncertainty” ( Nature 437 , 1 ; 2005 10.1038/437001a ), for learned societies to create fast-acting working parties to respond to sensational news stories arising from journals, is unrealistic in the United Kingdom The best that might be achieved would be for those societies that publish journals to call upon their editorial boards to justify the decision to publish, and to clarify any uncertainty arising out of media reporting
 I suggest that more than three centuries earlier, in The Divine Comedy, his fellow countryman Dante Alighieri intuitively grasped what Galileo was later to establish as one of the pillars of modern science. In 1632, Galileo described his experience of motion aboard a large ship and exposed in detail the invariance principle, which was then rightly named after him A contemporary physicist could show that, given such dimensions and whatever the speed, the fictitious centrifugal force experienced by the passenger would be much smaller than the surface force due to the apparent wind: no such force is mentioned in the text A remarkable feature of this masterpiece is the vividness of the narration: it is a work of fiction brought to life by the realistic detail Although such a derivation would have been beyond the knowledge of physics in the Middle Ages, Dante did understand how his motion occurred seemingly in a straight line: he indicates its direction, by decomposing the vector describing the apparent wind in terms of its horizontal (“upon my face”) and vertical (“from below”) components Although the monster is wheeling, its motion occurs “slowly, slowly” while obeying Virgils command “Now, Geryon, bestir thyself; / The circles large, and the descent be little” At the bottom, the monster sets the poet down close to the wall, so the flight path may be assumed to have a diameter similar to that of the cylindrical “abyss” But he is probably one of the first to describe the actual sensation of flying, which he does with an accuracy that is evidence of his extraordinary imagination, as noted by several commentators  But sitting on the monsters back, Dante could not do much better than rely on and consider his own sensory perceptions Dante asserts that, aside from the effect of the wind, his sensation of flying was not dissimilar from being at rest Dante himself reminds us that he is not the first, mythologically speaking, to have flown: Phaeton and Icarus had done it before him Dante intentionally devised a journey, setting up different scenes and situations to express his message directly or allegorically Dante intuitively grasped the concept of invariance but, unlike Galileo, he did not pursue this idea any further First, the observer Dante can imagine himself in a frame that a contemporary physicist would define, with fair approximation, as inertial From a physical point of view, this ‘invariance’ is in agreement with the concept expressed by Galileo some three hundred years later Geryon then turns and leaves the circle rim, causing Dante to lose his points of visual reference: “I perceived myself / On all sides in the air, and saw extinguished / The sight of everything but of the monster” His imagined experience of flight is the core of this part of the narration, with the entire scene and landscape being created as a stage for its description However, the steepness of the bank between the two circles makes descent possible only by flying — in this case on the back of the monster Geryon In Galileos work, the invariance is explicitly related to observations and experimental results In spite of its apparent simplicity, the tercet reveals some remarkable physical intuition In this instance he seems to avoid allegory, perhaps to allow for a more factual, physical interpretation of the text It is difficult to argue that this descriptive accuracy is accidental Now comes the crucial point One part deals with Dantes descent from the seventh to the eighth circle, recounted in canto XVII of the Inferno  Sitting on Geryons back, Dante describes the initial motion of the infernal monster by comparing it to “a little vessel [that] shoves from shore” So the flight path corresponds to a wide, slowly sinking spiral and is travelled smoothly (“swimming”), or, a physicist would say, almost uniformly Still, it seems that he was well ahead of his time with regard to the views about the laws of nature held in the Middle Ages. The Divine Comedy narrates Dantes journey through the hereafter Then (lines 115–117, written around 1310 and translated by Henry Longfellow in 1867 (ref. 4 )): “Onward he goeth, swimming slowly, slowly / Wheels and descends, but I perceive it only / By wind upon my face and from below.”  These three lines are a typical example of Dantes ability to summarize several concepts and to describe complex situations in simple statements of a few words This was estimated by, among others, Galileo to be 35 Italian miles wide, or about 60 km: this value relies on two precise indications, given in canto XXIX, line 9 and canto XXX, lines 86–87, respectively (which also suggest that Dante was aware of the approximation π≈22/7) Up to this point, the pilgrim Dante had travelled on foot and occasionally by other means (for example, on Phlegyas boat, in canto VIII, and on the back of the centaur Nessus, in canto XII) With regard to the motion experienced on the flying monster, in the original tercet Dante says “ ma non me ne accorgo ”: he is not aware (or, more accurately, he imagines that he is not aware) of anything but the apparent wind
 According to Orr, if the infrastructure used to pump carbon dioxide into the ground was roughly the same size as the infrastructure currently deployed to bring oil to the surface, it could deal with about a seventh of the worlds production of fossil-fuel-generated carbon All these sites have been continuously monitored for possible leakages, but none seems to have occurred Although contributions from nuclear and renewable sources may increase, the IEA predicts that 85% of the rise in demand will be met by greater use of fossil fuels Although more expensive, and less profitable, than conventional plants, they have very low emissions of sulphur dioxide and other pollutants And experience with oil shows that such reservoirs can keep their contents stored away for geological lengths of time, points out Günter Borm, director of geo-engineering at Germanys National Research Centre for Geosciences in Potsdam and coordinator for the European Union-funded Ketzin project Another possibility, Socolow points out, would be simply to subsidize the technology As the costs of distribution and transmission are hardly affected, he calculates that the retail cost of electricity would increase by just 20% As yet, industrial-scale CCS activities are limited to just three sites — in Norway, Canada and Algeria — and to megatonnes rather than gigatonnes of carbon At Ketzin, scientists will keep track of any undesired chemical interactions between carbon dioxide and minerals, which could in principle dissolve the cap-rock that seals a storage site, or contaminate drinkable ground water But emitting a tonne of carbon dioxide currently costs less than $20 on the European exchange, and analysts doubt that the price is likely to increase much in the future. “The price of emitting carbon dioxide must rise, otherwise it just wont work,” says Borm. “CCS is perfectly doable at modest costs,” says Jon Gibbins, a CCS expert at Imperial College London and project manager with the UK Carbon Capture and Storage Consortium. “But politically were unfortunately in a very chaotic situation where its hard to look forward for more than one or two years But given present trends, experts think it unlikely that CCS will be employed at any substantial level before 2030, by which time the 1,400-gigawatts worth of power stations will already have been built But Hawkins counsels against too much pilot-project research of this type But IGCC plants use two thermodynamic cycles; the hydrogen from the gasifier and the shift reaction drives a gas turbine while the heat from that turbine and the gasifier drives a separate steam turbine But it would not necessarily be a terrible burden for consumers, says Socolow But pipeline building and well-drilling are mature and remarkably inexpensive technologies, and running costs would be extremely low But provided storage sites are chosen carefully, designed for safe operation, and properly monitored, the risks are manageable, says Lynn Orr, director of the Global Climate and Energy Project at Stanford University in California But some fear that capture-readiness will just provide a cheap way of doing a small amount to cut emissions. “The term capture-ready is pretty meaningless, because its definition includes subsequent installation of unidentified equipment,” says Hawkins But there could be news soon But they have environmental benefits — among which is being cheaper to kit out for CCS By the end of the year, drilling will start at a former gas storage facility on the edge of town Carbon dioxide capture from plants such as these would be significantly easier and cheaper than from conventional plants CCS would drop the efficiency of both sorts of plant to about 30% Conventional coal-burning technology, which will probably be used to produce 1,200 of the 1,400 gigawatts, produces flue gases that are about 14% carbon dioxide David Hawkins, director of the National Resources Defense Councils Climate Center in Washington DC, goes further: “Global efforts are completely out of scale with what is needed.”  Act now or pay later The International Energy Agency (IEA) predicts that by 2030, global energy demand will grow by 1.7% a year Deep aquifers in the worlds sedimentary basins have a total storage capacity estimated at between 1,000 and 10,000 gigatonnes  During their lifetimes, the new generation of plants will release 140 gigatonnes Everyone agrees that large-scale carbon dioxide storage would be a gargantuan technical feat Experts calculate that setting up storage facilities, each capturing several million tonnes of carbon per year, for the carbon dioxide produced from hundreds or thousands of plants, might cost as much as $80 billion Experts see it as a central part of any strategy for maintaining the generation of energy at todays levels: as Vassilios Kougionas, a European Commission officer in charge of clean-coal initiatives and international energy relations, puts it, “Without CCS there is no point in continuing with fossil fuels.”  And yet, for all this enthusiasm, there is a distinct lack of urgency in government approaches Fitting such equipment into a plant not designed for it is expensive For CCS to make a difference, the mechanisms it requires must be available to a substantial fraction of those plants after they have been built Four IGCC plants are currently in operation — two in the United States, one in the Netherlands and one in Spain Ground work “Its a big enterprise,” says Socolow Having more than one cycle means that, in principle, it should be possible to push the overall efficiency much higher, to the point where, even when paying the energy penalty associated with CCS, the plants would still be competitive. “First comes efficiency, then CCS,” says Jacek Podkanski, a senior energy technology specialist with the IEA He also points out that even if some reservoirs leak, it still makes more sense to use them, and thus spread out emissions over time rather than do nothing He also points to a peculiar long-term advantage He calculates that if carbon dioxide levels are to be kept in the desired range, then humanity needs to avoid about a third of the emissions expected in the next 50 years He thinks 2–3 cents per kilowatt-hour would make CCS a profitable route for a new coal-fired plant using todays technologies He thinks that each reservoir will have unique geological characteristics that will need to be assessed in situ  How expensive depends on technology choices and geographical circumstances, but rough estimates suggest that the average production costs of electricity will double, from 4 to 7 cents per kilowatt-hour If burned with CCS, they are gone for good, with the environment unchanged. “It doesnt make a lot of difference in which form carbon stays in the ground,” he says. “But with carbon dioxide rather than desirable fossil fuels in the ground you have a very different path ahead.” If fossil fuels are left unburned, they could be used in the future If the carbon dioxide is to be captured and stored it must first be scrubbed from the gas stream, typically by running the gases through an amine solution If we dont it means were running a very costly strategy.”  The good news is that, in principle, such vast amounts of gas could indeed be tackled by CCS If you want to tackle climate change you should do it aggressively or not bother at all.”  The road ahead For Gibbins, the best way forward is to ensure that every new plant is capture-ready — that is, designed in such a way that CCS mechanisms can be relatively easily incorporated at a later date In 2004, Ketzin was chosen as the site of mainland Europes first large-scale carbon storage demonstration project In a world set to invest $16 trillion in energy by 2030, $80 billion is not an unthinkable amount; the cost of deep disposal for Britains nuclear waste has recently been estimated as £11.3 billion ($21 billion) In Europe, the German energy company RWE Power has recently announced that it will invest e1 billion (US$1.3 billion) in the construction of a 450-megawatt IGCC plant in Germany In IGCC plants, the fuel — coal, fuel oil or biomass — is introduced into a hot gasifier along with oxygen and steam In low-lying land, such leakages could suffocate people because carbon dioxide is heavier than air, so will fill up valleys and basins In the Canadian and Algerian projects, the gas being stored away is also being used to enhance the productivity of oilfields, which covers some of the costs In the next two years, some 60,000 tonnes of carbon dioxide (roughly the annual carbon dioxide output of 40,000 cars) will be injected into an aquifer of salty water 700 metres beneath the surface In total, 11 or so full-scale CCS projects are planned, or have been proposed, in the United States, Canada, Britain, Germany, Norway and Australia Ketzin, a dozy village of 4,000 people west of Berlin, hardly looks like a vision of the future Little more than a fringe idea five years ago, CCS was singled out at the 2005 G8 summit as a technology that could make a difference to climate change Locking away 250 million tonnes of carbon per year — equivalent to 4% of annual global emissions — would require an injection of 25 million to 35 million barrels per day, depending on compression density Making it pay At the moment, the efficiency of IGCC plants is about 40%, which is roughly the same as that for good conventional plants Meanwhile, climate scientists are arguing that carbon dioxide levels should not be allowed to get much higher than 550 parts per million (p.p.m.); the current level is 380 p.p.m., which compares with 280 p.p.m. in the eighteenth century Meanwhile, the number of power stations whose carbon dioxide is neither captured nor stored is rising inexorably, as is the atmospheric level of the gas Nestled in the Havel countryside — an idyllic mix of rivers and forests — it has a small tourist industry and, as is typical for such parts of eastern Germany, a not-so-small unemployment problem. “Theres no news at the moment”, says the communitys website Not all reservoirs are as well adapted to CCS as a 100-million-year-old oilfield might be Oil companies already pump carbon dioxide into petroleum reservoirs on a routine basis as a way of flushing out the hydrocarbons Other companies, such as Swedish Vattenfall, are also experimenting with ways to get more efficiency out of traditional plants, and with oxyfuel plants in which the coal is burned in pure oxygen, producing a flue gas that is richer in carbon dioxide and so better suited to CCS. “Were by no means proceeding as though there were all the time in the world, but new technologies need time,” says Johannes Ewers, head of new power-plant technologies at RWE. “We do know that if we want to burn coal we have to reduce carbon dioxide.”  In theory, the EUs emissions trading system should be providing incentives for such developments by putting a price on emissions Pumping carbon dioxide into them is a straightforward matter Robert Socolow is a physicist and co-principal investigator of the Carbon Mitigation Initiative at Princeton University in New Jersey Scientists monitoring a smaller storage project, the Frio Brine Pilot Experiment in Texas, recently reported that the injection of carbon dioxide had made the brine 1,500 metres down substantially more acid ; such acidic brine could potentially eat through the surrounding rock and escape into higher aquifers Since 1750, humanitys burning of coal has released about 150 billion tonnes (gigatonnes) of carbon into the atmosphere Since it began in 1996, the Norwegian project has pumped around 10 million tonnes of carbon dioxide 1,000 metres beneath the North Sea bed into the Utsira Sand formation; the carbon dioxide is a contaminant in natural gas from the Sleipner West field Some argue that the ceiling needs to be a lot lower Some may leak, and in some there might be a risk of sudden, catastrophic releases of gas Such incentives have been shown to work: the sequestration of carbon dioxide from the Sleipner platform in Norway is the oil and gas company Statoils response to the countrys $50 per tonne of carbon dioxide tax on emission-intensive industries Such standards could become gradually more strenuous as better technologies become available Taking into account the existing plants that will be shut down, the world is looking at 1,400 gigawatts worth of new coal plants (see graphic on page 623) That is less than half the amount produced at power stations and large factories — the sources for which CCS is best suited That is only a little more than the 1.8-cent subsidy the United States currently gives producers of wind-generated electricity. newsad; No matter which technological options and economic or regulatory incentives are used, CCS will cost society money. “Electricity will clearly become more expensive,” says Ewers That means finding a way to not release 175 gigatonnes of carbon. “If we get going now,” he says, “the job will be less than half as difficult Thats equivalent to about a third of the flow of oil currently coming from reservoirs The capital costs for IGCC plants are 20% greater than for conventional plants The carbon dioxide can be relatively easily separated at this point The carbon monoxide then goes through a second shift reaction with steam, making carbon dioxide and more hydrogen The cost of capturing, transporting and storing a tonne of carbon dioxide is estimated by the Intergovernmental Panel on Climate Change to be between $20 and $70, which is why the Statoil sequestering project makes sense The countries most interested in CCS have, at best, preliminary plans for it; most havent even got that far The idea is also part of an EU–Chinese memorandum of understanding on near-zero-emissions power generation technology, and was highlighted in the 2005 G8 action plan The Ketzin project will test the storage part of carbon capture and storage (CCS), a strategy designed to allow energy to be generated from fossil fuels without the carbon dioxide produced in the process ending up in the atmosphere The main alternative to the conventional plant is the integrated gasification combined cycle (IGCC) The plant, fully equipped for CCS, could become operational in 2014 The problem with using this technique is that the equipment needed not only costs money — it also takes up a lot of space The UK government is considering requiring that all new coal-fired plants are capture-ready The US FutureGen initiative, a $1-billion public–private partnership to design, build, and operate a coal-fuelled zero-emissions power plant by 2015, aims to prove the technical and economic feasibility of a commercial-scale IGCC plant fitted with CCS These costs, says Gibbins, are trifles compared to the long-term benefits of allowing companies to go on generating power with proven technology but without adding to the greenhouse effect This doubling of capacity is the greatest expansion of power generation in the planets history This means the overall capacity of coal-fired power plants will have to double in that time, from 1,100 gigawatts to 2,200 gigawatts  This might be bad news for coal producers, as, all other things being equal, it would make the fuel they sell much less desirable, tilting the market towards natural gas This produces a fuel gas consisting mainly of carbon monoxide and hydrogen This takes up the carbon dioxide and then, when heated, releases it in pure form To him, it would make more sense for governments to set up well-defined performance standards for power-generating facilities, such as a maximum carbon dioxide output allowed per unit of electricity To some observers, this represents a failure not of science or technology, but of will. “It does require quite substantial research and technology efforts to make CCS better and more efficient — but we could still start today if desired,” says Hans Ziock, a physicist at Los Alamos National Laboratory in New Mexico, who has worked on carbon dioxide capture technologies for more than a decade Under the sea, gas-filled reservoirs could potentially trigger landslides and thus tsunamis Whats more, the figure might come down as the technology matures and economies of scale cut in
 After a flat close to 2005, the Nasdaq biotechnology index moved forward in January, with most of the rise attributable to a flurry of recent clinical trials results and acquisition activity And worse-than-expected efficacy data for anticancer drug candidate G-024856 saw shares in Massachusetts-based Curis lose a quarter of their value Arena Pharmaceuticals of San Diego, California, for example, revealed promising interim phase II data for its obesity drug candidate APD356, and saw its shares rise by almost two-thirds But Amgen itself played a part in that, by announcing plans to acquire one of its important partners in drug development, biotechnology company Abgenix of Freemont, California, for $2.2 billion Despite reporting rapid revenue and profit growth in 2005, shares in industry bellwether Amgen, of Thousand Oaks, California, has slipped by 12% in the past eight weeks Given Amgens heavy weighting in this index, it is remarkable that the biotechnology index still managed to rise by 4% over the period Massachusetts-based Vertex Pharmaceuticals also enjoyed a 42% rise, driven by strong clinical data from its hepatitis C drug candidate, VX-950 Offsetting these gains were some spectacular falls: Rigel Pharmaceuticals of San Francisco, California, saw its share value nosedive by 64% after disappointing phase II data for its nasal allergy candidate R112 Shares in Abgenix, whose main product, the antibody Panitumumab, is expected to win US approval for the treatment of colorectal cancer early this year, rose by 67% on the news. This week Wood Mackenzie, an Edinburgh-based research and consulting firm, reviews recent trends in biotechnology stocks
 For example, magnetic force microscopy allows the investigation of magnetic structures with a spatial resolution in the nanometre range, but with low sensitivity, whereas SQUIDs and atomic magnetometers enable extremely sensitive magnetic-field measurements to be made, but at low resolution Here we use one-dimensional Bose–Einstein condensates in a microscopic field-imaging technique that combines high spatial resolution (within 3 micrometres) with high field sensitivity (300 picotesla). Todays magnetic-field sensors are not capable of making measurements with both high spatial resolution and good field sensitivity A BEC is trapped at the measurement site so that its density profile can be directly imaged A comparison of different magnetic-field measurement techniques (see supplementary information ) shows that BECs as magnetic sensors could reach unprecedented sensitivity over a large range of spatial resolution As a demonstration, we measured the magnetic-field variations above the 100-µm-wide current-carrying wire used to create the trap itself As long as this structure is grounded and carries no current, the atomic-density profile is homogeneous within the detection sensitivity As soon as a small current (about 5 mA) is passed through the wire, a characteristic field profile is imaged By changing to a different atom with higher mass and/or by reducing the interatomic interaction, a significant increase in sensitivity can be achieved Currently available CCD (charge-coupled device) cameras allow atom-shot noise-limited detection with a Δ N value of better than 10 atoms per pixel in absorption imaging, so that a sensitivity, Δ B , of 1 nanotesla is possible even at a high spatial resolution of 1 µm (or 1 picotesla at 10 µm) Density modulations in trapped thermal atomic clouds have already been used as a measure of magnetic field variation caused by irregular current flow in nearby conductors  From this map, we reconstructed the local current flow in the wire and found extremely small angular deviations (2×10 −4 root-mean-square radians) from a straight current path (for details, see supplementary information ) Here Δ N is the minimal atom-number variation resolved by the imaging system, and γ contains all the atomic-physics parameters of the specific atom ( γ =8.63×10 −29 tesla cubic metres for the 87 Rb used in our experiment) Its sensitivity is not limited by the temperature T of the cloud, but is rather determined by the chemical potential µ of the condensate, which can be orders of magnitude lower than k B T (where k B is Boltzmanns constant) Scanning the position of the BEC enabled us to reconstruct a full two-dimensional magnetic-field profile ( Fig. 1b ) near the wire with unprecedented accuracy (sensitivity of 4 nanotesla) at the measurement resolution (3 µm) The optimal potential sensitivity of a BEC used as a field sensor, Δ B = γ Δ N / z 0 , is achieved if the trapping parameters are adjusted so that the clouds transverse size matches the desired spatial resolution z 0  The principles of the technique are shown in Fig. 1a  The sample measurements we present here reach higher sensitivities than those obtained with established techniques operating at the same spatial resolution. The spatially varying density is a measure of the potential energy and hence of the local magnetic-field variation The technique is applicable not only to magnetic fields, but can also be used to detect variations in electrostatic fields, as can be shown by charging the probed structure electrically This corresponds to an upper bound in potential roughness of less than 10 −14 eV, corresponding to a temperature of 200 picokelvin (field sensitivity of 300 picotesla) This measurement is more sensitive than the one discussed above because the trapping parameters can be adjusted independently from the measured potential landscape by using a separate wire for holding the BEC To probe spatial magnetic-field variations, we start by confining a one-dimensional BEC (in which µ is smaller than an energy quantum of transverse excitation) in an elongated magnetic micro-trap with strong transverse and weak longitudinal confinement, created by small conductors mounted on the surface of an atom chip  Trapped cold atoms are ideal magnetic sensors as they are very sensitive to changes in magnetic-field landscapes, even in the presence of large homogeneous offset fields We also investigated an independent field landscape by placing a BEC close (5 µm) to a test wire structure We have produced a versatile, high-resolution sensor based on Bose–Einstein condensates (BECs)
 A previous study using this method showed that Bitesize binds to Moesin, a cytoplasmic protein believed to mediate membrane–cytoskeletal interactions in the apical domain  Although satisfying, this model leaves several significant questions unanswered Although the results imply that Moesin functions to link the plasma membrane structurally to the underlying cytoskeleton, other studies in fruitflies indicate instead that Moesin regulates a small GTPase called Rho, which in turn regulates cytoskeletal assembly  An intricate system of interacting protein complexes divides the cell surface into at least three functionally and molecularly distinct domains: the apical membrane, the basolateral membrane and, in between, the adherens junction ( Fig. 1 ) Both adhesion and polarity rely on a highly organized internal structural network called the cytoskeleton Careful microscopy of living mutant embryos established that, in the absence of Bitesize, the Baz/Par-3 complex and adherens-junction proteins are recruited normally to the apical membrane in the early stages of epithelial formation, but the adherens junction is not stable and rapidly disassembles Disruption of either characteristic can have catastrophic effects — the loss of intercellular adhesion and apical/basal polarity allows cancer cells to spread, for instance Epithelial cells, such as those that make up the skin and the lining of the intestine, all share fundamental characteristics — the ability to stick tightly to one another and an asym-metric organization of the proteins and lipids that constitute the cell membrane (a property known as apical/basal polarity) Furthermore, intact microfilament and microtubule cytoskeletons are required for Bazooka to reach the apical membrane  Genetic studies suggest that the apical and basolateral complexes compete to stake out regions of the plasma membrane, with the adherens junction serving as referee by physically separating these competing parties  How do the complexes assemble reproducibly in specific regions of the plasma membrane? The formation of adherens junctions requires the Baz/Par-3 complex However, as with most advances, the study raises as many questions as it answers However, it is not known whether the Bitesize protein has a similar function However, this complex does not need an intact adherens junction to assemble in the apical domain of fruitfly epithelial cells  In addition, Bitesize requires Bazooka to localize apically, but does not need E-cadherin In addition, they found that knocking down Moesin produced features, including disruption of E-cadherin and epith-elial integrity, that were indistinguishable from those of bitesize mutants In particular, there is the issue of how adherens-junction assembly is controlled downstream of Baz/Par-3, which Pilot et al . now address Interestingly, the authors demonstrate that apical localization of Bitesize also depends on a molecule called PI(4,5)P 2  Is it possible that Rho function is spatially regulated in epithelial cells to promote adherens-junction assembly and therefore overall apical/basal polarity? Does the role of synaptotagmin-like proteins in other contexts suggest that vesicle trafficking is involved in adherens-junction formation and apical/basal polarity? Is Bitesize function required in other fruitfly epithelia, and are its mammalian relatives required in mammalian epithelia? Time, and the continued use of genetic and genomic approaches in model systems, will tell. On page 580 of this issue, Pilot et al . shed light on how epithelial cells organize the cytoskeleton, and thereby regulate both assembly of specialized adhesive structures and apical/basal polarity Pilot et al . confirmed this interaction and showed that, in the absence of Bitesize, Moesin does not localize normally in the adherens junction Pilot et al . found a defect in apical actin assembly that precedes disassembly of the adherens junction, suggesting a previously unknown mechanism for stabilizing apical actin in the early embryo Pilot et al . next examined the role of Bitesize in epithelial morphogenesis using RNA interference (RNAi) So it would seem that the Baz/Par-3 complex might control Bitesize localization by recruiting PTEN to the apical domain, although this has yet to be tested Synapto-tagmin-like proteins bind to members of the Rab family of enzymes called small GTPases and have been implicated in exocytosis , a process by which cells transport lipids and certain proteins to the cell surface, in many cases aided by the cytoskeleton The adherens junction is composed of the adhesive protein E-cadherin, which spans the cell membrane, plus associated cytoplasmic catenin proteins and actin microfilaments (which make up the cytoskeleton) The current consensus is that the different domains are characterized by the presence of particular multi-protein complexes — the Bazooka/Par-3 (Baz/Par-3) complex and the Crumbs complex define the apical domain, and the Discs-large complex defines the basolateral domain These properties are essential for the epithelia to form protective barriers and to regulate cell proliferation and specialization These results suggest that adherens junctions assemble normally without Bitesize, but cannot stabilize because there is no underlying band of actin microfilaments These results suggest that an inherent cytoskeletal polarity provides the initial cue for assembly of the Baz/Par-3 complex, which in turn controls the subsequent assembly of the other components that define apical/basal polarity These results suggest that Bitesize functions downstream of the Baz/Par-3 complex and upstream of the adherens junction These RNAi knockdown experiments, together with experiments using standard genetic mutations, showed that when bitesize function is disrupted, epithelial integrity is compromised This phospholipid is a product of PTEN, a lipid-modifying enzyme that also binds to Baz/Par-3 (ref. 9 ) This technique targets specific messenger RNAs for degradation, thus halting production of the encoded protein To solve the mystery of how Bitesize regulates actin, they examined data from yet another genome-based approach that searches for functional protein–protein interactions in yeast Together, these results fill a large gap in our understanding of how the Baz/Par-3 polarity complex, the actin cytoskeleton and the adherens junction cooperate to establish apical/basal polarity in developing epithelia Using genome-wide arrays to pinpoint genes expressed during the development of epithelia in fruitfly embryos, they picked out bitesize , a gene that encodes a synaptotagmin-like protein that has previously been identified as affecting growth in adult flies  Why is the adherens junction unstable in bitesize mutants? Interactions with the underlying actin cytoskeleton are thought to stabilize the adherens junction, although the underlying mechanism is not well understood 
 Academies are not particularly expensive to run, and they already exist in many African countries African capitals do not enjoy the best of circumstances Although their membership is small and their expertise is in many cases limited, there are areas in which they could be helping their respective governments right now But as a meeting in Amsterdam of African academy officials heard earlier this month, rapid progress could be made in other countries too, if scientists, government officials and donor nations would step up to the plate But others could be tackled by less expensive and more subtle means: the development of properly functioning scientific academies in African nations Even in the best of circumstances, it is extremely difficult to get politicians to listen to independent scientific advice For this model to make headway, of course, political leaders need to be convinced of its value Greater expertise will then be brought to bear, particularly with regard to pressing African issues, such as standards in education at all levels In 2002, for example, when Zambia decided to reject food aid from the United States on the grounds that it contained genetically modified maize, its president Levy Mwanawasa appealed on television for the countrys scientists to help him out In Britain, the Netherlands and the United States, for example, academies have long played a broadly productive role in raising the level of public discussion on technical issues In Uganda, for example, scientists will be trained to work effectively with media outlets to get their message across, and regular meetings will be arranged between researchers, businesses, government officials and politicians to discuss their responses to malaria Progress on both these fronts remains patchy, but scientists can strengthen their prospects of being heard by working to build up the effectiveness of their own academies, while finding proactive means of getting their message out to politicians, the media and the wider public Self-elected bodies of accomplished scientists make a significant contribution to public discourse in most wealthy nations Some of them, such as the provision of health care and basic scientific education, are bound to be expensive to address That will only happen in nations with leaders who are genuinely accountable to their electorates, and where a reasonably free press permits public discussion of the issues The broadcast was the first Zambias science academy knew of his interest, as there was no established channel for communication between the academy and his government in Lusaka The existing academies have had little influence The medical, scientific and environmental challenges facing the continent of Africa can seem simply overwhelming The participants in the National Academys ten-year project, supported by $20 million from the Bill Melinda Gates Foundation, are already showing the way ahead, particularly with regard to health issues The US National Academy of Sciences, under its former president Bruce Alberts, began a laudable, long-term project to build up the prowess of such academies in three African nations: Nigeria, South Africa and Uganda There is an opportunity, in the rapidly developing polities of modern Africa, for similar academies to emerge there There is no good reason why this state of affairs should persist They also provide governments with advice on matters as diverse as public transport and nuclear-waste disposal They were not involved, for example, in shaping the New Partnership for Africas Development (NEPAD), an important collaboration between Africas governments whose plans include the creation of research centres and networks to tackle continent-wide woes, such as malaria and poor water supply This lack of clout has been equally apparent at the national level What is often missing are the political skills needed to get such advice heard, in government or in the media Yet the political situation in many of these capitals is fluid, and determination from scientists to make their collective voices heard could go a long way towards bringing their expertise to bear on African problems.
 Alas, I have counted barely ten papers since then that have addressed such radiations, which end up being labelled as non-adaptive Alexander Loddoch of the University of Münster in Germany and his colleagues built a model to simulate mantle convection beneath a stagnant lid Around 12,000 of its more than 23,000 genes are active in the developing embryo Astron Astronomy: Recipe for X-rays Mon At the same time, a current was passed through the damaged tube B. 273, 539–546; 2006) Biol . doi:10.1038/nsmb1170 (2006) A molecular machine that seems to act like a ruler in fact performs a dynamic balancing act, researchers report Biologists know that the enzyme ACF controls the spacing between DNA-packaging units called nucleosomes, in which DNA is wrapped around protein spools Biomechanics: Jeepers creepers Phys Blebbing occurs when the membrane detaches from the cortex and inflates, forming a bulge on the cell surface Bradley Wouters of the University of Maastricht in the Netherlands and his colleagues used an antiproton facility at CERN, the European particle-physics laboratory near Geneva, Switzerland, to make the first measurements of the particles effects on mammalian cells But how about those hyperdiverse clades in the tree of life in which many species have little morphological difference between them? I first pondered this problem when musing about my thesis on the flowering-plant taxon Astragalus  But practical therapeutic uses are far off: making antiprotons currently requires a circular accelerator with a diameter of at least 100 metres But Shigella produces a protein-chomping enzyme called VirA, which acts on microtubulin But their antimatter cousins could pack even more of a knockout punch because antiprotons and matter annihilate one another, releasing a burst of energy Cell Biol. 175, 477–490 (2006) Researchers hoping to understand a part of the cells skeleton known as the cortex have made headway by studying a process called blebbing Cell Biology: Battle of the bulge J Cell biology: Spaced out Nature Struct Chihiro Sasakawa of the University of Tokyo and his team used fluorescence- and electron microscopy to photograph cells infected with Shigella  Contractile proteins then pull the layer down, all within 30 seconds Evolutions spectacular adaptive radiations get a lot of press: Darwins finches and the Hawaiian silversword plants being textbook examples For antiprotons, this ratio was some 3.75 times greater than for protons For example, the lineages may have evolved by tracking the ebb and flow of favourable habitats. Guillaume Charras and his colleagues at Harvard Medical School in Boston, Massachusetts, studied how the cortex reassembles beneath the bulging membrane H I hope the most recent will shake things up a bit I was cursed with perhaps 2,500 species, many remarkably similar It analyses the speciation rate of North American Plethodon , a clade of salamanders most diverse in the woodlands of the Appalachian mountains (K It has been suggested that such ultraluminous X-ray sources are powered by black holes larger than can be formed in the death throes of any normal star It has long been used as a marker of neuronal activity, even though its physiological role was not clear It seems that ACF continuously samples the stretches of DNA bordering each nucleosome, and pushes longer pieces of DNA through the nucleosome faster than shorter stretches Journal club Michael Sanderson University of Arizona, Tucson A biologist turns his attention to evolutions neglected radiations Knocking out VirA production in Shigella prevented the deaths of infected mice Kozak et al  Lett. 251, 79–89 (2006) Planets such as Mars and Venus (pictured) with rigid, unmoving crusts can experience transient bursts of plate tectonics, according to new computer simulations Lett. 97, 184302 (2006) How do climbing plants grasp the poles up which they wind? And why do some twine around thin poles but not thick ones? Researchers going back to Charles Darwin have puzzled over these questions Loddochs group found instead that bouts of plate tectonics can be far enough apart for the crust to completely reform Microbiology: Burrowing bacteria Science 314, 985–989 (2006) Researchers in Japan have figured out how Shigella bacteria, which cause dysentery, burrow through cells Mol Nanotechnology: Shrink to fit Nano Lett . doi:10.1021/nl061671j (2006) Carbon nanotubes shrunk to order could be the next fashion in nanotube devices, thanks to a process developed by Alex Zettl at the University of California, Berkeley, and his colleagues Neuroscience: Memory gene Neuron 52, 437–444; 445–459; 461–474; 475–484 (2006) Four papers published in Neuron help to demystify the mechanism of a gene implicated in the consolidation of memories Not Now Alain Goriely at the University of Arizona in Tucson and Sébastien Neukirch at the Pierre and Marie Curie University in Paris, France, show that a simple model can explain the plants behaviour Oncol. doi:10.1016/j.radonc.2006.09.012 (2006) Protons are the particles of choice to zap tumours in sensitive areas of the body because where they deposit their energy can be controlled precisely Planetary science: Time heals Earth Planet Previous studies have suggested that once such plate tectonics starts, it either continues or recurs in episodes so closely spaced that the crust remains unsettled Prickly all over Science 314, 941–952; 960–962 (2006) The genome of the purple sea urchin, Strongylocentrotus purpuratus , has been sequenced Proc R R Radiology: Tumour annihilation Radiother Remarkably, the rate of speciation in the groups early days matched or exceeded rates seen in the textbook adaptive radiations Rev Roberto Soria of the Harvard-Smithsonian Center for Astrophysics in Cambridge, Massachusetts, and Diane Sonya Wong of the University of California, Berkeley, note that radio images of M99 show a cloud of fast-moving hydrogen impinging on the galactic disc near the X-ray source Sasakawas team saw that VirA sliced up the microtubules, creating tunnels through which the bacteria could spread Sci Sea urchins, like humans, are members of the superphylum of deuterostomes and hence are more closely related to us than the other lab favourites fruitflies and nematodes Soc Soc. 372, 1531–1539 (2006) On the outskirts of the spiral galaxy M99 is an object that, in some X-ray frequencies, outshines all the rest of the galaxy put together Studies in vitro suggest that the gene controls the appearance and disappearance of receptors for the neurotransmitter AMPA on neuronal surfaces Such episodes give rise to easily observable diversity and have stimulated extensive study Such receptor trafficking is known to modify the strength of connections between neurons, which is fundamental to learning and memory The appeal for device designers is that a tubes electrical properties are intimately linked to its diameter: as the tube shrinks, resistance increases The authors make some interesting suggestions about the role of geography, ecology and adaptation in the salamanders evolution The bacterias movement is hindered by the cells dense network of microtubulin, a cytoskeletal protein The cortex is a layer of cytoskeleton wrapped beneath the cell membrane, which helps to maintain cell shape and aid cell movement The gene, known as Arc/Arg3.1 , is expressed in the brain during learning The genome also boasts large families of genes involved in innate immunity The new research shows that mice with the Arc/Arg3.1 gene knocked out fail to form long-lasting memories The sequenced genome reveals that many genes thought to be unique to vertebrates crop up in the sea urchin too, including some important for human hearing and sight The transparent sea urchin embryos are also ideal for studying early development Their observations may help efforts to combat the microbe, which kills 1.1 million people each year Their small differences were typically of uncertain adaptive significance These organisms, in adapting to environmental pressures, underwent both rapid speciation and radical morphological change They blasted a nanotube with an electron beam, knocking some atoms from its structure They compared the number of cells killed in the target zone with the number that died in the surrounding tissue They examined how friction between the rod and a supporting pole holds up the growing helix, and showed that the angle at which the curling tip meets the poles surface determines the maximum radius of pole around which the stem can wind They show that it happens in steps, with actin and actin-bundling proteins following the anchor protein ezrin They suggest that this influx of hydrogen could have compressed material at the edge of the disc into an anomalously large star, which later evolved into a black hole of a size suited to such X-ray brilliance They treated a twining plant stem as an elastic rod that has an intrinsic tendency to curl This establishes an equilibrium state between neighbouring nucleosomes that favours even spacing This group has an evolutionary history that runs back 28 million years and has spun off about 46 species, many of which are only diagnosable by molecular markers This made it reform, with few defects, at a smaller diameter (pictured right) This suggests that we have a lot to learn about the evolutionary phenomena driving such radiations This will hearten developmental and systems biologists for whom the sea urchin serves as a model organism This would fit some theories of Mars and Venus histories, the team suggests To find out more, Geeta Narlikar and her colleagues at the University of California, San Francisco, tagged nucleosomes with fluorescent dyes and tracked their movements in real time Under some conditions the lid, or crust, breaks up and its parts begin to move
 All this represents necessary progress As part of the investigation that led to the report, immunologist Stephen Inglis of the National Institute for Biological Standards and Control near London and his colleagues developed an in vitro test using human blood cells that recreated the behaviour of the trial volunteers cells But the fact remains that many of the drugs now being readied for clinical trials, for all their enticing potential benefits, carry risks that can never be eliminated But this test was retrospective — a team of immunologists took months to recreate something that bitter experience had shown to be possible Implicit in the list of 22 recommendations released by the panel on 7 December is an acceptance of the inherent dangers posed by some drug candidates — particularly those that target the immune system Inglis and the rest of the advisory panel now advocate including such tests in future preclinical evaluations of antibody drug candidates Instead, the report leans towards learning as much as possible about such molecules before they are administered to people It also advocates creating a database of animal data, which might flag up adverse reactions observed previously that could otherwise be missed by regulators It will no longer be enough simply to demonstrate that a compound is non-toxic in an animal model Less satisfactory is the governments failure so far to hold anybody accountable for the Northwick Park incident Phase I clinical trials, or first in man trials, will always carry an inherent risk; the critical thing is how to manage the risk to the paid participants who volunteer as test subjects Preclinical trials in monkeys had shown no such adverse reaction, despite the fact that they share an almost identical receptor for the antibody Sooner or later during the life of any drug candidate, there comes the time when it must be administered to humans TGN1412, for example, was intended to bypass one of the cellular checks blocking the activation of a certain class of T cell The groups final report describes such compounds as “high-risk drugs”, but makes no recommendations about when the MHRA should refuse to authorize a trial on the basis of unknown risk The MHRA, in a subsequent investigation, exonerated both itself and Parexel, the company that administered the trial; TeGenero, the German firm that developed the drug, has gone bust The panel recommends, for example, that the MHRA should consult external experts with specific knowledge of the area in question, such as a particular group of compounds The panel was brought together to advise the Medicines and Healthcare Products Regulatory Agency (MHRA), which governs British clinical trials, on how to minimize the risks of such an event recurring The panels advice included several recommendations that should be simple common sense The problem was that, in humans, its activation was more widespread than expected among the different types of T cell, inducing a storm of inflammatory molecules that led to widespread inflammation and organ failure The proposals depart from the British regulators prior practice of approving clinical trials through a process that amounted to ticking a series of boxes, towards a more subjective consideration of how drug candidates actually work The victims have been appallingly maimed, suffering from amputations and with bleak health prospects They are well represented legally and will doubtless now look to the courts, rather than the regulator, to determine where responsibility for their condition lies. This is the question that a panel convened in Britain has sought to answer in the wake of the trial of TGN1412 — an antibody aimed at treating autoimmune diseases such as rheumatoid arthritis — that put six men in intensive care at Londons Northwick Park Hospital in March this year (see Nature 440 , 388 – 389 ; 2006 ) This is to be applauded Using similar methods to spot dangerous compounds before they go to trial will always be an exercise in guesswork Volunteers should be dosed one by one, rather than simultaneously; doctors performing the tests should have specialist, rather than general, expertise; and trials should be carried out in dedicated centres within existing hospitals, with 24-hour emergency facilities
 By inhibiting the internalization step of PIN constitutive cycling, auxin increases levels of PINs at the plasma membrane Concomitantly, auxin promotes its own efflux from cells by a vesicle-trafficking-dependent mechanism Furthermore, asymmetric auxin translocation during gravitropism is correlated with decreased PIN internalization Here we show that a major regulator of plant development, auxin, inhibits endocytosis No such mechanism of hormone action has been shown in plants although several proteins, including the PIN auxin efflux facilitators, exhibit constitutive cycling  One of the mechanisms by which signalling molecules regulate cellular behaviour is modulating subcellular protein translocation Our data imply a previously undescribed mode of plant hormone action: by modulating PIN protein trafficking, auxin regulates PIN abundance and activity at the cell surface, providing a mechanism for the feedback regulation of auxin transport. This effect is specific to biologically active auxins and requires activity of the Calossin-like protein BIG This mode of regulation is often based on specialized vesicle trafficking, termed constitutive cycling, which consists of repeated internalization and recycling of proteins to and from the plasma membrane  A gravity stimulus was applied by horizontal positioning of plates; after 60 min, BFA solution was carefully added followed by incubation for 60 min All treatments and gravity experiments were performed at least in triplicate, with a minimum of 60 roots evaluated in total in each treatment Analysed cells on scans were selected interactively from the cortex of the same root region Cell-border-associated and internal fluorescence were quantified separately from at least 80 cells for each treatment (10 µM NAA or 50 µM BFA for 90 min) Cells of tobacco ( Nicotiana tabacum L., lines BY-2 and VBI-0) were grown in suspension culture as described elsewhere  Control treatments contained an equal amount of solvent (dimethylsulphoxide or ethanol) Electron microscopy Treatments (10 µM NAA and/or 50 µM BFA for 90 min) and ultrastructure analysis of chemically fixed root sections were performed exactly as described . Experiments were performed on 4-day-old seedlings grown on vertically oriented plates containing Arabidopsis medium (AM; half-strength MS agar, 1% sucrose, pH 5.8) Fluorescein isothiocyanate-conjugated and CY3-conjugated anti-rabbit secondary antibodies ( Dianova ) were diluted 1:200 and 1:600, respectively For gravitropism experiments, plants were grown on vertically aligned plates containing a 1-mm layer of AM medium For whole-mount immunolocalization in roots, immunoglobulins from the crude serum were precipitated by saturated (NH 4 ) 2 SO 4 solution (2:1) and dialysed against PBS From about 3,500 M1 families, we identified eight lines that under these conditions showed resistance to NAA (that is, they displayed normal internalization of PIN1:GFP into BFA compartments, as could be observed in the wild type after treatment with BFA without auxin) Genetic screen A mutant screen to isolate plants for resistance to auxins inhibitory effect on PM protein internalization was performed on the ethylmethane sulphonate-mutagenized PIN1:GFP population Immunolocalizations Whole-mount immunofluorescence preparations and antibody staining of maize tissue sections were performed as described In controls, gravitational stimulation and BFA treatments were performed in the presence of 10 µM NPA In each experiment, inhibitors of transcription (20 µM cordycepin) and/or protein synthesis (50 µM cycloheximide) were applied to exclude any effects on PIN2 expression Incubation of seedlings with various chemicals was performed in 24-well cell-culture plates in liquid AM medium Luschnig and was used at a dilution of 1:400 Methods Materials and growth conditions The following mutants and transgenic plants of Arabidopsis thaliana have been described previously: AUX1:HA , GNOM-myc , PIN1:GFP , PIN2:GFP , DR5rev::GFP , doc1 (ref. 19 ), sur1 (ref. 12 ), tir3 (ref. 18 ), yucca , yucca doc1 double mutant , 35S::TMS2 (ref. 11 ) and EGFP-Q8 (PIP2)  Other antibodies were diluted as follows: anti-PIN4 (1:400) , anti-GFP (1:300; Molecular Probes ), 9E10 anti-Myc (1:600; Santa Cruz ), anti-TLG2a (1:200; Rosebiotech ), anti-AtSec12 (1:50; Rosebiotech ), anti-ARF1 (1:1,000) , anti-Atγ-COP (1:1,000) and anti-PM-ATPase (1:1,000)  Pretreatments for 30 min with 5 µM NAA, 5 µM IAA plus 400 µg ml -1 BHT, 5 µM 2,4-D, 50 µM 2-NAA, 200 µM aminocyclopropane carboxylic acid or 10 µM NAA amide were followed by 90 min of concomitant treatment with one of the above plus 50 µM BFA Quantitative confocal microscopy Quantitative confocal microscopy evaluation of the PIN2 signal was performed with Leica LCS quantification software  Seedlings 5 days old were treated with 30 µM NAA for 30 min, followed by 30 µM NAA and 50 µM BFA for 90 min, and the BFA-induced internalization of PIN1:GFP was analysed with an epifluorescence microscope Statistical significance was evaluated with Students t -test The anti-PIN2 antibody was provided by C The FM1-43 uptake experiments were performed with BY-2 cells equilibrated in 2,4-D-free medium for 24 h The measured signal was normalized to the value of control cells at 4 °C and data were expressed relative to the 26 °C control sample The purified fraction was diluted 1:400 The rabbit anti-PIN1 polyclonal antiserum was raised against amino-acid residues 288–452 of PIN1 protein and was used previously for PIN1 localization in tissue sections  The scans were performed with identical microscope and laser settings for all experiments Unless otherwise indicated, the following conditions were used Uptake and accumulation experiments Auxin accumulation experiments in suspension-cultured VBI-0 and BY-2 cells were performed as described previously  Uptake experiments with FM4-64 ( Molecular Probes ) in Arabidopsis were performed in 5-day-old seedlings, using a 5-min incubation with 1:500 dilution in AM medium A classical model, which attempts to explain multiple self-organizing auxin effects—the so-called canalization hypothesis—proposed feedback regulation between auxin signalling and intercellular auxin transport  After stimulation by gravity, asymmetric auxin flow resulted in auxin accumulation at the lower side of the root, as detected by the auxin response reporter DR5rev::GFP ( Fig. 4a ) All the results are consistent with the notion that auxin inhibits the internalization of constitutively cycling auxin efflux catalysts, thus increasing their incidence at the cell surface and thereby stimulating its own efflux All these results strongly indicate that the auxin effects on endocytosis and on its own transport might be functionally linked An auxin-dependent increase in the amount of cell-surface-localized PIN auxin efflux regulators would afford a mechanism by which auxin can control its own transport An important additional level of regulation upstream of cellular auxin signalling is a specific transport system dependent on polarly localized PIN auxin efflux regulators  An important control was the confirmation that auxins did not influence the uptake of BFA into Arabidopsis roots ( Supplementary Fig Auxin concentrations that would normally lead to the visible inhibition of BFA-induced internalization of the PIN1 protein ( Fig. 3a–c ) were ineffective in big mutants ( Fig. 3e–g ) Auxins also completely abolished the BFA-induced increase in FM1-43 internalization that results from the inhibition of membrane recycling back to the cell surface  Auxins also did not interfere with the BFA-induced formation of endosomal BFA compartments or with the aggregation of Golgi stacks at their periphery ( Fig. 2a–f , Supplementary Fig Because in VBI-0 cells, but not in BY-2 cells, 2,4-D is a good substrate for an efflux carrier ( Supplementary Fig BFA inhibits trafficking from endosomes to the PM and causes endosomes to aggregate into ‘BFA compartments’  , which become surrounded by Golgi stacks  BFA-induced reversible internalization also occurred when transcription, protein synthesis or protein degradation were inhibited ( Supplementary Fig BIG is a single-copy gene present in Arabidopsis and other plant and animal genomes Biochemical, genetic and molecular data have confirmed that auxin promotes SCF TIR1 -mediated ubiquitination and degradation of the auxin/indole-3-acetic acid (AUX/IAA) repressors, thus releasing auxin response factor (ARF) transcriptional regulators from inhibition  Both 2,4-D and NAA inhibited FM1-43 uptake in a concentration-dependent manner ( Fig. 2j ) By contrast, treatment with BFA (inhibiting the exocytic step of the cycling) had the opposite effect and caused a massive accumulation of PIN2 inside cells, decreasing the cell-surface signal (28%, P 0.001) Co-localization of cycling proteins ( Supplementary Fig Concentrations as low as 5 µM NAA and 2,4-D were enough to elicit near-maximal effects ( Fig. 1e , f , Supplementary Fig Concomitantly, auxins promote their own efflux by a vesicle recycling-dependent mechanism Double labelling revealed that, in the same cells, auxin treatment did not affect the formation of Golgi-stack-encircled BFA compartments but prevented the internalization of PM proteins and therefore their accumulation in such compartments ( Fig. 2c , f ) Earlier physiological experiments did indeed imply that auxin is required to maintain its own polar transport  For a molecular characterization of the pathway by which auxin inhibits endocytosis, we performed a genetic screen to find mutants altered in the auxin effect on endocytosis Furthermore, Arabidopsis mutants with increased concentrations of endogenous auxin such as superroot1 ( sur1 ) (data not shown) or yucca ( Fig. 1k ) showed decreased PIN1 internalization after treatment with BFA in comparison with wild-type plants Furthermore, big mutants also showed resistance to endogenously increased auxin concentrations in combination with yucca mutants, as demonstrated by a pronounced inhibition of BFA-induced internalization in yucca (see Fig. 1k ), but not in yucca big , mutant roots ( Fig. 3j ) Furthermore, in yucca roots, which contain higher concentrations of endogenous IAA , the uptake of FM4-64 was also inhibited ( Fig. 2i ) Furthermore, when assessed in parallel in planta during the gravitropic response, the same root cells that exhibited increased auxin translocation also displayed a decreased rate of endocytosis Generally, the net accumulation of radioactively labelled auxins in cells gives a measure of the relative rates of their uptake and efflux However, a direct effect of auxin on its own efflux has not been shown However, even at maximal effective concentrations, auxins did not completely block BFA-induced internalization IAA was chemically unstable under our experimental conditions (verified by high-performance liquid chromatography and mass spectroscopy; Supplementary Fig If auxins inhibit the endocytic step of constitutive cycling, the protein pool at the PM should increase after treatment with auxin In addition, the inhibitory effect of auxin on the internalization of the endocytic tracer FM4-64 (see Fig. 2g–i ) was less pronounced in big mutant roots ( Fig. 3k ) In animals, constitutive cycling is an entry point for multiple regulation, including by signalling molecules  In Arabidopsis roots, even low concentrations of exogenously applied auxins clearly decreased the detectable uptake of FM4-64 ( Fig. 2g , h ), showing the inhibition of endocytosis In Arabidopsis this cycling involves a brefeldin A (BFA)-sensitive regulator of vesicle budding, the guanosine exchange factor for adenosine-ribosylation-factor-type small GTPases (ARF GEF) known as GNOM  In constant carrier-driven (and thus saturable) transport across the PM, the auxin accumulation would be expected to exhibit saturation kinetics until the uptake and efflux rates reached equilibrium In contrast, for the pretreatment, an auxin that is a weak substrate for an auxin efflux carrier had to be used to prevent competitive inhibition of NAA efflux In contrast, no asymmetry in auxin accumulation (as detected by DR5rev::GFP; Fig. 4d ) and no inhibition of PM protein internalization in response to BFA occurred in non-stimulated roots ( Fig. 4i ) or after treatment with NPA ( Fig. 4e , f ), which under these conditions inhibits auxin flow but not protein cycling  In contrast, the physiologically inactive structural isomer of NAA, naphthalene-2-acetic acid (2-NAA), had no effect even at a tenfold higher concentration ( Fig. 1i ) In contrast, trafficking from the PM to the endosomes seems to be insensitive to BFA In Drosophila the mutations at the corresponding locus lead to multiple defects including altered synaptic transmission and male sterility ; in Arabidopsis , big mutations lead to a weak physiological resistance to auxin but also affect other signalling pathways including those for ethylene, cytokinin, gibberellin or light  In plants, even high concentrations of several phytohormones including abscisic acid, brassinosteroids, cytokinins, ethylene and gibberellins had no detectable effect on various trafficking processes, including BFA-induced internalization ( Fig. 1h , Supplementary Fig In the control (no auxin treatment), the PM pool composed approximately 62% of the total PIN2 protein In this case, the accumulation of auxin had to be measured by using an auxin that is taken up by passive diffusion (to exclude the possible interference by the activity of auxin influx carriers) and, simultaneously, one that is a good substrate for efflux carrier(s) in tobacco cells; NAA fulfilled these criteria in both VBI-0 and BY-2 cells In this manner the expression of different sets of genes is activated, thereby eliciting different cellular and, consequently, developmental responses In wild-type plants grown under normal conditions, BFA-induced internalization was clearly inhibited in these cells ( Fig. 1l ) Induced increases in intracellular concentrations of endogenous auxin also had an inhibitory effect on the internalization of constitutively cycling PM proteins. 35S::TMS2 plants overexpress the amidohydrolase that converts biologically inactive auxin amides into active auxins  Interestingly, however, auxins such as the naturally occurring IAA and its synthetic analogues naphthalene-1-acetic acid (NAA) and 2,4-dichlorophenoxyacetic acid (2,4-D) efficiently inhibited the internalization of PIN1, PIN2, PIN4, PM-ATPase, PIP2:GFP and maize cell wall pectins in response to BFA ( Fig. 1e–g , Supplementary Fig Interestingly, the sur1 mutant, which has elevated internal auxin concentrations and downregulated endocytosis, also shows increased auxin transport  It remains unclear which molecular pathway auxin uses to exhibit its effect on endocytosis Mutations in the Calossin/Pushover protein BIG render endocytosis partly auxin-resistant NAA was less effective, which is consistent with its decreased retention in tobacco cells  Next we examined the subcellular site(s) at which auxin acts on the BFA-induced internalization of PM proteins Next we investigated whether the pretreatment with auxin could directly affect the activity of auxin efflux One group of mutants that showed resistance to the auxin effect on endocytosis was allelic to transport inhibitor response3 ( tir3 ). tir3 was originally isolated in a screen for resistance to auxin transport inhibitors and other alleles have also been identified by their involvement in light signal transduction ( dark overexpression of CAB1 ( doc1 ) and attenuated shade avoidance ( asa1 )) or cytokinin response ( umbrella ( umb1 ))  Only higher auxin concentrations were able to inhibit the BFA-induced internalization ( Fig. 3d , h ) Other tested PM proteins such as PIN2 (data not shown) and PM-ATPase ( Fig. 3i ) behaved in a similar way as PIN1 Our findings indicate a previously undescribed mode of action of plant hormones, namely the modulation of protein activity by regulating their intracellular trafficking PIN proteins rapidly and constitutively cycle between the plasma membrane (PM) and endosomes  Plasma membrane H + -ATPase (PM-ATPase) was preferentially internalized in rapidly elongating epidermal cells ( Fig. 1c ), indicating the possible existence of both dynamic and more static populations of the protein Pretreatment for 20 min with 5 µM 2,4-D significantly decreased the accumulation of [ 3 H]NAA (increased its efflux) and, moreover, abolished the inhibitory effect of BFA on auxin efflux ( Fig. 2p ) Protophloem cells of root have been shown to have higher concentrations of auxin than surrounding tissues  Reduced uptake of the endocytic tracer FM4-64 was also observed at the lower side, in comparison with the upper side, of the root ( Fig. 4g , h ) Root gravitropism—the directional growth of roots along a gravity vector—is a well-characterized physiological process that involves the rapid establishment of auxin flow along the lower side of a horizontal root after gravity perception  S10a–c ) S10a–c ), we used BY-2 cells for this experiment S10d ) and a high-affinity substrate for efflux carrier(s) in tobacco cells (NAA ; Fig. 2o ) S1a ), PIN3 (ref. 4 ) and PIN4 ( Supplementary Fig S1a–c ), the endocytic tracer FM4-64 ( Supplementary Fig S1d ), the PM water channel PIP2 ( Fig. 1d ) and maize cell-wall pectins ( Supplementary Figure S1h ) S1e–g ) and endosomal markers ( Fig. 2b ) revealed that the proteins studied here recycle through the same endomembrane compartments S1i–p ) S2 ), confirming that proteins accumulating in BFA compartments were not synthesized de novo but originated from the PM S3 ) S4 ) indicating that these compounds might be sufficiently active even at lower concentrations S5 ) S5 ), but when an antioxidant (butylated hydroxytoluene; BHT ) was included in the medium, IAA was also effective at concentrations as low as 5 µM ( Fig. 1g , Supplementary Fig S6 ) S7 ) S8 ) S9 ) Several plant PM markers were rapidly and reversibly internalized in response to BFA Significantly, a similar spatial asymmetry within the root was observed for the BFA-induced internalization of PIN2:GFP and PIP2:GFP ( Fig. 4b , c ), indicating that their endocytic recycling might have been inhibited at the lower side of the gravistimulated root Taken together, these data strongly indicate that auxins might inhibit the endocytic step of constitutively cycling PIN proteins, thus increasing their levels at the PM The corresponding gene, since renamed BIG , encodes a member of the Calossin/Pushover family present in other multicellular organisms  The effects of auxin on its own transport were quantitatively assessed in suspension-grown tobacco cell lines VBI-0 and BY-2, which are well-established systems for studies of auxin transport in vivo  The lines differ in their abilities to export different auxins, and the most important feature related to this study is that 2,4-D is a much better substrate for an auxin efflux machinery in VBI-0 cells than in BY-2 cells ( Supplementary Fig The local, asymmetric distribution of the plant growth regulator auxin mediates a variety of developmental processes such as axis formation, organ initiation and positioning, directional growth (tropisms) and meristem activity  The observation that BFA compartments (revealed as an aggregation of endocytic vesicles) still formed after treatment with auxin was confirmed by an examination of ultrastructure by electron microscopy ( Fig. 2k–m ) There is no experimental support for a connection between the BIG-dependent auxin signalling pathway for inhibiting endocytosis and previously characterized SCF TIR1 -related auxin signalling for the regulation of gene expression There were no apparent effects of auxin on the distribution of ER (Sec12 (ref. 3 )), presumptive trans-Golgi network (TLG2a (ref. 3 )), Golgi apparatus (γ-COP (ref. 3 )) or endosomal (ARF1 (ref. 15 )) markers ( Supplementary Fig These auxin-induced changes in the relative rates of endocytosis and exocytosis lead to increased concentrations of PIN auxin efflux regulators at the cell surface These data do not support a direct involvement of the BIG protein in the auxin signalling pathway but rather in more general cellular processes, possibly in some aspect of endocytosis These data indicate that auxins might interfere with the endocytic step of constitutive cycling without visibly affecting other subcellular trafficking processes These data indicate that BIG is required for the auxin-mediated inhibition of endocytosis and thereby identify a molecular component of this specific pathway of auxin action These data show that some plant PM proteins are retained at the PM, but many exhibit constitutive cycling between the PM and endosomes These differential effects of BFA on endocytosis and exocytosis lead to the internalization and accumulation of constitutively cycling proteins in the BFA compartments These experiments confirmed that the endocytic step of the cycling of PM proteins is the target for auxin action These included PIN auxin efflux regulators such as PIN1 (ref. 2 ) ( Fig. 1a , b ), PIN2 (ref. 3 ) ( Supplementary Fig These proteins might be involved in subcellular vesicle trafficking, because they affect the subcellular localization of PIN1 after treatment with auxin efflux inhibitors  These two previously unidentified auxin effects share similar kinetic characteristics, substrate requirements and inhibitor sensitivities This decrease in accumulation (that is, an increase in efflux) was abolished by treatment with BFA ( Fig. 2o ), indicating that the stimulation of 2,4-D efflux was dependent on BFA-sensitive recycling of auxin efflux carriers back to PM This dynamic auxin distribution network mediates directional (polar) auxin flow between cells, which contributes to the formation and maintenance of asymmetric auxin distribution This effect was completely reversed by both a known inhibitor of auxin efflux (1-naphthylphthalamic acid (NPA); Supplementary Fig This finding strengthens the likelihood that the effects of auxin on endocytosis and on auxin transport are linked This is inferred from the observation that some accumulation of constitutively cycling PM proteins inside cells could be observed when the treatment with BFA in the presence of auxins was prolonged ( Supplementary Fig This process represents an ideal system in which to examine auxin translocation and endocytic recycling in parallel This shows that the observed decrease in 2,4-D accumulation results from an increased capacity in its carrier-driven efflux Through this mechanism, hormones such as insulin or vasopressin can control the relative rates of endocytosis and exocytosis and thereby regulate the concentrations, and thus the activity of surface-localized proteins, including ion and water channels, transporters and receptors  Thus it is possible that the auxin effect on endocytosis uses a previously unknown and so far molecularly uncharacterized signalling pathway that does not involve the regulation of gene expression. Thus our results show, and provide a mechanistic explanation for, a positive auxin effect on auxin transport rate Thus, asymmetric auxin translocation is closely correlated spatially with the inhibition of endocytosis during the root gravitropic response Thus, in Arabidopsis BFA can serve as a tool for revealing subcellular protein movement between endosomes and the PM  To assess directly the effect of auxin on endocytosis, we used the fluorescent dye FM4-64, an established endocytic tracer  To assess possible effects of auxin on different trafficking processes, we used established markers for various endomembrane compartments To confirm and quantify the auxin effect on endocytosis, we measured the uptake of another endocytic tracer, FM1-43 (ref. 16 ), into suspension-grown tobacco BY-2 cells To test this prediction we directly measured the ratio of cell surface to internalized PIN2 protein by using quantitative confocal microscopy Together, these data show that in tobacco cells in vivo , auxin stimulates its own efflux by a vesicle-trafficking-dependent mechanism Together, these results show that physiological concentrations of exogenously applied and/or endogenously produced auxins downregulate the BFA-induced internalization of constitutively cycling PM proteins Treatment with auxins (NAA) increased the cell-surface signal significantly (85%, P 0.001), showing higher levels of PIN2 at the PM ( Fig. 2n ) We found that in both the tir3 and doc1 alleles of big , endocytosis of PM proteins was inhibited by auxins less than in the wild type We have shown that biologically active auxins, but not their biologically inactive analogues nor other plant hormones, negatively regulate endocytosis and the internalization of constitutively cycling proteins from the PM We next explored in planta the link between the effects of auxin on endocytosis and auxin transport When treated with NAA amide or IAA amide, 35S::TMS2 ( Fig. 1j ) but not wild-type plants (data not shown) showed inhibition of BFA-induced PIN1 internalization When VBI-0 cells were incubated with [ 3 H]2,4-D, after an initial increase in its internal concentration, the accumulation of [ 3 H]2,4-D decreased steadily with time instead of reaching a stable equilibrium ( Fig. 2o )
 By detuning the laser frequency with respect to the cavity resonance, we have observed a drastic cooling of the microresonator by intracavity radiation pressure, down to an effective temperature of 10 kelvin For opposite detuning, efficient heating is observed, as well as a radiation-pressure-induced instability of the resonator Further experimental progress and cryogenic operation may lead to the experimental observation of the quantum ground state of a micromechanical resonator , either by passive or active cooling techniques . Here we present an experiment where a micromechanical resonator is used as a mirror in a very high-finesse optical cavity, and its displacements are monitored with unprecedented sensitivity Operation at higher powers will be crucial for further sensitivity enhancement, but dynamical effects caused by radiation pressure on the interferometer mirrors must be taken into account, and the appearance of optomechanical instabilities may jeopardize the stable operation of the next generation of interferometers  Recent table-top optical interferometry experiments and advances in gravitational-wave detectors have demonstrated the capability of optical interferometry to detect displacements with high sensitivity Such ‘optical spring’ effects have already been demonstrated for the mechanical damping of an electromagnetic waveguide with a moving wall , the resonance frequency of a specially designed flexure oscillator , and the optomechanical instability of a silica microtoroidal resonator  These instabilities are the result of a nonlinear coupling between the motion of the mirrors and the optical field, which modifies the effective dynamics of the mirror A similar result has recently been demonstrated with a silicon microlever, using the photothermal force rather than radiation pressure  Above this line, the resonator becomes unstable and starts to oscillate at its effective resonance frequency, as has already been demonstrated with a microtoroidal resonator  Additional dephasings appear, and the radiation-pressure force F rad can be written in Fourier space : with where x [ Ω ] is the Fourier component of the resonator displacement, φ  = Ψ/γ the detuning normalized to the cavity damping rate γ , and Ω c the cavity bandwidth. ϕ  NL is a nonlinear phase-shift which characterizes the optomechanical coupling between the resonator and the light in the cavity Also note that the secondary peaks on the red spectrum of Fig. 3b (more than 50 dB below the resonance spectrum level) are due to the lower stability of the cavity operation close to the instability region As a consequence, the spring constant of the resonator is balanced by the radiation-pressure force: for a positive detuning, the displacement creates a negative linear force and thereby an additional binding force, increasing the effective spring constant, whereas for a negative detuning, the force corresponds to a softening of the oscillator As the Langevin force is not modified, one gets a situation somewhat similar to that obtained by cold damping : the system still obeys the fluctuation-dissipation theorem , but at a different effective temperature, given for small frequency shifts (Ω eff  - Ω m ) by: Both radiation-pressure cooling and heating can therefore be performed, depending on the sign of the cavity detuning As we are only interested in the motion at frequencies Ω close to a resonance frequency Ω m of the resonator, the mirror dynamics can be approximated as those of a single harmonic oscillator, with resonance frequency Ω m , mass M , damping Γ m and mechanical susceptibility χ m [Ω] given by: The resonator is submitted to a radiation-pressure force F rad induced by the intracavity field Bolometric effects are difficult to estimate, but both the low absorption and the large thickness of the resonator are in favour of a negligible effect Both are in very good agreement Both cooling and heating are evident on the noise spectra of Fig. 3  Both the quality of the low-loss dielectric coating and the low roughness of the resonator have allowed us to reach an optical finesse F  = π/γ = 30,000 , with a cavity bandwidth Ω c /2π = 1.05 MHz ( L  = 2.4 mm) Depending on the detuning Ψ  ≡ 4π L / λ [2 π ] , where L is the cavity length and λ the laser wavelength, any small displacement x of the resonator induces a variation of the intracavity power P and of the radiation pressure ( Fig. 1b ) Effects are null at resonance, maximum at the half-width of the optical resonance, and proportional to the incident power Experimental series of points were taken for fixed stabilized incident powers, following the Airy curves in the plane Figure 3 shows the thermal noise spectra obtained for negative detunings and a 5 mW incident beam ( Fig. 3a ), and for positive detunings and a 2.5 mW incident beam ( Fig. 3b ) Figure 4a presents our experimental results, for five optical powers from 0.5 mW to 3.2 mW, along with the theoretical fits deduced from equations (7) and (8)  Figure 4b presents a colour-chart of the dependence of the effective damping Γ eff in the detuning/intracavity power plane Figure 4c displays the variations of the effective temperature with the detuning ϕ  First, the calibration is performed when the cavity is at resonance with a frequency modulation of the laser  For a fixed input power of 3.2 mW, T eff ranges from 20 K at an optimum detuning φ ≈ −0.45 , to 2,000 K for a positive detuning, very close to the instability region For a negative detuning, the spectra are both widened and drastically decreased at their resonance frequencies For larger negative detunings, the noise spectrum is so low that the thermal noise background due to other vibration modes of the resonator is no longer negligible: a slight modification of our model taking this background into account depicts well the characteristics of our experimental results (solid line) For that purpose, we drive the resonator into motion (with an amplitude of ∼10 −13 ) with a modulated electrostatic force at 814 kHz and monitor the displacement signal for different detunings, and an incident power (50 µW) low enough to ensure that radiation pressure has no effect Further enhancement and low-temperature operation of such a system may lead to the experimental demonstration of the quantum ground state of a mechanical resonator : radiation-pressure cooling is a fundamental process that involves nothing but a mechanical oscillator in interaction with one cavity mode and its quantum fluctuations, yielding a reliable estimation of the cooling limit Furthermore, our knowledge of the other modes’ dynamical behaviour appears as a major issue on the road to the quantum ground state, as their out-of-resonance tails will no longer be negligible for extreme cooling ratios Grey curves correspond to equal effective dampings Γ eff and the black one to Γ eff  = 0 In both cases, the black curve corresponds to the resonant situation ϕ  = 0 In our experiment ( Fig. 2 ), a silicon doubly-clamped (1 mm × 1 mm × 60 µm) beam with a mirror coated upon its surface is used as a back mirror of a single-ended Fabry–Perot cavity  In our experiment, however, owing to the high-finesse cavity and the high resonance frequency, such a static approach is no longer valid and one has to take into account the cavity storage time to evaluate the resonator dynamics In particular, a mode with a resonance frequency Ω m  = 2π × 2.824 MHz larger than the cavity bandwidth Ω c exhibits a frequency shift (Ω eff  - Ω m ) with an opposite sign, as expected from equations (3) and (7) for not-too-large detunings ϕ  Indeed, with the estimated mirror absorption (∼3 p.p.m.), thermoelastic effects are expected to be 10 6 times lower It corresponds to the normalized phase-shift of the cavity induced by the static recoil effect of the resonator and is given by: At thermodynamical equilibrium, the equation of motion of the resonator is: where F T is the Langevin force responsible for the brownian motion  It exhibits the expected linear dependence, with P / P in  = 2,970 in agreement at the 1% level with the value deduced from cavity and insertion losses Note also in both cases the clear frequency shift (Ω eff  - Ω m ) of the resonances Other possible novel effects in quantum optics include the experimental demonstration of the standard quantum limit , radiation-pressure-induced squeezing of light , quantum non-demolition measurements or non-classical states of the resonator motion . Our experimental results can be further tested by looking at the dependence of both the damping ratio Γ eff /Γ m and the frequency shift (Ω eff  - Ω m )/2π with respect to the detuning ϕ  Our experimental set-up is to our knowledge the first high-sensitivity optical displacement sensor to show a direct effect of radiation pressure, a ubiquitous—though extremely weak—back-action effect that every optical experiment will eventually (once all technical problems are resolved) be sensitive to, once limited only by quantum noise Second, we have to take into account the lowering of the sensitivity for a non-zero detuning, which stems from two origins: the lower dependence of the phase response with cavity detuning away from resonance, and the distortion of the PDH signal for large detunings Such a high finesse dramatically increases both the radiation-pressure cooling effect and the sensitivity of the phase of the reflected field to the resonator displacements The absence of any spurious noise in the spectra is due to both the high sensitivity of our experiment and the stable operation of the cavity The calibration of our set-up is performed in two steps The colour code ranges from dark blue (for large Γ eff and low T eff ) to red (for low Γ eff and large T eff ) The decrease of the area of the curves, which is directly related to the effective temperature by the equipartition theorem, is a strong indication of the temperature reduction The dependence with ϕ  is well accounted for by our single oscillator theoretical model ( equation (9) ) for positive and negative but not too large detunings (dashed line) The discrepancy is accounted for by the overall accuracy of both the FEM computation and the fabrication of the microresonator, by the imperfect overlap of the vibration mode with a non-centred optical beam, and by the coupling of the mode with the ones of the wafer the resonator is engraved onto The green points (corresponding to Γ  eff  ≈  Γ  m ) are located at the resonance, at large detunings (where the slope of the Airy peak vanishes) and at low intracavity power (where radiation-pressure effects are weaker) The highest cooling (dark blue) is obtained near a negative detuning φ ≈ −0.6 and for a high intracavity power P , whereas the largest heating effect (red) is obtained for a positive detuning The inset shows the intracavity power at resonance P , the single free parameter derived from the preceding fits, as a function of the incident power P in  The observed modulation has been used to calibrate every spectrum observed The Q factor in equation (8) indicates a much stronger dependence of the damping upon radiation-pressure effects as long as the imaginary part of 1/Δ stays comparable to its real part, that is, for Ω m  ≈  Ω c  The radiation-pressure effects can then increase or decrease the damping of the resonator, depending on the sign of the detuning The residual discrepancy at large detuning (leftmost point in Fig. 4c ) cannot be related to a residual heating process since effective temperatures as low as 10 K have been obtained with a 12 mW incident beam The resonator is placed at the end of a linear cavity, along with a conventional coupling mirror ( Fig. 1a ) The situation is opposite for positive detunings, where the spectra are strongly narrowed and increased at resonance These effects have already been directly observed , as well as the bistable behaviour of the cavity for a negative detuning  This clearly shows that the observed cooling effect is solely due to radiation pressure This equation of motion can be rewritten from equation (2) without the radiation-pressure term, but with an effective mechanical susceptibility χ eff [Ω]: In the limit of a mechanical quality factor Q  = Ω m /Γ m  ≫ 1, χ eff [Ω] still has a lorentzian shape, but with effective resonance frequency and damping given by: where Δ is now evaluated at the resonance frequency Ω m  This is to our knowledge the first experimental demonstration of such a radiation-pressure instability in an open optical cavity This thermal noise spectrum (r.m.s. amplitude ∼2.9 × 10 −14 , driven by a 8 × 10 -25 N 2  Hz -1 Langevin force spectral density) has been used to infer the value of the effective mass (190 µg) used throughout this Letter This value is in good agreement with a finite-element method (FEM) computation, which yields a value of 130 µg Using a highly stabilized laser source and a Pound–Drever–Hall (PDH) phase modulation scheme has indeed allowed us to reach a sensitivity of 4 × 10 −19 m Hz −1/2 near the resonance frequency ( Supplementary Information ): the thermal peak of the resonator at room temperature is observed with a 50 dB signal-to-noise ratio with respect to the background thermal noise of the surrounding vibration modes We have also performed the same experiment for other modes of the resonator, with the same excellent agreement with theory We have observed a similar effect, as shown on Fig. 4a and b , where the instability region is displayed with no adjustable parameter We use one particular vibration mode, which has the following characteristics: Ω m /2 π  ≈ 814 kHz , an effective mass M  = 190 µg, a spring constant k  ≈ 5 ×10 6 Nm −1   , and a mechanical quality factor Q  = 10,000 ( Supplementary Information ) in vacuum (residual pressure below 10 -2  mbar), with the whole vacuum chamber at room temperature T  = 300 K
 Among its many intuitive features, the conditional-entropy function is always greater than or equal to zero As the omitted letters can be inferred with near-certainty from the others, they dont contribute to the uncertainty about the sentence and can therefore be compressed away Claude Shannons landmark 1948 theory of communication tackles a nuts-and-bolts question: how do we find the best way to communicate using a given resource, such as a telegraph line or a satellite antenna? To answer that question, Shannon first took a detour into more philosophical territory by working out how to quantify the elusive concepts ‘uncertainty’ and ‘information’ Conditional uncertainty can be represented in similarly simple terms Entanglement is such a strong form of correlation that it can actually be used to send qubits from the sender to the receiver using a procedure known as quantum teleportation  For example, X and Y could represent future issues of the Financial Times and The Wall Street Journal , respectively: readers who take the time to follow both newspapers will be intimately familiar with the practical meaning of the inequality! In the context of conditional uncertainty, the interpretation is again highly intuitive: the amount of extra information required to decipher a message cannot be less than zero bits or, equivalently, it is impossible to be more than certain about the outcome of an event Horodecki, Oppenheim and Winter analyse a quantum-mechanical version of the message-completion problem and find that the amount of extra information required can sometimes be less than zero qubits (a qubit is simply the quantum version of a bit) If some extra letters are provided, however, the task becomes feasible: T_ _ s / i _ / _ a _ d _ r / t_ / r _ a d If Y is used to represent the information already given to the receiver — the analogue of the indecipherable four letters in our example — the amount of extra information that must be provided is H(X,Y) – H(Y) , a quantity known as the conditional entropy of X given Y (ref. 3 ) In general, the ‘uncertainty’ of a data source is the amount of space in bits required to transmit its output reliably In more technical language, the puzzle was how to quantify conditional uncertainty In other words, the receiver can be more than certain! In practice, if the receiver is more than certain, the sender doesnt need to transmit any qubits at all for the receiver to be able to decipher the message In such cases, the systems A and B are said to be entangled (for a popular account of this phenomenon, see ref. 5 ) In their formulation, what had been pathological becomes profound: with quantum information, it is possible not just to be certain, but to be more than certain In their version of the problem, there are three participants: call them the sender, the receiver and the referee Inspired by Shannon, but working with the notoriously counterintuitive theory of quantum mechanics, they seek to understand uncertainty and information in the quantum world by analysing the practical questions first, in the hope that the answers might then illuminate more fundamental conceptual issues Intuitive indeed, but alas no longer true in quantum information theory It is no longer possible to decipher the sentence uniquely because there are many grammatically correct options More than half a century on, quantum-information theorists have in many ways taken the opposite approach Most readers will be able to decipher the following English sentence: D r _ p / e _e r _ / t h _ r d / _ e t _ e r Now consider another sentence, this time with more than three out of every four letters deleted: T_ _ _ / _ _ / _a_ _ _r / _ _ / _ _ a _ On page 673 of this issue , Horodecki, Oppenheim and Winter demonstrate how effective this approach can be by justifying, in operational terms, a definition of conditional uncertainty that had previously been widely rejected owing to its strange and apparently nonsensical properties On the accounting ledger, therefore, having stored entanglement is almost as good as being able to communicate Once again, quantum information has proved to be more versatile and more surprising than anyone expected. One consequence of entanglement is that conditional uncertainty, S(A,B) – S(B) , can sometimes be less than zero One of Shannons seminal results was to find a simple formula for the uncertainty of a data source X  So the receiver can put some certainty in the bank for a rainy day, in the form of extra entanglement with the sender that could be used to reduce the receivers uncertainty about future messages Thats because there is potentially more to be ignorant of in two messages X and Y together than in Y alone, so the inequality H(X,Y) ges; H(Y) holds The authors provide a sampling of these applications in their paper, including an easy solution to a quantum version of the problem of many cellphones trying to communicate simultaneously to a single base station  The authors show that the number of qubits that the sender needs to transmit is precisely S(A,B) – S(B) , where A now refers to the senders particles, B to the receivers particles and S is the von Neumann entropy, a direct quantum-mechanical generalization of Shannons entropy The formula S(A,B) – S(B) had been proposed , but was widely rejected because of its pathological tendency to become negative The gap between what was provided at first (four letters), and what allowed us to decipher the sentence (no more than ten letters) illustrates the notion of ‘conditional uncertainty’ — the amount of extra information required to decipher a message The referee prepares a quantity of quantum information consisting of many particles, some of which he distributes to the sender and the receiver, and the rest he keeps for himself The senders job is to find an encoding that allows her to transfer her share of the information to the receiver using as few qubits as possible This astonishing solution shows that one senders quantum information can, despite its fragility, be used to help decode the other senders transmissions at higher rates than would otherwise be possible This formula is identical in form to the solution of the non-quantum version This function, usually written H(X) , is known as the Shannon entropy of X  This neat and satisfyingly bizarre resolution disposes of a long-standing puzzle in quantum information theory: put simply, how to quantify who knows what This second formula is easy to interpret: the extra information required is equal to the uncertainty in the total message, consisting of both X and Y , minus the uncertainty owing to Y alone, which should be subtracted, as Y is already known To further isolate the quantum-mechanical features of the problem, the sender is also allowed to send old-fashioned messages consisting of bits at zero cost To understand what such a statement could mean requires first absorbing how information theorists think about uncertainty Until now, no one had succeeded in finding a setting in which the formulas full range of positive and negative values would have a meaningful interpretation. (It was a quantum-information theorists version of the famous conundrum from The Hitchhikers Guide to the Galaxy : if 42 is the answer to Life, the Universe and Everything, what is the question?) In addition to finally placing the quantification of uncertainty in quantum mechanics on a solid footing, the new result opens the door to solving many previously intractable problems in quantum information theory With quantum particles, however, it is possible for A and B to be correlated in ways that are impossible in the classical situation 
 Affected countries are failing, or refusing, to share their human samples with the WHOs influenza programme in Geneva And from the dozens of patients who caught the deadly H5N1 strain this year, the WHO has managed to obtain just six samples And Perdue is hopeful that other countries will follow: “The presentations drove home the importance and urgency of sharing data.” And the FAO and OIE are drafting a standard ‘material transfer’ agreement to clarify the conditions of use of flu samples, and the intellectual-property rights of the countries that provide them But he argues that the FAO and OIE are in a difficult position. “Some countries have provided samples but stipulated that the information cant be shared with the wider community,” he says But Nature has discovered that it is nearly eight months since the World Health Organization (WHO) last saw data on isolates from infected poultry in Asia But that is not enough to indicate a broader change in the strain, says Perdue Countries are wary of sharing viruses with outside laboratories because they fear losing control over information, says one flu expert. “Authorities in Vietnam are very sensitive as to what they tell the people,” he explains. “They dont want outside groups making pronouncements and these getting into the press without being vetted by the ministries of health and agriculture.”  Scientists in countries with avian flu often want to work on virus samples first, he adds Domenech argues instead that the FAO has no recent samples to share Early signals that the virus is mutating might be picked up from viruses circulating in poultry Human cases are beginning to appear in clusters, which suggests that people are transmitting the virus, older people are falling ill, and milder cases are being reported It is also impossible for the agency to link this mutation of the virus to possible changes in how pathogenic and transmissible it is in humans Meanwhile, the WHO has begun soliciting poultry samples directly from affected countries One FAO consultant, who also asked not to be named, confirms there is a “time lag” in sharing what samples there are with the WHO Paris Tracking genetic changes in bird-flu viruses is vital for early warning of a human pandemic Sensitive samples Some countries dont have the resources to collect, conserve and securely transport samples, says Joseph Domenech, head of the Animal Health Service at FAO headquarters in Rome (see Nature 433 , 102 – 104 ; 2005 ). “But things that should be happening are not,” he adds. “Samples sometimes sit in labs,” lacking authorization for export Stöhr, Perdue and other WHO officials flew to Manila in the Philippines last week to meet government health representatives from Vietnam, Cambodia and Laos Such lack of cooperation is a key concern as anxiety about a possible pandemic increases Such studies “arent happening”, says Stöhr Taken together, these trends suggest that the virus is becoming less virulent and more infectious — two characteristics typical of pandemic flu strains That would require molecular information on hundreds of viruses, and full clinical data on the cases from which they come The FAO and the World Organisation for Animal Health (OIE) should be collecting samples, but a recent FAO check reveals that the agency has not been receiving any The meeting heard that Vietnam has recently agreed to ship a large number of poultry samples direct to the WHO flu centre at the US Centers for Disease Control and Prevention in Atlanta, Georgia The talks included presentations on the mutated human strains The UN Food and Agricultural Organization (FAO) set up a network of labs to collect animal samples last year, but it has not received any for months, and Michael Perdue, head of Animal Influenza Liaison at the WHO flu programme, complains that the FAO “hasnt been sharing” what it does have The WHOs flu programme was last given access to a sample in October 2004, so it has no idea how the virus is changing in birds There has been “complacency” at national levels, he admits, adding that the FAO has now instructed its regional networks to redouble their efforts to acquire isolates They want to get credit for their work, he explains, and to use the data to develop their own vaccines With so few samples to work on, it is impossible to judge how worried to be, says Klaus Stöhr, coordinator of the WHOs flu programme. “Its as if you hear a noise in your car engine, but you keep driving, not knowing whether its serious.”  Of the six human samples that the WHO has received from Vietnam, several contain a mutated version of H5N1
 A A group led by Jörg Weber of the Charité Medical School in Berlin, Germany, has now worked out how the bacterium damages the endothelial cells that make up the barrier A recent paper in Science (D Am Am Another approach is to use multiple magnetic layers, so more than one bit can be stored per spot Appl Because these molecules interactions are weak, they can be displaced by other molecules that bind to gold, such as alkanethiols Blocking the first rapid flux stops the sperm changing direction even though the second wave elevates Ca 2+ levels, revealing a surprising complexity in calcium-ion signalling But how can we use such a wealth of figures to find out about natural selection? One tantalizing idea is that we can measure — in an objective way — how quickly species are evolving But instead of escaping straight from the endosome into the outer regions of the cell, the virus within its endosome entered a small bubble-like vesicle But Phillip Messersmith and colleagues at Northwestern University in Illinois, Evanston, plan to turn one of their own proteins against them But rather than responding to overall levels of Ca 2+ , as previously thought, the sperm react to the rate at which its concentration changes, reports a team led by Christopher Wood at the National Autonomous University of Mexico, Cuernavaca But researchers led by Stephen Higgs of the University of Texas Medical Branch in Galveston have shown that the virus can pass between two mosquitoes if they sip blood simultaneously from an uninfected host But researchers will not rest until they have tested its validity in extremely strong electric fields, such as those generated by heavy nuclei Cell Biol. doi:10.1083/jcb.200411001 (2005) Eggs attract sperm by releasing chemicals that boost calcium ion (Ca 2+ ) levels inside a sperm, so altering the direction in which it swims Cell biology: Calling tails J Chem Chem Clin Combining the two tactics, researchers from the University of Konstanz in Germany and the Hitachi San Jose Research Center in California deposited multiple layers of cobalt and palladium onto a field of silicon pillars, spaced 300 nanometres apart Counting the number of sweeps that have affected the human genome will, I suspect, tell us that our species is changing rapidly through adaptation Culture shock Nature Med. doi:10.1038/nm1268 (2005); Proc Data storage: Pillar talk J Experiments in sperm from the sea urchin Arbacia punctulata suggest that attractant chemicals trigger two waves of Ca 2+ that pass through the sperms tail First they identified a gene with different variants in a population Genetic differences in a population accumulate randomly over time, so regions of the genome where polymorphisms are rare must have been swept clean recently by a spreading variant of a gene Hinds et al . 307, 1072–1079; 2005) is a prime example of such a set, but we have yet to exploit them His group, and teams headed by Francis Chisari at the Scripps Research Institute, California, and Charles Rice at Rockefeller University, New York, propagated this clone in a human liver-cancer cell line His team persuaded 1-adamantanethiol molecules to self-assemble into a monolayer on gold Immunology: Poxy antibodies Nature Med. doi:10.1038/nm1261 (2005) More than 200 years after Edward Jenner realized that infection with cowpox made milkmaids resistant to the smallpox virus, a group led by Genoveffa Franchini from the National Cancer Institute in Bethesda, Maryland, has discovered how a smallpox vaccine based on the vaccinia virus confers immunity In independent papers, three teams now report successful in vitro systems for propagation, using a unique hepatitis C virus clone derived from a Japanese patient by Takaji Wakita at the Tokyo Metropolitan Institute for Neuroscience In the 1970s, studies followed a common pattern In this case, the recipient mosquito may acquire the virus by directly ingesting infected saliva from a feeding neighbour, but this remains to be proven Invest. 115, 1607–1615 (2005) To cause meningitis, Streptococcus pneumoniae must find its way across the blood–brain barrier Journal Club John Brookfield University of Nottingham, UK A population geneticist ponders the evolution of his field Materials: Foul play J Medicine: Barrier grief J Nanotechnology: Going for gold J Natl Acad Natl Acad Now that we have DNA sequences, we can find single nucleotide polymorphisms, in which a single letter of the sequence varies Once a variation in a gene, known as a polymorphism, was identified, they tried to establish whether natural selection was operating on it One pathway is triggered by toxins produced by living S. pneumoniae , the other by components of its cell wall Phys. 97, 103910 (2005) One way to pack more data on to magnetic disks is to pattern the surface, defining small dots that store single bits Quantum physics: Lamb chops Phys Rev Lett. 94, 223001 (2005) The field theory of electromagnetism — known as quantum electrodynamics — is the best-tested theory in physics Sci Sci Since I started in the business of population genetics, the field has been transformed by the extraordinary increase in size of the data sets Soc. 127, 7972–7973 (2005) Mussels stick tenaciously to the hulls of boats, and this increases the boats drag Soc. doi:10.1021/ja042621o (2005) Spherical cages of carbon atoms that attach gently to gold should allow more complex molecular patterning of gold surfaces, according to Paul Weisss group at the Pennsylvania State University, University Park That could explain why we seem so different from our ape relatives That meant looking for detectable differences between individuals — for example, as in my PhD, differences in the charges of enzymes The authors of the Science paper use DNA chips to find the frequencies of more than 1.5 million single nucleotide polymorphisms in three human populations The B cells produce antibodies that bind specific poxvirus proteins — and the researchers found that antibodies from vaccinated humans protected macaques from severe disease The cell swallowed the virus into a structure called an early endosome at the cells edge, as expected The finding may assist the search for a safer alternative to the current live-virus vaccine The first is short and rapid, the second long and slow The latter mechanism has implications for therapeutic treatment — antibiotics that target the S. pneumoniae cell wall might cause further tissue damage through the release of cell-wall debris The material could have applications not only in marine engineering but also in medicine, for example, to keep implanted devices clean The non-stick element is a polymer made from an artificial analogue of glycine The surrounding layer would prevent the pattern spreading by diffusion, overcoming a problem encountered when some molecules are printed on bare gold surfaces The team tracked the vesicular stomatitis virus as it infected cultured cells The test was three times more precise than the previous best measurement Their systems produce high yields of virus that can be used to infect further cells These sweeps are evidence of adaptive change These vesicles only fuse with the outer membrane of the endosome when the complex is deep inside the cell, releasing the virus right next to the cells nucleus They find that the pathogen induces programmed cell death through two different mechanisms They have developed an antifouling polymer that prevents biological adhesion — a non-stick compound is anchored to a surface by a peptide that mimics the adhesive protein of blue mussels ( Mytilus edulis ) They stored two bits per pillar, giving higher data densities than otherwise possible with this scale of patterning This made it possible to see the Lamb shift, a split in energy levels usually visible only in the single-electron hydrogen atom This means that infection takes place in two steps — not one, as previously thought This should make it possible to print patterns of molecules, perhaps with conducting or sensing properties, into the 1-adamantanethiolate layer This type of transmission has previously been demonstrated in ticks and blackflies Titanium coated with the antifouling polymer remains relatively cell-free in a culture of tissue-forming fibroblasts for months To do this, Alexandre Gumberidze of the Heavy Ion Research Centre in Darmstadt, Germany, and his colleagues measured a tiny split in the energy levels of a uranium ion from which all but one electron had been stripped Understanding the life cycle of the virus is essential for developing effective treatments, but progress has been limited because the virus is difficult to grow in culture and therefore hard to study USA doi:10.1073/pnas.0503596102 (2005); Science doi 10.1126/science.1114016 (2005) More than 170 million people worldwide are infected with the virus that causes hepatitis C, a major liver disease USA doi:10.1073/pnas.0503835102 (2005) The discovery that one mosquito can transmit the West Nile virus directly to another may help explain the surprisingly rapid spread of the disease through North America Using macaques infected with monkeypox virus, which is a good model for smallpox infection in humans, the researchers showed that the protective power of the vaccine is mediated by the immune systems B cells, rather than its T cells Usually mosquitoes ( Culex pipiens quinquefasciatus ) pick up the West Nile virus by feeding on birds infected with it Viral transport: Stowaways Nature Cell Biol. doi:10.1038/ncb1269 (2005) Certain viruses improve their ability to infect cells by stowing away in structures called internal vesicles, according to a team led by Jean Gruenberg at the University of Geneva, Switzerland We might also identify the genes in which these changes have occurred — a perennial goal of human evolutionary genetics. West nile disease: Blood wedding Proc
 Comparison with the human and chimpanzee genomes reveals that modern human and Neanderthal DNA sequences diverged on average about 500,000 years ago Direct high-throughput sequencing of a DNA extract from this fossil has thus far yielded over one million base pairs of hominoid nuclear DNA sequences Existing technology and fossil resources are now sufficient to initiate a Neanderthal genome-sequencing effort. Neanderthals are the extinct hominid group most closely related to contemporary humans, so their genome offers a unique opportunity to identify genetic changes specific to anatomically fully modern humans We have identified a 38,000-year-old Neanderthal fossil that is exceptionally free of contamination from modern human DNA A 95% confidence interval generated by bootstrap re-sampling of the alignment data gives a range of 465,000 to 569,000 years A Neanderthal genome sequence would therefore allow the research community to determine whether DNA sequence differences between humans and chimpanzees that are found to be functionally important represent recent changes on the human lineage A necessary first step for sequencing nuclear DNA from Neanderthals is therefore to identify a Neanderthal specimen that is free or almost free of modern human DNA A schematic neighbour-joining tree estimated from this alignment is shown in Fig. 3  A total of 41 unique DNA sequences from the Vi-80 fossil had their closest hits to different parts of the human mtDNA, and comprised, in total, 2,705 base pairs of unique mtDNA sequence A total of 736,941 positions contained the same base in all three groups Actinomycetales , a bacterial order with many soil-living species, was the most populous order and accounted for 6.8% of the sequences Additionally, late in their history, some Neanderthal groups adopted cultural traits such as body decorations, potentially through cultural interactions with incoming modern humans  All Neanderthal-specific changes were therefore disregarded in the subsequent analyses and the Neanderthal sequences were used solely to assign changes to the human or chimpanzee lineage where the human and chimpanzee genome sequences differ and the Neanderthal sequence carries either the human or the chimpanzee base All other individual orders were substantially less frequent Although ancient DNA is degraded and damaged, this comparison controls for many of the aspects of the analysis including sequencing and alignment methodology Although some of these sequences are extremely short, they are all more closely related to one another than to modern human mtDNAs  Although there is no evidence of contemporaneous cohabitation at any single site, there is evidence of geographical and temporal overlap in their ranges before the disappearance of Neanderthals Although this is at present a daunting task, technical improvements in the procedures described here that would make the retrieval of DNA sequences of the order of ten times more efficient can easily be envisioned (our unpublished results) Among the mtDNA sequences analysed, there are 14 positions where the Neanderthal carries a base identical to the chimpanzee, and 13 of those were confirmed by PCR An important artefact of local sequence alignments, such as those produced here, is that they necessarily begin and end with regions of exact sequence identity Ancestral population size Humans differ from apes in that their effective population size is of the order of 10,000 while those of chimpanzees, gorillas and orang-utans are two to four times larger  Are fossil and technical resources today sufficient to imagine the determination of a Neanderthal genome sequence? The results presented here are derived from approximately one fifteenth of an extract prepared from ∼100 mg of bone As a corollary, it is possible to envision the determination of a Neanderthal genome sequence As expected, this estimate of the average human diversity is less than the divergence seen between the human and the Neanderthal sequences, but constitutes a large fraction of it because much of the human sequence diversity is expected to predate the human–Neanderthal split  As seen in Fig. 5 , the patterns of the chimpanzee-specific and human-specific changes are similar to each other in that the eight transversional changes are of approximately equal frequency and about fourfold less frequent than each of the four transitional changes, yielding a transition to transversion ratio of 2.04, typical of closely related mammalian genomes  As seen in Fig. 6b , we recover a line describing combinations of population sizes and split times compatible with the data and lack power to be more precise (see Supplementary Methods and Results ) As suggested by the analysis of the mtDNA sequences, this category contains positions that have changed on the Neanderthal lineage, as well as a large proportion of errors that derive both from base damage that have accumulated in the ancient DNA and from sequencing errors As we show above, in regions not affected by sweeps a substantial proportion of polymorphic sites in humans will carry derived alleles in the Neanderthal genome sequence, whereas no sites will do so in regions affected by sweeps Assuming that the evolutionary rate of DNA change was the same on the Neanderthal and human lineages, the majority of observed differences specific to the Neanderthal lineage are artefacts Assuming that the ratio of Neanderthal to contaminating modern human DNA is the same for mtDNA as it is for nuclear DNA, the Vi-80 bone therefore yields DNA fragments that are predominantly of Neanderthal origin and provided that the contamination rate was not increased during the downstream sequencing process, the extent of contamination in the final analyses is below ∼6% At 3,447 positions, the Neanderthal base differs from both the human and chimpanzee bases, which are identical to each other At 434 positions, the human base differs from both the Neanderthal and chimpanzee bases, which are identical to each other Because the 454 sequencing technology allows the base in a base pair from which a sequence is derived to be determined, the relative frequencies of each of the 12 possible categories of base changes can be estimated for each evolutionary lineage Because the latter conclusions are based on mtDNA, a single maternally inherited locus, they are limited in their ability to detect a Neanderthal contribution to the current human gene pool both by the vagaries of genetic drift and by the possibility of a sex bias in reproduction Both X and Y chromosomes are represented, with a lower coverage of 2.18 and 1.62 bases per 10,000, respectively, showing that the Vi-80 bone is derived from a male individual Consistent with this, modern human sequences determined by 454 sequencing show no excess amount of C to T or G to A differences ( Supplementary Fig. 2 ), indicating that lesions in the ancient DNA rather than sequencing errors account for the majority of the errors in the Neanderthal sequences Direct large-scale DNA sequencing from the Vindija Neanderthal Because the Vi-80 Neanderthal bone extract is largely free of contaminating modern human mtDNA, we chose this extract to perform large-scale parallel 454 sequencing  Each autosomal nucleotide position in the alignment that did not contain a deletion in the Neanderthal, the human or the chimpanzee sequences and was associated with a chimpanzee genome position with quality score ≥30 was classified according to which species share the same bases ( Fig. 5 ) Fifth, because each sequenced product stems from just one original single-stranded template molecule of known orientation, the DNA strand from which the sequence is derived is known  Figure 1 shows that the level of contamination differs drastically among the samples Figure 4 shows where they map to the human karyotype (see Supplementary Methods ) Finally, a total of 51 positions contain different bases in all three groups First, a Neanderthal genome sequence would allow all nucleotide sequence differences as well as many copy-number differences between the human and chimpanzee genomes to be temporally resolved with respect to whether they occurred before the separation of humans from Neanderthals, or whether they occurred after or at the time of separation First, it circumvents bacterial cloning, in which the vast majority of initial template molecules are lost during transformation and establishment of clones For comparison, we generated 454 sequence data from a DNA sample from a modern human For example, the crania of late Neanderthals have protruding mid-faces, brain cases that bulge outward at the sides, and features of the base of the skull, jaw and inner ears that set them apart from modern humans  For example, using 454 sequencing, the rate at which cytosine is converted to uracil and read as thymine can be distinguished from the rate at which guanine is converted to xanthine and read as adenine, whereas this is impossible using traditional PCR or bacterial cloning For several reasons, the 454 sequencing platform is extremely well suited for analyses of bulk DNA extracted from ancient remains  For several reasons, we believe that this would represent a valuable genomic resource For the Neanderthal-specific changes the pattern is very different in that mismatches are dominated by C to T and G to A differences Fourth, it generates hundreds of thousands of reads per run, which is crucial because the majority of the DNA recovered from fossils is generally not derived from the fossil species, but rather from organisms that have colonized the organism after its death  From 100–200 mg of bone from six of these specimens we extracted DNA and analysed the relative abundance of Neanderthal-like mtDNA sequences and modern human-like mtDNA sequences by performing PCR with primer pairs that amplify both human and Neanderthal mtDNA with equal efficiency From subsequent cloning into a plasmid vector and sequencing of more than a hundred clones from each product, we determined the ratio of Neanderthal-like to modern human-like mtDNA in each extract Furthermore, the population size of the ancestor of humans and chimpanzees was found to be similar to those of apes, rather than to humans  Genomic divergence between Neanderthals and humans Assuming that the rates of DNA sequence change along the chimpanzee lineage and the human lineage were similar, it can be estimated that 8.2% of the DNA sequence changes that have occurred on the human lineage since the divergence from the chimpanzee lineage occurred after the divergence of the Neanderthal lineage Given that the Neanderthal X chromosome shows a higher level of divergence than the autosomes (R.E.G., unpublished observation), gene flow may have occurred predominantly from modern human males into Neanderthals Given uncertainty in both the sequence divergence time and the population split time, our estimate of the ancestral population size varies from 0 to 12,000 However, although the Neanderthal-specific changes that are heavily influenced by errors are not used for this analysis, some errors in the single-pass sequencing reads from the Neanderthal extract will create positions where the Neanderthal is identical either to human or chimpanzee sequences, and thus affect the estimates of sequence change on the human and chimpanzee lineages However, both morphological evidence and the variation in the modern human gene pool support the conclusion that if any genetic contribution of Neanderthals to modern human occurred, it was of limited magnitude However, some of the samples are better preserved in that they contain high levels of amino acids (more than 20,000 p.p.m.), low levels of racemization of amino acids such as aspartate that racemize rapidly, as well as amino acid compositions that suggest that the majority of the preserved protein stems from collagen However, temporal resolution of the genetic changes along the human lineage, where remarkable morphological, behavioural and cognitive changes occurred, are limited without a more closely related genome sequence for comparison However, the length of the branch leading to the Neanderthal mtDNA is 2.5 times as long as the branch leading to modern human mtDNAs Hublin, personal communication), then our point estimate of the ancestral population size is ∼3,000 Identification of a Neanderthal fossil for DNA sequencing Although it is possible to recover mtDNA and occasionally even nuclear DNA sequences from well-preserved remains of organisms that are less than a few hundred thousand years old, determination of ancient hominid sequences is fraught with special difficulties and pitfalls  If the human–chimpanzee divergence time is set to 6,500,000 years (refs 40 , 41 , 44 ), this implies an average human–Neanderthal DNA sequence divergence time of ∼516,000 years If we use a split time of 400,000 years inferred from the fossil record (J In 1997, a segment of the hypervariable control region of the maternally inherited mitochondrial DNA (mtDNA) of the Neanderthal type specimen found at Feldhofer was sequenced In addition to degradation and chemical damage to the DNA that can cause any ancient DNA to be irretrievable or misread, contamination of specimens, laboratory reagents and instruments with traces of DNA from modern humans must be avoided In agreement with previous results, the Neanderthal mtDNA falls outside the variation among modern humans In combination with future knowledge about the function of genes and biological systems, comprehensive information from the Neanderthal genome will then allow aspects of Neanderthal biology to be deciphered that are unavailable by any other means In contrast, among the remaining 20 positions, where the Neanderthal sequences differed from both humans and chimpanzees, only seven were confirmed In fact, the origin of Homo erectus may have been associated with genetic or cultural adaptations that resulted in drastic population expansions as indicated by their appearance outside Africa around two million years ago In fact, when sensitive polymerase chain reaction (PCR) is used, human mtDNA sequences can be retrieved from almost every ancient specimen  In particular, comparison to the Neanderthal would enable the identification of genetic changes that occurred during the last few hundred thousand years, when fully anatomically and behaviourally modern humans appeared In this case, five bases at both ends of the alignments, amounting to ∼14% of all data, needed to be removed ( Supplementary Fig. 1 ) to eliminate biases in estimates of sequence divergence In this case, ∼7.1% of the divergence along the human lineage is assigned to the time subsequent to the divergence of the two human sequences In this technology, single-stranded libraries, flanked by common adapters, are created from the DNA sample and individual library molecules are amplified through bead-based emulsion PCR, resulting in beads carrying millions of clonal copies of the DNA fragments from the samples In view of that prospect, we have recently initiated a project that aims at achieving an initial draft version of the Neanderthal genome within two years. Interestingly, some of the deviations seen in the Neanderthal are present also in the modern human, whereas others are not It has been dated by carbon-14 accelerator mass spectrometry to 38,310 ± 2,130 years before present and its entire mtDNA hypervariable region I has been sequenced  It is thus feasible to determine large amounts of sequences from this extinct hominid J Malez and co-workers in layer G3 of Vindija Cave in 1980 More extensive sequencing of the Neanderthal genome is necessary to address this possibility Neanderthal genetic differences to humans must therefore be interpreted within the context of human diversity Neanderthal mtDNA sequences Among the 15,701 sequences of primate origin, we first identified all mtDNA in order to investigate whether their evolutionary relationship to the current human mtDNA pool is similar to what is known from previous analyses of Neanderthal mtDNA Neanderthal sequences and human polymorphisms Another question that can be addressed with these data is how often the Neanderthal has the ancestral allele (that is, the same allele seen in the chimpanzee) versus the derived (or novel) allele at sites where humans carry a single nucleotide polymorphism (SNP) Neanderthals are the hominid group most closely related to currently living humans, so a Neanderthal nuclear genome sequence would be an invaluable resource for annotating the human genome Neanderthals were first recognized as a distinct group of hominids from fossil remains discovered 150 years ago at Feldhofer in Neander Valley, outside Düsseldorf, Germany Nevertheless, this high level of derived alleles in the Neanderthal is incompatible with the simple population split model estimated in the previous section, given split times inferred from the fossil record No data other than a Neanderthal genome sequence can provide this information No significant nucleotide sequence similarity in the databases was found for 79% of the fossil extract sequence reads None of the putative Neanderthal mtDNA sequences map to the two hypervariable regions that have been previously sequenced in Neanderthals Notably, the average percentage identity for the primate sequence alignments was 98.8%, whereas it was 92–98% for the other frequently occurring orders Nuclear DNA sequences We next analysed the sequence reads whose closest matches are to the human or chimpanzee nuclear genomes and that are at least 30 base pairs long Obviously, these divergence estimates are dependent on the human–chimpanzee divergence time, which is a much larger source of uncertainty Of the 14 positions found to represent errors in the sequence reads, seven were C to T transitions, four were G to A, two were G to T and one was T to C On the basis of various population models, it has been estimated that a maximal overall genetic contribution of Neanderthals to the contemporary human gene pool is between 25% and 0.1% (refs 10 , 14 ) Once this is done, the confidence that any particular nucleotide position where the Neanderthal differs from human as well as chimpanzee is correct can be reliably estimated One bone (Vi-80) from Vindija Cave, Croatia, stood out in that ∼99% of the 63-base-pair mtDNA segments and ∼94% of the 119-base pair segments are of Neanderthal origin Out of 14 Neanderthal remains from layer G3 that we have analysed, this bone is one of six samples that show good bio-molecular preservation, while the other eight bones show intermediate to bad states of preservation that do not suggest the presence of amplifiable DNA Over this period they evolved morphological traits that made them progressively more distinct from the ancestors of modern humans that were evolving in Africa  Overall, 0.04% of the autosomal genome sequence is covered by the Neanderthal reads—on average 3.61 bases per 10,000 bases Patterns of nucleotide change on lineages We generated three-way alignments between all Neanderthal sequences that map uniquely within the human genome and the corresponding human and chimpanzee genome sequences (see Supplementary Methods ) Phylogenetic analysis showed that it falls outside the variation of contemporary humans and shares a common ancestor with mtDNAs of present-day humans approximately half a million years ago  Preservation conditions in Vindija Cave thus vary drastically from bone to bone, a situation that may be due to different extents of water percolation in different parts of the cave Rationale and prospects for a Neanderthal genome sequence We demonstrate here that DNA sequences can be generated from the Neanderthal nuclear genome by massive parallel sequencing on the 454 sequencing platform Roughly 35 million nucleotide differences exist between the genomes of humans and chimpanzees, our closest living relatives  Second, because each molecule is amplified in isolation from other molecules it also precludes template competition, which frequently occurs when large numbers of different DNA fragments are amplified together Second, the fact that Neanderthals carry the derived allele for a substantial fraction of human SNPs suggests a method of identifying genomic regions that have experienced a selective sweep subsequent to the separation of human and Neanderthal populations Sequences with similarity to a database sequence were classified by the taxonomic order of their most significant alignment Soon, genome sequences from other primates such as the orang-utan and the macaque will allow such differences to be assigned to the human and chimpanzee lineages Subsequent Neanderthal finds in Europe and western Asia showed that fossils with Neanderthal traits appear in the fossil record of Europe and western Asia about 400,000 years ago and vanish about 30,000 years ago Subsequently, mtDNA sequences have been retrieved from eleven additional Neanderthal specimens: Feldhofer 2 in Germany , Mezmaiskaya in Russia , Vindija 75, 77 and 80 in Croatia , Engis 2 in Belgium, La Chapelle-aux-Saints and Rochers de Villeneuve in France , Scladina in Belgium , Monte Lessini in Italy , and El Sidron 441 in Spain  Such selective sweeps in the human genome will make the variation in these regions younger than the separation of humans and Neanderthals The amplification products span segments of the hypervariable region of the mtDNA in which all Neanderthals sequenced to date differ from all contemporary humans The average divergence time between alleles within humans is thus ∼459,000 years with a 95% confidence interval between 419,000 and 498,000 years The consensus sequence seen among these clones revealed the same nucleotides seen by the 454 sequencing at 20 of the 34 positions and no additional differences The data presented in Fig. 4 show that when the hit density for sequences that have a single best hit in the human genome is plotted along the chromosomes, several suggestive local deviations from the average hit density are seen, which may represent copy-number differences in the Neanderthal relative to the human reference genome The latter case identifies SNPs that were present in the common ancestor of Neanderthals and present-day humans The latter class of changes is of interest, because some of them will be associated with the emergence of modern humans The latter group of sequences may indicate copy-number differences that are unique to the Neanderthal relative to the modern human genome sequence The most similar database sequence for each query was identified and classified by its taxonomic order ( Fig. 2 ) (see Supplementary Methods ) The nature of the interaction between Neanderthals and modern humans, who expanded out of Africa around 40,000–50,000 years ago and eventually replaced Neanderthals as well as other archaic hominids across the Old World is still a matter of some debate The Neanderthal sequence data now allow us to ask if the effective size of the population ancestral to humans and Neanderthals was large, as is the case for apes and the human–chimpanzee ancestor, or small, as for present-day humans The next largest category comprises 10,167 positions in which the human and Neanderthal base are identical, but the chimpanzee base is different The second most populous order, to which 15,701 unique sequences or 6.2% of the sequence reads were most similar, was that of primates The size of these regions is a function of the scoring parameters for the alignment The vast majority of these samples had low overall contents of amino acids and/or high levels of amino acid racemization, a stereoisomeric structural change that affects amino acids in fossils, indicating that they are unlikely to contain retrievable endogenous DNA  The Vi-80 bone was discovered by M Therefore, the small effective population size seen in present-day human samples may not be unique to modern humans, but was present also in the common ancestor of Neanderthals and modern humans These are subsequently sequenced by pyrosequencing on the GS20 454 sequencing system These positions are likely to have changed either on the hominid lineage before the divergence between human and Neanderthal sequences or on the chimpanzee lineage These positions are likely to have changed on the human lineage after the divergence from Neanderthal These primer pairs, which are designed to yield amplification products that vary in length between 50 and 98 base pairs (including primers), were used in a multiplex two-step PCR from the same Neanderthal extract that had been used for large-scale 454 sequencing These results also show that the likelihood of observing errors in the sequencing reads is drastically different depending on whether one considers nucleotide positions where a base in the Neanderthal mtDNA sequence differs from both the human and chimpanzee sequences, or positions where the Neanderthal differ from the humans but is identical to the chimpanzee mtDNA sequences These results suggest that the population ancestral to present-day humans and Neanderthals was similar to present-day humans in having a small effective size and thus that the effective population size on the hominid lineage had already decreased before the split between humans and Neanderthals These were aligned to the human (build 36.1) , chimpanzee (build 1) and mouse (build 34.1) complete genome sequences, to environmental sample sequences in the GenBank env database (version 3, September 2005), and to the complete set of redundant nucleotide sequences in GenBank nt (version 3, September 2005, excluding EST, STS, GSS, environmental and HTGS sequences) using the program BLASTN (NCBI version 2.2.12)  Third, its current read length of 100–200 nucleotides covers the average length of the DNA preserved in most fossils  Third, once large amounts of Neanderthal genome sequence is generated, it will become possible to estimate the misincorporation probabilities for each class of nucleotide differences between the Neanderthal and chimpanzee genomes with high accuracy by analysing regions covered by many reads such as mtDNA, repeated genome regions of high sequence identity, as well as single-copy regions covered by multiple reads This fact, in conjunction with the absence of any related mtDNA sequences in currently living humans or in a small number of early modern human fossils strongly suggests that Neanderthals contributed no mtDNA to present-day humans This is important since nucleotide conversions and misincorporations in ancient DNA are caused by damage that affects different bases differently and this pattern of false substitutions can be used to estimate the relative probability that a particular substitution (that is, the observation of a nucleotide difference between DNA sequences) represents the authentic DNA sequence of the organism versus an artefact from DNA degradation This is in general agreement with previous estimates of Neanderthal–human mtDNA divergence of 317,000–741,000 years based on mtDNA hypervariable region sequences and is compatible with our presumption that the mtDNA sequences determined from the Vi-80 extract are of Neanderthal origin This is likely to be due to errors in our Neanderthal sequences derived from substitution artefacts from damaged, ancient DNA and from sequencing errors  This is typical of large-scale sequencing both from other ancient bones and from environmental samples , although some permafrost-preserved specimens can yield high amounts of endogenous DNA  This may suggest gene flow between modern humans and Neanderthals This number is presumably an overestimate since the SNPs analysed were ascertained to be of high frequency in present-day humans and hence are more likely to be old This pattern of change is typical for ancient DNA, where deamination of cytosine residues and, to a lesser extent, modifications of guanosine residues have been found to account for the majority of nucleotide misincorporations during PCR This problem is especially severe when Neanderthal remains are studied because Neanderthal and human are so closely related that one expects to find few or no differences between Neanderthals and modern humans within many regions , making it impossible to rely on the sequence information itself to distinguish endogenous from contaminating DNA sequences This provides an advantage over traditional PCR from double-stranded templates, in which the template strand is not known, because the frequency of different nucleotide misincorporations can be deduced This represents an approach to identifying selective sweeps in humans that is not possible from other data This suggests that no large source of errors other than what is detected by the PCR analysis affects the sequences Thus, the pattern of change seen among the Neanderthal-specific alignment mismatches is typical of the nucleotide substitution pattern observed in PCR of ancient DNA Thus, the primate reads, unlike many of the prokaryotic reads, are aligned to a very closely related species Thus, when more Neanderthal sequence is generated in the future, it may be possible to determine copy number differences between the Neanderthal, the chimpanzee and the human genomes To achieve one-fold coverage of the Neanderthal genome (3 gigabases) without any further improvement in technology, about twenty grams of bone and 6,000 runs on the current version of the 454 sequencing platform would be necessary To analyse the extent to which errors occur in the Neanderthal mtDNA reads, we designed 29 primer pairs ( Supplementary Methods ) flanking all 39 positions at which the Vi-80 Neanderthal mtDNA sequences differed by substitutions from the consensus bases seen among the 311 human mtDNA sequences Twenty five of the PCR products, containing 34 of the positions where the Neanderthal differs from humans, were successfully amplified and cloned, and then six or more clones of each product were sequenced Using the SNPs that overlap with our data from two large genome-wide data sets (HapMap , 786 SNPs and Perlegen , 318 SNPs), we find that the Neanderthal sample has the derived allele in ∼30% of all SNPs Using these PCR-confirmed substitutions and a divergence time between humans and chimpanzees of 4.7–8.4 million years , we estimate the divergence time for the mtDNA fragments determined here to be 461,000–825,000 years Using this line we can estimate the ancestral population size, given estimates about the population split time from independent sources We aligned these mtDNA sequences to the complete mtDNA sequences of 311 modern humans from different populations as well as to the complete mtDNA sequences of three chimpanzees and two bonobos ( Supplementary Information ) We analysed the DNA sequences generated from a contemporary human using the same sequencing protocol as was used for the Neanderthal We applied a method that co-estimates the ancestral effective population size and the split time between Neanderthal and human populations ( Fig. 6a ; see Supplementary Methods ) We recovered a total of 254,933 unique sequences from the Vi-80 bone (see Supplementary Methods ) We speculate that a small effective size, perhaps associated with numerous expansions from small groups, was typical not only of modern humans but of many groups of the genus Homo  We tested more than 70 Neanderthal bone and tooth samples from different sites in Europe and western Asia for bio-molecular preservation by removing samples of a few milligrams for amino acid analysis We used two different primer pairs that amplify fragments of 63 base pairs and 119 base pair to gauge the contamination levels for different lengths of DNA molecules When only PCR-confirmed sequence data are used to estimate the mtDNA tree ( Fig. 3 ), the Neanderthal branch has a length comparable to that of contemporary humans When the effects of such errors in the Neanderthal sequences are quantified and removed (see Supplementary Methods ), ∼7.9% of the sequence changes along the human lineage are estimated to have occurred after divergence from the Neanderthal Whereas only around 1% of the mtDNA present in three samples from France, Russia and Uzbekistan was Neanderthal-like, one sample from Croatia and one from Spain contained around 5% and 75% Neanderthal-like mtDNA, respectively
 For tasks in which precision is at a premium, performance would be optimal if no noise were added in movement planning and execution: motor output would be as accurate as possible given the quality of sensory inputs Here we use visually guided smooth-pursuit eye movements in primates as a testing ground for this notion of optimality In response to repeated presentations of identical target motions, nearly 92% of the variance in eye trajectory can be accounted for as a consequence of errors in sensory estimates of the speed, direction and timing of target motion, plus a small background noise that is observed both during eye movements and during fixations Suppose that the variability in our movements is caused not by noise in the motor system itself, nor by fluctuations in our intentions or plans, but rather by errors in our sensory estimates of the external parameters that define the appropriate action The magnitudes of the inferred sensory errors agree with the observed thresholds for sensory discrimination by perceptual systems, suggesting that the very different neural processes of perception and action are limited by the same sources of noise. All procedures had been approved by the Institutional Animal Care and Use Committee of the University of California, San Francisco and were in compliance with the National Institutes of Health Guide for the Care and Use of Laboratory Animals As expected if the changing target direction simply rotates the ideal response trajectory, there were just two principal components, corresponding roughly to horizontal and vertical pieces of the ideal trajectory Before analysis, each trial record was inspected and rejected if a saccade occurred within the time-window chosen for analysis Data sets consisted of eye velocity responses to 112–223 repetitions of target motion in each direction Directions were chosen randomly from up to 14 directions (that is, -9° to +9° relative to horizontal, in 3° increments) Each trial began with the monkey fixating a stationary target at centre-screen for a random interval of 700–1,200 ms Experiments lasted 2–3 h, during which the monkey sat in a specialized primate chair with its head immobilized, and received a juice or water reward for accurately tracking visual targets presented on a screen in front of it Experiments were presented as a series of trials, each representing a single target motion Eye-position and velocity signals were sampled and stored at 1 kHz Finally, changes in target motion direction should produce rotations of the ideal trajectory First, changing the onset time t 0 should be equivalent to translating the response along the time axis of the ideal trajectory, so that v time = ∂ v ideal /∂ t 0 = -∂ v ideal /∂ t  First, we used a ‘white’ noise model in which errors were independent in 1-ms bins, and eye-velocity variance grew as a function of the mean eye velocity : Δ C had 80 to 90 significant eigenvalues Furthermore, the reconstruction of the mean trajectories for different directions combined these components with coefficients that corresponded to the sines and cosines of the relevant directions Methods Eye movements were recorded from three male rhesus monkeys ( Macaca mulata ) that had been trained to fixate and track visual targets Parameters of target motion were varied so that they were presented in random order Second, changes in target speed should produce ideal trajectories that are uniformly scaled to be proportionately faster or slower, at least over a narrow dynamic range , so that v speed = ∂/∂ v [( v / v 0 ) v ideal ] Second, we preserved the form of temporal correlations in eye velocity during fixation ( Fig. 2a ), again with variances that scaled with the mean response: the three dominant eigenvalues captured only 67.5% of the variance and the axes defined by speed, direction and time accounted for less than half of the total variance Standard deviations were computed from analyses based on 40–50 random draws of half of the data set Statistical analysis of these models confirmed that the observed low-dimensional structure of trial-by-trial variations in the pursuit trajectory had a very low probability of occurring by chance ( 10 -5 ). The 125-ms time-window for pursuit analyses began at eye-movement onset, determined by the intersection of two lines each fitted to pre- and post-pursuit intervals of average responses The target then underwent a step-ramp motion with steps of 2.5–3.7° and ramped back towards the extinguished fixation point at a constant speed, typically 20° s -1  The time-window for analyses of ‘background’ data began 125 ms before target motion and ended with the onset of target motion The visual target was typically a 0.8° square spot presented in a dimly lit room on a high-resolution analogue display oscilloscope that subtended a 48° by 38° visual angle Therefore, we were able to identify v dir = ∂ v ideal /∂ θ with (∂ Rcirc; ( θ )/∂ θ ) θ = 0 · v ideal , where Rcirc; ( θ ) is the matrix representing rotation through an angle θ  To analyse deviations from ideal behaviour on individual trials, we subtracted the mean response for a given target direction from each individual pursuit trial to form a noise vector To compute the derivatives in equation (1) , we took advantage of symmetries To recover the ideal trajectory v ideal ( t ; t 0 , v , θ ) ( equation (1) ), we averaged eye velocity over many responses to the same target motion Vertical and horizontal eye-velocity signals were passed though an analogue double-pole, low-pass filter that differentiated frequencies below 25 Hz and rejected higher frequencies with a roll-off of 20 dB per decade We checked this last symmetry using principal component analysis of mean trajectories in response to (typically) 14 different directions We computed the temporal covariance of pursuit noise across all trials (a 250 × 250 matrix), and then subtracted the covariance of the background to form Δ C  We tested alternative noise models to confirm that the low-dimensional structure we observed in Δ C did not arise from our choice of ‘background’ noise A standard deviation of just 15 ms produces a variation in eye movement trajectories that is larger than we see in experiments ( Fig. 1b ), suggesting that the timing of target motion must be represented with a precision of better than 15 ms After the initiation of pursuit (green square), there should be exactly three additional components that reflect the variances in δ t 0 , δ θ and δ v  Also, closer inspection of Fig. 1b reveals that the trial-to-trial fluctuations in trajectory include a more rapidly fluctuating component that is ‘background noise’, visible even before the initiation of pursuit: δ v back ( t ) Although correlations between variations in direction and speed would imply a ‘handedness’ to the pursuit system that seems implausible, there is no symmetry that forbids correlations between variations in timing and speed An appealing and simple conclusion is that the initial response of the pursuit system adds little additional noise beyond the variations in sensory estimates, and thus its precision is defined by the noise in the sensory representations As explained in the Methods, this collapse of dimensionality is enormously unlikely to have occurred by chance As hinted at by the results in Fig. 1c , the standard deviation of these timing errors is quite small, 7–10 ms across our set of nine experiments ( Table 2 ) As summarized in Table 1 , 93 ± 1.4% of the variance in trajectories is captured by these three eigenvectors, which in turn have 96–99% overlap with axes corresponding to errors in estimating target speed, direction and timing At least for perception, these estimates are not perfect: humans and non-human primates can make reliable visual discriminations only among trajectories that differ by ∼10% in speed and ∼2–3° in direction  At times before the initiation of pursuit (yellow square), the covariance matrix should describe the background noise δ v back ( t ) Because steady-state tracking is driven largely by extra-retinal signals, the absence (or presence) of covariation between perceptual and pursuit errors during steady-state tracking does not speak to the question of whether the errors in perceptual and motor readouts of visual motion arise from the same noise source But this model does not provide an explanation of the low-dimensionality of the noise, except by assuming a similar low dimensionality in the gain noise—that is, that the fluctuating components of the commands affect the entire 125-ms trajectory uniformly Comparison of the synthetic and actual trajectories reveals that noise on the scale that limits perceptual discrimination is sufficient to generate variation in motor output that is close to what we see experimentally Demonstrations of the limits to perceptual discrimination of target direction and speed have revealed that there is noise in the sensory inputs Each daily experiment involved a total of more than 1,000 trials, so statistical errors within a single experiment are much smaller than variations among experiments Even though a number of motor behaviours have been shown to have similar low-dimensional structures , several aspects of our results seem novel Experimentally (see Methods), we sampled the horizontal and vertical components of the vector velocity v ( t ) with 1-ms resolution throughout a 125-ms window after the initiation of pursuit, so that a single trajectory is described by 250 numbers Figure 1a shows an ensemble of eye-velocity trajectories generated by random scalings and rotations of the mean trajectory of eye velocity for target motion that steps from 0 to 20° s -1 in a rightward direction rotated 9° above the horizontal; the standard deviations of these scalings and rotations were chosen to match the sensory noise levels of 10% and 2.3° Finally, any model that ascribes the observed behavioural variability largely to the motor side of the nervous system must explain why the inferred gain variations are so large when the variability of motor neuron discharge is so small  Finally, the magnitudes of the fluctuations in the three relevant directions have a clear physical and biological meaning in relation to the parameters used to specify visual motion First, the low dimensionality cannot be interpreted as a limitation of the motor system itself, as the eye movement motor system is observed to generate trajectories that fill ∼80 dimensions under the different conditions of fixation before the onset of pursuit For 200-ms stimulus presentations, human discrimination thresholds and the limits to precision inferred from the variability of pursuit trajectories improve, and are even more similar For brief stimulus presentations like the ones used here (∼125 ms), human subjects have thresholds of Δ θ ≈ 2.3° in direction and Δ v / v ≈ 10% in speed For comparison, in Fig. 1b we show an ensemble of actual pursuit trajectories in response to repeated presentations of the same direction of target motion; these trials are interspersed with target motions in other directions to eliminate the possibility of prediction and to force pursuit to be guided by estimates of visual motion For example, studies of perceptual and closed-loop motor variability in smooth pursuit reach opposite conclusions: both find that perception and pursuit have similar degrees of variability, but one addressing motion direction finds evidence for a common noise source , whereas another experiment addressing motion speed errors does not  Further testing is needed to rule out alternatives in which a precise representation of target motion is degraded by noise that accumulates independently along perceptual and motor pathways Furthermore, although tracking over long timescales involves feedback and is driven by a combination of retinal and extra-retinal signals, the eye trajectory in the ∼125-ms time interval before feedback can arrive is generated purely from estimates of the targets motion, using visual inputs present before the onset of the response  Furthermore, the residual differences between actual and predicted responses have a distribution that agrees substantially with the distribution of background noise (grey versus black distributions in Fig. 3d ) Given the small number of spikes that are emitted by neurons in the MT region of the visual cortex in response to the first 100 ms of target motion , the neural mechanisms that decide when to initiate a movement must be able to do so on the basis of the timing of just a few spikes However, on timescales longer than the ∼125 ms we have considered, the sensory–motor feedback loop for pursuit has been closed, complicating the comparison However, the brain has no independent knowledge of these parameters, and must estimate them visually if experiments are designed to remove opportunities for prediction If the brains estimate of speed on one trial is larger than the mean (as the result of noise), then the goal of the movement on this trial will be indistinguishable from that for a genuinely faster target speed, and the corresponding commands to the eyes will drive proportionately larger eye accelerations and velocities In a total of nine experiments with three monkeys (pk, yo and wt) direction and speed errors had standard deviations of 2.1–3.5° and 11–18%, respectively In contrast to direction and speed, little is known about the limits of perceptual discrimination of motion timing In contrast, the matrix Δ C formed by subtracting the background covariance matrix ( Fig. 2d , yellow box) from that for the first 125 ms of pursuit ( Fig. 2d , green box) has just three eigenvalues that are significantly different from zero ( Fig. 2c ) In decomposing errors into direction, speed and timing components, it is important to account (as we do) for the fact that although direction and speed errors make orthogonal contributions to the pursuit trajectory, speed and timing errors do not In Fig. 1c we illustrate the consequences of errors in timing estimation In Fig. 3 , we show how the three dimensions corresponding to speed, direction and timing errors can be used to synthesize the eye-movement trajectory on a single trial In our experiments, target motion begins at a random time relative to the onset of a fixation spot In the simplest concrete alternative, motor output variation is dominated by trial-by-trial fluctuation in the strength of commands sent to the eye muscles In the time domain, the noise has significant components with a correlation time of less than 10 ms ( Fig. 2a ) and the distribution of noise velocities is nearly gaussian ( Fig. 2b ) Indeed, we observe significant speed–timing correlations in many experiments ( Table 2 ) Instead, they point oppositely along similar axes in the three-dimensional space It is convenient to describe pursuit eye movements as depending on the speed and direction of target motion Longer stimulus presentations have been used for perceptual experiments in monkeys, yielding thresholds nearly identical to those in humans  More detailed computations show that the magnitude of the gain fluctuations must be tuned differently for each direction of motion to account quantitatively for the data More formally: imagine that there is an ideal (vector) eye-velocity trajectory v ideal ( t ; t 0 , v , θ ) in response to a target that starts to move at time t 0 at speed v and in direction θ  On a given single trial, however, the brain lacks a perfect marker of the time of target motion onset, and so it must be estimated On any single trial, the brain has access only to noisy estimates of these parameters so that it makes errors δ t 0 , δ v and δ θ On average, the trajectory of smooth pursuit seems to be locked to the trajectory of the target Other studies have shown that eye movements and perception share neural pathways and have access to the same sensory estimates of visual motion  Our findings do not indicate whether the precision of sensory representations of visual motion is limited by noise arising in the retina, or whether it accumulates along motion-sensitive neural pathways Perceptual discrimination thresholds are limited by noise in neural activity in sensory areas: estimates of speed and direction will fluctuate from trial to trial as the brain tries to decode this noisy representation  Putting the terms together, we formalize the predicted trajectory in a natural, sensory space for a single trial as: v ( t ) = v ideal ( t ; t 0 , v , θ ) + δ t 0 · ∂ v ideal ( t ; t 0 , v , θ ) ∂ t 0 + δ θ · ∂ v ideal ( t ; t 0 , v , θ ) ∂ θ + δ v · ∂ v ideal ( t ; t 0 , v , θ ) ∂ v + δ v back ( t ) (1) In equation (1) , v ideal can be recovered by averaging the actual trajectories over many trials, and the various derivatives can be extracted from the data without any further assumptions (see Methods for details) Second, the particular three dimensions in which the system operates are not arbitrary, but in fact are those predicted in advance Similar considerations apply to errors in direction Smooth-pursuit eye movement is the familiar ‘tracking’ behaviour elicited by the motion of small targets across the visual field ( Fig. 1 ) Starting with the mean trajectory ( Fig. 3a , dashed traces), we add components for each of the three natural modes ( Fig. 3b ), scaled by particular values of δ v , δ θ and δ t 0 (arrowheads in Fig. 3c ) to create accurate predictions ( Fig. 3a , red and blue traces) of eye-velocity responses from individual trials ( Fig. 3a , solid black and grey traces) That variation in pursuit behaviour can be assigned largely to noise in representation of the sensory stimulus may fit with other examples in which the nervous system achieves optimal or near-optimal performance . The agreement between the distributions of the background noise and the residuals of trial-by-trial reconstructions from the three natural modes is a restatement of our results on the eigenvalues and eigenvectors of Δ C , but presents the results in a different, and perhaps more intuitive, form The agreement between the limits to precision in pursuit and perceptual behaviour biases us to think that sensory processing is the main contributor to variability in pursuit trajectory, and that other sources of noise in the system are effectively smaller, perhaps because motor strategies are selected to minimize other noise sources  The analysis of timing errors deserves special consideration The covariance matrix of the background noise has the symmetric structure expected for stationary fluctuations, with ∼80 eigenvalues that are significantly different from zero The eigenvectors corresponding to these eigenvalues span the same three-dimensional space defined by the three derivatives of v ideal ( t ) in equation (1)  The observation of just three significantly non-zero eigenvalues for Δ C means that the variability of smooth-pursuit trajectories is effectively limited to three dimensions The overlap of the significant dimensions of pursuit variation with those expected from the parameters of the motion trajectory may have important implications for the operating principles of the brains motor circuits The precision of pursuit behaviour correlates well with the results from perceptual experiments  The predictions of equation (1) can be tested by examining the covariance matrix of trial-to-trial fluctuations in eye velocity, shown in Fig. 2d  The results of Fig 1a–c motivate the hypothesis that variability in smooth-pursuit trajectories is dominated by errors in sensory estimation The sign of the correlations corresponds to ‘start later–go faster’, but because we are analysing the open-loop response of pursuit, there is no feedback signal to ensure that late starts are compensated for by larger eye accelerations Then, the actual eye movements will be v ideal ( t ; t 0 + δ t , v + δ v , θ + δ θ ) These alternatives require that noise added in the motor system preserve the sensory form and have a magnitude similar to that measured for perception This explains why speed and time have similar magnitude projections onto modes 1 and 2 of Δ C , but with a sign difference that disambiguates ‘moving faster’ from ‘starting earlier’ This is much smaller than the range of reaction times for discrete movements such as saccades  Thus, even though the time of onset of target motion is not known to the brain a priori , the pursuit system is able to estimate that time with remarkable precision Thus, it seems likely that the correlation between variations in speed and timing is intrinsic to the estimation or representation of motion in the visual system To generate appropriate motor outputs, the brain must represent when the target starts moving, in addition to estimating the speed and direction of target motion We assume that errors are small, so that we can approximate the consequences of changing parameters just by the first term in a Taylor series We can think of the timing error δ t 0 as a measure of latency relative to the mean that looks for the best fit of a template to the whole 125-ms open-loop segment of the eye-velocity trajectory rather than (for example) the traditional measure of latency as the moment at which the eye velocity rises significantly above background noise We derived distributions of the values of δ v , δ θ and δ t 0 by performing the same projection for each individual pursuit response in the data set onto the natural modes ( Fig. 3c ); the distributions are approximated well by gaussians We have predicted the structure of variations in the initiation of pursuit from first principles, and have provided data that are consistent with, but do not prove, the hypothesis that variation in initiation of pursuit arises largely from the sensory representation of visual motion We have shown that essentially the entire motor variation that is specific to pursuit lies along the axes of the sensory parameters of target direction, speed and timing, and that the limits to precision of pursuit are nearly the same as those for perception Whatever its origin, we imagine that the variability we observe in pursuit initiation is reflected in the responses of cortical neurons (for example, in MT/V5) Within the bounds of measurement error and differences in stimulus presentation, we conclude that the limits in precision for pursuit and perception are very similar
 A fresh round of research missions is set to probe the seafloor rupture that triggered the devastating tsunami of 2004 As with previous studies of the region, vessels will not have permission from the Indian government to enter the countrys territorial waters But after decades of being refused entry to Indian waters, they are resigned to relying on the limited data produced by Indian research vessels and the occasional chance to join those voyages But in the south, the Indian plate is moving underneath its neighbour. newsad; Chris Goldfinger, a marine geologist at Oregon State University in Corvallis who is organizing a trip for later this year, says lack of access is hampering attempts to understand how frequently major earthquakes have occurred in the area. “This is readily determined by geologic sampling,” says Goldfinger But when researchers arrive in the Indian Ocean, they will find some areas are off-limits David Tappin of the British Geological Survey in Nottingham, who is sailing with the German team, says access to the southern part of the 2004 rupture zone is crucial for studying the behaviour of the two plates that caused the earthquake Goldfinger says he is working with the National Institute of Oceanography in Goa and hopes to participate in future Indian missions. In the absence of progress at the diplomatic level, researchers are focusing on collaborations with Indian colleagues In the north, the plates slip horizontally past each other Indian science secretary Valangiman Ramamurthi told Nature that the ministry of defence does not allow any foreign vessels in its territory for “reasons of national security and sovereignty” It is a policy that hampers research, say scientists involved, and ultimately sets back attempts to prepare for earthquakes Organized by the Federal Institute for Geosciences and Natural Resources in Hannover, the six-week mission will run studies such as seismic surveys and sediment sampling Other nations, including Britain and the United States, also plan to send ships, but none will be able to survey the northernmost 900 km of the 1,300-km rupture zone Such sampling is currently only scheduled for Indonesia, he says, leaving important work to a scattering of good but limited efforts under way in India That stance is unusual The data gathered will boost efforts to model the earthquake and help gauge the likelihood of further major tsunamis in the area The first of this years missions set sail from Bremen in Germany on 20 January They interact differently in different places, he explains This part lies in Indian waters, and researchers say they have not even attempted to ask for permission to enter With other countries scientists say they are almost always able to reach an agreement to send research missions
 But the origin of the observed relation between black hole mass and stellar velocity dispersion, and its connection with the evolution of galaxies, have remained unclear Here we report simulations that simultaneously follow star formation and the growth of black holes during galaxy–galaxy collisions In the early Universe, while galaxies were still forming, black holes as massive as a billion solar masses powered quasars Supermassive black holes are found at the centres of most galaxies today , where their masses are related to the velocity dispersions of stars in their host galaxies and hence to the mass of the central bulge of the galaxy  The energy released by the quasar expels enough gas to quench both star formation and further black hole growth This determines the lifetime of the quasar phase (approaching 100 million years) and explains the relationship between the black hole mass and the stellar velocity dispersion. This suggests a link between the growth of the black holes and their host galaxies , which has indeed been assumed for a number of years We find that, in addition to generating a burst of star formation , a merger leads to strong inflows that feed gas to the supermassive black hole and thereby power the quasar A large fraction of the black hole mass in galaxies today is thought to have been assembled during the peak of quasar activity in the early Universe , when large amounts of matter were available for accretion onto central black holes Also, hierarchical models of galaxy formation imply that mergers of galaxies form elliptical or spheroidal components in galaxies, by destroying stellar disks and triggering nuclear starbursts Also, the morphologies of the remnants in the two simulations begin to differ significantly Although only weak starbursts and accretion events are triggered at this time, it is already evident that black hole feedback alters the thermodynamic state of the gas, as indicated by the relatively lower density and higher temperature of the gas surrounding the galaxies in the simulation with black holes As described in the Supplementary Information , we include a novel treatment of gas accretion onto supermassive black holes and its associated feedback in the centres of merging galaxies As galaxies merge to form spheroids, the dynamical response of the gas to the energy supplied by accretion halts further growth once the black holes have reached a critical size for the gravitational potential of the bulge At this saturation point, the active galactic nuclei (AGN) generate outflows that drive away gas and inhibit further star formation At this time, the black holes in the centres of each galaxy (top panel) have already grown significantly from their initial masses and are accreting at a moderate level Black hole growth is self-regulated in our models Consequently, the black hole mass saturates, quasar activity stops, and star formation is inhibited, so that the remnant resembles a ‘dead’ elliptical galaxy whose stellar population quickly reddens  Differences persist as the remnants settle into a relaxed state (fourth pair of images in Fig. 1 , t = 2.5 Gyr) During this strong accretion phase and for this interval of time, the object would be a bright quasar with a specific lifetime Figure 3 shows the black hole mass versus the stellar velocity dispersion of the merger remnants from our simulations, compared with observations For the same reasons, the initial growth of the black holes, which is regulated by the properties of nearby gas, depends on the total mass Here, the tidal interaction has distorted the disks into a pair of bisymmetric spirals, and gas is shocked between the two galaxies Here, the total gas supply for accretion is larger, and the gravitational potential well is deeper, and so the black hole has to grow much more before its released energy is sufficient to expel the gas in a quasar driven wind, which then terminates further nuclear accretion and star formation However, in the simulation with supermassive black holes (top image), nearly all the gas is expelled from the centre, quenching star formation and black hole accretion itself However, the coupling of star formation with black hole growth in the context of galaxy evolution is difficult to treat on the basis of analytical estimates alone However, the damping of star formation and black hole activity is more abrupt in the more massive systems However, the overall star formation rate is essentially unaffected by the presence of the black holes, as indicated by Fig. 2 , which plots the star formation rate (in both cases), the black hole accretion rate and black hole mass (for the top panels of Fig. 1 ) as a function of time However, this suggests that part of the intrinsic scatter in the observed relation can be ascribed to different gas fractions of the galaxies during black hole growth In contrast, the simulations with black holes exhibit a significant change in the thermodynamic state of the circumnuclear gas, which is heated by the feedback energy provided by the accretion and partly expelled in a powerful wind In fact, a significant wind has started to flow out of the centres In the hierarchical model of galaxy formation, a new disk can grow around this spheroid, turning it into the bulge component of a spiral galaxy In the model without black holes, most of the gas is still inflowing in a comparatively cool phase In the particular example we show, the remnant of this major merger is an elliptical galaxy In this picture, black hole accretion is expected to have a crucial effect on the evolution of the host galaxy In very gas-rich mergers, a disk component may even survive directly (an example of this is shown in the Supplementary Figure ) Indeed, observations point to the existence of strong outflows in bright quasars  Interactions and mergers between galaxies are known to trigger large-scale nuclear gas inflows , which are required for the growth of central black holes by accretion It is faster in more massive systems, which can therefore reach the exponential, Eddington-limited growth phase more easily Models with different mass qualitatively reproduce the key features of the evolution shown in Fig. 1 : the star formation and black hole accretion rates are both quenched in the remnant, and black hole growth saturates owing to feedback provided by accretion energy Moreover, self-regulation in our hydrodynamical simulations predicts a specific duration of the luminous episode of a black hole in a given galaxy, thereby explaining the origin of quasar lifetimes Note that black holes in more gas-rich mergers reach somewhat larger masses than those growing in gas-poorer environments (which is expected from our prescription for the accretion rate), but this is partly compensated by an increase in the velocity dispersion of the corresponding bulges, maintaining a comparatively tight M BH – σ  relation Our approach can also be implemented in cosmological simulations of hierarchical structure formation in representative pieces of the Universe Our lowest mass galaxy models probe a region of the M BH – σ  relation where few measurements are available, and predict that this correlation should hold towards small black hole masses and small velocity dispersions, in tentative agreement with recent observations  Our results should also apply for cases involving minor mergers Our simulations are, to our knowledge, the first self-consistent models to demonstrate that self-regulation can quantitatively account for the principle observational facts known for the local population of supermassive black holes, most notably the M BH – σ  relation Owing to the enhanced gas density, the black holes, which also merge to form one object, experience a rapid phase of accretion close to the Eddington rate, resulting in significant mass growth Remarkably, our simulations reproduce the observed M BH – σ  correlation very well Star formation and supernova feedback are included in both simulations, but we add our black hole growth and feedback model in one (top four panels of Fig. 1 ; see also Supplementary Video ) and neglect it in the other (bottom four panels) Such simulations will allow us to study directly why quasars were much more numerous in the early Universe than they are today, and how black holes and galaxies have influenced each other throughout cosmic history. The accretion rate is estimated by relating the small-scale, unresolved flow around the black hole to the large-scale, resolved gas properties using a spherical Bondi–Hoyle model The black hole accretion activity also has a profound effect on the host galaxy The dependence of black hole growth on galaxy mass yields a relation between the stellar spheroid of the remnant galaxy and its central black hole The evolution of star formation rate, black hole accretion rate and black hole mass for mergers when the progenitor galaxy mass is varied (including the model shown in Fig. 1 ) are shown in Fig. 2  The first pair of images (at time t = 1.1 Gyr) shows the galaxies soon after their first encounter, when strong gravitational forces have spawned extended tidal tails The lifetime of the active black hole phase, however, increases for smaller black hole masses, implying that low-luminosity quasars should be more numerous than bright ones The remnant spheroid is gas-poor and has low residual star formation, so it evolves to a red stellar colour on a short timescale The remnant without black holes (bottom image) retains a large amount of dense cold gas, yielding prolonged star formation at a steady rate The second snapshot ( t = 1.4 Gyr) in Fig. 1 shows the galaxies when they begin to coalesce The simulations shown here make it possible to draw firm conclusions about this and other links between black hole growth, quasar activity and properties of the galaxy population The tidal response drives gas into the central regions of each galaxy This has led to suggestions that the M BH – σ  relation (where M BH is the black hole mass, and σ  is the velocity dispersion of stars in the bulge of galaxies) could arise in galaxy mergers, provided that strong outflows are produced in response to major phases of accretion, capable of halting further black hole growth  This is consistent with them residing in a greater number of smaller galaxies and with what has been found in recent surveys  This ‘feedback energy’ gives an effective feedback energy heating rate Ė  feed = fL = fηMdot; c 2 , where we fix the radiative efficiency, η , to 0.1, the typical value derived from Shakura–Sunyaev accretion models onto a non-rotating black hole. (Here c is the velocity of light, L = ηMdot; c 2 is the accretion luminosity, and Mdot; is the mass accretion rate) To illustrate the effect of central, supermassive black holes on mergers of two disk galaxies, we compare the gas evolution between two simulations involving galaxies that are roughly the size of the Milky Way ( Fig. 1 ) We describe black holes using collisionless ‘sink’ particles that can grow in mass by accreting gas from their surroundings We further assume that a small fraction, f , of the radiated luminosity couples thermodynamically to the surrounding gas We further assume that f = 0.05, so that ∼0.5% of the accreted rest mass energy is available to heat the gas We have, therefore, performed detailed numerical simulations of galaxy mergers that include radiative cooling, star formation, black hole growth, energetic feedback from supernovae and accretion onto black holes, as well as the gravitational dynamics of gas, stars and dark matter (see Supplementary Information and further details in ref. 21 ) We note that our choice of f = 0.05 is consistent with the value required in semi-analytic models to explain the evolution of the number density of quasars We note that the final black hole masses we obtain are roughly proportional to the inverse of the value assumed for the feedback efficiency, f  We show simulations with six different galaxy masses, each of which has been run with three different initial gas mass fractions of the galaxies disks We therefore expect black holes in bulges of spiral galaxies to be assembled in a manner similar to those in ellipticals When the galaxies finally merge, as shown in the third pair of images in Fig. 1 ( t = 1.6 Gyr), much of the gas is quickly converted into stars in intense bursts of star formation 
 Defining the molecular mechanisms by which HCV regulates the host response is of crucial importance and may reveal targets for novel therapeutic strategies. Hepatitis C virus (HCV) evades the host response through a complex combination of processes that include signalling interference, effector modulation and continual viral genetic variation These evasion strategies support persistent infection and the spread of HCV This ‘host response’ is our first line of immune defence against infection as it imposes several barriers to viral replication and spread Viral infection of mammalian cells rapidly triggers intracellular signalling events leading to interferon α/β production and a cellular antiviral state A current model Studies defining the viral induction, evasion and control of the host response to HCV collectively provide a model of virus–host interactions and viral adaptation that form a foundation for chronic infection ( Fig. 4 ) A explanation for this comes from the observation that NS5A can induce IL-8 expression and secretion About 15–25% of exposures to HCV typically render an acute resolved infection  Among these is interleukin (IL)-1, which mediates antiviral actions against HCV  Assessment of IFN-α/β receptor signalling processes has revealed mechanisms by which HCV proteins can antagonize IFN signalling Because dendritic cells represent a major source of IFN production during viral infection, modulation of their function may influence systemic and/or local IFN signalling and ISG expression  By this model, hepatic ISG levels would vary with the composition and extent of immune cell infiltration, which has been observed  Cell interactions with virus particles may also trigger signalling events that induce IFN production Control and evasion of the host response The success of HCV in persisting is linked to its overall ability to disrupt the host response and evade antiviral defences Exogenous induction of antiviral hepatic defences Multiple studies provide molecular evidence for a clear absence or only a low level of IFN-α/β gene expression in hepatocytes of patients with chronic HCV  Exogenous/extrahepatic immune effector cells that infiltrate the liver, including IFN-producing macrophages and dendritic cells , may also contribute to hepatic ISG expression Expression of the HCV core protein has been associated with increased expression levels of suppressor of cytokine signalling (SOCS)-3 in cultured cells  Expression of the HCV NS5A protein induces cellular stress and signalling pathways that activate STAT3 (ref. 34 ) First, this control attenuates two major pathways of IFN production in hepatocytes  For RNA viruses, protein and nucleic acid products of infection or replication, including single-stranded (ss) or double-stranded (ds) RNA and polyuridine signatures, have been identified as viral PAMPs and are each engaged by specific Toll-like receptors (TLRs) or nucleic-acid-binding proteins that serve as PAMP receptors ( Fig. 1 )  Fourth, in addition to its role in host defence, IRF-3 has been ascribed proapoptotic and tumour suppressor functions  Functional genomic analyses from cohorts of human subjects with chronic infection have shown that infection is associated with a hepatic gene expression profile marked by ISGs, whose levels vary widely among patients and possibly with different degrees of liver fibrosis and cirrhosis  Functional genomics analyses have shown that NS5A expression confers a general attenuation of ISG expression  Further examination of HCV interactions with the IFN-induced 2′,5′-oligoadenylate synthetase (OAS)/RNase L pathway have revealed that HCV proteins also interact with this pathway , and that once activated the pathway directs the capacity of RNase L to cleave HCV genomic RNA into non-functional nucleolytic products  Gene expression profiling has demonstrated that acute resolving HCV infection in chimpanzees is associated with a robust host response characterized by high level hepatic ISG expression and that the overall expression level of certain ISGs and virus-responsive genes identified them as ‘outcome predictors’ of infection Genetic distinctions between virus strains and viral genotypes are likely to impart differential levels of control and activation of this response , and during acute infection their activation of the host response will lead to the production of IFN and ISG to mediate an antiviral state in the local hepatic tissue  Genetic studies have revealed that RNase L preferentially cleaves HCV RNA only at certain UU and UA dinucleotide sites  Genotype 1 HCV sequences in general have fewer RNase L cleavage sites than HCV genotypes 2 or 3 (ref. 72 ) HCV protein expression in general has been associated with the inhibition of STAT1 function independently of STAT tyrosine phosphorylation  HCV pseudo-particle binding to dendritic cells has been shown to mediate particle uptake and dendritic cell activation  HCV–host interactions within RIG-I, TLR3, IFN signalling pathways and ISG pathways, and at other key sites of host defence, serve to control the host response and may attenuate the therapeutic actions of IFN, thus providing a foundation for persistent HCV replication and spread Hepatic defences triggered by HCV are not always sufficient Hepatic defences to HCV infection have been studied in vivo through functional genomic and biochemical approaches to evaluate human liver from patients with chronic infection and chimpanzee liver from animals undergoing experimental HCV infection Hepatitis C virus (HCV) is remarkably successful Highly fit variants of HCV will mediate signalling interference, in which the NS3/4A protease will block RIG-I and TLR3 signalling pathways to evade the host response to infection and viral RNA replication However, this regulation is not universal and is subject to alteration through viral genetic variation (see below) , indicating that evasion of PKR-independent processes of ISG function contribute to HCV escape from IFN action IFN-γ exerts antiviral effects on HCV RNA replication  IL-8 is a proinflammatory chemokine whose actions interfere with IFN  In addition to inducing ISG expression, IFN-α primes or induces the maturation of immune effector cells, and it potentiates the production of other proinflammatory cytokines by resident hepatic cells to indirectly modulate the cell-mediated defences and adaptive immunity to HCV  In hepatocytes (the target cell of HCV infection), independent pathways of retinoic-acid-inducible gene I (RIG-I) and TLR3 signalling comprise two major pathways of host defence triggering by dsRNA  In human liver this most probably serves to enhance the sensitivity of signalling in infected tissue In recent years much has been learned about the molecular mechanisms by which viruses trigger and regulate these antiviral processes, referred to here as the ‘host response’ In the context of chronic HCV, the latter possibility could occur through TLR3 engagement of viral or host RNA products by hepatocytes and surrounding cells that are not infected and remain competent to signal an ISG response In the course of persistent infection, error-prone virus replication generates a repertoire of highly related but genetically distinct viral variants or ‘quasispecies’ In the latter example, this gene set was defined as those virus-responsive genes whose high expression associated with low viraemia and viral clearance but whose low expression correlated with progression to chronic infection  In this case, prolonged blocking of IRF-3 function could disrupt these actions, perhaps to render a tumorigenic potential to infected cells, thus providing a possible biochemical link between chronic HCV and hepatocellular carcinoma  In vitro studies have shown that this signalling provides an amplification loop to further promote IFN and ISG expression, limiting HCV RNA replication  Indeed, sequencing studies have shown that the resolution of acute HCV infection is associated with an overall reduction in viral quasispecies complexity within the E1 and E2 coding regions of HCV, whereas progression to chronic infection and resistance to IFN therapy is associated with increased viral genetic complexity  Induction of SOCS-3 expression by the HCV core protein could impart evasion from IFN actions, but the overall role of SOCS-3 in HCV infection is not known Inhibition of PKR may allow HCV to evade in part the translational-suppressive actions of IFN and the PKR-dependent signalling processes that amplify the host response to infection  Insight into its evasion strategies has come from studies of model systems and human patients Interferon regulatory factor (IRF)-3 (refs 10 , 11 ) and nuclear factor κB (NF-κB) figure largely in this response IRF-3 and NF-κB are activated through viral PAMP-responsive signalling cascades that culminate in their nuclear translocation and transcription effector actions IRF-5 and IRF-7 have also been implicated as direct transcription effectors of viral PAMP signalling , although the events that confer their activation are incompletely defined and their role in HCV infection is not known IRF-7 is an ISG and is expressed in many tissue types, including complex liver tissue, in response to IFN  ISG expression profiles have also been observed in animals with chronic HCV infection  ISG products impart cell or viral-regulatory functions that limit HCV replication through processes that include disruption of viral RNA translation and inhibition of antigenomic strand RNA synthesis  ISGs are the genetic effectors of the host response to virus infection, and the human genome encodes hundreds of ISGs  It is likely that PKR activation by the core protein is associated with the similar ability of the latter to bind RNA , thereby providing the PKR activator substrate and a possible mechanism of PKR activation during HCV infection It is notable that hepatic ISG expression has been associated with liver pathology  It is the hepatic host response that imposes initial immune defences against HCV infection It is the IFN-α component of the host response that is exploited by the current IFN-based therapy for HCV infection ( Fig. 1 )  It typically produces a persistent infection that, unless interrupted by interferon (IFN)-based therapy, will continue for the lifetime of the individual and present vast opportunities for further transmission within the human population Its N-terminal domain encodes a serine protease, and its carboxy-terminal domain encodes an RNA helicase; the latter may support replication by unwinding the viral RNA  Jak–STAT signalling leads to a second and later wave of transcriptional activity marking ISG expression in the infected cell Key sites of HCV control over the host response are found within the PAMP-responsive signalling pathways that impart IRF-3 activation, within the IFN-α/β receptor signalling pathway that confers ISG expression, and at the level of ISG effector protein products  Last, the blockade of virus-induced NF-κB activity regulates the expression of a variety of chemokines and cytokine genes whose expression is dependent on NF-κB  Like many virus-responsive genes and ISGs, the various products of this ‘outcome predictor’ gene set interact with components of T-cell immunity, implicating a complex cross-talk within the host response between parameters of virus, IFN signalling, and the adaptive immune response to HCV infection Many PAMP receptors and their constituent signalling partners are ISGs, and although expressed basally at a low level that facilitates surveillance, their levels increase markedly after IFN production Moreover, the HCV core protein can activate protein kinase R (PKR), a cellular antiviral protein kinase and an effector component of the host response to virus infection  NF-κB is also involved in inducing the expression of chemokines and proinflammatory cytokines that function in parallel with IFN to mediate the inflammatory response to HCV  NS3 is a bifunctional enzyme NS5A stimulates IL-8 production through transactivation of the IL-8 promoter , and serum IL-8 levels have been found elevated in patients with chronic hepatitis C  Parallel processes that activate ATF-2 and direct chromatin remodelling result in the assembly of an enhanceosome complex with IRF-3 and NF-κB on the IFN-β promoter, leading to a transcriptional response that produces secreted IFN-β from the infected cell  PKR is an ISG and a dsRNA-binding protein whose RNA-dependent activation results in localized translational suppression and parallel stimulation of NF-κB and IRF-1 transcription-effector actions  Protein products of virus infection may also stimulate the host response or activate specific components of this response as they accumulate in the cell Regulation of IFN signalling Local IFN production in hepatic tissue is likely to influence HCV replication and may impart antiviral effects that contribute to the resolution of acute infection  Regulation of ISG expression or function HCV evasion of the host response includes various strategies directed by viral proteins to control ISG expression or function ( Table 1 ) RIG-I contains amino-terminal regions of homology to the caspase activation and recruitment domain (CARD; Fig. 2a ) RIG-I is a DEx/D-box RNA helicase belonging to a small family of helicases involved in host response signalling  Second, many of the components of these pathways, including RIG-I, TLR3, TRIF and the downstream IκB kinase (IKK)-ɛ kinase (one of the enzymes that can phosphorylate and activate IRF-3) , are responsive to IFN and although expressed at low basal levels their abundance is induced severalfold on exposure of cells to IFN-α/β Secreted IFN-β engages the local tissue through autocrine and paracrine processes of binding the IFN-α/β receptors Secretion of IFN-γ by hepatic effector T cells and NK cells also contributes a level of ISG expression partly redundant with the ISGs induced during the IFN-α/β response  Sequence analysis of the HCV NS5A coding region has similarly identified specific domains that exhibit sequence variation in association with the outcome of IFN therapy Signalling is mediated by the CARD homology motifs, which direct the downstream activation of IRF-3 and NF-κB through processes independent of TLR3 ( Fig. 2b )  Similar studies of infected chimpanzees have revealed insights into how this host response is associated with infection outcome STAT3 promotes gene expression through processes that involve the Jak–STAT pathway  The actions of IFN are pleiotropic, both at the signalling level and the ISG response, and it is most likely that HCV evades IFN effects through multiple strategies, including possibly disruption of non-canonical IFN signalling pathways  The expression of IFN-β and various IFN-α subtypes is dependent on virus activation of IRF-3 (ref. 2 ), and the lack of IFN-α/β gene expression within the HCV-infected liver provides indirect evidence that HCV imposes a blockade to IRF-3 activation in vivo  The former possibility is indicated by cell-culture studies in which stress-induced cytokines, including TNF-α and IL-1, triggered signalling crosstalk to activate IRF-1 and derive a level of IFN-β production  The HCV NS3/4A protease functions as an antagonist of virus-induced IRF-3 activation and IFN-β expression through its ability to block RIG-I signalling and to ablate TLR3 signalling by cleaving the TRIF adaptor protein ( Fig. 2 ) The HCV NS5A and E2 proteins of HCV are both inhibitors of PKR  The HCV NS5A protein has been identified as an IFN antagonist, and expression of NS5A alone can suppress IFN-α actions sufficiently to rescue the replication of an IFN-sensitive virus in cultured cells  The helicase activity of NS3 is dispensable for the control of IRF-3 activation, but NS3/4A protease activity is required for this regulation  The host response and the ensuing adaptive immune response present pressures that will select for the outgrowth of viral quasi-species that can evade and successfully control the host response and immune defences  The host response is triggered when a pathogen-associated molecular pattern (PAMP) presented by the infecting virus is recognized and engaged by specific PAMP receptor factors expressed in the host cell, initiating signals that ultimately induce the expression of antiviral effector genes  The host response to infection Virus infection initiates a series of intracellular events that culminate in the generation of an antiviral state directly within the infected cell and indirectly within the surrounding tissue The hostile antiviral host environment may drive the outgrowth of HCV ‘evasion variants’ from a pre-existing quasispecies pool or through viral genetic adaptation The IFN-responsiveness of these factors confers amplification of PAMP signalling action to further enhance the magnitude and duration of the host response The ISG56 product, p56, imparts translational suppressive actions of IFN on HCV RNA replication , and reduced levels of ISG56 expression have been associated with IFN resistance of HCV RNA replication in vitro  The largest effect of PAMP receptor engagement is the activation of latent cellular transcription factors that mediate the rapid onset of gene expression, thus marking the immediate-early phase of the host response  The mechanisms by which IL8 antagonizes IFN actions are not known but probably involve an end result of altering ISG expression The nature of at least one HCV RNA PAMP receptor was revealed through complementation studies of cells with defective host-response signalling programmes , including cells that are highly permissive to HCV RNA replication  The NS3/4A complex constitutes the essential viral protease, which liberates the non-structural proteins from the HCV polyprotein during virus replication  The overall low response rate of HCV (particularly genotype 1 HCV) to IFN therapy indicates that HCV can evade or resist IFN actions in vivo , both locally in the context of a hepatic host response and more globally in the context of IFN therapy ( Fig. 3 ) The paracrine effects of IFN-β induce ISG expression within the neighbouring uninfected cells of the local tissue, inducing an antiviral state that limits cell-to-cell virus spread The proteolytic targeting of host factors by NS3/4A as an evasion strategy from host defence was affirmed through pharmacological studies with a peptidomimetic active-site NS3 protease inhibitor The recent development of cell-culture models of HCV infection now provides a foundation from which to define the molecular mechanisms and novel sites for therapeutic modulation of the host response controls that regulate the HCV infection and replication cycle. The resulting IFN-stimulated gene factor-3 (ISGF3) transcription factor complex localizes to the cell nucleus, where it binds to the IFN-stimulated response element (ISRE) within the promoter/enhancer region of IFN-stimulated genes (ISGs) The signalling blockade imposed by NS3/4A breaks this IFN amplification loop (see Table 1 )  The SOCS proteins are best known for their role as negative regulators and inhibitors of Jak–STAT signalling, where they mediate a classic negative feedback loop on IFN-α/β receptor signalling events  The transcription effector action of IRF-7 promotes IFN-α subtype expression and diversification of the ISG response, establishing a positive-feedback loop that amplifies IFN production and antiviral action  The transmission event results in an acute infection that involves viral regulation of the host response though RIG-I, TLR3 and other virus-responsive signalling pathways within the infected hepatocyte  The viral disruption of RIG-I or TLR3 signalling has many implications The viral RNA of HCV contains each of these PAMP signatures and is sufficient to trigger the host response when introduced into naive cells  These observations demonstrate, first, that the hepatic host response is triggered during HCV infection but is differentially regulated in association with disease course, and second, that in chronic infection HCV can successfully control or evade the host response to persist in the infected cell and hepatic tissue These observations suggest that HCV can both trigger and control the hepatic host response during infection These studies have revealed several levels of immune regulation and evasion conferred by HCV protein products Third, the MHC components of antigen processing and presentation are themselves ISG products , and host-response regulation may effect alterations in antigen presentation, leading to inefficient activation of cytolytic T cells and an inability of the adaptive immune response to clear HCV-infected hepatocytes  This association has been variable in different patient populations, but recent meta-analyses and long-term follow-up of these studies provide overall support for NS5A sequence variation within a 40-residue ‘interferon sensitivity determining region’ (ISDR) that is associated with IFN therapy outcome  This confers STAT activation and stable association with IRF-9 This has been attributed in part to the expression of high levels of protein phosphatase 2A within HCV-infected liver tissue, which may signal STAT1 hypomethylation and inactivation  This indicates that host immune pressure may drive the outgrowth or selection of viral evasion variants able to persist and resist IFN action This is most problematic for the infected patient because quasispecies variation affords remarkable adaptive potential to HCV and has been implicated in evasion and control of the host response to infection and differential sensitivity to IFN therapy  This may explain why some patients with chronic infection do not express significant levels of hepatic ISGs, but it fails to explain why others exhibit broad and abundant ISG expression despite a paucity of IFN-α/β expression in the infected liver This may provide a genetic basis for HCV 1a and 1b resistance to IFN therapy ( Table 1 ) This model invokes an important role for viral adaptation or quasi-species selection in the successful evasion and control of the host response, and projects a ‘foot race’ between the virus and the host for control of this response that in most cases the virus will win This provides pharmacological confirmation that the protease action of NS3/4A is a functional antagonist of the host response induced by dsRNA and viral PAMP signalling This raises the possibility that ISG expression can be induced indirectly as a result of cellular stress from fibrosis and/or cirrhosis, or is induced through TLR engagement exogenously by extracellular products of damaged tissue or viral replication This region of NS5A encompasses a genetically flexible domain that is a key site of adaptations that influence HCV RNA replication fitness  This response probably has a role in controlling HCV infection  This results in a gene-expression profile that includes ISGs and proinflammatory cytokines that may influence the overall level of HCV RNA replication  This results in activation of the Jak–STAT pathway, in which the receptor-associated Jak and Tyk1 protein kinases catalyse the phosphorylation of signal transducer and activator of transcription (STAT) proteins on critical serine and tyrosine residues This review will explore the mechanisms by which HCV triggers, controls and evades antiviral defences directly within the infected hepatocyte and hepatic tissue to support HCV replication and persistence This success is linked to an ability of HCV to evade and antagonize the immune response of the host and to resist the antiviral actions of IFN therapy This work identified RIG-I as a viral PAMP receptor that binds dsRNA , including dsRNA motifs of the HCV genome , to signal the downstream activation of IRF-3 and NF-κB, thereby inducing IFN-β expression and onset of the host response Thus, if successful, the hepatic host response will provide protection against the replication and spread of HCV Thus, ISDR variation may affect the host response to infection indirectly by altering replication efficiency and the abundance of viral proteins available for interaction with and regulation of host response effectors TLR3 directs the activation of IRF-3 and NF-κB through processes that require the protein Toll–interleukin-1 receptor-domain-containing adaptor inducing IFN-β (TRIF)  TLR3 is a dsRNA PAMP receptor that also signals a host response on engagement of a dsRNA ligand ( Fig. 2c )  To replicate and spread successfully, viruses direct various strategies to evade host defences  Transmission of HCV from a source individual and infection of a recipient host present enormous pressure for the virus to adapt to the new host environment and to control the host response to infection Treatment of cells that express functional NS3/4A alone or in the context of active HCV RNA replication showed that the protease inhibitor effectively removed the blockade to RIG-I and TLR3 signalling imposed by NS3/4A, thereby restoring virus-induced IRF-3 phosphorylation/activation and the activation of NF-κB  Triggering the host response to HCV infection Although HCV is a ssRNA virus, its genome RNA encodes regions of extensive secondary dsRNA structure that impart potential PAMP signatures, thus presenting the possibility that HCV RNA is recognized and engaged by host-cell PAMP receptors during infection  Unlike humans, in which acute HCV infection progresses to chronic infection with high frequency that includes a wide-ranging disease course, infection of chimpanzees can progresses to chronic infection but usually with lower frequency and with only minor disease  Until recently, native HCV could not be adequately propagated in cultured cells to support molecular studies of the virus–host relationship Various studies have shown that genome-length or specific subgenomic fragments of HCV RNA are sufficient to trigger IFN-β promoter activation and IFN production when introduced into cultured human hepatoma cells , indicating that during infection these HCV RNA motifs are recognized and engaged by PAMP receptor(s) that trigger the host response  Viral control of NF-κB may therefore contribute to the broader systemic immune defects and enhanced permissiveness for HCV infection Viral genetic variation and the host response to infection As with all RNA viruses, the viral polymerase of HCV lacks a proofreading function Viral triggering and control of the host response may define cellular permissiveness for HCV RNA replication and influence the outcome of infection Virus signalling through RIG-I and TLR3 pathways confers a host response that regulates cellular permissiveness for viral replication
 A pioneering hurricane researcher, Emanuel presents the science at a level that is not too technical for non-specialists, yet is sufficient to describe the basic physics with few equations A scientific discussion of what happens when a hurricane makes landfall is framed within Richard Strausss tone poem Death and Transfiguration  Divine Wind by Kerry Emanuel is therefore timely During the previous hurricane season, Florida was struck by a record number of hurricanes Emanuel compares a view of the eye of a typhoon with a scene from Dantes Inferno  Emanuel deftly interweaves an exposition of the science of hurricanes with historical accounts of major tropical cyclones and artists impressions of the feelings that these tropical tempests instil Emanuel has recently been in the public eye as a result of his recent letter in Nature ( 436 , 686 – 688 , 2005 ) , in which he suggested that any further warming of the troposphere might increase the destructive potential of tropical cyclones Emanuel notes a similarity between The Tempest and an account of a hurricane in 1609 given by William Strachey, an acquaintance of William Shakespeare Emanuels inclusion of art has a welcome humanizing effect He also describes the challenge of predicting and understanding hurricanes His book ends with some further provocative thoughts on hurricanes and climate. Hurricane formation, energetics and ocean interaction are all clearly explained Hurricane Ophelia, which came soon after Katrina, brushed the Carolina coasts, and Hurricane Rita struck Louisiana and Texas Hurricanes are dangerous, but they are beautiful too, if observed from the safety of an aircraft inside the eye of the storm or from space In late August, Hurricane Katrina, following an encounter with South Florida, devastated parts of the US Gulf coast and led to the inundation of New Orleans Instrumentation such as radar, satellites, aircraft, remotely piloted aircraft and scatterometers is also described and explained It would have been nice if the effects of all the forces had been summarized, particularly in the section on numerical weather prediction, where only the sum of all the forces is noted Many scholars say this rules out Edward De Vere as a possible author of The Tempest , because he died before Strachey told his tale My favourite chapter is a photo essay depicting the inside of a hurricane or typhoon One photograph, taken during a US Air Force reconnaissance flight, shows the eye of a typhoon viewed from below Other books have dealt with the historical accounts in more depth, but the overall effect of those in Divine Wind is unique Others have views looking straight down at the turbulent ocean surface and windblown spray, and there is even one image from the space shuttle Some of them affected the course of history, such as the typhoons that struck Japan in the thirteenth century (the ‘divine wind’, or kamikaze , that saved Japan from Kublai Khan), and a hurricane in the sixteenth century that interfered with an attempt by the French to settle Florida Stracheys account itself is poetic: For four and twenty hours the storm in a restless tumult, had blown so exceedingly, as we could not apprehend in our imagination any possibility of greater violence, yet did we still find it, not more terrible, but more constant, fury added to fury, and one storm urging a second more outrageous than the former...The Sea swelled above the clouds, and gave battle unto heaven Technical figures such as satellite and radar images are intermixed with historical photographs and realistic, abstract and sometimes apocalyptic paintings The book also covers the 1900 Galveston hurricane, the New England hurricane of 1938, Hurricane Camille in 1969, Cyclone Tracy in Australia in Christmas 1974 and Hurricane Andrew in 1992 The book does a remarkable job of covering the history, science and terrible beauty of hurricanes, which makes it tempting not only to the storm aficionado and professional scientist, but also to the general public The effects of Katrina are likely to be as long lasting, politically, socially and economically, as those of its predecessors The fundamentals of numerical weather prediction using computers, including chaos theory and its relevance to forecasting, are also well treated The only minor criticism I have is that each of the forces that control the behaviour of hurricanes is treated separately The total number of fatalities has not yet been tallied, but it is expected to be high, and the number of people displaced, damage to property, and economic loss from the disappearance of businesses and interruption of oil and gas production are staggering The tropical atmosphere has recently been surpassing itself The ‘great hurricane’ of 1780 in the Caribbean was one of the deadliest hurricanes ever to strike in that part of the world There are accounts of major historical hurricanes and typhoons There are poems of the regular, not tone, variety, and colourful and easy-to-interpret figures illustrating scientific principles This hurricane has been called the worst natural disaster ever to hit the United States Throughout, Emanuel achieves a perfect balance between the scientific and non-scientific aspects of hurricanes Whereas other books on hurricanes focus on history, such as Erik Larsons Isaacs Storm (Little Brown, 1999), or on science, like Rick Anthes Tropical Cyclones (American Meteorological Society, 1982), Divine Wind addresses both
 A hardy microbial world inhabits the acidic waters of the Tinto river A lake of red-hued water lies below, and groves of orange trees stretch out in the distance A satellite dish is relaying data from the drill site at a rate of 50 megabytes per day — roughly equivalent to the speed at which a spacecraft on Mars might be able to transmit information to Earth A team of mission scientists is pretending that this drill, and the precious core it carries, is located on Mars Although Amils and other biologists have quantified the microbial ecosystem at the surface , the MARTE project has been their first opportunity to go underground Although the martian surface is too cold, dry and drenched in radiation for anything to survive above ground, past life forms could have taken refuge underground, some scientists think Amils labels many of the oozy, lumpy patches ‘scum’, a euphemism for ‘difficult to identify’ Amils thinks that some of the rivers heavy metals are extracted from their ores by bact-eria living inside the rocks Another huge challenge is cleaning out the hole, to prevent the drill from clogging Around Nerva, the Spanish town where the MARTE team is based, the hills are scarred by open pits and abandoned mining equipment As the robot ejects a new core, a researcher lunges inside the rig to catch it on sterilized tin foil Astrobiologists routinely cite such techniques when they talk about searching for life on other planets  Back at Rio Tinto, the drill is working hard to bring up new samples Biologists will be back at the Rio Tinto site, regardless Bottom dwellers Although the Tinto river is naturally acidic and loaded with heavy metals, mining has exacerbated these characteristics  But it pretends otherwise. “If we see a filament in the rock, we know its a root,” says Ballesteros But Rio Tinto, he says, is a good place to include But the root is sampled and tested before they conclude that it is life Data from the swarm of spacecraft currently roaming over and orbiting Mars have identified some possible spots where surface life may once have thrived. “We do our best to pick the sweet cherries, the prime candidates for life,” says James Dohm, a planetary geologist at the University of Arizona, Tucson. “But eventually we have to have subsurface analysis.”  The Spanish project is headed by planetary scientist Carol Stoker of the Ames Research Center, a veteran of previous Mars missions, and focuses on the unusual geochemical environment of Spains Rio Tinto region Despite such difficulties, the MARTE team remains optimistic During a tour of some springs near the source of the Tinto, he notes the murky red, brown and white deposits in the water and on the surrounding rocks For 5,000 years, locals mined the deposit for heavy metals, notably copper For years, Mars researchers have been studying the life forms that eke out an existence in the Atacama Desert of Chile or in the cold, parched Dry Valleys of Antarctica Geologists may snicker to call this deep drilling, but Stoker calls it an impressive accomplishment for a robotic drill loaded with science instruments. “Nothing like this has been done before,” she says He says the river could serve as “an exhaust for a giant underground bioreactor” Her imagination was fired by the idea of an underground ecosystem. “Im not sure it struck him as a really good planetary analogue, but it did me,” she says Hitting the ‘yes’ button will trigger the drill to release its cargo, and reveal whether it has managed to bore material from metres beneath our feet. “Have we got a core?” asks Howard Cannon, an engineer from NASAs Ames Research Center in California Hostile habitat But its underground, in the rocks from which the scenery is carved, that the Rio Tinto region may be most like Mars If the remote researchers spot an interesting part of a core, they can get the robotic drill to subsample it, and pass the sample through sophisticated life-detection systems In 2004, the projects second year, it got a huge boost from data flowing back from NASAs Mars Exploration Rovers, Spirit and Opportunity In contrast, a robotic drill on Mars is stuck on its own with just one drill bit and one technique In this case, the team knows theres a good chance that life could exist in the borehole It is designed to run with minimum human intervention. “Right now, were sitting here doing nothing,” says Cannon. “But every once in a while something will fail and we have to step in.”  Terrestrial drillers would usually select their drill bit to suit the rock, and change the speed and power depending on the conditions they encounter Its Cannons job to see if he can get the drill to work here on Earth Its silver arm draws up from the deep hole it has made in the dirt Local authorities recognize the beauty of the place; they erected a sturdy stone picnic bench for tourists — right on one of the teams preferred drilling sites Lone worker A screw around the outside of the drill bit is meant to carry the debris to the surface, but it keeps getting encrusted with muck Michael Meyer, NASAs lead scientist for Mars, says it is important to study as many of these places as possible. “We dont want to get too far ahead of ourselves in predicting what Mars is like and expend all our energy on one site,” he says Microbiologist Ricardo Amils, of the Autonomous University of Madrid, a member of the science team, has studied the area for years and once gave Stoker an enthusiastic tour Moments later, she dabs a cotton bud over the core, swabbing material to analyse for ATP, the energy-rich molecule that acts as fuel for life on Earth Most are not yet classified Of the samples analysed already, “we have detected life in cores three and five”, says a team biologist Olga Prieto Ballesteros, head of the remote-operations team, marks the new core on a whiteboard On Earth some kind of fluid can be pumped down the drill shaft to remove the cuttings One group is exploring ice-bound communities of bacteria in a frozen volcano on Svalbard, the arctic archipelago off the coast of Norway Others put rovers through their paces in rock-strewn deserts Peering into the end of the instrument, he spots a plug of red mud, some 7 centimetres long Planetary scientists, with their study subjects so far out of reach, have long scoured Earth for otherworldly environments Red dust coats everything, including the laptops running the robot Samples destined for the SOLID instrument are rushed from the drilling tent to an air-conditioned vehicle next door, because the tent is too hot for the instrument to operate properly So, for the team, extracting this chunk of red earth could be a step towards finding out whether life lurks beneath the sterile surface of Mars Some are minerals, some are life Some, in an effort to understand the martian atmosphere, are studying the dust devils whipped up in Nevadas Eldorado Valley Stoker agrees, and is enthusiastic about what they have learned: “This project has advanced the date the technology might be ready for a drilling mission — theres no doubt about that.” Still, the projects US$6-million funding runs out this year, and its unclear whether the drilling rig will get another outing The acidity, in turn, led to other metals in the rocks dissolving, including the iron that gives the Tinto river its distinctive red colour and name The drill is a prototype for an instrument that might one day be sent to Mars The drill is equipped with scientific instruments to search for signs of life in the dirt The drill sits at the edge of an old mining pit that is surrounded by pine trees The drilling technologies being tested here, or others like it, may one day travel to the red planet aboard European Space Agency or NASA missions (see First drill on Mars ) The point of the simulation, they say, was to see what works and what needs to be worked on. “Weve got a lot of work to do, but this is a first step,” says Cannon The remote science team can access data from the drills instruments, including pictures of the core and the output of an imaging spectrograph that helps identify the minerals present The results come from the signs-of-life detector (SOLID) instrument, which uses a protein microarray to look for molecules that are characteristic of life The rovers identified minerals on the surface of Mars, including the sulphate jarosite, which suggested that, when it existed, martian water was salty and acidic  The team can also instruct the drill to lower a camera into the borehole, to inspect the surrounding walls The team has resorted to vacuuming it clean The Tinto river gets its unique chemistry from the Iberian Pyrite Belt, a vast deposit of sulphide minerals tens of kilometres wide that runs for about 250 kilometres through southern Spain and Portugal These are just the kind of conditions found at Rio Tinto  These minerals were laid down when the region was under water; at the site of a hydrothermal vent, deep-seated volcanism forced hot water, rich with dissolved chemicals, through cracks in Earths crust They had not set out to solve every drilling and scientific question in 30 days They may have drilled deep holes, but Amils says theyve only scratched the surface of understanding how this ecosystem works This is good news This is what astrobiologists dream of finding in the subsurface of other worlds This isnt feasible on Mars, so the drill built for the MARTE by New York-based Honeybee Robotics operates dry This unique bio-sphere, he reckons, is powered by sulphur and iron This year, the teams month of drilling nets them a hole just over 6 metres deep Thus, the Mars Analog Research and Technology Experiment (MARTE) was born To a visitor, the landscape looks little like barren Mars Todd Stevens, his colleague and an expert in geomicrobiology from Portland State University in Oregon, sums it up: “We have a lot of work to do to understand the interactions of the rocks and microbes on Earth before we can do it on other planets.” While Cannon is operating the robotic drill in the stuffy tent, Stoker and other members of the MARTE science team are enjoying the air-conditioning of the ultra-modern Center for Astrobiology building outside Madrid “Okay, were at the surface,” a voice calls across the tent. “Can someone hit the ‘yes’ button?” In the centre of a makeshift laboratory, sweltering beneath the Spanish sun, people cluster anxiously around a robotic drill
 Biotech fights back The US Biotechnology Industry Organization is spearheading a drive to shield small businesses from the requirements of a corporate ethics law that it says is too cumbersome for its member companies Breathe easier Tobacco giant Philip Morris has embarked on a business alliance aimed at helping premature babies to breathe Greenwood backed the bill when in Congress. Jim Greenwood, the former Pennsylvania congressman who is now the organizations president, is leading the push to relax the Sarbanes-Oxley law Philip Morris will use its proprietary aerosol technology to develop a device that will deliver the surfactant deep into the lungs The 2002 law tightened corporate accountability in response to accounting scandals surrounding the energy conglomerate Enron and other US corporations The company, based in Richmond, Virginia, has joined up with Discovery Laboratories of Warrington, Pennsylvania, which makes an artificial surfactant — a protein-lipid substance produced in the lungs that is critical for breathing, but often missing from babies who are born more than a month premature The states economic development office says it has agreed tenancy terms for the project with Richard Bransons Virgin Galactic, which intends to put its headquarters there and use the facility as a launch site for space tourists Virgin says 100 people have already paid $200,000 a ticket for suborbital jaunts on a vehicle to be built by California-based Scaled Composites, which won last years X Prize for sending a privately developed vehicle to the edge of space Virgin territory Plans have been unveiled for a US$200-million private spaceport to be built near Las Cruces, New Mexico, in 2007
 Apomictic organisms (not strictly asexual of course), such as dandelions, can develop localized populations accumulating mutations that render them distinct from other members of their clade Colonial bees, wasps and many butterflies and moths all bear distinctive and colourful markings discouraging interference He assumes that complex organisms similar to flowering plants, insects and peacocks would evolve, but that without sex the world would be drab and colourless However, asexually reproducing plants would probably still take advantage of animals for spore dispersal, producing fruits or other rewards (advertised by special structures) as ‘payment’ However, the pro-sex lobby always seems to downplay the importance of asexual reproduction to evolution in stable environments Indeed it is likely that our colour vision developed in order to detect ripe fruits, which have little to do with sex and a lot to do with seed dispersal Sex is good, but it aint everything. Sexual reproduction, in maintaining genetic heterogeneity within a population, is clearly a major mechanism by which species survive catastrophes and adapt to the subsequent conditions Similarly, although it is true that many gaudy avian displays are aimed at mate attraction, there are many brightly coloured animals whose decoration serves as a threat or warning Sir Rolf Hoekstra in News and Views (“Why sex is good”  Nature 434 , 571 ; 2005 ) surely overstates the contribution of sexual reproduction to the aesthetic appeal of nature This kind of diversification is rarely seen in sexually reproducing populations unless they are subjected to selective pressure
 A lot of samples were destroyed.”  The team searched for liquid-nitrogen dewars to replenish, particularly those containing transgenic cell lines. “It was very difficult to find things in labs we were not familiar with,” Backes says. “We pulled out stuff as best we could.”  LSUs four animal research facilities, containing rodents, dogs and primates among others, were on the flooded ground floors. “100% of those lab animals were lost,” says Moerschbaecher A survey team there also discovered freezers without electricity, but didnt have the chance to fully explore because of the high waters Academic rescue teams may have saved some projects, entering flooded buildings and topping up dewars of liquid nitrogen to keep specimens cold Accompanied by rescue workers and armed military personnel, small teams assessed the damage to labs that had been underwater or without power for many days At the Tulane centre, the animals were located on the eighth floor, well beyond the reach of the flood waters But as the agency struggles to feed and house tens of thousands of people caught in Katrinas path, research is a low priority. But the full scientific loss may not be known for weeks or months Dozens of institutions opened their doors last week to displaced researchers, who had often lost their homes as well as their bench space Four years ago, a storm destroyed similar facilities at a medical center in Houston (see Nature 411 , 874 ; 2001 10.1038/35082202 ) Hurricane Katrina has apparently devastated research laboratories in New Orleans In 2001, the tropical storm Allison swamped the Texas Medical Center in Houston, drowning research animals and destroying years of cell lines John Clements, head of microbiology and immunology at Tulane, said the 6 September expedition was so harried that he could not check on his own home, just three blocks off the truck caravans path Late last week, Katrinas flood waters began to recede in New Orleans as the US Army Corps of Engineers patched breaks in the city-protecting levees and started pumping the water back into the neighbouring Lake Pontchartrain On 6 and 7 September, more than a week after Katrina hit the region, researchers made their first trips into the medical and research complexes of LSU and Tulane University in downtown New Orleans Once inside, the researchers found that a dozen buildings were flooded with two metres of water Rescue teams last week discovered that many frozen specimens and cell cultures had thawed, making them useless, and laboratory animals had drowned. “This was a real disaster for research,” says pharmacologist Joseph Moerschbaecher, vice chancellor for academic affairs at the Health Science Center of Louisiana State University (LSU) in New Orleans Scientists based in Louisiana or Mississippi have moved as far as California to maintain their projects Shortly after Katrina hit, NIH director Elias Zerhouni said it was not his agencys responsibility to help universities weather catastrophic storms That task, he argued, belonged to the Federal Emergency Management Agency The catastrophe may trigger debate over how prepared academic institutions ought to be for natural disasters The Katrina disaster will raise questions about how scientific institutions should prepare for storms and who should take responsibility for emergency measures, especially given past experiences in the region The National Science Foundation, the National Institutes of Health (NIH), and the Department of Energy are extending grant deadlines, offering to match affected researchers with academic hosts, and generally doing what they can to help along recovery from Katrina The team walked the dark hallways with flashlights, searching for research material that could be saved before they had to evacuate by the nightly curfew. “It was hot, humid and smelled like mouldy refrigerators,” Backes says. “All the −70 °C freezers were at room temperature Together LSU and Tualane have about 300 researchers who are annually funded by $130 million of NIH money Trying to keep cool At the LSU centre, the flood water was too high for a Humvee to navigate, so the team climbed aboard trucks, says pharmacologist Wayne Backes, LSUs assistant dean for research and lead academic on the survey team Tulanes main campus, located on higher ground uptown, survived Katrina in relatively good shape With more than half a dozen colleges and universities effectively out of commission along the US Gulf Coast, scientists and students have begun scattering across the country to try to salvage their careers and studies
 A critical weakness lies in the Department for Education and Skills, which is often criticized for a lack of responsiveness and excessive control A drive towards applied research into low-carbon energy technologies could help bridge the gap between UK academics and the numerous small firms that work in this area Although more money is available, an increasing proportion of it is directed towards specific outcomes, and the freedom to fund responsively in some disciplines is succumbing to other priorities Behind it all lies a lack of joined-up government in addressing the supply and demand for future researchers But although Labour has indeed performed impressively on this front, there are noticeable gaps in its record But it ultimately lies with Blair to ensure that the departments responsible for universities work coherently But the scandal of the Blair governments record on science is to be found in the universities CaSE calculates that the proportion of science funds controlled by central government has risen from 2% to 20% since 1997 — but that the funds available to the key funding agency for the great majority of physicists and chemists, the Engineering and Physical Sciences Research Council, have risen by only 6% Credit where it is due Everyone agrees that the gap must be made up predominantly by industry — everyone, that is, but industry itself, which, apart from the biomedical sector, by and large persists with a chronic lack of interest in research and is in long-term decline in several manufacturing sectors Funding for science in universities and the research councils, the main source of UK grants, is up by more than 80% at £4.3 billion (US$8.1 billion) annually since 1997 and is set to go on rising He has been greatly aided by the championship for science and associated wealth creation by the chancellor of the exchequer, Gordon Brown, who is widely expected to take over from Blair as prime minister within the next four years In relation to science, this has been his most signal failure. Meanwhile, the stream of department closures in the physical sciences is set to continue, to the increasing alarm of industry Sainsbury has consistently proved himself to be an enthusiastic science minister with well-tuned instincts for policies that are both sound and deliverable Scientists and their organizations need to put pressure on Tony Blairs administration as it enters a third term in office Tax breaks and other measures announced last year will help, but many doubt whether the goal can be met The balance between the freedom of universities to control their development and the nations need to protect its knowledge and skills base is a delicate one The continuing growth of biology-based industries will help, as will a focus on emerging and potentially research-intensive industries such as renewable energy The fact that the countrys main science lobbying group has recently changed its name from Save British Science to the Campaign for Science and Engineering (CaSE) says much about what the government has achieved since then The government also faces a bigger challenge: how to reach the ambitious target, set last year, of raising total spending on research and development from 1.9% to 2.5% of gross domestic product by 2014 The government has also employed a chief science adviser, David King, who has won the respect of researchers and the media and the ear of senior politicians The government needs to abandon the target or explain how to meet it The latter have been too selective in favour of top-rated departments and have exposed the high costs of science departments to increasingly market-driven management The rise in the grant-funding science budget has not been accompanied by appropriate infrastructural and teaching support from higher-education funding councils There has been a haphazard response to the combination of declining interest among the young in science as a career — not unique to Britain — and misguided university funding schemes This lack of conflict was one reason why science played such a minor role in last weeks UK elections When the Labour party came to power in Britain in 1997, it inherited a decaying science base staffed by disillusioned scientists When the science minister David Sainsbury and his two opposition counterparts met for a press briefing last month, the spokesmen for both the Liberal Democrats and the Conservatives began by congratulating the Labour government for its record on science Wisely, the critical problem of the nations crumbling science infrastructure was tackled first Yet many UK scientists say it is as hard as ever to fund the basic research they want to do
 Here we report the discovery of both Kea- and Loa-like major and trace element compositions in olivine-hosted melt inclusions in individual, shield-stage Hawaiian volcanoes—even within single rock samples Instead, the observed chemical variation is probably controlled by the thermal structure of the plume. Melt inclusions, or samples of local magma ‘frozen’ in olivine phenocrysts during crystallization, may record complexities of mantle sources , thereby providing better insight into the chemical structure of plumes The Hawaiian–Emperor volcanic island and seamount chain is usually attributed to a hot mantle plume, located beneath the Pacific lithosphere, that delivers material sourced from deep in the mantle to the surface  The shield volcanoes of the Hawaiian islands are distributed in two curvilinear, parallel trends (termed ‘Kea’ and ‘Loa’), whose rocks are characterized by general geochemical differences  This has led to the proposition that Hawaiian volcanoes sample compositionally distinct, concentrically zoned, regions of the underlying mantle plume  We infer from these data that one mantle source component may dominate a single lava flow, but that the two mantle source components are consistently represented to some extent in all lavas, regardless of the specific geographic location of the volcano We therefore suggest that the Hawaiian mantle plume is unlikely to be compositionally concentrically zoned Analytical uncertainty is 1–2% for major elements, and 5–10% for minor elements Each melt inclusion was measured using 3–20 points, the compositions of which were then averaged EPMA and LA-ICP-MS analyses We measured major element compositions for 147 melt inclusions from 13 rock samples of submarine Hana ridge, Haleakala volcano and 63 melt inclusions from 3 rock samples of submarine Koolau volcanoes Inclusions and host olivine were analysed by electron probe microanalysis (EPMA) with a JEOL-8800 instrument at the Tokyo Institute of Technology, following procedures described elsewhere  Methods Homogenization of melt inclusions Olivine-hosted melt inclusions were subjected to experiments designed to homogenize them by melting and quenching, using a 1-atm gas mixing furnace following accepted procedures and conditions  Olivines from single samples were loaded into Pt capsules that were gradually lowered, over 10 min, from the top of the furnace (100 °C) to the hottest place in the furnace (1,250 °C) and kept at that temperature for 10 min before quenching The oxygen fugacity was kept at the quartz–fayalite–magnetite (QFM) buffer The resulting precision, determined by analysing a standard as an unknown, is better than about 10% for most elements. Trace element abundances were measured using laser ablation inductively coupled plasma source mass spectrometry (LA-ICP-MS) coupled with a ThermoElemental PQ2 Ω instrument at the Tokyo Institute of Technology, following procedures described elsewhere  We measured trace element compositions for 58 melt inclusions from 13 Hana ridge lavas and 21 melt inclusions from 3 Koolau lavas A final implication is that melt compositions are ‘fingerprinted’ by the source and transported independently before final mixing and homogenization in the magma chambers of individual volcanoes  All host olivines have CaO contents (0.16–0.29 wt%) that are typical of magmatic olivine and significantly higher than those of mantle (that is, xenocrystic) olivine  Also some major element ratios, such as Na/Ti, vary systemically with isotope compositions  As the volcano grows, it migrates away from the hot plume axis with plate motion At higher temperatures, basaltic eclogite melts will react with peridotite, producing Kilauea-like melts with a composition higher in MgO and lower in SiO 2 than melts formed at lower temperatures  Bulk lavas from some younger stages of the Hawaiian shields have enriched isotopic characteristics (for example, Mauna Loa, the Haleakala shield (Honomanu), and the Koolau shield Makapuu stage), suggesting that the proportion of fertile pyroxenite is higher than the proportion of depleted peridotite sampled by the melts Detailed sample information, including specific locality and whole rock geochemistry, has been presented elsewhere  Experimental petrology shows that, for a given degree of partial meting, depleted peridotite generates melts having higher Ca/Al, lower SiO 2 and higher FeO contents than does fertile peridotite  Far from the plumes centre, temperatures would be lower, and the more fertile, isotopically enriched material (for example, eclogite) may be sampled to a greater extent. Furthermore, we exclusively use major element ratios (such as Al 2 O 3 /CaO and TiO 2 /Na 2 O) and incompatible trace element ratios (such as Zr/Nb and Sr/Nb) in order to circumvent problems associated with olivine fractionation in the magmas, possible modification of inclusions from exchange with olivine during eruption, and re-equilibration between the host olivine and inclusion before analysis  Here, we demonstrate that both Kea and Loa components co-exist in a single shield at both Haleakala and Koolau; therefore, a compositionally zoned mantle plume is inconsistent with our data However, Zr and Nb should not be affected as they are highly incompatible in both plagioclase and clinopyroxene In contrast, melt inclusions can provide important information on compositions of magmas before extensive magma mixing  In other words, in the plume core, higher temperatures are able to generate melts from the more refractory component (that is, depleted peridotite), but at plume margins, lower temperatures permit melting of only the more fertile material Lavas suspected of derivation from a source containing recycled oceanic gabbroic crust have Th/La and Th/Ba values less than the primitive mantle , and excesses of Eu and Sr  Likewise, the presence of Sr-enriched, light rare earth element-depleted melt inclusions from Mauna Loa also suggests a recycled lower oceanic crustal component in the Hawaiian plume  Major element compositions of melts derived from recycled eclogite would be expected to be associated with enriched isotopic signatures  Major element ratios (Al 2 O 3 /CaO, TiO 2 /Na 2 O) and incompatible trace element ratios (Zr/Nb, Sr/Nb) are correlated in our melt inclusion data, implying that these ratios reflect source geochemical characteristics and the variations, therefore, must reflect source heterogeneity Major element ratios (such as Al 2 O 3 /CaO and TiO 2 /Na 2 O), together with incompatible trace element ratios (such as Zr/Nb and Sr/Nb), of melt inclusion from submarine Hana ridge lavas overlap the fields for both Kilauea and Mauna Loa lavas ( Figs 2a , 3a ) Melt inclusions reported here have Al 2 O 3 /CaO and Sr/Nb that are well correlated with Zr/Nb (not shown), indicating that mixing of primitive and evolved magmas is unlikely to have occurred Mixing of primitive and evolved (for example, plagioclase-fractionated) magmas in the magma plumbing system could also cause variations in Al 2 O 3 , CaO and Sr, because of the affinity of these elements for plagioclase Most importantly, melt inclusions from individual rock samples at both Hana ridge and Makapuu display not only significant heterogeneity, but also span the compositional fields for both Kilauea and Mauna Loa lavas (for example, K214-9, K214-15A, S500-5B, S500-1; Figs 2b–d , 3b–d ) Most major and trace element compositions of melt inclusions from the Makapuu stage of Koolau olivines are similar to data for whole rocks from Koolau (Makapuu stage, extreme Loa) lavas , however, other melt inclusions extend well into the fields for Mauna Loa and Kilauea lavas ( Figs 2d , 3d ) Most of our current understanding of the geochemistry of mantle plumes originates from data on whole rocks Multiple melt inclusions from individual olivine phenocrysts show much more limited variability than observed in the population from whole rocks Ocean crust basalt typically has low Sm/Yb values as melting occurs extensively and at shallow depths, whereas Hawaiian shield lavas usually have higher Sm/Yb values because of deep melting of a garnet-bearing source Overall, general geochemical differences exist in whole rocks between Kea- and Loa-trend volcanoes, but in detail these differences can also exist within a single shield , and can vary relative to eruption age , suggesting a more complicated structure for the Hawaiian mantle plume  Partial melting at 2–3 GPa of eclogite with a composition like that of mid-ocean-ridge basalt produces silica-rich basaltic andesites low in FeO and with low CaO/Al 2 O 3 (refs 25 , 26 ) Potential processes that might cause the observed major and trace element ratio variations among the melt inclusions include the assimilation of ocean crust basalt by Hawaiian plume-derived magmas, or mixing of evolved magmas with primitive magmas Previous work has consistently demonstrated that trace element ratios, such as Zr/Nb and Sr/Nb, are correlated with radiogenic isotope ratios in Hawaiian shield lavas, and it is widely accepted that these trace element ratios reflect mantle source compositions  Primary information about the mantle source composition beneath Hawaii can, in theory, be obtained from data on melt inclusions, provided the host olivines are derived exclusively from Hawaiian plume melts The compositional variations in melt inclusions in individual rock samples from Haleakala (Kea trend) and Koolau (Loa trend) suggest that the length-scale of chemical heterogeneity is remarkably smaller than that estimated on the basis of bulk rock geochemistry The data are presented in Supplementary Table 1  The dominant component sampled at a given shield volcano may reflect melting processes related to the position of the volcano relative to the hot centre of the plume The geochemistry of Hawaiian lavas, particularly isotopically ‘enriched’ lavas from Koolau, has been explained by the presence of a recycled eclogite (or pyroxenite) component in the Hawaiian plume  The melt inclusions have relatively constant Sm/Yb values that are high, much higher than those associated with ocean crust basalt ( Fig. 4 ), making assimilation an unlikely scenario  The plume may be envisioned as having a matrix characterized by one composition (for example, Kea) with streaks or ribbons of another composition (for example, Loa) distributed throughout the entire plume The presence of both Kea and Loa compositions in melt inclusions from individual shield volcanoes, and even in single lava samples, indicates that whole rocks may sample one mantle source component dominantly, but that the two (or more) source components are consistently represented to some extent, regardless of the specific geographic locations of the volcano (for example, above the ‘Kea’ zone) Therefore, changes in major element compositions of melt inclusions from Kilauea- to Mauna Loa- to Koolau (Makapuu)-like probably reflect changes in the source available for melting (that is, from relatively depleted to relatively fertile peridotite) Therefore, in the same way that isotopic compositions (for example, Pb isotopic ratios) are used, these major and trace element ratios may be sufficient in distinguishing the Kea and Loa signatures of the Hawaiian shield lavas.The Kea and Loa geochemical trends among the Hawaiian shield volcanoes are commonly believed to reflect melting above a compositionally concentrically zoned or compositionally left-right asymmetrically zoned mantle plume These characteristics are also present in melt inclusions examined in this study This is most easily explained if melting zones for lavas from the younger stages of Hawaiian shields are located farther from the hot mantle plume axis This recycled ancient oceanic crust may remain distinct geochemically , forming streaks or ribbons that are deformed and stirred by stretching and folding as the plume rises through the mantle  To best explain both the overall geochemical trends and the newer, more detailed whole rock and melt inclusion data, we propose a Hawaiian mantle plume characterized by more random heterogeneity than would be present in a compositionally zoned mantle plume To test the homogeneity of the mantle plume source sampled in the Kea and Loa trends by Hawaiian shield volcanoes, we examined major and trace element compositions of olivine-hosted melt inclusions from Hawaiian shield lavas, using electron microprobe and laser ablation inductively coupled plasma source mass spectrometry (see Methods) We selected lava samples from the submarine Hana ridge, Haleakala volcano (Maui), and the submarine exposures of the Makapuu stage, Koolau volcano (Oahu), because these two volcanoes are believed to represent the sampling of the two distinct compositions, having erupted above the Kea trend and Loa trend, respectively ( Fig. 1 ) Yet, whole rocks record only an ‘average’ composition produced by complex petrogenesis involving partial melting in the mantle, subsequent aggregation of melts on their way to the surface, and mixing of melts in shallow magma chambers 
 Natl Acad Number Crunch Scientists this week announced the longest-ever electronic tracking of a migrating animal, a diminutive seabird called the sooty shearwater. 65,000 km is the distance travelled by a sooty shearwater in 200 days. 5,000 km is the distance travelled each year by some caribou, the land animals that migrate the farthest. 800 g is the average weight of an adult sooty shearwater. 189 kg is the average weight of a caribou On the Record “Americans arent gullible enough to believe that they came from a fish.”  Creationist John Morris on a new Museum of Creationism in Kentucky. “Today, with all the pollution, you cannot get cleaner water than melted ice-cap water.”  Salik Haard promotes his new beer, made with water from Greenlands shrinking glaciers Sci Scorecard Chemical analysis Isotope ratio mass spectroscopy showed that testosterone found in the urine of Floyd Landis, winner of the Tour de France, did not have the same carbon isotope ratio as other hormones in the sample, showing it had a different, external source. newsad; Climate porn A report by the Institute for Public Policy Research, a UK think-tank, highlights the “quasi-religious register of doom, death, judgement, heaven and hell” in alarmist climate reporting that can become “secretly thrilling” Sources: Associated Press, BBC News, Proc This is not, the institute argues, a helpful way of framing things USA
 Here we investigate the methane-emitting Haakon Mosby Mud Volcano (HMMV, Barents Sea, 72° N, 14° 44′ E; 1,250 m water depth) to provide quantitative estimates of the in situ composition, distribution and activity of methanotrophs in relation to gas emission It is also unclear how efficiently methane-oxidizing microorganisms remove methane Mud volcanism is an important natural source of the greenhouse gas methane to the hydrosphere and atmosphere  Recent investigations show that the number of active submarine mud volcanoes might be much higher than anticipated (for example, see refs 3–5 ), and that gas emitted from deep-sea seeps might reach the upper mixed ocean  The HMMV hosts three key communities: aerobic methanotrophic bacteria ( Methylococcales ), anaerobic methanotrophic archaea (ANME-2) thriving below siboglinid tubeworms, and a previously undescribed clade of archaea (ANME-3) associated with bacterial mats This mechanism limits the capacity of the microbial methane filter at active marine mud volcanoes to 40% of the total flux. Unfortunately, global methane emission from active submarine mud volcanoes cannot be quantified because their number and gas release are unknown  We found that the upward flow of sulphate- and oxygen-free mud volcano fluids restricts the availability of these electron acceptors for methane oxidation, and hence the habitat range of methanotrophs A detailed description of in situ data and the geochemical models applied here is provided elsewhere . A detailed description of the methods described here is provided in the Supplementary Information  Bottom water was sampled with a bottom water sampler and methane concentrations were determined by gas chromatography  Chloride concentrations were determined from pressure-filtered pore water by ion chromatography Fluorescence in situ hybridization (FISH) Cells of Methylococcales as well as ANME-3/DBB and ANME-2/DSS aggregates were quantified by FISH with monolabelled oligonucleotide probes as previously described  Lipid analysis Lipid biomarkers from frozen sediment samples and tubeworm tissue were extracted, separated and derivatized as described previously  Methods Sampling Our studies took place during two cruises with RV L’Atalante (2001) and RV Polarstern (2003), both equipped with ROV VICTOR 6000  Microsensor measurements Microsensors (20 µm tip diameter) for O 2 , H 2 S and pH were manufactured and used as described previously  Profiles were recorded in situ with a spatial resolution of 0.025 cm by deploying a profiler unit (equipped with the sensors) with the ROV or a free falling lander system Sediment cores as well as in situ microsensor profiles were obtained along a radial transect from the centre to the east of the mud volcano ( Fig. 1b ) Sediments were collected with ROV pushcores and gravity cores for on board ( ex situ ) measurements Single lipid compounds were analysed by gas chromatography, mass spectrometry and isotope ratio mass spectrometry to determine their quantity, identity and stable carbon isotope ratio, respectively  Sulphate and chloride concentrations Sulphate concentrations were determined by high-performance liquid chromatography (HPLC) analysis from the supernatant of 5 ml sediment fixed with 25 ml zinc acetate solution  Sulphate reduction and methane oxidation rates Microbial rates of aerobic and anaerobic methane oxidation (MOx and AOM, respectively) and sulphate reduction (SR) in sediments were determined ex situ using 14 CH 4 and 35 SO 4 - tracers  Accordingly, microbial biomass peaked in the top 3 cm ( Fig. 3g ) and mainly consisted of a previously undescribed consortium of archaea and sulphate-reducing bacteria (SRB) forming dense cell aggregates ( Fig. 2c ). 16S rRNA gene analyses of DNA revealed a dominant cluster of archaeal sequences forming a new phylogenetic group named ANME-3 ( Supplementary Fig. 1 ) Accordingly, the maximum AOM was found between the base of the worm tubes and the hydrate layer (60–90 cm below sea floor (b.s.f.)), coinciding with a subsurface peak of ANME-2/DSS aggregates (5.5 × 10 6 aggregates cm –3 ) and their specific biomarker lipids ( Fig. 3i–l ) Aerobic oxidation of methane had a minor role (1–3%) compared with anaerobic oxidation, which removed up to 37% of the total methane flux An essential difference between the habitats is the fluid flow modelled from in situ gradients of temperature, oxygen and sulphide concentrations  An interesting question remains: which factors determine the transition between Beggiatoa mats and tubeworm fields, and the temporal succession of the thio- and methanotrophic communities? Visual observation of the sea floor showed that sulphide-oxidizing mats and tubeworm colonies are mutually exclusive (no worms were found within bacterial mats) Analyses of 16S rRNA genes and lipid biomarkers showed that the bacterial partner associated with ANME-3 is different from all other ANME consortia (see Supplementary Information ) ANME cells were not microscopically detectable in the centre cores using all known ANME oligonucleotide probes, and anaerobic oxidation of methane (AOM) was not detectable ANME-3 and ANME-2 consortia both dominate areas with lower flow, and profit from the association with other organisms that re-oxidize sulphide to sulphate As predicted by the fluid flow model for this area , methanotroph cell numbers, lipid biomarkers and rates of aerobic methane oxidation (MOx) peaked in the uppermost surface sediment and decreased more than fivefold in the second centimetre because of limited oxygen penetration ( Fig. 3a–d ) As predicted by the fluid flow model, 95% of ANME-3/DBB aggregates were found directly below the Beggiatoa mats ( Fig. 3g ) At their maxima in abundance and activity ( Fig. 3 ), methanotrophic communities show relatively low cell-specific rates of methane oxidation (around 0.1 fmol CH 4 per cell per day, under atmospheric pressure), possibly owing to the low ambient temperature of –1 °C Balancing downward diffusion and upward fluid flow, maximum sulphate penetration could reach 12 cm Because of reduced fluid flow velocities, sulphate can penetrate the upper 4–6 cm of the sediment column ( Fig. 3f , Table 1 ) Consequently, as in the case of the HMMV, methane rising with warm, oxidant-depleted fluids might accumulate in muds and escape as free gas to the hydrosphere Further quantitative in situ measurements of fluid flow and microbial methane consumption are necessary to define the relevance and control of methane emissions from submarine mud volcanoes and other fluid-flow driven geo-bio-systems. Furthermore, if such fluids transport heat from below, they could even suppress the formation of hydrates, which represent an important—although dynamic—sink for methane on earth  Furthermore, the re-oxidation of sulphide by the sulphide oxidizer mats replenishes the sulphate pool in these sediments, further contributing to the maintenance of high activity and biomass of the AOM community in this zone Hence, the efficiency of microbial methane removal is substantially lower than in other methane-fuelled systems  Here we have shown that the efficiency of the microbial filter against methane decreases considerably at fluid flow rates 0.4 m yr –1 , causing increased efflux of methane to the hydrosphere and probably even to the atmosphere  High concentrations of a 13 C-depleted (–80‰), type I methanotroph-specific fatty acid (C16:1ω8c) were found in the same samples ( Fig. 3d ) High flows of methane-laden fluids introduce a negative switch in the relationship between fluid flow and methanotroph activity However, compared with filamentous sulphide oxidizers, tubeworms can reach much deeper zones of sulphide production, and might efficiently compete for sulphide and methane uptake However, geofluids produced from compaction processes and dewatering are depleted in electron acceptors However, the measured oxygen and sulphate penetration in the tubeworm field ( Figs 2d , 3i, j ; Table 1 ) show that the tubeworms substantially increase the transport of electron acceptors into deeper sediment layers In 2003, methane emission to the hydrosphere from the HMMV reached 8–35 × 10 6  mol yr –1 (ref. 8 ), resulting in a total methane flux of 13–40 × 10 6  mol yr –1  In agreement with the low subsurface temperature gradient in this zone ( Fig. 3e, i ), gravity cores from this area contained gas hydrate below the worm-infested sediment layers In conclusion, we found that methane oxidation was the main energy source for microbial biomass in all habitats of the HMMV In situ microsensor profiles of sulphide concentrations in HMMV sediments indicated that AOM occurs in older mud flows, 2–3 cm below the sulphide-oxidizer mats ( Figs 2c, 3f ) In the tubeworm fields, fluid flow rates modelled from temperature profiles (0.4 m yr –1 ) were lower than those in the centre or bacterial mat area  Integrated ex situ methane consumption was higher than in other zones of the HMMV ( Table 1 ) Investigation of the HMMV with RV Polarstern and ROV Victor 6000 in 2003 showed extensive outcroppings of fresh subsurface muds associated with steep thermal gradients , gas and fluid vents, and a large gas plume reaching the mixed upper water column above the HMMV  It is closely related to Desulfobulbus spp. (DBB) and also takes up methane-derived carbon, as indicated by its specific lipid biomarker C17:1ω6c with a δ 13 C-value of –70‰ ( Fig. 3h ) It is generally assumed that with increasing upward flow velocities, more dissolved methane is transported to the surface, fuelling increasingly active seep communities (for example, see ref. 26 ) Its formation might have coincided with a submarine landslide during the late Pleistocene, 330,000–200,000 years ago  Microbe–invertebrate symbioses have an advantage over free-living microbial populations because they can engineer their environment to increase access to both electron donors and acceptors by special migratory behaviour, mining and pumping Moreover, the archaeal lipid biomarkers have stable C-isotope signatures (δ 13 C-values –98‰), indicating that methane is the main carbon source of ANME-3 cells Oligobrachia haakonmosbiensis , the dominant species in the investigated area, is up to 60 cm long and has a diameter of 0.5 mm Only small amounts of methanotroph lipids (0.1 μg per gram sediment dry weight; µg g-dw -1 ) and very low numbers of cells (∼10 7  cells cm –3 ) were found below a sediment depth of 5 cm ( Fig. 3c, d ) Populations of aerobic or anaerobic methanotrophs comprised 56–76% of the total microbial community (centre and Beggiatoa mat habitats) Seafloor videography in combination with geochemical measurements provided in situ estimates of gas flux , fluid flow and habitat distribution  Single sequences of this cluster were only sporadically detected at cold seeps , which are typically dominated by other phylogenetic clades of anaerobic methanotrophs (that is, ANME-1 and ANME-2 with their bacterial partners, sulphate reducers of the Desulfosarcina/Desulfococcus (DSS) branch)  The 16S ribosomal RNA gene sequences of the dominant Methylococcales types (HMMV-MetI and -MetII) are closely related to sequences of methanotrophic mussel symbionts (94–97%) and to clone sequence Hyd24-1 (96–99%) from gas-hydrate-bearing sediments of Hydrate Ridge  The concentrations of gases in sediments and bottom water were elevated in all three habitats ( Table 1 ) The emitted gas is of a mixed microbial/thermogenic origin and consists of 99% CH 4 with a δ 13 C-isotope signature of –60‰ (refs 12 , 13 ) The HMMV ( Fig. 1 ), a circular structure of 1 km diameter and 10 m elevation above the adjacent sea floor, has been studied since the 1990s as a typical example of an active mud volcano  The next significant transition in HMMV habitats occurs about 300–400 m from its geographical centre, where the sulphide oxidizer mats are replaced by dense tubeworm colonies on the hummocky periphery of the HMMV ( Fig. 2d , Table 1 ) The results indicate that the upward transport of oxidant-depleted mud volcano fluids hinders downward diffusion of oxygen and sulphate, and limits methanotrophic habitats in the centre and below bacterial mats to the uppermost millimetres to centimetres, respectively  The rising fluids are depleted in sulphate, chloride and magnesium as a result of subsurface clay dewatering  The surface of the most recent mud flows in the centre of the HMMV, characterized by steep temperature gradients of 3°C m –1 (ref. 14 ), hosted high numbers of microbes, reaching 3.6 (±2.1; ±s.d.) × 10 9  cells cm –3 , of which 56% (±8%) belonged to type I aerobic methanotrophic bacteria of the orders Methylococcales and Methylophaga ( Figs 2b , 3c ) The total integrated activity and biomass was lower for the aerobic methanotrophs than for the AOM communities, as the former were limited to the surface of the centre muds by high fluid flow ( Table 1 , and see Supplementary Information ) These data confirm that fluid advection acts as a main habitat-structuring factor at cold seep ecosystems, by regulating the availability of electron acceptors and hence the distribution and activity of methanotrophs Today, fluids, gas and muds rise from a depth of 2–3 km through a conduit below the HMMV  Total methane consumption in the centre, Beggiatoa and tubeworm habitats was up to 0.2, 1.8 and 3.0 × 10 6  mol yr –1 , respectively (sum 5.0 × 10 6  mol yr –1 ) Tubeworm larvae probably cannot settle on Beggiatoa mats owing to the high fluid flow and high AOM-based sulphide concentration in this habitat Two siboglinid tubeworm species, Oligobrachia haakonmosbiensis and Sclerolinum contortum , populate this area with biomasses of 1–2 kg wet weight m –2 (estimated from sieved boxcore samples) Velocities of decimetres to metres per year are within the average range of fluid flow measured at cold seeps , so the described inhibition of microbial methane consumption might be widespread at seeps We focused on the three main concentric habitats above the gassy muds ( Fig. 2 ): the centre of the HMMV, which was devoid of visible epifauna; thiotrophic bacterial mats dominated by a Beggiatoa species; and surrounding fields of siboglinid tubeworms We have now identified and quantified the methanotrophs that populate the three habitats to assess their role in controlling methane flux at the HMMV ( Table 1 ; Figs 2 , 3 ) We propose that members of the ANME-3 cluster are also capable of AOM, for three reasons: the AOM maximum coincides with the sulphide production zone; there are high numbers of ANME-3 aggregates (19.7 (±0.6) × 10 6 aggregates cm –3 at 1–2 cm sediment depth), making up 80% of total cell numbers; and concentrations of the lipid biomarkers sn2 -hydroxyarchaeol, archaeol and specific penta-methyl-icosenes are highly elevated ( Fig. 3e–h )
 50 YEARS AGO The longest earthworm in the world, Megascolides australis , is found in Gippsland, Australia, and grows up to eleven feet in length...When disturbed, the worm squirts out a series of pairs of jets of fluid from a line of pores opening down each side of the body Although there are reports that the fluid has a corrosive action, it is only slightly alkaline and contains some dissolved salts, body wastes like urea and some proteinous materials and cells Ambassador at Washington An altogether exceptional feature of the ceremony was that a degree was conferred on the King, who was represented by Sir Mortimer Durand, H.M An American dinner is managed somewhat differently from our own, for the toast-master is not, as with us, a servant with a stentorian voice, but is the most highly honoured of the hosts of the occasion.. From Nature 10 May 1906. From Nature 12 May 1956. 100 YEARS AGO “The bicentenary celebration of the birth of Benjamin Franklin” — The oldest scientific society in the new world is, I believe, the American Philosophical Society of Philadelphia...founded by Benjamin Franklin.. In announcing this degree the Provost read with great effect the celebrated speech on England from Henry V It is pleasant to record the enthusiastic cheers which the whole audience gave, standing, as the Ambassador was hooded.. The effect can be most spectacular, for these jets rise as high as eighteen inches or two feet into the air The fluid comes from the worms body cavity and is squirted out by violent contractions of the body-wall which force the fluid out under great pressure through the pores The fluid is used for lining or lubricating the burrows of the worms There is no record of the fluid having anything but a mildly irritating effect on the skin of human beings Those who have taken part in such festivals in America need not be told that the organization was admirable and the hospitality unbounded
 B.K. In Seeds: Time Capsules of Life (Papadakis, £35/Firefly, $60), artist Rob Kesseler and seed morphologist Wolfgang Stuppy, both of the Royal Botanic Gardens at Kew, present a natural history of seeds, showcasing their specialized architecture in stunning close-up photographs and scanning electron micrographs The walls of the balloon seed of the yellow paintbrush ( Castilleja flava ) shown here have dissolved, leaving a honeycombed cage ready to ride the wind They first appeared 360 million years ago and have helped plants colonize much of Earths surface True time capsules of life, seeds may travel thousands of miles and wait for many years until they encounter the right conditions for germination Whether clinging to a sock, surfing the breeze or sliding through an animals gut, seeds have been beautifully designed by evolution for dispersal
 Atg7 deficiency caused massive neuronal loss in the cerebral and cerebellar cortices Here we report that loss of Atg7 (autophagy-related 7), a gene essential for autophagy, leads to neurodegeneration However, little is known about the precise roles of autophagy in neurons In addition to the ubiquitin–proteasome system, emerging evidence points to the importance of autophagy—the bulk protein degradation pathway involved in starvation-induced and constitutive protein turnover—in the protein quality-control process  Notably, polyubiquitinated proteins accumulated in autophagy-deficient neurons as inclusion bodies, which increased in size and number with ageing Our results indicate that autophagy is essential for the survival of neural cells, and that impairment of autophagy is implicated in the pathogenesis of neurodegenerative disorders involving ubiquitin-containing inclusion bodies. Protein quality-control, especially the removal of proteins with aberrant structures, has an important role in maintaining the homeostasis of non-dividing neural cells  There was, however, no obvious alteration in proteasome function We found that mice lacking Atg7 specifically in the central nervous system showed behavioural defects, including abnormal limb-clasping reflexes and a reduction in coordinated movement, and died within 28 weeks of birth Antibodies against Atg7, Atg5 and LC3 have been described previously  Antibodies against Rpt1, Rpn2 and α5 were provided by K Assay of proteasome activity Peptidase activity was measured using a fluorescent peptide substrate, succinyl-Leu-Leu-Val-Tyr-7-amido-4-methylcoumarin (Suc-LLVY-MCA), as described previously  Atg7 flox/flox mice were bred with nestin- Cre transgenic mice to produce Atg7 flox/flox ; nestin- Cre mice B Brain tissues were excised and processed for morphological analysis as described previously  Electron microscopy and immunoelectron microscopy Fixed brains were post-fixed with 1% OsO 4 , embedded in Epon812 and sectioned Experimental protocols were approved by the Ethics Review Committee for Animal Experimentation at the Tokyo Metropolitan Institute of Medical Science For counting TUNEL-positive signals in the cerebral cortex, 60 coronal sections containing the anterior portion of the hippocampus (∼0.6-mm thick in total) were cut, and TUNEL staining was performed on every sixth section, on a total of ten sections For light microscopic analysis, 10-µm cryosections were cut and stained with HE or immunolabelled with the following antibodies: anti-human NeuN ( Abcam ), anti-GFAP ( Sigma ), anti-calbindin ( Sigma ), anti-myelin basic protein (MBP; MCA409S , Serotec ) and anti-ubiquitin ( DAKO ) antibodies Glycerol gradient analysis Samples were fractionated by 10–40% (v/v) linear glycerol density gradient centrifugation (22 h, 100,000 g ) as described previously  Hendil Histological examination Atg7 flox /+ ; nestin- Cre and Atg7 flox/flox ; nestin- Cre mice were fixed by cardiac perfusion with 0.1 M phosphate buffer containing 4% paraformaldehyde, 4% sucrose for light microscopy and immunohistochemistry, with 0.1 M phosphate buffer containing 2% paraformaldehyde, 2% glutaraldehyde for standard electron microscopy, or with 0.1 M phosphate buffer containing 4% paraformaldehyde, 0.1% glutaraldehyde for immunoelectron microscopy Immunoblot analysis Immunoblots were carried out as described previously  Immunoelectron microscopy was carried out on cryothin sections as described previously  In brief, brains were frozen in phosphate buffer containing 2.3 M sucrose and 20% polyvinyl pyrrhoridon Methods Animals Nestin- Cre transgenic mice were purchased from the Jackson Laboratory  Mice were housed in a pathogen-free facility Motor function was assessed using a rotarod test  Ornithine decarboxylase (ODC)-degradation activity was assayed as described previously . Polyclonal anti-ubiquitin (FK2 ; Medical Biological Laboratories ) and anti-actin (MAB1501R ; Chemicon ) antibodies were also used The TUNEL assay has been described previously  Ultrathin sections were mounted on Formvar carbon-coated nickel grids, blocked with 1% bovine serum albumin (BSA) in PBS, and incubated with anti-ubiquitin antibody (1B3) and colloidal gold-conjugated secondary antibody Although loss of Purkinje cells was observed in the mutant brain, we could not detect TUNEL-positive Purkinje cells at any developmental stage examined Although we do not know whether autophagy and proteasome degradation target a similar set of normal and/or misfolded proteins, it is plausible that the autophagic pathway assists in degrading accumulated intractable proteins when cellular levels of aberrant proteins overwhelm the disposal capacity of the proteasome At P56, ubiquitin-positive dots were detected in several regions of the Atg7 flox/flox ; nestin- Cre mouse brain, including the cerebral cortex ( Fig. 3b ), cerebellar Purkinje cells ( Fig. 3d ), hippocampal pyramidal neurons ( Fig. 3f ), thalamus (data not shown), hypothalamus ( Fig. 3h ), amygdala ( Fig. 3j ) and pontine nuclei ( Fig. 3l ) Atg12–Atg5 conjugate was detected only in the brains of control mice by immunoblotting with an anti-Atg5 antibody ( Fig. 1a ) Atg7 flox/flox ; nestin- Cre mice were viable at birth and indistinguishable in appearance from their littermates Atg7 is an E1-like enzyme for both the Atg12- and Atg8-conjugation systems , and is essential for autophagy  Atg7 protein was absent at postnatal day (P)28 in brain from Atg7 flox/flox ; nestin- Cre but not control ( Atg7 flox /+ ; nestin- Cre ) mice ( Fig. 1a ) Autophagy also has a role in cellular remodelling during differentiation and the development of multicellular organisms, such as dauer formation in Caenorhabditis elegans and metamorphosis in Drosophila melanogaster  Both forms were detected in brains from control mice, but only the LC3-I form was detected in Atg7 flox/flox ; nestin- Cre brain ( Fig. 1a ) Consistent with the above immunohistochemical analysis ( Fig. 3p , q ), immunoblot analysis revealed increasing levels of high-molecular-mass polyubiquitinated proteins with age in the brains of Atg7 flox/flox ; nestin- Cre mice ( Fig. 4a ), and an increase in their insoluble forms at later developmental stages (data not shown) Dots found in the intercellular space might correspond to ubiquitin inside neurites, because they were observed in myelinated axons around pontine nuclei using both light and electron microscopy ( Supplementary Fig Electron microscopy showed that Atg7 flox/flox ; nestin- Cre hypothalamic neurons had circular or elliptical large structures composed of fibrillar elements in the perikarya ( Fig. 3m , n ) Finally, we examined whether autophagy deficiency influences proteasome functions For example, whereas most neuronal cells in the amygdala ( Fig. 3j ) and hypothalamus ( Fig. 3h ) contained several ubiquitin dots of small to large size, only a small number of cerebellar Purkinje cells stained for ubiquitin, and the immunoreactive dots were of small size ( Fig. 3d ) Furthermore, the ATP-dependent degradation of ornithine decarboxylase (ODC) by 26S proteasomes was similar in control and mutant brains ( Fig. 4c ) Furthermore, the mice showed motor and behavioural deficits, including abnormal limb-clasping reflexes ( Fig. 1c ) and tremor, and in some cases, they walked on their tiptoes Furthermore, whether autophagy has a role in cell death or cell survival is currently under debate  Genetic studies using various model organisms have highlighted the importance of autophagy in physiological and pathological events  Hence, our data indicate a central role for constitutive autophagy in the elimination of unfavourable proteins and in the survival of neurons, independent of the proteasome system (see the proposed model in Supplementary Fig Histological analysis using Meyers haematoxylin and eosin (HE) staining showed marked atrophy of the cerebral cortical region of Atg7 flox/flox ; nestin- Cre brain at P56 ( Fig. 2a , b ) However, it remains unknown whether these two proteolytic systems work independently or cooperatively to maintain protein homeostasis in cells However, the physiological functions of autophagy, particularly in neurons, are still largely unknown However, the survival rate of the mutant mice diminished markedly by four weeks after birth, and all Atg7 flox/flox ; nestin- Cre mice were dead within 28 weeks ( Fig. 1b ) However, when Atg7 was specifically depleted in Purkinje cells using transgenic mice expressing Cre recombinase under the control of the Pcp2 gene promoter (Pcp2- Cre ), a marked reduction in the number of Purkinje cells was detected in the absence of TUNEL reactivity (data not shown), suggesting that neurons deficient in autophagy can die in a cell-autonomous fashion Immunoelectron microscopy further confirmed that these aberrant structures contained ubiquitin ( Fig. 3o ) Immunostaining for the glial marker GFAP (glial fibrillary acidic protein) showed an increase in GFAP signal in the cerebral cortex of Atg7 flox/flox ; nestin- Cre mice ( Fig. 2e , f ), suggesting the presence of neuronal damage in this region In a rotarod test, most Atg7 flox/flox ; nestin- Cre mice fell after grasping the rod only briefly ( Fig. 1d ) In contrast, almost no ubiquitin dots were observed in astroglial cells ( Supplementary Fig In contrast, free Atg5, which was faintly observed in the control mouse brain, was clearly increased in the mutant brain ( Fig. 1a ) In contrast, several ubiquitin-containing inclusions were clearly noted in Atg7 flox/flox ; nestin- Cre cortex and hypothalamus at P18, increasing in number and size by P56 ( Fig. 3p , q ) In the cerebellar cortex, HE staining revealed a large reduction in the number of Purkinje cells in the mutant brain ( Fig. 2g , h ), which was further confirmed by immunolabelling of Purkinje cells with an anti-calbindin antibody ( Fig. 2i , j ) Increasing evidence indicates that ubiquitin-positive inclusion bodies—the pathological hallmark of various neurodegenerative diseases—are formed by dysfunction of proteasome degrading machinery  Indeed, proteins with aberrant structure impair proteasome functions directly, thus attenuating ‘garbage disposal’   Macroautophagy (hereafter referred to as autophagy) is an evolutionarily conserved pathway in which the cytoplasm and organelles are engulfed within double-membraned vesicles, known as autophagosomes, in preparation for the turnover and recycling of these cellular constituents  Moreover, constitutive autophagy, which occurs independently of nutrient stress, contributes to mouse liver homeostasis , major histocompatibility class (MHC) II antigen presentation , and cellular defence against invading streptococci and Mycobacterium tuberculosis  Moreover, the relative amounts of several subunits of the 26S proteasome did not change in the brain irrespective of autophagy deficiency (as detected by immunoblotting, Fig. 4d ) Moreover, we find that autophagy deficiency in neurons leads to the accumulation of ubiquitin-containing inclusion bodies, without obvious deficits in proteasome function Notably, almost no large pyramidal neurons were observed in Atg7 flox/flox ; nestin- Cre mice compared with the corresponding region in brains from control mice ( Fig. 2c , d ) On the other hand, the accumulation of autophagosomes owing to impairment of fusion with lysosomes is observed in various disorders, including Alzheimers disease , and it has been proposed that autophagy functions to degrade toxic proteins in familial neurodegenerative diseases  Only a few ubiquitin-positive aggregates were noted in the neurons of control and mutant cerebral cortex and hypothalamus at P9 ( Fig. 3p , q ) Over the past decade, researchers working in the field of neurodegenerative diseases have made great progress in uncovering the mechanisms of these disorders by focusing on the interplay between proteolytic stress and neural cell death  S1 ) S2 ) S3a, b ) S3c ) S4 ) Similar neuronal loss was also recognized in the hippocampal pyramidal cell layer of mutant brain ( Supplementary Fig The chymotryptic activities of 26S and 20S proteasomes (measured using Suc-LLVY-MCA as a substrate) were comparable in extracts from both control and Atg7 flox/flox ; nestin- Cre brains ( Fig. 4b ) The degree of staining varied by region The level of Atg7 protein in other tissues such as liver, lung, heart and muscle was comparable between Atg7 flox/flox ; nestin- Cre and control mice (data not shown) The loss of both Atg7 and LC3-II proteins was observed from P0 in the brain of Atg7 flox/flox ; nestin- Cre mice ( Supplementary Fig The mammalian homologue of yeast Atg8, microtubule-associated protein 1 light-chain 3 (LC3), exists in two forms (LC3-I and LC3-II)  The principal role of autophagy is in the supply of nutrients for survival, as shown in yeast and early neonatal mice  The ratios of cortical thickness to dorsoventral thickness of the brain in Atg7 flox /+ ; nestin- Cre and Atg7 flox/flox ; nestin- Cre mice were 0.17 ± 0.00031 and 0.15 ± 0.00034, respectively ( n = 5, P 0.01) These motor and behavioural deficits began to appear at P14–P21 These results indicate an age-dependent increase in ubiquitin-containing inclusion bodies in autophagy-deficient neurons These results indicate complete impairment of autophagy in the central nervous system of Atg7 flox/flox ; nestin- Cre mice after birth These results indicate that age-dependent accumulation of ubiquitin-positive aggregates in the autophagy-deficient brain occurs despite the apparently normal function of proteasomes These results suggest that autophagy deficiency in the central nervous system results in a severe neurological disorder These ubiquitin dots appeared not only in the perikarya of neurons, but also in the intercellular space (see Fig. 3h , j , l ) To determine whether the reduced number of neurons observed in Atg7 flox/flox ; nestin- Cre mouse brain was caused by cell death, we performed TUNEL (TdT-mediated dUTP nick end labelling) assays To examine the relationship between neuronal pathology and autophagy deficiency in vivo , we crossed Atg7 -conditional knockout mice ( Atg7 flox/flox ) (ref. 8 ) with transgenic mice expressing Cre recombinase under the control of the nestin promoter (nestin- Cre ) (ref. 14 ), to produce mice deficient for Atg7 specifically in the central nervous system ( Atg7 flox/flox ; nestin- Cre ) Together with the results in Fig. 3 , we concluded that most of the distinct ubiquitin dots were located in neurons Together, these results indicate that lack of autophagy in the central nervous system leads to neurodegeneration We also observed growth retardation as early as P14 in these mice (data not shown) We examined the development of ubiquitin-containing inclusion bodies at different stages by dissecting the brains of Atg7 flox /+ ; nestin- Cre and Atg7 flox/flox ; nestin- Cre mice at P9, P18 and P56 We have previously reported that autophagy is responsible for constitutive protein turnover in quiescent hepatocytes even under nutrient-rich conditions, and that a defect in autophagy leads to the accumulation of large, ubiquitin-containing inclusion bodies  We have shown that a lack of autophagy is associated with neurodegeneration, even in the absence of harmful gene products found in neurodegenerative disorders such as Huntingtons disease, Parkinsons disease and amyotrophic lateral sclerosis We have shown that Atg7 flox/flox ; nestin- Cre mice exhibit neurological abnormalities and neuronal death, suggesting that impaired autophagy causes neurodegeneration We observed a marked increase in the number of TUNEL-positive cells in the cerebral cortex ( Fig. 2k–m ) and granular cell layer of the cerebellum at P56 in Atg7 flox/flox ; nestin- Cre mice ( Fig. 2n–p ) compared with control mouse brains We suggest a particularly important role for autophagy in the brain, to which nutrients must be constantly supplied from other organs, even under fasting conditions We therefore predict that the role of autophagy becomes even more critical in the pathogenesis of such neurodegenerative diseases, when disease-related, aggregation-prone proteins are expressed as a result of genetic mutations and/or environmental insults, leading to early-onset symptoms. We therefore probed brain sections with an anti-ubiquitin antibody to examine the presence of ubiquitin-containing inclusion bodies
 Adiabatic potential-energy surfaces—usually derived using quantum chemical methods that assume mutually independent nuclear and electronic motion —quantify the fundamental forces between atoms involved in reaction and thus provide accurate descriptions of a reacting system as it moves through its transition state  Electron emission only occurs once the vibrational energy exceeds the surface work function, and is at least 10,000 times more efficient than the emissions seen in similar systems where large-amplitude vibrations were not involved  Gaining insight into the nature and dynamics of the transition state is the essence of mechanistic investigations of chemical reactions , yet the fleeting configuration when existing chemical bonds dissociate while new ones form is extremely difficult to examine directly  Here we report the detection of ‘hot’ electrons leaving a metal surface as vibrationally highly excited NO molecules collide with it There is, however, some evidence calling into question the correctness of this theoretical approach for surface reactions: electronic excitation upon highly exothermic chemisorption has been observed , and indirect evidence suggests that large-amplitude vibrations of reactant molecules can excite electrons at metal surfaces  These observations unambiguously demonstrate the direct conversion of vibrational to electronic excitation, thus questioning one of the basic assumptions currently used in theoretical approaches to describing bond-dissociation at metal surfaces. This approach, widely tested for gas-phase reactions , is now also commonly applied to chemical reactions at metal surfaces  A detailed mechanistic explanation for the experimental observation of electron emission induced by large-amplitude molecular vibration will require interactions between theory and additional experimental work, but some aspects of the dynamics already seem clear A pulsed molecular beam containing NO with a kinetic energy of 29 meV is formed in the ‘source’ vacuum chamber After passing through a 1-mm aperture into an ultrahigh-vacuum surface science chamber, the molecules collide with the metal surface, inducing emission of electrons Although this assumption has been widely tested for gas-phase reactions, less is known for reactions at metal interfaces As yet, however, there are no direct observations of ‘hot’ electrons produced by excitation exchange with large-amplitude vibration By comparison, we note that the yield previously observed for exoelectron emission from ground vibrational state NO, O 2 , N 2 O and NO 2 on Cs and Li films is of the order of 10 -8 to 10 -6 (refs 12–18 ) Collisions of NO( v ) with low-work-function surfaces resulted in electron emission for v = 9–18 Cs-covered gold surfaces prepared in this way have work functions between 1.3 and 1.6 eV (ref. 21 ) Electronically adiabatic potential-energy surfaces computed with ab initio quantum chemistry methods have played a central role in advancing our understanding of chemical reactions Emitted electrons were counted with a multi-channel scaler Figure 1 shows the results observed when monitoring the electron current emitted from the surface, while scanning the de-excitation laser wavelength (upward-going signals) in the SEP( v = 18) pumping scheme First, it seems unlikely that we are witnessing electron emission resulting from NO dissociation For comparison, the energetic equivalent position of the surface work function is shown as a grey-shaded bar Furthermore, such a dissociative mechanism could not explain the observed vibrational threshold, without invoking a coincidental dissociation barrier equal to the work function Greber has described how a ‘hole’ on a newly formed O - ion formed after dissociative electron transfer may plummet in energy far below the Fermi level before an additional electron is transferred to produce the ground electronic state O 2-  Here we report experiments intended to demonstrate the importance of non-adiabatic electronic effects associated with large-amplitude intramolecular motions similar to those associated with transition-state traversal In such an O - ‘chemical hole diving’ process, electron emission efficiencies of 10 -6 –10 -8 were reported , whereas here we observed efficiencies as high as 0.02 In this case, the vibrational energy would transfer in small amounts to many electrons and it is unlikely that any single electron would acquire energy beyond the work function Indeed, the observation of a vibrational energy threshold for electron emission near the value of the surface work functions indicates that multiple vibrational quanta are coupled to a single electron, a conclusion that is easily reconciled with a mechanism where an electron is transferred transiently to the NO molecule It also seems unlikely that the vibrational energy transfer proceeds in a fashion where single vibrational quanta are transferred efficiently but sequentially in multiple steps It then passes through a skimmer into another ‘excitation and detection’ vacuum chamber, where it is resonantly excited with laser light to prepare selected quantum states in high vibrational levels Motion through a transition state involves large-amplitude vibration: bond elongation is so extreme that dramatic changes occur in the structure of the electronic cloud holding the atoms together as the system reorganizes to new chemical species NO ( v = 8) was prepared and sometimes yielded a non-zero emission signal No electron emission was observed for NO in its ground vibrational state No surface oxide was required to observe the electron emission, indicating a mechanism of electron emission different from previous reports of exoelectron emission resulting from NO ( v = 0) interactions at surfaces  Perhaps the greatest value of the electronically adiabatic potential-energy surface stems from its use in providing an accurate description of motion through a chemical transition state, given that experimental detection of chemical transition states is extremely difficult (see ref. 2 for a notable exception) Resonances in the depletion of side fluorescence were measured simultaneously at the preparation zone SEP was also used to prepare NO( v = 4, 5, and 7), resulting in no detectable electron emission Spontaneous emission from NO-A 2 Σ + ( v = 0), which produces molecules in vibrational states v ≤ 5, also gave no electron emission States higher than v = 18 were not studied Stimulated emission pumping , SEP( v ), was used to produce NO molecules in a selected excited vibrational states, v , where 18 ≥ v ≥ 4 The absolute number of fluorescence photons was derived from the observed current of a solar-blind photomultiplier tube, accounting for: (1) measured photomultiplier gain, (2) photocathode quantum efficiency, (3) optical collection efficiency of the lens system, and (4) spatial overlap of the laser and molecular beams The angle of incidence between the molecular beam and the surface normal was fixed at 60° to maximize electron collection The observation that large-amplitude vibrational motion can efficiently excite metallic electrons by more than 1.3 eV points to the need to account for strong electronically non-adiabatic influences in theories of chemical reactions at metal interfaces. The observed resonance wavelengths can be predicted from spectroscopic theory of the NO molecule to better than the bandwidth of the laser (0.12 cm -1 ) The quenching of this hole can result in an Auger emission event The surface temperature was ∼300 K in all the experiments reported here The vibrational dependence of the per-collision electron emission efficiency is shown in Fig. 2  The work function of various metals with submonolayer Cs coverage drops below the asymptotic work functions of both the base metal and pure Cs  There is a one-to-one correspondence between electron emission and fluorescence depletion resonances, establishing that incident NO( v = 18) is responsible for the observed electron signal There is already indirect evidence that under these conditions, heavy-atom vibrational motion can exchange large amounts of energy, producing electronic excitations in a metal, which casts doubt on the electronically adiabatic picture of chemical transition states for reactions at metal interfaces  These are also shown in Fig. 1 (downward-going signals) These results indicate a yield of approximately 0.02 electrons per incident NO( v = 18) molecule This chamber also provides a laser-induced fluorescence (LIF) detection station for monitoring the intensity of the beam of vibrationally excited molecules This powerful conceptual and predictive system is based on the assumption that nuclear motion associated with the reorganization of chemical bonds proceeds without facile electronic excitation (called the electronically adiabatic or Born–Oppenheimer approximation) This provided an internal standard of electron emission that allowed us to gain a measure of control over the day-to-day reproducibility of the experiment This was accomplished through excitation of NO to the excited electronic state A 2 Σ + ( v ′ = 3) followed by laser-induced de-excitation to the targeted vibrational state, v , back in the ground (X 2 Π) electronic state Thus for most reactions, theory plays an essential role in revealing their fundamental nature Thus, the considerations presented above strongly suggest that the observed electron emission results from a process that converts large-amplitude vibrational energy of heavy nuclei in the vicinity of the metal surface to translational energy of a metal electron by a mechanism involving electron transfer from the metal to the NO molecule To carry out this work, we used an apparatus similar to that of ref. 19  To determine the per-collision efficiency for electron emission, the absolute number of NO( v ) molecules in the molecular beam pulses was determined from saturated laser-induced fluorescence detection at the position where the beam collides with the surface To obtain the relative electron emission signals for different vibrational states, we compared the signal produced by the SEP-prepared state to the residual signal produced in the absence of the de-excitation laser, where vibrational states are populated by spontaneous emission from A 2 Σ + ( v ′ = 3) Tuning the laser away from either of the two resonances (excitation and de-excitation) used for state preparation resulted in a reduction or complete loss of electron emission We also used spontaneous emission from laser-prepared A 2 Σ + ( v = 0) to populate vibrationally excited states, X 2 Π( v ≤ 5) We detected emitted electrons with a 40-mm double microchannel-plate detector located close to the surface and identified the observed signals as electrons by the fact that a 2–3-gauss magnetic field effectively removes the signal We monitored the effect of Cs dosage on the work function by observing the photoemission generated by a He-Ne laser ( hν = 1.96 eV), which enables us to prepare surfaces that exhibit maximum photoemission and thus a surface near the work function minimum  We prepared low-work-function surfaces by depositing Cs on Au(111) with a commercially available source (SAES Getters) in a ultrahigh-vacuum chamber with base pressure of ∼1 × 10 -10  torr We see a vibrational threshold near the energetic equivalent of the surface work function, strong evidence that we are witnessing direct conversion of vibrational energy to electronic excitation in the metal
 Here we show that intranasal administration of oxytocin, a neuropeptide that plays a key role in social attachment and affiliation in non-human mammals , causes a substantial increase in trust among humans, thereby greatly increasing the benefits from social interactions In the absence of trust among trading partners, market transactions break down In the absence of trust in a countrys institutions and leaders, political legitimacy breaks down Little is known, however, about the biological basis of trust among humans Much recent evidence indicates that trust contributes to economic, political and social success  On the contrary, oxytocin specifically affects an individuals willingness to accept social risks arising through interpersonal interactions These results concur with animal research suggesting an essential role for oxytocin as a biological basis of prosocial approach behaviour. Trust is indispensable in friendship, love, families and organizations, and plays a key role in economic exchange and politics  Trust pervades human societies  We also show that the effect of oxytocin on trust is not due to a general increase in the readiness to bear risks After every transfer decision, each investor was asked about his belief with regard to the expected back transfer from the trustee After subjects had read the instructions in each experiment, we checked whether they understood the payoff structure by means of several hypothetical examples All decisions in the experiments and the answers to the questionnaires were entered on a computer using z-Tree software  All subjects (with one exception) answered the control questions correctly All subjects gave written, informed consent before participation Behavioural experiment and questionnaires After substance administration, subjects completed questionnaires on a computer to measure demographic items and psychological characteristics During this 5-min waiting period, subjects were seated at different tables Each subject in the trust experiment made four decisions in the same player role while paired with different, randomly selected interaction partners Exclusion criteria for participation were significant medical or psychiatric illness, medication, smoking more than 15 cigarettes per day, and drug or alcohol abuse In addition, subjects received an oral summary of the instructions In order to avoid any subjective substance effects (for example, olfactory effects) other than those caused by oxytocin, the placebo contained all inactive ingredients except for the neuropeptide In particular, an investors payoff risk (that is, the distribution of payoffs) in the risk experiment was identical to that in the trust experiment at any feasible transfer level In the risk experiment, everything was identical to the trust experiment, except that all subjects played the role of an investor who could transfer 0, 4, 8, or 12 MU into a project rather than to a trustee In total, 16 individuals out of the original sample of 194 were excluded because of incorrect substance administration (7 in the trust experiment, 5 in the risk experiment) or their stated disbelief that the opponent in the trust game was actually a human being (4 participants) Methods Subjects A total of 194 healthy male students (mean age ± s.d., 22.0 ± 3.4 yr) from different universities in Zurich participated in the study No pair of subjects interacted twice Notably, trust levels were statistically constant across the four decisions One subject did not answer the control questions correctly and was excluded from the data set (this subject also did not apply the substance correctly) Owing to the crucial role of the social environment in triggering behavioural effects of oxytocin (as shown in animal research) , subjects were asked to wait in the rest area while the next part of the experiment was prepared Participants were informed at the time of recruitment that the experiment would evaluate the effects of a hormone on decision making Subjects at the same table could talk to each other, but at the beginning of the experiment they were informed that they would not be interacting with those subjects who sat at the same table Subjects in the role of the investor received no feedback about the trustees decision between the different interactions Subjects received a flat fee of 80 Swiss francs for participation in the experiment; each MU earned in the trust and the risk experiment was worth 0.40 Swiss francs. Subjects were instructed to abstain from food and drink (other than water) for 2 h before the experiment, and from alcohol, smoking and caffeine for 24 h before the experiment Subjects were randomly and anonymously assigned to the role of investor or trustee in the trust experiment, and did not know the identity of the persons with whom they were matched Subjects were randomly assigned to the oxytocin or placebo group (double-blind, placebo-controlled study design) Substance administration Subjects received a single intranasal dose of 24 IU oxytocin ( Syntocinon-Spray , Novartis ; 3 puffs per nostril, each with 4 IU oxytocin) or placebo 50 min before the start of the trust or the risk experiment The study protocol was approved by the ethics committee of the University of Zurich The trust experiment had 128 participants, and 66 subjects participated in the risk experiment There is no time trend in investors decisions in either the oxytocin or the placebo group To measure alterations in the psychological state of subjects throughout the course of the experiment, we assessed their mood and calmness at the beginning of the experiment (before substance administration) and immediately before the trust experiment or the risk experiment, by means of a suitable questionnaire  When subjects re-entered the laboratory for both experiments, they received written instructions (available from the authors on request) explaining the payoff structure of the experiment and the private payment procedure at the end of the experiment A Mann-Whitney U -test indicates that these expectations do not differ significantly between oxytocin and placebo groups at every feasible positive transfer level ( P 0.357, two-sided tests at transfer levels of 4, 8 or 12 MU) A second mechanism behind the effect of oxytocin on trust could be based on subjects beliefs An element of trust characterizes almost all human social interactions An increase in the transfer level from 4 or 8 MU to 12 MU decreased the investors average payoff slightly, whereas it increased the objective risk of very low back transfers by the trustee As sharing the proceeds is costly for the trustee, a selfish trustee will never honour the investors trust because the investor and the trustee interact only once during the experiment As this motive cannot operate in the risk experiment, it can only increase transfers levels in the trust experiment Aside from its well-known physiological functions in milk letdown and during labour, oxytocin receptors are distributed in various brain regions associated with behaviour , including pair bonding, maternal care, sexual behaviour, and the ability to form normal social attachments  At every positive transfer level (4, 8 or 12 MU), their back transfers are statistically indistinguishable from those of placebo trustees (Mann Whitney U -tests; P 0.243, two-sided tests for each positive transfer level) Finally, there is the possibility that oxytocin helps subjects to overcome their betrayal aversion in social interactions First, the investor has the option of choosing a costly trusting action by giving money to the trustee Given that oxytocin is believed to promote social attachment and affiliation in non-human mammals, we hypothesized that oxytocin might also promote prosocial approach behaviours—such as trust—in humans Here we have sought to examine the effect of oxytocin on trust in humans However, betrayal aversion alone cannot explain why investors given oxytocin make higher transfers in the trust experiment compared with the risk experiment, because betrayal is impossible in the risk experiment However, if we add the oxytocin group in the trust experiment to these three samples, significant differences are observed (Kruskal-Wallis test; χ 2 = 8.610, d.f. = 3, P = 0.035), indicating that only the investors in the oxytocin group of the trust experiment behave differently However, our findings may also have positive clinical implications for patients with mental disorders that are associated with social dysfunctions (for example, social phobia or autism) However, the trustee also has the option of violating the investors trust However, trustees given oxytocin do not show more trustworthy behaviour ( Fig. 3 ) If the investor transfers money, the total amount available for distribution between the two players increases but, initially, the trustee reaps the whole increase In contrast, only 21% of the subjects in the oxytocin group had a trust level below 8 monetary units (MU), but 45% of the subjects in the control group showed such low levels of trust In contrast, the trustees can condition their behaviour on the basis of the investors actions In fact, our data show that oxytocin increases investors trust considerably In non-human mammals, the neuropeptide oxytocin has a central role in general behavioural regulation, particularly in positive social interactions In order to address this question, we measured the investors subjective expectation about the trustees back transfer after every transfer decision In order to answer this question, we conducted a risk experiment in which the investor faced the same choices as in the trust game but in which a random mechanism, not the trustees decision, determined the investors risk In particular, social phobia ranks as the third most common mental health disorder and is characterized by marked social deficits, including persistent fear and avoidance of social interactions In the latter case, the investor is worse off than if he had not trusted at all and, adding insult to injury, the trustee has an unfair payoff advantage relative to the investor In the trust game, the risk on the part of the investors is due to the uncertainty of the trustees behaviour—that is, a social interaction with a specific trustee constitutes the risk In this risk experiment, the investors behaviour does not differ between the oxytocin and the placebo groups ( Table 1 and Fig. 2b ) In this trust game, two subjects interacting anonymously play either the role of an investor or a trustee ( Fig. 1 ) Moreover, in order to provide an additional control for non-specific effects that might be associated with oxytocin administration, we explicitly measured mood and calmness before substance administration and 50 min after administration (but before subjects played the trust or the risk game) Moreover, oxytocin does not affect investors beliefs about the likelihood of a good outcome in the risk experiment ( P 0.128, two-sided Mann Whitney U -tests for transfer levels of 4, 8 or 12 MU) Moreover, the aversion of investors to abuse of trust seems to have an important role across different human cultures and social groups in the context of our game  Moreover, there is no significant difference in a comparison of the placebo group in the trust experiment with the oxytocin group and the placebo group in the risk experiment (Kruskal-Wallis test; χ 2 = 0.533, d.f. = 2, P = 0.766), with identical median transfers across groups ( Table 1 ) Of course, this finding could be misused to induce trusting behaviours that selfish actors subsequently exploit Our hypothesis that oxytocin increases the trusting behaviour of investors implies that the investors in the oxytocin group ( n = 29) will show higher money transfers than those in the placebo group ( n = 29) Our interpretation of oxytocins effect on trust in terms of betrayal aversion may be seen in the light of animal studies indicating that increased availability of oxytocin in the central nervous system facilitates approach behaviour, by linking the overcoming of social avoidance with the activation of brain circuits implicated in reward (for example, the nucleus accumbens)  Out of the 29 subjects, 13 (45%) in the oxytocin group showed the maximal trust level, whereas only 6 of the 29 subjects (21%) in the placebo group showed maximal trust ( Fig. 2a ) Oxytocin might render subjects more optimistic about the likelihood of a good outcome Rather, oxytocin specifically affects the trusting behaviour of investors ng the central nervous system effects of oxytocin in humans  Research in non-human mammals suggests that oxytocin has a key role in social attachment and affiliation Risk experiment: z = 0.620, P = 0.535 for calmness; z = -0.841, P = 0.400 for mood; n = 31; two-sided Wilcoxon signed rank tests.) This provides further support for our conclusion that the effect of oxytocin on human trust is not caused by non-specific, psychotropic effects of oxytocin Specifically, all the indirect effects of oxytocin on the state of a subject, such as possible effects on mood or calmness, would be present in both the trust and the risk experiment Specifically, investors have to make the first step; they have to ‘approach’ the trustee by transferring money Subjects given oxytocin seem better able to overcome trust obstacles such as betrayal aversion Substantial evidence exists to show that humans are averse to such risks  The fact that oxytocin affects subjects approach or trust behaviour, but not their degree of reciprocity, is in agreement with animal studies The higher transfers in the trust experiment can be reconciled with betrayal aversion if one acknowledges that investors behaviour in the trust experiment is also likely to be driven by the motive to increase the available amount for distribution between the two players  The investor is therefore caught in a dilemma: if he trusts and the trustee shares, the investor increases his payoff, but he is also subject to the risk that the trustee will abuse this trust The investors average transfer is 17% higher in the oxytocin group (Mann-Whitney U -test; z = -1.897, P = 0.029, one-sided), and the median transfer in the oxytocin group is 10 MU, compared to a median of only 8 MU for subjects in the placebo group The investors have to overcome their aversion against these risks in order to trust, allowing us to address the question of whether oxytocin modulates this trusting behaviour in humans The median transfer is 8 MU and the average transfer is 7.5 MU in both groups (Mann-Whitney U -test; z = 0.022, P = 0.983; two-sided test, n = 31 in oxytocin group, n = 30 in placebo group) The random mechanism in the risk experiment replicated the trustees decisions in the trust experiment The risk experiment constitutes a powerful control for the effects of oxytocin on trusting behaviour because everything is kept constant relative to the trust experiment, except that the investors risk in the risk experiment is not generated through a social interaction The trustee is then informed about the investors transfer and can honour the investors trust by sharing the monetary increase generated by the investors transfer The ubiquity of trusting behaviour is perhaps one of the distinguishing features of the human species There is substantial evidence that oxytocin promotes prosocial approach behaviour by inhibiting defensive behaviours , but there is no evidence that oxytocin affects reciprocity in animals There were no statistical differences in the levels of mood and calmness before and after the administration of oxytocin in either the trust or the risk experiment. (Trust experiment: z = -1.541, P = 0.123 for calmness; z = 1.452, P = 0.146 for mood; n = 29 Therefore, the differences between the oxytocin group in the trust experiment and the oxytocin group in the risk experiment are highly significant (Mann-Whitney U -test; z = -2.563, P = 0.010, two-sided), suggesting that oxytocin specifically affects trust in interpersonal interactions Therefore, the investors faced exactly the same risk as in the trust experiment (see Methods); however, their transfer decisions were not embedded in a social interaction because there were no trustees in the risk experiment Therefore, these potential indirect effects of oxytocin cannot be responsible for the effect of oxytocin on trusting behaviour These differences in the distribution of trust result in higher average and median trust levels for subjects given oxytocin ( Table 1 ) This explanation is consistent with the differing effects of oxytocin across the trust and the risk experiments, and is further supported by the fact that investors faced a considerable betrayal risk This finding is illustrated by a comparison of Figs 2a and b , which show that only 10% of the subjects with oxytocin choose the maximal transfer level in the risk experiment, whereas 45% choose the maximal level in the trust experiment This implies that oxytocin should affect not only the prosocial behaviour of the investors but also that of the trustees This raises the question of whether oxytocin helps humans to overcome a general aversion against risks or whether oxytocin specifically affects trusting behaviour in social interactions Thus, if the investor gives money to the trustee and the latter shares the proceeds of the transfer, both players end up with a higher monetary payoff Thus, our results might lead to fertile research on the role of oxytocin in several mental health disorders with major public health significance. Thus, oxytocin does not increase the general inclination to behave prosocially Thus, oxytocin increases the investors transfer levels in the trust experiment but not in the risk experiment Thus, oxytocin seems to permit animals to overcome their natural avoidance of proximity and thereby facilitates approach behaviour Thus, the investors given oxytocin show more trusting behaviour but do not hold significantly different beliefs about the trustworthiness of others Thus, the psychology of trust is important for investors, whereas the psychology of strong reciprocity is relevant for trustees We analysed the effect of exogenously administered oxytocin on individuals decisions in a trust game with real monetary stakes  We find that intranasal administration of oxytocin causes a substantial increase in trusting behaviour We hypothesize that the differing effect of oxytocin on the behaviour of investors and trustees is related to the fact that investors and trustees face rather different situations We used a double-blind study design to compare trusting behaviour in a group of subjects that received a single dose of intranasal oxytocin with that of subjects in a control group that received placebo We used a questionnaire suitable for repeated measures within short periods of time, one that is widely used in neuropharmacological studies in humans and correlates with physiological measures  We would therefore predict that those trustees who are given oxytocin should make higher back transfers at any given level than the trustees who received placebo What mechanisms might be involved in generating the effect of oxytocin on trusting behaviour? One possibility is that oxytocin causes a general increase in prosocial inclinations
 After the wave passed, villagers reported that areas with more mangrove cover suffered less damage Already, there are signs that governments and developers are returning to their old ways And the islanders have been so devastated by these disasters that — understandably — planting trees is not their first priority. “Many of the people are still traumatized,” Suryadiputra says And the paid contractors had no reason to continue caring for the young, fragile shoots And the projects have tended to ignore, alienate or exploit the people living closest to the mangrove forests. “Local communities must have more of a say in the control, use and protection of mangroves,” says Ed Barbier, an environmental economist at the University of Wyoming in Laramie Before the disaster, Wetlands International estimated that Simeulue Island had at least 1,000 hectares of mangrove swamps Boom and bust The problem, says Alfredo Quarto, director of the Mangrove Action Project, Port Angeles, Washington, is that “mangrove areas are remote, usually public lands, available to lease by corrupt officials” Building the nursery brought the village together, as entire families pitched in to help But rebuilding after the tsunami has been more challenging, Suryadiputra says, and covers a wider area But the devastation wrought by the tsunami has inspired governments to try to restore these ecosystems, which environmental scientists and economists have long said are natural defences against storm damage But the group has also begun work on Simeulue Island, 300 km southwest of Banda Aceh, which was hammered by the tsunami and its aftershocks But the tsunami — plus another earthquake that followed this March — lifted parts of the island by 1–2 metres, cutting off mangroves and coral reefs from the tidal waters that sustain them Getting it right is slower and more difficult, say the groups with long-term experience of mangrove restoration in Asia Healthy mangroves are nurseries for fish, crabs and other creatures that mature in the ocean If 70% of the seedlings are still alive after five years, the village keeps the money; otherwise it must repay part of the loan In India, the government of the southern state of Kerala has pledged $8 million to supplement an existing programme to restore mangroves destroyed by cyclones In Indonesia, despite official support for buffer zones, shrimp farms destroyed in the tsunami are being rebuilt without setting aside space for trees In many cases, local people are unhappy about these new developments, but they lack influence with government officials In return, the programme provides support staff and a loan that the villagers can use to start businesses, such as chicken and goat farms In some cases, says Parish, the Indonesian government has given newly damaged coastal land to developers, to create new shrimp farms. “These are strong pressures, as they were before,” says Parish In the five countries hit hardest by the tsunami, development eliminated 1.5 million hectares of mangroves between 1980 and 2000 — 26% of the regions mangrove cover  In three states in India, where Selvam works, 33 villages have worked with forestry officials to restore 1,500 hectares of mangroves since 1993 Indonesia has pledged $22 million for mangroves, and has already planted 300,000 seedlings near the city of Banda Aceh International donor groups also offered money and seedlings, and several meetings were set up to coordinate the restoration projects Kajhu village is in the province of Aceh on Sumatra — the area most brutally devastated by last years tsunami Local and international officials gave speeches, and some of the villagers performed a traditional dance ceremony Malaysia has promised $25 million to replace 4,000 hectares of mangroves lost to the storm and to development Mangrove deforestation compounded the effects of the tsunami Mangrove restoration is notoriously difficult, however, and these replanting projects face huge challenges Mangroves have been disappearing from southeast Asian coastlines for decades, replaced by vast shrimp farms and tourist resorts Nyoman Suryadiputra, a wetlands ecologist and technical director of WIIP, says this encourages villagers both to plant and care for the forests, making them more likely to survive Of the approximately 300,000 killed on 26 December 2004, more than 130,000 were from Aceh On a cloudy, humid day last month, 250 people gathered near the beach in the small Indonesian village of Kajhu Otherwise, future restoration projects will suffer the same fate as past ones — and fail to have any lasting results Past restoration projects have planted the wrong species in the wrong places, scientists say Poor fishers and farmers rarely have any land rights and cannot prevent mangroves being cleared for shrimp ponds. “The people who enforce the laws dont live in these areas and can be convinced by someone with money to turn their backs on the destruction,” Quarto says S Shifting ground How likely are these projects to succeed? Many of the seedlings planted on the Aceh coast earlier this year have already died, because they were planted too soon and in the wrong places, say scientists working in the region. “Sometimes the site selection was not so good, and there was still debris from the tsunami washing up that destroyed the seedlings,” says Faizal Parish, an ecologist and director of the Global Environment Centre in Selangor, Malaysia Shrimp farms create temporary jobs, but the boom-and-bust cycle hurts villages more than it helps So eliminating the mangroves cuts off a source of food and income So far, three-quarters of the seedlings have survived, Selvam says, double that of other techniques So far, villagers have replanted 350 hectares of land along 3.5 kilometres of Indonesian coast through these arrangements So the group first had to convince Simeulue residents that planting trees would restore some of their lost livelihoods Some of the groups current activities focus on the Aceh coast, including the project in Kajhu Swaminathan Research Foundation in Chennai, India. “It used to take us years to convince people that mangroves are worth saving,” Selvam says. “Now it is much easier, because people see them as a bioshield.”  Many southeast Asian governments have now pledged their support for mangrove restoration The authors caution that vegetation does not prevent the worst devastation, but they see a protective role for plants in reducing damage from regular storms, such as the typhoons that batter the Philippines every year The buckets held tiny mangrove and Casuarina pine seedlings, which the villagers tucked into shallow trenches they dug at the waters edge The communities saw the benefits of their work when the trees buffered the impact of the tsunami, says Selvam, who is trying to enlist new villages in restoration projects The group coordinates replanting projects by negotiating agreements with villages The Kajhu ceremony was a small act of hope in the wake of tragedy The project is one of many across southeast Asia that aims to replace mangrove forests destroyed by the tsunami and by human industry The question is whether commitments to restoration will last longer than one year after the tsunami The replanting marked the launch of the Green Coast Programme, a plan drawn up by non-profit groups, international donors and the Indonesian government The result in Indonesia, notes Parish, is that “the initial sensible plan to have some sort of greenbelt along the coast has not advanced as much as it could have.”  The next storm in Kajhu is unlikely to be a tsunami, but without healthy mangroves it could still be devastating. The seedlings are now about a metre tall and have just been planted, Suryadiputra says. “Its been a really big challenge, and I dont want to say our approach will be successful,” he says. “We want to do this properly from the beginning, and thats not easy.”  Gathering storm The time and effort involved in community-based programmes makes them harder to execute, but those with experience say approaches that involve local people are the only ones that make sense The Thai government has expressed its support for mangrove restoration and coastal rebuilding The villagers commit to plant a certain number of seedlings they collect from the wild The Wetlands International Indonesia Programme (WIIP), based in Bogor, Java, has been running projects since 1998 Then, everyone carried shovels and buckets along a gravel road past a flattened area of the beach littered with broken tree stumps These anecdotal reports have been bolstered by analysis of satellite images taken before and after the tsunami These findings supported the locals perceptions that mangroves are natural barriers, says Vaithilingam Selvam of the M This is the situation facing poor communities everywhere, not just in areas hit by the tsunami, says Jurgenne Primavera, a marine biologist at the Southeast Asian Fisheries Development Center in Iloilo, the Philippines. “The people who are at risk are poor, so they cant lobby the government to put protective greenbelts in the places where they live,” says Primavera This October, international researchers coordinated by the Nordic Agency for Development and Ecology in Copenhagen, Denmark, reported that areas with mangrove or tree cover were significantly less likely to have experienced major tsunami damage  This summer, staff member Eko Budi Priyanto persuaded villagers in Langi, on Simeulue Island, to plant a nursery of 5,000 Calophyllum tree seedlings grown from seeds they collected on the beach When the farms collapse, due to disease or contamination, a wealthy owner can move on to another stretch of virgin coast, leaving a useless waste site behind 
 50 YEARS AGO “Use and abuse of English in science” — Another problem which is causing increasing concern — to printers as well as to editors — is the frequent and indiscriminate use of abbreviations in the form of a single capital letter, or a group of capitals, to represent the name of a substance, or perhaps even an adjective or adverb From Nature 2 November 1905. From Nature 5 November 1955. 100 YEARS AGO A return has been published, we learn from the Pioneer Mail , regarding the measures adopted for the extermination of wild animals and venomous snakes during the year 1904 Indeed the time does not seem far away when high-school pupils will have to learn a new table of symbols apart from those atomic It is reported that in the Seoul district of the Central Provinces anti-venin was used with success in two cases, and the question of introducing more generally the treatment of snake-bite by potassium permanganate is under the consideration of the local Government The mortality from snake-bite rose from 21,827 to 21,880 The most notable decrease occurred in Madras and the United Provinces, namely, from 438 and 404 in 1903 to 237 and 193 in 1904 respectively.. The printer is concerned because a page of text sprinkled with capital letters is not pleasing in appearance; and like other craftsmen, he feels that his efforts are being frustrated.. The total mortality among human beings reported to have been caused by wild animals was 2157, against 2749 in 1903 The total number of snakes killed was 65,378 The use of abbreviations, especially initial letters, is now becoming so fashionable among scientists that one suspects authors sometimes go out of their way to use them. ... this fashion may, if not checked, defeat its own ends and produce a veritable ‘Tower of Babel’
 Collecting these data and turning them into model parameters, such as how many people one person might contact in a certain time period, was harder than writing the programs code, Ferguson says Ferguson says that the results argue for improving disease monitoring, creating international stockpiles of antiviral drugs and vaccines, and planning detailed strategies for a rapid response to suspicious clusters of human cases For his latest research, Neil Ferguson had to face an event that could spell disaster for the world How fast would the flu spread? What, if anything, could be done to stop a pandemic? To find out, Ferguson, with fellow epidemiologist Don Burke at Johns Hopkins Bloomberg School of Public Health, and their colleagues, built the largest computer simulation of infectious-disease epidemics yet published In fact, the team hooked up ten high-powered computers in parallel, but even then the final runs took more than a month of computer time Making up for this shortfall was an important part of the teams research Meanwhile, Ferguson and his team are working on a model of what would happen if containment failed and a pandemic spread from Asia to Europe and the United States. Once they had the data and the computer model, Ferguson and his team set out to make sure they covered all possibilities The advanced online publication of the paper has already helped prompt Roche to stockpile drugs to enable the World Health Organization to tackle flu outbreaks using similar methods to those modelled by Fergusons group The epidemiologist at Imperial College London wanted to know what would happen if the avian influenza virus H5N1 mutated so that it could pass readily from human to human The model simulated an outbreak starting in Thailand, so the first thing the team needed was detailed data on that countrys population. “The sizes and locations of households, workplaces and schools, and how far people travel between each are key,” Ferguson explains The outcome (see page 209 ) was worth the wait The process was further complicated by a lack of background information. “We had to make some assumptions about how a new influenza virus would behave,” says Ferguson. “These had to be based on what was seen in past influenza epidemics and pandemics.” But that sort of information proved hard to come by. “Less detailed statistical work had been done on past pandemics than we hoped,” Ferguson says The team found that on average one person infected with a new pandemic virus might infect 1.8 other people, that people are likely to be highly infectious for only 1 or 2 days after they develop symptoms and, most importantly, that we have a chance of preventing a pandemic if we can detect the first few cases and act fast enough They used ‘sensitivity analysis’, which involves running the model over and over again using different assumptions about unknown parameters, such as incubation times, and looking at how the outcome changes This meant running the model hundreds of thousands of times To do these runs quickly, the model needed to be coded efficiently, and required computers with huge amounts of memory — 20 times that found on a typical PC
 And it said that, so far, the risk of cancer seems unique to X-SCID, and may not apply to ADA-SCID At the meeting, oncologist Utpal Dave of the National Cancer Institute described unpublished research suggesting that some of the risk of cancer in the X-SCID trials was related to that form of the disease, and might not appear in other variants of SCID But he found no data to suggest a similar risk for ADA-SCID. “Although not conclusive, these are the first data that suggest the gene may play a role in these cancers,” says Daniel Salomon, a molecular biologist at the Scripps Research Institute in La Jolla, California But the US panel said that US trials on X-SCID could proceed on patients who have failed to respond to other treatments or are likely to do so Daves data linked the gene that is missing in children with X-SCID to cancer in mice He theorized that the method used in the French trial to replace this gene could be increasing the childrens risk of cancer On 4 March, an advisory meeting in Rockville, Maryland, heard evidence that the cancer risk exposed by the French trial may be specific to one form of the disease, known as X-linked SCID The advisory panel recommended that a gene-therapy trial for another variant of the disease, called ADA-SCID, should be allowed to proceed The French trial has so far successfully treated six children with X-linked SCID, but three other patients have since developed cancer, and one of these has died The leader of the French trial, Alain Fischer of the Necker Hospital for Sick Children in Paris, has already said that he will not continue his trial until he has made changes to the methods he uses to deliver the therapeutic gene to children with X-SCID The third of the cancer cases was reported in January, and prompted the US Food and Drug Administration to suspend three US gene-therapy trials on SCID (see Nature 433 , 561 ; 2005 10.1038/433561a ) There is one planned US trial in ADA-SCID, led by Donald Kohn of the Childrens Hospital Los Angeles. “Im glad they agreed that ADA clearly has a safer record to date,” Kohn says. Washington Gene-therapy trials for children suffering from severe combined immunodeficiency disease (SCID) are set to resume in the United States, despite another cancer case in a French trial of the technique
 A few weeks later I was back in the United States, teaching an undergraduate geophysics class Akira Suzuki of Japans Akita University School of Medicine and his fellow authors also note that people suffering from hereditary disorders such as Cowden disease — which make them susceptible to tumours — carry mutated copies of PTEN  And it seems that Sar1p is involved from start to finish, because buds formed in the presence of mutant Sar1p are unable to pinch off, remaining attached to the membrane layer Animal behavoiour: Chicken little Curr Animals lacking one copy of the gene showed unregulated expansion of vessels around tumours and faster cancer growth than controls As I filled the blackboard with equations for heat transport in Earths interior, I dutifully crossed out the radiative terms as negligible Astronomers from the University of Delaware in Newark have used the Hubble Space Telescope to collect the first ultraviolet spectrum of a brown dwarf Astronomy: Growing dwarf Astrophys Biol. 15, R620–R621 (2005) Migrating birds are known to use the Earths magnetic field to orient themselves, but researchers have struggled to condition birds to respond to fields in the lab Brown dwarfs often seem like the runts of the astronomical litter, being too small to fuse hydrogen But how are the vesicles sculpted? Researchers led by Randy Schekman at the University of California, Berkeley, have revealed that a protein called Sar1p initiates membrane curving by poking a helical arm into the membrane But observations now confirm that they grow like proper stars Cancer: Vessels take off Genes Dev. doi:10.1101/gad.1308805 (2005) The tumour suppressor gene PTEN governs the formation of blood vessels by influencing vascular growth factors, suggests a study in mice Cell Biology: Bubble wrap Cell 122, 605–617 (2005) Within cells, many proteins are transported inside bubble-like lipid sacs called vesicles Cell Signalling: Second signal Neuron 47, 515–528 (2005) One way that cells communicate is through receptor proteins called receptor tyrosine kinases Cristina Gutierrez from the Pasteur Institute in Paris and her colleagues isolated rare strains of tubercle bacilli from patients in east Africa Ecology: Richer soil Science 309, 1387–1390 (2005) The average gram of unpolluted soil contains a million different bacterial species, according to a reanalysis of existing data Eigens paradox points out that long genomes need complex enzymes to replicate themselves reliably — and questions whether the code for such enzymes could fit within these genomes Evolution: Margin for error Nature Genet. doi:10.1038/ng1621 (2005) A classic problem in biology, concerning the origin of life, may benefit from a relaxed view Genetic comparison with Mycobacterium tuberculosis , the agent responsible for most tuberculosis cases today, revealed that a common ancestor existed an estimated 3 million years ago He was rhapsodizing about the translucent, blue crystals he had formed by squeezing olivine — a major constituent of Earths mantle — to the pressures found deep beneath the surface However, a team led by Rüdiger Klein at the Max Planck Institute of Neurobiology in Martinsried, Germany, has shown that signalling by receptors called Ephs — which guide axon growth — is not that simple If the arm is removed from the protein, budding never begins In September 1999, after a long day at a conference, I was sharing a bottle of wine with Joe Smyth on the shore of Lake Maggiore in northern Italy It also calculates that pollution with toxic metals wipes out 99.9% of bacterial species, despite an unchanged cell count J. 630, L89–L91 (2005) Joe had measured the absorption spectra of his beautiful blue crystal — a hydrous ringwoodite — as it was squeezed between two diamonds to the pressure found 645 km down (H Journal club Craig Bina Northwestern University, Evanston, Illinois A geophysicist revises his heat-flow notes by the light of a deep blue crystal Keppler and J Lett . 87, 083106 (2005) A diamond material that has been assembled from spherical carbon molecules (C 60 ) is denser and harder than the real thing, report Natalia Dubrovinskaia from the University of Bayreuth in Germany and her colleagues Materials: Diamond geezers Appl Microbiology: Ancient disease PLoS Pathogens 1, 5 (2005) Tuberculosis may have affected early hominids, according to a genetic analysis that extends the pathogens family tree Mineral. 1209–1212; 2005) Nanotechnology: Drop by drop Nature Mater. doi: 10.1038/1455 (2005) Demonstrating exceptional chemical wizardry, a team of European researchers has harnessed light-powered molecular motion to drive a droplet of liquid up a sloping surface Not all the consequences are clear, but one thing is certain: Im revising my lecture notes before classes begin. Now a team led by Rafael Freire from the University of New England in Armidale, Australia, has achieved this in an unlikely species: the domestic hen Now Eörs Szathmáry of the Collegium Budapest in Hungary and his colleagues redefine what consitutes a ‘reliable’ copy by mapping the effect of mutations — or mistakes — in RNA molecules called ribozymes Past calculations assumed that all species were equally common Phys Previous estimates put the figure at 10,000 R Sar1p then interacts with other proteins that stabilize the budding vesicle and capture its cargo Smyth Am So, illuminating the front edge of a droplet drags it forward The comparison also showed that genetic recombination had occurred between the diverging strains The direction of a local magnetic field was shown to influence the direction in which a chick started its search over a series of trials The material is 0.2–0.4% more dense than natural diamond, and tests suggest it could form longer-lasting coatings for precision drill bits The number of species is estimated by jumbling DNA from a sample and seeing how quickly matching sequences group together The researchers attribute their success to the use of a social stimulus, rather than the usual food, as a reward in their experiments The researchers coated the slopes surface with rotaxanes The researchers squashed the fullerene molecules together at 2,200 °C using 20 gigapascals of pressure, which is equivalent to the weight of the Titanic pressing down on an area the size of a CD The spread of a complex of strains resembling M. tuberculosis may have coincided with waves of human migration out of Africa, the researchers speculate The surprising result? The absorption of red and infrared wavelengths decreased as the pressure intensified The team designed the rotaxanes so that ultraviolet light would push the shuttle group to one end, hiding a fluoroalkane segment of the chain in the process The team genetically engineered mice to carry an altered form of an Eph called EphA4, whose kinase is permanently active The team suggests that clustering of receptors (pictured in green on the red growth cone of an axon) triggers signalling through an additional mechanism The technique could be used in lab-on-a-chip devices Their study of object 2M 1207 reveals a cold cloud of molecular hydrogen surrounding the dwarf star, and ions heated to 100,000 °C accreting on its surface There matters rested, until I picked up the July issue of the American Mineralogist , and was reminded of Joe and those crossed-out terms These bud off the membrane layers of the endoplasmic reticulum, where such proteins are made These characteristics are shared with bigger T Tauri stars, which are bright young things with less than twice the mass of the Sun These molecules consist of a chain threaded through a ring that shuttles up and down the structure They show that a ribozymes function, which is defined by its shape (or phenotype), can survive a relatively large number of mutations to its sequence (or genotype) This finding also reveals that the chickens magnetic compass has survived thousands of years of domestication This is probably because the vessels feed and sustain the developing cancer This left them with a translucent cylinder made from a jumble of diamond nanorods, each of which was less than 20 nanometres across This makes the rotaxane layer more wettable where the light is shining This means that plates heat up more quickly than we thought as they subduct into the mantle, and it affects our modelling of mantle plumes such as those that produced the volcanic islands of Hawaii This suggests that long genomes could survive much higher error rates in copying than researchers had previously thought Thus, for realistic ringwoodite, radiative heat transfer is important To reach the higher figure, the team from Los Alamos National Laboratory in New Mexico allowed for variation Typically, such receptors relay signals when a kinase enzyme that forms part of their structure is activated Unexpectedly, some aspects of neural development were still normal We have all known since the 1970s that rocks are opaque to radiation at the high pressures and temperatures of the mantle, so its contribution to heat flow is deemed unimportant Young domestic chickens were allowed to develop an attachment to a red ball and were then sent to find it
 As well as being a member of the European Parliament, I am a scientist — a population geneticist with a degree from Oxford University and a PhD from the University of Toronto — and I am critical of the theory of evolution as a scientist, with no religious connotation I believe that, as a result of media bias, there seems to be total ignorance of new scientific evidence against the theory of evolution If we have no explanations we should say so, and not claim that an unproven theory is a fact. It also includes formation of geological strata sideways rather than vertically, archaeological and palaeontological evidence that dinosaurs coexisted with humans, a major worldwide catastrophe in historical times, and so on It is the media that prefer to consider my comments as religiously inspired, rather than to report my stated position accurately No positive mutations have ever been demonstrated — adaptations to antibiotics or herbicides are equivalent to immunological adaptation to diseases, and not a creation of a new function Sir In your News story “Polish scientists fight creationism” ( Nature 443 , 890 – 891 ; 2006 doi: 10.1038/443890c ), you incorrectly state that I have called for the “inclusion of creationism in Polish biology curricula” Such evidence includes race formation (microevolution), which is not a small step in macroevolution because it is a step towards a reduction of genetic information and not towards its increase We do not know its origin, but we know it exists, can be spoiled by mutations, but never improves itself spontaneously We keep on searching for natural explanations of everything in nature We know that information exists in biology, and is transferred over generations through the DNA/RNA/protein system
 Because insulin resistance is among the earliest pathological changes in type 2 diabetes, our results show the potential of chemical biology for dissecting the molecular pathogenesis of this disease. G proteins are an important class of regulatory switches in all living systems GEF inhibitors are therefore of interest as tools for elucidating the function of these proteins and for therapeutic intervention; however, only one small molecule GEF inhibitor, brefeldin A (BFA), is currently available  Here we used an aptamer displacement screen to identify SecinH3, a small molecule antagonist of cytohesins SecinH3-treated mice show increased expression of gluconeogenic genes, reduced expression of glycolytic, fatty acid and ketone body metabolism genes in the liver, reduced liver glycogen stores, and a compensatory increase in plasma insulin The application of SecinH3 in human liver cells showed that insulin-receptor-complex-associated cytohesins are required for insulin signalling The cytohesins are a class of BFA-resistant small GEFs for ADP-ribosylation factors (ARFs), which regulate cytoskeletal organization , integrin activation or integrin signalling  They are activated by guanine nucleotide exchange factors (GEFs), which facilitate the exchange of GDP for GTP  This activity makes GEFs attractive targets for modulating disease-relevant G-protein-controlled signalling networks  Thus, cytohesin inhibition results in hepatic insulin resistance All data sets passed the Kolmogorov and Smirnov test for gaussian distribution Differences of means were considered significant at a significance level of 0.05. Methods Details of aptamer labelling and the aptamer displacement screen, determination of K d s by isothermal titration calorimetry, GDP/GTP exchange assays, the ARF6 activation assay, mice, quantification of Igfbp1 expression in cell culture, quantification of gene expression in mouse liver, siRNA transfections, immunoblotting and immunoprecipitation, determination of physiological parameters, synthesis and characterization of compounds, and the characterization of the cytohesin-3 antibody are provided in Supplementary Information  Statistical analyses were performed by the two-tailed t -test using the InStat program (GraphPad) Statistics Results are given as the mean ± s.d Where the standard deviations of the compared pairs were different, the Welch correction was applied to the t -test Accordingly, 3-hydoxybutyrate was increased in the serum of SecinH3-treated mice ( Fig. 3g ) All available biochemical and gene expression data therefore converge on the view that cytohesins are fundamentally involved in insulin signalling and that their impairment results in physiological alterations that are characteristic of hepatic insulin resistance All cytohesins, including the mouse and Drosophila homologues of cytohesin-3, exhibited half-maximal inhibitory concentrations (IC 50 values) between 2.4 and 5.6 μM ( Table 1 ), indicating that H3 recognizes an evolutionarily conserved region An ARF6-specific siRNA also inhibited the insulin effect whereas an ARF1-specific siRNA did not (see Supplementary Fig. 7 ) Analysis of liver glycogen levels revealed that the compound also inhibited insulin-dependent glycogen synthesis ( Fig. 3b ) Aptamer displacement screens demand small molecules of high initial potency, leading to effective and specific inhibitors that can be used as drug leads or tools in chemical biology. Because mutations of these genes have not been described for most patients suffering from type 2 diabetes , additional factors seem to be involved Because of its inhibitory profile, we named the new compound class Secins (for Sec7 inhibitors) Besides Igfbp1 , we analysed hepatic expression of the genes for pyruvate carboxykinase-1 and -2 ( Pck1 , Pck2 ), fructose-1,6-bisphosphatase 2 ( Fbp2 ) and glucose-6-phosphatase ( G6pc ), which are involved in gluconeogenesis, and the glycolytic enzymes glucokinase ( Gck ), its regulator ( Gckr ), pyruvate kinase ( Pklr ), and hexokinase 2 ( Hk2 ) Co-immunoprecipitation studies revealed insulin-dependent interactions of cyh2, cyh3, and ARF6 with the insulin receptor–IRS1 complex, which were reduced in the presence of SecinH3 ( Fig. 2e ) Compared to mice fed the same chow without SecinH3, the expression levels of the insulin-repressed gluconeogenic genes were elevated (green in Fig. 3a ), whereas the insulin-induced glycolytic genes were reduced (red in Fig. 3a ) Consistently, insulin-stimulated translocation of ARF6 to the plasma membrane was also inhibited by SecinH3 (see Supplementary Fig. 5 ) Cytohesins are multi-domain proteins in which a Sec7 domain bears the GEF activity D5, a structurally related compound ( Fig. 1a , right) that was inactive in the aptamer displacement and GDP/GTP exchange assays (see Supplementary Fig. 1b ; Table 1 ) did not affect insulin-dependent levels of IGFBP1 mRNA ( Fig. 2a ) Enhanced β-oxidation due to elevated Cpt1a and Hadha levels, which leads to increased generation of acetyl-CoA together with reduced acetoacetate consumption by Aacs, should raise the levels of ketone bodies Expression of IGFBP1 is controlled by insulin acting through the forkhead box transcription factors FoxO1A and FoxO3A Finally, SecinH3 had no direct effect on various kinases, including those involved in insulin signalling ( Supplementary Table 1 ) For EFA6–Sec7 and Gea2–Sec7, a large GEF from yeast, the IC 50 s were 18- and 12-fold higher, respectively Four different but highly homologous cytohesins are known in mammals, whereas only one, the cytohesin homologue steppke, exists in flies From a diverse library of synthetic chemicals, we identified a series of 1,2,4-triazole derivatives as initial hits and selected the most promising compound, H3 ( Fig. 1a , left), for synthesis and further studies (see Supplementary Figs 1, 2 ) Furthermore, we show here how to translate information stored within an aptamer into a small molecule H3 bound to the Sec7 domains of human cytohesins-1–3 with dissociation constants ( K d values) between 200 and 250 nM ( Table 1 ) H3e, H3ip and H3bio, in which substituent R 1 is increased (see Supplementary Fig. 2 ), showed gradually decreased Sec7 affinity However, the molecular mechanism that leads to impaired insulin sensitivity is poorly understood However, the next step, activation of IRS1 by its phosphorylation, was inhibited by SecinH3 (see Supplementary Fig. 11 ) In accordance with the reduced Fas expression, serum triglycerides ( Fig. 3e ) and non-esterified fatty acids ( Fig. 3f ) were reduced In summary, the effects of the cytohesin inhibitor SecinH3 on insulin signalling and gene expression in the liver, and the resulting physiological alterations, correspond to the pathological changes seen in mice with a liver-specific insulin receptor knockout (see Supplementary Table 2 ), indicating that not only are cytohesins required for insulin signalling in the liver, but their dysfunction also contributes to the pathogenesis of hepatic insulin resistance In summary, these data show that SecinH3 is a Sec7-specific GEF inhibitor with preference for the small GEFs of the cytohesin family Insulin resistance is an important hallmark of the pre-clinical stages of type 2 diabetes; organisms compensate for this by increasing insulin secretion to maintain blood glucose at physiological levels Insulin resistance is considered to have a causative role in the pathogenesis of type 2 diabetes  Insulin stimulation increased the level of ARF6–GTP that was pulled down with GGA3, which was reduced in SecinH3-treated cells but remained unaffected by D5 ( Fig. 2b ) Insulin-stimulated Akt phosphorylation was also inhibited in SecinH3-treated mice (see Supplementary Fig. 13 ) Knockout of either the insulin receptor or IRS-2 (refs 27 , 28 ), or the liver-specific expression of a constitutively active form of FoxO1 (ref. 29 ) in transgenic mice, results in hepatic insulin resistance Liquid chromatography–mass spectrometry analysis verified that livers from SecinH3-fed mice contained the unaltered compound (see Supplementary Fig. 12 ; method is described in detail in Supplementary Information and Nature Protocols doi: 10.1038/nprot.2006.414) Metabolic insulin signalling in the target cell is initiated by insulin binding to the insulin receptor, which undergoes autophosphorylation on cytoplasmic tyrosine residues Morphological analysis of HepG2 cells transfected with enhanced green fluorescent protein (EGFP)-tagged FoxO1A showed that the insulin-induced exclusion of FoxO1A from the nucleus was completely prevented by SecinH3 (see Supplementary Fig. 9 ) Neither autophosphorylation of the insulin receptor nor its density on the HepG2 cell surface was affected by SecinH3 (see Supplementary Fig. 10 ), showing that cytohesins act after receptor activation Our data indicate that cytohesins might be one of these factors and that their function might be crucial for regulating the sensitivity of insulin-responsive tissues Quantitative PCR (qPCR) and western blotting confirmed the specificity of siRNAs for their respective target mRNAs (see Supplementary Fig. 6 ) SecinH3 almost completely blocked the insulin-dependent transcriptional repression of IGFBP1 ( Fig. 2a ) with an IC 50 of 2.2 μM (see Supplementary Fig. 4 ; see Supplementary Information and Nature Protocols doi: 10.1038/nprot.2006.413 for details of methods) SecinH3 also inhibited the insulin-induced expression of the genes for fatty acid synthase ( Fasn ) and acetoacetyl-CoA synthetase ( Aacs ), which are involved in triglyceride synthesis and ketone body metabolism, respectively ( Fig. 3a ) So far, no cytohesin knockout mouse has been described, but flies lacking steppke show reduced growth , suggesting that it is involved in insulin signalling The binding of IRS1 to the insulin receptor was also inhibited by SecinH3, indicating that the cytohesin–ARF6 complex facilitates the formation of the insulin receptor–IRS1 complex The CDC25-like domain of the ras-GEF Son of sevenless (Sos) was not bound The expression of the genes for two key enzymes of mitochondrial β-oxidation, carnitine palmitoyltransferase 1a ( Cpt1a ) and hydroxyacyl-CoA dehydrogenase ( Hadha ), both of which are repressed by insulin, was increased in the SecinH3-treated mice ( Fig. 3a ) The GEF activity of Sos was unaffected The only known small GEF Sec7-domain inhibitor is the RNA aptamer M69, which represses guanine nucleotide exchange in vitro and reduces T-cell adhesion  The phosphotyrosines of pIRS serve as binding sites for phosphatidylinositol-3-OH kinase (PI(3)K), which then activates its downstream targets, including Akt  The Sec7 domain of EFA6, an ARF6-GEF that does not belong to the cytohesin family, was bound about 30-fold more weakly, despite its 32% identity and 46% similarity with the cytohesin-1 Sec7 domain Thereby, chemical space can be explored in a rapid, focused, and modular manner, by indirectly taking advantage of the highest molecular diversity currently amenable to screening, namely that of up to 10 16 different nucleic acid sequences These results show that cyh2 and cyh3 are fundamentally involved in the earliest steps of insulin signalling This is followed by binding and phosphorylation of specific tyrosines in the insulin receptor substrate (IRS) proteins To analyse whether SecinH3 affects ARF activation by cytohesins in living cells we used immobilized GGA3 (Golgi-associated, gamma adaptin ear containing, ARF binding protein 3) to capture activated, GTP-bound ARF (see Supplementary Methods and Nature Protocols doi: 10.1038/nprot.2006.412 for detailed methods) To assess the compound’s inhibitory potential, guanine nucleotide exchange assays were performed with ARF1 and full-length cytohesins  To confirm that SecinH3 affects insulin signalling by inhibition of cytohesins, we knocked down cytohesins 1–3 (cyh1–3), the only expressed cytohesins in HepG2 cells (data not shown), by RNA interference and analysed gene expression ( Fig. 2c ) To test whether SecinH3 maintained its in vitro preference for cytohesins in living cells, we monitored its effect on the structural integrity of the Golgi apparatus, which depends on the function of BFA-sensitive large GEFs  Treatment with 20 μM BFA completely disrupted Golgi integrity ( Fig. 1b , panel 2), whereas treatment with SecinH3 caused a minor effect only at or beyond 50 μM, consistent with this concentration being close to the IC 50 for the large GEF Gea2 ( Fig. 1b , panels 3, 4) Unlike the large (∼200 kDa) ARF-GEFs, the small ones (∼47 kDa) are insensitive to BFA  Upon insulin stimulation, protein kinase B (PKB/Akt) is activated by phosphorylation and translocates to the nucleus, where it phosphorylates FoxO proteins leading to their nuclear exclusion and, thus, reduction of target gene expression  Using M69 and the cytohesin-1 Sec7 domain, we established an assay based on fluorescence polarization to identify cytohesin-specific small molecules that displace the aptamer from its target and adopt its inhibitory activity (see Supplementary Fig. 1a ) We found significantly increased levels of serum insulin with slightly elevated glucose concentrations in SecinH3-treated mice ( Fig. 3c, d ) We found that SecinH3 inhibited the insulin-dependent phosphorylation of Akt and FoxO1A in a concentration-dependent manner ( Fig. 2d ; Supplementary Fig. 8 ) We next investigated the involvement of cytohesins in insulin signalling in vivo , by feeding mice chow containing SecinH3 We propose that the insulin-dependent physical association of the cytohesin–ARF6 complex with the insulin receptor–IRS complex is required for the phosphorylation of IRS and thus for the activation of the insulin signalling cascade immediately at the insulin receptor We tested the requirement for mammalian cytohesins in insulin signalling by monitoring the transcription of the prototypic insulin-regulated gene for insulin-like growth factor binding protein 1 ( IGFBP1 ) in the human liver cell line HepG2 Whereas the knock-down of cyh1 did not prevent the insulin-dependent repression of IGFBP1 expression, knockdown of cyh3 inhibited the insulin effect to a similar level as with SecinH3, and knockdown of cyh2 had an even stronger effect
 A key breakthrough was being able to control when and where the cancer-causing mutations occurred . “Were getting the right combination of mutations at the right place at the right time,” says Jacks, who now heads his own lab at the Massachusetts Institute of Technology in Cambridge Adding human cells into the mix is one approach After all, there is only so much one can learn from studying cells in a lab dish Although some genetically engineered mice have come a long way since the early days, many researchers concede that other kinds of mouse model remain especially problematic Although virtually every successful cancer drug on the market will have undergone xenograft testing, many more that show positive results in mice have had little or no effect on humans, possibly because the human tumours are growing in a foreign environment. “In many cases, the mouse is just a container for the human cells,” says Roberto Weinmann, the director of oncology at pharmaceutical company Bristol-Myers Squibb in Princeton, New Jersey And now both academia and industry are keen to put these mice to the test and see whether they can better predict how humans will respond to new drug compounds. “It took a while to make mouse models that accurately reflect human diseases but now that we have them, now is the time to use them,” says David Tuveson of the University of Pennsylvania in Philadelphia And, as mammals, they share enough biology with us to make some useful comparisons possible Another way to make mice respond to drugs in a more human-like fashion is to give the mouse human genes As hundreds of mice are required for screening, xenografts are quicker and cheaper Assisted by the Internet and better bioinformatics tools, there are large-scale efforts to collect and catalogue data on a wide range of human tumours. newsad; Howard Fine of the NCI is leading one such initiative But despite having broad similarities, mice have significant differences that can scupper cancer experiments ( see graphic ) But human cells are likely to behave differently in a mouse than in a human body, making results hard to interpret But industry and the scientific community shouldnt expect too much from the humble rodent. “Mice are valuable but they are, after all, still mice,” says Fine. “The best study subject will always be the human.” (See box ) But interactions between tumour cells and their neighbours are often lost in xenografts, because proteins from one species cant interact with their counterparts in the host. “The consequence is that the tumour often looks nothing like that seen in the patients,” says Weinberg But now researchers are tackling the process in a systematic and comprehensive fashion But now they have to show what they are worth,” says Anton Berns, of the Netherlands Cancer Institute in Amsterdam But others can be fixed But the mice didnt get retinoblastoma But there is a limit to how far scientists can get mice to be like humans But when he saw that mutations in such genes didnt cause the same kind of cancer in mice and humans, he began to ask himself why But, as the models get better, we are watching the field very carefully,” adds Richard Gaynor, vice-president of cancer research at Eli Lilly in Indianapolis But, in therapeutic terms, the real test is how well they reflect the human response to drugs Cancer is a complex, three-dimensional disease that changes, evolves and spreads through the body Combining these humanized mice with revamped mouse cancer models could be a powerful way to test drug candidates Connective tissue cells, or stromal cells, play an important role in the development of a tumour, often supplying it with the cell signals and nutrients it needs Data are correlated with each patients clinical course Different strokes Mice are still crucial for cancer research Early attempts to genetically engineer mice to develop cancer were, in retrospect, simplistic: turning a cancer-associated gene on or off in every cell in every tissue of the mouse Early signs are encouraging . “New mouse models hold a lot of promise For instance, two human enzymes CYP2D6 and CYP3A4, which together metabolize more than 70% of drugs on the market, have markedly different activities compared with their rodent equivalents  For one thing, most mouse tumours originate in different types of tissues from ours and, unlike us, their healthy cells can maintain the ends of their chromosomes, a key factor influencing which mutations tumour cells develop Foreign bodies The pharmaceutical industry has typically used xenograft models to screen new drugs He and his postdoc Tyler Jacks were trying to develop a mouse model for retinoblastoma, a childhood cancer of the retina He became aware of other examples that challenged researchers faith in how accurately mice could replicate human tumours, and has since sought to bring this to his colleagues attention . “There is a laundry list of problems with mouse models of cancer,” he says He was involved in the early work on the first human cancer-causing and cancer-suppressing genes in the early 1980s Human touch But recreating the sequence of genetic mishaps in a cluster of cells isnt necessarily enough to replicate human cancer Humanized mice such as these could help researchers tackle some fundamental questions — such as where and how cancer begins. “The problem is we dont know much about the cell-of-origin in human cancers,” says Jacks In recent years, researchers have developed tricks to genetically engineer mice, or tinker with the human cells they graft into them, that more accurately reflect cancer in humans In the future, researchers may broaden the types of human genes they add in to the mouse. “My hope is that we will be able to create mouse cells and tissues that may closely resemble human tissues,” he says In the past, clinical data have often been collected on an ad hoc basis In these, human cancer cells are injected under the skin of a mouse with a deficient immune system, to prevent rejection of the tumour Instead, they developed tumours in their pituitary glands Intellectual-property issues aside, xenografts will remain many companies model of choice for the foreseeable future It is also possible that drugs that would have worked in people failed in preclinical mouse trials, although there is no way of knowing. “Im not a naysayer who thinks we should discard valuable mouse models, thereby throwing the baby out with the bathwater,” says Weinberg. “My rallying cry is that we need to be working on this problem.” Now many researchers, Weinberg included, are doing just that, by making mouse models more faithful replicas of human cancer development It results from the loss of a gene called Rb , so the team genetically engineered mice to lack the same gene It was in 1991 that Bob Weinberg first realized he had a problem with mice Making connections One possible way to improve xenografts is to manipulate the cellular environment into which cancer cells are injected Many companies therefore are interested in the new genetically engineered mouse models. “We are in a transition,” says Giulio Draetta, head of basic cancer research at drug company Merck, based in Boston. “We are now building a substantial operation using transgenic models and are investing in licensing genetic models that currently exist as well as building our own models,” he says. “We still rely very heavily on xenografts, as do most companies Melanocytes, the pigment-producing cells that become cancerous in melanoma, are found in the outermost layer of human skin, but in mice, they are confined to hair follicles, making it harder to study the effects of UV radiation Merlino works on melanoma, which is induced by ultraviolet (UV) irradiation of the skin Merlinos team engineered mice to over-express a cell signal that causes melanocytes to be found in the outer layers of the rodents skin, as in humans Mice, easy to breed and genetically manipulate, and with a completed genome sequence, are the obvious choice for scientists wanting to pick apart these processes and test new drugs Mine of information Researchers have tackled this problem by engineering genes encoding some of the human enzymes into the mouse  Of the potential anticancer drugs that give promising results in tests on mice with cancer, only about 11% are ever approved for use in people  One of the key mouse models, especially in drug testing, involves grafting human cancer cells into mice and seeing how the resulting tumours respond to treatment Over the past decade, researchers have been able to recreate these steps more accurately Researchers are increasingly shuttling between human and mouse, using information from human data to refine mouse models and using insight from the mouse to uncover new disease processes and test predictions for clinical responses So other researchers are mining human clinical data for insights into the cancer process, then using this to inform mouse studies Some argue that a major factor preventing industry fully embracing transgenic mice are the patents associated with certain kinds of mice engineered to develop cancer, in particular the OncoMouse patents owned by chemical company DuPont, which constrains the commercial development of such mice  Some of these problems are insoluble, arising as a result of fundamental differences between the two animals Some suspect that it is the stem cells that repair and renew adult tissues (see The root of the problem, page 742 ). “Those are hard questions to get to in humans Some think the patents have deterred drug companies from embracing transgenic mouse models Studies of these humanized mice indicate they can process some drugs in a more human-like manner The aim is to perform genetic and molecular analyses of samples of human brain tumours sent to the NCI The consequence is that mouse models may be of limited value in predicting the effectiveness or toxicity of drugs in humans The driving force behind this is the considerable differences in the way that mice and humans metabolize drugs The finding shocked Weinberg. “Up until then, I had always believed that all mammals were biologically equivalent,” he says. “This planted the seeds of doubt in my mind.”  Weinberg, based at the Whitehead Institute for Biomedical Research in Cambridge, Massachusetts, is one of the pioneers of the molecular age of cancer research The latest generation of mouse models mimics the human disease process more faithfully The licensing arrangements that commercial groups need to negotiate with DuPont have made using such models “more arduous and expensive”, says Gaynor, although academics and non-profit groups can use the technology freely The physical differences between humans and mice can be a major obstacle, says Glenn Merlino of the National Cancer Institute (NCI) in Bethesda, Maryland The resulting tumours have a more human-like structure and metastasize more like human cancers do . “It gets us closest to the human situation,” says Ronald DePinho of the Dana-Farber Cancer Institute in Boston, Massachusetts, who has co-founded the company AVEO Pharmaceuticals to develop tissue-specific cancer models, including breast cancer The study is a pilot for the NCIs larger cancer Biomedical Informatics Grid, which will provide a global network for researchers to input information and access bioinformatics tools for mining cancer data The study, which currently has data for 700 tumours and will eventually contain information for 2,000 tumours, is already yielding results, says Fine, who hopes to publish the findings shortly These mice often developed tumours, but they rarely looked anything like the human cancer, as Weinberg discovered They can be ready within weeks, whereas transgenic mouse models can take months to develop tumours and are often unpredictable in where and when they develop them They went on to show that very young, but not adult mice, exposed to UV radiation develop malignant melanoma, giving strong evidence to back up previous epidemiological studies highlighting the potential dangers of sun exposure in children  This is an example of the value of mouse models — they are highly manipulable, for which there is no comparison in human,” says Jacks Weinberg is among a number of scientists who have addressed this problem by putting human connective tissue cells into mice along with the cancer cells Whats more, the resulting tumours show a different cellular structure under the microscope Whats more, the technology used to alter mouse genes took effect early in development, whereas most human tumours develop later in adult life, following a stepwise series of mutations that turn a normal cell into an invasive cancer
 And there must be openness to ideas and critical evaluation from other countries Another is the shameful lack of interest in science displayed by wealthy Arab states, in contrast to Muslim states in east Asia and Africa Another more philosophical and cultural motivation is a belief in the value of objective thinking in the midst of a maelstrom Another stimulus of our coverage is the diversity of the 57 Muslim nations that make up the Organization of the Islamic Conference (see the map on pages 20–21 ) Appointments and promotions need to be transparently based on merit Attributed to the prophet Muhammad, the words encapsulate two principles: the duty of Muslims to seek an understanding of Gods creation, and to search for knowledge beyond Islamic cultures But there is a danger of such inspiration being thwarted by currents in contemporary Islamic thought and politics Collaboration and cooperation There is no need to despair, however, and any tendency to do so should be challenged For Western scientists, working with researchers who approach sciences challenges within different cultures can only be good for science and encourage broader mutual awareness How very different from the great age of scientific study lasting from the eighth to the thirteenth centuries, when leaders encouraged science and when debate and disagreement were more highly valued If Islamists are willing to embrace ijtihad — unfettered reasoning — and critical investigation of the natural world, they could help unlock the great human potential of the Muslim world In an unfortunate contrast, across the Muslim world secular governments are giving way to more overtly religious Islamist leaderships that suppress free enquiry and critical-minded scholarship International politics is avoided as a specific topic, even though it is unavoidable as a context It is disturbing that Islamist leaderships impose such restrictions while simultaneously encouraging science It is reasonable to distrust their motivations when the originator and salesman of Pakistans nuclear technology, Abdul Qadeer Khan, highlights the right of Muslim nations to have their own nuclear capability independently of internationally agreed safeguards It needs to call on talented expatriate scientists and duly reward them Its contribution may be small amid the current turbulence, but it is all the more worth pursuing Mistrust and isolation Diversity is also apparent in the application of Islam to issues surrounding science, and indeed science itself Researchers in scientifically developed countries are further discouraged from contact because of politics, which has undermined non-political collaborations on synchrotrons and water purification, for example; because of regulations by non-Islamic states; and because of their own suspicions that collaboration is asking for trouble That history can inspire todays young Muslims towards scientific ambition The eleventh-century caliphates displayed such a spirit of engagement, and todays sultans and emirs need to foster it, seeking inspiration from both ancient and modern examples in Muslim states The goals of developed scientific nations and individual scientists within them should be to foster these components at every opportunity The intention, rather, is to survey some of the key influences and trends within Muslim states attitudes towards, and uses of, science The modern scientific world flourishes on collaboration and cooperation, wherever talent is to be found The omens seem even more adverse given the bellicose rhetoric of the president of one of his major historical clients, Iran The pursuit of collaboration creates not only opportunities but also risks for those who do it — and the international institutions that are meant to minimize those risks are weak The tension between support for science and restrictions on expression is one thread that runs through this special issue about science in Islamic countries (see page 19 ) There are contradictory views, for example about the acceptability of weapons of mass destruction, therapeutic cloning, and the compatibility of evolution by natural selection with the existence of God There has never been a greater need for the measured, evidence-based approach to problems that comes from scientific training There is much anti-Western feeling in Muslim states, and vice versa These themes emerged in an event that stimulated this issue: a meeting earlier this year organized by Nature at the Rockefeller Foundations Bellagio Centre in Italy, attended by eminent scientists and science stakeholders from several Muslim countries They can draw inspiration also from the diverse attitudes of fellow Muslim states, reclaiming a great Islamic past in which new knowledge was valued and scholars were free to pursue all lines of enquiry. This is manifest in their various states of economic health and development, as well as the degree of influence and fundamentalism of Islam This is not a question of simply importing Western ideas To what extent is science and scientific cooperation in these countries a casualty of these agendas? Certainly they cannot be helped by the resulting international mistrust and isolation of Islamist governments Unfortunately, diversity is less obvious in the tendency to restrict freedom of expression Walk down a street in some predominantly Muslim cities and the chances are that youll see taxis and buses bearing in Arabic the words “Seek knowledge, even as far as China” What appears this week is an exploration of the issues raised What are the critical components necessary for any Muslim nation with serious ambitions in science? A minimal requirement is an education system that embraces science as well as a critical approach, and at least one first-rate university Without explicit guidance from the Koran or sharia law, the regulations are, as elsewhere, the outcome of religious opinion, culture and accepted evidence
 Although the ability of PPAR-γ agonists to antagonize inflammatory responses by transrepression of nuclear factor kappa B (NF-κB) target genes is linked to antidiabetic and antiatherogenic actions , the mechanisms remain poorly understood As a result, NCoR complexes are not cleared from the promoter and target genes are maintained in a repressed state Here we report the identification of a molecular pathway by which PPAR-γ represses the transcriptional activation of inflammatory response genes in mouse macrophages Peroxisome proliferator-activated receptor-γ (PPAR-γ) has essential roles in adipogenesis and glucose homeostasis, and is a molecular target of insulin-sensitizing drugs  The initial step of this pathway involves ligand-dependent SUMOylation of the PPAR-γ ligand-binding domain, which targets PPAR-γ to nuclear receptor corepressor (NCoR)–histone deacetylase-3 (HDAC3) complexes on inflammatory gene promoters This in turn prevents recruitment of the ubiquitylation/19S proteosome machinery that normally mediates the signal-dependent removal of corepressor complexes required for gene activation This mechanism provides an explanation for how an agonist-bound nuclear receptor can be converted from an activator of transcription to a promoter-specific repressor of NF-κB target genes that regulate immunity and homeostasis. A 150-bp region of the iNOS promoter was amplified spanning the most proximal NF-κB site to the start of transcription  A 150-bp region of the mouse Cd36 promoter was amplified spanning the PPRE sequence  Anti-HA antibody ( Covance ) was used at 1:1,000 dilution Anti-HA protein A sepharose beads ( Covance ) were used for wild-type and mutant HA-tagged PPAR-γ proteins Anti-HDAC3 and anti-p65 antibodies were from Santa Cruz  Anti-NCoR antibody was from Affinity Bioreagents  Anti-PPAR-γ antibodies H-100 ( Santa Cruz ) and 39338 ( Active Motif ) were used in combination Antibodies against TBL1 and TBLR1 have been described previously  Antibodies used for endogenous immunoprecipitation and western blot for PPAR-γ/PIAS1 interaction experiments were obtained from Active Motifs and Santa Cruz, respectively Cell lysates were immunoprecipitated and washed four times in lysis buffer containing 0.1% SDS, 0.5% deoxycholate, 0.5% TritonX-100, 1 mM EDTA, 20 mM Tris-HCl pH 7.8 and 150 mM NaCl Cells were cultured in 0.01 µM trichostatin A (TSA) before ligand treatment for 16 h Cells were pre-treated with 0.1 µM rosiglitazone (1 h) and stimulated with 1 µg ml -1 LPS (1 h) before crosslinking for 10 min with 1% formaldehyde Chromatin immunoprecipitation assays ChIP assays were performed as previously described  Co-immunoprecipitations and western blotting For co-immunoprecipitations, RAW264.7 cells or 293 cells were transfected with HA-PPAR-γ (wild type) and 2 × FLAG-PIAS1 (wild type) using Superfect reagent in 10-cm dishes Colonies were picked 4–6 days after mating Effects of these siRNAs on cellular protein levels are illustrated in Supplementary Fig Finally, interactions were verified by α-galactosidase activity in yeast liquid culture assays For each experimental condition, 2–4 × 10 6 primary macrophages or RAW 264.7 cells were used For mammalian two-hybrid assays, 200 ng of UAS-TK luciferase reporter and 100 ng each of VP16–PPAR-γ wild-type and Gal-DBD–NCoR constructs were transfected into RAW264.7 cells For northern blot analysis, 10 µg total RNA and an iNOS -specific probe were used For RNAi experiments, smart-pool siRNAs ( Dharmacon ) against PIAS1, Ubc9, HDAC3, HDAC7 or control non-specific and (previously validated) NCoR were transfected into primary macrophages using lipofectamine 2000 ( Invitrogen ) and incubated for 48 h For siRNA experiments, RAW264.7 cells were transfected with siRNAs (40 nM) using Superfect reagent for 48 h before activation with PPAR-γ ligands and LPS induction (6 h) For transrepression experiments, wild-type PPAR-γ or PPAR-γ mutants were transfected at a 3:1 (PPAR-γ to reporter plasmid) ratio using Superfect reagent ( Qiagen ) HA-tagged wild-type and K77R and K365R PPAR-γ mutants were cloned into a pcDNA3 backbone ( Invitrogen ) Immunoprecipitates were resolved by SDS–PAGE and immunoblotted using anti-HA or anti-Myc antibodies. Immunoprecipitates were washed four times with wash buffer containing 10 mM Tris-HCl pH 8, 100 mM NaCl, 1 mM EDTA, 0.5% NP-40 and 0.5% Triton X-100, boiled in 1 × sample loading buffer and separated by 10% SDS–PAGE In all transfections, cells were treated with 0.1 µM rosiglitazone, stimulated with 1 µg ml -1 LPS and assayed for luciferase activity 6 h later M2 anti-flag antibody ( Sigma ) was used at 1:1,000 dilution Methods Plasmids and cell culture Primary macrophages were elicited by intraperitoneal injection with 2 ml of thioglycollate One microgram of total RNA was used for cDNA synthesis, and 2 µl of cDNA was used for PCR using iNOS or inflammatory-gene-specific primers Polymerase chain reaction (PCR) inserts were amplified and sequenced PPAR-γ bait used for the yeast two-hybrid, including the DNA-binding domain, hinge region and ligand-binding domain (PPAR-γ DHL), was inserted into the pGBK7 vector ( Clontech ) RNA isolation, semiquantitative PCR and northern blot analysis Total RNA (isolated by the Trizol method) was prepared from primary macrophages pretreated with 1 µM rosiglitazone (2 h) before 1 µg ml -1 LPS stimulation (6 h) S1  Statistical analysis was performed using Students t -test, with P 0.01 considered statistically significant SUMOylation assays For in vivo SUMOylation experiments, 250 µg total protein extract was prepared from HeLa cells transfected with HA-tagged wild-type PPAR-γ or SUMO point mutants (K77R and K365R) and Myc-tagged SUMO-1 The library was transformed into the AH109 yeast strain and was mated to Y187 strain transformed with PPAR-γ DHL bait Transfection experiments evaluated each experimental condition in triplicate and results are expressed as mean ± s.d Transient transfection The RAW264.7 mouse macrophage cell line was transiently transfected with iNOS or Aox-TK promoters directing luciferase expression, as previously described  VP16 refers to the transactivation domain of herpes simplex viral protein 16, and Gal-DBD refers to yeast Gal4 DNA-binding domain Whole-cell extracts were prepared using lysis buffer: 10 mM Tris-HCl pH 8, 420 mM NaCl, 1 mM EDTA and 0.5% NP-40 with protease inhibitor cocktail ( Roche Biochem ) Wild-type (WT)-PIAS1 and PIAS1-N were cloned into a 2 × FLAG-pcDNA3 expression vector Yeast plasmids were purified from individual clones Yeast two-hybrid screen A yeast two-hybrid library was generated with the pGAD vector ( Clontech ) with RNA derived from primary peritoneal macrophages elicited from normal and hypercholesterolaemic mice Although NCoR was cleared from the iNOS promoter within 10 min of LPS treatment, pretreatment of cells with rosiglitazone inhibited clearance at all time points tested ( Fig. 1d )  in a repressed state As expected, the p65 component of NF-κB was recruited exclusively to the iNOS promoter in response to LPS, and was not affected by rosiglitazone treatment ( Fig. 1e ) Because signal-dependent induction of NF-κB target genes has been suggested to require removal of NCoR complexes through Ubc5-dependent ubiquitylation , we used validated siRNAs directed against TBL1, TBLR1 and the ubiquitin conjugating enzyme Ubc5c (ref. 13 , also known as Ube2d3), all of which inhibited iNOS induction in response to LPS ( Fig. 1c ) Because this amino group is the point of covalent attachment of SUMO, the PPAR-γ crystal structures suggest that K365 could be SUMOylated in a ligand-dependent manner ChIP assays indicated that wild-type PPAR-γ and PPAR-γ K77R were efficiently recruited to the iNOS promoter in response to rosiglitazone, whereas PPAR-γ K365R was not ( Fig. 3e ) ChIP assays were next performed in macrophages to determine the roles of PIAS1 and Ubc9 in ligand-dependent recruitment of PPAR-γ to the iNOS promoter and in the prevention of NCoR clearance Chromatin immunoprecipitation (ChIP) experiments confirmed that NCoR, HDAC3, TBL1 and TBLR1 were present on the iNOS promoter under basal conditions, and that the NCoR and HDAC3 components cleared following LPS stimulation ( Fig. 1b ) Consistent with these findings, knockdown of NCoR expression, but not SMRT expression, resulted in the reversal of repression of an iNOS promoter reporter by PPAR-γ in RAW264.7 macrophages ( Supplementary Fig Consistent with these results, knockdown of HDAC3 reduced, but did not prevent, recruitment of PPAR-γ to the iNOS promoter in response to ligand, as determined by ChIP assays ( Fig. 4b ) Evaluation of the iNOS promoter (negatively regulated by PPAR-γ) and the Cd36 promoter (positively regulated by PPAR-γ) in macrophages revealed that PPAR-γ was recruited to both promoters in a ligand-dependent manner ( Fig. 1e ) Finally, knockdown of Ubc9, the SUMOylation pathway rate-limiting E2 ligase, significantly impaired PPARγ-dependent transrepression of iNOS in both RAW264.7 cells and primary macrophages ( Fig. 2c and Supplementary Fig Furthermore, co-immunoprecipitation experiments using antibodies directed against either endogenous or epitope-tagged PPAR-γ and PIAS1 showed a basal interaction in RAW264.7 cells and primary macrophages that was modestly enhanced by treatment with rosiglitazone ( Fig. 2a ) Genes subject to transrepression by this pathway are marked in the basal state by the presence of NCoR–HDAC3–TBL corepressor complexes However, in cells treated with rosiglitazone or GW0072, both NCoR and HDAC3 remained on the iNOS promoter after LPS stimulation ( Fig. 1b ) In addition, knockdown of PIAS1 or Ubc9 prevented the retention of NCoR on the iNOS promoter in the presence of rosiglitazone and LPS ( Fig. 2e ) In contrast, PPAR-γ showed a ligand-dependent increase in interaction with an NCoR deletion mutant lacking the IDC that was abolished by knocking down Ubc9 or PIAS1 ( Fig. 4a and Supplementary Fig In contrast, wild-type PPAR-γ and each of the PPAR-γ mutants were recruited to the positively regulated Cd36 promoter ( Fig. 3f ) Inhibition of NCoR expression using an NCoR-specific short interfering (si)RNA validated for efficacy ( Supplementary Fig Interestingly, allosteric changes in the PPAR-γ ligand-binding domain required for entry into the SUMOylation-dependent transrepression pathway are distinct from changes that regulate interactions with conventional coregulators It will be of interest to define the extent to which this pathway is used by PPAR-γ and other nuclear receptors, and to explore how this mechanism can be exploited to develop new drugs for the treatment of inflammatory and metabolic diseases. Knockdown of PIAS1 expression abolished recruitment of PPAR-γ to the iNOS promoter, but did not affect recruitment to the positively regulated Cd36 promoter ( Fig. 2d ) Ligand-dependent dismissal of these complexes requires Ubc5-dependent ubiquitylation and proteosomal degradation, with TBLR1 functioning as an essential E3 ligase  Ligand-dependent interaction of PPAR-γ with the iNOS promoter was abolished by siRNA-mediated knockdown of NCoR, indicating that NCoR is required for PPAR-γ recruitment ( Fig. 1f ) LPS signalling results in the clearance of the NCoR and HDAC3 components of this complex in a TBL1-, TBLR1- and Ubc5-dependent manner, allowing a switch from active repression to transcriptional activation Mammalian two-hybrid assays also showed an interaction between PPAR-γ and HDAC3, but this interaction was only modestly affected by ligand or by knockdown of PIAS1 or Ubc9 ( Supplementary Fig Mammalian two-hybrid assays confirmed this interaction and demonstrated that knocking down expression of PIAS1 or Ubc9 did not influence ligand-dependent dissociation of PPAR-γ from the IDC ( Fig. 4a ) Mammalian two-hybrid assays were used to explore effects of SUMOylation on interactions of PPAR-γ with NCoR and HDAC3 Moreover, siRNA-mediated knockdown of PIAS1 in primary macrophages abolished PPAR-γ transrepression of the endogenous iNOS gene ( Fig. 2c ) NCoR and the related factor SMRT (silencing mediator of retinoic acid and thyroid hormone receptors) are components of corepressor complexes containing HDAC3, transducin beta-like protein-1 (TBL1) and TBLR1 that interact with a subset of unliganded nuclear receptors and mediate active transcriptional repression  Notably, crystal structures of the apo and rosiglitazone-bound forms of PPAR-γ indicate that the primary amine group of K365 is oriented towards the interior of the ligand-binding domain in the apo form, but is solvent-exposed in the rosiglitazone-bound form ( Fig. 3a ) Notably, Ubc5 was rapidly recruited to the iNOS promoter following LPS stimulation in the absence of rosiglitazone, but was not recruited to the promoter when rosiglitazone was present ( Fig. 1d ) One of the clones isolated in this screen encoded the first 208 amino acids of PIAS1 (protein inhibitor of activated STAT1), initially identified as a suppressor of interferon-dependent transcription and now known to belong to a family of SUMO E3 ligases  Potential roles for NCoR-associated HDAC proteins were supported by the finding that treatment with 10 nM of the histone deacetylase inhibitor trichostatin A reversed rosiglitazone-dependent transrepression of iNOS ( Supplementary Fig PPAR-γ K365R did not inhibit the iNOS promoter, whereas PPAR-γ K77R retained full transrepression activity ( Fig. 3c ) PPAR-γ K77R showed enhanced transactivation function, consistent with previous findings , whereas PPAR-γ K365R showed approximately the same activity as wild-type PPAR-γ on the positively regulated Aox-TK luciferase promoter ( Fig. 3d ) Previous studies have demonstrated that unliganded PPAR-γ binds to one of two nuclear receptor interaction domains in the extreme C terminus of NCoR (termed the IDC), and that this interaction is reversed by ligand  Recent studies indicate that NCoR/SMRT complexes are also required for basal repression of a subset of NF-κB and AP-1 target genes , with loss of NCoR resulting in a partially activated phenotype in macrophages  S1 ) resulted in complete reversal of iNOS transrepression by the synthetic PPAR-γ ligands rosiglitazone and GW0072 (ref. 18 ) ( Fig. 1a ) S1 ) resulted in significant inhibition of PPARγ-dependent repression of the iNOS promoter, similar to the effects observed for NCoR siRNA ( Fig. 2b ), but did not impair transcriptional activation of a positively regulated PPAR-γ target gene (data not shown) S1 ) was tested in RAW264.7 cells S2a ) S2b ) S2c ) S3b, c ) S4a ) contains motifs previously shown to interact with various nuclear receptors  S4b ) S4c ), suggesting a role for PIAS1 or other PIAS proteins in this process S5a ) S5b ) S5c ) Similar results were obtained for four additional LPS-inducible, PPARγ-sensitive promoters: Ccl3 , Ccl7 , Cxcl10 and Tgtp ( Supplementary Fig SUMOylation of the PPAR-γ2 AF-1 domain at residue K107 (equivalent to K77 of PPAR-γ1) inhibits ligand-dependent activation of positively regulated target genes  SUMOylation of transcription factors has previously been correlated with impaired transcriptional activation and/or transcriptional repression  The HDAC3-specific siRNAs, but not control siRNAs directed against HDAC7, reversed the transrepression observed on the iNOS promoter in this system ( Supplementary Fig The interaction between PPAR-γ and the PIAS1 clone was confirmed both by yeast survival and α-galactosidase liquid assays ( Supplementary Fig The observation that ligand-dependent recruitment of PPAR-γ to LPS-responsive promoters requires NCoR raises a paradox, because ligand binding disrupts direct interactions between NCoR and PPAR-γ  The PIAS1-N fragment dominantly inhibited PPARγ-dependent transrepression of the iNOS promoter in RAW264.7 cells ( Supplementary Fig The PPARγ-dependent transrepression pathway is initiated by ligand-induced SUMOylation of the ligand-binding domain The present studies define sequential steps of a pathway mediating ligand-dependent transrepression of inflammatory response genes by PPAR-γ in macrophages ( Fig. 4c ) The primary amino acid sequence of murine PPAR-γ shows an additional SUMOylation consensus sequence (ψKXE/D; where ψ represents a hydrophobic amino acid and X refers to any amino acid) at K365 (corresponding to K367 in the human PPAR-γ sequence, Fig. 3a ) The recruitment of PPAR-γ to the iNOS promoter did not involve sequence-specific DNA binding because a PPAR-γ mutant (PPAR-γ C126A/E127A ) containing amino acid substitutions in the DNA-binding domain that abolish binding to PPAR-γ response elements and its recruitment to the Cd36 promoter, was efficiently recruited to the iNOS promoter ( Supplementary Fig.S3a ) The region of PIAS1 isolated in this screen (hereafter referred to as PIAS1-N, see Supplementary Fig These data are consistent with the hypothesis that the TBL1–TBLR1-recruited ubiquitylation complex is required for LPS-dependent clearance of NCoR and HDAC3 from the iNOS promoter, and that PPAR-γ represses iNOS activation by preventing TBL1–TBLR1-dependent corepressor clearance These observations predicted that NCoR–HDAC3–TBL complexes should associate with the iNOS promoter These results suggest that NCoR is required for ligand-dependent recruitment of SUMOylated PPAR-γ to the iNOS promoter and that HDAC3 plays a quantitative role in stabilizing this interaction These results suggest that PIAS1/Ubc9-mediated PPAR-γ SUMOylation is required for PPARγ-dependent transrepression These results suggest that PPAR-γ acts to repress LPS induction of the iNOS gene by preventing recruitment of the Ubc5/19S proteosome machinery required for the clearance of NCoR and HDAC3 This is consistent with previous studies of PPAR-γ C126A/E127A indicating that it does not activate PPAR-γ target genes but that it retains transrepression activity  This modification targets PPAR-γ to NCoR complexes associated with the promoter, preventing Ubc5 recruitment in response to LPS signals To evaluate specifically the role of HDAC3, the effect of a validated HDAC3-specific pool of siRNAs ( Supplementary Fig To identify PPARγ-interacting proteins that might potentially resolve this paradox, a yeast two-hybrid screen was performed using a library constructed from messenger RNA derived from primary mouse macrophages To specifically evaluate the consequences of loss of PIAS1 expression, transfection of validated PIAS1 siRNAs ( Supplementary Fig To test this hypothesis, K365 of PPAR-γ was mutated to arginine (K365R), and the wild-type and mutant proteins were tested for SUMOylation in vivo and in vitro  We focused on the mouse inducible nitric oxide synthase gene ( iNOS , also known as Nos2 ) as a model because it is one of several inflammatory response genes expressed by macrophages that is strongly induced by lipopolysaccharide (LPS) and negatively regulated by PPAR-γ agonists  We next used ChIP assays to evaluate whether an ordered sequence of events was required for NCoR clearance in response to LPS stimulation in the presence or absence of rosiglitazone We note that a number of inflammatory response genes that are derepressed in NCoR-deficient macrophages are also subject to transrepression by PPAR-γ agonists, suggesting a possible role for NCoR in this process Wild-type PPAR-γ, but not PPAR-γ K365R , showed a significant increase in SUMOylation following treatment with rosiglitazone ( Fig. 3b and data not shown) To determine the functional consequences of K77- and K365-dependent SUMOylation, the ability of each mutant to inhibit the iNOS promoter and/or transactivate a positively regulated PPARγ-dependent promoter was tested in RAW264.7 cells
 A key question is how to interpret the global organization of such networks as the coexistence of their structural subunits (communities) associated with more highly interconnected parts After defining a set of new characteristic quantities for the statistics of communities, we apply an efficient technique for exploring overlapping communities on a large scale Here we introduce an approach to analysing the main statistical features of the interwoven sets of overlapping communities that makes a step towards uncovering the modular structure of complex systems Identifying these a priori unknown building blocks (such as functionally related proteins , industrial sectors and groups of people ) is crucial to the understanding of the structural and functional properties of networks Many complex systems in nature and society can be described in terms of networks capturing the intricate web of connections among the units they are made of  Our studies of collaboration, word-association and protein interaction graphs show that the web of communities has non-trivial correlations and specific scaling properties. The existing deterministic methods used for large networks find separated communities, whereas most of the actual networks are made of highly overlapping cohesive groups of nodes We find that overlaps are significant, and the distributions we introduce reveal universal features of networks A similar effect can be observed by changing the value of k as well: increasing k makes the communities smaller and more disintegrated but also at the same time more cohesive A unique feature of our method is that we can simultaneously look at the network at a higher level of organization and locate the communities that have a key role within the web of communities Agglomerative methods do the same, but in the reverse direction All these can be explored systematically and can result in many overlapping communities (illustrated in Fig. 1c ) Although different values of k and w * might be optimal for the local community structure around different nodes, we should set some global criterion to fix their values if we wish to analyse the statistical properties of the community structure of the entire network Although the numerical determination of the full set of k -clique communities is a polynomial problem, we use an algorithm (which can be downloaded from http://angel.elte.hu/clustering/ ) that is exponential, because it is significantly more efficient for the graphs corresponding to real data Although the range of overlap sizes is limited, the behaviour of the cumulative overlap size distribution P ( s ov ), shown in Fig. 4c , is close to a power law for each network, with a rather large exponent Although the scaling of the size of non-overlapping communities has already been shown for social networks , it is striking to observe how this aspect of large real networks is preserved even when a more complete picture (allowing overlaps) is investigated Among the many possible applications is a more sophisticated approach to the spreading of infections (for example, real or computer viruses) or information in highly modular complex systems. An arbitrary network can always be transformed into a binary one by ignoring any directionality in the links and keeping only those that are stronger than a threshold weight w * An important biological application is finding the communities of proteins, based on their interactions Another, biological, example is that a large fraction of proteins belong to several protein complexes simultaneously  As an illustration, in Fig. 2 we show diagrams of the communities of three selected nodes of three large networks: the social network of scientific collaborators ( Fig. 2a ), the network of word associations related to cognitive sciences ( Fig. 2b ) and the molecular-biological network of protein–protein interactions ( Fig. 2c ) At the first part of P ( d com ), in contrast, a characteristic scale appears, because most of the communities have a size of the order of k (see Fig. 4a ) and their distribution around dominates this part of the curve Because for unweighted networks no threshold weight can be set, for these we simply select the smallest value of k for which no giant community appears Because of this relatively low number, we can depict the entire network of protein communities as in Fig. 3  By far the most significant GO term for the biological process of this community is ‘ribosome biogenesis/assembly’ Changing the threshold is like changing the resolution (as in a microscope) with which the community structure is investigated: by increasing w * the communities start to shrink and fall apart Divisive methods cut the network into smaller and smaller pieces, and each node is forced to remain in only one community and be separated from its other communities, most of which then necessarily fall apart and disappear Finally, in Fig. 4d we display the cumulative distribution of the membership number P ( m ) Finally, the size of any community α can most naturally be defined as the number of its nodes For example, because with our approach it is possible to ‘zoom’ in on a single unit in a network and uncover its communities (and the communities connected to these, and so on), we provide a tool with which to interpret the local organization of large networks and can predict how the modular structure of the network changes if a unit is removed (for example, in a gene knockout experiment) For example, when we applied the agglomerative method of ref. 18 , at some point ‘bright’, as a single word, joined a ‘community’ of 890 other words For finding meaningful communities, the way in which they are identified is expected to satisfy several basic requirements: it cannot be too restrictive, it should be based on the density of links, it is required to be local, it should not yield any cut-node or cut-link (whose removal would disjoin the community) and, of course, it should allow overlaps For our purposes these directed links have been replaced by undirected ones with a weight equal to the sum of the weights of the corresponding two oppositely directed links For some proteins no function is yet available For the former network both sets of parameters result in very similar communities (see Supplementary Information ) For the overlap size, for example, P ( s ov ) means the proportion of those overlaps that are larger than s ov  For the protein interaction network this gives k = 4, resulting in 82 communities For the protein Ycr072c, which is required for the viability of the cell and appears in the dark green community on the right, SGD provides no biological process (function) Further relevant statistical features will be introduced later Furthermore, members of our communities have their own communities, resulting in an extremely complicated web of the communities themselves However, in the protein interaction network the largest membership number is only 4, which is consistent with the also rather short distribution of its community degree However, most real networks are characterized by well-defined statistics of overlapping and nested communities In addition, new cellular processes can be predicted if as yet unknown communities are found with our method In addition, such methods inevitably lead to a tree-like hierarchical rendering of the communities, whereas our approach allows the construction of an unconstrained network of communities In Fig. 4a the power-law dependence P ( s com )∝( s com ) - τ  with an exponent ranging between τ  = 1 and τ  = 1.6 is well pronounced and is valid over nearly the entire range of community sizes In general, each node i of a network can be characterized by a membership number m i , which is the number of communities that the node belongs to In most cases, relaxing this definition (for example, by allowing incomplete k -cliques) is practically equivalent to decreasing k  In particular we focus on their cumulative distribution functions denoted by P ( m ), P ( s ov ), P ( d com ) and P ( s com ) In particular, the communities of G In spite of this ambiguity, the presence of communities in networks is a signature of the hierarchical nature of complex systems  In Table 1 we have collected a few statistical properties of the network of communities In the co-authorship network of the Los Alamos e-print archives each article contributes a value 1/( n - 1) to the weight of the link between every pair of its n authors In the collaboration and word-association networks there seems to be no characteristic value for the membership number: the data are close to a power-law dependence, with a large exponent In the Database of Interacting Proteins (DIP) core list of the protein–protein interactions of Saccharomyces cerevisiae each interaction represents an unweighted link between the interacting proteins In the present case the principle of organization (scaling) is preserved (with some specific modifications) when going to the next level, in good agreement with the recent finding of the self-similarity of many complex networks  In the related percolation phenomena a giant component appears when the number of links is increased above some critical point In the South Florida Free Association norms list the weight of a directed link from one word to another indicates the frequency with which the people in the survey associated the end point of the link with its starting point In this way we ensure that we find as many communities as possible, without the negative effect of having a giant community that would smear out the details of the community structure by merging many smaller communities In turn, a single node can belong to several communities In turn, any two communities α and β can share nodes, which we define as the overlap size between these communities Indeed, most proteins in the communities shown in Figs 2c and 3 can be associated with either protein complexes or certain functions, as can be looked up by using the GO-TermFinder package and the online tools of the Saccharomyces Genome Database (SGD)  It is well known that the nodes of large real networks have a power-law degree distribution It should be pointed out that the average clustering coefficients 〈 C com 〉 are relatively high, indicating that two communities overlapping with a given community are likely to overlap with each other as well, mostly because they all share the same overlapping region More details about the method and its speed are given in Supplementary Information  Most real networks typically contain parts in which the nodes (units) are more highly connected to each other than to the rest of the network Naturally, the communities also constitute a network, with the overlaps being their links One such example can be seen in the enlarged portion of Fig. 3  Parisi (whose contributions in different fields of physics are well known) shown in Fig. 2a are associated with his fields of interest, as can be deduced from the titles of the papers involved The basic observation on which our community definition relies is that a typical community consists of several complete (fully connected) subgraphs that tend to share many of their nodes The community degrees ( Fig. 4b ) have a unique distribution, consisting of two distinct parts: an exponential decay with a characteristic community degree (which is of the order of 〈 d com 〉 shown in Table 1 ), followed by a power-law tail proportional to ( d com ) - τ   The criterion we use is based on finding a community structure that is as highly structured as possible The existing methods for finding communities in large networks are useful if the community structure is such that it can be interpreted in terms of separated sets of communities (see Fig. 1b and refs 10 , 15 , 16 , 17 –18 ) The extent to which different communities overlap is also a relevant property of a network The four distributions characterizing the global community structure of these networks are shown in Fig. 4  The four-clique communities of the word ‘bright’ ( Fig. 2b ) correspond to the various meanings of this word The high fraction of shared nodes is yet another indication of the importance of overlaps between the communities The knowledge of the community structure enables the prediction of some essential features of the systems under investigation The networks chosen above have been constructed in the following ways The number of such links of community α can be called its community degree,  The sets of such nodes are usually called clusters, communities, cohesive groups or modules ; they have no widely accepted, unique definition The specific scaling of the community degree distribution is a hitherto undescribed signature of the hierarchical nature of the systems we study The tail of the community degree distribution is therefore simply proportional to that of the community size distribution There are other parts of the whole network that are not reachable from a particular k -clique, but they potentially contain further k -clique communities Therefore, to approach this critical point from below, for each selected value of k (typically between 3 and 6) we lower the threshold w * until the largest community becomes twice as big as the second largest one These examples (and further examples included in Supplementary Information ) show the advantages of our approach over the existing divisive and agglomerative methods recently used for large real networks These networks are very large, consisting of 30,739, 10,617 and 2,609 nodes and 136,065, 63,788 and 6,355 links, respectively These pictures can serve as tests or validations of the efficiency of our algorithm These plots demonstrate that a node can belong to several communities This can be illustrated by the numerous communities that each of us belongs to, including those related to our scientific activities or personal life (school, hobby, family) and so on, as shown in Fig. 1a  This definition seeks to represent the fact that it is an essential feature of a community that its members can be reached through well-connected subsets of nodes This happens, for example, with the word ‘bright’ when we apply the method described in ref. 16 : it tends to stay together mostly with the words of the community related to ‘light’, while most of its other communities (for example, those related to ‘colours’; see Fig. 2b ) completely disintegrate (‘green’ becomes associated with the vegetables, ‘orange’ with the fruits, and so on) This has led us to k = 6 and k = 5 with f * = 0.93 and 0.75, respectively, for the collaboration network, and k = 4 with f * = 0.67 for the word-association network This has long been understood by sociologists but has never been studied systematically for large networks This is consistent with our understanding of a complex system having different levels of organization with units specific to each level This method is based on first locating all cliques (maximal complete subgraphs) of the network and then identifying the communities by carrying out a standard component analysis of the clique–clique overlap matrix  This new kind of behaviour is consistent with the community size distribution if we assume that, on average, each node of a community has a contribution δ to the community degree Thus, the degree to which P ( d com ) deviates from a simple scaling depends on k or, in other words, on the prescribed minimum cohesiveness of the communities Thus, the fact that they show up in our approach as members of communities can be interpreted as a prediction of their functions Thus, we define a community, or more precisely a k -clique community, as a union of all k -cliques (complete subgraphs of size k ) that can be reached from each other through a series of adjacent k -cliques (where adjacency means sharing k - 1 nodes)  To characterize the community structure of a large network we introduce the distributions of these four basic quantities To show that the communities we find are not due to an artefact of our method, we have also determined the above distributions for ‘randomized’ graphs with parameters (size, degree sequence, k and f *) the same as in our three examples but with links stochastically redistributed between the nodes Understanding both the universal and specific features of the networks associated with these data has become a significant task We can conclude that there is no characteristic overlap size in the networks We can therefore infer that Ycr072c is likely to be involved in this process We denote by f * the fraction of links stronger than w *, and use only those values of k for which f * is not too small (not smaller than 0.5) We employ the community definition specified above, because none of the others in the literature satisfy all these requirements simultaneously  We find that if we consider the network of communities instead of the nodes themselves, we still observe a degree distribution with a fat tail, but a characteristic scale appears, below which the distribution is exponential We have found that the distributions are indeed extremely truncated, signifying a complete lack of the rich community structure determined for the original data We use our method for binary networks (that is, with undirected and unweighted links) When we are interested in the community structure around a particular node, it is advisable to scan through some ranges of k and w * and monitor how its communities change Will the same kind of distribution hold when we move to the next level of organization and consider the degrees of the communities? We find that it is not so With recent technological advances, huge sets of data are accumulating at a tremendous pace in various fields of human activity (including telecommunications, the Internet and stock markets) and in many areas of life and social sciences (such as biomolecular assays, genetic maps and groups of World Wide Web users)
 But a ruling by the Supreme Court in Karlsruhe could take years. “In the meantime, it is very hard on me and my family,” Brustle says, “particularly for kids whose father has been accused of doing things so bad they are considered to be against public order.” He points out that the ministry stipulates that its grantees should attempt to patent inventions from projects that it supports It was made in the wake of a public call by Germanys largest research agency, the DFG, for a relaxation of stem-cell laws, which are stricter than those of many other European countries (see Nature 444 , 253 ; 2006 ). newsad; Brüstle says he will now appeal to the Supreme Court in Karlsruhe, arguing that the ruling goes beyond German law, which allows the use of human embryonic stem-cell lines created before 2002 Just last year, the ministry of research awarded Brüstle a grant for work with human embryonic stem cells derived before 2002 Munich A German court has revoked a patent on a method for generating a class of human embryonic stem cells The 5 December ruling is seen as yet another setback for stem-cell research in a nation where it is already constrained by tight regulation The environmental group argued that the derivation of the cell lines in question had involved the destruction of human embryos, which breaches guidelines issued by the German Patent Office The federal patent court in Munich heard a charge brought by Greenpeace that the patent, held by University of Bonn neurobiologist Oliver Brüstle on a way to generate precursor nerve cells, was contrary to public order The judge, Eva-Maria Schermer, quickly ruled in Greenpeaces favour — much to the dismay of Brüstle, who arrived in court with three bodyguards to protect him The ruling will become binding in a few weeks
 A follow-up study found the quality of information had improved considerably by last October  A set of guidelines on how to report a clinical trial, the statement is designed to ensure that authors present results transparently Along with other registry advocates, he would like to see all clinical results, not just protocols and outcomes, published in public databases Although outright deception is rare, there is now ample evidence to show that our view of drugs effectiveness is being subtly distorted And a publication in a big journal can boost authors careers as well as company coffers And in 2004, the International Committee of Medical Journal Editors announced its members would not publish the results of trials that had not been placed in a public registry And that, notes Laine, makes it impossible for journals and health agencies to assess potential drugs. “You never quite know if other data are out there that would influence your conclusions,” she says And the motivation, say the researchers, is financial gain and personal ambition. “Patients volunteer for trials, but finances and career motives decide what gets published,” says Peter Gøtzsche, an expert in clinical trials and director of the Nordic Cochrane Centre in Copenhagen. “This is ethically indefensible And when Chan looked at those missing data, he found that inconclusive results were significantly more likely to have been left out of the final publication Aside from the commercial concerns of the drugs industry, the creation of a results database could lead to patients pressurizing doctors for access to experimental medicines Asked about the missing outcomes, most authors simply denied the data were ever recorded, despite evidence to the contrary At that time, the antidepressant Paxil (paroxetine), made by London-based drug giant GlaxoSmithKline, was a popular treatment for adolescents in the United States Because clinical researchers are not obliged to publish their findings, ambiguous or negative results can languish in filing cabinets, resulting in what Christine Laine, an editor at the Annals of Internal Medicine in Philadelphia, Pennsylvania, calls “phantom papers” But according to Richard Smith, a former editor of the BMJ (which was the British Medical Journal ) and now head of European operations for the US insurer UnitedHealthcare, editors may be biased towards positive results But critics say that clinical researchers carry a greater ethical burden, as their findings inform decisions about the licensing of drugs But doctors have now been warned off prescribing Paxil to youngsters, after evidence emerged that it increases the risk of suicidal behaviour But even with all the data, journal editors face another challenge: hype But it would not be simple But that was based on data collected over six months But we have to assume that the company has done all it can to make its product look as good as possible.”  Editorial control At JAMA , editors began insisting last year that all research sponsored by for-profit organizations undergo independent statistical analysis before acceptance But what if the target were the researchers who test drugs? And what if the allegations came not from the tabloid press, but from studies published in prestigious medical journals? The slurs may sound over the top, but each is based on hard data By matching papers with protocols, several groups have shown that many trials are completed but not published By registering all trials when they begin, researchers will find it harder to suppress outcomes, editors believe Cathy DeAngelis, the journals editor-in-chief, says JAMA had asked authors to do this for years, but began requiring it after editors started seeing papers that they thought dishonest. “People said that for-profit companies would stop sending us trials,” she notes. “Well, guess what? If you look at what were publishing youll see that thats not true.”  Still, Goodman and others caution against blaming everything on industry Chan, now working for the WHO registry team in Geneva, says the first round of consultations with stakeholders should produce a policy statement in April Change is not easy, but we must get there.”  It is a dramatic conclusion to come from a field of study with no proper name, staffed by part-time volunteers Clinical-trials experts welcomed the move, but the industry response was patchy Critically, the association was not explained by the papers having more positive results Crucially, papers with inconclusive results not only took longer to publish (see graph), they were less likely to see the light of day at all Despite these successes, advocates of reform say bigger fights lie ahead Dont believe the hype Nor do the problems end when a trial hits an editors desk During his PhD at the University of Oxford, UK, epidemiologist An-Wen Chan looked at the protocols for 122 trials registered with two Danish ethics committees in 1994–95 For drug companies this is a step too far, akin to asking an inventor to publish the description of an invention before it is patented For each act, be it the suppression of results or the omission of outcomes, there is a financial motive for the company whose drug is being tested For many clinical-trials experts, these funding biases explain all the others For the devotees of ‘journalology’ or ‘research into research’, the literature on clinical trials is their raw data and patterns of bias are their results Full disclosure Such accusations make medical editors angry Given the combination of motive and opportunity, many see drug-company influence as an inevitably distorting factor. “When we see an industry article we get our antennae up,” says Steven Goodman, a medical statistician at Johns Hopkins University in Baltimore and an editor at the Annals of Internal Medicine . “Its not that we assume the research is done badly Going public too early, they say, would deter companies from taking risks on potential treatments and slow down the generation of new drugs Good peer reviewers and hands-on editors should, for example, weed out hype Government-sponsored trials also tend to report positive outcomes , although the effect is weaker than with industry studies He and others add that although industry will probably continue to resist, the public attention generated by recent scandals, and the wealth of data available on the problems, mean that time is ripe for change. “Im not relying on hope,” says Gøtzsche. “But the results of all trials should be made public, not only those that the sponsor cares to tell the world about Health insurers and hospitals might also change the drugs they use after seeing the raw results, rather than waiting for peer-reviewed papers. newsad; The debate is in its infancy Horton and other editors at top journals say they rebuff such threats, but some less well staffed journals lack policies for separating commercial and editorial decisions, suggesting that reprint income at least has the potential to distort decisions If that happens, the journal record will give an over-optimistic impression of the treatments studied, with consequences for peer reviewers, government regulators and patients In 2003, epidemiologist Bodil Als-Nielsen and her colleagues at the University of Copenhagen looked at factors that might influence researchers conclusions about a drugs efficacy or safety  In a study under review, Gøtzsche and his colleagues show that industry-funded meta-analyses — studies that combine results from several clinical trials of a drug — are similarly prone to draw positive conclusions that are not supported by the data (see graph) In an article published last May, titled “Medical journals are an extension of the marketing arm of pharmaceutical companies”, he pointed out that reprints of papers reporting positive results can generate millions of dollars, and that this might influence editorial decisions  In many cases, the company funding the study also employs one or more of the authors Instead, the companies propose depositing such information in a locked database, to be released when the drug obtains marketing approval It is a powerful idea, which could one day make all trial information public It is also an idea that has pitched pharmaceutical companies against advocates for reform, in a tussle over whether transparency or commercial confidentiality best serves medical science It seems to be helping It was claimed in a court case brought in the United States that GlaxoSmithKline had suppressed data showing this since 1998 Journals have also endorsed trial registries Just say no One of the biggest problems with clinical-trial reporting, the suppression of negative results, shows the importance of such debates Last June, the committee was forced to issue another statement after finding that some sponsors were being deliberately vague and entering terms such as ‘investigational drug’ in the field for the drug name Last year, for example, a French team showed that only 40% of trials registered with its countrys ethics committees in 1984 had been published by 2002, despite more than twice as many having been completed  Levelled at politicians, such accusations would come as no surprise Medical journals can, however, request such missing data Merrill Goozner, who tracks pharmaceutical issues at the Center for Science in the Public Interest, a lobby group in Washington DC, agrees. “Its a financial conflict of interest, plain and simple,” he says More than half of the outcomes that the protocol said would be measured were missing from the published paper, he found  Most are journal editors, medical statisticians or public-health experts, united by fears for the integrity of clinical trials One alleged example hit the headlines in 2004 One idea, adopted by The Lancet three years ago, is to insist that authors send in a trial protocol when they submit results One of the first initiatives, introduced in 1996 and revised in 2001, is the statement on Consolidated Standards of Reporting Trials (CONSORT) Others add that journals must also share the blame Others are working on what could become the biggest reform of clinical-trial reporting for decades: the creation of a comprehensive international registry of all clinical trials Phantom papers can be tracked down through trial protocols — the document describing how a trial will be run and what outcomes will be measured — which have to be registered with local ethics committees Researchers and sponsors tend to be interested in things that work rather than those that do not, so authors may subconsciously tweak results and talk up conclusions. “Researchers are so worried about getting papers rejected that they put a lot of spin on results to make them seem as exciting as possible,” says Doug Altman, a medical statistician who supervised Chan at Oxford Researchers in any field can sit on negative or inconclusive results Results from a trial of the arthritis drug Celebrex (celecoxib) looked good when they were published in 2000, for example, but less so when physicians scrutinized the full data set Rick Koenig, a spokesman for GlaxoSmithKline, says the company thought the charges unfounded, but agreed to pay $2.5 million to avoid the costs and time of litigation Several registries already exist, including one run by the US government Since 1990, a group of researchers has met every four years to lay bare the biases that permeate clinical research Since top journals began insisting that authors follow the guidelines, researchers descriptions of their methods, for example how they place subjects in treatment or control groups, have become more accurate  Some of these researchers are using their findings to change medical journals and make it harder for authors to misrepresent results Such information aids reviewers decisions That should help identify whether researchers are reporting all the information they gathered The experts working on the WHO registry want a list of mandatory entries for trial data, including the primary outcome The hype shows up in a papers conclusions The Lancet s Richard Horton has said that authors sometimes contact him to say that sponsors are likely to buy large numbers of reprints if their study is published The original paper, which appeared in the Journal of the American Medical Association ( JAMA ), dismissed fears that Celebrex could cause ulcers The original studys authors say that the later data were too unreliable to be included, but acknowledge that they could have “avoided confusion” by explaining to editors why they had omitted them The results make for uncomfortable reading The World Health Organization (WHO) is working on an online portal that would bind these databases into a single source Their analysis of 370 trials showed that the strongest predictor of the authors conclusions was not the nature of the data, but the type of sponsor There is certainly evidence that drug companies attempt to use reprint income as a lever on journals They answer only the questions they want to answer They deny that commercial pressures influence peer review, adding that journals have introduced several measures that have helped to clean up clinical-trial reporting They ignore evidence that does not fit with their story They set up and knock down straw men This case is not a one-off This is incredibly important.” This proposal would seem to tackle problems with reporting data and bias Trials funded by for-profit organizations were significantly more likely to reach a favourable verdict than those sponsored by charities or governments When other physicians analysed a full years worth — which the authors already had at the time of their JAMA submission — they claimed that Celebrex seemed to cause ulcers just as often as other treatments  Yet clinical-trials experts are more optimistic than they have been at many points in the past 15 years Yet for critics such as Smith, even the WHO portal does not go far enough
 A single mutation is sufficient to override the inhibitory effects of the drug, rescuing thiamine synthesis  Amazingly, the strict selectivity is completely reversed by the substitution of only a single RNA base in the binding site Both TPP and SAM are chemically and structurally more complex than purines By contrast, RNA has only four components at its disposal — adenine, guanine, cytosine and uracil — that are all similar in size and chemistry Does this mean that small-molecule drugs could be found that bind to these RNAs and inhibit their function? Would bacteria and fungi become resistant to such drugs, or do riboswitches represent a chink in microbial armour? Highly specific substrate recognition by proteins exploits an arsenal of 21 amino acids that vary significantly in charge, size and polarity In contrast, molecules that bind to RNA are typically decorated with positively charged groups that provide favourable electrostatic inter-actions with the negatively charged RNA In many cases, the end result is suppression of the production of enzymes that are responsible for the biosynthesis of the detected metabolite ( Fig. 1 ) In this issue, Serganov et al . ( page 1167 ) and Montange and Batey ( page 1172 ) describe the structures of two distinct classes of riboswitch, providing remarkable insight into RNA metabolite recognition and the control mechanism for gene expression Indeed, a TPP analogue (pyrithiamine pyrophosphate, PTPP) shows antimicrobial activity by blocking the binding site of the TPP-sensing riboswitch, shutting down thiamine metabolism in bacteria It is now clear that natural selection can also produce RNAs with extraordinary substrate specificity It seems that the structural flexibility that allows a riboswitch to alter its conformation upon substrate binding may also facilitate the emergence of resistance to drugs targeted against it Just like guanine or adenine in the purine-sensing riboswitches, TPP and SAM become deeply buried in the RNA structures, embedded between interacting helices Microbes develop resistance to PTPP by allowing mutations to emerge within the riboswitch, despite the need to preserve the RNAs structural architecture Montange and Batey study a riboswitch that binds S -adenosylmethionine (SAM, a cofactor that donates a single carbon unit and that is required for many enzymes) Notably, TPP carries two negatively charged phosphate groups Riboswitches are not rare — they account for about 2–3% of genetic control in bacteria , and are also found in archaea, fungi and plants  Serganov et al . describe a riboswitch that senses thiamine pyrophosphate (TPP, an enzyme cofactor derived from vitamin B 1 ) in bacteria Since their discovery a few years ago, numerous riboswitches have been found that specifically recognize substrates as diverse as nucleotides, amino acids, vitamins and co-enzymes  Some bacterial messenger RNAs directly regulate the expression of proteins involved in the syn-thesis of certain metabolic products Studies of aptamers — RNAs selected experimentally to recognize small molecules — demonstrate that RNA can discriminate between closely related structures at least as well as antibodies can  The close structural similarity of riboswitches from bacteria and plants emphasizes how difficult it may be for a single RNA molecule to combine substrate recognition with genetic control The most astonishing finding was the extra-ordinary selectivity achieved by these RNAs: for instance, the guanine-sensing riboswitch binds to guanine with 100,000-fold greater affinity than it does to adenine, a remarkable feat considering the close chemical similarity of the two purine substrates The overall architectures created by these two riboswitches are surprisingly similar and resemble small RNA enzymes (ribozymes) The riboswitches described in this issue demonstrate how RNA overcomes its limited chemical diversity by adaptively folding into remarkably complex architectures to create highly specific binding pockets The similar mode of substrate recognition observed in diverse riboswitch classes suggests a common functional mechanism, whereby conformational adaptability enables the RNA to encapsulate the substrate The structure of a TPP-sensing riboswitch in plants has also been reported elsewhere  The TPP-sensing structures show that RNA recruits positively charged metal ions to mediate otherwise unfavourable electrostatic interactions, resembling the use of metal ions to glue together other RNA structures  The traditional view of RNA as a passive messenger in the transfer of genetic information has long been abandoned The two structures presented in this issue provide even more remarkable examples of RNA molecular recognition These regulatory RNA domains are typically located in regions of mRNA that directly precede the protein-coding sequence These RNAs are evolutionarily ancient, and are widespread in bacteria, plants and fungi These RNAs — known as riboswitches — elegantly couple metabolite recognition with gene regulation in the absence of protein helpers They use a simple modular architecture — a metabolite-sensing domain recognizes the substrate, and another region, known as the gene-expression signal, regulates protein production in response to substrate binding This exquisite molecular recognition is accomplished by completely encapsulating the substrate in the riboswitch, surrounding the substrate with specific RNA contacts This regulation responds to changing levels of the metabolites in the cell, a type of feedback mechanism that was previously known to be mediated only by proteins This similarity has fuelled interest in riboswitches as attractive targets for antibacterial drugs, particularly because there is an apparent absence of such RNA systems in humans Unfortunately, these RNAs may be surprisingly proficient at developing drug resistance When riboswitches were first discovered, two questions immediately arose: how is the metabolite recognized, and how does binding of the substrate trigger genetic regulation? Preliminary answers were provided by the structures of guanine- and adenine-sensing riboswitches — guanine and adenine are organic bases collectively known as purines When the substrate binds to the metabolite-sensing domain, a structural reorganization of the RNA occurs that unveils (or sometimes masks) the gene-expression signal Yet every few years we are still surprised by the discovery of another function that RNA performs
 A minute or two after the heat is applied, neutron emission starts, reaching a peak of about 1,000 per second; once the heat source is removed, the device gradually switches itself off A solid target containing deuterium in the form of erbium deuteride (ErD 3 ) was placed a few centimetres in front of this electrode Although this output is too small for most applications, the authors outline plans to increase the yield to a million neutrons per second, comparable to that of some commercial portable neutron generators As a result, portable neutron generators have found a wide range of applications, including well-logging for oil exploration, and the screening of baggage for airline security As the potential rose, the field near the tungsten electrode increased to a value — around 25 gigavolts per metre — sufficient to produce field ionization of the deuterium gas Field ionization of gases occurs when a potential difference of a few volts exists over atomic distances — equivalent to a field greater than 10 gigavolts (1×10 10 volts) per metre Figure 1 shows how Naranjo et al . combined these effects to generate fusion neutrons In both cases high-voltage power is required, and the apparatus is fairly complex Indeed, in some ways it is remarkably low-tech — the only input is a few tens of volts, to bias an electron-suppression grid, and some gentle heat (around 2 watts) Modest voltages applied to electrodes of very small radius can produce these extremely high fields near the electrode tips, ensuring the ionization of essentially all gas molecules entering the high-field region More recently, various man-made materials have been investigated, and potentials of around 100,000 volts reported for crystals such as lithium tantalate (LiTaO 3 ), with the emission of energetic electrons under suitable conditions Neutrons can penetrate significant quantities of matter, and interact primarily with the nucleus rather than the electronic structure of an atom Nevertheless, even at the level already attained, there are laboratory uses, such as measuring neutron detector response or for student practical demonstrations, for which a simple, inexpensive, monoenergetic neutron source would be most valuable. On hitting the target on the opposite wall of the device, the energetic deuterons interacted with the deuterium target to produce 2.5-MeV neutrons via the D+D reaction On page 1115 of this issue, Naranjo, Gimzewski and Putterman report the successful demonstration of an intriguingly simple neutron generator that produces neutrons possessing an energy of 2.5 mega-electronvolts (MeV) from reactions involving the fusion of two nuclei of deuterium Raising the temperature of the crystal at a rate of 12.4 °C per minute changed the spontaneous polarization of the crystal, and raised the potential of the positive electrode at a rate of about 50 kilovolts per minute Several commercial devices are available that use fusion reactions of deuterium (D) and tritium (T), whose nuclei contain one and two neutrons respectively (ordinary hydrogen nuclei have none) The accelerating potential can be maintained only while the crystal temperature is changing; thus, the duration of the pulse at this current level was limited to a few minutes by the attainable temperature rise The authors grounded one face of a 1-cm-thick pyroelectric crystal to the inside of a vacuum chamber containing deuterium gas at a pressure of 0.7 pascals (for comparison, Earths atmospheric pressure is around 10 5 pascals) The device reported by Naranjo et al . falls into the solid-target category, only without much of the complexity The effect is widely used as the basis of field-ion microscopy The key to the devices simplicity lies in the replacement of the miniature ion-source and accelerator in existing generators by a system based on a combination of two well-known phenomena — the pyroelectric effect and field ionization The maximum current obtained in this experiment was about 4 nanoamperes, leading to a maximum neutron production rate of around 1,000 neutrons each second The positively charged ions (deuterium nuclei, or ‘deuterons’) produced in this process were accelerated towards the target across essentially the full potential generated by the crystal; the electrons stripped from the deuterium atoms by the ionization experienced a potential drop of only a few volts as they fell back to the crystal The pyroelectric effect — the fact that some materials become charged when heated — was probably first recorded in 314 BC by Theophrastus , Aristotles student and successor, from his studies of the gemstone tourmaline The reactions generate helium and a single neutron that carries away most of the reaction energy: D+D→ 3 He+n (energy ∼2.45 MeV) These neutron generators rely either on an ion beam from a miniature accelerator producing reactions in a solid target loaded with deuterium and/or tritium, or on the electrostatic confinement of a D–D or D–T plasma They then attached a tiny tungsten electrode to a plate on the positive face of the crystal This device, it must be stressed, will not generate net energy, and is not related to past controversies about ‘cold fusion’ This effect was used by Brownridge to produce a small pyroelectric X-ray generator, of which a commercial version, powered by a 9-volt battery, is now available 
 A US embargo was denying them the necessary technology, so Soviet agents resorted to covert methods to obtain it, while the CIA did all it could to thwart them At the time I was surprisedand shocked to discover that US industrywas deliberately producing products with a short lifespan By the late 1950s, GM cars had become chrome-finned monstrosities and the US public went to the other extreme, beginning to buy small cars, such as the Volkswagen Beetle, that were built to last For a decade now that is what has kept the wheels of industry turning, at least in China. He also has a chapter on the introduction of nylon, but he misses a chance to explain how the hosiery industry, faced with apparently everlasting stockings and tights, introduced obsolescence by making the thread so fine it broke easily He proposed it as a possible solution to the Depression, which was being made worse because people had stopped buying I suspect it disappeared 20 years ago because it was no longer needed In fact many affluent people wanted an excuse to buy a new car, and by realizing this and pandering to it, General Motors (GM) was to become the worlds largest company In the 1970s and 1980s the Soviet Union was falling behind the United States in the manufacture of microchips and computers, yet it needed them if it was to exploit and export its vast reserves of oil and gas to earn desperately needed foreign currency In the late 1920s they began to boost sales by launching a new model every year, even if it was merely a style change It worked — but it went too far Londons suggestion was at variance with the idea of the father of mass production, Henry Ford, who assumed that people would obviously want cars to last — and a 15 million Model Ts had shown that the idea had its appeal Made to Break is both entertaining and thought-provoking, but finally somewhat unsatisfying in that it does not say whether planned obsolescence is still with us Made to Break is not just about planned obsolescence; indeed, it is more about the unplanned obsolescence that technological development brings One failure burst an oil pipeline, creating a lake more than 10 kilometres long and2 metres deep before it was brought under control Perhaps it will re-emerge this century if the new method that keeps us spending — unlimited credit — fails Planned obsolescence had become self-defeating Planned obsolescence it was called, but little did I realize that this was tobe the secret weapon that won the Cold War for the United States Planned obsolescence looked like the solution to economic stagnation in a world with abundant natural resources and unemployed labour Slade tells the tale of the early days of FM radio and how the emerging television industry commandeered its broadcast frequencies, making all FM radios of the 1940s obsolescent That little-known story is one of the intriguing Made to Break s hidden gems The phrase planned obsolescence was first used by Bernard London in 1932 The result was a series of spectacular explosions, some so large that they were observed by satellites The subtitle of Giles Slades Made to Break suggests that the book is an update of Vance Packards The Hidden Persuaders (Longmans, 1957), which I remember reading as a student in the 1960s Then Gus Weiss, an economist and government security adviser, made an ingenious suggestion: allow the Soviet agents to succeed, but make sure they bought specially doctored microchips that looked like the real thing but had inbuilt obsolescence This inbuilt obsolescence included sudden catastrophic malfunctioning, such as suddenly instructing a pump to work at a pressure far higher than a pipeline could withstand This industrial sabotage ensured that the Soviet Union lost the cold war says Slade, and he makes it almost believable Today we have technological obsolescence on a large scale — witness the dumping of PCs in favour of laptops — and the book ends with a chapter on mobile phones, where technological obsolescence is such that some users upgrade every year
 A final decision will be made at UNESCOs executive board meeting in April Although other projects exist to help geoscientists in developing countries (see Nature 433 , 449 ; 2005 10.1038/433449a ), geologists say that the community will be sad to see one of the most established programmes cut. “Almost all of the impact will be on scientists from developing nations,” says Douglas Erwin, a palaeontologist at the Smithsonian Institutions Museum of Natural History in Washington DC. “It is short-sighted for UNESCO to do this.”  Additional reporting by Rex Dalton, San Diego. And according to information leaked to Nature , UNESCO is to cut annual funding to the IGCP, currently about US$200,000, by almost half from 2006 But changes are afoot But he adds that geologists would have much to contribute to such work He says UNESCOs science activities are focusing on water and ecology, following a reduction in the total budget for 2006 It has long been seen as the star of the Earth-sciences division of the United Nations Educational, Social and Cultural Organization (UNESCO) Members of the IGCPs scientific board issued a joint communication last week appealing to UNESCO to maintain current levels of funding. “Drastic cuts would be demoralizing,” says Muhongo Munich Geoscientists are protesting against proposed cuts to a small but successful international Earth-sciences programme Since 1972, some 500 regional geological and mining-related projects in 150 countries have received seed funding of up to $10,000 from the IGCP The IGCP should still receive about $90,000 a year from the International Union of Geological Sciences The International Geoscience Programme (IGCP), which provides seed money for local projects, has helped thousands of geologists from developing countries to coordinate their work and liaise with colleagues around the world This focus is fine, says Sospeter Muhongo, a geologist at the University of Dar es Salaam in Tanzania and newly elected chairman of the IGCPs scientific board Walter Erdelen, UNESCOs assistant director-general for natural sciences, confirmed that there are plans to substantially reduce the programme, although he would not say by how much When UNESCOs Earth-sciences director retired in November he was not replaced
 According to this idea, the mean density of matter in the cosmos remains constant; the Universe has no beginning, no end and no age Although coronal heating is now known to come from the dissipation of energy propagating outwards from the Sun, the resulting coronal expansion — the ‘solar wind’ — is most simply described by changing the boundary conditions in Bondis spherical accretion model to yield an analogous flow with opposite sign Although he could be ruthless when confronted with flawed arguments, whatever their source, he respected the intellectually honest opponent working from different axioms An earlier paper, written with Hoyle and Lyttleton, had argued that gravitational energy released by accreted gas heats the corona of the Sun to more than a million degrees As a schoolboy in Vienna he showed precocious mathematical ability, and decided that he wanted to work with the renowned mathematician and astronomer Arthur Eddington at the University of Cambridge As a scientific adviser to successive British governments, he also contributed immensely to the public life of his adopted country Bondi also applied his mathematical skill to various problems in cosmic gas dynamics Bondi arrived at the universitys Trinity College in 1937 Bondi believed strongly in the social responsibility of scientists, and so was active in the Pugwash movement and the scientific education of the public Bondi remained true to Popper, and gave up the steady-state hypothesis in the face of increasing conflicting observational evidence, such as the discovery in 1965 of the cosmic microwave background radiation, which the steady-state hypothesis could not easily explain Bondi was born in Austria to Jewish parents Bondis legacy in this area is his superbly written monograph Cosmology , and a series of papers on general relativity, especially on gravitational radiation Bondis motivation came in part from observational difficulties then besetting the rival Big Bang cosmology (to use Hoyles intentionally pejorative term), but also from his conviction that an acceptable cosmology must satisfy Machs principle, which relates local inertial effects to the global properties of the cosmos Bondis parents and sister followed his cabled advice to “drop everything and leave”, settling eventually in New York; he himself, an anglophile, remained based in England for the rest of his life Bondis student, Roger Tayler, exploited their technique further in a thesis that foreshadowed the now established picture of stellar evolution through nuclear processing from the main sequence to the giant branch But as an astrophysicist, mathematician and cosmologist, his interests were wide-ranging and his intellectual brilliance undoubted But Bondi is undoubtedly best known for his partnership with Hoyle and Gold in the advocacy and detailed study of steady-state cosmology But he also began a parallel life as a high-level public servant, becoming director-general of the forerunner of the European Space Agency, the Paris-based European Space Research Organization, in 1967 Equally, one ‘fact’ that cast doubt on evolutionary cosmology — the ages of the oldest stars apparently exceeded the estimated age of the Universe — disappeared in 1952 with Walter Baades doubling of the cosmic distance scale From 1951, Bondis academic career continued at Kings College London, and culminated in his election in 1983 as master of Churchill College, Cambridge From 1982 to 1999 he was president of the British Humanist Association He favoured steady-state cosmology because it was ‘vulnerable’ — it made precise predictions that were falsifiable, in Poppers sense of the word He showed little interest in the subsequent revised versions proposed by Hoyle and his collaborators He will be much missed, as both a public servant and a private man. Hermann Bondi, who died on 10 September aged 85, is perhaps best known as one of the original advocates of the steady-state theory of the Universe, advanced as an alternative to the now dominant Big Bang theory His philosophy of science was strongly influenced by Karl Popper In a subsequent wide-ranging career in Britain that was testament to both his intellectual and his organizational abilities, he was successively chief scientific adviser to the Ministry of Defence, chief scientist to the Department of Energy, where he laid the groundwork for Britains first long-term energy policy, and chairman of the Natural Environment Research Council In Canada, he met a fellow Viennese internee, Thomas Gold, who became his lifelong friend and collaborator In March 1938, German troops entered Austria and Anschluss was proclaimed In particular, he wrote an elegant paper on the spherically symmetric, pressure-limited gravitational accretion of interstellar gas by a star at rest in a gas cloud In the late 1930s, Hans Bethe and Carl-Friedrich von Weizsäcker had shown that, at the high temperatures inside stars, energy liberated from the nuclear fusion of hydrogen to form helium could supply stellar luminosity In the panic following the collapse of France in 1940, Bondi was interned on the Isle of Man and then in Canada In this model, the expansion of the Universe — inferred by Edwin Hubble from the redshifted spectral lines of distant galaxies — is exactly compensated by the continuous creation of matter It was this trios off-duty discussions on astronomy that were to bear fruit when they returned to Cambridge at the end of the war On their return to Britain in 1941, Bondi and Gold joined the Admiraltys radar research group, led by Fred Hoyle One of his greatest achievements was his report written after the 1953 floods that devastated parts of eastern England, which ultimately led to the construction of the Thames Barrier to protect London from storm surges The list of concepts that bear his name shows his influence: the Bondi news function, the Bondi mass, Bondi waves, the Bondi–Metzner–Sachs group and the Tolman–Bondi universe This led Hoyle and Ray Lyttleton to a reappraisal of the physics and mathematics of stellar structure developed by Bondis hero Eddington This puritanical stance was tempered by his appreciation that incontrovertible observational facts were often hard to find This was a time of momentous advances in astrophysics Thus he pointed out that the mass of Capella, used by Eddington to calibrate his stellar mass–luminosity relation, had since been revised Together with his wife Christine — one of Hoyles doctoral students — Bondi transformed these equations, so simplifying the construction of stellar models, especially those of chemically inhomogeneous stars With typical resourcefulness, he helped set up a camp university at which he gave lectures on mathematics
 A bank spokesman accuses Attaran of “waging war against the bank”, The spokesman claims that Attaran refused a 2002 invitation to discuss the issue with bank officials. And Basu insists that the bank is working closely with the World Health Organization (WHO) to ensure that the treatments it funds are recommended ones Attaran et al  Bank officials admit that their initial drive was unsuccessful, partly because they did not receive as many applications from African governments as they expected Basu describes the allegations as “flat wrong” But Attaran and his co-authors retort that the bank should stop trying to lead global efforts against malaria and instead turn its funds over to dedicated health agencies such as the Global Fund to Fight AIDS, Tuberculosis and Malaria. “If you woke up with a fever, you wouldnt ring your bank for help,” Attaran says. “The World Bank is great at being a bank, but bad at being the worlds doctor.”  In 2004, Attaran criticized the US Agency for International Development over the handling of its $90-million malaria budget (see Nature 435 , 257 ; 2005 10.1038/435257b ), and he has argued angrily with World Bank officials in the past But Attaran complains that the bank, which has an annual tax-funded budget of $20 billion, initially promised to raise all the funds by itself But the banks critics point out that by 2005, no more than $150 million had been provided. “In 2000, they made the largest ever promise to spend money on malaria in Africa,” says Amir Attaran, a law professor at the University of Ottawa, Canada, and lead author of a commentary that sets out the criticisms in this weeks issue of The Lancet (A But they point out that the 2005 pledge, which aims to help the global Roll Back Malaria initiative hit its 2010 target of halving malaria cases, is already making progress. “These criticisms are a year out of date,” Suprotik Basu, a member of the banks malaria team, told Nature  Charges levelled More seriously, Attaran and his colleagues accuse the bank of massaging figures from previous malaria projects in Brazil and India to make them seem more successful Data used to compile the banks figures, given to Attaran upon request, came from peer-reviewed studies, and were neither collected nor doctored by the bank He says that, since the effort was relaunched last year, projects worth a total of $190 million have been approved in Eritrea, Niger, Zambia and the Democratic Republic of Congo, and that the total will stand at $400 million by July next year It will broker deals with other banks and with non-government organizations such as the Seattle-based Bill and Melinda Gates Foundation to raise the remainder of the cash Lancet doi:10.1016/S0140-6736(06)68545-0; 2006). “Its now 2006, and they have broken that promise.” The commentary is co-authored by 12 epidemiology and public-health experts, from Africa, Europe and North America Last year, the World Bank made a fresh pledge to implement global antimalaria schemes worth up to US$1 billion over the next five years Resistance to chloroquine is rife among P. falciparum , but Attaran says that, in areas of India where both forms are prevalent, patients are treated with the drug anyway, with partial success. newsad; Basu insists that this is in accordance with WHO recommendations The bank pledged in 2000 to make between $US300 million and $500 million available to African governments for antimalaria treatments and infrastructure The bank will provide roughly half of the money itself The World Bank has been forced to rebut a series of stinging criticisms from public-health commentators They also charge it with endorsing treatment options in India that will leave millions exposed to resistant forms of the disease They have accused it of failing to fulfil its promise to provide funds and leadership for Africas fight against malaria This weeks accusations mark the latest chapter in an acrimonious battle between the bank and a group of advocates who think it should hand the pledged funds over to agencies that, they argue, have greater public-health expertise Whereas most malaria in Africa is spread by the Plasmodium falciparum parasite and ideally treated using drugs called artemisinins, around half of Indias cases are caused by P. vivax , and can be treated using the much cheaper drug chloroquine
 A wiki on gene function would make life very much easier for biologists A wiki on gene function, which utilizes the collective brain power of biologists around the world, would be an invaluable tool for biological sciences. After a microarray experiment or a BLAST search, hundreds or thousands of interesting gene names are revealed, but the average biologist has no clue as to the function of most of them As a frequent user of Wikipedia and also a biologist, I hope that one day a wiki on gene function will be voluntarily created and maintained by biologists But although many short statements have accumulated in this database, it would be useful to have concise summaries compiled by experts, and these are not usually available But the information is collected from highly heterogeneous experimental and computational data sources, so the annotations often lack confidence measures Concise and accurate gene-function annotations compiled and edited by human experts are preferable in many cases Following up with a literature search wastes a lot of researchers time and energy In addition, the entries in these gene-function databases — unlike those in Wikipedia — cannot be conveniently commented on or edited by average biologists It would also be more accurate, as long as statements are accompanied by references Several gene-function databases already exist, but each has certain disadvantages for the average biologist Sir Your Special Report “Internet encyclopaedias go head to head” ( Nature 438 , 900 – 901 ; 2005 ) shows that Wikipedia comes close to Britannica in terms of the accuracy of its science entries Such a wiki would also be less susceptible to spam, as most users would be biologists The Entrez Gene database ( http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene ) contains a Gene Reference Into Function, or GeneRIF, that allows users to submit statements with supporting literature references to annotate gene function The Molecule Pages for signalling proteins ( http://www.signaling-gateway.org/molecule ) and the OMIM database for human inherited diseases ( http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=OMIM ) both rely heavily on community input, but are both limited to special-interest groups The UniProt Knowledge Base ( http://www.uniprot.org ) provides an integrated view of gene functions This discourages input from many potential contributors
 Another implication of the ethics rules became apparent last month when three top NIH officials — including Tony Fauci, director of the National Institute of Allergy and Infectious Diseases — were introduced by name, but not affiliation, at a dinner held by the lobby group Research!America But critics say it is going too far But he says the sometimes arbitrary rules are just something that researchers should learn to live with. “It is very hard for a large organization to have common sense,” he says. “You just accept it.”  But researchers may soon have to accept even more of it: last month the NIH published tighter conflict-of-interest rules (see Nature 434 , 3 – 4 ; 2005 ) He adds that their implementation will “limit the ability of NIH scientists to engage in critically important teaching and scholarly activity.” Holli Beckerman Jaffe, an attorney who directs the NIH ethics office, explains that only plaques of “little intrinsic value” are permitted It is supposed to prevent lobbyists from corrupting the agency and to guard against insiders exploiting the system for personal gain San Diego Is an honorary plaque costing little more than $25 enough to cause a conflict of interest for a US National Institutes of Health (NIH) administrator? The biomedical research agencys ethics office certainly thought so last year when it advised the National Postdoctoral Association (NPA) that it could spend only $25 on an award plaque for Ruth Kirschstein, the former acting director of the NIH Thats certainly what Alyson Reed, director of the Washington-based NPA, thought when her young organization sought to present Kirschstein with its inaugural Distinguished Service Award. “We had a hard time finding a plaque that cheap,” says Reed The $25 was probably a rough estimate made by an office staffer, she says The ethics office, which deals with issues at the 27 NIH institutes and their 18,000 employees, faces a tough challenge The steady flow of such anecdotes is beginning to irk researchers both inside and outside the NIH. “Its madness,” says John Hardy, chief of the neurogenetics lab at the National Institute on Aging These are already under attack from organizations such as the Federation of American Societies for Experimental Biology (FASEB). “Many of the rules are overly restrictive,” says Paul Kincade, president of FASEB
 But although the panel is likely to act as a safe haven for whistle-blowers, it will not itself investigate misconduct allegations But even as details of the plan are being finalized, its architects have generated controversy by saying that they would consider accepting funding from the pharmaceutical industry Critics also fear that the proposed UK Panel for Health and Biomedical Research Integrity — which will operate under the umbrella of Universities UK (UUK) — may lack the teeth to police research properly If UUK approval is secured next month, Pritchard expects panel members to be nominated in May and to start work by October It has the approval of the government, and the Department of Health is currently helping to select the first panel members John Pritchard, a senior policy adviser at Sheffield Hallam University who is working on the plans on behalf of UUK, says the panel will instead advise institutions on how to run inquiries and nominate participants. “Id like to see a rigorous system of investigation and enforcement,” says Brian Gennery, president of the Faculty of Pharmaceutical Medicine at the Royal Colleges of Physicians, one of the first UK organizations to promote the need for a research-integrity watchdog. “Then I would have much more confidence in this new body.”  Some organizations established elsewhere to oversee research integrity, such those in Denmark and the United States, have the power to run their own inquiries London British biomedical science is to get its first watchdog Plans to establish the panel should be completed next month at a board meeting of the UUK, which represents most of Britains higher-education institutes Pritchard declined to comment on this issue until details of the plan have been approved by UUK, saying only that the whistle-blower facility alone would have a positive effect on subsequent investigations by employers Pritchard discussed the plans on 11 March at a London meeting of the Committee on Publication Ethics, an association of journal editors Pritchard says no decision on funding has been taken, but adds that the pharmaceutical industry is a major funder of biomedical research and it would be a mistake not to engage with them. “Theyre a stakeholder,” he says. “It will be a missed opportunity if their responsibility is put aside.” She points out that the behaviour of the industry is currently under investigation by parliament following claims that some firms failed to publish sensitive research (see Nature 429 , 793 ; 2004 10.1038/429793b ). “This is not the right time to jump into bed with them,” says Heath The body will initially cover all biomedical research in universities and the National Health Service The idea of the panel has been spearheaded by Michael Farthing, principal of St Georges Hospital Medical School in London The need for an independent body to oversee investigations of misconduct, such as plagiarism and fraud, has been made clear by several science organizations in recent years The panel will also develop a non-mandatory code of conduct for biomedical researchers and raise awareness of misconduct through local events The panel would initially be established for a three-year period, pending a review of its performance When Pritchard mentioned that UUK was considering accepting funding from a range of sources — including the pharmaceutical industry — some delegates responded angrily. “How will pharmaceutical sponsorship square with public confidence in this body?” asks Iona Heath, a London-based general practitioner and chairwoman of the British Medical Journal s ethics committee
 In the News and Views article “Hydrogen at the flick of a switch” by Masanori Takimoto and Zhaomin Hou ( Nature 443 , 400 – 401 ; 2006 ), the e-mail address for Zhaomin Hou was incorrect The correct address is houz@riken.jp
 A 23 February article in The New York Times , for instance, questioned whether a planned clinical trial to use human embryonic stem cells to treat spinal injury is going “too far, too soon into uncharted territory” Although the US Congress has recently considered the question of loosening federal rules , the regulations currently limit federal dollars to work on the 78 human embryonic stem-cell lines created before August 2001 And although Hall says that the CIRM plans to import many NIH procedures, the institute and the other state funding mechanisms are still unknown entities. “The less the NIH is involved in something, the less assurance we have that good ethical guidelines are followed,” observes Jon Retzlaff, director of legislative relations with the Federation of American Societies for Experimental Biology And biologists are divided on its likely consequences And he makes no secret of his hope that stem-cell research will help his 14-year-old son, who has juvenile diabetes And the agencys first awards are expected to be for academic institutions across California to hire graduate students and postdocs. “What were calling for here is a vast expansion of the intellectual and scientific workforce,” says Hall And this, some biologists argue, makes it unwise to pour hundreds of millions of dollars into this area any time soon. “A lot of money could be wasted on what is not the best work,” warns Sean Morrison, a stem-cell biologist at the University of Michigan in Ann Arbor And this, some researchers fear, may be set for a backlash Assuaging these concerns will test Kleins powers of persuasion Biologists also want to investigate the basics, such as how stem cells arise in the developing embryo, and which signals coax them into developing into different tissue types. “I think everybody agrees that more fundamental work needs to be done,” says Evan Snyder, a stem-cell biologist at the Burnham Institute in La Jolla. “This is an initiative to move the field forward in an unencumbered way.”  Researchers will have to be careful to ensure that work involving non-approved cell lines is strictly separated from projects involving federal grants Biologists welcome this emphasis on bringing young researchers into the field Bob Klein is a man in a hurry But Klein wants to avoid delay, by leasing space lying empty in the San Francisco Bay Area and other cities. “There are lots of opportunities,” he says But setting up a new research agency demands the skills of a consummate scientist–administrator, which he is not But some are anxious about the CIRMs wider effects on the US funding landscape But some question whether the CIRM can spend the huge sums at its disposal without wasting money on second-rate research But such subtleties were lost in the frenzy of the campaign But the deeper concern is that the Bush administration and its congressional allies will let the states take the lead, and scale back funding for the NIH But theres no doubting his personal commitment to the cause Disappointment could result if treatments fail to emerge rapidly, or if patients suffer adverse events in clinical trials — as has happened in the field of gene therapy . “I think there was a concern about promising too much, even before Proposition 71,” says Gordon Keller, a stem-cell biologist at the Mount Sinai School of Medicine in New York. “My fear is that there are people who will try to move forward quicker than they should, and that could backfire very badly.”  The media are already alert to this possibility Everyone is dying Firm foundations Klein adds that researchers have difficulty winning grants from the NIH in a young field such as stem-cell research, as its difficult for them to gather enough preliminary data to make a case for serious study. “Some of the brightest minds cannot get access to funding,” says Klein For one thing, state activity is likely to provoke opponents of embryonic stem-cell research in the federal government into further action. ‘Pro-life’ conservatives in the US Congress will almost certainly resume legislative attempts to ban all human cloning procedures, whether for reproduction or research Hall has already begun to temper Kleins enthusiasm with a dose of caution, noting that the practical challenges of setting up a review process rule out the initial goal of approving some grants in May. “We still dont have our working groups appointed,” says Hall. “In the fall we might be able to approve our first grants.”  The CIRMs main goal is to support research that either cant be backed by the federal government, or is unlikely to receive “timely or sufficient” funding Having made his fortune providing quality low-cost housing in the state, Klein ploughed $3 million of his own money into the Proposition 71 campaign Headhunters are still drawing up a shortlist of candidates for the key position of president of the CIRM Hope or hype? Another worry about putting stem-cell research in state hands is that it may be more vulnerable to the ebb and flow of public opinion Im just dying a little faster.’ For a father, thats not something you can live with.”  Kleins heart-on-sleeve demeanour and boundless energy were just what was needed in winning support for Proposition 71 In addition to investigating the feasibility of ‘therapeutic cloning’, in which a patients own cells might be used to derive grafts to replace damaged tissues, cloning can be used to create embryonic cell lines from patients with genetic diseases — which could prove invaluable for understanding these conditions and testing potential treatments  In the interim, the post has been taken by Zach Hall, whose previous roles include directing the National Institute of Neurological Disorders and Stroke in Bethesda, Maryland In the long run, the CIRM may provide funding to build new labs to help this separation Indeed, some researchers who are gearing up to receive CIRM funding feel a heavy burden of responsibility. “A lot of people do feel accountable here in California,” says Fred Gage, a stem-cell researcher at the Salk Institute for Biological Studies in La Jolla. “We want to make sure that its done right, because were under the microscope.” Indeed, with several other states following Californias lead and providing budgets for stem-cell research (see map, below), an unprecedented shift in the balance of power is under way Institute officials say that maintaining quality will be their priority, adding that their efforts wont be entirely focused on embryonic stem cells Interviewed by Nature in late February, he was determined to press ahead as soon as possible: “My goal would be to approve the first grants in May.”  But today Klein and his supporters are wrestling with the practical realities of building their multibillion-dollar research agency, called the California Institute for Regenerative Medicine (CIRM), from scratch, while fending off political and legal attacks from both long-standing opponents and former allies Its already clear that Kleins May deadline will be missed by several months Keirstead took a prominent role in the Proposition 71 campaign, discussing unpublished experiments in which spinal-injured rats were made to walk again. “It has never been my intention to contribute to the hype,” says Keirstead, who stresses that he doesnt expect to see similarly dramatic results in human patients Klein recalls a 2002 conversation with his son: “He said, ‘Dad, dont worry about me Many biologists are concerned about the implications of the NIH having a reduced role in stem-cell research Many of the lines that seem most promising for research were isolated after this date Maybe so, but experts in the field point out that relatively few researchers currently have expertise in working with human embryonic stem cells Meanwhile, state senators Deborah Ortiz, a Democrat, and George Runner, a Republican, have said that they will press for a new ballot initiative to “reform” the stem-cell programme Ortiz backed Proposition 71, but has since criticized the initiatives procedures for accountability and avoiding conflicts of interest Others worry that the initiative has set a dangerous precedent by moving the centre of gravity of an important area of biomedical research away from the federal government, and subjecting it to the shifting winds of state electoral politics Researchers also say they need new cell lines that havent been grown on a layer of mouse cells, as this causes biochemical contamination that will rule out their eventual use in human therapies  So part of the CIRMs strategy will be to provide ‘seed’ money to allow researchers new to the field to gather sufficient results for a convincing full grant application So the CIRMs top priorities will include the creation of new embryonic stem-cell lines, mostly from embryos left over from in vitro fertilization procedures, but also from embryos created by cloning Some also fear a public backlash against stem-cell research, as claims about ‘cures’ made during the ballot campaign may have left people with unrealistic expectations Some Californian stem-cell researchers say that they are now planning outreach activities to help manage public expectations Stem-cell biologists are looking forward to the injection of funds, whenever it finally arrives The agency might also choose to back specific therapeutic strategies that have been neglected by the federal National Institutes of Health (NIH), Klein argues The agencys budget is already under pressure, given Bushs programme of tax cuts and the cost of the Iraq war, and the biomedical research community knows that it cant expect many favours. “I am worried that the willingness of states to take up the slack is going to absolve the federal government of its responsibilities in this area,” says George Daley, a stem-cell researcher at Harvard Medical School in Boston The CIRM will support work on adult stem cells, and fund research into other questions that must be addressed to bring stem-cell therapies to the clinic The CIRMs legal and political difficulties centre on its governance, which is unusual for a state agency The committee, chaired by Klein, includes representatives of the biotech industry and academic institutions likely to receive CIRM funding The stem-cell ballot initiative, known as Proposition 71, placed the agency under the control of a 29-person citizens committee with little input from Californias legislature The trial, which could begin next year, is based on the work of Hans Keirstead of the University of California, Irvine, who has shown that embryonic stem cells can be made to differentiate into cells that help to maintain and protect neurons  The use of the slogans “cures for California” and “save lives with stem cells” during the Proposition 71 campaign may have set public expectations too high, they say These have been denied a hearing in the California Supreme Court, but the battle will resume in lower courts, and could yet interfere with the institutes plans to begin distributing money They respect the federal agencys procedures for backing scientific excellence and adhering to rigorous ethical standards This energetic 59-year-old entrepreneur rose to public prominence last year, spearheading the campaign that convinced Californias voters to back an audacious plan to create a $3-billion public fund to advance research on human stem cells Under attack Lawsuits have been filed denouncing the CIRM as unconstitutional With other states pitching in, the momentum in stem-cell research is shifting away from the federal government — and opinion is divided on whether thats a good or a bad thing. “This represents a paradigm shift in how biomedical research gets funded in this country,” says Snyder. “It could turn out to be a really wonderful opportunity.” But other biologists see potential threats
 Although this correlation is not perfect, the time cost to the UK research community of conducting the RAE is not justified by the difference As someone involved in the review of research grants in the United Kingdom, I have found that research income — at least in the case of government research councils, and probably also for charities and industry — is highly dependent on previous and proposed research outcomes For example, if comparisons were made at the full departmental level, biology departments would be rewarded for dumping their field researchers in favour of molecular or cell biologists, and computer science departments for dumping theory of computation in favour of robotics. Funding proposals require a brief biography listing previous outcomes as well as a list of expected outcomes and dissemination strategies, both of which reviewers are asked to assess Further, interdisciplinary researchers who contribute to more than one literature will no longer be disadvantaged Perhaps this is why previous runnings of the Research Assessment Exercise (RAE) have shown a strong correlation between research income and RAE score, at least in disciplines such as science, which require substantial grant income Sir Christopher Exley, in Correspondence (“Funding should recognize outcome, not income”  Nature 440 , 1112 ; 2006 10.1038/4401112c ), criticizes the use of research income as a metric of science somewhat unjustly The main concern is that comparison must be done on a sufficiently narrow scope so that different branches of disciplines do not lose political clout if their research is relatively inexpensive
 100 YEARS AGO A description of the large diamond found recently in the Premier Mine, Transvaal, is given in the Geological Magazine (April) by Dr A ALSO: In proposing the toast of “The Japan Society” at its annual dinner on May 3, Sir Frederick Treves referred to the medical and surgical ability of the Japanese Corstophine, with reproductions of four photographs which represent the diamond in its actual size from four different points of view.. F For a large stone the crystal is of a remarkable purity.. From Nature 11 May 1905. 50 YEARS AGO In 1947, Evans and Guild described a technique for the quantitative extraction of earthworms G H Hatch and Dr I found, however, that population estimates obtained by the permanganate technique were considerably lower than those suggested when a more laborious hand-sorting method was employed In order to measure the relative efficacy of these techniques, permanent pasture on light soil of alluvial origin was sampled by both methods contiguously.. J Nothing astounded him more, he said, in his recent visit to Japan than the way in which the Japanese have inquired into the medicine and surgery of the western world and the marvellous thing they are making of it.. S Sir F Svendson From Nature 14 May 1955. The Japanese have all the qualities of a surgeon The method was said to recover a high proportion of the total population.. The stone is bounded by eight surfaces, four of which are faces of the original crystal, and four are cleavage surfaces, which are distinguished from the original octahedral faces by greater regularity and smoothness The stone, which has been named the Cullinan diamond, weighs 9600.5 grains troy, or 1.37 lb. avoirdupois; this is more than three times the weight of the largest diamond previously known They have infinite patience and infinite tenderness This consisted of treating a known area with a solution of potassium permanganate (1.5 gm. per litre) at the rate of 6.8 litres per sq. metre Treves is confident that not many years hence there will be seen in Japan one of the most progressive schools of medicine the world has ever known While the fifty soil cores... produced 639.5 worms, the permanganate samples... produced only 350 worms
 But engineers are worried that Vinogradovs hook could lodge the ball in a solar panel or other piece of vital equipment It will then use the beasts as tourist attractions Louis Post-Dispatch Scorecard Rampaging elephants Sri Lanka announces plans to tame, rather than kill, unruly wild elephants NASA wouldnt comment on Vinogradovs handicap, saying only that the swing would be put off for a more thorough safety analysis. On the Record “Carbon dioxide Overhyped A golf shot round the world newsad; NASA mission planners have delayed a spacewalk to drive a gold-plated golf ball into low Earth orbit Rabbit romance Urologists develop prosthetic penises for male bunnies Race of the clones The first cloned equines — two mules called Idaho Gem and Idaho Star — are ready to run against each other, and others, in competitive mule races Sources: CEI, St The implants could have human applications, too The publicity stunt, sponsored by Canadian golfing firm Element 21, would have made International Space Station Commander Pavel Vinogradov a sporting celebrity They call it pollution Tracking whales University of Washington researchers are training failed drug-detecting dogs to sniff out the floating faeces of endangered killer whales We call it life.”  Television adverts from the Competitive Enterprise Institute — a group that receives funds from the oil industry — imply that rising levels of CO 2 are nothing to be alarmed about. “The ads are a deliberate attempt to confuse and mislead the public.”  Curt Davis of the University of Missouri, Columbia, criticizes the institute for misusing his findings on the East Antarctic ice sheet
 Ab initio calculations, corroborated by Raman measurements, strongly suggest that doping is substitutional Although the local resistivity of semiconducting silicon in its standard crystalline form can be changed by many orders of magnitude by doping with elements, superconductivity has so far never been achieved Electrical resistivity and magnetic susceptibility measurements show that boron-doped silicon (Si:B) made in this way is a superconductor below a transition temperature T c  ≈ 0.35 K, with a critical field of about 0.4 T For sufficiently high boron doping (typically 100 p.p.m.) silicon becomes metallic  Here we report that superconductivity can be induced when boron is locally introduced into silicon at concentrations above its equilibrium solubility Hybrid devices combining silicon’s semiconducting properties and superconductivity have therefore remained largely underdeveloped Our findings will facilitate the fabrication of new silicon-based superconducting nanostructures and mesoscopic devices with high-quality interfaces. The calculated electron–phonon coupling strength is found to be consistent with a conventional phonon-mediated coupling mechanism  We find that at a higher boron concentration of several per cent, achieved by gas immersion laser doping, silicon becomes superconducting Ab initio calculations Our calculations were based on an ultrasoft pseudopotential plane-wave implementation of density functional theory with a generalized-gradient description of the exchange-correlation functional All magnetic measurements were performed with the magnetic field perpendicular to the film plane Data were collected around the (004) silicon Bragg reflection with an angular resolution better than 3 × 10 -3  degree Electrical and magnetic measurements Electrical resistivity measurements were performed from room temperature down to 0.35 K using a Quantum Design Physical Properties Measurements System and were extended down to 40 mK in dilution refrigerators using standard lock-in techniques Electronic and phonon momentum were sampled with a 5 × 5 × 5 and 4 × 4 × 4 Monkhorst–Pack grid, respectively Estimated thicknesses (in nm) for samples 1, 2 and 3 were 35 ± 5, 30 ± 5 and 110 ± 10, respectively For the sake of comparison with experiment, the theoretical frequencies have been rescaled by 520/502 = 1.036 in Fig. 4 . Gold wires were attached onto the samples in a four-terminal configuration either directly with silver epoxy or on evaporated Au:Ti contacts for a better definition of geometrical factors HeCd laser (3 mW at 325 nm) were collected at room temperature in air under a ×40 microscope objective High-resolution XRD measurements were performed with a commercial Philips Materials research diffractometer at the Cu K α1 wavelength of 0.15406 nm selected with a (220)Ge four-reflection Bartels-type monochromator In situ monitoring of the transient reflectivity at 675 nm, as well as previous calibrations by secondary ion mass spectroscopy , enabled us to adjust the power and duration of the pulses in order to ensure maximum doping over the whole thickness of the melt Measurements of a.c. magnetic susceptibility were obtained by recording the change in the mutual inductance of a small coil at 9 kHz with a Stanford Research 836 lock-in amplifier Methods Sample preparation and characterization Laser-induced doping was performed with a 308 nm wavelength laser over ten separate 6 mm 2 areas of the same wafer in a special GILD configuration Micro-Raman backscattering spectra excited by a c.w Rocking curves were obtained by measuring the diffracted intensity as a function of the rotation, θ , of the sample The absence of polycrystalline phases was checked by additional diffraction measurements at grazing incidence The coil response was calibrated by measuring a thin film of niobium with similar size and shape The electronic sampling was increased to 10 × 10 × 10 for evaluating λ  The normalized resistance values displayed in Fig. 3a result from d.c. measurements with I  = 100 nA The Perdew–Burke–Ernzerhof functional was used, together with a 25 Ryd and a 200 Ryd cut-off for the eigenstates and charge density, respectively The precursor gas (BCl 3 ) was injected and chemisorbed on a {001}-oriented silicon wafer surface before each of the 200 laser shots of 25 ns duration The spectral resolution was better than 2 cm -1  They were performed with the Plane Wave Self-Consistent Field package ( www.pwscf.org ) To avoid artefacts, various careful checks were made, such as the comparison of a.c. and d.c. electrical measurements as well as current–voltage I – V characteristics We used a HR800-UV Jobin-Yvon-Horiba spectrophotometer equipped with an edge filter and a liquid-N 2 -cooled 256 × 2,048 pixel CCD detector Within the present approach, the zone centre optical modes for pure cubic silicon are found at 502 cm -1 , compared to the experimental value of 520 cm -1  A sharp drop of the resistance is observed with an onset around 0.4 K Alternatively, the observed dependence might be a consequence of the film’s inhomogeneity: it could arise if the dimensions of the superconducting regions are restricted parallel to the film surface, or be due to percolation or localization phenomena  An immeasurably small R value is observed below 150 mK As compared to undoped silicon, we found a ∼42 cm -1 softening of the zone-centre optical modes As depicted in Fig. 1 , this was achieved by gas immersion laser doping (GILD), where the precursor gas (BCl 3 ) is chemisorbed on a (001)-oriented silicon wafer before each ultraviolet laser pulse  As for boron-doped diamond , most of the coupling originates from the optical modes As illustrated in Fig. 4 , the calculated softening agrees well with the broadened Raman peaks observed in samples 1, 2 and 3 at 464, 480 and 485 cm -1 respectively, and can be compared with a peak position of 520 cm -1 in pure Si As shown in Fig. 1 , we observed one or two broad diffraction peaks well separated from the narrow line from the substrate Assuming that the Si:B alloy retains the elastic properties of bulk silicon, this yields an in-plane tensile stress (‘negative’ pressure) of 2.6 GPa and 3.9 GPa, and isotropic lattice parameter variations of -1.4% and -2.1% Averaging over the Brillouin zone and phonon bands, we find a coupling constant λ of 0.28 Close to the Fermi level (which is located 0.5 eV below the top of the valence bands), the calculated band structure resembles that of undoped silicon, confirming the degenerate nature of Si:B at such a high doping level During each melting/solidification cycle, boron diffuses into molten silicon, and is incorporated at substitutional sites of the crystal as the liquid/solid interface moves back to the surface of the epilayer  Experimentally, the shift to lower frequency and the broadening are more pronounced for sample 1, which has the highest T c  From Vegard’s law and previous calibrations , this corresponds to substitutional boron concentrations of respectively 5.7 at.% and 8.4 at.% (that is, 2.8 × 10 21 and 4.2 × 10 21  B cm -3 ) Hall measurements performed at room temperature on the same sample (sample 1) give a free-hole density of the order of (5 ± 2) × 10 21  cm -3 , which is comparable to the higher boron concentration deduced above Here we report structural, electrical and magnetic experiments performed at room pressure on a set of boron-doped silicon thin layers where boron was incorporated into cubic silicon well above its equilibrium solubility (1.2 at.% or 6 × 10 20  cm -3 ) High-resolution X-ray diffraction (XRD) analysis of three samples was performed around the (004) Bragg reflection In contrast, superconductivity has been sought in silicon for 60 years but observed only in its β-Sn and hexagonal (sh) metallic phases obtained under extreme pressures of the order of 10 GPa In order to define the phase diagram in the magnetic field–temperature ( H – T ) plane, we performed electrical measurements; these involved varying the temperature at different magnetic fields, and varying H at different temperatures (see the insets in Fig. 2b ), with the field always applied perpendicular to the plane of the film In order to provide some insight into the microscopic pairing mechanism, we performed an ab initio study of the electronic, vibrational and electron–phonon coupling properties of boron-doped silicon It should be noted that elemental boron becomes superconducting only under a very high pressure (of the order of 160 GPa) and therefore cannot account for this superconductivity Semiconductors, such as GeTe, PbTe and SrTiO 3 , have been shown in the past to become superconducting at low temperature upon carrier doping  Similarly, as the temperature decreases there is an onset of diamagnetism below 0.34 K, but full magnetic screening is not achieved until 150 mK al relaxation led to an isotropic contraction of 1.9% of the lattice parameter compared to the pure silicon, related to the reduced Si–B bond length (2.1 Å in our calculations), and within the range of values deduced experimentally by XRD The appearance of an additional Raman-active Si–B stretching mode 100 cm -1 above the zone-centre optical modes, seen experimentally, is found in the calculation to correspond to a Si–B stretching mode at around 590–600 cm -1  The critical field versus temperature curve in Fig. 3b has a marked curvature compared with the standard Bardeen–Cooper–Schrieffer (BCS) dependence  The critical temperature T c2 and the critical magnetic field H c2 where the resistance is 10% of its normal state value are plotted in Fig. 3b (the 10% criterion corresponds to the onset of diamagnetism in zero field) The foot of the resistive and diamagnetic transitions, and the width of the magnetic response, are typical of an inhomogeneous superconductor : this inhomogeneity is expected, given the non-uniform boron distribution detected by XRD The in-plane lattice matching to the substrate and the local incorporation of boron atoms of lower covalent radius result in the formation of biaxially strained pseudomorphic layers with thicknesses ranging from 10 nm to 120 nm The inset of Fig. 2 shows measurements made to lower temperature with a dilution refrigerator The Landau–Ginzburg superconducting coherence length is estimated in the orbital limit to be 13 nm from the experimentally measured slope of H c2 against temperature at T c , whereas a larger estimate of approximately 20 nm is found based on the values of T c and H c2 (0) (at zero temperature) within the standard BCS theory The peaked structure of the Eliashberg function around ω  0  = 470 cm -1 suggests the use of the following modified McMillan formula appropriate for a δ-shaped spectrum: T c  =  ħω  0 exp[-(1 +  λ )/(l- μ *(1 + λ))], where μ * accounts for the screened Coulomb repulsion The phonon density of states (pDOS) is represented in Fig. 4  The room-temperature sheet resistances (in Ω per □) of samples 1, 2 and 3 are 35, 17 and 8, respectively, while their resistivities are of the order of 100 μΩ cm, and have a dependence on temperature over the 0.35–300 K range typical of disordered metals (see Fig. 2 ) The softening is caused by hole injection, which more than compensates the effect of lattice contraction The temperature dependence below 0.5 K of the d.c. electrical resistance, R , and of the real part of the a.c. magnetic susceptibility, χ ′, for sample 1 is plotted in Fig. 3a  The transitions remain sharp and no hysteresis or supercooling was seen, which is consistent with the transition to superconductivity under field being of second order The two broad maxima detected in sample 1 at 35.56° and 36.02° correspond to a contraction of the lattice parameter, a , along (001) of d a / a  = -2.5% and -3.7%, respectively The XRD results shown in Fig. 1 indicate that sample 2 has a slightly lower B concentration, whereas sample 3 is thicker and has a much lower concentration than sample 1 Theory as well as experimental results obtained on superconducting boron-doped diamond lead us to expect that a higher superconducting transition temperature might be achieved if more boron could be incorporated into the silicon These measurements unambiguously demonstrate the occurrence of superconductivity in sample 1 These values are not much smaller than the estimated thickness of the film (35 ± 5 nm), which can also act to limit the extent of the coherence length  This feature could be explained by paramagnetic limitation if the carriers are assigned a gyromagnetic factor, g , 40% larger than the standard value of 2 This indicates a non-uniform distribution of the strain perpendicular to the surface and thus of the boron content, but confirms the epitaxial single crystal character of the films This is an exciting possibility, as it would considerably facilitate the development of Si:B nanostructures and mesoscopic devices exploiting superconductivity. This is in good agreement with λ  = 0.30 for 5% doping within the virtual crystal approximation  This is surprising, given that theoretical calculations have consistently predicted doped germanium and silicon to be superconducting in their face-centred cubic (f.c.c.; ambient pressure) diamond structure and that conventional superconductivity has been found in materials that contain light group IV elements, such as silicon clathrates and boron-doped diamond  This observation further confirms the substitutional incorporation of boron This observation, and the relatively high value of the critical field, 0.4 T (see Fig. 3b ), which exceeds that of lead (8×10 -2  T), the strongest known type I superconductor, suggests that boron-doped silicon is a type II superconductor This suggests that a standard BCS mechanism can account for the observed superconducting transition To estimate the superconducting transition temperature, we calculated the electron–phonon coupling function (Eliashberg function), which measures the coupling strength as a function of the phonon energy ( Fig. 4 ) To indicate the width of the transition, the positions of maxima of the slope of the resistance versus temperature (d R /d T ) in the T -sweeps and maxima of d R /d H in the H -sweeps are also shown (open symbols in Fig. 3b ) Two of the samples (1 and 2) undergo superconducting transitions to zero resistance, respectively at 150 mK and 45 mK, whereas sample 3 shows only a partial transition We adopted a supercell approach, with one boron atom substituted for every 16 silicon atoms arranged in an f.c.c. cell, yielding a 6.25 at.% concentration, close to the values estimated for the superconducting samples (see Methods) We find that for μ * in the range 0.08–0.12 (a value of μ * = 0.1 was adopted in ref. 12 ), T c is predicted to vary in the range 0.5–0.03 K We now discuss the electrical characterization of the samples
 Across the Atlantic, the British government is interested in tracer releases in London But responding to an explosive release of harmful airborne material would be even more difficult But Tom Keiss, acting programme manager for radiological countermeasures in the DHS Office of Research and Development, says the results from such experiments could lead to models accurate enough for use in an emergency. “These models could tell us what sort of area first-responders should evacuate, and even the information you would give the public,” he says, such as safe routes out of a city. “We consider this to be a sound investment that can save lives.”  The gases are being released from an area of two square kilometres south of Central Park on six days (see graphic), determined by the weather, between 6 and 26 August Data from the New York experiments, principally funded by the Department of Homeland Security (DHS), will be fed into computer models that can be run in an emergency, to predict how a plume of material will disperse over the following hours and to inform emergency services about how to respond Earlier tracer experiments took place in Oklahoma City and Salt Lake City, and a small-scale preliminary to the Manhattan experiments was carried out around Madison Square Garden in March Emergency services responding to attacks in built-up areas already have to balance helping the injured, evacuating survivors and sealing the site for forensic examination It is impossible to test every material, in every location and in all conditions It tested its models with data from a tracer experiment to examine air pollution in the city, and is deciding whether to fund a large-scale tracer-release programme in London. “Experiments in New York are not much use to London or Paris Our cities are very different physically, and have different climates,” says Alan Robins, a specialist in environmental fluid mechanics at the University of Surrey, Guildford, and chair of the London project. Plumes of inert gas are rising above Manhattan this week as part of a research programme to improve the US response to terrorist attacks Researchers will track the fate of seven different gases to test and refine models of how chemical, biological or radioactive material might spread through the city The research is part of the four-year Urban Dispersion Programme, which began in 2003 To decide how far to move people from the scene and in which direction, authorities need some idea of how material will spread, and how that is affected by factors such as the weather Using nearly 180 samplers and 35 weather stations, researchers from government and university labs will track the gases movement through the streets and into buildings and the subway system
 But evidence for the suggested feedback mechanism has to date come solely from small-scale laboratory and field experiments and modelling studies  Here we use data from the National Soil Inventory of England and Wales obtained between 1978 and 2003 to show that carbon was lost from soils across England and Wales over the survey period at a mean rate of 0.6% yr -1 (relative to the existing soil carbon content) More than twice as much carbon is held in soils as in vegetation or the atmosphere , and changes in soil carbon content can have a large effect on the global carbon budget Our findings indicate that losses of soil carbon in England and Wales—and by inference in other temperate regions—are likely to have been offsetting absorption of carbon by terrestrial sinks. The possibility that climate change is being reinforced by increased carbon dioxide emissions from soils owing to rising temperature is the subject of a continuing debate  The relationship between rate of carbon loss and carbon content is irrespective of land use, suggesting a link to climate change We find that the relative rate of carbon loss increased with soil carbon content and was more than 2% yr -1 in soils with carbon contents greater than 100 g kg -1  Accordingly, for these sites sampling was designed with d = 2 g kg -1 for soils with C org 150 g kg -1 , d = 5 g kg -1 for C org = 150–300 g kg -1 and d = 10 g kg -1 for C org 300 g kg -1  At each site, 25 soil cores were taken at 4-m intervals in a 20 m × 20 m square centred on the grid intersection  Derivation of equation (1) Equation (1) is a regression, but was not fitted by ordinary least squares because the original systematic sampling precludes the assumption that the residuals are independent random variables  Equation (1) was fitted as a mixed model with a spatially-dependent random effect and a white noise term such that, for any pair of locations x i and x j , the expected squared difference of the residuals, η ( x i ) and η ( x j ), is E [{ η ( x i ) - η ( x j )} 2 ] = 2 { c 0 + c 1 (1 - exp[- | x i - x j |/ a ])} , where c 0 and c 1 are the variances of the white noise and spatially dependent components, respectively, and a is a distance parameter For the non-agricultural sites, the standard deviation of C org was greater, particularly for more-organic soils Hand-written field records from the original sampling were examined to see if outliers in the data (based on the log normalized changes in C org ) had any common features Methods Original sampling The 5-km sampling grid was offset 1 km north and 1 km east of the origin of the National Grid to avoid sampling at the edges of published maps No artefacts were found that would have led us to believe the outliers were not true representations of the changes One portion was stored in a polythene bag inside a cardboard box at ambient temperature and humidity without further treatment Organic carbon analysis Exactly the same methods were used for the two samplings Resampling The minimum proportions of the original sites to be resampled so as to detect changes in C org with 95% confidence were calculated using the relation n 2 / n 1 ≥ 1/[1 + n 1 ( d / z α s ) 2 ], where n 1 and n 2 are the sizes of the original and resampled populations, α is the probability that the change in mean C org is greater than some small value d , z α is the probability of the standardized normal distribution of C org being less than α , and s is the standard deviation of the original population Sites were selected at random from the original sites within these groupings in proportion to the original regional sampling density, and sampled exactly as originally Soils with C org approximately 150 g kg -1 were analysed by a modified Walkley-Black method  The accuracy of the C org measurement in the laboratory (see below) was ± 1 g kg -1 , and hence the minimum value of d is 2 g kg -1  The cores were bulked in the field, giving a total of approximately 1 kg of moist material for each site The cores were taken to a maximum depth of 15 cm from the surface using a 2.5-cm diameter auger, with the soil surface taken as the zero of measurement, and excluding litter layers and living vegetation The model was fitted by residual maximum likelihood . The other portions were crushed to 2 mm, and subsamples analysed for organic carbon as below The samples were air-dried at temperatures not exceeding 30 °C, and each then divided into three equal portions The small subsamples this uses are unrepresentative of highly organic soils, so soils with C org approximately 150 g kg -1 were analysed by loss on ignition (LOI) , converted to C org by C org = 0.5 × LOI This showed the accuracy of relocation was better than 20 m on enclosed land and better than 50 m on open land, and values of C org at 0, 20 and 50 m from the target measured using the original methods were not significantly different from each other ( Supplementary Fig. 1 ) This value was used for the arable/rotational grass and permanent grass sites To check for differences in analytical precision between the samplings, we reanalysed stored samples from 10% of the original sites and obtained good agreement with the original values across the full range of C org ( Supplementary Fig. 3 ) To check that the change of method introduced no artefacts, we applied both to 95 soils with C org = 20–200 g kg -1 and obtained good agreement and no systematic deviation ( Supplementary Fig. 2 ) To test the accuracy with which the sites could be relocated, six surveyors were instructed to revisit 10 sites with widely differing characteristics following the originally recorded site descriptions, their positions recorded with a global positioning system, and the distances between them subsequently measured Urban areas and water bodies were avoided, but otherwise all soils were sampled Also consistent with this, more-organic soils necessarily contain a greater proportion of slowly decaying organic matter, and the rate of turnover of this material appears to be more sensitive to temperature changes than that of more-labile organic matter  An analysis of known rates of change in soil carbon under different conditions showed this to be reasonable But in wet anoxic soils, increased oxygenation of the soil as evaporation increases the depth to the water table will greatly reinforce the increase in decomposition with increased temperature But only 8% of the unexplained variation is spatially structured, so a more sophisticated statistical model is unjustified But we found no statistically significant relations between rate of change and land use, rainfall class or soil textural class, whether for the data as a whole or for outlying data Climate change will affect soil carbon turnover through various processes Figure 1a shows the distribution of soil organic carbon contents across England and Wales measured in the original sampling (1978–83) Figure 1b shows the distribution of rates of change across England and Wales for all the sites, with values for the sites that were not resampled obtained using equation (1)  Figure 2 summarizes the results grouped by soil type and land use For comparison, the UKs current industrial CO 2 emission is about 150 Tg yr -1  From the data in Fig. 3 , the relative rates of change (rate of change/mean C org over sampling interval, in units of % yr -1 ) were 1.43, 0.14, -0.69, -1.84, -2.71, -3.01 and -2.35 for original C org ranges (in g kg -1 ) 0–20, 20–30, 30–50, 50–100, 100–200, 200–300 and 300, respectively From the distribution of soil types in the 1:250,000 National Soil Map interpolated on a 1-km grid, Bradley et al. estimate the total carbon stock of the soils of the UK to be 2,542 Tg over 0–30 cm depth (1,015 Tg in England, 194 Tg in Wales, 1,161 Tg in Scotland, 172 Tg in Northern Ireland) Given that the bulk of the UKs carbon stocks are in organic soils , this result gives cause for concern Hence the relative rates of loss also tended to increase with C org , although not above 300 g kg -1  However the magnitudes of these effects are unknown However, for soils with C org 100 g kg -1 , relative rates of loss over the survey period were 2% yr -1  However, we do not have sufficient data at the scale of the National Soil Inventory to explore these effects However, we found a significant negative linear correlation between rate of change and original organic carbon content (C org ); that is, the rate of loss increased with C org ( Fig. 3 ) If the rate of change found here also applies to the soils of Scotland (but note that most soils in Scotland have large organic carbon contents , and therefore the true rate of loss is likely to be larger), and if the rate of change over 0–30 cm depth is the same as over 0–15 cm, then pro rata the total rate of loss across the UK is 13 Tg yr -1  In freely drained soils, warmer drier conditions may retard decomposition of organic matter if lack of moisture limits soil microbes Increases in temperature will tend to increase rates of organic matter decomposition by soil microbes, although the magnitude of this effect and differences between soils are uncertain  On the basis of atmospheric observations, net carbon absorption by terrestrial systems in the Northern Hemisphere has increased in recent decades  Our findings show that losses of soil carbon in the UK, and by inference in other temperate regions, are likely to have been offsetting absorption by terrestrial sinks, greatly adding to the uncertainty of future trends. Over the survey period, the mean temperature across England and Wales increased by about 0.5 °C and there were also changes in rainfall distribution  Roughly 40% of the original sites were resampled Samples were collected and soil profiles described at the intersections of an orthogonal 5-km grid over the whole area (Methods) Soil carbon contents depend on rates of addition from plant growth versus rates of removal in decomposition, leaching and other soil processes, and each of these is sensitive to changes in land use, climate and other variables  Soils with C org 50 g kg -1 did not lose significant amounts of carbon (that is, not detectable over 10 yr), and those with C org 20 g kg -1 appear to have gained it Some differences between soils and land uses are apparent: for example, peat soils lost carbon an order of magnitude faster than brown soils and man-made soils, and bogs and upland grass lost carbon an order of magnitude faster than lowland heath, which appears to have gained carbon on average Some proportion will have been emitted to the atmosphere as CO 2 and some will have been leached to deeper soil layers and to drainage waters and beyond Such effects may in part explain the increase in the relative rate of loss with soil carbon content because more-organic soils tend to be wetter Sufficient subsets of the sites were resampled at intervals from 12 to 25 yr after the original sampling to be able to detect changes in carbon content with 95% confidence (Methods) Table 1 gives estimates of the total changes in carbon in the upper 15 cm of soil for the whole of England and Wales, with rates for the sites that were not resampled predicted using equation (1)  The effects of temperature will interact in a complicated way with changes in soil moisture brought about by changing rainfall and evapo-transpiration patterns, and changes in atmospheric CO 2 and nitrogen deposition The fact that the losses appear to be happening across both countries irrespective of land use suggests a link to climate change The latter would be consistent with the observed increases in dissolved organic carbon in surface waters across much of England and Wales over the past 40 yr (refs 12 , 13 ) The magnitude of the carbon sink in different regions and the contributions of different processes are highly uncertain, but the main sinks are thought to be changes in land use and increased forest growth with increased atmospheric CO 2 and nitrogen deposition The National Soil Inventory was made to obtain an unbiased estimate of the distribution of the soils of England and Wales and of the chemistry of the topsoil (0–15 cm depth)  The relation applied for the data as a whole and for the three main land use groupings separately, though with different slopes and intercepts The residuals from this regression applied to the whole data set show some regional features, notably a tendency to overestimate the rate of loss in uplands in the northwest and southwest of England The total amount of carbon in the upper 15 cm at the time of the original sampling is estimated to be 864 Tg, and the total rate of change in this depth is -4.44 Tg yr -1  This is the only soil inventory on such a scale anywhere in the world to have been resampled This was done in three phases: in 1994–95 for arable and rotational grassland sites (853 of the original 2,578 sites), in 1995–96 for managed permanent grassland sites (771 of the original 1,579), and in 2003 for non-agricultural sites (bogs, scrub, rough grazing, woodland, and so on; 555 of the original 1,505) This yielded about 6,000 sites, of which 5,662 could be sampled for soil To allow for the varying time interval between samplings, annual rates of change in carbon were calculated for each site by assuming that the process of change was linear over the sampling interval Various changes in land use will have contributed to carbon losses from soils across England and Wales over the survey period, both under agricultural uses (drainage schemes, post-war grassland conversion, increased stocking rates) and non-agricultural uses (afforestation on wet soils, increased erosion, increased burning of upland vegetation) We cannot with the existing data say where the missing carbon has gone We took a random subsample of 1,000 observations from the data as a whole, and obtained the following relation by linear regression specifying an exponential variogram for the residuals (Methods): Rate of change in C org = 0.6 - 0.0187 × original C org (1) The standard error (s.e.) of the intercept is 0.148 and the s.e. of the slope is 0.00081; the rate of change in C org is in units of g kg -1  yr -1 , and C org is in g kg -1 
 As a consequence, norm violations occur more often if the punisher and the norm violator belong to the same group Here we show that these experiments confirm the prediction of parochialism However, as altruistic norm compliance and norm enforcement often emerge in the context of inter-group conflicts , they are likely to be shaped by parochialism —a preference for favouring the members of ones ethnic, racial or language group Norm violators also expect that punishers will be lenient if the latter belong to their social group Our results are puzzling for evolutionary multi-level selection theories based on selective group extinction as well as for theories of individual selection ; they also indicate the need to explicitly examine the interactions between individuals stemming from different groups in evolutionary models. Social norms and the associated altruistic behaviours are decisive for the evolution of human cooperation and the maintenance of social order , and they affect family life, politics and economic interactions  We found that punishers protect ingroup victims—who suffer from a norm violation—much more than they do outgroup victims, regardless of the norm violators group affiliation We have conducted punishment experiments , which allow ‘impartial’ observers to punish norm violators, with indigenous groups in Papua New Guinea Due to the absence of any hostilities between the two tribes, finding parochialism across these two tribes makes our results even stronger Each participant received a show-up fee of K3 and drew a number at the beginning Experimental procedures Game instructions and procedures are based on the work of Henrich et al.  In each experimental session, 18 participants first received some preliminary verbal instructions as a group Methods Subjects A total of 195 members—aged 17 to 60—of two small-scale societies in the Western Highlands of PNG (the Wolimbka and the Ngenika) participated in a third-party punishment game, permitting us to conduct 65 games with three players each One at a time, in the order of the pulled numbers, the subjects then came into a separate room to participate in the experiment Otherwise the dummy variable is zero Participants who failed to understand the instructions were dismissed from the experiment but could keep their show-up fee Player C made this decision before (s)he knew the dictators actual transfer level Since we collected 11 punishment decisions from each player C—one punishment decision for each feasible transfer level—we always controlled for repeated measurement in the statistical analysis of punishment decisions Statistical methods The punishment decisions were examined with ordered probit regressions The dictators transfer decisions were analysed with tobit regressions that consider the transfer level as a function of the expected punishment and the treatment dummies of interest. The game was then explained to them verbally in much detail They are neutral towards each other and do not exchange any gifts or goods, except in the rare case of inter-tribe marriage This means that player C indicated how much he or she is willing to spend on punishment for each of player As feasible transfers Treatment effects were measured by dummy variables that take on a value of one if the observation comes from the treatment of interest Tribal warfare is a frequent event in PNG, but the Ngenikas and the Wolimkas never conducted tribal warfare with each other within the memorized history of the older members of the two tribes We conducted 17 games in the AB treatment and 16 in each of the other treatments We controlled for repeated individual measurements and for individuals transfer levels in all regressions We elicited player Cs punishment decision with the strategy method (see Supplementary Information ) We ensured that the participants did not communicate about the game before the experiment A one-unit increase in expected punishment raises the transfer level by 1.43 units (tobit regression, P 0.001, two-sided, N = 65) After player A and C had chosen their actions, we also elicited their expectations about how the dictators would be punished at the three transfer levels K0, K5 and K10 Although our findings are puzzling from the viewpoint of current selective extinction models , they also suggest how the models could be extended in order to explain the full empirical pattern Although punishment of low transfers is not zero in the AB and the AC conditions, the size of the punishment across the ABC, the AC and the AB condition obeys the order that selective extinction models predict: punishment is much higher when all three players belong to the same group (ABC) compared to the AC and the AB treatments, where punishment is roughly the same ( Fig. 1 ) As we wanted to examine the parochial behavioural patterns, we allocated each subject in our study to one of the following four treatment conditions. (1) All three players in the game are from the same tribe (treatment ABC). (2) Only players B and C are from the same tribe, while A is an outgroup member (BC). (3) Only players A and B are from the same tribe (AB). (4) Only players A and C are from the same tribe (AC) Centralized institutions for the enforcement of legal rules are largely absent in PNG, meaning that social norms almost exclusively regulate social life Controlling for the transfer level, the probability that the third party punishes a violation of the sharing norm is 30.4 percentage points higher in the BC condition than in the AC and AB conditions Current evolutionary models based on the idea that human altruism evolved through the selective (cultural or biological) extinction of groups in inter-group conflicts predict the following punishment pattern Current individual selection models also cannot readily explain the full pattern of punishment behaviours Currently, no single theory seems to be able to explain the entire pattern of parochialism across treatments, providing an opportunity for developing new theories or modifying existing ones. Every Kina spent on punishment reduces As income by K3 First, A can transfer any amount between K0 and K10 to B First, these models focus on norm enforcement within groups for the purpose of winning inter-group conflicts while neglecting the potential benefits from cooperative inter-group interactions For example, even in the conditions with relatively low punishment levels (AB and AC), 58% of the third parties punish if the dictator transfers nothing, but only 3% punish at K5 and nobody punishes at transfers higher than K6 For example, only 41% of the dictators expect the maximal punishment at a transfer of K0 if the third party is from their group, but 73% of the dictators expect the maximal punishment if the third party is from the other group ( Fig. 3b ) For example, the average punishment at a transfer level of K4 is more than twice as high in BC than in ABC How do these punishment patterns, together with the parochial pattern of voluntary norm compliance, shape the transfer levels? We find that the transfers are higher in those conditions where A and B belong to the same group (tobit regression, P = 0. 018, two-sided, N = 65) However, the ingroup favouritism observed in these experiments does not reveal parochial tendencies in human altruism because the subjects only distributed resources between two other subjects If a group has a reputation for punishing individual attacks by outgroup members, the latter are deterred from such attacks and all ingroup members enjoy more protection If an egalitarian sharing norm exists, we should observe both that dictators transfer money to the recipients and that third parties exhibit altruistic punishment for transfer levels below the equal split In addition, PNG societies more closely resemble the human societies under which our social instincts evolved than the modern, complex societies in which most people at present live In fact, punishment in BC is even significantly higher than in ABC ( Fig. 1 ; ordered probit regression, P = 0.022, two-sided, N = 352) In our study, we conducted an anonymous, one-shot, third-party punishment experiment involving a dictator (player A), a recipient (player B) and a third party (player C) In this case the dictators transfers are substantially lower on average compared to the conditions where A and C belong to different groups ( Fig. 3a ; tobit regression, P 0.001, two-sided, N = 65) In this paper, we study the potentially parochial nature of altruistic norm enforcement by conducting third-party punishment experiments with members of two small, distinct, cohesive and non-hostile indigenous groups in the Western Highlands of Papua New Guinea (PNG)—the Wolimbka and the Ngenika It is therefore difficult to see why kin selection should have favoured a sharing norm that applies to all tribe members alike—in particular in situations such as our experiment, where the dictators fitness loss roughly equals the recipients fitness gain It is therefore likely that the existence of these norms had a deep impact on the properties of human altruism, because norm obedience and norm enforcement involve important altruistic behaviours Kin selection theory is also not fully satisfactory, because the average genetic relatedness between two randomly selected adult tribe members in tribes of several hundred people is rather low, due to migration and marriages with outgroup members Likewise, the group competition theories predict zero punishment in condition BC because A is an outgroup member who is not obliged to obey a sharing norm in interactions with an ingroup member Models based on repeated interactions or reputation formation seem to predict that punishment will be highest in the ABC condition, because the third partys reputational benefits from punishing are most favourable in this condition: protecting an ingroup victim may yield a future ally and punishing an ingroup violator lessens the likelihood of being cheated in future interactions with the norm violator Moreover, subsequent research has shown that costless ingroup favouritism in these experiments is due to the expectation that ingroup members will receive some reciprocation from other ingroup members Moreover, the punishment threat subjectively perceived is significantly lower if the third party belongs to the dictators group (ordered probit regression, P = 0.022, two sided, N = 65) No punishment should be observed in treatment AC if A does not share, because there is no obligation to share with a recipient B from the outgroup Normative obligations are thus likely to apply only to ingroup members; people who do not belong to the group neither obey the norm nor benefit from the altruistic behaviours the norm enforces Norms emerge through interactions in groups and apply to interactions within groups; group members enforce them, and they often arise in the context of inter-group conflicts  Our experiment is designed to capture the altruistic enforcement of egalitarian sharing norms that ethnographic studies have documented  Perhaps, if a sharing norm already exists for other reasons, kin selection might have favoured a lower punishment of ingroup members, which could explain the lower punishment in ABC compared to the BC condition Player A receives an endowment of 10 Kina (K), which is equivalent to a high daily labourers wage in the informal sector of the economy Player As reluctance to share if B does not belong to his group is strongly reinforced if the third party comes from As group Player B, the recipient, has no endowment and player C, the third party, receives K5 PNG is therefore an ideal environment for studying the parochial nature of human altruism Punishing outsiders who harm an ingroup victim increases the general security of all ingroup members by preventing attacks by outgroup members Punishment in the BC condition is also much higher than in the AC and the AB conditions ( Fig. 1 ; ordered probit regression, P 0.001, two sided, N = 539) Regardless of the treatment condition, individuals in both roles believe that a transfer of K0 will be punished severely, while transfers of K5 or K10 will not be punished Researchers have found some forms of ingroup favouritism in simple allocation experiments based on the minimal group paradigm Second, the lack of explicit modelling of individual inter-group encounters makes it also difficult to understand why—regardless of the norm violators group affiliation—punishment is so high in those conditions where the third party and the recipient (ABC and BC) belong to the same group Sharing with an outgroup member would only help the competing group, possibly at the expense of the ingroup Social norms such as food sharing, or those related to cooperative hunting and participation in warfare, shaped human life throughout important evolutionary phases  Subjects thus bore no cost, regardless of how they allocated the available resources between the other two subjects Such sharing norms are beneficial for the group because they insure group members against the uncertainties in individual food acquisition success The current models therefore have problems in explaining our first main result—the existence of egalitarian sharing norms in all four conditions—but a suitably extended model, which explicitly formalizes individual strategies in inter-group encounters, may be able to capture this fact The decision-makers in all four treatments were informed about the other two players group affiliation The dictators even transfer more money in these conditions if we control for their punishment expectations (tobit regression, P = 0.086, two-sided, N = 65) The dictators expect significantly more punishment at K0 in those conditions where B and C belong to the same group ( Fig. 2 ; ordered probit regression, P = 0.019, two sided, N = 65), and the expected punishment level at K0 has a significantly positive effect on transfer levels The dictators expectations also support this deterrence effect of third-party punishment The difference between ABC and the other two treatments is highly significant (ordered probit regression, P = 0.007, two sided, N = 539), while the difference between the AC and the AB conditions is negligible and insignificant (ordered probit regression, P = 0.947, two sided, N = 539; see also statistical methods in Supplementary Information ) The difference between these two conditions is particularly large at transfer levels of K3 and K4 The fact that social norms are group level phenomena suggests that parochial social instincts —which we define as preferences for favouring the members of ones own social group—may have shaped human altruism in decisive ways The human species is unique in the extent to which it regulates social life with normative obligations that constrain selfish behaviour  The same punishment prediction is made for condition AB, where the third party is an outgroup member; in this case A violates a sharing norm if she or he does not share with B, but player C—being an outgroup member—has no obligation to punish a norm violation within the other group The third parties and the dictators beliefs further support this interpretation The use of cohesive, indigenous groups from simple societies distinguishes our study from minimal group experiments based on artificially created laboratory groups of students Then C is informed about As transfer and has the opportunity to punish As action by spending K0, K1 or K2 on punishment There is little punishment for transfers at and above the egalitarian level, while sharing decisions that give the dictator a larger share of the ‘pie’ are more heavily punished the more the dictator deviates from the equal split These findings imply that regardless of the dictators group affiliation, punishment is much higher if the recipient and the third party belong to the same group This approach makes it difficult to understand when hostility characterizes inter-group reactions and when cooperative norms govern them This finding suggests the existence of an egalitarian sharing norm in all four conditions, and not just in the ABC condition—a fact that is puzzling in view of the predictions above Thus, both actual punishment and punishment expectations suggest that victims of norm violations are much more protected if the victim and the third party belong to the same group Thus, dictators expect that ‘their’ third parties will be lenient, inducing them to transfer little to the recipient Thus, dictators who expect the same level of punishment give more in those conditions where A and B belong to the same group, suggesting a higher degree of voluntary norm compliance in these treatments (see also statistical methods in Supplementary Information ) Thus, if future research confirms the robustness of our results, the parochial patterns of human altruism constitute a challenge for existing evolutionary theories Thus, taking the problem of group reputation into account could possibly explain the high punishment in both the BC and the ABC conditions Thus, the ABC treatment is the only condition in which evolution should have favoured altruistic punishment, because punishment in ABC sustains group norms that enhance a groups ability to compete with other groups Thus, third parties are more lenient if the norm violator belongs to their group Thus, to the extent to which third-party punishment deters potential norm violators, the victims of potential norm violations are much more protected by the threat of third-party punishment if the third party belongs to the victims group Thus, what looked like a preference for ingroup favouritism was in fact based on the expectation of ingroup reciprocity  We observe that the punishment pattern is qualitatively similar in all four treatment conditions ( Fig. 1 )
 Arising from: T E Here we show that their empirical observations are also consistent with a distribution of genetic variation between nuclei within spores (that is, heterokaryotic), given that there is fusion of fungal hyphae Pawlowska and Taylor find that genetic variation within AM fungal cells is not lost as a result of segregation, and they interpret this as evidence that the variation is present within each nucleus and that all nuclei within individual spores are genetically identical (that is, homokaryotic) Pawlowska J Taylor Nature 427 , 733 – 737 ( 2004 ) ; Pawlowska Tylor reply Arbuscular mycorrhizal (AM) fungi (Glomeromycota) reproduce asexually, are multinucleate, and have high genetic variation within single cells This analysis, together with complementary findings , suggests that AM fungi have an unusual genomic structure in which multiple, genetically diverse nuclei are maintained within cells through remixing by hyphal fusion. W As shown by Pawlowska and Taylor, we can reject the possibility that AM fungi are both haploid and have no hyphal fusion By allowing fusion of hyphae derived from a single spore, as has been empirically observed , high levels of variation can be maintained within spores over long periods, assuming either haploidy or diploidy ( Fig. 1 ) For example, with a bottleneck of 20%, rates of hyphal fusion greater than 30% will reduce variant loss to that consistent with the observations of Pawlowska and Taylor Given this observation and those of haploid genomes in related species of AM fungi , we suggest that Pawlowska and Taylors empirical observation of low rates of loss of variants may be due to heterokaryotic arrangement of the variation within spores that is maintained by hyphal fusion However, we cannot reject the possibility that AM fungi are haploid and have low-to-moderate rates of hyphal fusion ( Fig. 1g ) Hyphal fusion, in particular, has strong effects because it allows the remixing of previously separated nucleus types, thereby stemming the loss due to drift  In fact, there are many combinations of bottleneck rates and hyphal fusion that can reproduce their results Pawlowska and Taylor also amplified the internal transcribed spacer region from microdissected nuclei and found that three variants were present in each nucleus Pawlowska and Taylor observe that each of 20 single progeny spores had all 13 variants of a putative single-copy gene — that encoding DNA polymerase I Their statistical confidence in this conclusion comes from simulations of the segregation process that assume haploidy, no hyphal fusion and no selection They argue that the preservation of these variants is inconsistent with heterokaryotic organization of the genome because, under this genomic structure, stochastic loss of variants would be expected We calculated the likelihood of losing variants from spores with 13 variants within one generation, as did Pawlowska and Taylor , but we varied the rate of fusion (see Methods) We note that this is not a definitive test for homokaryosis because the nuclei could still vary in the numbers of the three types of internal transcribed spacer, as well as in other regions of the genome. We relaxed the first two assumptions and showed that both diploidy and hyphal fusion could delay the loss of variation ( Fig. 1 ) What then are reasonable rates of hyphal fusion in AM fungi? Although fusion of hyphae among geographically divergent isolates may be inhibited, rates of hyphal fusion have been found to be very high for fungal isolates from the same proximity, with fusion occurring in 60–85% of contacts between hyphae derived from spores from the same cultures 
 The courses are in fact part of a core lecture module on evolution, introduced to give second-year students sufficient evidence and confidence to debate evolution in schools, universities or society in general. The Special Report “Anti-evolutionists raise their profile in Europe” ( Nature 444 , 406 – 407 ; 2006 ) stated incorrectly that the University of Leeds plans to introduce remedial courses on evolution for first-year science students
 Counting fluorophores by the stepwise photobleaching of single GFP molecules showed that each motor contains ∼22 copies of GFP–MotB, consistent with ∼11 stators each containing two MotB molecules Fluorescence recovery after photobleaching and fluorescence loss in photobleaching showed turnover of GFP–MotB between the membrane pool and motor with a rate constant of the order of 0.04 s -1 : the dwell time of a given stator in the motor is only ∼0.5 min Here we have investigated the protein stoichiometry, dynamics and turnover of MotB with single-molecule precision in functioning bacterial flagellar motors in Escherichia coli  Many essential cellular processes are carried out by complex biological machines located in the cell membrane The bacterial flagellar motor is a large membrane-spanning protein complex that functions as an ion-driven rotary motor to propel cells through liquid media  This is the first direct measurement of the number and rapid turnover of protein subunits within a functioning molecular machine. We also observed a membrane pool of ∼200 GFP–MotB molecules diffusing at ∼0.008 µm 2  s -1  We monitored motor function by rotation of a tethered cell body , and simultaneously measured the number and dynamics of MotB molecules labelled with green fluorescent protein (GFP–MotB) in the motor by total internal reflection fluorescence microscopy Within the motor, MotB is a component of the stator that couples ion flow to torque generation and anchors the stator to the cell wall  Average curves were generated for FRAP and FLIP of both motor and membrane components; all intensity components were corrected for photobleaching ( Supplementary Methods 5 ) Data analysis and simulations Continuous TIRF intensity data were filtered by using a Chung–Kennedy (C–K) algorithm ; spatial frequency analysis of the pairwise intensity-difference histograms was used to determine the unitary step size ; membrane diffusion was modelled by using Monte Carlo simulations for mobility of single GFP–MotB molecules; rate constants for the turnover process at the motor were evaluated by using a least-squares fit to FRAP and FLIP data (see Supplementary Information for details). Fluorescence emission was imaged at ∼50 nm per pixel in frame-transfer mode at 1 Hz (25 Hz for immobilized GFP molecules, 10 Hz for particle tracking) by a 128 × 128-pixel, cooled, back-thinned electron-multiplying charge-coupled-device camera ( iXon DV860-BI , Andor Technology ) Fluorescence microscopy We used a home-built inverted TIRF microscope with an excitation wavelength of 488 nm ( Supplementary Methods 5 ) For FRAP and FLIP experiments, single TIRF exposures were taken at intervals up to 256 s after bleaching with a focused laser spot for 0.5 s, centred either over a fluorescent spot of a putative motor (FRAP) or 1 µm from a motor (FLIP) Image acquisition and photobleaching Images were sampled continuously for 300 s, resulting in 90% photobleaching within range of the TIRF field Methods E. coli strains and cell preparation A strain expressing GFP–MotB from the genome in normal MotB physiological quantities was constructed, and cells were prepared as described in Supplementary Methods 1  Motor and membrane components were separated as described in the text for TIRF bleaches A relatively high value of D agrees with other data suggesting that MotB in the membrane pool does not bind significantly to the cell wall  After 90 min, fluorescence recovery ranged from 75% in buffer enriched with nutrients to 7% with protein synthesis blocked (attributable to GFP maturation ) All cellular components showed roughly exponential photobleaching under TIRF illumination: I ( t ) = I 0 exp (- t / t 0 ) ( Fig. 2a , Table 1 and Supplementary Fig. 4 ) Both components recovered over the course of a few minutes; motor recovery was slightly delayed as compared with membrane Cytoplasmic GFP and autofluorescence were not expected to contribute because only the cell surface adjacent to the coverslip was illuminated Dividing the initial membrane component of background intensity by I GFP gave an average of 0.052 ± 0.022 molecules per pixel Early work estimated 16 stators in a motor , whereas subsequent studies estimated 8 stators  Eleven stators, each with a dissociation rate ∼0.04 s -1 , gives an overall exchange of ∼0.44 stators per s Figure 2c and d shows the pairwise-distance distribution function (PDDF; Supplementary Methods 3 ) and its power spectrum, respectively, for the filtered curve 3 in Fig. 2b (refs 22 , 23 ) Figure 3a shows TIRF images of a cell before and after bleaching of a region containing a motor Fitting all of the FRAP and FLIP data to an extended diffusion model, incorporating binding and unbinding at the motor and bleaching in the TIRF field ( Supplementary Methods 7 ), gave a dissociation rate at the motor of 0.04 ± 0.02 s -1  Fitting all of the membrane FRAP data from ROIs lacking motors to a model of a diffusing GFP–MotB membrane pool gave a diffusion coefficient, D , of 0.0075 ± 0.0013 µm 2  s -1 ( Supplementary Methods 6 ) Fluorescence loss occurred on the same timescale in both components Fluorescence recovery (FRAP) of both motor and background components in the bleached region is visible, as is fluorescence loss (‘one-shot’ FLIP; Supplementary Methods 5 ) at the other end of the cell Fluorophore counting indicated that there are 22 ± 6 GFP–MotB molecules per motor FRAP and FLIP ( Fig. 3b ) of motor and membrane components respectively, averaged over 13–38 cells, are shown in Fig. 3c and d  GFP fusion constructs have been used with total internal reflection fluorescence (TIRF) microscopy to detect single interactions at the basal membrane in vivo , and fluorescence recovery after photobleaching (FRAP) and fluorescence loss in photobleaching (FLIP) have been used to measure dynamics of membrane protein populations  Here we show that protein components of a functioning biological machine undergo rapid exchange with a freely diffusing pool in the cell membrane In summary, by replacing wild-type motB in the genome with gfp–motB , we expressed the fusion protein in natural quantities, enabling us to investigate protein stoichiometry and dynamics under physiological conditions It should be possible using similar methods to learn whether other membrane proteins also turnover rapidly and, if not, to investigate possible reasons for differences between complexes. Little is understood, however, about protein dynamics and turnover within individual complexes under natural conditions in living cells Many membrane proteins function in multimeric complexes, and investigating their organization and dynamics is essential for understanding their function Measurements of solubility and copurification with MotA suggest that MotB is stable in the cytoplasmic membrane only as a dimer in 1:2 stoichiometry with MotA  Our methods for counting the number of proteins in a membrane complex in living cells and observing their turnover using TIRF microscopy should be applicable to other membrane protein complexes Our photobleaching result also agrees with freeze-fracture electron microscopy showing 11–12 stators around the rotor  Over 30% of all proteins are integrated in biological membranes, where they carry out diverse essential cellular functions Polystyrene beads (0.75 µm in diameter) attached to filaments rotated three times slower than on the parental strain ( Supplementary Fig. 3 ), indicating some reduction in GFP–MotB function Previous research indicates that a motor has 8–16 stators , each containing two copies of MotB and four copies of MotA  Separation into motor and background components introduced extra noise ( Fig. 2a ); therefore, we calculated I GFP using total intensity rather than the motor component alone Similar spots were observed for stuck cells, with one or occasionally two spots visible Spot size and number were consistent with a ring of GFP–MotB molecules bordering a rotor with a diameter of ∼50 nm (refs 14 , 18 ; Fig. 1b ) and ∼6 motors per cell ( Supplementary Note 1 ) Step-wise photobleaching of single surface-immobilized GFP molecules showed an average step size of ∼13,000 counts s -1 in our microscope, after correcting for differences in laser power and exposure time ( Fig. 2f ) Supplementary Fig. 5a and b show distributions of I GFP and initial motor intensities ( I 0 m ), respectively, for 134 traces from different cells The bacterial flagellar motor is ideal for examining a single protein complex in vivo ; rotation of the whole cell when the filament is attached to a surface ( Fig. 1 ) is an instantaneous indicator of motor function The broad distributions in our counting estimates may include both natural variation in the number of stators per motor and noise due to background fluorescence, GFP blinking and instrumental limitations The double-sized step in Fig. 2e presumably corresponds to two successive unitary photobleaches that were not resolved by the filtering algorithm; furthermore, no steps were detected in photobleaches of the parental strain The GFP membrane component bleached considerably more slowly than the motor, which we attribute to diffusive exchange with unbleached fluorophores from outside the TIRF field The intensity of these spots was consistent with a GFP–MotB dimer ( Supplementary Fig. 9 ) The large uncertainty is a consequence of the small difference between recovery rates of motor and membrane components relative to noise The peak in the power spectrum indicates a unitary step size of I GFP ≈ 5,400 counts (ref. 23 ) The reduced uncertainty of this estimate (22 ± 6, ± s.d.) as compared with the ratio of peaks in Supplementary Fig. 5a and b (19 ± 8) reflects covariation of I 0 m and I GFP , as expected for variations due to TIRF intensity The widths probably reflect different TIRF intensities, which varied about fourfold over the measured range of cell heights (∼150 nm) owing to different distances from motor to coverslip This suggests that, on average, a motor has 11 stators, each with the composition MotA 4 :MotB 2  TIRF images of tethered cells showed spots at the centre of cell rotation measured from brightfield images ( Fig. 1c , Supplementary Videos 1 and 2 ) TIRF intensity falls exponentially with distance over ∼100 nm ( Supplementary Methods 5 ); thus, the average value of I GFP is consistent with motors being ∼90 nm from the coverslip To confirm that this corresponds to bleaching of one GFP molecule, we reduced the background fluorescence by prebleaching the cell, facilitating direct observation of successive photobleaching steps in the motor component of fluorescence ( Fig. 2e and Supplementary Methods 4 ) Total intensity (minus instrumental background) in ROIs containing motors photobleached in steps at roughly integer multiples of a unitary level, I GFP , consistent with photobleaching of individual GFP molecules ( Fig. 2b , e ) Unexpectedly, an anchored component, MotB , of a multiprotein complex was found to diffuse in the membrane and exchange rapidly with the motor, a finding that may alter the conventional ‘static’ view of molecular complexes; if proteins in the flagellar motor are undergoing dynamic exchange, this finding may well apply to other macromolecular complexes We also measured very low fluorescence anisotropy in motors after bleaching with polarized light ( Supplementary Methods 9 ), indicating that GFP fluorophores in motors are free to rotate and therefore all are counted by the photobleaching method We also studied slow recovery after complete bleaching of whole cells ( Supplementary Methods 8 and Supplementary Videos 5–7 ) We attached live cells to a coverslip either by the filament (‘tethered’) or by the cell body (‘stuck’) and observed them with TIRF or brightfield microscopy ( Fig. 1a ) We confirmed the accuracy of the counting by testing it against simulated TIRF photobleach traces generated by the extended diffusion model ( Supplementary Fig. 11 ) We estimated instrumental background from an empty ROI close to the cell in each image and autofluorescence from the parental strain We estimated the cell-surface area as 3,700 ± 500 pixels; thus, the total number of non-motor GFP–MotB molecules per cell is 190 ± 80 We estimated the total number of GFP–MotB molecules per motor by dividing I 0 m by I GFP for each trace ( Supplementary Fig. 5c ) We investigated protein turnover between membrane and motor components using focused laser exposures of 0.5 s to photobleach all fluorophores in regions with a width of ∼1 µm We measured a mobile membrane pool of ∼200 GFP–MotB molecules with D ≈ 0.008 µm 2  s -1 , which is ∼40% smaller than the diffusion rate measured for free membrane proteins of comparable size to a GFP–MotB dimer , and only ∼20% smaller than that for a MotA 4 :(GFP–MotB) 2 stator, assuming that the Stokes radius r scales to the 1/3 power with molecular weight and that D scales as 1/ r  We modelled fluorescence intensity ( I ) in 400-nm square regions of interest (ROIs) containing a single motor as a uniform background plus a gaussian spot of width 300 nm (motor width plus microscope point-spread function) and identified three background components: GFP–MotB in the membrane, nonspecific cellular autofluorescence and instrumental background ( Supplementary Methods 2 ) We obtained an independent, single-molecule estimate, D = 0.0088 ± 0.0026 µm 2  s -1 , by tracking mobile fluorescent spots that could occasionally be resolved after prebleaching ( Supplementary Methods 6 and Supplementary Videos 3 and 4 ) We previously observed at least 11 discrete speed increments after induced expression of functional Mot proteins in a defective background  We replaced genomic motB in E. coli with gfp–motB to express GFP–MotB in wild-type amounts (see Methods)
 A subcommittee of the US House Committee on Energy and Commerce, which is investigating the shipments, said on 13 June that Sunderland received $285,000 for the samples But biobank officials will have to tackle other issues if the initiatives are to succeed, such as questions about who ‘owns’ the information stored in tissue repositories Ethicists and scientists fear that reports of lax policies and misconduct will hurt such initiatives. “If there is a perception that the researcher is using the samples to line his or her pockets on the side, youre going to lose public support,” says Arthur Caplan, an ethicist at the University of Pennsylvania in Philadelphia. “There is nothing more corrosive to altruism than people making money off research.”  Scandals elsewhere have already had similar effects He is accused of shipping more than 3,000 samples of human spinal fluid to the drug company Pfizer without approval from his employers His lawyer did not return phone calls seeking comment Iceland, Estonia and the United Kingdom are already developing national databases, and the United States is considering setting up a biobank containing information on hundreds of thousands of Americans (see Nature 429 , 475 – 477 ; 2004 ) In April, for example, a US federal judge had to intervene in a dispute between patients, a researcher and the University of Washington in St Louis over a valuable tissue repository housed at the university (see Nature 440 , 1102 – 1103 ; 2006 ) In Britain, for example, scientists reported a drop in the donation of organs for research after a pathologist at Alder Hey Hospital in Liverpool was revealed to have illegally removed organs from the bodies of children on which he had conducted post-mortems (see Nature 409 , 655 ; 2001 10.1038/35055696 ) In Sunderlands case, a lack of oversight is giving particular cause for concern. “A lot of this stuff was collected with pretty vague consent and rules,” says Caplan. “Its an issue and its going to pop up again.” Michael Gottesman, NIH deputy director for intramural research, says the agency will clarify its policies on the storage and shipment of tissue samples and develop an electronic database for tracking patient samples in all of its 27 branches. newsad; Such measures could help to restore confidence among potential donors National laws differ on such matters, although several efforts are under way to devise uniform rules. “Theres a real movement for harmonization across international barriers,” says Mark Sobel, executive officer of the American Society for Investigative Pathology. “I think by 2007 or 2008, were really going to see some global acceptance for it.” Revelations about the unauthorized transfer of tissue samples by a US neuroscientist are adding to the challenges faced by researchers who are attempting to set up biobanks — stores of human tissues that can be used to probe the causes of disease Such criticism worries researchers, because scientists are starting to use stored banks of tissue to link genetic, medical and personal health data Sunderland invoked his right not to testify against himself at a 14 June hearing The allegations, which surfaced after a tip-off from a whistleblower in April last year, angered lawmakers. “What we have learned from this investigation is that the National Institutes of Health (NIH) lacks adequate controls for human tissue samples, human subject protection, and the scientific conduct of many of its senior employees,” says committee member John Dingell (Democrat, Michigan) The incident led to new human-tissue legislation in 2004 and the creation of the Human Tissue Authority, tasked with overseeing the handling of such samples The latest problems stem from the case of Trey Sunderland, chief of the Geriatric Psychiatry Branch of the National Institute for Mental Health The NIH has already announced two specific projects linking genetic and environmental information on patients with conditions such as Alzheimers disease There are also concerns about how investigators protect the privacy of patients who donate tissue, and how they give consent for future studies on these tissues This was part of more than $600,000 he received from the company between 1998 and 2004
 Another S$1 billion is earmarked for a project to attract world-class research institutes As a start, the NRF says it will establish a joint research centre with the Massachusetts Institute of Technology next year in Singapore, and hire 300–400 researchers to work there But whereas those in the favoured fields have welcomed the money, others complain that, as ever, basic research is losing out Despite previous investment, the NRFs chairman, Tony Tan, says the Singaporean government is concerned about keeping its competitive edge in science and technology research, compared with big and growing economies such as those of India and China He says he learned the importance of specializing in a small number of research areas that are likely to turn a profit How the remaining S$2.6 billion will be spent has yet to be decided Next year, the government plans to open the first phase of a Fusionopolis complex, which will house information-technology and media companies Now, the government says it will almost double its research budget over the next five years, to a hefty 3% of its gross domestic product (GDP) One example is Biopolis, a S$500-million development that houses biotech research institutes and pharmaceutical giants such as Novartis Others are underwhelmed Over the past few years, Tan has travelled to other small but wealthy countries such as Switzerland, Denmark and Sweden to find out how they do it S$330 million is likely to go towards strengthening technologies that allow the country to produce clean water, for domestic use and for export S$500 million will go towards developing media technologies such as video games and digital cinema. newsad; Some academics, such as Barry Halliwell, deputy president of research and technology at the National University of Singapore (NUS), have acclaimed the funding, saying it will help to attract big names from overseas S$550 million will go towards biomedical research, especially translational and clinical studies — a move from the previous focus on basic research Singapore already has a reputation for throwing money at scientists in particular fields it wants to develop Singapore is famous for big science initiatives, especially in the biomedical sector The announcement represents the first big move in the governments ambitious plan to increase its research and development budget to S$13 billion for 2006–10, or 3% of the countrys GDP The government announced on 7 July that its newly established National Research Foundation (NRF) will spend S$1.4 billion (US$876 million) during 2006–10 in three areas: biomedical research; environment and water technologies; and interactive and digital media The NRF is now discussing exactly how funds in each of the three research areas will be spent and when to start accepting grant applications The NUSs Juan Walford, who studies seahorses as a barometer for the quality of the marine environment, says the new categories are just a reclassification of areas already given the bulk of government money. “There is really nothing new,” he says. “Its all applied technology and engineering, theres no new opening for scientific research” This is part of the S$5-billion five-year budget set aside for the NRF when it was created in January
 Abyssal-hill-bounding faults that pervade the oceanic crust are the most common tectonic feature on the surface of the Earth Conversely, plate stretching, with differing amounts of constant-rate magmatic dyke intrusion, can explain the great variety of fault offset seen at slow-spreading ridges Plate unbending with distance from the top of an axial high reproduces the observed dip directions and offsets of faults formed at fast-spreading centres Recent observations reveal a large range of fault sizes and orientations; numerical models of plate separation, dyke intrusion and faulting require at least two distinct mechanisms of fault formation at ridges to explain these observations The recognition that these faults form at plate spreading centres came with the plate tectonic revolution Very-large-offset normal faults only form when about half the plate separation at a ridge is accommodated by dyke intrusion. A consensus emerged that stretching the cold brittle lithosphere at a ridge is what produces a valley  A few kilometres from a fast-spreading axis the lithosphere may be five times thicker than it is on axis and the crust may be solid  A justification for this assumption comes from seismic results that show a bright reflector at a depth of 0.7–2 km along the axis of most ridges with axial highs  A maximum fault-related relief of 50 m was developed in the models, in the range of observed values  A numerical model of dyking and stretching To look at fault development we treat the model of stretching and dyking using the same numerical technique used for the buoyancy cases, except that we allow for asymmetric deformation across the axis A rift valley flanked by normal faults was the first feature identified as marking the axis of mid-ocean ridges when ridges were discovered 50 years ago  A simple geometric argument shows how faults and dykes might interact at a ridge with a fixed position of dyking and fixed thermally defined strength structure According to this standard model, all faults at ridges result from tectonic stretching of thin axial lithosphere during amagmatic periods  After a phase of fast-strain weakening, continued slow-strain weakening does not affect the bending faults because bending strains are small All loads driving plate motion and deformation are produced by lateral density variations in the Earth Also, for M = ∼0.5 nearly all the magmatic accretion occurs on the side of the axis with small-offset faults, as may happen at outside corners of some ridge-transform intersections Also, this model predicts a magnitude and distribution of brittle strain that is consistent with the average observed horizontal fault strain  An outside-corner core complex would require slip on the extension of the transform outside the ridge-transform intersection As a result, faults should move with the hanging-wall block, as inferred from these model results As shown in Fig. 3 , a good case had 10 MPa of cohesion loss occurring over 1% of strain As shown in Fig. 3 , the fully two-dimensional model fits the general shape of a real axial high As shown in Fig. 4 , the plate to the left of the axis moves with velocity - V p /2, where V p is the total plate separation rate As the curved plate passively moves away from the axis it unbends As with previous thin-plate models, the wavelength of the high depends on the off-axis plate thickness and a good fit was found for a 5-km-thick brittle plate At the slowest-spreading ridges, sometimes called ultraslow-spreading ridges , an extreme range of along-axis variations in magma abundance is seen on a segment scale (∼ 100 km)  Because the buoyancy-dominated (or axial high) case is expected to develop symmetrically, only one side of the ridge is modelled Because the hanging-wall block no longer deforms, but continues to translate, the active part of the fault moves with the hanging wall Bending was concentrated on these widely spaced ‘hinge’ faults, but did not result in appreciable fault-offset-related surface relief Bending-related faulting is the dominant faulting mode at fast- and perhaps at some intermediate-spreading centres Besides having a similar range of relief for the axial valley and the inside-corner high (2 km), the model topography has other characteristics observed on topographic profiles for an ocean core complex ( Fig. 5b ): (1) a domed shape with a flat-lying abandoned-fault footwall; and (2) the characteristic shape of the fault breakaway Deformation occurs because accreted elements are denser than the material in the axial partial melt zone During plate unbending, extensional plastic failure, normal fault nucleation and offset would occur in the top of the plate above a neutral depth—with compressional failure below that depth Dyke intrusion may supply much of the heat that keeps the axis hotter and the axial lithosphere thinner than the lithosphere farther from the axis Dyke opening is simulated with a vertical column of special elasto-plastic dyke elements that are made to widen at a constant rate Dykes accrete by addition of a column of new elements at the axis every time the off-axis boundary has moved one grid spacing Dykes are assumed to open at one horizontal position in a cross-section of a ridge axis Dykes supplied from a central magma chamber have to open in nearly straight lines to keep the supply of magma flowing along and into an opening dyke Eventually, it will be easier to form a new fault cutting the axis and the first fault will be abandoned Eventually, the down-dropping side (the hanging-wall block) cannot drop further and stops deforming Faults are not specified but develop where the stress is sufficient for brittle yielding Faults are quasi-planar weak zones in the lithosphere, the brittle outer shell of the Earth, where earthquakes and tectonic strain are concentrated Faults at buoyancy-dominated ridges Here we develop models of ridge axis deformation in the light of these observations Faults at stretching-dominated ridges To deal with the apparent variety of stretching-related faulting we consider that ridge-axis dyke intrusion at various rates must be considered Finally, although it is not well resolved in our numerical models, the bending associated with large fault offsets should result in small-offset, high-angle faults Finally, the lithosphere cannot thicken very fast with distance from the axis First, M has to be close to 0.5 First, the dip directions of mid-ocean-ridge normal faults show systematic variability as a function of spreading rate For a reasonable density contrast and brittle layer thicknesses the model reproduces both the shape of the axial high and some of the basic characteristics of the flanking faults For both the buoyancy- and stretching-dominated model cases the same strain-weakening parameters were used: with fast weakening for the first percent of strain and slow strain weakening for greater strain For M = 0, dykes account for none of the plate spreading and for M = 1, dykes accommodate all the plate separation For M = 0.5 the hanging wall of the fault does not move away from the axis, so the fault could build up potentially unlimited offset For M = 0.5 the model produced two large faults with offsets 20 to 30 km on one side of the spreading axis and a series of small faults on the other For M = 0.95, the model also generates a fairly symmetric pattern of mainly inward-dipping, small-offset faults, and a symmetric axial valley For M close to 1 the maximum fault offset can be small, while for M close to 0.5 the offset should be very large compared to L  For M less than 1, the thermal advection related to fault offset may affect the ways faults continue to slip, but this is a complex question related to hydrothermal cooling of lithosphere  For this reason, many authors assume that faults form only during periods when no magma is available for dyke intrusion and that the total slip on faults depends on the time interval between dyking events  Further, the standard model cannot explain the across-ridge asymmetry associated with most oceanic core complexes Having this block on the inside of the ridge-transform intersection minimizes the shear strain across the transform However, at slow-spreading ridges there may be much smaller differences between on- and off-axis lithospheric thickness (see Fig. 2 ) If one fault forms owing to lithospheric stretching then it should initially cut the thinnest axial lithosphere on one side of the axis, shown in Fig. 4  If our view of the kinematics of the hanging-wall block bounded by a fault and an axial dyke ( Fig. 4 ) for M ≈ 0.5 is correct, then it suggests a simple explanation for oceanic core complex formation on the inside corner of a ridge-transform intersection If the fault moves away from the axis into thicker lithosphere, it then becomes harder to continue offsetting that fault even though it is weaker than the surrounding lithosphere If the rate of strain weakening is low, say 10 MPa of strength loss over a strain of 50%, then no localization into fault-like behaviour is seen In contrast, for a high rate and large amount of strain weakening, curved faults developed that cut completely through the lithosphere In the last decade it has become clear that the stretching model cannot explain the variety of faults seen at ridges In these models, even small-magnitude stretching (that is M just less than 1) produces large axial valley relief Increased axial valley relief seen at slow-spreading segment ends compared to segment centres correlates with thicker lithosphere at the ends than at centres  Insights from previous models of normal faulting show that when a normal fault forms, one side moves up and away from the fault by about the same amount that the other side moves down and away from the fault It is also particularly important to understand ridge fault systems because they affect major hydrothermal mineral deposits and chemosynthetic biological communities  It is possible that these strain-weakening parameters may also describe how faults form in other tectonic environments, such as strike–slip and thrust-faulted regions Lateral density variations may relate to the formation of the axial high seen at many fast-spreading centres ( Fig. 1a ) Lavas cover faults offset very close to the axis , but abyssal-hill-bounding faults continue to grow out to 20–30 km from the axis  Local buoyancy refers to lateral density variation on the scale of the axial region (within ∼10 km of the axis) Local loads, related to magmatic accretion and near-axis cooling, may drive lithospheric bending and faulting at any ridge Local magmatic isostasy at the axis should occur when there is enough magma to accommodate all plate separation Magma supply and fault mode A single set of fault strain-weakening parameters reproduced the essential features of both stretching- and bending-related faults Magmatic accretion is assumed to account for all plate separation, so no stretching occurs at the axis Magmatic accretion is assumed to occur at a constant rate at all depths through the axial lithosphere Many intermediate-spreading ridge segments fit reasonably well into our end-member categories, some being buoyancy-dominated and some stretching-dominated Maximum relief increases with increasing model axial lithospheric thickness, on the basis of models not presented here  the axis and the other half dip away  Nearly instantaneous strength reduction had to occur, once the yield stress was reached, for bending to produce small-offset, inward- and outward-dipping faults similar to those seen near axial highs Next, the fault weakening must be large and more than half of the weakening has to occur moderately slowly with strain Oceanic core complexes occur mainly at the inside corners of ridge-transform intersections of slow-spreading ridges On the opposite side of the axis, a series of small-offset normal faults develop, along which the lithosphere moves up from the deep axial valley region Only with limited strength loss that occurred very rapidly with strain does the model develop a fault pattern that bears some resemblance to real axial-high flanking faults Our work shows that differences in magmatic input to dykes may produce the observed differences in faults Outside this region that is underlain by magma the lithosphere is too strong to respond in a local isostatic manner Pairs of graben-bounding faults that dipped towards each other developed during plate unbending Previous numerical treatments of this model could not resolve faults and so direct comparisons with observed fault populations have not been possible Rather than pillow basalts that are cut by high-angle faults, the core complex surface, sometimes called a detachment, may expose gabbros and mantle rocks that were probably brought up from depths of at least several kilometres Real dykes are intruded over a matter of days with the time between intrusion events measured in years , but in the model we consider the time-averaged rate of dyke intrusion Second, faults bounding abyssal hills near fast-spreading ridges begin to form ∼2–4 km from the axis of normal axial highs and not at the axis, where the seismically imaged lithosphere is thinnest  Several dozen numerical cases were run with various values of M , strain weakening rates and numerical grid sizes Slower strain weakening had to occur to get larger-offset faults seen at some slow-spreading centres Solid-state advection below the ridge axis should also affect the thermal structure of the ridge axis, but for simplicity we fix the thermal structure Stretching faults should dip towards the axis Stretching is related to loads and motions at the scale of plate tectonics Structures developed in association with model large-offset faults are similar to the oceanic core complexes seen at more than twenty ridge-transform intersections on slow-spreading ridges  Such distributed small-offset, high-angle normal faults are seen on the surface of oceanic core complexes  Temporal variations in magma supply on a very long timescale are not required to produce large-offset faults The across-axis strength structure can also affect the pattern of faulting, although the models presented here do not deal with different strength structures The base of the dyke column is placed within the weak asthenosphere, which always deforms via viscous creep (see Supplementary Information for details) The continued weakening may relate to wearing and widening of the fault zone with greater offset The density of the axial zone controls the normal stress boundary condition applied to the axial elements and to the level of accretion of the top accreted elements The distance L from the axis out to which the fault can remain active should depend on the strength structure of the axis and the fault-weakening parameters The dyke column is placed at the axis of the assumed symmetric ridge thermal and strength structure ( Fig. 2b ) The fast strain weakening may correspond to the sudden loss of cohesion as a fault break forms The faults develop over such a wide distance range because that is where progressive unbending occurs, and the faults cease growing where the plates are essentially flattened out The faults did not develop appreciable offset until they were several kilometres away from the axis and they grew steadily out to a distance of ∼20–25 km The great variations in the fault pattern along many ‘normal’ slow-spreading segments (for example, Fig. 1 ) appear to require very different rates of magmatic dyke intrusion along those segments The horizontal component of fault slip rate is V p (1 - M ), so the amount of fault offset before abandonment is L (1 - M )/( M - 0.5), as plotted in Fig. 4  The lithosphere of the outside corners looks more like typical slow-spreading lithosphere with moderate-amplitude abyssal hills and nearly continuous exposures of pillow basalts at the surface  The magma and underlying partial melt should accrete to the sides of the adjacent separating plates and get denser as it cools and freezes The main simplifying assumption in the model is that fluid magma rises to the level of local isostatic equilibrium at the axis of plate spreading The model uses an explicit finite-element approach that efficiently deals with elastic, viscous and brittle-plastic deformation and is set up in a way similar to our previous ridge faulting studies  The near-off-axis lithospheric thickness of both fast- and slow-spreading ridges may be nearly the same, on the basis of seismic interpretations and thermal models of ridges  The numerical models developed here show how distant loads and local loads may produce very different modes of normal faulting at mid-ocean ridges The obliquity of nearly amagmatic parts of ultraslow-spreading ridges may be directly tied to the lack of dyke intrusions coming from a magma chamber at the centre of a segment The other (footwall) block continues to move up and out as asthenosphere from below accretes to that layer The pattern of faulting in the numerical models of axial-high-related plate unbending is very sensitive to the prescribed rate and amount of weakening with strain The pattern of faulting produced by stretching a spreading centre is controlled by the rate of magmatic accretion The rate of dyke opening is specified by the fraction of the plate separation rate, M , that is accommodated by magmatic dyke opening The results of two cases with the same strength structure, grid size and strain-weakening parameters are shown in Fig. 5  The space generated at the valley by the far-field pull of plate tectonics can be filled by magmatic dyke intrusion at lower stress than is needed for faults to slip and accommodate tension  The tectonic pull caused by cooling and contraction of plates that float on a weak asthenosphere can contribute to stretching by transmitting stresses over long distances The top of the dyke is set at the height of the adjacent elements, which are free to move up or down in the course of a calculation The top of the new column is set to be at the level of local isostatic equilibrium The velocity step across the axial dyke is MV p  There may be a central, magma-rich part of these segments where the magma supply is nearly enough to accommodate plate separation ( M just below 1) with an adjacent magma-poor part of the segment where M ≈ 0.5 These cases show that the normal fault offset varies greatly as a function of M and that for M = 0.5 we can get a very large fault offset, as predicted by our kinematic conceptual model These density variations may be important at fast-spreading ridges because the axial lithosphere is very thin, hot and underlain by partially molten crust  These regions have been likened to continental metamorphic core complexes where rocks from depths of ∼10 km are exposed at the surface Third, a completely different type of fault structure was discovered on parts of slow-spreading ridges called ‘oceanic core complexes’ or ‘megamullion’ structures ( Fig. 1c ) This assumption is based on the idea of feeding of melt to magma chambers at the centres of ridge segments, for which there is ample evidence  This bright reflector has characteristics consistent with a magma-filled lens and so is described as an axial magma chamber This load bends down each plate, and additional accretion forms a plate with a concave upward curvature This may account for the limited offset of the large faults seen in this case This plot is at best a qualitative guide to expected results because L is expected to be a nonlinear function of fault offset  This small stretching on one side of the axis will contribute to migration of the large-offset faults away from the axis on the other side of the axis Three specific observations stand out Thus, the hanging-wall block of the fault will move away from the axis at a speed of V p ( M - 0.5) To approximate the strength structure of slow-spreading ridges we assumed uniform elastic coefficients, pressure- and strain-dependent Mohr Coulomb brittle-plastic failure stresses and temperature-dependent non-newtonian viscosity ( Supplementary Information ) To deal with faulting at fast-spreading ridges we consider the effect of local buoyancy To explain the 1–2-km-deep, 20–30-km-wide axial valley seen at most slow-spreading ridges (see Fig. 1b , c ) was a great challenge of early ridge studies To fit these core complex structures into the standard stretching model, amagmatic spreading with durations of the order of a million years would be needed To get the large-offset faults that may characterize oceanic core complexes our models require that three conditions be met To look at fault development near ridges we use a numerical technique that allows for localization of the deformation in a brittle-plastic layer in shear zones simulating faults  To simulate the freezing of partially molten lower crust, elements are also accreted at the non-vertical boundary between the weak axial zone and the brittle lithosphere ( Fig. 2a ) To study how faults form it is logical to look at mid-ocean ridges, where faults are constantly forming Two phases of strain weakening were needed Understanding why the magmatic accommodation of plate separation varies so much along ridge segments, and why it seems to occur in various modes rather than vary smoothly, is a clear challenge to understanding how spreading centres work. Unlike other models it does not depend on potentially complex viscous flow under the ridge axis Unlike typical spreading segments, magma-starved parts of ultraslow-spreading segments can be oblique to the spreading direction We adopt the approach of the recently developed accretional curvature model  We believe that these small faults, which were not part of our kinematic conceptual model, accommodate a small part of the tectonic stretching across the axis We have considered only end-member cases to demonstrate these ideas, so we can only speculate about the behaviours of ridge segments with a range of spreading rates and magma supply
 A magnitude-7.3 quake struck, and Chinese officials claimed that the prediction had saved thousands of lives Advocates are pushing lawmakers to find more money for the NIH, but there is little time: the House hopes to finalize all budgets by the 4 July recess Am. 96, 757–795; 2006) Among those who used its legendary 40-inch telescope are astronomer Edwin Hubble and astrophysicist Subrahmanyan Chandrasekhar.* Geologists find clues to Chinese quake prediction The background to one of the most famous earthquake predictions in history has now been established, after a team of scientists gathered declassified documents and interviewed local people to determine what really happened An editor at Angewandte Chemie says the journal will look into the matter Antiquated and hampered by light-polluted skies, the observatory has had limited use as a research facility since the 1970s Blue indicates thinner, cirrus-type clouds Both the University of California, San Francisco, and Harvard University have begun work in the field that was set back when Woo Suk Hwang, South Koreas cloning pioneer, was found to have fabricated some of his published findings Brighter outlook for stem-cell research in Europe International societies for stem-cell research have written an open letter of support to Italys new research minister, Fabio Mussi, who has said he will withdraw Italy from a pledge to oppose the use of European Union (EU) money for human embryonic stem-cell research But earthquake forecasting has enjoyed little success since Chem Chen, S Cloud satellite pierces the gloom Earths clouds are getting their best-ever internal scans, now that NASAs CloudSat satellite is up and running CloudSat and its partner satellite CALIPSO are building up a global picture of atmospheric water droplets and aerosols, which is designed to resolve the three-dimensional structure of clouds (see Nature 437 , 468 – 469 ; 2005 ). Computations cast doubt on chemical synthesis An impressive 37-step chemical synthesis published this year (J D Each of the 100-square-kilometre ‘exploratories’ is divided into 1,000 observation units Ed. 45, 2769–2773; 2006) has been called into question German biodiversity study goes back to the land A large-scale field study in Germany aims to investigate the relationship between land-use intensity and biodiversity in unprecedented detail Harvard officials announced on 6 June that they had given the go-ahead after two years of regulatory review by eight committees Historic observatory to be preserved in luxury complex Spa-goers and star-gazers can live side by side at the Yerkes Observatory House votes against budget boost for the NIH Call it the case of the disappearing cash In February 1975, local governments ordered some areas around Haicheng, a town in northeast China, to be evacuated Int La Clair Angew Lett. doi:10.1021/ol0611346; 2006) Maybe I synthesized a compound that is not hexacyclinol but something else, and it needs a new name.”  La Clair has been engaging with critics on at least one chemistry blog On 7 June, a subcommittee of the US House of Representatives voted not to raise the budget of the National Institutes of Health (NIH) next year One goal is to gather reference data to be able to study biodiversity changes in the future in a more coordinated manner Research advocates say this defies the expectations set in May, when the House voted to spend an additional $7 billion on health and education programmes. “To see the NIH is getting nothing of that is disappointing,” says Jon Retzlaff, director of legislative relations at the Federation of American Societies for Experimental Biology Researchers will use the field data to test ideas about how biodiversity changes as woodlands and grasslands change from semi-natural to intensively used environments Rychnovsky Org Rychnovskys computer predictions suggest that the molecule was assigned the wrong structure when first isolated from a fungus in 2002 Scott Rychnovsky, a chemist at the University of California, Irvine, says the synthesis of the chemical hexacyclinol is “an impossibility” if his computational paper is right (S Seismol Six EU countries opposed to embryonic stem-cell research signed the pledge in November So Kelin Wang of the Geological Survey of Canada recently teamed up with three colleagues in China to document the history of the Haicheng prediction (K So what was synthesized? The author of the Angewandte Chemie paper, James La Clair of the Xenobe Research Institute in San Diego, California, says: “I didnt make it up Soc Sun and A The budget approval process is taking longer in the Senate, where lawmakers have promised to boost budgets The colours represent particles of different reflectivities, with red indicating highly reflective particles such as water droplets or ice crystals The EUs seventh Framework research programme, now going through the final stages of political approval, has provisions for such research — even though it is forbidden in some EU countries The letter, on behalf of the International Society for Stem Cell Research and the European Consortium for Stem Cell Research, applauds what it calls an “honourable decision” that would ensure that “Italy is no longer blocking scientific progress for universal benefit” The New York-based Mirbeau Company plans to build a 100-room spa and 72 luxury homes on part of the site, pending approval by the nearby village of Williams Bay, Wisconsin The observatory and most of the remaining land will be preserved as an education and outreach facility — run by a non-profit organization and funded in part by room and property taxes from the new buildings The region had previously been identified as at risk, but Wangs team found that local officials gave orders to evacuate after a series of strong foreshocks The teams plan to ask women to donate their eggs, but do not know whether they will undergo the invasive procedure for research purposes only The three-year, €8-million (US$10-million) project funded by the DFG, Germanys main research-funding body, will be located at three test sites in different parts of the country The University of Chicago has sold the 109-year-old building and surrounding site to a land developer for roughly US$8 million The US teams now join some half-a-dozen groups around the world already working to grow human embryonic stem cells from cloned human embryos The vote would leave the NIH budget at $28.3 billion — still making it the richest US science agency, but with an essentially flat budget after being cut last year for the first time in three decades The work is highly controversial because human embryos are discarded in the process, and US researchers are banned from using federal research money for such studies Their combined weight would have blocked approval of the Framework programme provisions, but if Italy withdraws, the block would be lifted They tracked down and translated documents, from secret reports to notes in geologists logbooks This image, of a warm-front storm over the Norwegian Sea on 20 May, is the first returned by the spacecraft Unfortunately, foreshocks dont occur before every quake US universities cleared to continue stem-cell research Two US universities are back in the race to grow embryonic stem cells matched to human patients Wang Bull Wang, Q.-F
 A deeper understanding of these mechanisms is expected from studying the genes present in the identified chromosomal ‘magnetosome island’, for which the connection with magnetosome synthesis has become evident  According to our hypothesis, magnetosome architecture represents one of the highest structural levels achieved in prokaryotic cells. Here we use gene deletion in Magnetospirillum gryphiswaldense to show that magnetosome alignment is coupled to the presence of the mamJ gene product Magnetotactic bacteria are widespread aquatic microorganisms that use unique intracellular organelles to navigate along the Earths magnetic field MamJ is an acidic protein associated with a novel filamentous structure, as revealed by fluorescence microscopy and cryo-electron tomography Questions in the study of magnetosome formation include understanding the factors governing the size and redox-controlled synthesis of the nano-sized magnetosomes and their assembly into a regular chain in order to achieve the maximum possible magnetic moment, against the physical tendency of magnetosome agglomeration These organelles, called magnetosomes, consist of membrane-enclosed magnetite crystals that are thought to help to direct bacterial swimming towards growth-favouring microoxic zones at the bottom of natural waters  We suggest a mechanism in which MamJ interacts with the magnetosome surface as well as with a cytoskeleton-like structure A 1,394-bp upstream region and a 1,433-bp downstream region of mamJ were amplified using the primers ASmamJu_f/ASmamJs_r (5′-GGAATTCTTACCCCCAATGGTGCGTTTG-3′; 5′-CCCGGGCATTATCCCGCTCCACCCTCAA-3′) and ASmamJe_f/ASmamJd_r (5′- CCCGGGTAGAGACCTGTGGATTGATCTGT-3′; 5′-CTCTAGAGCTCATCCTTACCTACTCCAAAG-3′), respectively All surface-rendered visualizations were de-noised beforehand by anisotropic nonlinear diffusion Briefly, cells were aligned at different angles relative to a light beam by means of an external magnetic field Bright-field TEM images were obtained with a Zeiss EM10 transmission electron microscope at an accelerating voltage of 60 kV Cell membranes were stained with FM4-64 (final concentration 1 nM) Construction and detection of fusion proteins The M. gryphiswaldense mamJ gene (accession number AM085146) and egfp ( pEGFP-N2 , Clontech ) were amplified using primers ASmamJs_f/ASmamJe_r5 (5′-GGAATTCATGGCAAAAAACCGGCGTG-3′; 5′-GCCCTTGCTCACCATTTTATTCTTATCTTCAGC-3′) and ASegfp_f1/ASegfp_r3 (5′-GCTGAAGATAAGAATAAAATGGTGAGCAAGGGC-3′; 5′-TCTAGATTACTTGTACAGCTCGTCCATGCC-3′), respectively Construction of an unmarked in-frame mamJ deletion mutant Gene replacement was performed by homologous recombination of flanking sequence regions of mamJ between the M. gryphiswaldense chromosome and pAS2 Double-crossover was confirmed by Southern blot analysis Electron microscopy For TEM, cells and isolated magnetosomes were adsorbed on carbon-coated copper grids Energy-filtered TEM (EFTEM) was performed on a Philips CM120 BioTwin equipped with a Gatan energy filter. ‘Most probable loss images’ were acquired at around 30 eV with a 20-eV energy window and with white and black inverted as described  Expression of MamJ–EGFP in Δ mamJ cells restored magnetosome chain formation as monitored by electron microscopy Fluorescence microscopy was performed using an Olympus AX70 microscope equipped with a digital CCD camera For tomography, wild-type and Δ mamJ mutant cells were vitrified in liquid ethane and investigated at liquid nitrogen temperature with a Philips CM300 field emission transmission electron microscope equipped with a Gatan energy filter Fragments were fused by cloning into the Eco RI and Xba I sites of the pK19mobsacB vector, resulting in pAS2 Image rescaling and cropping was done using Photoshop 6.0 Images were acquired with Metamorph 5.0 ( Universal Imaging Corp. ) using exposure times of 0.5–5.0 s In addition, presence of the product of the mamK gene (which is located immediately downstream of mamJ ) was confirmed using a specific antibody (data not shown) In this medium, which contained only trace amounts of iron, cells formed only a few tiny crystallites and did not show a magnetic response Liquid cultures of wild-type and mutant strains of M. gryphiswaldense MSR-1 (DSM6361) were grown microaerobically in modified FSM medium  Magnetite induction experiments were performed microaerobically on these non-magnetic cells in modified FSM medium that had a reduced content of carbon sources Magnetosomes were isolated as previously described from cultures grown microaerobically in an oxygen-controlled fermenter  Methods Bacterial strains, media and magnetosome isolation Escherichia coli strains were grown as described  Multiple single-axis tilt-series at cryo-conditions and in zero-loss imaging mode were recorded and reconstructed by weighted back-projection Non-magnetic cells were grown at moderate iron limitation by repeated cultivation in modified FSM medium, from which ferric citrate and yeast extract were omitted Owing to the limited tilt-range (± 60°), all tomograms contain artefacts (the ‘missing-wedge’ effect, that is, information missing perpendicular to the tilt-axis), resulting in surface-rendered representations that show incomplete visualization of the cellular membrane and vesicles. Plasmids were introduced into M. gryphiswaldense by biparental conjugation and screening for recombinants was performed as previously described  Purified magnetosomes were negatively stained with 2% (w/v) uranyl acetate Restoration of the chain-forming phenotype in Δ mamJ cells was achieved by transcomplementation with wild-type mamJ expressed from plasmid pBBR1MCS2 Single colonies were cultivated on ACA medium  The average magnetic orientation of cell suspensions (‘magnetic response’) was assayed by an optical method as previously described  The nonpolar character of the mutation was confirmed by reverse transcription PCR detection of the transcripts of several genes located downstream of mamJ  The ratio of the resulting maximum and minimum scattering intensities ( C mag ) is well correlated with the average number of magnetic particles and can be used for quantitative assessment of magnetite formation (for practical purposes, non-magnetic cells were assumed to have C mag = 0) Under these conditions, cells did not grow appreciably but remained viable and produced magnetosomes for several hours upon induction of magnetite formation by the addition of ferric citrate to a final concentration of 50 µM Using the gene fragments as templates, fusion polymerase chain reaction (PCR) with the ASmamJs_f/ASegfp_r3 primer pair generated a functional 1,998-bp mamJ – egfp fusion, which was cloned into the EcoR I and Xba I sites of the pBBR1MCS2 vector Among them, we identified the conspicuous 426-amino-acid MamJ protein , which is characterized by a high content of acidic amino acids and a repetitive domain structure ( Supplementary Fig. 1 ), features that have frequently been found in other proteins associated with biomineralization processes  Approximately 30 min after induction, small (approximately 5–10 nm in diameter) crystallites were formed simultaneously at multiple discrete sites along the entire length of both wild-type and mutant cells At closer inspection, both wild-type and mutant magnetosomes were tightly interconnected by organic material, which appeared to form junctions between individual particles ( Fig. 1a , inset II) At this time, electron-dense particles seemed mostly confined to midcell Consistent with a tightly regulated biosynthetic assembly, a large genomic ‘magnetosome island’ was identified as being essential for magnetosome formation in M. gryphiswaldense  Consistent with the position of magnetosome chains as revealed by TEM ( Fig. 1a ), the fluorescent structure is located close to the concave side of the cell, but exceeds the length of magnetosome chains, which are usually confined to the midcell Contrary to our expectations, the mutant was not affected in biomineralization, but produced magnetite crystals identical in size, morphology and number to wild-type magnetosomes Empty vesicles and immature magnetosomes were predominantly located at the ends of chains in wild-type cells, and mature magnetosomes were mostly found at midcell Filaments extended up to the cell pole (data not shown) and were located close to the cytoplasmic membrane First, they must precisely control the biomineralization of a magnetite crystal within the single-magnetic-domain size range For better visualization of empty vesicles, we grew cells at moderate iron limitation to reduce the number of magnetite crystals Given that magnetosome chains resembling those in magnetotactic bacteria have been identified in higher organisms , the biological mechanisms of chain formation will be relevant for understanding the evolution and function of magnetoreceptive organelles in both prokaryotic and eukaryotic organisms. Given the essential requirement of MamJ for the assembly of magnetosome chains, we postulate a mechanism that involves magnetic interactions within the chain, physical contact between adjacent particles, and the interaction of MamJ with a cytoskeleton-like structure that directs the assembly and localization of the prokaryotic organelles ( Fig. 4 ) Glöckner, and D However, a string of magnetic dipoles has an inherent tendency to agglomerate in order to lower its magnetostatic energy , unless it is adequately stabilized by an organic structure However, although mutant cells responded to external magnetic fields if examined by microscopy, they showed substantially reduced magnetic orientation in a quantitative light-scattering assay , as measured by C mag (the ratio of maximum and minimum scattering intensities; C mag wild type, 1.7; Δ mamJ , 0.5) as numerous larger particles were present In addition, such a structure would have to properly anchor the chain, in order to rotate the whole cell into alignment with magnetic field lines  In contrast, cytosolic localization of the MamJ–EGFP fusion was observed if expressed in the non-magnetic mutant strain MSR-1B, in which a large part of the magnetosome island (including all magnetosome genes) has been deleted  In contrast, the localization of immature crystals did not change significantly for about 140 min in Δ mamJ cells In fully magnetic wild-type cells, mature magnetosome chains were adjacent to the cytoplasmic membrane, apparently following the cell curvature in a helical manner ( Supplementary Fig. 2 ) In such a configuration, the total magnetic dipole moment is the sum of the moments of individual particles—this generates the maximum possible magnetic moment for magnetotaxis  In vivo , a functional MamJ–EGFP fusion protein was visualized as a linear structure stretching from pole to pole in both wild-type and Δ mamJ cells ( Fig. 1b ) In wild-type cells, growing crystals started to concentrate at midcell after 175 min, first assembling into imperfect, loosely spaced chains that gradually (over 360 min) developed into straight, tightly packed chains of mature particles In Δ mamJ cells, empty vesicles were widely spaced and located along the entire length of cells, in contrast to the tightly packed clusters of mature magnetite crystals usually located at midcell In Δ mamJ cells, however, empty vesicles and those containing immature crystals were scattered throughout the cytoplasm and were dissociated from the filaments Individual filaments were approximately 3–4 nm thick, which is in good agreement with similar structures observed in Spiroplasma melliferum  Intriguingly, mamJ is co-transcribed with the mamK gene (S Magnetite crystals from Δ mamJ cells were membrane-enclosed and no longer organized in clusters, but spontaneously re-formed in-plane chains or flux-closed rings identical to those of wild-type cells ; however, removal of organic material by SDS caused agglomeration of particles Magnetotactic bacteria are of considerable biophysical interest because they have evolved cellular mechanisms that allow them to exactly meet the requirements for effective magnetic orientation  Notably, most magnetosome vesicles were arranged closely along this filamentous structure in wild-type cells Notably, transmission electron microscopy (TEM) revealed that the mutant no longer produced straight magnetosome chains, but that magnetite crystals were instead arranged in compact three-dimensional clusters ( Fig. 1a ) O Our observation that this cytoskeletal structure seems to be absent in the MSR-1B mutant (which lacks mamK ) is consistent with this speculated role Our results demonstrate that magnetosome chain assembly is genetically controlled to achieve one of the highest structural levels in a prokaryotic cell for optimal function in magnetotaxis S., manuscript in preparation), which has previously been hypothesized to encode a cytoskeletal structure because of its striking similarity to actin-like MreB proteins in other bacteria  Schübbe, C Second, growing particles must be properly assembled into a linear chain  The mechanisms governing the formation of magnetosome chains, and any structures preventing them from collapse, have remained elusive The organization of the filamentous structures, however, appeared identical to that in wild-type cells These observations indicate that the presence of the magnetosome membrane is required for coherence within the chain, but that the ability to form chains in vitro is not affected by loss of MamJ These results indicate that a structure resembling a cytoskeleton is associated with the magnetosome chain, and that the MamJ protein connects magnetosome vesicles to this putative cytoskeletal structure This indicates that the agglomeration of particles occurs at a later stage of crystal growth, and is probably caused by increasing magnetic attraction between crystals once they are in close proximity to each other This magnetosome island encodes a number of specific magnetosome-associated polypeptides, the exact functions of which are unknown This observation prompted us to examine whether the formation of clusters results from agglomeration of empty magnetosome vesicles, or whether chain collapse is instead caused by magnetic interactions between mature magnetite crystals This pattern is most likely explained by the dynamic localization of magnetosome particles during chain assembly This pattern, which is reminiscent of the localization of a GFP fusion with a different magnetosome protein (MamA) , indicates that the localization of MamJ does not depend on the presence of mature magnetite crystals This suggests that MamJ interacts with a linear structure encoded within the magnetosome island, but is not likely to form this structure itself To analyse this in greater detail in a close-to-native state, we studied subcellular structures putatively governing the localization of MamJ by means of cryo-electron tomography (cryo-ET), which allows three-dimensional reconstruction at high resolution with a minimum of preparative artefacts To determine whether clustering resulted from a loss of magnetosome membrane integrity caused by the Δ mamJ mutation, we isolated magnetosomes from wild-type and mutant cells To verify the assumed essential role of MamJ in the formation of functional magnetosomes, we generated a MamJ-deficient mutant strain (Δ mamJ ) ( Supplementary Fig. 2 ) Tomograms of wild-type and Δ mamJ cells clearly showed a network of filamentous structures ( Fig. 2 and Supplementary Video 1 ) We next constructed enhanced green fluorescent protein (EGFP) fusion proteins in order to visualize the subcellular localization of MamJ We therefore studied the process of magnetosome formation in a time course experiment ( Fig. 3 ) Würdemann, F
 50 YEARS AGO ...you reveal more than I think you were aware of when writing “a nation using...a minority language cannot escape bilingualism if it desires to attain high standards of scholarship” Bastians heresies, we cannot but admire his dogged support of what seems to us a lost cause Charlton Bastian re-expounds his well known biological heresies with a vigour and industry worthy of a better cause From Nature 15 February 1906. From Nature 18 February 1956. 100 YEARS AGO Dr H If the sentence is understood as referring to the use of minor languages for publishing, it is indisputable; but all too frequently it turns the other way — scholars within the major language groups neglecting the literature outside their own language.. It is a waste, and it is also inconsiderate, to publish primary scientific material in a minor language It is something to stand unus contra mundum with no loss of courage or good humour That our Soviet colleagues know more about ‘Western’ literature than the reverse is nothing new, but it is deplorable.. That the English and even more the American literature should emerge as the narrowest is scarcely unexpected.. The expected happens — multitudes of living particles appear.. The first heresy is that “ archebiosis ” is a present occurrence, that living organisms may here and now arise from non-living materials... we are recommended to take an infusion of turnip or fresh beef, to filter this through two layers of the finest Swedish paper, to let a drop fall on a cleaned microscope slip, to put a cover-glass on, to remove excess of fluid with blotting paper, to allow one or more air bubbles to remain in the film, to seal up with melted paraffin wax...to incubate at blood-heat for two to three hours, and to await events To illustrate this point I have made a small survey of world scientific literature.. While we must stand aloof from Dr
 An enzyme demonstrated to influence implantation, cyclooxygenase 2 (COX2) (ref. 5 ), was downregulated in LPA 3 -deficient uteri during pre-implantation Downregulation of COX2 led to reduced levels of prostaglandins E 2 and I 2 (PGE 2 and PGI 2 ), which are critical for implantation  Every successful pregnancy requires proper embryo implantation Exogenous administration of PGE 2 or carbaprostacyclin (a stable analogue of PGI 2 ) into LPA 3 -deficient female mice rescued delayed implantation but did not rescue defects in embryo spacing Here we report a newly discovered molecular influence on implantation through the lysophosphatidic acid (LPA) receptor LPA 3 (refs 2–4 ) Low implantation rate is a major problem during infertility treatments using assisted reproductive technologies  Targeted deletion of LPA 3 in mice resulted in significantly reduced litter size, which could be attributed to delayed implantation and altered embryo spacing These data identify LPA 3 receptor-mediated signalling as having an influence on implantation, and further indicate linkage between LPA signalling and prostaglandin biosynthesis. These two events led to delayed embryonic development, hypertrophic placentas shared by multiple embryos and embryonic death Because no difference was observed for all the parameters examined between wild-type and heterozygote female mice ( Supplementary Table 2 , Supplementary Fig. 8a, b , and data not shown), females of either wild-type or heterozygote genotypes were used as controls Data representation Data are expressed as mean ± s.d Embryos at E10.5 were fixed in 10% formalin overnight before being weighed Females were naturally mated with wild-type stud males For amplification of COX2, the following primers were used: forward 5′-AAGCGAGGACCTGGGTTCA-3′; reverse, 5′-AAGGCGCAGTTTATGTTGTCTGT-3′ Implantation sites at E4.5 and E5.5 were localized by intravenous injection of Evans blue dye (200 µl, 1% in 1 × PBS, Sigma )  Implantation sites were detected using Evans blue dye at E4.5 In situ hybridization and histology The animals were anaesthetized with halothane inhalation followed by cervical dislocation In situ hybridization and histology were performed as described  Mating, embryo collection and implantation localization All the mice used in this study were of mixed background (129/SvJ and C57BL/6) Methods Quantitative RT–PCR Primers used were as described  PGI 2 was measured as 6-keto-PGF 1α  Plugged females were anaesthetized with halothane inhalation followed by cervical dislocation Prostaglandin administration E3.5 LPA 3 -deficient females were intraperitoneally injected with 100 µl of vehicle (10% ETOH with saline, as control) or 5 µg cPGI and 5 µg PGE 2 ( Cayman Chemical , in 10% ETOH with saline) at 10:00 and 18:00 Prostaglandin measurement Uteri from E3.5 wild-type or LPA 3 -deficient mice were immediately frozen and crushed in liquid nitrogen Prostaglandins were extracted by the ethyl acetate extraction method Quantitative RT–PCR was performed as described  Sense and antisense DIG-labelled cRNA probes were generated using appropriate polymerases from a full-length murine LPA 3 complementary DNA Statistical analyses were done using Students t -test or χ 2 test The day a plug was found was designated as E0.5 The number of embryos initially implanted in LPA 3 -deficient and wild-type and heterozygote uteri were retrospectively calculated from E10.5 as follows: at E10.5, embryos in an average of 1.2 implantation sites (out of a total of 5.0) were absorbed in LPA 3 -deficient uteri, but embryos in only 0.09 implantation sites (out of a total of 8.4) were absorbed in wild-type and heterozygote uteri ( P = 1.7 × 10 -5 ) The prostaglandin levels of each sample were determined using the prostaglandin enzyme-linked immunoassay kit ( Cayman Chemical ) The significance level was set at P 0.05. The transcript number of target genes was quantified and normalized against GAPDH or β-actin transcript number Uteri of pregnant females were dissected at E3.5, E4.5, E5.5, E10.5 and E18.5 With an average of 1.65 live embryos per implantation site in LPA 3 -deficient uteri and 1.0 live embryo per implantation site in wild-type and heterozygote uteri at E10.5, the total number of embryos initially implanted should be 8.3 ((3.8 live + 1.2 absorbed) × 1.65) in LPA 3 -deficient uteri and 8.4 ((8.31 live + 0.09 absorbed) × 1.0) in wild-type and heterozygote uteri After prostaglandin exposure, significantly more LPA 3 -deficient female mice with normal (on-time) implantation were detected compared with LPA 3 -deficient females given vehicle controls ( Fig. 4c , P = 0.003) As a class, lysophospholipid receptors represent a ‘drugable’ target, as demonstrated by the compound FTY720, which is currently in phase III clinical trials for prevention of transplantation rejection  At E10.5, 44% of implantation sites in LPA 3 -deficient uteri contained two to four embryos (averaging 1.65 live embryos per implantation site) ( Fig. 2a , b ) At E18.5, 28% of placentas were shared by two to three embryos ( Fig. 2c ) and associated with placental hypertrophy ( Fig. 2d ; see also Supplementary Fig. 5 ) By E4.5, implantation sites identifiable by Evans blue labelling in control animals were absent in uteri of LPA 3 -deficient dams Components of prostaglandin signalling were therefore examined in uteri of LPA 3 -deficient mice Considering the fact that no LPA 3 mRNA was detected in wild-type pre-implantation blastocysts, these results eliminate significant contributions of LPA 3 via pre-/post-implantation embryos, and indicate that maternal LPA 3 signalling is responsible for the observed phenotypes Consistent with this function, the suppression of COX2 expression in E3.5 LPA 3 -deficient uteri resulted in reduced production of PGE 2 and PGI 2 ( Fig. 4b ), leading to conditions that are inadequate for implantation, which normally occurs around E4.0 (refs 18 , 26 ) COX2 is a rate-limiting enzyme for prostaglandin biosynthesis Delayed implantation and aberrant embryo spacing were thus associated with both delayed embryonic development and embryonic death, which could account for the reduced litter sizes produced by LPA 3 -deficient females Deletion of LPA 1 and LPA 2 in mice revealed roles for these receptors in neural development, craniofacial formation, neuropathic pain and altered cellular signalling, but without obvious effects on female reproduction  Functional deletion of LPA 3 was achieved by replacing a fragment covering the untranslated region and the start codon in exon 2 with a neomycin-resistance gene in reverse orientation in R1 embryonic stem cells ( Supplementary Figs 1 and 2 ) However, LPA 3 -deficient females produced litter sizes of less than 50% compared with that of wild-type and LPA 3 heterozygote controls ( Supplementary Table 2 ), and showed a statistically significant prolongation of pregnancy (20.9 ± 0.5 days versus 19.4 ± 0.7 days in wild-type and LPA 3 heterozygote controls, P 0.05) Implantation sites became detectable at E5.5 in uteri of LPA 3 -deficient mice ( Fig. 1f , g )  In addition to delayed implantation, LPA 3 -deficient uteri had a reduced number of implantation sites compared with that in the control uteri, despite the fact that comparable numbers of blastocysts were available for implantation In addition, embryos isolated from LPA 3 -deficient uteri (at E10.5 and E18.5) were always smaller than those from wild-type or LPA 3 heterozygote controls at comparable ages ( Fig. 3a–c ), although newborns from LPA 3 -deficient females were, on average, heavier ( Fig. 3c ), possibly resulting from prolonged pregnancy and/or smaller litter size In contrast, embryo implantation studies identified clear phenotypic changes in LPA 3 -deficient dams: delayed implantation and altered positioning/crowding of embryos In view of the phenotypic similarities between LPA 3 deficiency and cPLA 2α /prostaglandin deficiency, we proposed that LPA 3 might converge on this signalling pathway Indomethacin is an inhibitor of cyclo-oxygenases , which convert arachidonic acid to prostaglandin H 2 (PGH 2 ) in the biosynthesis of prostaglandins, whereas cPLA 2α is an important enzyme producing arachidonic acid LPA 3 is a receptor with distinct signalling properties and a preference for unsaturated LPA species  LPA has a range of influences that are mediated by at least four G-protein-coupled receptors, LPA 1–4 (ref. 2 ) Moreover, PGE 2 and carbaprostacyclin (cPGI, a stable analogue of PGI 2 ) can partially correct implantation defects in both cPLA 2α -deficient and COX2-deficient mice  Multiple factors can adversely affect successful pregnancy No significant differences in blastocyst number or developmental stage, isolated from E3.5 uteri, were observed between control and LPA 3 -deficient females No significant differences were observed in superovulation, fertilization or decidualization between wild-type or LPA 3 heterozygote controls and LPA 3 -deficient female littermates Notably, COX2 deficiency, but not COX1 deficiency, in mice results in multiple female reproductive failures, including implantation defects , although the precise phenotypes can be influenced by genetic background  Notably, LPA 3 mRNA levels increased during early pregnancy, peaking around embryonic day 3.5 (E3.5) then returning to basal levels from E4.5 through to the end of pregnancy ( Fig. 1a ) Notably, this rescue did not affect the uneven embryo spacing nor completely restore the reduction of implantation sites compared with wild-type controls ( Figs 1g and 4d ) One molecular factor that has been previously implicated in female reproduction is the small, bioactive phospholipid LPA  Only COX2 mRNA levels were significantly reduced in LPA 3 -deficient uteri ( Fig. 4a , Supplementary Fig. 7 , and data not shown) RT–PCR of microdissected E3.5 uterine tissue and in situ hybridization indicated that LPA 3 mRNA expression was confined to the luminal endometrial epithelium at E3.5 ( Fig. 1b–d ; see also Supplementary Fig. 3c ) RT–PCR revealed the presence of LPA 3 mRNA in oviduct, placenta and uterus but not in ovary and eggs (unfertilized eggs and fertilized eggs from one cell to pre-implantation blastocyst; data not shown) Similarly, when LPA 3 -deficient blastocysts were transferred to wild-type pseudo-pregnant uteri, no implantation or spacing abnormalities were observed ( Supplementary Fig. 6 and data not shown) The average number of live embryos per animal that could be isolated from LPA 3 -deficient females decreased after initial implantation ( Fig. 3d ) The implantation sites in the LPA 3 -deficient uteri were crowded/clustered in the uterine segments proximal to the cervix ( Fig. 1g ) The LPA 3 -deficient mice were born with normal mendelian frequency without sexual bias ( Supplementary Table 1 ), and appeared grossly normal (data not shown) The number of pre-implantation blastocysts recovered from E4.5 LPA 3 -deficient uteri was comparable to that from E3.5 control and LPA 3 -deficient uteri ( Fig. 1e ), indicating that delayed implantation in uteri of LPA 3 -deficient mice was due to extra-embryonic influences of LPA signalling The observed implantation phenotypes of LPA 3 -deficient mice were markedly similar to those reported for rats and mice treated with indomethacin , and for mice deficient in cytosolic phospholipase A 2α (cPLA 2α )  The reduced litter sizes observed in receptor-null mutants for another lysophospholipid, sphingosine 1-phosphate, suggest that other lysophospholipid receptors may also influence mammalian reproduction through pharmacologically tractable mechanisms . These components included cPLA 2α , COX1 and COX2, and G-protein-coupled prostaglandin E 2 receptors EP 1–4 and prostaglandin I 2 receptor, IP , along with leukaemia inhibitory factor (LIF) and Hoxa-10, two key regulators in implantation  These data indicate that the cPLA 2α –arachidonic acid–COX–prostaglandin pathway is crucial for implantation  These data indicated no obvious defects in ovulation, ovum transportation and blastocyst development in LPA 3 -deficient female mice ( Fig. 1e ; see also Supplementary Fig. 4 ) These data suggested that LPA 3 loss of function resulting in reduced litter sizes could involve direct effects on the female reproductive system These factors are particularly important for the clinical success and efficacy of assisted reproductive technologies These findings identify LPA signalling as having an influence on embryo implantation, and are the first to link a lysophospholipid G-protein-coupled receptor to prostaglandin biosynthesis, thereby influencing female fertility These phenomena were never observed in controls These phenotypes were independent of stud genotype, indicating defects in female reproduction These results suggested that LPA signalling in female reproduction might be mediated by other LPA receptors including LPA 3 (formerly known as Edg7) (refs 3 , 4 ), LPA 4 (ref. 15 ), unidentified LPA receptor(s), or possibly non-receptor pathways This aberrant crowding of embryos in uteri of LPA 3 -deficient mice was further demonstrated by findings at later gestational stages This raises the possibility of creating medicines that influence implantation timing, a critical factor for in vitro fertilization and also for reducing the incidence of multi-embryo gestations, especially monochorionic gestations, which can result in fetal demise  To determine whether LPA 3 loss in the embryo itself might contribute to the phenotypes, embryo transfer experiments were pursued To explore this possibility, we examined major events in female reproduction: from ovulation through to decidualization To rescue this prostaglandin reduction, we delivered exogenous PGE 2 and cPGI to E3.5 LPA 3 -deficient female mice, a general approach previously reported  Towards determining whether LPA 3 deletion might directly affect the female reproductive system, expression patterns of LPA 3 messenger RNA were assessed using polymerase chain reaction with reverse transcription (RT–PCR) and in situ hybridization Towards identifying LPA-dependent mechanisms affecting reproduction, we targeted LPA 3 for deletion Transferred wild-type embryos in wild-type or LPA 3 -deficient pseudo-pregnant uteri were phenotypically indistinguishable for implantation and development compared to embryos produced by natural matings in wild-type or LPA 3 -deficient animals Two of these factors are failed synchronization between embryonic and endometrial development during implantation and occurrence of multiple gestations (especially monochorionic gestation), which can result in fetal demise  Wild-type and LPA 3 -deficient blastocysts had comparable implantation rates in wild-type pseudo-pregnant uteri i Within the uterus, LPA 3 mRNA expression was upregulated during postnatal development and varied during the oestrous cycle ( Supplementary Fig. 3a, b )
 A separate budget for a European Research Council will probably be included in the proposal According to commission insiders, the ‘instruments’ of the programme, such as the transnational Integrated Projects and Networks of Excellence, will remain the same After publication, the plan has to be approved by both the European Parliament and the European Council But early indications of its content suggest that the form-filling requirements that irked researchers in previous programmes will not worsen significantly But Janez Potočnik, the Slovenian economist who became EU research commissioner in November, remains confident. “I hope we wont be forced to cut priorities that were favoured in Lisbon,” he says, adding that he doesnt expect this to happen But they will be joined by two new ones: space science and security In preparing its plans, the EU Research Commission has taken into account various political demands, including the ‘Lisbon objectives’, set out in 2000, which aim to increase Europes long-term competitiveness by strengthening research In view of these, it will request that the four-year budget be more than doubled to some €30 billion (US$40 billion) Instruments have sometimes changed radically between each Framework, so that experience gained in applying for one programme did not help much in the next Munich Officials in Brussels are drawing up plans for the European Unions Seventh Framework Programme of Research (FP7), and the proposed scope may cheer the continents scientists Some fear that the creation of this council could make the basic-research component of FP7 politically vulnerable, but Potočnik says he will fight to maintain it. “Basic research is fundamental to our plans at all levels,” he says. The officials hope to avoid major revisions to the existing, Sixth Framework Programme (FP6) — but FP7 will be twice as big and include a more extensive basic-research component The proposal still has to survive months of political wrangling that will follow its publication by the European Commission in April The thematic areas are likely to remain the same: life sciences, information sciences, nanosciences, aeronautics, food quality, energy and governance This approval process has previously reduced Framework programmes and increased the bureaucratic burden on grantees To ensure a smooth transition from FP6, which runs until 2006, final approval will be sought this September
 A Nobel prizewinner could be found sitting next to a gaggle of graduate students, and speakers were interrupted by good-natured questions A star of fermion physics, Deborah Jin, a physicist with NIST in Boulder, discussed her latest work at the Banff meeting According to the 1957 Bardeen–Cooper–Schrieffer (BCS) theory, when two electrons merge to form a ‘Cooper pair’, this new boson can then effortlessly speed through the superconductor without resistance Although this work isnt conclusive, it offers hope that studying the links between BEC and BCS behaviour will deliver new insight. “BCS theory is just very robust within condensed matter,” says Levin. “It is the theory of all theories — if it turns out to be part of an even bigger theory, which I believe it is, then thats very exciting for us.”  Hulet, a veteran of cold-atom research, is also interested in how BECs can influence other fields An atom interferometer requires two coherent atom waves (essentially two atom lasers), which can then be made to overlap and produce an interference pattern An early question was whether BECs, like helium, are superfluids As Randy Hulet, a physicist at Rice University in Houston, Texas, says: “We can use BECs to model condensed-matter systems so cleanly, in ways you just cant do in real condensed-matter systems.”  Jin now hopes to ‘see’ a Cooper pair in a BEC — something researchers can only do indirectly in a superconductor As she describes it, one of the main differences between fermionic and bosonic matter is that two bosons can exist in the same place, like two crossing beams of light, whereas fermions cannot At a fundamental level, all matter comes in two varieties: fermions, such as protons, and bosons, such as photons At Harvard University, physicist Lene Hau recently formed both vortices and ‘straight density waves’, which are akin to a sound wave, in the same BEC Back then, creating the much colder temperatures necessary to make a gaseous condensate seemed impossible Birthday parties dont get much cooler than this — a mountain-top get-together for researchers fascinated by ultracold matter But fermions can also behave strangely at low temperatures But he admits, “So far the solitons we can produce are too small.”  The greater reliability of atomic systems compared with optical ones has even got the military interested But her transition is not unique But over the past five years, BEC physics has grown, not just in size but in ambition But supercooled helium is a liquid rather than a gas, and so is not considered a ‘true’ Bose–Einstein condensate (BEC) By contrast, the field of ultracold atoms has swelled to some 100 labs and counting Cornell and Wieman first created such everlasting vortices in 1999, and today most people accept that BECs are superfluids Creating condensates out of fermions instead of bosons was a highlight of the past two years Creation was an end in itself DARPA is also tracking the potential of BECs in quantum computing — although Lowells hopes for that are more in the 10–50 year range DARPAs plans involve atom interferometer technology, pioneered by Ketterles lab among others Early last year, Jins lab reported a breakthrough — they had created bosons out of fermions and then turned them into a condensate  Early research focused on making BECs — always a painstaking exercise — from yet more, and different, atoms Eric Cornell of the National Institute of Standards and Technology (NIST) and Carl Wieman of the University of Colorado in Boulder cooled 2,000 rubidium atoms into one entity; and Wolfgang Ketterle, a physicist at the Massachusetts Institute of Technology, made a condensate from half-a-million sodium atoms For the moment, however, the idea remains firmly in the realms of theory From the start there were hopes that studying fermion condensates would give insight into BCS theory He was one of the first to create a BEC soliton, essentially a wave that never dissipates Ignacio Cirac of the Max Planck Institute of Quantum Optics in Garching, Germany, gave a fascinating talk in Banff on how one might get BECs to behave as qubits — the basic building block of a quantum computer In 1924, Albert Einstein and Satyendra Nath Bose used quantum mechanics to describe what would happen to a cloud of gas atoms if they were made so cold they essentially stopped moving In the past two years, with research into high-temperature superconductors stalled, more and more condensed-matter physicists have begun studying cold atoms In theory, once a superfluid starts swirling it should continue forever Indeed, Kathy Levin, a theorist from the University of Chicago, began her talk by saying: “There is a wonderful esprit de corps and camaraderie here — which one doesnt see in all fields, and which I think is a secret of its success.”  Levin recently escaped from the notoriously combative field of high-temperature superconductivity, another branch of condensed-matter physics It is perhaps this, more than anything, that has attracted so many condensed-matter physicists to the BEC field Last month, to mark the tenth anniversary of the creation of the first Bose–Einstein condensate, physicists met in Banff, Canada, to discuss ultracold atoms in the morning and ski in the afternoon Locked together, moving as one, this condensate of atoms would become a new phase of matter — different from solid, liquid or gas Major Jay Lowell at the US Defense Advanced Research Projects Agency (DARPA), which funds cold-atom research, says he would like to see inertial navigation systems based on BECs within five to ten years One is Fei Zhou of the University of British Columbia, who chaired a session in Banff and says he has never looked back since making the switch 18 months ago Predicting which directions will bear more fruit — fermions, solitons or something unknown — is not easy, but a field that even insiders consider esoteric continues to generate excitement She watched them collide and blossom into something like a spinning umbrella in the process of turning inside-out So far, the enigmatic dance partners remain hidden, but she can see correlations in the fermions positions that hint at Cooper pairs Some of the fastest-moving research in cold atoms involves fermions Squeeze them and they would merge into a single entity, a giant superatom Such exquisite experiments demonstrate the control researchers now have over BECs Ten years on, theres no slowing down. “I thank my lucky stars,” says Hulet, “that I stumbled on to this intellectual gold mine.” The air outside was cold and crisp, but inside the atmosphere was invitingly warm The concept behind Bose–Einstein condensation is much older than this youthful exuberance would suggest The moment a new theory comes out, there is someone in the wings ready to test it. “The experimentalists are wonderful,” says Gordon Baym of the University of Illinois in Urbana–Champaign. “Not only do they do great experiments, but they do them once a week.” It is this speed that helps make the field such a welcoming place The scene verged on the cosy Then, in 1995, two groups did it almost simultaneously There is a sense that there is room for everyone There is excitement, funding and, most importantly, the chance to do some fascinating new science These feats were recognized with a physics Nobel prize in 2001, but no one had foreseen just how much they would inspire a new generation of physicists. “The past ten years have just been an explosion,” says Ketterle, who was unable to make it to Banff. “There have been so many surprises These intense waves might one day be used to make inertial sensors for detecting changes in gravity or acceleration They have learned how to fine-tune the attraction between atoms in a BEC to do anything from spacing them in ordered lattices to forcing an entire BEC into something like a mini supernova. “Im just amazed,” says Ketterle, “that an experiment I thought was bloody difficult when I did it ten years ago is now being done regularly, with sophistication and much more experimental control.”  And although theorists have had ten years to catch up, experiments are still driving the field This difference should rule out a fermion condensate This idea remained no more than a thought experiment until 1938, when helium-4 was cooled to below 2.2 K and became a new kind of fluid that flows without friction — a ‘superfluid’ This theory explains superconductivity only at very cold temperatures — high-temperature systems discovered in the 1980s spawned numerous theories and rancorous debate, but no firm explanations Today, although some researchers continue to characterize BECs, others attempt to apply BEC physics to other fields, and yet others are exploring the relatively new area of condensates made from a class of fundamental particle known as fermions Todays inertial sensing relies on optical instruments and Hulet believes that cold atoms could increase their accuracy Until then, Zhou says that every year hed find fewer colleagues at the condensed-matter symposia he attended What has been done by far exceeds our expectations — in even my boldest dreams I could not think of so many interesting studies.”  Ketterles surprise is understandable When certain solids are cooled sufficiently, their conducting electrons — which are fermions — can pair up to create a boson, a phenomenon at the heart of our understanding of superconductivity When we discovered the BEC we had a short list of what we thought would be important Young physicists who were at graduate school when the first BECs were made are now claiming the field as their own, and many older scientists are switching to what they hope are greener pastures
 A three-dimensional surface image of the parietal peritoneal wall, obtained with the SEE probe in vivo , is shown in Fig. 1b : several raised tumour nodules are evident and the inset shows a histological section Colour could be introduced by using three separate broad-bandwidth sources, each centred at visible red, green or blue wavelengths Endoscopes help medical procedures to be less invasive, thereby reducing the risk of complications as well as costs and recovery times, but their application is limited in part by their size and inflexibility and by their inability to provide a three-dimensional perspective Even though the probe diameter is small, the number of pixels in a SEE image is larger than that from fibre bundles, being dependent only on the spectral width of the light source and the ability of the probe to separate out the components of different wavelengths Fibre-bundle endoscopes with submillimetre diameters have been used for a variety of clinical applications  Here we describe a new type of endoscopy that enables video-rate, three-dimensional images to be transmitted from flexible probes that are comparable in diameter to a human hair However, they have not been widely adopted owing to their rigidity and inadequate image quality, which is due in part to relatively low numbers of pixels and superimposition of a honeycomb pattern (a pixelation artefact) In combination with a broad-bandwidth (700–900 nm) titanium–sapphire laser, Michelson interferometer and high-speed spectrometer (see supplementary information ), this miniature probe can be used to obtain volumetric images with about 400,000 resolvable points at video rates (30 frames per second) Light from a single-mode fibre, expanded through a 1.8-mm-long silica spacer, is focused by a gradient-index (GRIN) lens and then diffracted by a transmission grating (1,000 lines per mm) fabricated on the tip of the probe at Littrows angle Light reflected from the patient can then be decoded outside the body by using a spectrometer, to form one line of the endoscopic image Miniature endoscopes still use bundles of optical fibres to transmit a two-dimensional image, but larger endoscopes now employ solid-state, charge-coupled-device cameras for superior image quality Navigation mechanisms are still needed that add minimal bulk without compromising flexibility Photographs of a prototype miniature SEE probe are shown in the insets of Fig. 1a  SEE using fluorescent light should also be useful for imaging labelled molecular species, reporters and molecular beacons. Spectral encoding can also provide depth information by using optical interferometry  Spectrally encoded endoscopy (SEE) is a miniature-endoscopy technique that overcomes many of the limitations of fibre-optic imaging bundles  The diameter of the SEE probe can be as small as that of the optical fibre, which is typically in the range 80–250 μm The first endoscope was invented almost 50 years ago and consisted of a bundle of optical fibres  The maximum diameter of the probe is 350 μm The second dimension is obtained by moving the fibre using a mechanical-transduction mechanism, such as an external motor or a galvanometer The SEE probe was delivered through a modified 23-gauge needle into the abdominal cavity The size and flexibility of this device will allow safer navigation through delicate intraluminal structures such as the fallopian tube, the salivary, mammary and pancreatic ducts, and safer fetal, pediatric and neurosurgical interventions This technology opens up the possibility of moving operations to an outpatient setting, reducing requirements for anaesthesia, and minimizing tissue damage To demonstrate the potential of SEE for minimally invasive applications, we imaged metastatic ovarian tumour nodules on the peritoneum of a living mouse (for methods, see supplementary information ) With SEE, polychromatic light emanating from a single optical fibre is configured such that each colour (wavelength) is projected to a different location on the tissue surface ( Fig. 1a )
 Here we report the crystal structure of this ferric αHb–AHSP complex at 2.4 Å resolution Moreover, conversion to the ferric bis-histidine configuration strongly and specifically inhibits redox chemistry catalysis and haem loss from αHb Our findings reveal a striking bis-histidyl configuration in which both the proximal and the distal histidines coordinate the haem iron atom The observed structural changes, which impair the chemical reactivity of haem iron, explain how AHSP stabilizes αHb and prevents its damaging effects in cells. The structure of AHSP bound to ferrous αHb is thought to represent a transitional complex through which αHb is converted to a non-reactive, hexacoordinate ferric form  The synthesis of haemoglobin A (HbA) is exquisitely coordinated during erythrocyte development to prevent damaging effects from individual α- and β-subunits  The α-haemoglobin-stabilizing protein (AHSP) binds α-haemoglobin (αHb), inhibits the ability of αHb to generate reactive oxygen species and prevents its precipitation on exposure to oxidant stress  To attain this unusual conformation, segments of αHb undergo drastic structural rearrangements, including the repositioning of several α-helices A 15-µl sample taken from the mixture was applied to a 6% native polyacrylamide gel under 150 V constant voltage at 4 °C A 610 was recorded every 30 s after the addition of H 2 O 2  Absorbance at 412 nm ( A 412 ) was recorded and is shown against time Absorbance spectra were recorded every 5 min AHSP contained residues 1–91 and the point mutation P30A Circular dichroism spectra on αHb–AHSP complexes were performed with a π star 180 spectrophotometer ( Applied Photophysics ) Crystals were grown at 4 °C by using the hanging-drop vapour-diffusion method Data collection and structure determination Crystals were equilibrated in buffer containing 0.1 M MES pH 6.5, 15% (w/v) PEG2000-monomethyl ether and 21% (v/v) glycerol, and were flash frozen under a cold nitrogen stream Data were processed with Denzo and Scalepack  For further evaluating the kinetics of oxidant generation, the rates of change of A 610 were calculated. Incubations were performed at 37 °C and initiated by the addition of 350 µM H 2 O 2  Methods Protein purification and crystallization Molecular cloning and protein purification were as described  Native polyacrylamide gel electrophoresis Oxidized αHb–AHSP complex (200 µM) was incubated with equal molar ratio of βHb on ice for 10 min in 25 µl of assay buffer containing 20 mM sodium phosphate pH 7.4 and 100 mM NaCl Positions of the iron atom were identified by using SOLVE  Production of secondary oxidants by αHb Fe  iii -αHb–AHSP and Fe  ii -αHb–AHSP complexes and free αHb were incubated at room temperature, at a haem concentration of 10 µM, with H 2 O 2 (400 µM) in the presence of N,N,N′,N′-tetramethylbenzene-1,4-diamine (TMPD) in 20 mM sodium phosphate buffer pH 7.4 containing 100 mM NaCl and 10 µM diethylenetriamine pentaacetic acid (DTPA) Quantification of oxyferryl Hb and sulphHb was performed by linear regression to absorption coefficient spectra for the involved species SulphHb was generated by the addition of 2 mM Na 2 S to Fe  iii -HbA and excess H 2 O 2 (ref. 19 ) The atomic models of AHSP and αHb were refined with the use of CNS  The crystals belong to the space group C 2 and contain two complexes per asymmetric unit The electrophoresis buffer contained 25 mM Tris-HCl and 250 mM glycine The final refined model, at 2.4 Å resolution, contains residues 1–91 of AHSP and residues 2–136 of αHb in both complexes The native and iron multi-wavelength anomalous dispersion data sets were collected at the NSLS X25 and X12C beamlines, respectively, at the Brookhaven National Laboratories The purified oxy-αHb–AHSP complex was oxidized by four molar equivalents of K 3 Fe(CN) 6 at 0 °C for 5 min The unit cell has the following dimensions: a = 65.6 Å, b = 113.5 Å, c = 79.5 Å and β = 94.7° The well buffer contained 0.1 M MES pH 6.5 and 15% (w/v) PEG2000-monomethyl ether Treatment of αHb with H 2 O 2 Free αHb, Fe  ii -αHb–AHSP and Fe  iii -αHb–AHSP complexes were prepared at a haem concentration of 35 µM AHSP binds αHb on the side of the molecule opposite the haem pocket ( Fig. 1a ) AHSP-null red blood cells contain excessive ROS with signs of oxidative damage, haemoglobin precipitates and decreased circulating lifespan  Although the Fe  ii complex had a moderate effect on the preservation of haem, it significantly decreased the production of accessory oxidants in comparison with free αHb Although the αHb–AHSP interface resembles that of the α1–β1 complex between αHb and βHb (ref. 5 ) (both involving the hydrophobic surfaces of the G and H helices of αHb), the orientations of the partner helices are quite different Because these two complexes have identical structural features, we limit our discussion to one such complex Bis-histidine coordination has previously been identified in the haemoglobin of rice plants , Arabidopsis and Drosophila and also within the mammalian haemoglobins cytoglobin and neuroglobin  Both Fe  ii and Fe  iii haem react with hydrogen peroxide (H 2 O 2 ) to produce oxyferryl intermediates Compared with Fe  ii -αHb bound to AHSP ( Fig. 2a ) or in HbA ( Fig. 2b ), the structure of the Fe  iii -αHb bound to AHSP shows significant conformational changes involving translocation of main chain atoms by as much as 10 Å ( Fig. 2 ) Consequently, the ability of the haem iron to act as a catalyst of redox reactions is predicted to decrease Deconvolution of these spectra to known standards indicates that within 1 min, 33% of the haem in the Fe  ii complex was converted to the ferryl form ( Supplementary Fig. 2 ) During the AHSP-induced transition from the Fe  ii to the Fe  iii state, structural rearrangements in αHb occur in 80% of its sequence and are concentrated primarily in three segments that are located close to the haem-binding pocket ( Fig. 2 ) First, through direct binding, AHSP thermodynamically stabilizes αHb and minimizes the chances that αHb will denature and thereby form cytotoxic precipitates in cells Free αHb is toxic because its haem iron can participate in redox chemistry that generates reactive oxygen species (ROS)  Free αHb produced oxidants at the highest rate, whereas the Fe  ii complex decreased this rate From a starting concentration of 18.2 µM Fe  ii -αHb–AHSP, 8.3 ± 0.05 (s.e.m) µM sulphHb was formed, whereas only 1.9 ± 0.07 µM sulphHb was formed from the Fe  iii complex Further reaction of radical oxyferryl haemoglobin with H 2 O 2 regenerates Fe  iii haem and oxygen H 2 O 2 induced a rapid decline of Soret absorbance (412 nm) from free αHb ( Fig. 3b , left panel) Haemoglobins undergo a complex set of reactions with the partly reduced oxygen species that occur in vivo , which could be influenced by AHSP-induced structural changes  Having established that the Fe  iii complex decreased oxidant-induced haem damage, we compared the abilities of the complexes to catalyse other redox reactions Hence, AHSP-bound Fe  ii -αHb interacts with H 2 O 2 to produce an oxyferryl intermediate, which after further reaction produces haem loss/destruction Here, formation of the bis-histidyl configuration induced by AHSP binding is an essential step in preventing the cytotoxicity of unpaired αHb ( Fig. 4 ) However, the functions of these bis-histidyl haemoglobins are not fully characterized In addition, in the presence of βHb, the AHSP-bound, oxidized αHb can be recruited to form tetrameric Hb ( Fig. 3e ) In HbA the distance between the Nɛ atom of the imidazole ring of His 58 and haem iron is about 4.3 Å In later stages of incubation, haem loss was decreased from the Fe  ii complex In particular, the distal histidine, His 58, is located in this segment In support of this notion, the binding by AHSP increases the melting temperature of αHb by 8° ( Fig. 3d ) In the crystals AHSP adopts an elongated three-helix bundle, whereas αHb is composed of seven α-helices, known as helices A–C and E–H  In the Fe  ii -αHb–AHSP complex, the F helix is disordered and the haem surface is open to interaction with solvent  In the Fe  ii -αHb–AHSP complex, this distance is shortened to 2.13 Å because of the coordination of His 58 with the Fe  ii atom In the Fe  iii -αHb–AHSP complex, the F helix is well-defined In the αHb–AHSP complex, helices α1 and α2 of AHSP cross the G and H helices of αHb at an angle that is about 50° different from that made by the corresponding B and G helices from βHb ( Fig. 1b ) Less than 10% of the Fe  iii haem was converted after 30 min Moreover, αHb is structurally unstable and tends to denature, releasing toxic α-globin polypeptide, and also free haem and iron, which themselves catalyse ROS production On oxidation of the iron atom, the F helix is reformed to generate the bis-histidyl configuration Our findings show that AHSP-induced conversion of αHb to the Fe  iii bis-histidyl complex confers protection from both oxidant-induced haem loss and the generation of free oxidant Our present and previous studies indicate a model in which AHSP protects αHb Perhaps more significantly, the G and H helices of αHb are also the primary structural elements that interact with βHb to form the α1–β1 complex  Reaction of the non-radical oxyferryl form generates Fe  iii haem and superoxide  Recently, we showed that the binding of AHSP to oxygenated ferrous (Fe  ii ) αHb induces a unique rearrangement in which the Fe  ii -haem group becomes coordinated by the distal (His 58) but not the proximal (His 87) histidine, which normally binds haem iron in HbA (ref. 5 ) Second, by facilitating the oxidation of the haem group and by sequestering the oxidized haem in a redox-inert, bis-histidyl state, AHSP ensures that αHb does not cause oxidative damage to cells Structure alteration also occurs at the C-terminal end of αHb, where the C-terminal half of helix H is transformed into a rigid loop ( Fig. 2c , right panel) The bis-histidyl structure of Fe  iii -αHb–AHSP could provide protection from peroxide-induced damage by preventing the formation of oxyferryl intermediates The distances between the haem iron and the Nɛ atom of the imidazole ring are 2.10 and 2.13 Å, respectively, for the distal and the proximal histidine residues The Fe  iii -haem group is planar ( Fig. 1c ) The Fe  iii -αHb–AHSP complex is exclusively in an α-helical conformation ( Fig. 1 ) The Fe  iii -αHb–AHSP complex was completely oxidized by potassium ferricyanide The Fe  iii complex ( Fig. 3c , upper panel) further inhibited the production of ROS The first segment includes the C-terminal half of helix B, the entire C helix, the amino-terminal half of helix E, and the intervening loops ( Fig. 2c , left panel) The formation of ferryl haemoglobin is inhibited after the formation of the bis-histidyl Fe  iii -αHb–AHSP complex The haem iron atom is coordinated by both the distal histidine (His 58) and the proximal histidine (His 87) in the Fe  iii -αHb–AHSP complex ( Fig. 1c ) The initial rate of haem loss was decreased in the Fe  iii complex but not the Fe  ii ( Fig. 3b , left panel) The interaction of redox-active haem iron with H 2 O 2 generates hydroxyl radicals The interface between the Fe  iii -αHb and AHSP is nearly identical to that of the Fe  ii -αHb–AHSP complex, including the preservation of three specific hydrogen bonds and all van der Waals contacts in the centre of the interface  The iron atom is much less exposed to solvent, even in comparison with αHb from HbA ( Fig. 3a ) The only structural elements that do not undergo significant conformational changes upon the oxidation of αHb are the entire G helix and the N-terminal half of the H helix ( Fig. 2a ), which are primarily responsible for interacting with AHSP ( Fig. 1 ) The predominant difference in the rate of oxidant generation occurred in the early phase of the reaction ( Fig. 3c , lower panel) The production of superoxide within the haem pocket can result in haem degradation and the release of haem iron and porphyrins  The reaction with Fe  iii haem also generates a free radical within the globin chain  The root-mean-square-deviation (r.m.s.d.) is 3.2 Å for 135 main-chain Cα atoms (residues 2–136) between αHb in HbA and in the AHSP-bound, oxidized state The second segment encompasses helix F, which harbours the proximal histidine, His 87, and its N-terminal loop ( Fig. 2c , middle panel) There are two αHb–AHSP complexes in each asymmetric unit These changes are accompanied by a significant rearrangement of the side chains that interact with the haem group ( Supplementary Fig. 1 ) These conclusions illustrate a new facet of haemoglobin homeostasis. These conformational changes are more appropriately classified as structural rearrangements because the hydrophobic core is also altered ( Fig. 2c ) These effects contribute to the pathophysiology of β-thalassemia, a common inherited anaemia in which mutations that inhibit β-globin synthesis cause the accumulation of free αHb  This arrangement presumably permits multiple forms of AHSP-bound αHb to bind βHb and generate tetrameric HbA This configuration is in sharp contrast to previously reported structures of erythrocytic haemoglobins, in which haem is bound only by the proximal histidine, and to the Fe  ii -αHb–AHSP complex, in which haem is coordinated only by the distal histidine and the entire F helix is disordered  This decline reflects haem loss, most probably by breakdown as outlined above  This feature explains why AHSP can bind specifically to multiple forms of αHb despite significant conformational differences between them This is remarkable, given that the structure of AHSP-bound αHb has undergone drastic conformational changes after oxidation This possibility is supported by an analysis of the changes in αHb–AHSP spectra ( Fig. 3b , right top and bottom panels) This structural difference probably explains why AHSP binding has functional consequences that are completely different from those of βHb binding This value is in contrast to the r.m.s.d. of about 0.5 Å for the same Cα atoms between the T-state and the R-state of αHb This was most probably caused by the formation of the more stable Fe  iii haem state, as indicated by the ultraviolet–visible spectra ( Fig. 3b , top right panel) Thus, the crystal structure of the Fe  iii -αHb bound to AHSP reveals an inert, bis-histidyl configuration that cripples the ability of αHb to generate ROS and prevents haem loss induced by oxidative stress ( Fig. 4 ) To confirm these observations, we examined the effect of sulphite addition, which reacts with ferryl haem to form Fe  ii -sulphHb , which can be distinguished spectrophotometrically  To examine this hypothesis we compared the abilities of Fe  ii -αHb–AHSP, Fe  iii -αHb–AHSP and free αHb to participate in redox catalysis To facilitate crystallization, we introduced a point mutation (P30A) into AHSP and removed the carboxy-terminal 11 residues of AHSP, which are known to be dispensable for αHb binding  We assessed how AHSP affects these processes by comparing H 2 O 2 -induced spectrophotometric changes in Fe  ii -αHb–AHSP, Fe  iii -αHb–AHSP and free αHb We assessed the production of oxidants from the reaction of H 2 O 2 ( Fig. 3c ) We crystallized the Fe  iii -αHb–AHSP complex and determined its structure at 2.4 Å resolution ( Fig. 1 , Table 1 and Supplementary Table 1 ) We proposed that this complex represents a transitional structure because the Fe  ii -haem group was rapidly converted to an oxidized (ferric; Fe  iii ) state in which all six coordinate positions were ligand-bound 
 But the authors point out that in the past the story must have had a more serious edge Edmonds and Gerlach estimate that a lava flow of 1 m 3 s −1 could in principle produce 3.7 kg s −1 of HCl, or 300 tonnes daily Edmonds and T Eruptions of Hawaiian volcanoes in 1840, 1919 and 1950 produced massive lava flows, with sustained lava fluxes entering the sea Figures of this latter order of magnitude produce only localized high concentrations of HCl gas and acid rain First, from thermodynamic considerations they calculate that the HCl gas is created following the hydrolysis of magnesium chloride salts (and not of sodium chloride, as an alternative explanation has it) For various reasons that they discuss, this number is likely to be much lower (3–30 tonnes) Gerlach have investigated the composition of such plumes produced by lava from Kilauea Volcano, Hawaii ( Earth Planet Lett. doi: 10.1016/j.epsl.2006.02.005) M M Sci Second, given that conclusion, they estimate how much HCl is produced by the lava–seawater interaction The most notable of Edmonds and Gerlachs conclusions stem from their analyses of this last species, HCl The outcome depends on various assumptions and factors, including the type, extent and duration of the lava flow The plumes seen in this picture consist not only of steam produced by the evaporation of water, but also of aerosols and gases that stem from the reaction between the lava and salt water The result was an estimated HCl output of 200–2,200 tonnes per day over several weeks, a much more serious environmental hazard. Their main tool was open-path Fourier transform infrared spectroscopy, which allowed remote sensing of the plumes and estimation of the amounts of various components — water, carbon dioxide, nitrogen dioxide, sulphur dioxide and hydrogen chloride There is more than just a sizzle when red-hot lava meets the sea
 According to the grapevine, Hoffren says, the regulator could deem the A380 safe to fly more closely behind other aircraft — on account of its bulk Airbus wont comment on the requirements, but Jaakko Hoffren, an aeronautical engineer at the Helsinki University of Technology in Finland says: “My impression is that Airbus had always assumed that the in-flight separation requirements for the A380 would be the same as for the Boeing 747.”  Increased spacing requirements would defeat the whole rationale for the A380, he asserts All aircraft create tornado-like counter-rotating vortices that trail from the tips of the wings as they fly And the ICAO suggested more stringent horizontal and vertical spacing requirements for the A380 at cruising altitudes At cruising altitudes “no difference has been found between the two aircraft types”, he says. “At low altitude, there is a slightly bigger vortex on the A380, compared with the 747.” Voskuhl adds that it is up to the ICAO to decide safe distances for the new aircraft Boeing and the ICAO declined to comment Bumpy ride The problem is turbulent airflow But draft guidelines issued late last year for the European challenger suggest that it could be hampered by safety restrictions But that success is very much in doubt: back in July, Airbus chief executive Gustav Humbert quit over delays to the A380 and other management issues at the company Current ICAO guidelines divide commercial aircraft into three weight categories: small, medium and heavy He agrees that the ICAOs preliminary A380 guidelines were too stringent — but sees little prospect that the final ones will be the same as those for the 747 Hoffren predicts that a surprise compromise could be in store when the ICAO announces its final guidelines Hoffren says that his calculations suggest “the in-flight separation limits, in time or distance, behind an A380 should be some 10–30% larger than behind a Boeing 747, for similar hazard levels” However, US industrialists and politicians have bitterly complained that its financing arrangements amount to an unfair subsidy by European governments If final regulations due this November resemble the preliminary ones, they will add to the projects woes If the preliminary requirements get implemented, each A380 flight would mean fewer slots In the airliner market, meanwhile, Boeing has begun to reassert itself, once again surpassing Airbus in total sales Increased aircraft weight strengthens wake vortices, whereas longer wingspans and increased speed reduce their intensity It also flew airliners into the wakes of others at cruising altitude, to compare the levels of turbulence It also said that planes landing after an A380 should stay back 18 kilometres — about twice the distance they have to hang back from 747s Last year, the ICAO shocked Airbus by suggesting that jets set to take off after A380s should wait for 60 seconds longer than they do behind Boeing 747s Most major hub airports already have too few take-off and landing slots Over the past decade, the European firm has drawn level with Boeing in terms of overall airliner sales, establishing itself as a rare example of European success in a huge, high-technology industry Since the preliminary guidelines were issued, Airbus has commissioned the German Aerospace Agency, the DLR, to conduct research that it hopes will prove the A380 is safe at spacing distances closer to, or the same as, those for the Boeing 747 That would allow it to leave more space in its wake, while occupying the same time slot as its rival. The A380 has a maximum take-off weight of 560 tonnes and wingspan of 80 metres, compared with the 747s 397 tonnes and 64 metres The European firm Airbus hopes that its A380 can break the Boeing 747s stranglehold on the market for very large airliners The research used light detection and ranging (LIDAR) — a technique similar to radar, but using light instead of radio waves — to study the vortices created by airliners The success of the worlds biggest passenger airliner could hinge on an obscure regulatory decision to be made by the International Civil Aviation Organization (ICAO) later this year The US manufacturer has rejected costly plans to build a super-jumbo akin to the A380, leaving the European manufacturer — and much of Europes entire aviation industry — relying on the success of the project These can pose a safety risk to other aircraft — especially during take-off and landing These studies were “a worldwide first”, says David Voskuhl, a spokesman for Airbus They will mean that other planes would have to stay farther away from the A380 than from 747s This could see the A380 lose valuable take-off and landing slots at busy airports, compromising its bid to establish itself in the market Thomas Gerz, a meteorologist and head of the aerospace agencys wake-vortex project, says that the preliminary guidelines would create a fourth super-heavyweight class, with the A380 as its only member. “There is no reason for this,” he says. “The A380 does not justify another weight class.” He acknowledges that A380s produce stronger vortices than 747s, but contends that current ICAO spacing guidelines are “very conservative”
 Hamiltons concept of kin selection , whereby individuals can benefit indirectly by helping a relative, was a crucial breakthrough for understanding apparently altruistic systems Here I show, using genetic measures of relatedness and reproductive success, that kin selection can explain the evolution of cooperative courtship in wild turkeys However in the only direct test of kin selection in coordinated display partnerships, partners were unrelated , discounting kin selection as an explanation for the evolution of cooperation In the few species of birds in which males form display partnerships to attract females, one male secures most or all of the copulations  Subordinate (helper) males do not themselves reproduce, but their indirect fitness as calculated by Hamiltons rule more than offsets the cost of helping This leads to the question of why subordinate males help in the absence of observable reproductive benefits This result confirms a textbook example of kin selection that until now has been controversial and also extends recent findings of male relatedness on avian leks by quantifying the kin-selected benefits gained by non-reproducing males. About 100 µl of blood was taken from the wing vein and stored in blood storage buffer About 50% of the population was marked in any given year Additional details such as reaction conditions and allelic diversity are provided in Supplementary Table 2  Adults were tagged with uniquely numbered patagial wing tags, and a subset ( n = 8 males, n = 68 females) were outfitted with backpack-style radiotransmitters All adults were genotyped at least twice, and genotypes were more than 0.999 complete All individuals were then genotyped at ten microsatellite loci identified from previous studies of wild or domestic turkeys  All procedures were approved by the University of California, Berkeley, and the California Department of Fish and Game Although many of the unassigned offspring were probably fathered by unsampled males, others were fathered by known males but could not be assigned to them Analysis of genetic data Relatedness was calculated with RELATEDNESS 5.0 (ref. 26 ) Behavioural definitions Coalitions were defined as adult males in their third year (2 years old) or older that were seen displaying to females at least twice while within 2 m of each other CERVUS generates a test statistic ( Δ ) based on the difference in LOD scores (cumulative log-likelihood ratio of parentage compared with non-parentage) between the two most likely sampled males Data on individual coalitions and solitary males are provided in Supplementary Table 1  Details of the CERVUS analysis are given in Supplementary Table 3  DNA extraction and genotyping DNA was extracted from samples using DNEasy tissue extraction kits ( Qiagen ) then diluted to a concentration of 20 µg ml -1  Genetic samples from offspring ( n = 325) were collected by a combination of capturing flightless young soon after they had hatched, salvaging from failed or abandoned nests, and collecting early nests to incubate and sample eggs Given the wild turkeys unique kin structure, coalition males were handicapped by necessarily having close relatives among the set of candidate males. I captured 126 immature and adult turkeys (51 males, 75 females) by using walk-in traps or drop nets In addition, we regularly drove along about 20 km of roads in and around the reserve, and during the breeding season we hiked at least a 2-km loop at a nearby ranch to search for turkeys without radios Maternity of an offspring was assigned to the female incubating that nest if she had no more than one locus mismatching the offspring Methods Field methods From 1999 to 2004 I studied an introduced population of M. gallopavo at the Hastings Natural History Reservation in Carmel Valley, Monterey County, California Offspring genotypes were 0.98 complete; individuals were rerun if allelic calls were questionable or if they did not match the genotype of the incubating female One primer of each primer pair was fluorescently labelled and loci were multiplexed on an ABI 3730 automated sequencer  Paternity was calculated by a combination of maximum likelihood assignment with CERVUS 2.0 (ref. 27 ) and genotypic exclusion, meaning that a male could be assigned paternity only if he met the strict 95% assignment level and was the only perfect genotypic match among sampled males Polymerase chain reaction products were run on 96-well plates that contained one negative control and two positive controls (the same two individuals were included with every run) Relatedness values were then calculated for all pairs of males, and coalition values were compared with 1,000 sets of eight randomly selected values Reproductive success was determined by assigning parentage to sampled offspring Sets of full siblings, half siblings and mother–offspring pairs were identified during subsequent paternity analyses (see below); r values were calculated for these known genealogical relationships to confirm that the relatedness estimates generated from microsatellite genotypes corresponded to those predicted by pedigree Solitary males were males that never met this criterion and either were observed at least twice displaying alone or showed patterns of association that precluded them from having a specific partnership with another male Some level of mismatching is to be expected because of both marker mutation and nest parasitism by other females The background allele frequencies were defined as the allele frequencies for adults only The more genotypically similar that two candidate parents are, the more likely they are to have similar LOD scores and therefore to generate a smaller Δ  score The program then compares this value with a user-defined critical value based on the percentage of simulations (here, 95%) that correctly assigned an offspring to the actual parent These samples were stored in one or more of the following: blood storage buffer, dimethyl sulphoxide or 100% ethanol This set of conservative criteria lead to the assignment of 75 of 325 offspring to a known, sampled male Using GENEPOP , I determined that these loci were unlinked With one or two field assistants each year, I attempted to relocate radio-tagged birds visually at least twice a week in January, February and June, and daily from March to May, to identify female nesting attempts and to observe courtship behaviour and associations Within a coalition, the dominant male was the one that performed most of the full strut (stereotyped pulmonary puff) displays A previous observational study found that only one male in each coalition mates All changes in coalition membership observed were losses rather than gains of individuals ( n = 7 coalitions across 11 coalition-years; 6 losses, 0 gains, Sign test P 0.04) Although this work was published long before molecular techniques were available to measure relatedness and reproductive success directly and has been questioned on other grounds , the story remains a well-cited example of kin selection  An alternative hypothesis is that the benefit is due to differences in individual quality of dominant males rather than the help provided by their subordinate partner(s) Because subordinate males acquire large indirect fitness benefits, do not themselves gain direct reproduction and are unlikely to increase their future mating opportunities, kin selection seems to provide the best explanation for the evolution of cooperative behaviour in wild turkeys By contrasting these results with the patterns described for Chiroxiphia manakins and ruffs , it is evident that although these species independently evolved cooperative courtship as a solution to intensely competitive mating systems, the exact form of fitness benefit maintaining subordinate cooperation can differ greatly. Coalitions form before adulthood (three coalitions were marked as 1-year-old subadults); furthermore, no solitary displaying male was observed to later join a coalition ( n = 14 males and 24 male-years) Contrary to these predictions, both dominants and solitary males show bimodal distributions of reproductive success, with n = 3 dominant males and n = 10 solitary males not reproducing at all Dominant males mated with more females ( χ  2 (1) = 9.0, P 0.005) and fathered more offspring than solitary males ( χ  2 (1) = 58.3, P 0.001) Finally, Hamiltons rule can be evaluated by assuming the cost of helping, C , for subordinate male turkeys is equal to the average fitness of non-cooperative solitary males (0.9 offspring per male) Finally, turkeys do not defend territories either during the breeding season, when several male groups may court a given flock of females, or outside the breeding season, when males are highly social  First, coalitions are clearly composed of relatives, as shown by the similarity of microsatellite genotypes between dominant and subordinate males ( Fig. 1 ) Given that half-brothers have an expected r value of 0.25, processes that produce half-siblings such as multiple paternity, quasiparasitism or crèching of broods fathered by the same male should not reduce relatedness among brood-mates to the point in which cooperative behaviour is no longer favoured Here I show that kin-selected indirect fitness benefits do in fact explain cooperative courtship in wild turkeys pecies that form male display partnerships? In contrast to reproductive ‘sharing’ by satellite males in ruff ( Philomachus pugnax ) partnerships , I found no evidence of direct reproduction by subordinate male turkeys ( Fig. 2 ) However, most examples of helping or cooperative breeding involve offspring retained in intergenerational family groups in which it is difficult to separate the indirect fitness benefits due to kin selection from benefits due to direct fitness , even when the dynamics of helping behaviour qualitatively fits the predictions of Hamiltons rule  If this were true, one would predict a difference in the distributions of reproductive success between dominant and solitary males, and that there would be little or no difference between the success of presumed high-quality males that successfully reproduce, whether they are in a dominant member of a coalition or display as a solitary individual In cooperative partnerships of Chiroxiphia manakins, subordinate males seem to benefit through an increased likelihood of future inheritance of a display perch  It was not possible to test specific genealogical hypotheses for individual coalitions because of an insufficient number of loci  Male turkeys form coalitions of two to four same-aged males that court females and defend those females against other groups and solitary males No empirical study has yet quantified this kin-selected benefit relative to alternative benefits such as low frequencies of matings or future inheritance of dominant positions None of eight marked subordinate males fathered any offspring during my study, compared with four out of seven dominant members of coalitions (Fisher exact test, P = 0.026) On the basis of the values in Table 1 , helping behaviour should be observed as long as coalitions are related at a level of r 0.15 One coalition was initially observed to contain three males and another four males, although these both were reduced to pairs during their first season, presumably by hunting or natural predation events Second, the help provided by subordinate males increases the reproductive success of dominant males compared with non-cooperating solitary males ( Fig. 2 ) Similar results are obtained if presumably low-quality (non-reproducing) males are excluded from calculations ( Table 1 ) Six coalitions (five pairs and one four-member group for a total of eight dominant–subordinate male dyads) combined for a mean (± s.e.m.) coalition relatedness, r , of 0.42 ± 0.07, significantly higher than r of males drawn randomly from the population (randomization test, 1,000 iterations, P 0.001) Species with aggregated male displays are therefore valuable for studying kin selection because it is possible to isolate the role of indirect fitness in the absence of direct benefits stemming from delayed dispersal Support for kin selection requires the following three conditions to be met: first, that dominant and subordinate males are related; second, that there is a measurable benefit to the dominant male due to the help of the subordinate; and last, that Hamiltons rule ( rB - C 0) must be met, the indirect benefit to the subordinate ( rB ) outweighing the cost of helping instead of attempting to breed independently ( C ) (refs 3 , 4 ; Table 1 ) Surprisingly, the role of kin selection on leks has only recently been proposed , and kin associations of displaying males have now been demonstrated for several species including grouse , peafowl and manakins  The authors of that study believed that coalitions were composed of brothers (sibling nestmates), thereby providing the relatedness necessary to accrue indirect fitness benefits The benefit B , as calculated by the difference between the mean fitness of dominant males and the mean fitness of solitary males, was 6.1 offspring per male ( Table 1 ) The fitness benefits for third- or lower-ranked males would require further assumptions, including size-specific coalition productivity, which I could not calculate on the basis of my limited sample size The minimum level of relatedness necessary to offset a subordinates loss of independent reproductive opportunities can be calculated by setting the indirect benefit, rB , equal to the cost C and solving for r  The observation that cooperation in birds typically occurs between relatives is superficial support for the idea that kin selection is a general explanation for avian helping behaviour The relatedness within coalitions is equivalent to the mean r calculated for two groups of known genealogical relationship with expected r = 0.5 based on pedigree (full siblings, r = 0.52 ± 0.05 , n = 10; mothers and their offspring, r = 0.46 ± 0.03 , n = 12, analysis of variance F (2,27) = 0.947, P = 0.40) This benefit is calculated on the assumption that all coalitions are dyads This conclusion is robust to an almost 50% underestimate in relative fitness of solitary males This kinship facilitates indirect fitness benefits for low-ranked males because female visitation often increases at larger leks, thereby explaining why a male might settle at one lek rather than another  This pattern indicates that if the dominant male disappears from a cooperative pair, the subordinate is left as a solitary male and does not attract a new display partner This trend cannot be explained by solitary males joining distant coalitions outside the study area, because coalitions and solitary males were observed at similar rates (see Supplementary Table 1 ) This value is an underestimate to the extent that high relatedness makes it more difficult to assign paternity to males in coalitions (see Methods) Thus future resource or territory inheritance cannot account for subordinate male cooperation Thus kin selection seems to best explain the pattern of relatedness and distribution of reproductive success; the important issue of individual male quality that has been studied in captive settings remains to be integrated into the complex mating system of free-living turkeys Unlike Chiroxiphia , wild turkey coalitions do not act as social queues because coalitions change only through attrition When only the presumably high-quality males that reproduce are used to calculate the average fitness of dominant and solitary males, the dominant males father significantly more offspring (49) than do solitary males (13) (Mann–Whitney U = 0.5, P = 0.026, n = 4 for both groups), and the benefit B increases to 9.0 offspring per male rather than decreases ( Table 1 ) Wild turkeys ( Meleagris gallopavo ) are among the few species of birds to form male display partnerships within larger display aggregations With this assumption, the net benefit to helping is +1.7 offspring per male ( Table 1 ), indicating a clear selective benefit to cooperation for subordinate males
 Here we show that their analysis was not carried out in a consistent manner and that density dependence gives an equally valid mechanistic explanation for RSA patterns in addition to, and independently of, dispersal limitation. We have demonstrated that information on relative species abundance (RSA) cannot, without additional information, be used to discriminate among biological explanations for different RSA patterns ; but Chave et al . claim that our conclusion is premature  As a second example, consider the dispersal limitation model studied by Volkov et al . using the biodiversity parameter Θ =50 and the immigration parameter m =0.1 Assume now that we were given the RSA data ( Fig. 1 , top) and asked what we could learn from it Clearly, the dispersal-limitation model from which the data were derived provides a perfect description of the data, so it might be tempting to conclude that the mechanism underlying the data is in fact dispersal limitation with the selected model parameters Consider a very simple model of immigration, in which the birth and death rates for a species with n individuals is given by b n = b * n +c * and d n =d * n , respectively, or the equivalent per capita rates are b n / n = b * = c * / n and d n / n = d * , where b * and d * represent the intrinsic per capita birth and death rates, respectively, and c * is a constant that captures the effects of immigration from a surrounding metacommunity that has a uniform distribution of species Figure 1 shows the RSA data for this model obtained through the analytical expression derived in ref. 3 , as well as a graph of the density-dependent birth–death rate ratio rcirc; n plotted aginst n , deduced from this RSA data ( rcirc; n =[( n +1)/ n ] [ b n / d n+1 ]=[( n +1)/ n ][〈 φ  n +1 〉/〈 φ  n 〉] , where 〈 φ  n 〉  represents the mean number of species with abundance n ) Furthermore, rcirc; n does not constrain the individual birth and death rates, but only their ratio However, a symmetric density-dependence mechanism that gives rcirc; n versus n ( Fig. 1 , bottom) would also yield exactly the same RSA data In summary, any RSA data set is exactly equivalent to an effective symmetric density-dependence model Our assumption was that the RSA data were a measure of 〈 φ  n 〉  , the average RSA, whereas Chave et al . consider the multivariate probability distribution for φ  n and maximize it for the snapshot in question The key unknown is what led to this effective density dependence: did it arise from a dispersal-limitation model, by some other mechanism, or is there intrinsic symmetric density dependence at play? It is not possible, in principle or in practice, to distinguish between these options given just the RSA data . The results for four forests (forests with a large value of m are very slow in their convergence) shown in Table 1 do not support the claim by Chave et al .  This model can equally well be envisaged as arising not from immigration but from a density-dependent birth mechanism, so it is impossible to determine the biology underlying the resulting RSA data without additional information This provides even greater flexibility in the range of models and mechanisms that are able to fit the data exactly To compare the two models consistently, we computed 〈 φ  n 〉  by generating 100,000 realizations of each plot with the estimates by Chave et al . of the parameters Θ  and m  Turning to the narrower issue of the comparison between two simplified models, the table presented by Chave et al . is misleading because their analysis is inconsistent
 As an exact solution is not available, approximations were necessary until an equation with an analytical solution could be derived As soon as that condition changes, the search optimization strategy should also change At first glance, diffusion might seem to be a satisfactory strategy for minimizing search time Averaging over all possible trajectories presents the startling fact that the mean first-passage time to any particular target is infinite But in the case of the albatross, the act of catching food cannot be accomplished during a flight ( Fig. 1 ), so too much time is spent in the flight segments for a Lévy strategy to minimize search time But spending too much time searching, t 1/ k , when a target is not present will not be conducive to optimizing the search efficiency either But this is not so But under what conditions? The theoretical Lévy strategy has a wide distribution of flight segment lengths, and the mean of this distribution is infinite But what if there are many targets? Consider a random walker starting on a line of targets on a square lattice Bénichou and colleagues analysis holds under strict conditions, especially that the seeker has no knowledge about where the perishable targets are Bénichou et al . consider a low-density system in which the average distance, B , between two targets is much greater than the distance A from which a target can be discovered Despite this unpromising prognosis, Bénichou and colleagues rely, in part, on diffusion in their two-dimensional search model for non-revisitable static targets Essentially, this is a requirement that ballistic relocation should be very efficient relative to diffusion Even in one dimension, some particle trajectories move to the right while a hidden, static target is on the left For instance, a figure-of-eight search pattern of an aircraft scouring littoral waters would be different from the pattern for a search of deep-ocean waters For instance, a methodical search would be best if the target must be found regardless of the amount of time involved For other cases — where the target can move or trick the seeker, for example — other optimal strategies are expected Here, the walker gradually diffuses away from the line, so the targets are visited less and less over time In a second, static case, the seeker is stationary and reacts with the target at a certain rate when the target comes within a certain range In addition, they stipulate the condition D / v A , where v is the velocity of the seeker in the ballistic phase In any probability-based search problem, adding information provides values for conditional probabilities In both cases, the time spent on the search phase is a random variable In the case of a static seeker, abandoning a search too quickly (within time t 1/ k ) will probably result in missing a target that is present In the first, dynamic case, the searching is diffusive, and the target is found immediately when it is within a certain distance, A  In three dimensions, the result is worse: even more targets go unfound, with only ln N sites discovered  It might seem that any target will be found because its location will eventually fall under the spreading gaussian peak One can calculate that after a large number of jumps N , only N 1/2 /ln N of the targets are visited One such question was the optimization problem How to hunt a submarine , the analysis of which had to take several factors into account One such study interpreted data from transmitters attached to the legs of itinerant albatrosses Operations research — the field that uses mathematical methods to optimize complex real-world structures and processes — grew out of the analysis of military problems during the Second World War Optimal mean times for search and relocation are possible Presumably, the flight pattern reflected a search for food, and perhaps also the lifetime of thermals on which the seabirds ride Similarly, spending too much time diffusing in an area without targets is unproductive, as is spending too little time in a target-rich environment Since the early days of aircraft hunting submarines, many types of search have been investigated in which the target may or may not be destroyed upon contact Surprisingly, however, for an optimal search in both the static and dynamic cases, the same condition is found for the mean time spent in the ballistic motion phase The aim of such searches is to remove the target, and, writing in Physical Review E , Bénichou and colleagues bend their minds to minimizing the amount of time needed when searching for such non-revisitable targets The approximate formula that emerged agreed well with simulations The authors derive an equation for the distribution of first-passage times required for the seeker to find the target, for a general model combining the static and dynamic cases and allowing for an arbitrary rate of diffusion, D , and rate of reaction, k  The optimal mean search time is found to be different in the static case, where it depends on k and is proportional to 1/ v 1/2 , and in the dynamic case, where it depends on D and is proportional to 1/ v 2  The problem was also complicated by the fact that a negative search might mean only that a submarine was submerged, not that it was absent The radio signal was silenced when an albatross was in the water The same would be true if different cost penalties, other than minimizing the search time, are chosen: if, for instance, the ballistic phase were more costly per unit time than the diffusive phase. These results for non-replenishable targets might be useful for situations ranging from animals foraging for food to proteins binding on DNA They propose a two-state search pattern This is a function of A and B , proportional to 1/ v , and independent of D and k  This phase is followed by a further search phase, and so the cycle continues What emerged was a fractal on–off signal pattern that was consistent with the bird flying a self-similar pattern — one in which the whole has the same shape as smaller component parts — with the end of each segment punctuated by a water landing Whatever the exact reason, this research led to several papers demonstrating that fractal patterns of the albatross type, called Lévy flights, are an optimal search strategy When a particle starting at an arbitrary origin moves randomly, its location is described by a gaussian probability distribution that spreads out with a variance that grows linearly with time When the search phase ends, either successfully or unsuccessfully, the motion of the seeker changes to a relocating ballistic: it shoots off in a random direction for a random stretch of time during which, according to the model, discovery of a target is not possible
 A group of more intact endogenous retroviruses are considered to have entered the genomes of some species more recently, through infection by exogenous viruses , but this event has never been directly proved Endogenous retroviruses are a common ancestral feature of mammalian genomes with most having been inactivated over time through mutation and deletion  Here we show that KoRV also shows features of a recently inserted endogenous retrovirus that is vertically transmitted The finding that some isolated koala populations have not yet incorporated KoRV into their genomes, combined with its high level of activity and variability in individual koalas, suggests that KoRV is a virus in transition between an exogenous and endogenous element This ongoing dynamic interaction with a wild species provides an exciting opportunity to study the process and consequences of retroviral endogenization in action, and is an attractive model for studying the evolutionary event in which a retrovirus invades a mammalian genome. We have previously reported koala retrovirus (KoRV) to be a functional virus that is associated with neoplasia  Additional PCR primer sets used were: envelope gene primers, Env2 5′-ATGCTTCTCATCTCAAACCCG-3′ (sense) and 5′-TTCAAGTCCTCCGCACCTCC-3′ (antisense), Env3 5′-GGAGGTGCGGAGGACTTGAA-3′ (sense) and 5′-CGTGGTGGGAGATGGAGTAC-3′ (antisense); and polymerase gene primers, 5′-CCTTGGACCACCAAGAGACTTTTGA-3′ (sense) and 5′-TCAAATCTTGGACTGGCCGA-3′(antisense). β-actin PCR was performed in parallel with KoRV PCR as a control for DNA quality Cells were harvested after three days and chromosomes prepared using standard methods with 3 h of incubation with colcemid Cycling parameters are described in Supplementary Methods  Cytogenetics/fluorescence in situ hybridization Koala PBMCs were isolated from whole blood and cultured as described in Supplementary Methods  Detection was performed on a phosphorimager plate ( Kodak ) and SI phosphorimager ( Molecular Dynamics ) Digoxygenin (DIG)-labelled KoRV probes were prepared as described in Supplementary Methods  Hybridization was performed using the DIG hybridization kit ( Roche ) and images were collected with an Axiophot imaging system ( Zeiss ) Individual sperm were isolated and both sperm and negative controls were treated with Promega DNase as described in Supplementary Methods  Methods Southern blotting DNA was isolated from whole blood or tissue samples using the Qiagen DNA Mini or QIamp DNA mini kit ( Qiagen ) PCR cycling and analysis by capillary electrophoresis are described in Supplementary Methods  PCR DNA was isolated from whole koala blood or sperm using the Qiamp DNA mini kit ( Qiagen ) Permits The work in this paper was conducted under animal ethics approvals issued by the University of Queensland Animal Ethics Committee and the South Australian Department of the Environment and Heritage, Wildlife Ethics Committee Primers for multiplex fluorescent PCR were: KoRVmgbf, FAM–5′-TTGGAGGAGGAATACCGATTACAC-3′ and KoRVmgbr, 5′-GCCAGTCCCATACCTGCCTT-3′ ( Qiagen ) Primers were: 5′-AGATCATTGCCCCACCT-3′ (sense) and 5′-TGGAAGGCCCAGATTC-3′ (antisense) Real-time PCR was performed as described previously  Research permits for wildlife research were obtained from New South Wales National Parks and Wildlife, Victorian Department of Sustainability and the Environment, and South Australian National Parks and Wildlife. Single-cell sperm PCR Koala sperm were obtained by epididymal washing Southern blots of samples consisting of 10 µg of DNA digested with Hind III were hybridized with 32 P-dCTP-labelled KoRV pol or env probes (described in Supplementary Methods ) Sperm for FISH analysis were prepared as described in Supplementary Methods  Although no standard definition of an endogenous virus exists, most sources agree that they must be integrated into germ-line tissue and passed on to offspring as a mendelian allele  Although the association of KoRV with disease in a vulnerable species raises important management issues for both wild and captive koalas, the dynamic interaction between this virus and its new host also provides an exciting opportunity to study the process of endogenization in action in a natural setting Although there are functional endogenous proviral loci in other species, and indeed endogenization of single proviruses derived from pre-existing loci have been observed in mice , KoRV is unique in that we are observing the initial entry of a new family of proviruses into a wild host genome Banding patterns in the offspring ( Fig. 2b ) were found to be a combination of parental patterns, with some bands being inherited across three generations Considerable variation was seen both between and within animals; however, 63.5% of these were silent mutations and no premature stop codons were found Cytogenetic analysis of koala PBMCs with a KoRV probe was also performed ( Supplementary Fig. 1a ), which showed that inserts were spread throughout the koala genome, unlike the pattern seen for the only other marsupial retrovirus studied in detail—the kangaroo endogenous retrovirus KeRV-1 (ref. 8 ) Deletions of up to nine base pairs in the envelope gene region were observed, but all deletions were found to be in frame Further evidence for KoRV inserts retaining functional activity, apart from their apparent full length, was suggested by sequencing of the hypervariable region of the KoRV envelope gene (determined by comparison with GALV ; data not shown) Given the presence of KoRV in germ-line cells, we investigated family lineages for inheritance of specific insert patterns Given the very high levels of KoRV activity, both endogenous and exogenous spread of the virus may be occurring in areas of mixed KoRV status Given these observations, KoRV seems to have entered the koala population within the last 100 years and to still be invading the koala genome However, it was unusual in that it possessed a full-length replication-competent genome, viral particles could be produced from cultured koala peripheral blood mononuclear cells (PBMCs), and its sequence indicated a close relationship with gibbon ape leukaemia virus (GALV)—a pathogenic exogenous virus of gibbons  Hybridization of probes derived from the envelope ( env ) ( Fig. 1b , left panel) and polymerase ( pol ) ( Fig. 1b , right panel) regions of KoRV revealed considerable variation in both the number and pattern of integrations Important structural features, such as the eight histidine residues conserved among gamma-retroviruses, were maintained  In contrast, among KoRV-infected animals from southeastern Queensland, 3 out of 63 succumbed to neoplastic disease over the course of our 18-month study  In support of our earlier observations of a link between KoRV and disease in koalas , haematology data from a survey of wild Kangaroo Island animals showed no cases of leukaemia in 225 animals investigated Koala populations were established on a small number of islands (including Kangaroo Island) in the early 1900s and have remained isolated since the 1920s Koalas were largely exterminated on mainland southern Australia as a result of hunting during the late nineteenth and early twentieth centuries KoRV is also actively transcribed in koalas, and both haematopoietic neoplasia and chlamydiosis are positively linked with plasma viral load  On the basis of these data, KoRV seemed more like an exogenous, rather than endogenous, virus One of the puzzling aspects of KoRV when it was first isolated was the very high degree of similarity with GALV Only a few bands were common to some animals, with none common to all Other populations in southern Australia showed a mixed prevalence of KoRV Single-cell fluorescent PCR of koala sperm was performed in order to eliminate the possibility of lysed blood or somatic cell contamination yielding false PCR positives, and this confirmed that KoRV was present in koala germ cells ( Supplementary Fig. 1c ) Southern blotting of Hin dIII-digested DNA extracted from blood cells of related animals from a captive colony and hybridization with the KoRV env probe ( Fig. 2a ) demonstrated that these animals showed a higher degree of insert pattern similarity than unrelated animals (compare with Fig. 1b ) Southern blotting was performed on Hind III-digested DNA from lymph node tissue from unrelated animals from captive and wild populations ( Fig. 1 and Supplementary Table 1 ) Speculation that the two viruses diverged only recently is supported by our study and the search for a potential common ancestor is currently underway The fact that these island and other southern Australian populations have such a low prevalence of KoRV suggests that the virus was not present in the foundation stock in the early 1900s, and that the virus has entered the koala population only in this very recent time frame The koala retrovirus, KoRV, was originally identified as an endogenous retrovirus based on its presence in all koalas tested  The smallest fragments revealed by Southern blotting ( Fig. 1b ) were no less than 5,000 ( pol probe) and 2,500 ( env probe) nucleotides in length, suggesting that the majority of KoRV inserts are full length, although polymerase chain reaction (PCR) data from a previous report , and our own unpublished work, demonstrates that truncated inserts do occur in some koalas The viral insert pattern did not vary across tissues in an individual, further indicating that the virus was endogenous ( Fig. 2c ) These populations have since been used to restock the mainland in ongoing relocation programmes  This is in marked contrast to other modern endogenous retroviruses where the most recent estimate for endogenization is a porcine virus that entered its host approximately 5,000 years ago  This may help shed light on an almost universal process in species development, and answer fundamental questions as to the establishment and role of endogenous retroviruses in their hosts. This pattern is not typical for an endogenous virus of a single host species where a higher degree of conservation of bands could be expected  This result was supported by fluorescence in situ hybridization (FISH) analysis of koala whole sperm with a KoRV-specific probe. ( Supplementary Fig. 1d ) This type of selection for functional quasi-species has been reported for exogenous viruses , but is not typical for endogenous viruses where loss of functionality is expected to occur through random mutation  This was in contrast to the uniform detection of KoRV in Queensland animals ( Fig. 3 ), suggesting ongoing infection and endogenization in the koala population, spreading from northern to southern Australia To examine KoRV insertions in the koala population as a whole, blood samples were obtained from wild koalas over the geographical distribution of the species, and KoRV pol - and env -specific PCR and real-time PCR performed on extracted DNA To examine this apparently ongoing dynamic interaction between KoRV and the koala population, we examined variation in KoRV inserts between individual koalas Two methods were used to confirm KoRV integration into germ-line tissue Unexpectedly, KoRV was not detected in any of the animals from Kangaroo Island (situated off the coast of South Australia; Fig. 3 ) We have found previously that the KoRV genome copy number varies between individual animals 
 According to official statistics, some 330,000 people have been infected so far, but little research has been done into the extent of the epidemic, and there is no credible reporting system for new cases Among other things, this would provide people with AIDS with antiretroviral treatment, which can cost up to $10,000 per person per year As elsewhere, the disease first infected injecting drug users and sex workers, groups that often overlap But it now seems to be moving into a second wave, where HIV is passed more by sexual transmission than shared needles But Khachatrian feels that this would be far from enough. “Whats really needed is a single AIDS strategy spanning research, prevention, treatment and human rights,” he says But the epidemic is now believed to be growing faster in Russia and central Asia than anywhere else in the world Health experts from Europe and the United States have called on the Russian government to strengthen its fight against the countrys dramatically worsening HIV and AIDS problem In an open letter to Russian president Vladimir Putin, the TPAA has asked for the creation of a presidential council on HIV and AIDS that would develop and review such a strategy. In comparison, Brazil, whose population is about the same size, spends almost $200 million a year Large-scale action is urgently needed to prevent the disease spreading from vulnerable groups to the general population, he says. “Neither AIDS prevention and treatment, nor research related to the disease, have been big priorities here.”  In recent years the Russian government has spent just US$3 million to $4 million a year fighting the disease Last week, the Russian Health Ministry proposed spending up to $90 million extra each year Most Russian AIDS programmes are run by non-governmental and international organizations, such as the World Health Organization or the Bill Melinda Gates Foundation The committee is starting with Russia, and organized the Duma hearing as a first step. “Its bizarre,” she says. “Sex is for sale on every corner here, but a sexual-health strategy just doesnt seem to exist.”  AIDS arrived late in Russia, thanks to the countrys relative isolation during the cold war, and the first case of HIV was not reported until 1987 The epidemic there is set to explode, posing a serious threat to the former superpowers social and economic welfare, and even its stability, they told a parliamentary hearing at the Russian State Duma on 23 September. “Russia needs to do a lot more than it has done in the past,” says Chris McCafferty, chairwoman of a Council of Europe committee on social affairs that is launching a detailed study of HIV and AIDS in Europe The fear is that within five years, up to 10 million of Russias 140-million population could be infected, says Alec Khachatrian, Russian programme director of Transatlantic Partners Against AIDS (TPAA), a New York, Moscow and Kiev-based charity that gave evidence at the hearing The number of unreported cases is thought to exceed 1 million
 Creation of these enzymes demonstrates the feasibility of exploiting the underlying evolvability of this scaffold, and provides evidence that rational approaches based on these ideas are useful for enzyme design. Here we present the construction of seven specific and active synthases that use different reaction pathways to produce the specific and very different products Identified plasticity residues were systematically recombined based on a mathematical model in order to construct novel terpene synthases, each catalysing the synthesis of one or a few very different sesquiterpenes It is generally believed that proteins with promiscuous functions divergently evolved to acquire higher specificity and activity , and that this process was highly dependent on the ability of proteins to alter their functions with a small number of amino acid substitutions (plasticity)  Many structural and biochemical analyses have identified the active or binding site residues important for functional plasticity (plasticity residues)  The application of this theory of divergent molecular evolution to promiscuous enzymes may allow us to design enzymes with more specificity and higher activity To understand how these residues contribute to molecular evolution, and thereby formulate a design methodology, plasticity residues were probed in the active site of the promiscuous sesquiterpene synthase γ-humulene synthase  Algorithm for systematic remodelling of plasticity residues To design the specificity for novel sesquiterpene synthases, combinations of mutations were selected based on the results from the previous screening An aliquot (50 µl) of this seed culture was inoculated into fresh LB medium containing 10 mM mevalonate, 0.1 mM isopropyl-1-thio-β- d -galactopyranoside (IPTG), 50 µg ml -1 carbenicillin and 50 µg ml -1 kanamycin (5 ml), overlaid with 500 µl dodecane, and grown for 24 h at 30 °C An aliquot of dodecane (50 µl) was diluted into 200 µl of ethyl acetate, and the mixture was analysed by GC-MS using a GC oven temperature programme of 80 °C for 1 min, then steps of 30 °C min -1 to 110 °C, 5 °C min -1 to 160 °C and 130 °C min -1 to 250 °C for Cyclosil-B capillary column analysis, or at 80 °C for 3 min, then steps of 5 °C min -1 to 160 °C and 120 °C min -1 to 300 °C for DB-5MS capillary column analysis Assuming that there is no interaction between plasticity residues, the effect of a certain mutation is the same for both wild type and other mutants Gas chromatography-flame ionization detector (GC-FID) analysis was also carried out to quantify each sesquiterpene product using the method described herein Homology structural modelling of γ-humulene synthase The homology structural model for γ-humulene synthase ( Supplementary Data 1 ) was built using MODELLER ( http://salilab.org/modeller/ ) Methods GC-FID and GC-MS analysis for sesquiterpenes A single colony harbouring pTrcHUM and pBBRMBIS (kanamycin; antibiotic-resistance gene was replaced) was inoculated into Luria Bertani (LB) medium containing 50 µg ml -1 carbenicillin and 50 µg ml -1 kanamycin and grown overnight at 30 °C See Supplementary Methods for additional methods. Sesquiterpenes were identified from their mass spectra and GC retention times by comparison to available authentic standards (γ-humulene, longifolene, α-longipinene and E -β-farnesene) and spectra in libraries previously reported in the literature (sibirene , α-ylangene , β-bisabolene and Z , E -α-farnesene ) Similarly, the overall productivity at the m th generation was calculated using the following equation: P m = ∑  i = 1 n   P i , m = ∑  i = 1 n   p i ∏  g = 1 m   x i , g The combinations of mutations were selected so as to decrease the ω  m value and to maintain P m  The alignment ( Supplementary Fig. 11 ) and the structure of 5- epi -aristolochene synthase (PDB entry 5eat) were used as guides The predicted percentage of product distribution of compound i by addition of m distinctive mutations ( m th generation), D i , m , is then represented as follows: D i , m = d i ,0 ∏  g = 1 m   x i , g ∑  j = 1 n   d j ,0 ∏  g = 1 m   x i , g × 100 (%) where d i ,0 represents the parent (0th generation) product distribution of compound i (which can be predicted) and x i , m represents the effects by the m th mutation The proportion of each product was determined based on the ratio of the relative peak abundance for each product The resulting homology structure was visualized using Chimera ( http://www.cgl.ucsf.edu/chimera ) The selected mutations were added to γ-humulene synthase and the results were inspected Therefore, the product distribution profile upon another round of mutagenesis can easily be calculated using the following equation: D i = d i x i ∑  j = 1 n   d j x j × 100 (%) where D i is the predicted percentage of product distribution of compound i for all compounds 1 to n (in this study n = 17), d i is percentage of parent product distribution of compound i (which can be predicted) and x i is the effect of a particular mutation on compound i productivity relative to the wild-type enzyme To improve the accuracy of the design methodology, we included 17 different product profiles, which correspond to 95% of total products To maintain specific activity and productivity, the overall productivity was calculated using the following equation: P = ∑  i = 1 n   P i = ∑  i = 1 n   p i x i where P is total productivity, P i is predicted productivity for compound i , and p i is parent productivity for compound i  To screen the library resulting from site-directed saturation mutagenesis, a single colony harbouring only pTrcHUM was inoculated into LB medium containing 0.1 mM IPTG and 50 µg ml -1 carbenicillin overlaid with 500 µl dodecane, and grown for 24 h at 30 °C To select the mutations that probably introduce the desired function, the root mean square deviation of the predicted product distribution from the desired product distribution was calculated using the following equation: ω  m = ∑  i = 1 n    D i , m - d i ′ 2 n  (%) where ω  m represents the relative closeness of product profiles of mutants with m th generation ( m mutations) to the one specified, and d ′ i is the percentage of desired product distribution for compound i (for example, for β-bisabolene synthase d ′ 7 = 100% and d ′ i ≠7 = 0%) All effects other than antagonistic, however, would still be predicted to some extent using the methodology outlined here All terpene synthases share a similar active site scaffold  Almost all mutations were added by saturation mutagenesis so as not to miss any better substitutions that were not predicted by the algorithm Although many of these residues were identified to be plastic, four residues significantly affected catalysis: W315, M447, S484 and Y566 ( Supplementary Figs 2–5 ) Although mutations to residues in the conserved aspartate-rich motif in the active site are known to alter the reaction mechanisms of terpene synthases , these residues were not considered further because mutations in this motif are usually accompanied by significant losses of activity  Although plasticity residues can be found anywhere in proteins, many biochemical and genomic analyses have indicated that they tend to be more focused inside or near active sites  Although the construction of α-ylangene synthase was not achieved (AYG), the algorithm predicted that it would not be possible to create such an enzyme from the current set of plasticity residues Although we assumed that the plasticity residues behaved as if they were independent and that changes to these residues were additive, the effects could be partially additive, synergistic, antagonistic, or even absent altogether  Although we demonstrated systematic recombination using the subset of plasticity residues located in the active site, other residues can also be considered in order to construct other specific enzymes or even enzymes that produce unnatural products. *In Figure 1 and Supplementary Figure 1, the structure of longifolene (4) has been corrected (it was missing a methyl group) As a result, the 19 residues composing the active-site contour were selected for saturation mutagenesis to investigate how each residue contributes to a particular reaction mechanism ( Fig. 2 ) As direct or indirect interactions between two residues increase, the impact of multiple mutations may be far from additive  Because natural evolution is known to be a highly accomplished designer for protein function, understanding how proteins acquire novel or altered functions and how plasticity residues contribute to the natural evolution process may help to formulate an efficient design methodology for new enzymes Because plasticity residues have very important roles in proteins , this approach, with some modifications, may be useful for designing novel functions for many other proteins, including enzymes, protein ligands/receptors, transcription factors and antibodies Consistent with this observation, results from directed evolution , which can search for such residues over entire proteins, also indicate that these residues most often occur in the active site  Construction of the large number of sesquiterpene synthases required fewer than 2,500 mutants to be screened For example, in the construction of a β-bisabolene synthase (BBA; product 7 in Fig. 1 ), two mutants (M447H/A336V/I562T ( ω  = 6.7) and M447H/A336V/I562V ( ω  = 5.4)) were predicted to be the best combinations of mutations to these three amino acids to maximize β-bisabolene selectivity ( ω  = 24.4 for wild type) Hence, in practice, the assumption that mutations will have an additive effect is rational, and the resulting enzyme design methodology is simple, yet powerful However, in almost all cases, the predicted substitutions gave the desired product distribution ( Fig. 3 ; see also Supplementary Tables 2–7 and Supplementary Figs 6–10 ) However, in directed evolution—currently touted as an effective tool to alter protein function —tens of thousands to a million or more mutants must be screened to find a few critical mutations; hence its application is limited by the availability of an efficient screening method However, the significantly greater promiscuity of this enzyme compared to other enzymes makes functional design more challenging, and the lack of a selection or a high-throughput screen for evolved terpene synthases makes directed evolution nearly impossible If two residues to be mutated do not interact, then the effect of mutating the residues is likely to be additive In addition, it is extremely difficult to predict the relationships between primary sequence and enzyme function in this class of enzymes, because enzymes are closely related within or near species regardless of their functional disparity  In addition, we observed convergent evolution, as the product profiles of HUM and AYG are very similar to each other despite the significant differences in mutations that gave rise to these specific functions ( Fig. 4 ) In general, all of the designed enzymes maintained a level of specific activity comparable to the wild-type ancestor ( Table 1 ) In general, this reaction generates a large number of terpene structures with different regio- and stereochemistries  In none of the previous work was it shown that one could successfully control this reaction pathway of a highly reactive carbocation species, or improve the product selectivity for chemically more complex reactions In Supplementary Figure 1, the longipinene structure was also wrongly labelled longifolene and vice versa Interestingly, with the exception of the double mutant M339N/S484C, all mutations introduced into the enzyme were effectively additive It is thought that primordial enzymes may have been promiscuous to render primitive organisms adaptable to their environment; enzymes with higher specificity are the result of divergent evolution (gene duplications and subsequent mutations), driven by selective pressure, from promiscuous precursor enzymes M447 was important in specifying the 10,1 or 6,1 closure from the trans - or cis -farnesyl cation ( ω  = 16.3, Fig. 3b , c ); A336 was important in specifying the 11,1 closure from the cis -farnesyl cation ( ω  = 10.8, Fig. 3d , e ); and I562 was important in specifying acyclic terpene formation ( Fig. 3f ) M447H/A336V/I562T reduced production of product 1 and showed 2.5-fold better selectivity for production of 7 over 1 compared to that of M447H/A336V/I562V ( Fig. 3f ; see also Supplementary Table 2 ) Mutations to these residues shifted the relative selectivity (the amount of one product relative to another product) by 100- to 1,000-fold Numerous biochemical analyses have suggested that proteins have an ability to improvise novel or altered functions with a small number of amino acid substitutions (plasticity)  On the basis of the theories of molecular evolution and experimental observations, we formulated an approach for systematic recombination of the promiscuous γ-humulene synthase Owing to the extreme promiscuity of γ-humulene synthase, the product distribution could be very sensitive to changes in specific amino acid residues; hence, the enzyme should be an excellent model to study plasticity residues Promiscuous enzyme activities have long been believed to be an important determinant for molecular evolution of more specific and active enzyme functions  Saturation mutagenesis of residue S484 and subsequent screening by gas chromatography-mass spectrometry (GC-MS) suggested that 80 mutants were sufficient to obtain almost all possible amino acid changes ( Supplementary Table 1 ) SIB, HUM, ALP and AYG are new synthases that have not yet been discovered in nature The altered product distribution from each mutant was normalized to that of the wild-type enzyme and profiled The reaction is initiated by cleavage of the diphosphate group to yield a carbocation intermediate, which is then cyclized into many different structures The recombination was carried out using an algorithm (detailed in the Methods) based on the assumption that each plasticity residue is independent—the effect of a particular mutation on the reaction mechanism should be the same for the wild-type enzyme and any mutants The systematic recombination approach described herein enabled us to design enzyme specificity rapidly and efficiently without a screen for the desired activity The underlying evolvability of promiscuous enzymes is also thought to be very important in molecular evolution in order to allow organisms to adapt rapidly in response to environmental changes  Therefore, a method that would allow one to predict the effect of changes in amino acid residues in terpene synthases on product selectivity would alleviate the need for a high-throughput screen or genomic analysis in designing synthases useful for mass production of single terpenes that have found use as drugs, flavours, fragrances, nutraceuticals and in many other applications  These results indicate that in order to generate a specific enzyme from another specific enzyme, the enzyme must first acquire promiscuous function, supporting the theory that specific enzymes could evolve from promiscuous precursor enzymes with surprisingly few mutations  These results suggest that: (1) divergent evolution by rational design may be feasible on a significantly larger scale than currently possible; (2) plasticity residues could significantly drive molecular evolution; and (3) most of the substitutions in plasticity residues additively affect protein functions This correction was made on 27 February 2006. This lack of relatedness among the limited number of known sesquiterpene synthases with a similar function makes functional design based on phylogenetic analysis nearly impossible  Thus, a set of mutations to achieve a desired enzyme function was predicted based on how much the product distribution moved towards the desired product distribution, as measured by ω  for a particular combination of mutations Thus, a β-bisabolene synthase was successfully constructed while maintaining its activity ( Table 1 ) To determine the active-site residues important for γ-humulene synthase function, a homology structure for γ-humulene synthase was first built using the crystal structure of 5- epi -aristolochene synthase (Protein Data Bank entry 5eat ) as a guide  To investigate further how these plasticity residues contribute to molecular evolution and to formulate a design methodology for product selectivity, the mutations were systematically recombined based on the profiles obtained from saturation mutagenesis To investigate how promiscuous proteins might evolve to acquire more active and specific functions, we chose as a model enzyme γ-humulene synthase, a sesquiterpene synthase from Abies grandis that is known to produce 52 different sesquiterpenes from a sole substrate, farnesyl diphosphate, through a wide variety of cyclization mechanisms ( Fig. 1 and Supplementary Fig. 1 ) We refer to those residues that primarily govern enzyme specificity as plasticity residues We successfully constructed a large number of novel specific sesquiterpene synthases, each producing one or a few products derived from a predominant reaction pathway while largely maintaining the specific activity of the original enzyme We used this same method to create an E -β-farnesene ( 1 )/ Z , E -α-farnesene ( 8 ) synthase (BFN: W315P), a sibirene ( 2 ) synthase (SIB: F312Q/M339A/M447F), a longifolene ( 4 ) synthase (LFN: A336S/S484C/I562V), an α-longipinene ( 5 ) synthase (ALP: A336C/T445C/S484C/I562L/M565L) and two new γ-humulene ( 3 ) synthases (HUM: M339N/S484C/M565I and AYG: S484A/Y566F), the latter having significantly improved α-ylangene ( 6 ) production ( Fig. 4 , Table 1 , Supplementary Figs 6–10 and Supplementary Tables 3–7 )
 Addressing this very issue, one visionary bucked the trend in the grandest fashion, writing in 1902 that “the time is drawing near when it will be possible to suggest a systematic exploration of the future” An anthology of the best of Futures is planned, and the column itself will continue, for a while, in our sister publication Nature Physics  And even now, we havent quite come to the end of eternity And thats the key — SF is meant to amuse in the present As if to prove his point, the writer went on to outline a startling version of statistical mechanics in which the behaviour of large numbers of humans could be predicted, presaging Isaac Asimovs future science of psychohistory (in his Foundation novels) by half a century From this we can derive some comfort that Futures in Nature has indeed a venerable past G Later still, the writer notes that “the question what is to come after man is the most persistently fascinating and the most insoluble question in the whole world”, touching, even if coincidentally, on the theme of post-humanity that animates much current SF, itself a reaction to cloning and genetic manipulation Or, to put it more succinctly, “it is difficult to make predictions, especially about the future”, a sentiment usually attributed to baseball star Yogi Berra Since 1999, Nature has published no fewer than 156 such journeys into things to come, ranging from the serious to the whimsical, all of which (hopefully) provided some entertainment So for a little longer, at least, we can share the emotions of Wells Time Traveller (in his 1895 novel The Time Machine ), who “merged at last into a kind of hysterical exhilaration... with a kind of madness growing upon me, I flung myself into futurity”. That it might sometimes be found attached to Sam Goldwyn, Woody Allen or even Niels Bohr demonstrates its fundamental soundness — and also, perhaps, that the past is as unreliable as the future The most memorable SF works do this by projecting our present concerns onto the greater canvas of uncertainty that is the preserve of that part of history that hasnt happened yet This is a bold statement indeed, but one that makes more sense if it is recognized that science is a necessarily predictive endeavour This week features the last in the series of Futures, Nature s occasional excursion into speculative fiction (as science fiction, or SF, is sometimes known) Wells, writing in these very pages ( Nature 65 , 326 – 331 ; 1902 ) Who was this visionary? It was none other than H
 Across mammals, the amount and nature of sleep are correlated with age, body size and ecological variables, such as whether the animals live in a terrestrial or an aquatic environment, their diet and the safety of their sleeping site Most theories suggest a role for non-rapid eye movement (NREM) sleep in energy conservation and in nervous system recuperation Sleep may be an efficient time for the completion of a number of functions, but variations in sleep expression indicate that these functions may differ across species. The functions of mammalian sleep remain unclear Theories of REM sleep have suggested a role for this state in periodic brain activation during sleep, in localized recuperative processes and in emotional regulation A complementary hypothesis is that small herbivores and other mammals may need to maximize sleep amounts to conserve energy because their relatively high ratio of surface area to body mass makes it costly to maintain their body temperature A high metabolic rate results in the generation of high levels of reactive oxygen species (ROS) by mitochondria A remarkable feature of the transition from water to land is that fur seals immediately adopt their land sleep amounts without any evidence of REM sleep rebound, despite the absence or near absence of REM sleep while in the water  A second hypothesis is that these grazing animals may need to spend more time awake in order to eat because of the low calorific density of their food A species customary diet is correlated with sleep time A striking feature of sleep in animals with small daily sleep amounts, such as many herbivores, is that sleep depth, as judged by EEG and sensory response threshold, seems to be less than that in animals requiring more sleep All terrestrial mammals have minimal activity and maximal total sleep and REM sleep amounts at birth, with sleep gradually decreasing and activity gradually increasing to adult levels as the animals grow to maturity  Alternatively, we may need to revise our assumption that sleep is fundamentally similar in cetaceans and terrestrial mammals and focus on how cetaceans can dispense with some of the most readily detectable aspects of sleep Although a high level of heat generation is vital to maintaining their body temperature, sea temperature varies little over the 24-hour day, making the ‘recalibration’ proposed for thermoregulatory systems during their relative suspension in REM sleep less necessary  Although an initial study of the echidna suggested that monotremes do not have REM sleep , further observations indicated that they have an unusual form of this state Although anxiety can decrease the amount of REM sleep , acute stress can greatly increase REM sleep time in the rat, despite the absence of sleep loss during the previous stress , suggesting that under some conditions REM sleep ‘rebound’ may be related to the emotional or autonomic concomitants of the REM sleep-deprivation procedure rather than the loss of REM sleep itself Although behavioural immobility and reduced overall body metabolic rate relative to active waking are maintained, why has this state evolved when continued NREM sleep, with its reduction in brain metabolic activity, would seem to be more efficient at achieving the recuperative and energy-saving effects of sleep? Memory consolidation The idea that either REM or NREM sleep is ‘absolutely required’ for memory consolidation has received much attention recently Although motivated humans can overcome sleepiness for short periods, they cannot perform at high levels for sustained periods  Although neocortical EEG changes are the most easily observed electrical correlate of sleep because they are recordable from scalp electrodes in humans and from electrodes placed on the surface of the cortex in other animals, sleep produces large changes in the rates and patterns of neuronal activity in nearly all brain regions, not just in the neocortex Although neocortical size does not seem to be a major determinant of either NREM or REM sleep amounts, recent work has indicated that neocortical activity during sleep may be altered by prior waking activity Although some evidence for rebound was seen, the response was highly variable, with some animals showing little or no recovery of lost slow waves Although the nature of sleep states early in the development of the rat differs from adult patterns, the brainstem mechanisms generating REM sleep are present at birth  Although the thermosensitivity of the REM sleep on cell populations has not been characterized, it has been shown that cooling of the isolated brainstem produces a marked increase in REM sleep amount , just as heating of the forebrain produces a marked increase in NREM sleep  Altricial mammals, those that are immature at birth, tend to have more REM sleep than mammals that are mature at birth, or precocial An additional defining characteristic of sleep is that when it is prevented, the body tries to recover the lost amount An important task will be the identification of which of the hypothesized functions may only be achieved during sleep, and which may be executed during both waking and sleep, with sleep being a more efficient time for their accomplishment An interesting aspect of our findings was that the most marked changes occurred in a brain region with the highest rate of protein synthesis, and presumably with one of the highest rates of ROS generation, the supraoptic nucleus of the hypothalamus  And temperature in several brain regions increases during REM sleep , even though the regulation of body temperature is largely suppressed during REM sleep  Animals that are awakened from NREM sleep have poor sensory-motor function compared with those awakened from REM sleep  Animals typically awaken spontaneously from REM sleep  Another aspect of sleep strongly linked to body mass and brain size is the duration of the sleep cycle, that is, the average time taken to cycle from NREM sleep onset, through REM sleep, to waking As long as the extended NREM sleep of neonates is interrupted by the increased neuronal activity of REM sleep, neuronal development proceeds according to genetic programmes  As the animal gains mass and blubber and approaches adult size, adult-like ‘sleep’ or rest behaviour, including periods of immobility, emerges Awakening in a more alert state would convey a substantial selective advantage Body mass, metabolism and sleep control One of the best-established relationships in mammalian biology is the inverse link between body mass and mass-specific metabolic rate Both mother and calf go without substantial amounts of immobility and the eye closure linked to unihemispheric slow waves, for periods that greatly exceed those of sleep deprivation that are reported to kill rats  Both the echidna and platypus show evidence of brainstem activation during sleep, with the platypus displaying intense rapid eye, limb and bill movements periodically during sleep Both total brain weight and encephalization correlate poorly and negatively with total NREM and REM sleep amounts  Brain metabolic rate is correlated with body metabolic rate  But perhaps more remarkable is that altricial animals continue to have more REM sleep as adults By contrast, cetaceans (whales and dolphins) almost never have high-voltage slow waves in both hemispheres at the same time ( Fig. 3 ; refs 30 , 31 ) By contrast, the guinea pig has only 1 hour of REM sleep per day as an adult  Carnivores and omnivores, which tend to have more sleep than predicted on the basis of body mass alone, may make more use of the energy-conservation aspects of sleep because their generally safe sleep places and ability to eat meals with high calorific density may make continuous activity unnecessary Certainly disturbed sleep is not conducive to concentration and learning, but an essential role for sleep in memory consolidation remains unproven  Cetaceans deftly avoid obstacles during this constant motion, suggesting accurate bilateral processing of sensory information Conversely, damage to these regions greatly reduces sleep Conversely, the rat and the platypus, which have smooth cortices with small total neocortical volumes, have extremely large amounts of sleep, with the platypus having more REM sleep than any other animal studied so far ( Fig. 4 ; ref. 29 ) Cortical EEG phenomena are controlled by and reflect activity in thalamic, hypothalamic and brainstem reticular regions Cytokines such as interleukin-1 have been implicated in sleep control  Daily sleep amounts are highest in carnivores, lower in omnivores and lowest in herbivores Daily sleep amounts vary substantially from mammal to mammal Damage to these neurons greatly diminishes or prevents REM sleep for long periods  Detailed reviews of the physiological control of sleep are available elsewhere , but for the purposes of the current review, several aspects will be highlighted Differences in order do not simply explain differences in sleep amounts  Effects of sleep deprivation Sleep restriction leads to a feeling of sleepiness and, depending on the nature of the sleep lost, to increases in the amplitude of the brain-wave signals that characterize NREM sleep and the amplitudes and frequencies of the eye movements and twitches that characterize REM sleep, when sleep is allowed  Elevated metabolism is linked to a number of biochemical changes, several of which have been linked to sleep control Energy conservation may be particularly important in newborns Energy conservation Sleep may be adaptive because it conserves energy and suppresses behaviour across portions of the 24-hour day, just as hibernation does across certain seasons  Equally striking is the near absence of typical sleep behaviour in the mother during the postpartum period Fur seals Fur seals and other otariids (seals with external ear flaps) exhibit another difference from the sleep of terrestrial mammals Furthermore, animals that are immature at birth benefit from the sleep-induced reduction in exposure to danger Furthermore, this increased REM sleep time does not seem to produce a homeostatic reduction in REM sleep time during the subsequent night  Future directions Sleep probably has multiple functions for the brain and body Groups of sleep-active neurons have been discovered in the preoptic and basal forebrain regions ( Fig. 1 ) Heating of the preoptic regions increases NREM sleep However, even in terrestrial mammals, certain drugs can induce bilateral high-voltage EEG activity in individuals that are clearly awake  However, fur seal sleep, unlike that of cetaceans, is accompanied by striking motor asymmetries However, if one statistically controls for body weight or brain weight, REM sleep amount is most strongly correlated with immaturity at birth  However, neocortical size does not correlate positively with sleep amount However, the low-voltage neocortical EEG typically seen in eutherian and marsupial mammals during REM sleep is not consistently present during sleep in either the echidna or platypus during these activities  Humans, in particular, do not seem to have amounts or aspects of REM sleep or NREM sleep that distinguish them from other species, although they do have less sleep (more waking) than most omnivores ( Fig. 2 ) I and others have reviewed this issue elsewhere and concluded that this is unlikely to be the case If a strong relationship with previous waking existed, one would expect to see maximal REM sleep intensity and duration in the early part of the night, alternating with NREM sleep, which is most intense at this time If cortical and subcortical neuronal activity is similar during waking and REM sleep, why are these states so different? The differences between these two states, including the difference in muscle tone and the different levels of awareness of the environment, can presumably be attributed to the small number of neurons whose activity differs between these two states If sensory and motor systems do not show typical sleep inactivation, if behavioural and sleep rebound evidence for sleep debt is weak, do cetaceans sleep as conventionally defined? Certainly further work is necessary to determine which, if any, neurochemical and neurophysiological aspects of sleep, other than unilateral neocortical slow waves and eye closure, are preserved in cetaceans and might constitute the ‘essence’ of sleep If this hypothesis were valid, it seems clear that the nature of such resensitization would be specific for particular receptor types and brain regions  In all marine mammals studied to date, the eye contralateral to the brain hemisphere with slow waves is almost always closed while the other eye is almost always open In general, most theories have assumed that sleep serves the same function in all animals, although most data supporting such theories have been derived from observations limited to just a few species of terrestrial mammal In humans, the duration of REM sleep episodes progressively increases throughout the sleep period and is maximal at the expected time of awakening In neocortical neurons, the decrease in activity during NREM sleep compared with active waking is smaller than that seen in the brainstem, but the neuronal activity pattern differs greatly from the REM sleep and waking pattern In other words, animals with low sleep amounts do not seem to ‘make up’ for low sleep quantity by sleeping more ‘deeply’ In such a situation, reproductive fitness might best be served by energy conservation, which would reduce the need for hunting, aid nurturing of the young and speed development In these animals, the presence of continuous motor activity would be expected to maintain a high level of metabolic activity in brainstem structures 24 hours a day, eliminating any need for REM sleep activation of these systems In this review we will consider the vast knowledge that has been gained about the physiological nature of sleep and sleep-control mechanisms, evidence from sleep-deprivation studies and the distribution of sleep across species in the context of theories of sleep function It also remains to be determined which, if any, of the proposed functions are universal across mammalian species and across the lifespan, and which may be limited to particular species or phases of development. It has been argued that this phenomenon may be similar to mania seen in humans, which is also accompanied by a major reduction in sleep  It is also clear that sleep expression is adapted to ecological factors and may differ qualitatively across species It may be that a normal function of REM sleep is to dampen activity and emotional expression by causing the changes in monoaminergic systems proposed above Large herbivores may have evolved reduced sleep amounts because they are more vulnerable to predators than small herbivores  Manatees ( Trichechus inunguis , a member of the order Sirenia) also have unihemispheric slow waves  Many of these signs of sleep loss can be seen after hypothalamic damage and concomitant abnormal functioning of the endocrine and immune systems  Many sleep-active neurons are thermosensitive; when studied in tissue slices and in the intact brain they increase their activity at higher temperatures  Monocular light deprivation during the ‘critical’ neonatal period also caused a reduction in the thickness of the lateral geniculate layers innervated by the closed eye Moreover, high-voltage neocortical activity is not a required indicator of sleep; a NREM sleep state with low-voltage neocortical activity has been documented in rodents  Moreover, neither the mother nor the calf shows any rebound increase in the amount of sleep behaviour after this period Most studies of mammalian sleep have been performed on placental (eutherian) or marsupial mammals Neocortical maintenance A recurrent theme in theories of sleep function is that sleep time is determined by neuronal activity in the neocortex Neuronal activity across the sleep cycle With the important exception of the comparatively small populations of sleep-active and REM sleep-active neurons described above, and other small groups of ‘REM sleep off’ neurons to be considered below, most brainstem neurons are maximally active during waking with movement and during REM sleep and are minimally active during NREM sleep  Neuronal recording studies in terrestrial mammals suggest that the axial movements occurring in cetaceans during both normal swimming and swimming with unihemispheric slow waves are accompanied by activation of large regions of the brainstem reticular formation Nevertheless, we must not assume that the effects of sleep loss are independent of the deprivation technique used or that sleep loss has equally dire effects in all animals  New neurons are generated in adult animals in the olfactory bulb, the subventricular zone lining the lateral ventricles, and in the subgranular cell layer of the dentate gyrus of the hippocampus, in a process that produces functional neurons in 3–4 weeks NREM sleep phenomena can be generated by the isolated forebrain  One can imagine that REM sleep serves this function for other sensory systems and perhaps for motor systems as well, given the intense central motor activation that occurs during this state (whose peripheral expression is blocked by the inhibition of motoneurons)  One hypothesis was that brain glycogen is depleted during waking and restored during sleep ; however, subsequent work showed that this effect did not occur in all strains of mice, suggesting that this could not be a general regulatory mechanism or function of sleep  One may hypothesize that the ‘ratio’ of the energy conservation benefit of sleep to the waking metabolic-activity-derived need for sleep for brain recuperation varies across species One might expect species in each mammalian order to have a similar sleep pattern because of their genetic, behavioural and anatomical similarities One might hypothesize that these individuals would be less alert upon waking, a change that would have minimal survival implications in most contemporary humans but might have significant effects upon reproductive success in other animals One would not expect an increase in duration and intensity of REM sleep across the sleep period if REM sleep intensity were linked to one or more aspects of the previous waking episode Only one study has looked for sleep rebound after EEG slow waves were prevented by disturbing cetaceans Other substances, including adenosine, prostaglandin D 2 , a muramyl dipeptide, delta sleep inducing peptide, corticostatin, growth-hormone-releasing hormone, oxidized glutathione, uridine, tumour necrosis factor-alpha, oleamide, cortistatin, cholecystokinin, insulin, nitric oxide and neuropeptide S , have significant effects on sleep Others subsequently found that when animals were also REM sleep deprived during the critical period of susceptibility, this shrinkage was accelerated  Others, such as the elephant and giraffe, sleep for as little as 3–4 hours a day Possible explanations include the inverse correlation of metabolic rate with body mass and brain mass, the thermal inertia of the brain and body, the time required for diffusion of substances through the brain parenchyma or the time required to complete a particular anabolic or catabolic biochemical task Postpartum sleep behaviour in cetaceans Further evidence for the unique properties of ‘sleep’ in cetaceans is the near absence of sleep behaviour in neonates and a postpartum reduction in sleep behaviour in their mothers  Previous studies challenging the phylogenetic relationship between sleep time and metabolic rate have used the partial correlation statistical approach Primates as a group do not have sleep characteristics that distinguish them from Rodentia, Insectivora or other orders Protein synthesis in the brain is increased during slow-wave sleep  Recent reviews have critically evaluated many of these theories  Recent work suggests another role for sleep Recent work suggests that the cessation of histamine neuron activity is linked to the loss of consciousness in sleep, whereas the cessation of noradrenaline neuron activity is linked to muscle tone suppression during sleep  Regulation of monoaminergic systems The linked cessation of activity in noradrenaline, serotonin, histamine and hypocretin cells that occurs during normal REM sleep, and to a lesser extent during NREM sleep, suggests another possible function for sleep REM sleep amounts are maximal near the nadir of the brain and core body temperature cycles REM sleep and development REM sleep amount is positively correlated with total sleep amount and negatively correlated with body weight REM sleep deprivation causes an acceleration of body heat loss during subsequent waking in the rat  REM sleep deprivation has antidepressive effects REM sleep in adults If we accept that the large amount of REM sleep early in life serves to maintain or establish brain connections during crucial periods of development, what is the function of this state later in life? One idea that has been proposed repeatedly is that REM sleep stimulates the adult brain during sleep to reverse the effects of NREM sleep on immediately subsequent waking behaviour REM sleep is characterized by a low-voltage EEG, indistinguishable from that of waking in many animals REM sleep is ‘paradoxical’ in the sense that although an animal in REM sleep is behaviourally asleep, brain metabolic and neuronal activity are high, respiration and heart rate are variable, rapid eye movements and twitches of the extremities occur and males frequently develop erections  REM sleep itself is a state in which thermoregulation is attenuated , suggesting that recuperative changes in thermoregulatory control mechanisms may occur during REM sleep periods, perhaps through the maintenance, repair or sensitization of peripheral monoaminergic control mechanisms, in much the same way that an improvement in the central functioning of these systems has been proposed to take place during REM sleep REM sleep phenomena can be generated by the isolated brainstem, specifically by the pons and adjacent midbrain  Retreating to a warm, protected nest may minimize this cost Saying that it is desirable to be well rested and that the body seeks lost sleep with a vigour comparable to or greater than that displayed for food or sex does not answer the question of the functional role of sleep Several substances whose activities or levels may vary with overall metabolic activity in the brain have been proposed to have roles in sleep control or function Short-term (2–3-day) total sleep deprivation, even when other forms of stress are controlled for, also blocks subsequent proliferation of cells in the dentate gyrus  Similarly, the manifestation of REM sleep in monotremes as a largely brainstem state, without marked neocortical activation, suggests that REM sleep may have evolved as a state of brainstem activation, with cortical stimulation functions added later in evolution Similarly, the sheep and giraffe are relatively mature at birth and have little REM sleep (less than 1 hour per day) at maturity  Sleep deprivation in rodents and flies can cause death more quickly than food deprivation  Sleep in marine mammals All terrestrial mammals show relatively high-voltage neocortical EEG activity bilaterally during NREM sleep Sleep is reduced at temperatures outside the thermoneutral zone, and REM sleep amounts are maximal at the upper levels within this zone  Sleep loss causes intrusions of sleep into waking that can displace behaviours that have obvious survival value Sleep may resensitize these REM off or sleep off transmitter systems, which are tonically active during waking, by increasing the quantities and activities of their synthetic enzymes, transporter mechanisms and receptors  Sleep studies in terrestrial mammals To evaluate theories of REM and NREM sleep function, one must consider how sleep amounts differ across species Sleep time is inversely correlated with body mass in herbivores Sleep time may be related to defence against oxidative stress, particularly in, but not limited to, herbivores Sleep-controlling brain regions in mammals Neurophysiological studies have provided considerable information about the mechanisms controlling sleep states Slow (high-voltage 1–4-Hz) waves and spindle (high-voltage 8–12 Hz) waves are not by themselves conclusive evidence for sleep as defined at the beginning of this review Small animals have high metabolic rates; large animals have low metabolic rates Small animals have shorter sleep cycles, and cycle times range from about 8 minutes in the short-tailed shrew ( Blarina brevicauda ) to 1.8 hours in the Asiatic elephant ( Elephas maximus )  Some animals, such as bats and opossums, sleep for 18–20 hours a day ( Fig. 2 ) Some smaller cetacean species are rarely, if ever, immobile Some such changes dissipate with continued waking , suggesting that localized recuperative processes may take place during either waking or sleep in systems projecting to, or within, the neocortex Studies of arousal threshold have not been performed on cetaceans across putative sleep–wake cycles Surprisingly, in humans, one can increase the amount of REM sleep and percentage of total sleep time devoted to this state simply by extending sleep time Surprisingly, when the fur seal moves onto land after spending weeks in the water, a change in its sleep structure occurs immediately The absence or very small amounts of REM sleep in marine mammals displaying unihemispheric sleep with brainstem-regulated motor activity supports the hypothesis that the stimulation of brainstem-activating systems is an important function of REM sleep The amount of slow waves after deprivation bore no consistent relation to the amount of slow-wave activity that had been lost  The amplitude of the changes in brain metabolism and neuronal activity that occurs during sleep exceeds those which occur during most waking periods  The argument that sleep serves a vital function is compelling The asynchronous activity of adjacent neocortical neurons in both REM sleep and waking changes to a rhythmic discharge, synchronized across large regions of the neocortex The bottlenose dolphin ( Tursiops truncatus ), when not floating or resting on the bottom, generally swims in a single direction (usually counterclockwise) even as the hemisphere with slow waves alternates The cellular activity changes underlying the changes in neocortical EEG include calcium fluxes into and hyperpolarization of neocortical and thalamic neurons that are synchronized in large populations, producing high-voltage brain waves  The cold-induced increase in REM sleep amount in the isolated brainstem , the increased REM sleep amount at the minimum of the circadian brain and body temperature cycles and the increase in the temperatures of brain regions during REM sleep are consistent with this brainstem-activation hypothesis The effects of localized temperature changes in brainstem and forebrain regions on sleep should not be confused with the effects of environmental temperature The elephant, which has the largest neocortex of any terrestrial mammal, has one of the smallest amounts of sleep The evidence suggests distinct roles for REM and NREM sleep The existence of sleep ‘rebound’ after deprivation demonstrates that sleep is not simply a period of reduced activity or alertness regulated by circadian or ultradian rhythms, a phenomenon that can be seen even in non-sleeping organisms  The extremely high levels of REM sleep seen at birth, followed by a slow decrease to adult levels seen in many terrestrial mammals, must be an important clue to its function The fact that sleep debt can be accumulated suggests that sleep serves important functions that require some portion of the missed sleep amount to be made up The ferret, likewise, is immature at birth, and the adult has over 6 hours of REM sleep per day The flipper contralateral to the hemisphere with slow waves is immobile, the flipper contralateral to the hemisphere with low-voltage activity paddles to maintain the animals position, and the whisker contralateral to the hemisphere with low-voltage activity is used to monitor the seals position in the water The guinea pig is born with teeth, claws, fur and open eyes; it thermoregulates at birth, locomotes within an hour of birth and eats solid food within a day of birth The identification of the ‘dream state’ as a periodic physiological process during sleep has encouraged the addition of physiological and psychological theories to the more mystical theories of the ancients The initial REM sleep period of the night may last only 5–10 minutes, whereas the last REM sleep period may last more than 25 minutes The intensity of REM sleep, as measured by the density of eye movements and twitches, the prevalence of erections in males and the vividness of dream reports also increases as the night progresses The latter cells, which contain noradrenaline, epinephrine, serotonin, histamine or hypocretin, are continuously active during waking The platypus has 8 hours of REM sleep per day as an adult and the neonate cannot thermoregulate, locomote, acquire food or defend itself at birth and lives attached to its mother The preoptic and anterior hypothalamic regions, within which most of these sleep-active neurons are embedded, have central roles in controlling the body and brains temperature  The proposed functions of REM sleep in adults are consistent with the lack of any easily detectable cognitive or physiological symptoms in humans in whom REM sleep has been suppressed for months or years by monoamine oxidase inhibitors or brain lesions  The reason for this robust correlation is not known The relative importance of each of these ‘sleep factors’, the pathways by which they interact with each other and the way in which they might act on sleep-triggering mechanisms remain to be more fully elucidated The signs of long-term sleep deprivation, including skin lesions, hyperthermia followed by hypothermia, increased food intake and death, that have been noted in the rat, the subject whose response has been most thoroughly investigated, do not occur in the rat or cat even with total, long-term decortication , consistent with the lack of a positive correlation between cortical size and sleep time noted above The suppression of sleep behaviour also allows the neonate to swim with and be protected by its mother during development The suppression of sleep behaviour seen in cetaceans after birth is analogous to a reduction in sleep that has been seen during the migration season in one bird species studied, the white crowned sparrow The third subclass of mammals is the monotremes, found in Australia and New Guinea The unique thermoregulatory challenges faced by cetaceans may also be a factor in the apparent absence of significant amounts of REM sleep in this order Their high ratio of surface area to body mass makes the energy conservation achieved by sleep highly adaptive Theories of NREM sleep function There is no shortage of theories to explain the functions of REM and NREM sleep Theories of REM sleep function REM sleep, the state in which our most vivid dreams occur, has inspired a multitude of functional theories There are several themes that can be seen in some of these theories and for which the data reviewed above provide support, and other theories that are inconsistent with these data There have been no published reports documenting REM sleep in cetaceans, making them the only studied mammals in which this state has not been observed There were no such changes in the neocortex  These activity patterns are linked to maximal metabolic activity during waking and REM sleep, and minimal metabolic activity during NREM sleep in both the neocortex and the brainstem  These and other neuronal groups maintain waking These animals may never exhibit the immobility that we use in terrestrial mammals to define the state of sleep  These cells are maximally active during NREM sleep, and when stimulated will induce this state These data can guide theories of sleep functions These data support theories that suggest that sleep saves energy, keeps species from being active at inopportune times and reverses waking-induced changes in brain function These egg-laying mammals have more genetic and physiological similarities to reptiles and birds than do other mammals and are thought to possess characteristics of the common mammalian ancestor  These neurons act through direct and indirect inhibitory projections to aminergic, cholinergic and hypocretinergic (also called orexinergic) neurons in the forebrain and brainstem These phenomena and the vivid dreams that humans report upon awakening from REM sleep have made the function of this state particularly mysterious and intriguing These systems are well known to be involved in emotional regulation, and most antidepressive medications act through effects on monoaminergic systems and suppress REM sleep These ‘REM sleep on’ cells cause a complete loss of muscle tone in the postural muscles during REM sleep by triggering simultaneous inhibition of and withdrawal of excitation to motoneurons They all have decreased activity during NREM sleep (this decrease is particularly marked for hypocretin cells, which may also be silent during quiet waking) and cease discharge during REM sleep  They also have a crucial role in the regulation of REM sleep itself They have been linked to sleep because they generally accompany the behavioural signs of sleep in terrestrial mammals They move and avoid obstacles 24 hours a day from birth until death, even during unihemispheric slow-wave activity This additional sleep time would obscure any underlying sleep requirement that is linked to metabolic rate This causes a summation of excitatory and inhibitory postsynaptic potentials, resulting in the high-voltage 2–12-Hz neocortical waves that are seen by electroencephalogram (EEG)  This contrasts with the raised arousal thresholds and increased amplitudes of low-frequency brain-wave activity shown in individual animals after sleep deprivation  This correlation is responsible for a significant overall correlation between body mass and sleep time in all mammals studied so far ; however, sleep time and body mass are not significantly correlated in carnivores or omnivores when they are evaluated separately ( Fig. 2 ) This finding indicates that the activity of the visual system known to occur in REM sleep normally compensates for any asymmetrical, abnormal or absent input, preventing processes that prune away unused connections during development This is not the case This is not the pattern in cetaceans This is quite different from the great reduction in brainstem reticular activity that characterizes NREM sleep in terrestrial mammals  This minimal amount of sleep behaviour occurs during the period of most rapid growth of the body and brain for the newborn, during a period of bonding to the mother and learning how to nurse, find food, avoid predators and swim efficiently This neurogenesis is facilitated by exercise and blocked by stress This reduction persisted into adulthood, long after normal visual input had been restored This region contains a subgroup of neurons that are maximally active during REM sleep This ROS generation has been linked to ageing, producing a wrinkled, arthritic, demented mouse by two years of age, whereas larger animals such as humans do not experience such effects of ageing until they are 70–80 years old This sleep reduction was accompanied by high levels of alertness and was not followed by sleep rebound This statistical procedure is confounded when used with highly correlated variables such as metabolic rate and body mass This suggests that, in the intact animal, brainstem mechanisms triggering REM sleep may be facilitated by brainstem cooling or correlated metabolic changes This tendency is marked in the neonatal period This time course, combined with the observation that neuronal activity levels are high during REM sleep, led to the hypothesis that this sleep state is involved in the development of the brain This would account for an inverse relationship between body mass and sleep time Three studies favour a role for REM sleep in the maintenance of central noradrenergic receptors, whereas one study questions this role Thus, sleep may have a general role in allowing or facilitating neurogenesis Thus, these ‘primitive’ mammals seem to have a form of REM sleep that is mainly localized to the brainstem Two groups of cells whose activity differs between waking and REM sleep are the REM on cells, discussed above, and the REM sleep off cells Unihemispheric slow waves largely disappear, and bilateral NREM and REM sleep are present, similar in amount and form to those of comparably sized land mammals Unlike the terrestrial environment, there are few warm, safe places to sleep in the ocean We also saw changes in the brainstem, hippocampus and hypothalamus as a whole  We and others have shown that sleep deprivation in the rat is accompanied by increased oxidative stress and evidence of membrane disruption in the hippocampus, subcortical brain regions and peripheral tissues  We have found that killer whales ( Orcinus orca ) and dolphins have minimal amounts of sleep behaviour (that is, immobility or eye closure) at birth, with sleep behaviour slowly increasing to adult levels over a period of months We have hypothesized that the continuous activity of cetaceans has adaptive value in allowing the neonate, which is much less insulated by body fat than the adult, to thermoregulate in cold ocean water We hypothesize that, all other things being equal, higher metabolic rates in the brain require longer periods of sleep to interrupt ROS-induced damage to brain cells, facilitate the synthesis and activities of molecules that protect brain cells from oxidative stress, allow sufficient time for the repair or replacement of essential cellular components in neurons and glia and deal with other biochemical consequences of waking metabolic activity When ambient temperature is outside the thermoneutral range, REM sleep is suppressed more strongly than is NREM sleep , suggesting that the preservation of NREM sleep is of higher priority than that of REM sleep When body size increases and sensory-motor systems mature, young animals derive greater benefits from waking activities, consistent with the developmental decrease in sleep time When in the water, fur seals show a pattern of unihemispheric slow waves similar to that of cetaceans When in the water, the fur seal has an extremely small amount of REM sleep, and may go without any REM sleep for a week or two When slow-wave activity shifts to the opposite side, so do the motor asymmetries When these neurons are activated, which can be accomplished by microinjecting acetylcholine agonists into specific regions of the pons, prolonged REM sleep periods are elicited  Why do we spend one-third of our lives asleep? Why has our body evolved to press us relentlessly to make up for lost sleep? Can we separate the drive for sleep, manifested in sleepiness, from the function of sleep, as we can separate hunger from the benefits of food consumption? Why do so many species habitually sleep much more than humans, and others much less, and how do species that sleep for only short periods accomplish the functions of sleep in less time? Why does the daily sleep amount decrease from birth to maturity in all species of terrestrial mammals? And why do we have two kinds of sleep, rapid eye movement (REM) and non-REM (NREM) sleep? Sleep can be defined as a state of immobility with greatly reduced responsiveness, which can be distinguished from coma or anaesthesia by its rapid reversibility Wiesel and Hubel discovered that reducing light input into one eye for a period of several days in neonates led to a reduction in the number of cells in the visual system receiving input from that eye
 Nature 433 , 57 – 59 ( 2005 ) The x axis of Fig. 1 of this Letter was mislabelled The correct tick labels (from left to right) should read: ‘Root-free soil 0–10 cm’; ‘Intact soil 0–10 cm’; ‘Root-free soil 20–30 cm’; and ‘Intact soil 20–30 cm’ These errors do not affect any of our conclusions.
 Alas, this is all to no avail As first stated in an editorial in 1997, and since then in our Guide to Authors , if scientists wish to display drafts of their research papers on an established preprint server before or during submission to Nature or any Nature journal, thats fine by us. At Nature , this rich treasure trove of essential information is lovingly cared for by staff But perhaps the most malignant rumours are those spread by scientists themselves — in all good faith but erroneously Communication between researchers includes not only conferences but also preprint servers Editors labour mightily over policy development, and craft their statements with all the precision of a Swiss watchmaker Nature , it is said, does not allow authors to distribute preprints of their work or place drafts of their papers on preprint servers, or even discuss their submitted work at conferences Nature never wishes to stand in the way of communication between researchers One such is about prepublication So please lets put a myth about this journal to rest Successive improvements in our presentation of research papers are reflected in changes to stylistic guidelines The ArXiv preprint server is the medium of choice for (mainly) physicists and astronomers who wish to share drafts of their papers with their colleagues, and with anyone else with sufficient time and knowledge to navigate it The surest way of hiding the truth about a journals policies, it seems, is to publish it in the Guide to Authors This is false Too often, authors submit papers that fail to conform to our guidelines; outraged readers wishing to complain about content fail to follow the procedures; and journalists spread false representations of our media policies We seek rather to add value for authors and the community at large in our peer review, selection and editing
 Although still relatively low, the average impact factor of Iranian papers has also risen And because most scientific equipment contains US components that are covered by sanctions, Iranians can only procure it through middle-men who disguise the equipments ultimate destination but inflate its price and leave recipients with no quality guarantees or maintenance arrangements But much of the improvement can be traced back to a small number of researchers But they are admirably determined to help build up a research infrastructure in the country that will outlast their own careers During this period, social and political constraints on Iranian life have visibly relaxed Even Ayatollah Ali Khamenei, the senior cleric effectively in charge of the country, has been speaking up for science, calling on his country to develop “self-confidence in all scientific fields” Headscarves on the streets of Tehran are now sometimes perched so far back that Velcro is needed to stop them falling off altogether In February, academics salaries were sharply increased: as a result, many of them will be able to make ends meet without a second job, for the first time since the Islamic revolution in 1979 Instead, the situation could rapidly deteriorate Internal support for scientific development and for the free exchange of ideas is far from assured It has also introduced reforms — approved this year, after a tough fight — that give universities and research institutes much more autonomy It is just as likely, however, that the elections will yield instead a president less interested in either reform or scientific freedom Moin could be relied on to continue along the reformist path set by Khatami One candidate for the presidency is immunologist Mostafa Moin, a former research minister who resigned from the government in 2003 in protest at parliamentary opposition to the university reform act Over the past few years, however, the country has been investing more public money in science, and nurturing the gradual emergence of a climate in which high-quality research can flourish Science has also benefited from this relaxation Scientists everywhere should avail themselves of every opportunity to assist these grassroots efforts. Scientists in Iran tell stories of waiting up to two years for an order, only to receive shipment of the wrong model Some of the most productive laboratories, such as the Institute for Studies in Theoretical Physics and Mathematics (IPM) in Tehran and the Institute for Advanced Studies in Basic Sciences (IASBS) in Zanjan, have taken the opportunity presented by the reform package to reorganize themselves Stories about people who prevail against the odds are always heart-warming, and the tale in this issue of Nature about a group of Iranian neuroscientists (see page 264 ) is no exception Such successes have been rare in Irans recent history That may prove difficult to accomplish, given the current isolation of Iranian scientists from their peers abroad The call resonates within a small academic community that is keenly aware of Irans rich and ancient heritage of scientific achievement The government, led by the elected president, Mohammad Khatami, has meanwhile increased science funding The IPM says it is basing its new structure on that of the Max Planck Society in Germany, in which the research directors of individual labs have full control over budgets and research agendas The Iranian scientists who have put together strong research groups have done so by carefully steering clear of politics The number of papers per researcher at the IASBS, for example, is nearly twice that of its closest competitor, the Sharif University of Technology in Tehran The president will be replaced after elections due on 17 June The publication rate of Iranian scientists in international journals, meanwhile, has quadrupled over the past decade The reforms set out to extend the base of scientific excellence in Iran Unfortunately, given current tensions over Irans nuclear programme (see Nature 435 , 132 ; 2005 ), the sanctions are unlikely to be lifted in the short term US economic sanctions make it difficult for them to travel to meetings in the United States
 Channel SPP modes—channel plasmon polaritons (CPPs) —are electromagnetic waves that are bound to and propagate along the bottom of V-shaped grooves milled in a metal film Here we report the design, fabrication and characterization of CPP-based subwavelength waveguide components operating at telecom wavelengths: Y-splitters, Mach–Zehnder interferometers and waveguide–ring resonators However, the simultaneous realization of strong confinement and a propagation loss sufficiently low for practical applications has long been out of reach Our previous experiments showed that CPPs do exist and that they propagate over tens of micrometres along straight subwavelength grooves  Photonic components are superior to electronic ones in terms of operational bandwidth, but the diffraction limit of light poses a significant challenge to the miniaturization and high-density integration of optical circuits The main approach to circumvent this problem is to exploit the hybrid nature of surface plasmon polaritons (SPPs), which are light waves coupled to free electron oscillations in a metal that can be laterally confined below the diffraction limit using subwavelength metal structures  They are expected to exhibit useful subwavelength confinement, relatively low propagation loss , single-mode operation and efficient transmission around sharp bends  We demonstrate that CPP guides can indeed be used for large-angle bending and splitting of radiation, thereby enabling the realization of ultracompact plasmonic components and paving the way for a new class of integrated optical circuits. A typical optical image obtained with the transmitted light power at maximum is shown in Fig. 3c , along with the corresponding input and output average cross-sections for two different wavelengths exhibiting a clear difference in the transmitted CPP power ( Fig. 3d ) An interesting feature observed in most optical images is the signal enhancement in a splitting region (white dot in Fig. 1c , f ) Anticipating (relatively) low loss for S-bends with small curvature radii because of the subwavelength CPP confinement , we have chosen the S-bend design that connects two 5-µm-offset waveguides over a distance of 5 µm (the smallest curvature radius is in this case ∼2.25 µm) As an example, we have chosen a waveguide–ring (WR) resonator, which is interesting owing to its wavelength response and non-trivial dependence on the coupling between straight and ring waveguides  As light tends to concentrate in regions with higher refractive indexes, sufficiently deep grooves should support bound symmetric SPP modes that are confined to the groove bottom, where their effective index is at maximum, and predominantly polarized parallel to the metal surface  At resonance ( θ + φ  = 2π m , m is integer), the transmitted power vanishes at the condition of critical coupling, αη = | t |, allowing for dramatic influence of the ring transmission α on the WR resonator transmission and other interesting effects  Finally, we note that SNOM images are presented here in such a way that the excited CPP propagates in a channel waveguide structure from left to right Following the far-field adjustment, the whole fibre–sample arrangement was moved under the SNOM head for near-field mapping of the CPP intensity distribution in the structure under investigation by the uncoated sharp fibre tip of the SNOM For subwavelength slit widths, the mode field in the slit is nearly constant and close to its maximum, thereby rendering the propagation losses relatively low  Here, we have demonstrated a WR resonator with an insertion loss of 3 dB and a footprint of only 200 µm 2 (∼100  λ 2 ) that can be used for wavelength filtering with a bandwidth of ∼40 nm However, it is not clear to what extent it influences the signal measured in the middle of a groove with the SNOM fibre tip being actually below the sample surface by ∼40–100 nm, depending on the groove and tip shapes In general, such a choice is subject to a trade-off between the propagation loss and the bend loss, as the former decreases and the latter increases for shorter bends In order to understand the underlying physics of CPP propagation, we first consider SPP modes that are guided inside narrow slits between two metal surfaces, so that the SPPs associated with individual metal surfaces become coupled In the design of WR resonator, we used a 5-µm-radius ring and the same S-bend as in the first set of structures ( Fig. 3a ) In the present work, various waveguide structures consisting of V-grooves with the angles close to 25° and depths of 1.1–1.3 µm have been fabricated (using focused ion-beam milling) in a 1.8-µm-thick gold layer deposited on a substrate of fused silica In the splitting region, the groove width is nearly doubled, causing the CPP guiding to approach cut-off, the effective centre of CPP mode field to move upwards (out of the groove) and, thereby, the detected optical signal to increase It is important to note that the CPP guiding in V-grooves is counterintuitive: while a certain groove depth (for a given groove angle) is required to support a CPP mode, the CPP guiding approaches cut-off and the CPP mode field stretches farther out of the groove when the groove angle increases It is seen that the optical signal outside the grooves amounts to ∼15% of the maximum signal associated with the CPP mode at the input regions It is seen that the transmission is periodic with respect to the phase θ accumulated by the CPP mode per circulation, implying the possibility of wavelength filtering It should be stressed that, in contrast to the CPP-based structures, the degree of light confinement in dielectric waveguides, including those based on the photonic bandgap effect, is fundamentally limited by the light wavelength in the dielectric used Lateral cross-sections of the SNOM images obtained in the course of this investigation showed the average full-width at half-maximum (FWHM) of the CPP mode to be between 0.8 and 1 µm, being almost independent of the wavelength for a given groove—that is, values that are even slightly smaller than those obtained previously  Note that the achieved maximum-to-minimum transmission ratio is quite large (on average, 3) allowing for wavelength filtering with a bandwidth of ∼40 nm Note that, on the other hand, the choice of the groove angle is subject to trade-off, as better CPP confinement achieved with narrower grooves would ensure smaller bend losses, causing at the same time larger propagation losses  Our investigations have also revealed that these structures exhibit rather high tolerance to topological imperfections on the nanometre scale, that is, there seems to be little perturbation due to accidental presence of nanoparticles (for example, one particle sitting in the lower arm of MZ interferometer is clearly seen in Fig. 1d ) Our main interest was in verifying the possibility of realization of a plasmonic WR resonator and achieving thereby the wavelength dependent transmission of CPPs Our previous study on CPP guiding allowed us to identify the range of groove parameters for low-loss and well-confined (below the light wavelength) single-mode CPP guiding at telecom wavelengths as well as the corresponding fabrication conditions Our SNOM investigations showed that all fabricated structures (S-bends, Y-splitters and MZ interferometers) performed well over the whole range of laser tunability, exhibiting single-mode and subwavelength guiding with overall losses of a few dB, demonstrating thereby robustness to small variations in structural parameters Quantitative evaluation of the insertion loss was made by considering average cross-sections before and after the component in question, that is, Y-splitters or MZ interferometers ( Fig. 2 ) Similar cross-sections were used in order to evaluate the normalized output, that is, transmission, for the investigated WR resonators as a function of the light wavelength Similar values were found for the Y-splitter and MZ-interferometer transmissions at other wavelengths exhibiting (unsystematic) variations within 20% that can probably be attributed to different background levels (determined by positioning of the in-coupling fibre with respect to the input groove) The data obtained for both structures were fitted with the dependence calculated according to equation (1) , demonstrating quite good agreement ( Fig. 4 ) The design of S-bends was based on sine curves, allowing for continuous curvature throughout the bend  The dispersion equation is well known and its solution can be easily obtained, even when the metal dielectric function is complex The fabricated groove structure was 1.3-µm deep with a groove angle of ∼25° The fabricated plasmonic structures were characterized with a collection scanning near-field optical microscope (SNOM) having an uncoated fibre tip used as a probe and an arrangement for end-fire coupling of tunable (wavelength λ = 1,425–1,620 nm) TE-polarized (the electric field is parallel to the sample surface plane) radiation into a groove by positioning a tapered-lensed polarization-maintaining single-mode fibre  The fact that the investigated Y-splitter showed next to zero insertion loss is remarkable, considering the fact that the smallest curvature radius used was only ∼1.5 λ  The first set of structures to be investigated included straight reference guides, S-bends (that is, curved bends connecting two parallel waveguides offset with respect to each other), Y-splitters composed of two mirrored S-bends, and Mach–Zehnder (MZ) interferometers composed of two consecutive Y-splitters The fitted values were found to be η ≈ 0.78, t ≈ 0.33 and R ≈ 5.13 µm, which are consistent with the previous experiments (for example, the overall coupling efficiency η is relatively high, implying low radiation loss, similar to that seen above with Y-splitters and MZ interferometers) The intention with using an S-bend after the coupling region and laterally displacing the output channel was to decrease the influence of radiation scattered in the coupling region on the signal detected in the output channel The low loss level observed is a direct (though not straightforward) consequence of the subwavelength CPP field confinement, as discussed earlier  The main feature in this context is that, with the decrease of the slit width, the effective refractive index of a symmetric SPP combination increases (while the propagation length decreases), starting from the value corresponding to the individual SPP  The main system parameters are transmission and coupling coefficients, t and κ , and transmission around the ring, α exp( iθ ) (inset in Fig. 3a ) The near-field optical images ( Fig. 1c , f ) demonstrate very efficient and well-confined CPP guiding throughout the structures consisting of splitters and bends characterized by an average bend angle of 45° The performance of the considered structures could be further improved by perfecting the quality of fabricated grooves (especially walls and junctions) and optimizing geometrical parameters with respect to the above-mentioned trade-off The results obtained with the above set of structures encouraged us to further exploit the potential of CPPs and to realize a functional plasmonic component The tip was scanned along the sample surface at a constant distance of a few nanometres maintained by shear force feedback, and the radiation collected by the fibre was detected with a femtowatt InGaAs photoreceiver The track of the propagating radiation was clearly distinguishable for all structures and over the whole range of laser tunability The transmission through a WR resonator under the condition that a single unidirectional mode of the ring resonator is excited is given by T = α 2 η 2 + | t | 2 - 2 αη | t | cos ( θ + φ ) 1 + α 2 | t | 2 - 2 α | t | cos ( θ + φ ) , t = | t | exp ( iφ ), | t | 2 + | κ | 2 = η ,  θ = 2π λ N eff 2π R (1) where η is the overall coupling efficiency, which is influenced by the radiation (power) loss at the coupling region, R is the ring radius, N eff is the CPP effective index, and λ is the light wavelength in air These cross-sections were obtained with the optical images shown in Fig. 1 by averaging within ∼3-µm-long windows placed in straight groove regions This background signal becomes the main contribution in the optical images recorded in constant plane mode at the height of ∼200 nm above the sample surface  This demonstrates the potential of using similar groove structures in sophisticated plasmonic circuits, as well as the practical feasibility of their fabrication with sufficiently high quality Typical SNOM images of a Y-splitter and an MZ interferometer, along with the corresponding scanning electron microscope (SEM) images, are displayed in Fig. 1  We believe that the two main contributions to this effect are the out-of-plane scattering resulting in propagating field components (whose detection efficiency is larger than that of evanescent waves, such as CPPs) and the above-mentioned counterintuitive feature of CPP guiding We briefly review the main features of CPP propagation along grooves cut into planar metal surfaces  We can envisage further development of this concept for miniature bio-sensors and for ultracompact plasmonic interconnects that can be naturally integrated with electrical circuits in a way similar to that recently demonstrated with long-range SPPs . We have already noticed during the far-field adjustment that, contrary to the previously investigated structures, the transmitted power depended on the wavelength of light used We now consider a straight groove cut into metal and having a cross-section whose width is monotonously decreasing with depth, for example, a V-shaped groove We then recorded SNOM images for different wavelengths in the laser tunability range for two nominally identical WR resonators When fitting, we used the CPP parameters as previously calculated ( N eff = 1.015, α = 0.77, obtained from the calculated CPP propagation length and ring circumference, neglecting the bend loss), assumed the transmission coefficient to be real, that is, φ  = 0, and allowed for small variations in the ring radius R  With this in mind, one obtains for the transmission T of the Y-splitter and MZ interferometer the following ranges: 0.82 T Y 1 and 0.4 T MZ 0.49, respectively, using the output-to-input ratios of maxima of the corresponding signal distributions ( Fig. 2 )
 Each vertex represents an individual Evolutionary dynamics have been traditionally studied in the context of homogeneous or spatially extended populations  Evolutionary graph theory has many fascinating applications ranging from ecology to multi-cellular organization and economics. Furthermore, some graphs act as suppressors and others as amplifiers of selection Here we generalize population structure by arranging individuals on a graph It is even possible to find graphs that guarantee the fixation of any advantageous mutant Spatial structures are described by graphs where vertices are connected with their nearest neighbours The homogeneous population, described by the Moran process , is the special case of a fully connected graph with evenly weighted edges The weighted edges denote reproductive rates which govern how often individuals place offspring into adjacent vertices We also explore evolution on random and scale-free networks  We also study frequency-dependent selection and show that the outcome of evolutionary games can depend entirely on the structure of the underlying graph We determine the fixation probability of mutants, and characterize those graphs for which fixation behaviour is identical to that of a homogeneous population  A one-rooted graph has a unique global source without incoming edges A selection amplifier, like a star structure or a scale-free network, will enhance the spread of favourable ideas arising from any one individual A vertex is ‘hot’ if it is replaced often and ‘cold’ if it is replaced rarely All the peripheral vertices are connected only with the centre An evolutionary graph has fixation probability ρ  1 if and only if it is a circulation (see Fig. 2e ) Another application is somatic evolution within multicellular organisms As an illustration, imagine N players arranged on a directed cycle ( Fig. 5 ) with player i placing its offspring into i + 1 At each time step an individual is chosen for reproduction with a probability proportional to its fitness But the celebrated results of Maruyama and Slatkin indicate that spatial structures are irrelevant for evolution under constant selection Circulations no longer behave identically with respect to games Consider a homogeneous population of size N  Consider, as before, two types A and B , but instead of having constant fitness, their relative fitness depends on the outcome of a game with payoff matrix: A B A B a b c d In traditional evolutionary game dynamics, a mutant strategy A can invade a resident B if b d  Each individual places its offspring into the position immediately to its right Ecological habitats of species are neither regular spatial lattices nor simple two-dimensional surfaces, as is usually assumed , but contain locations that differ in their connectivity Evolutionary dynamics act on populations Evolutionary graph theory has many fascinating applications Evolutionary graph theory offers an appropriate tool to study selection on such networks Figure 2d gives an example of an isothermal graph where W is not symmetric For a super-star with large K , this r value diverges as long as b c  For all such lattices ρ  remains unchanged: it is equal to the ρ  1 obtained for the homogeneous population For constant selection, graphs can dramatically affect the balance between drift and selection For example, a stem cell in the centre generates differentiated cells, whose offspring either differentiate further, or revert back to stem cells For example, the hematopoietic system constitutes an evolutionary graph with a suppressive hierarchical organization; stem cells produce precursors which generate differentiated cells  For frequency-dependent selection, graphs can redirect the process of selection itself For games on graphs, the crucial condition for A invading B , and hence the very notion of evolutionary stability, can be quite different For instance, in the positive symmetric orientation, the fixation probability for large N of a single A mutant is given by equation (1) with r = ( b / d )( b / c ) K -1  For large N , the fixation probability of a randomly placed mutant on the star is ρ  2 = (1 - 1/ r 2 )/(1 - 1/ r 2 N ) Further generalizations of evolutionary graphs are possible Furthermore, we can prove that the general question of whether a population on a graph is vulnerable to invasion under frequency-dependent selection is NP (nondeterministic polynomial time)-hard Hence, these population structures guarantee fixation of advantageous mutants however small their selective advantage Here the results have a particularly elegant form Here we introduce evolutionary graph theory, which suggests a promising new lead in the effort to provide a general account of how population structure affects evolutionary dynamics Human organizations have complicated network structures  If a company is strictly one-rooted, then only those ideas that originate from the root will prevail (the CEO) If a graph has more than one root, then the probability of fixation is always zero: a mutant originating in one of the roots will generate a lineage which will never die out, but also never fixate ( Fig. 2i ) If a graph is not isothermal, the fixation probability is not given by ρ  1  If both these conditions hold then the graph is called a circulation, and the structure favours neither selection nor drift If the sum of the weights of all edges entering a vertex is the same for all vertices—meaning the mortality is independent of position—then the graph never suppresses drift If w ij = 0 and w ji = 0 then the vertices i and j are not connected Imagine that the individuals are arranged on a spatial lattice that can be triangular, square, hexagonal or any similar tiling In each iteration, an individual i is chosen for reproduction with a probability proportional to its fitness In fact, it can be shown that if W is symmetric, w ij = w ji , then the fixation probability is always ρ  1  In general, we can prove that for sufficiently large population size N , a super-star of parameter K satisfies: ρ  K = 1 - 1/ r K 1 - 1/ r KN (2) Numerical simulations illustrating equation (2) are shown in Fig. 4a  In small populations, random drift dominates, whereas large populations are sensitive to subtle differences in selective values In the absence of upstream populations, if the sum of the weights of all edges leaving the vertex is the same for all vertices—meaning the fertility is independent of position—then the graph never suppresses selection In the classical Prisoners Dilemma, these dynamics favour unconditional cooperators invading defectors. (3) Positive anti-symmetric: mutants at i interact with i - 1, but residents with i + 1 In the simplest case, the payoff of any individual comes from an interaction with one of its neighbours In this case, the matrix W need not be stochastic; the weights can be any collection of non-negative real numbers In this respect, our results for scale-free graphs are very suggestive In this so-called Moran process ( Fig. 1a ), the population size remains constant Individuals are labelled i = 1, 2, … N  Instead, the balance between selection and drift tilts; now to one side, now to the other Is it possible to suppress drift and amplify selection? Can we find structures where the fixation probability of advantageous mutants exceeds ρ  1 ? The star structure ( Fig. 3a ) consists of a centre that is connected with each vertex on the periphery Isothermality is equivalent to the requirement that W is doubly stochastic, which means that each row and each column sums to one It is striking that the notion of a circulation, so common in deterministic contexts such as the study of flows, arises naturally in this stochastic evolutionary setting Just as one-rooted structures entirely suppress the effects of selection, super-star structures function as arbitrarily strong amplifiers of selection and suppressors of random drift Let T i = Σ j w ji be the temperature of vertex i  Let us now turn to evolutionary games on graphs  Many more questions lie ahead More generally, an evolutionary graph has fixation probability 1/ N for all r if and only if it is one-rooted ( Fig. 2f , g ) Neither genes, nor cells, nor individuals evolve; only populations evolve Notably, scientific collaboration graphs tend to be scale-free  Note that W is a stochastic matrix, which means that all its rows sum to one Outcomes depend on the graph, the game and the orientation Remarkably, games on directed cycles yield the complete range of pairwise conditions in determining whether selection favours the mutant or the resident Scale-free networks, like the amplifier structures in Fig. 3 , have most of their connectivity clustered in a few vertices Selection favours the mutant if a d  Selection favours the mutant if b c . (2) Negative symmetric: i interacts with i - 1 Similar results hold for the funnel and metafunnel Similar results hold for the super-star in other orientations Small upstream populations feeding into large downstream populations are also suppressors of selection ( Fig. 2h ) Source and sink populations have the effect of suppressing selection, like one-rooted graphs  Star structures can also be instantiated by populations of differentiating cells Such amplifiers of selection could be used in various developmental processes and also in the affinity maturation of the immune response Such networks are potent selection amplifiers for mildly advantageous mutants ( r close to 1), and relax to ρ  1 for very advantageous mutants ( r ≫1) ( Fig. 4b ) Suppose all the resident individuals are identical and one new mutant is introduced Suppose in each iteration an edge ij is chosen with a probability proportional to the product of its weight, w ij , and the fitness of the individual i at its tail Suppose N individuals are arranged in a linear array The balance tilts towards selection, and against drift The circulation criterion completely classifies all graph structures whose fixation behaviour is identical to that of the homogeneous population, and includes the subset of isothermal graphs (the mathematical details of these results are discussed in the Supplementary Information ) The fixation probability is given by equation (1) with r = b / c  The fixation probability of the new mutant is: ρ  1 = 1 - 1/ r 1 - 1/ r N (1) This represents a specific balance between selection and drift: advantageous mutations have a certain chance—but no guarantee—of fixation, whereas disadvantageous mutants are likely—but again, no guarantee—to become extinct The graphs in Fig. 2a–c , and all other symmetric, spatially extended models, have the same fixation probability as a homogeneous population  The guaranteed fixation of this broad class of dominated strategies is a unique feature of evolutionary game theory on graphs: without structure, all dominated strategies die out The higher the correlation between the mutants fitness and its probability of fixation, ρ , the stronger the effect of natural selection; if fixation is largely independent of fitness, drift dominates The leftmost individual is never replaced The matrix W = [ w ij ] determines the structure of the graph ( Fig. 1b ) The mutant can only reach fixation if it arises in the leftmost position, which happens with probability 1/ N  The mutant is favoured if a c , behaving like a resident in the classical setting. (4) Negative anti-symmetric: Mutants at i interact with i + 1, but residents with i - 1 The mutant is favoured if b d , recovering the traditional invasion criterion The new mutant has relative fitness r , as compared to the residents, whose fitness is 1 The offspring replaces a randomly chosen individual The probability that individual i places its offspring into position j is given by w ij  The resulting offspring will occupy vertex j with probability w ij  The star acts as evolutionary amplifier, favouring advantageous mutants and inhibiting disadvantageous mutants The super-star possesses powerful amplifying properties in the case of games as well The super-star, funnel and metafunnel ( Fig. 3 ) have the amazing property that for large N , the fixation probability of any advantageous mutant converges to one, while the fixation probability of any disadvantageous mutant converges to zero The tension between selection and drift lies at the heart of the famous dispute between Fisher and Wright  The vast array of cases constitutes a rich field for future study The ‘isothermal theorem’ states that an evolutionary graph has fixation probability ρ  1 if and only if all vertices have the same temperature There are four natural orientations There is an even wider class of graphs whose fixation probability is ρ  1  There is evidence that population structure affects the interplay of these forces  This array is an example of a simple population structure whose behaviour is dominated by random drift Thus the individuals can be thought of as occupying the vertices of a graph Thus, any selective difference r is amplified to r 2  Thus, even a dominated strategy ( a c and b d ) satisfying b c will expand from a single mutant to conquer the entire super-star with a probability that can be made arbitrarily close to 1 Thus, it is easy to construct graphs that foster drift and suppress selection We can ask, for example, which networks are well suited to ensure the spread of favourable concepts We discuss the fixation probability of a single A mutant for large N . (1) Positive symmetric: i interacts with i + 1 We expect tissues of long-lived multicellular organisms to be organized so as to suppress the somatic evolution that leads to cancer We have sketched the very beginnings of evolutionary graph theory by studying the fixation probability of newly arising mutants We introduce population structure as follows We study the simplest possible question: what is the probability that a newly introduced mutant generates a lineage that takes over the whole population? This fixation probability determines the rate of evolution, which is the product of population size, mutation rate and fixation probability We want to calculate the fixation probability ρ  of a randomly placed mutant We will show that some graphs are governed entirely by random drift, whereas others are immune to drift and are guided exclusively by natural selection What is the fixation probability of a randomly placed mutant with fitness r ? Clearly, it is 1/ N , irrespective of r  What is the maximum mutation rate compatible with adaptation on graphs? How does sexual reproduction affect evolution on graphs? What are the timescales associated with fixation, and how do they lead to coexistence in ecological settings ? Furthermore, how does the graph itself change as a consequence of evolutionary dynamics ? Coupled with the present work, such studies will make increasingly clear the extent to which population structure affects the dynamics of evolution.
 The enzyme is found to be torque-sensitive, as the mean number of supercoils per step increases with the torque stored in the DNA The number of supercoils removed per step follows an exponential distribution They are vital for cell proliferation and are a target for poisoning by anti-cancer drugs  Topoisomerases relieve the torsional strain in DNA that is built up during replication and transcription Type IB topoisomerase (TopIB) forms a protein clamp around the DNA duplex and creates a transient nick that permits removal of supercoils Unlike a nicking enzyme, TopIB does not release all the supercoils at once, but it typically does so in multiple steps Using real-time single-molecule observation, we show that TopIB releases supercoils by a swivel mechanism that involves friction between the rotating DNA and the enzyme cavity: that is, the DNA does not freely rotate We propose a model for topoisomerization in which the torque drives the DNA rotation over a rugged periodic energy landscape in which the topoisomerase has a small but quantifiable probability to religate the DNA once per turn. A custom-made flow cell was used, consisting of two rectangular glass microscope cover slides separated by a single layer of parafilm Changes in DNA extension were analysed by making use of a sliding averaging window in which steps were accepted that were larger than three standard deviations of the Brownian noise of the bead  Data analysis For the step-size measurements, data traces were low-pass filtered at 2 Hz and averaged for 2 s, depending on force DNA constructs Step-size measurements were performed with bacteriophage λ DNA molecules (48 kilobases (kb) or 16 µm contour length) that were coated at one extremity with multiple biotin groups and at the other with multiple digoxigenin groups Human TopIB (100 kDa fragment) was purchased from Topogen  In all molecules, the consensus sequence for vaccinia TopIB cleavage (5′-CCCTT↓, where ↓ denotes the cleavage site) appears frequently (63 times for the full-length λ DNA molecule) Magnetic tweezers/flow cell The detailed experimental configuration of the magnetic tweezers, three-dimensional bead tracking, and force measurements have been described previously  Methods Enzymes and buffers Wild-type and mutant vaccinia TopIB proteins were purified as described previously  Nicking enzymes N.BbvCIA , N.BbvCIB and N.BstNBI were purchased from New England Biolabs  The bead velocity measurements were analysed from raw data obtained at 60 Hz The corresponding likelihood function L is thus given by: L = ∏  i = 1 N  ( N i 〈Δ Lk 〉) -1 exp(- Δ Lk i /〈Δ Lk 〉) The DNA molecules were incubated with streptavidin-functionalized magnetic beads (1 µm diameter , Dynal ) and introduced to the flow cell The lower slide was coated with polystyrene and anti-digoxygenin The rotation rate and the Δ Lk distribution measurements at 0.2 pN were performed on half-length bacteriophage λ DNA molecules The rotation rate measurements were performed in identical buffer except that 2 mM MgCl 2 was used The step-size distributions were measured in buffer containing 10 mM Tris-HCl pH 8.0, 50 mM NaCl, 10 mM MgCl 2 , 1 mM dithiotheitol, 0.1% Tween-20 and 200 µg ml -1 BSA The steps can be identified as arising from a single topoisomerase enzyme because the time it takes for the enzyme to remove supercoils is much smaller than the time between successive relaxation events The three nicking enzymes gave identical results, both in the step-size and the rotation rate measurements Therefore, the final step leading to the complete removal of plectonemes from the DNA is discarded This modified maximum-likelihood method is especially useful at higher stretching forces, where failure to apply the method underestimates 〈Δ Lk 〉 by approximately 25%. This surface was subsequently passivated with BSA To correct for the ensuing overrepresentation of small steps, one takes into account that each measured step Δ Lk i is not drawn from the entire Δ Lk distribution but rather from the probability distribution P i (Δ Lk ) = ( N i 〈Δ Lk 〉) -1 exp(- Δ Lk i /〈Δ Lk 〉), where N i is given by N i = exp(- Δ Lk noise /〈Δ Lk 〉) - exp(Δ Lk constrained, i /〈Δ Lk 〉), Δ Lk noise is the smallest observable step given the bead noise, and Δ Lk constrained, i is the remaining number of supercoils in the DNA molecule before the i th step TopIB concentrations were between 0.5 and 20 nM Treatment of step-size distributions Values for 〈Δ Lk 〉 were obtained using a modified maximum-likelihood method that takes into account the experimental bead noise and the fact that one cannot observe steps of Δ Lk n , where n is the number of supercoils in the DNA before cleavage We measure F with 5% accuracy by continuously determining the three-dimensional bead position with 10 nm accuracy  Accordingly, human TopIB presumably offers less freedom for the DNA to rotate than vaccinia TopIB Accordingly, we do not favour such a force-dependent mechanism. After nicking of the DNA by transesterification of vaccinia TopIB to the DNA 3′-phosphate end, the DNA rotates inside the enzyme cavity and its 5′-OH end passes the tyrosine-3′-DNA adduct once every turn An alternative model could consider the stretching force F applied to the DNA, rather than torque, as the parameter governing the religation probability As a function of torque, and thus force, we deduce that or, 〈Δ Lk ( F )〉 = 〈Δ Lk 〉  F = 0 e δθ 2 ξF / k B T (2) Equation (2) provides a good fit of the data for 〈Δ Lk 〉 versus force (red line in Fig. 2c ) At each pass, there is a finite probability p for vaccinia TopIB to religate the DNA and a probability q ≡ 1 - p that the enzyme does not religate the DNA At higher stretching forces, the functional forms of the distributions are unchanged, but the corresponding values for 〈Δ Lk 〉 increase significantly ( Fig. 2c , solid circles) At this position in the energy landscape, there is a possibility of establishing a covalent bond, with rate k r  Because a strand-passage mechanism implies that 〈Δ Lk 〉 is independent of the stretching force , we conclude that our data are inconsistent with such a model Bulk measurements previously performed on plasmids containing 15 ± 2 supercoils yielded an average number of supercoils removed per cleavage–religation cycle of 5 ± 1.5 (ref. 11 ) Cleavage occurs via a transesterification reaction in which the scissile phosphodiester is attacked by a tyrosine of the enzyme, resulting in the formation of a DNA–(3′-phosphotyrosyl)–enzyme intermediate and the expulsion of a 5′-OH DNA strand Control experiments with two different vaccinia TopIB mutants and with human TopIB provide further evidence that the decreased rotation rate in the TopIB reaction is caused by friction between the topoisomerase and the rotating DNA Each step signifies the removal of DNA supercoils during a single cleavage–religation cycle by a single TopIB enzyme Extending these measurements to human TopIB (dark red triangles), we find that the DNA rotation rate is lower than for wild-type vaccinia TopIB Figure 1d plots the DNA extension as a function of force and torque First, the rotation of the DNA inside the enzyme clamp is not free but is hindered by friction, as indicated by our velocity measurements First, we excluded the possibility that multiple topoisomerases bound to the DNA at sites other than the cleavage site were interacting with each other in a manner that caused a decreased rotation rate Fitting such a force-dependent model to our data yields the very large value of 20 Å for the force-sensitive step δx  However, earlier work showed that although vaccinia TopIB can religate 5′-OH DNA across a one-nucleotide gap (a distance roughly 3 Å larger than a nick), the religation rate for this reaction is already decreased by a factor of 200 in comparison to the religation rate across a nick Human TopIB encircles the DNA duplex fully , but vaccinia TopIB has the form of a C-shaped clamp  In a typical measurement, the DNA molecule is prepared in a positively supercoiled state ( σ  0), which corresponds to a short extension In accordance with this, the probability distribution for observing steps of size Δ Lk is given by the discrete probability function of the geometric distribution (Δ Lk = 1,2,…): P (Δ Lk ) = pq Δ Lk -1 = p (1 - p ) Δ Lk -1 , where 〈Δ Lk 〉 ≡ 1/ p  In addition, the low initial number of supercoils applied in the plasmid (roughly an order of magnitude lower than in our measurements) may have restricted the observation of large numbers of supercoils removed per cleavage–religation cycle In contrast to vaccinia TopIB, a control measurement of P (Δ Lk ) for a nicking enzyme shows a peak that coincides with the number of supercoils initially applied to the DNA molecule ( Fig. 2b , inset) In such a model, the enzyme would have to perform work over a distance δx against F to religate the DNA In the rejoining step, the DNA 5′-OH group attacks the covalent intermediate, resulting in expulsion of the active-site tyrosine and restoration of the DNA phosphodiester backbone In vivo , TopIB removes positive supercoils generated in advance of the replication fork  It is modelled by tilting the entire energy landscape by - Γ  c θ  It thus seems unrealistic that any religation events would be observed with a separation of 20 Å On the basis of structural and kinetic data, a mechanism has been proposed for TopIB, whereby supercoils are relaxed by swivelling of the DNA about the phosphodiester opposite the nick ( Fig. 1a–c ) Our experimental strategy entails anchoring a single, continuous linear double-stranded (ds)DNA molecule between a glass surface and a paramagnetic bead Our model has three ingredients Our results are, however, fully consistent with a swivel mechanism Owing to the loss of this amino-acid side chain lining the protein–DNA interface, we observe an increase in the DNA rotation rate (beige circles) compared with wild-type vaccinia TopIB Second, the mechanically applied constant torque Γ  c drives the uncoiling Second, we measured the effect of the vaccinia Y70A mutation on the DNA rotation rate The clamp-like structure of human TopIB around the DNA duplex suggests that the DNA cannot swivel unhindered, and consequently a ‘controlled rotation’ model has been proposed  The continuum limit of this distribution is equation (1)  The data in Fig. 3b clearly show that vaccinia TopIB (red diamonds) slows down the DNA rotation rate compared to the unhindered rate observed for the nicking enzymes (blue triangles) The distribution of Δ Lk , P (Δ Lk ), has a mean far greater than unity ( Fig. 2b ) and is well fitted by an exponential (red line in Fig. 2b ): P (Δ Lk ) ≈ exp(- Δ Lk /〈Δ Lk 〉) (1) where 〈Δ Lk 〉 refers to the mean change in linking number The DNA rotation is not smoothly continuous, but the free energy profile and accordingly the rotation rate vary during a single rotation The exponential functional form of P (Δ Lk ) for vaccinia TopIB can be understood by considering the DNA as it rotates during supercoil release The force-dependence of Γ  c is given by , where ξ is the bending persistence length of a dsDNA molecule ( ξ = 53 ± 2 nm) The functional forms of the distributions are also found to be insensitive to the sign of the supercoiling (data not shown) The height of the bead from the surface is equal to the extension of the DNA molecule The rate k across each of the barriers with height Δ G in this landscape follows an Arrhenius relation, k ≈ exp(- Δ G / k B T ), where k B is the Boltzmann constant and T the temperature in Kelvin The rate k ′ in the presence of a torque Γ  c thus becomes: k ′ ≈ exp(- Δ G ′/ k B T ) = exp(- (Δ G - Γ  c δθ )/ k B T ) The religation probability per turn p is thus given by p = T res k r = k r / k ′, where T res ≡ 1/ k ′ is defined as the residence time in the well at the religation location The rotation rate observed in the mixed reaction was indistinguishable from the rate observed with the nicking enzyme only The swivel mechanism of TopIB action is in stark contrast to the protein-assisted strand-passage mechanism of type IA and type II topoisomerases, in which there is an obligate step-size of 1 or 2 supercoils removed per cleavage–religation cycle, respectively  The velocity value is a measure of the rate at which the DNA swivels in the topoisomerase cavity as the supercoils are released These data provide what is, to our knowledge, the first direct measurement of friction in the TopIB relaxation mechanism These numerical values might be specific to the removal of positive (rather than negative) supercoils Third, within each 2π rotation of the DNA inside the topoisomerase cavity, there is only one position with a significant probability to religate the DNA This could have biased the average number of supercoils released in bulk towards lower values This decreases Δ G by an amount Γ  c δθ , where δθ is the angle from the well to the transition state This is modelled by a random walk over a rugged free-energy landscape ( Fig. 4 ), with the rotation angle θ between the 5′-OH end of the noncovalently held strand and the tyrosine-3′–DNA adduct as the reaction coordinate  DNA–3′-phosphotyrosine adduct before a religation can occur This value was indirectly obtained using ensemble-averaged rate constants, whereas our experiment directly measures the number of removed supercoils This variability in rotation speed could stem from the notion that the cross-sectional size of the DNA at the nick changes dramatically, from 2 nm at θ = 0 to about 4 nm at θ = 180° This was accomplished by a mixing experiment in which the nicking enzyme was reacted with the DNA in the presence of the vaccinia TopIB active-site mutant Y274F (green squares), which binds DNA noncovalently but is incapable of transesterification  Type IB topoisomerases alter DNA topology by cleaving and rejoining one strand of the DNA duplex , and are able to remove both positive and negative supercoils Tyr 70 is located on the concave surface of the amino-terminal domain of vaccinia TopIB, which clamps over the DNA duplex in the major groove on the helical face opposite the scissile phosphodiester  Unlike vaccinia TopIB, the nicking enzyme does not possess the ability to religate DNA and therefore all supercoils are released at once Using the rotation curve ( Fig. 1d ), we convert the changes in DNA extension to a number of rotations removed from the DNA, which equals the change in the linking number Δ Lk  We are able to resolve in real-time the velocity of DNA extension during supercoil removal We conclude that our model provides a good description of the single-molecule data at positive supercoils We find that by increasing the stretching force from 0.2 pN to 3 pN, the probability of religation per turn decreases from 3% to 0.7% ( Fig. 2c , inset) We make no assumptions about the exact shape of the energy landscape We measure this both for vaccinia TopIB and for endonucleolytic cleavage of one strand by nicking enzymes ( Fig. 3 ) We obtain an estimate for δθ of 0.23 ± 0.02 radians (13°) and an estimate for Δ Lk F = 0 of 19.3 ± 2.3 supercoils per cycle We propose a model that describes the effect of friction and torque on enzymatic activity We use a pair of magnets to apply a stretching force F and a degree of supercoiling σ  by translating a pair of magnets in the vertical direction or rotating them about their axis, respectively  When vaccinia TopIB, a prototypical eukaryotic type IB topoisomerase, is added, we observe discrete, step-wise increases in the extension ( Fig. 2a ) Within the experimentally accessible regime at negative supercoiling (see Fig. 1d ), the values of 〈Δ Lk 〉 for negative supercoils ( Fig. 2c , open circles) are similar to those measured for positive supercoils
 And it means that it can be processed, at some cost and effort, into hydrocarbon fuel of the sort that todays cars, trucks and planes can handle with relatively little modification But plants have advantages that, in some circumstances, outweigh their low efficiency But without careful and costly sequestration of the carbon dioxide produced, it would be a significant additional source of greenhouse gases But, as we argue in our Editorial (see page 654 ), a greenhouse-gas crisis and worries over oil supply mean that diversifying the range of options makes good sense — as does the development of new routes from research to large-scale deployment. Compared with, say, an array of solar cells, they are strikingly poor transducers of the Suns energy; even an intensively managed plantation struggles to store away more than a watt or two per square metre on average For a start, unlike solar cells, plants are very cheap to make; indeed, with a moderate supply of water and nutrients they will make themselves For countries that have a lot more coal than oil, this coal-to-diesel technology can look attractive purely on an energy-independence basis No fuel technology is perfect Our Features this week look at this potential in three different areas So although their inefficiency means that plants will never be the total answer to our global energy problems, they have substantial potential as a source for carbon-neutral fuel for the ever-thirsty transportation sector, as long as oil prices stay reasonably high The first (see page 670 ) addresses the worlds most substantial biofuel success — the Brazilian sugar-cane ethanol industry — and assesses its impact and potential The idea of using living plants as a way to capture the all-but-unlimited energy of the Sun has a powerful romantic attraction The second (see page 673 ) looks at the possibilities of making ethanol, or other alcohols, out of sources of cellulose from farm waste to poplar plantations — possibilities currently entrancing US entrepreneurs The third feature (see page 677 ) looks at a different approach to alternative fuels — the thermochemical route They use up carbon dioxide in the process, which is a definite environmental plus — and they turn that carbon, along with the Suns energy, into stable organic compounds This means that the Suns energy is made available at a later date when the Sun isnt shining This technology can be used to make fuel from biomass — but it can also, more easily, be used to make liquid hydrocarbons from solid coal, and this is where most research in the area is focused To governments worried about the stability of their fuel imports, or indeed the long-term future of global oil production, that could matter quite a lot Unfortunately, plants have a basic problem in this respect
 Earlier estimates had ranged widely but regularly suggested that there could be many tens of thousands of deaths (see Nature 351 , 4 ; 1991 10.1038/351004b0 ). “The effects on public health were not nearly as substantial as had at first been feared,” says Michael Repacholi, head of the radiation programme at the World Health Organization in Geneva It argues that future aid should focus on improving the healthcare system and promoting local economic development. On 26 April 1986, one of four reactors at the Chernobyl nuclear power plant in the Ukraine suffered a series of explosions and a meltdown — the worst nuclear accident in history Poverty and mental-health problems, such as stress, depression and anxiety, pose a much greater threat to the local communities than radiation, the report concludes Radioactive fallout contaminated more than 200,000 square kilometres of Europe, leading to the eventual relocation of more than 350,000 people Repacholi was among more than 100 scientists, economists and health experts who worked on the 600-page document, which aimed to summarize the available scientific data on the accident and the countries most affected by it: the Ukraine, Belarus and Russia So far, the report says, fewer than 50 deaths have been directly attributed to radiation exposure — most of them rescue workers who died of acute radiation syndrome shortly after the disaster Some 4,000 people — including emergency workers and residents of the most contaminated areas — could eventually die of factors linked to radiation exposure, the report says The authors estimate that the incidence of radiation-induced cancer rose by only about 3% in the affected areas The Chernobyl nuclear accident in 1986 will lead to far fewer deaths than originally thought, according to a report from the United Nations The report was due to be released by the Chernobyl Forum at a meeting in Vienna this week They add that the thousands of children who contracted thyroid cancer after the accident are likely to have a 99% survival rate, higher than the 80–85% previously thought
 As the equations progress through the Dirac equation, quantum chromodynamics and electroweak theory to the superstring action, Bais simply writes down the equations in their most compact and elegant form and discusses what the solutions mean At a recent public lecture on Einstein and the arts in the first decades of the twentieth century, my co-presenter from the perspective of art history commented on the sheer physical beauty of the equations that I risked presenting to the audience But when reading the book, I kept thinking: “If only he had said...” For example, why are complex numbers the natural language of quantum mechanics? Where do the horrendous complexities of turbulence come from in the Navier–Stokes equations? What was the step of genius that led James Clerk Maxwell to the final form of his equations for the electromagnetic field? If the key concept of the relativity of simultaneity had been introduced, so many of the problems of special relativity would have disappeared For me, these would have added to the insight and value of the exposition However, this is not really what the book is about — it is much more a concise exposition of what the equations can do, and the reader has to trust that the author has got it right I only wish he had included Galileos pivotal contributions as the founder of the whole business: “The book of Nature is written in mathematical characters.”  Who will gain most from reading this book? It has to be someone who wants an introduction to the power of mathematics in describing natural phenomena without actually having to do the maths In a book of only 96 pages, it is a real challenge to do much more than indicate to the reader the enormous richness of these equations and the imaginative ways they can be used to extend our understanding of the workings of nature at all levels In addition to its pedagogical value, Baiss book presents these icons of our physical world in all their beauty In the first few pages there is a lightning review of elementary mathematical operations, and this helps the reader understand the simpler equations, such as Newtons laws of motion and the continuity equation Indeed I cannot fault what he says about the meanings of the equations, and the main text is enlivened by brief sketches of the lives of some of the principal players It is debatable, however, whether these insights enable the reader to understand the importance of lagrangians, tensors, spin matrices and so on It is very good to be reminded of this. It would be a lovely birthday gift for them My suspicion is that the most important target audiences are young people who aspire to become mathematically oriented scientists and who will find the scope of the book inspiring Perhaps the most common comment I receive after delivering a public lecture is: “I enjoyed the lecture, but I couldnt understand the maths.” This difficulty doesnt just affect the public but is one that students and scientists encounter throughout their careers: how does one connect the behaviour of the real world with the mathematics used to describe it? After years of practice and hard thinking, professionals become adept at making this connection, which I regard as perhaps the greatest challenge in teaching mathematical physics Sander Baiss little book The Equations tackles this problem from the point of view of 17 of the basic sets of physics equations, which the subtitle refers to as “icons of knowledge” Still, if it were, the book would have grown out of all proportion The average interested public should be encouraged to dip into the book and see how they get on The equations are presented in their final definitive forms without any discussion of how they came about or why they have these forms This is fair enough if we are to regard the equations simply as icons of knowledge This latter aspect is not part of Baiss agenda, which is a pity
 Although overshadowed in the popular media by feathered dinosaurs, more than 200 new Mesozoic species have been named and designated as mammals, and they are profoundly reshaping our knowledge of mammalian structure and evolution And it is likely to become the first book to reach for when embarking on the trail of virtually any question or problem involving deep mammalian history But as Isaac Newton proved in deriving the calculus, two variables cannot be optimized in a single equation But even if criticisms of this books phylogenetic architecture are upheld, it simply highlights that much is yet to be learned about mammalian phylogeny and history But its phylogenetic framework is important to its overarching historical synthesis, and that framework was challenged in several papers published by Michael Woodburne and colleagues as this book was nearing completion But the new book, for which Kielan-Jaworowska was joined by Richard Cifelli and Zhe-Xi Luo, is twice the length of its predecessor By giving primacy to a simpsonian view, Mammals From the Age of Dinosaurs presents an encyclopaedic work whose thoroughness ensures it will have long and useful life I am glad to own two copies of this book If the critics are correct, then major structural features of the historical argument may crumble as well It is broader in content and scientific scope, and is in many ways a different book altogether It presents a broad historical synthesis of early mammalian evolution It will be the basic mediator of debate for many years to come, and I expect to wear out both copies long before a comparable work emerges to overshadow it. Its increased girth reflects recent areas of scientific advance, including exciting fossil discoveries from across the world, new technologies for analysing them, and changing philosophical perspectives on this defining segment of our own distant past Its informative narrative attests that mammalian palaeontology is in the midst of a renaissance of discoveries unexpected 30 years ago Most of the new names refer to isolated teeth and jaws, but some spectacular discoveries include complete skulls or articulated skeletons, and a few specimens even provide evidence of fur Palaeontologists may recognize Mammals From the Age of Dinosaurs as an update of an earlier classic, Mesozoic Mammals , edited by Jason Lillegraven, Zofia Kielan-Jaworowska and William Clemens (University of California Press, 1979), a volume of tremendous and lasting impact Taxon selection, character conceptualization and polarity, and other technical issues will be debated by those in the field as long as this book is read The book is extensively illustrated, comprehensive and detailed in its treatment of Mesozoic fossils and their primary literature The book overwhelmingly reflects the world view of George Gaylord Simpson, and shows signs of Willi Hennigs influence and the importance of phylogeny reconstruction in interpreting history The books architecture thus reflects a struggle that has dominated palaeontology for three decades The known fossil record of Mesozoic mammals has grown faster in the past 30 years than in the previous 300 The most important is a fundamental division of mammals into Australosphenidans and Boreosphenidans, and this casts doubt on the authors interpretations of character history, such as their views on the dual origins of the tribosphenic molar and mammalian middle ear The rich resources gathered between its covers are timely and exciting, and should foster a further boom in mammalian palaeontology The three authors of this volume have been directly involved in many of these discoveries, adding authority to this book This beautiful book surpasses all its predecessors in its scope and detail, and in using the most rigorous methods yet directed at such a broad panorama of early mammalian history
 Although Germanys space budget is shrinking each year, the country is locked into paying the highest contribution to the European Space Agencys science budget, based on its high GDP And environmental scientists are complaining that they dont have enough money to exploit Europes Earth observation satellites. “Germany is a big contributor to Earth observation hardware,” says Jochem Marotzke, an oceanographer and a director at the Max Planck Institute for Meteorology in Hamburg. “But we have little project money to make use of it.”  When asked about the crisis, a research ministry spokesman told Nature that space research remains a “high priority” for the German government And the APX ‘sniffer’ that first analysed the chemistry of martian rocks on NASAs 1997 Sojourner mission was also German And to make matters worse, they say they are unable to compete in placing instruments on international missions either But Germanys space research budget has shrunk by so much that the countrys scientists say they no longer have the opportunity to participate in space missions For example, although the APX spectrometer is to be included in NASAs Mars Science Laboratory (due for launch in 2009 or 2011), it will be developed in Canada, not Germany — because the department that first worked on it, at the Max Planck Institute for Chemistry in Mainz, has closed Frustrated by the governments failure to reverse the trend, they are warning that, without involvement in missions, the countrys space-related research laboratories will inevitably wind down too Its value is now only a third of what it was 15 years ago Munich Germany was once a leader in space research No national space-science mission is planned for the next five years, they point out Scientists are hoping that, with an election looming, their public plea will help persuade politicians to back that sentiment with further funds. Since reunification in 1990 put pressure on the countrys spending as a whole, the space research budget has slipped every year So on 21 June, the scientists published what they refer to as a “begging letter” The extraterrestrial-physics institute is also rethinking its strategy, and has abandoned gamma-ray astronomy to concentrate all its efforts on X-ray astronomy, says Hasinger The Mars Express pictures that fired the worlds imagination last year were taken by a German stereocamera, for example This means that Germany is paying for ESAs spacecraft and launches, but there isnt enough national money left over for German scientists to develop their own instruments to send on board, according to Günter Hasinger, a director of the Max Planck Institute for Extraterrestrial Physics in Garching Top astronomers, planetary scientists and climatologists have been discussing the crisis with politicians for months — but to no avail, say the researchers
 A specialist in one of the techniques was positive because he could find no flaw in its application And authors tend to be mightily upset if their papers are rejected when one or more reviewers are positive Another paper concerned the innovative application of chemistry to an environmental problem Between them, these elements add up to a verdict on the works credibility and robustness But before publication, the editor orchestrated considerable iteration between referees from quite disparate backgrounds to ensure that a common understanding of the paper and its reliability had been established But the editors felt that the therapeutic implications of the paper merited publication and, after resolving the technical issues raised by the referees, pushed ahead with publication of what turned out to be a highly cited development But the third referee uncovered a technical shortcoming in the second technique, and the paper was rejected after the editor assessed the significance of the shortcoming In another case, efforts to obtain review of a paper in genetics led to seven refusals to review, one damning review and only one positive review In another case, one of the referees recommended publication of a paper, but also pointed out limitations in the value of the finding In one case, an exciting result relied on two techniques and a theoretical interpretation In one such case, referees criticized a molecular-biology paper for a lack of mechanistic insight and expressed reservations about the appropriateness of some of the techniques the authors used In this case, the editor identified an experiment that would improve the paper and suggested it, yielding interesting results that were then published and well received Its imperfections — along with those of every other journal — are among the multifarious reasons why over-reliance on journal publications as a measure of researchers performance is dangerous Misconduct creates a negative perception of journals scientific peer-review processes, and the Hwang fraud saga has already fuelled some misconceptions about how the combination of referees and journal editors actually works Moreover, Nature often makes referees aware of what the others are recommending, which can sometimes provide useful feedback to the selection process Most of their reports contain exactly what we need: a statement of what the referee considers the central message of the paper; an assessment of its significance; and a critique of technical or interpretational weaknesses, either in the work itself or in its presentation Nature has also dished out its fair share of historically embarrassing rejections (see Nature 425 , 645 ; 2003 ) Nature is hugely grateful for the advice it receives from about 6,000 referees each year — typically two or three referees per paper On many other occasions, however, the editors discretion in making a decision results in a papers publication Only in a minority of cases does every referee agree on whether or not to publish a paper Peer review remains by far the best available system for scientific quality control, however, and is an ultimately inspiring one at that The above examples illustrate just a few ways in which such differences arise and demonstrate why journals would lose the respect of their authors and readers if they were to act robotically on the referees advice The editor concluded that the paper lacked the significance that would justify inclusion in the journal The lives of editors and editorial boards of all journals are made interesting by the fact that, in many cases, the referees disagree on the verdict The system, it should be noted, is reliant on trust that what is written in the paper is actually true: it is not designed to detect the tiny minority of papers that are fraudulent The theoretical referee was very positive because the work validated an interesting idea There is nothing like a high-profile fraud case to encourage journals to reflect on whether the standards and procedures they follow in selecting work for publication are thorough and appropriate We can only work to ensure that what we publish will do justice to the diversity of expertise that is brought to bear on its selection, and, above all, stand the test of time. We would never claim that Nature s decision-making process is perfect Why, they demand to know, should the view of a negative reviewer be allowed to dominate the editors selection decision? To shed some light on how these decisions are reached, it is worth reflecting on some case studies of how and why referees differ in their view of papers submitted to Nature and the Nature research journals
 Avian flu: Isolation of drug-resistant H5N1 virus Q Dinh Pham, Ha H Hien Nguyen, Khan H L Mai Le, Maki Kiso, Kazuhiko Someya, Yuko T Nguyen, N Ngyen, Shinya Yamada, Yukiko Muramoto, Taisuke Horimoto, Ayato Takada, Hideo Goto, Takashi Suzuki, Yasuo Suzuki, Yoshihiro Kawaoka Nature 437 , 1108 ( 2005 ) We omitted the accession numbers for the sequences of the A/Hanoi/30408/2005 clones, which are registered in the DNA Data Bank of Japan Sakai, T These are: AB239125 20051020120345.25409 for the haemagglutinin gene in clone 9; and AB239126 20051020122743.63420 for the neuraminidase gene in clone 7.
 Dogs cloned from adult somatic cells Byeong Chun Lee, Min Kyu Kim, Goo Jang, Hyun Ju Oh, Fibrianto Yuda, Hye Jin Kim, M Hossein Shamin, Jung Ju Kim, Sung Keun Kang, Gerald Schatten, Woo Suk Hwang Nature 436 , 641 ( 2005 ) This communication contains an error in the methods section of the supplementary information In the description of the fusion protocol on page 3, line 2, electrical pulses were delivered for 15 microseconds, and not for 15 seconds as published.
 Additional reporting by Tamara Grüner. But in the weeks running up to the anniversary celebration, three members of the academys 18-strong senate resigned, expressing many concerns including lack of clarity on how money flows into, and out of, the academy But the party has been pooped by allegations of mismanagement Ernst Pöppel, a neuropsychologist at the University of Munich, was dean of the science section of the academy but says he resigned because Unger had become “a one-man show”, changing the legal basis of the academy without discussion with the senate and not opening the accounts of the academy to scrutiny. “There is no transparency in the finances of the academy,” he says. “For example, once a very large debt appeared, but was then wiped out, without anyone being able to find out why we had gone into debt and who had paid the debt off.”  Bernd-Olaf Küppers, a philosopher from the University of Jena, who had been dean of the academys humanities section, said that he too resigned on the grounds of its lack of financial transparency Eugen Biser, a theologian at the University of Munich and dean of the academys world religion section, says that the accusations are born of “revenge and spite” and that the academy must allow the affair to blow over Gilbert Fayl, foreign secretary at the academy, says the accusations are “purely personal” He also noted that many ordinary members had resigned and had criticized a ‘personality cult’, ‘clientelism’ and ‘empty boasting’ at the academy He insists that the financial accounts have always been open to the senate. “Its all lies,” he says He says that they have been made up by people who have tried, but failed, to get money from the academy It is divided into seven sections, ranging in scope from religion to science, and has several institutes under its umbrella Its website also features a long list of companies and organizations designated as partners, benefactors, sponsors and donators Justin Stagl, a sociologist from the University of Salzburg and former chairman of the academys nominations committee, said in his 8 February resignation letter that he had resigned because he was unable to persuade Unger to stop nominating new members without discussion with, or the consent of, the senate The academy has some 1,200 members, nearly half of them from Austria or Germany The academy has the patronage of the city of Vienna and the Austrian government, and has a grant of €150,000 (US$200,000) from the European Commission, primarily to help cover its administrative costs The accusations centre on a lack of transparency about the bodys finances and the alleged failure of its president, Salzburg heart surgeon Felix Unger, to properly abide by the academys rules The European Academy of Sciences and Arts in Salzburg, Austria, celebrated its 15th anniversary last weekend with considerable pomp and ceremony These include two run by Unger himself — the European Heart Institute and the European Institute of Medicine — which share the same address Unger denies the allegations, which were first reported in the German newspaper Süddeutsche Zeitung on 4 March Unger has his supporters in the senate Unger says that the academy aspires to forge a European identity through interdisciplinary, transnational and bridge-building activities
 As the authors note, human impacts ranging from over-harvesting to eutrophication have the effect of reducing the importance of top predators, and effectively homogenizing the energy channels, thus endangering the stability of natural ecosystems Assessing the response of the model to both small and large perturbations, Rooney et al . show that, in general, asymmetry in the amount of energy flowing through the two levels, and in the pattern of predator attacks, promotes the most stable food webs At their base, many food webs consist of groups of species that use distinct sources of energy and nutrients But as one ascends the food web, these channels begin to merge, so a predatory fish such as the lake trout might be sustained ultimately by both phytoplankton production and detritivory But in the messy, tangled web of ecological systems, a fair dose of asymmetry may be required to prevent these systems from self-destructing. But there are more subtle implications of coupling channels that emerge from a theoretical study of a model of linked food chains Crucially, the authors also observe that the different channels are not equally important, but typically exhibit strong asymmetry, with considerably more resources flowing through one channel than through others, but without complete dominance by any particular channel Ecological communities are among the most complex entities studied by scientists, as they are composed of thousands of species with many distinct lifestyles, interacting in a myriad of ways For instance, a lake food web may be sustained by both phytoplankton (which create biomass via photosynthesis) and microbial decomposers (which consume detritus washing into the lake) In effect, there are distinct channels for inputs of energy and materials into the biota of the lake Including additional species and more complex assumptions about individual behaviour and interspecific interactions can lead to surprises in ecological models , and it seems likely that the effects emphasized by the authors could be obscured by other factors in some systems May demon-strated mathematically that increasing the diversity and connectedness of randomly assembled model food webs typically decreased their stability Most of the empirical studies included in the analysis involve highly aggregated data, and the authors model in essence describes the dynamics of just five interacting species Nonetheless, Rooney et al . provide an innovative empirical and theoretical contribution to this central ecological problem of identifying potentially key structural features of food webs that promote persistence On page 265 of this issue, Rooney et al . grapple with the problem of understanding the stability of complex food webs, and argue that strong asymmetries in energy flow and interaction strengths may be key determinants of ecological stability Phytoplankton and decomposers are very different potential resources for consumers, so organisms in the lower trophic ranks tend to be specialized Rooney et al . examine published food-web data from a wide range of aquatic and terrestrial ecosystems, such as marine upwelling regions, estuaries, and agricultural and forest soils So if complexity is to enhance ecosystem stability in real food webs, it must emerge from particular structural features of ecological systems Symmetry is elegant, and often desired in art, human affairs and the formulation of some fundamental theories in science The authors relate a principal ecosystem concept (turnover rate, which determines how long a given individual takes on average to be replaced) to a principal community concept (interaction strength, which governs how much one species changes in abundance following a change in anothers abundance) The authors weave together a survey of empirical studies of food-web energetics with theoretical arguments to suggest that a particular pattern of energy flow found in many food webs may contribute strongly towards stability The concept of symmetry is a guiding principle in much of science, ranging from fun-damental physics , to analyses of sex-ratio evolution , to the dynamics of persistent populations  The conventional view that diversity begets stability was overturned by the seminal work of Robert May in the early 1970s The organisms that define these distinct resource channels differ in properties such as body size, generation length and accessibility for higher consumers The word stability has many meanings, but in this context it refers to the capacity of a system to recover from perturbations in species abundances There are, of course, many questions that one can pose about the generality of these results These organismal traits have dynamical consequences for the food web as a whole They conclude that the pattern of channels that are distinct at the base of the food web and fuse as energy percolates up the web is widely observed They suggest that faster channels on average reflect strong interactions, and slow channels, weaker interactions They suggest that this is because the simultaneous presence of slow and fast channels prevents dramatic overshoots following large perturbations, while also permitting rapid recovery This difference in response times means that a predator using both fast and slow channels enjoys a more dependable prey base than predators specialized to just one or the other This in turn influences the timescale over which the channels in isolation would respond to disturbance Thus, the asymmetric patterns that the authors document in natural food webs are also the very kinds of asymmetry that promote stability and resilience in theoretical models Top consumers thus integrate a broad base of alternative energy sources ( Fig. 1 ) Understanding the relationship between the complexity and diversity of ecological systems, and their stability and persistence, is a perennial challenge in ecology Yet many phenomena reflect the action of strong asymmetries, including ageing , the evolution of species niches , and even the grand sweep of organic and human history 
 After it arrives in March next year, the MRO will spend eight months settling into its final 320-kilometre orbit After recent budget scares and shifts in priorities, the programme looks to be on track to send more advanced rovers to the planet over the next decade And new, more stringent recommendations from the National Academy of Sciences for sterilizing Mars-bound spacecraft, to protect against biological contamination of the planet, could drive up the cost even more Bringing samples home The new Mars plan retains a sample-return mission as a goal, but it has an unspecified launch time But bringing samples home will be difficult and expensive But the situation has improved, and the mission remains targeted for 2009, says Mars programme director Douglas McCuistion From there it will point six instruments at the planets surface, including a spectrometer for identifying minerals, a sounding radar for locating subsurface water (see Nature 435 , 266 – 267 ; 2005 ), and a camera sharp enough to resolve objects the size of a kitchen table McCuistion says that launching two MSLs, which science advisory groups have recommended partly as insurance against a launch failure, is “not impossible” but depends on future NASA funding levels McCuistion says the MRO and other spacecraft already orbiting the planet will serve as data relays instead Most scientists still consider bringing Mars samples back to Earth a priority, says Arizona State University planetary scientist Ron Greeley, as the rocks must be dated isotopically in a lab to sort out the planets complicated geological history Says Greeley: “Id be surprised if we didnt have sample return as a precursor to humans for safety reasons.” The $500-million Mars Reconnaissance Orbiter (MRO), due to launch from Cape Canaveral, Florida, on 10 August, may also signal a new period of stability for the agencys Mars programme The camera will increase high-resolution coverage of the planet from 2% to 20%, and allow Mars planners to scout for future landing sites The money crunch has also eased with NASAs decision to cancel the 2009 Mars Telecommunications Orbiter, which would have acted as a high-speed data relay for other Mars spacecraft The MRO will be followed in 2007 by the Phoenix lander, designed to search for water and organic molecules around the planets north pole Then in 2009 the most ambitious mission in the queue, the mobile Mars Science Laboratory (MSL), will launch This reprieve is partly due to a decision to defer missions that will pave the way for astronauts to visit Mars around 2030 This spring, the MSL was in serious danger of having its launch date slip two years or more as NASA struggled to contain rising costs University of Colorado planetary scientist Bruce Jakosky, who until recently chaired NASAs outside advisory group for Mars exploration, says there are “legitimate differences of opinion” about where sample return should fit in the mission queue With a price tag of at least $1 billion, the MSL will travel a kilometre or more from its landing site carrying a suite of sophisticated instruments for sniffing out chemical evidence of life. (See box ) With two healthy rovers still roaming the martian surface 19 months after they landed, NASA is set to take the next step in Mars exploration by sending its largest orbiter to the planet since the 1970s Yet NASAs long-term plan to send astronauts to Mars could ultimately work in favour of sample return, as engineers will need to understand how surface materials behave and what risks they might pose
 A cold spring rain pounded the windshield of her cruiser Gracie, ask Judge Hastings to issue us an arrest warrant.”  “Wow,” said the rookie. “Ive never heard of a case like that Gracie, do a round-up of the usual suspects.”  “Hold please, processing,” the tablet droned. “Wait a moment, lieutenant, I have a suspect He glanced up and flashed her a grin. “Morning lieutenant.”  She glared at him. “What can you tell me?”  “Well,” he said, unplugging his tablet from the data port on the dead mans neck. “His name is Henry Watson, age 275, Washington DC resident His immunobots are still fighting off infections, so he hasnt started stinking the place up,” he said. “I see,” she said, and pulled from her pocket a thin, silver tablet identical to her partners Im showing she illegally deactivated Mr Watsons cardiobots from a remote terminal on March 10, 2246 at 14:24:37.”  “But why would she kill her great-great- grandfather?” the rookie asked. “Thats three greats,” the lieutenant interrupted. “Im showing Mrs Howard has a conception licence application pending with the Bureau of Births and Population Management,” the tablet crooned. “Well theres your answer,” the lieutenant said. “The girl wanted to have herself a baby, and she knew the feds wouldnt let her unless someone in the family happened to keel over, which doesnt happen too often these days It was too early to play detective, but here she was. “Hey Joe,” she mumbled, flashing her shield to the cop outside the front door Looks like he worked on organ regeneration, mainly lungs.” He paused. “I guess hes the reason you can puff on those cancer sticks without getting cancer.”  “Spare me the poor schmucks life story,” she snapped. “Whatd he die of?”  “Looks like a myocardial infarction,” he said, glancing down at his tablet. “Heart attack, huh?” she smirked. “Havent heard that one for a while.”  She flicked her cigarette into the sink and walked over to the dead mans refrigerator Married to John Howard, age 94 Mr Watsons cardiobots have been inactive since 2246.”  “Thats almost 15 years!” the rookie said. “Yeah,” the lieutenant growled. “And with his diet, its no wonder he dropped dead Mrs Erin Marie Howard, age 72, of 414 Darrow Street, Ann Arbor, Michigan Mrs Howard is Mr Watsons great-great-great-granddaughter Not that it mattered what you ate these days Pizza, soda, cake. “This guy ate like a pig,” she thought to herself She pushed a button on the side, and it whirred into life. “Good morning lieutenant,” the tablet said smoothly. “Morning Gracie,” she replied. “I need you to run a diagnosis of our stiffs nanosystems.”  “One moment, please,” the tablet hummed softly in her hand. “Im showing an abnormality She sighed, turned up the collar on her overcoat and sprinted from the car to the porch She stepped inside and lit up a cigarette, pausing to let her eyes adjust to the gloom. “Come on in, lieutenant,” shouted a voice from the next room. “Christ,” she thought to herself. “How does he always beat me to the scene? And why is he sounding so goddamn perky?” She checked her watch, it wasnt even seven She took a soda, and walked back to the body to have a look She was so much younger than he was; theyre hardly even related Shes currently employed as a biomedical nanotechnician at GSK-Syngenta-PhilipMorris Talk about cold-blooded.”  “Id say something like this comes along every hundred years or so,” the lieutenant sighed and leaned against the kitchen counter, taking a swig of the deceaseds soda. “The girl probably barely knew Watson The body was curled up on the kitchen floor like a baby; the rookie stooped over it, peering at it like hed never seen a corpse before The guy is — sorry, was — a researcher at the National Institute of Radical Life Extension up in Bethesda The rookie interrupted her thoughts: “Our boys think hes been dead for at least a week, but its hard to tell Who knows, maybe he hadnt; hed only been on the force for 25 years Why not bump the old guy off? Clever too, giving him 15 years to do it to himself — too bad for her our boys used the time to develop AI crimepads like Gracie here.”  “Judge Hastings would like to know what charges youre filing against Mrs Howard,” the tablet asked. “Murder, Gracie,” the lieutenant replied. “Murder by natural causes.” Without his little nanofriends to scrub his arteries clean, the guys cholesterol must have gone through the roof
 A number of my Chinese friends in North America, including one senior postdoc, have, in my opinion, been discriminated against Although I currently work in a friendly and cooperative lab and feel fortunate to have helpful and supportive co-workers, my comfort does not mean that discrimination does not exist elsewhere Furthermore, competition in lab research is fierce, particularly in the United States, so anyone with an obvious weakness such as a language barrier or cultural difference is more likely to be taken advantage of I would like to think that mistreatment of the Chinese workforce in North American graduate schools is minimal at most, yet I fear that this is not a realistic hope Sir As a Chinese graduate student studying in Canada, I often hear stories that reflect your News Feature “Taking a stand” ( Nature 438 , 278 – 279 ; 2005 ), about my Asian colleagues feeling mistreated by their lab-mates The Ontario Human Rights Code states that “individuals have the right to equal opportunities in the workplace and to an educational environment free of harassment because of colour, age, sex, sexual orientation, ethnic origin, religion and handicap” The United States has a similar law To fight for equality in the workplace, one needs to be socially adaptable, and must voice concern if equal rights are being violated. Unfortunately, a traditional Chinese upbringing encourages passive and nonverbal avoidance of conflict
 According to current theories, the first dwarf galaxies hosted metal-free stars over a hundred times more massive than the Sun Astronomers have long been rummaging through the Universe for tell-tale signs of these dramatic beginnings Both variants seem to be in conflict with current observations  But Aharonian et al . show that intergalactic space is more transparent to γ-rays than would be expected if an infra-red background excess existed But if the first-generation stars were to collapse to massive black holes instead, gas accretion onto such black holes would produce large amounts of X-rays But it seems unlikely that they will be able to supply the fine-tuning required to make the HESS data consistent with the previously reported excess of infrared background light But rather than helping to decipher the epoch of cosmic first light, such observations have in fact created another puzzle But the timing and sequence of the events through which the very first galaxies and stars formed remain largely unknown Enter Aharonian and colleagues , and their measurements of teraelectronvolt (TeV) γ-ray photons from blazars First, there is an excess signal above the combined emission of normal foreground galaxies that would require energetic events to have occurred in the early Universe Further high-energy observations of blazars at different cosmological distances should settle this issue HESS uses four large telescopes ( Fig. 1 ) arranged at the corners of a 120-metre square to detect the faint flashes, lasting only a few billionths of a second, of blue ‘Cherenkov’ light emitted when a high-energy γ-ray hits the atmosphere If primordial sources are to account for all of this infrared radiation, current models of star formation in the young Universe look distinctly shaky If true, that could influence our ideas of how and when the first structures in the Universe evolved It is therefore conceivable that not all of the foreground emission has been subtracted from the diffuse-sky maps, and the excess may not be extragalactic after all Just last month, astronomers using NASAs Wilkinson Microwave Anisotropy Probe (WMAP) reported the latest detection of photons produced soon after the Big Bang Lower-energy ultraviolet light escaped this fate, but was stretched to longer, redder wavelengths Nevertheless, several groups have claimed to have found the footprints of baby galaxies at near-infrared wavelengths, using data from NASAs Cosmic Background Explorer (COBE) and Spitzer Space Telescope , and Japans Infrared Telescope in Space (IRTS)  On page 1018 of this issue, Aharonian et al . report the detection of copious high-energy γ-ray emission from two ‘blazars’ — a class of active galaxy — around 2 billion light years from Earth On the other hand, the fluctuations detected in highly sensitive images taken with the Infrared Array Camera onboard Spitzer do not change between observations performed six months apart, and changes would be expected if their origin was zodiacal light within the Solar System Remark-ably, the attenuation in the HESS images seems consistent merely with the integrated infrared output from resolved foreground galaxies, together with the total extragalactic light produced by second-generation stars according to recent theoretical calculations  Resolving this infrared glow is, however, a daunting task, because many other celestial sources — among them older stars in closer galaxies, active galactic nuclei known as quasars, and the bright foreground sources in the Milky Way and the Solar System — emit radiation at similar wavelengths Second, the very uneven distribution of the radiation could arise from the spatial clustering properties of primordial stellar systems Simply stated, the dawn of galaxies seems to be too brilliant: the excess signal outshines the cumulative emission from all galaxies between Earth and the extremely distant first stars Since June 2004, HESS has accumulated more than 80 hours of observations on two blazars So how much of the background light that we see comes from the first stars? As the Universe aged and expanded, part of the ultraviolet radiation emitted by these stars was absorbed again by re-formed atomic hydrogen So, if such γ-rays were propagating through a dense sea of infrared photons, as implied by previous measurements , the spectra of the two blazars recorded by HESS would reveal evidence of strong, energy-dependent attenuation The authors observations were made with the High Energy Stereoscopic System, HESS, inaugurated in Namibia in 2004 and operated by a collaboration of scientists from nine countries The distribution of this excess infrared component over different wavelengths is almost identical to that of sunlight reflected from local interplanetary dust clouds  The formation of structure in the Universe is believed to proceed hierarchically, with smaller galaxies merging, through the action of gravity, to build more massive ones The level of polarization allows the era of reionization to be pinpointed to some 400 million years after the Big Bang, when the Universe was just 3% of its present age  The observed level of γ-ray attenuation can, therefore, be used to estimate indirectly the energy density of infrared starlight present in intergalactic space The γ-rays emitted by these most distant known sources have energies between 0.2 and 3 TeV; infrared radiation at wavelengths longer than 1 micrometre absorbs γ-ray photons of energy greater than 0.7 TeV Their data show that these ‘cosmic microwave background’ photons became polarized (tending to oscillate in only one direction perpendicular to their line of travel) by scattering on free electrons in the early Universe Their evidence comes in two forms Therefore, although the early stellar populations were twinkling so long ago that current telescopes cannot detect them, their combined energy output is recorded in diffuse light that reaches Earth in the near-infrared region of the electromagnetic spectrum, at wavelengths of a few micrometres These photons ‘reionized’ the surrounding atomic hydrogen gas that had formed as the Universe cooled These photons, which carry 10 12 times more energy than visible light, interact with near-infrared photons through the quantum-mechanical process of electron– positron pair creation These stars shone intensely for only a few million years and then either blew themselves apart in gigantic supernova explosions, or collapsed to form the first massive black holes They are likely to spark further attempts to glimpse the crucial early stages of the galaxy formation process. This observation indicates that such radiation can travel largely unimpeded through the cosmos, and implies that the infrared glow of the first stars in the Universe and their remnants is fainter than previous measurements had led us to believe Through this process, most of the TeV photons are absorbed long before they reach Earth Too many massive stars ending their brief lives in a giant thermonuclear explosion would, for instance, eject large amounts of heavy elements such as carbon and oxygen into space, polluting the cosmos very early on and altering for ever the composition of the raw material available for second-generation stars Up to four images are combined to determine the direction of the γ-ray and the energy it deposits in the atmosphere What is the cause of the discrepancy between the HESS data and previous results? Aharonian and colleagues point out that their interpretation of the HESS results relies on the assumption that the intrinsic γ-ray spectra of the two active galaxies are not at odds with current models of blazar behaviour Whatever the final resolution of the mystery concerning the signature of the first stars, the HESS findings will stir much debate among cosmologists When the first stars ignited, they emitted large numbers of photons at ultraviolet wavelengths
 A report released this week by the Royal Society of Edinburgh (RSE) attempts to provide such an analysis for Scotland — a small country whose energy issues are not untypical of those facing Western Europe And it suggests that the executive should promote research collaborations in technologies such as clean coal and wave power, in which local industrial companies and researchers have international expertise And there is a disturbing tendency for this urgency to generate polarizing debates on plans that could have only a marginal effect on the unfolding crisis As the RSEs report explains, the energy crisis wont be addressed either by building wind-farms on the Isle of Lewis, or by licensing replacements for the nuclear plants that now produce half of Scotlands electricity But it isnt at all clear whether the resources will be provided to establish such an agency But the crisis demands more than the flailing efforts of governments or political parties to develop headline-grabbing initiatives But the most important recommendation is perhaps the dullest: a call for an agency, outside the government but answerable to it, that will formulate, champion and implement an energy strategy In Britain, an almighty row is looming over the replacement of a small number of ageing nuclear power stations In elections next spring, for example, the ruling coalition in the Scottish parliament looks set to split over the issue of nuclear power In the United States, such an argument has taken place over oil drilling in the Arctic National Wildlife Refuge It calls, instead, for a thorough, rational and rapid analysis of how effective energy policies should be rebuilt It is only this that can take energy usage over many years to a sustainable position, with no more lurches from complacency to crisis. Maxwell Irvine, the physicist who chaired the RSE panel, fears that without a comprehensive energy strategy, Britains privately owned electricity industry will repeat the ‘dash-for-gas’ — the Thatcherite energy policy of the 1980s Some of the recommendations concern such humdrum matters as making more effective use of existing planning regulations to construct energy-efficient buildings — an area in which Britain has always lagged behind its neighbours That policy caused the nation to burn its irreplaceable North Sea gas supplies, rendering itself dependent, in the long term, on imported gas to keep the lights on The energy issues facing many of the worlds governments are now acute The exhaustion of North Sea oil and gas, together with the rapid ageing of coal and nuclear power stations, presents a challenge for the Scottish Executive and the British government in London The report also calls for a more diverse approach to renewable energy, pointing out that the Scottish Executives existing incentive system serves to promote wind capacity (which can be built now) over alternatives such as wave power that require further research and development The reports 37 recommendations are not a cop-out from making choices, but are instead a realistic acknowledgement of the breadth of the problem The RSE committee, which raised funds for the study from foundations and other sources, is to be congratulated on bringing some sanity to an energy debate that is becoming unhinged from reality The urgency of the current crisis is driven by stubbornly high oil prices, the clear need to do something about greenhouse-gas emissions, and the benign neglect that has characterized many national energy policies for the past two decades This demand is also pertinent to Britain as a whole, which shut its energy department in 1992 Under Scotlands 1999 devolutionary settlement, London sets the energy policy, but Edinburgh is responsible for implementing it What is needed instead, in Scotland, the United Kingdom, the United States and elsewhere, is a rational energy strategy, executed by a competent agency Whats needed instead is a wide diversity of approaches to electricity generation and to energy use and distribution, and a comprehensive, integrated strategy for their implementation
 As new cells are generated, they move upwards away from the feathers tip But hair stem cells were found in a bulging region in the upper wall of the follicle and there is no such structure in a feather But the researchers soon realized that they had to adjust their approach because “feathers and hairs have totally different cell dynamics”, Chuong explains But there was still one outstanding question: how do the stem cells give rise to different feather shapes? There are two basic types of symmetry in feathers Cheng-Ming Chuongs fascination with feathers began some 20 years ago Chuong plans to continue his characterization of feather stem cells Flight feathers are bilaterally symmetrical, with the central quill dividing two mirror images, whereas downy feathers are radially symmetrical — looking a bit like dandelion seeds. “How these two kinds of symmetry are constructed and evolved is a mystery,” Chuong says. “One wonders about the enormous molecular codes required for these diverse designs.”  To their surprise, Chuong and his team discovered that in flight feathers, the ring of stem cells ‘tilts’ towards the side where the quill arises, but in radially symmetrical feathers the ring is horizontal He decided to try to track down the location of stem cells in feathers He has since assembled an interdisciplinary team to investigate the evolutionary origin, molecular signalling, complex patterning and tissue engineering of feathers He thinks that some of the tricks used in feather regeneration could be used to help regrow human tissues. In mammals, this is usually done by transplanting transgenically marked cells into mice and tracking their fate It seems that adjusting the angle of the rings tilt gives rise to different types of feather. “Nature has a simple solution for making complex feather forms,” Chuong says On page 1026 of this issue, Chuong and his team reveal the results of their hunt Once they had found suitable candidates, the researchers had to work out how to prove that they were indeed stem cells and able to generate multiple cell types Performing a neurological experiment in chickens, he saw that cells associated with feathers might have multiple roles. “It was a defining moment,” says Chuong, a developmental biologist at the University of Southern California in Los Angeles The pair thought that their task should be successful because the location of stem cells in hair —the mammalian equivalent of feathers — had already been identified The search began in chicken feathers and used typical techniques for labelling and identifying potential stem cells The team came up with a similar trick, eventually transplanting transgenic quail stem cells into chickens They conclude that feather stem cells appear in a ring on the internal wall of the vase-like follicle This helped the group to track and map the location of the feather stem cells This process also helps to explain why the ends of quills taper Together with graduate student Zhicao Yue, he began the search When birds moult, the stem-cell ring remains in the follicle to produce future generations of feathers With interest in stem cells increasing in recent years, Chuong became curious about how feathers are regenerated in adult birds
 Despite overwhelming mental distraction, I try to focus on writing this paper and imagining the difficult questions that those notorious reviewers might ask During my graduate years, I have reviewed dozens of papers for my principal investigator and ripped apart data, suggested experiments or controls, and blatantly stated that this work is not worthy of the journal to which its been submitted I am probably too close to this work to judge its merit: I know the intricacies of the experiments and that the story has some holes here and there I am proud of my near-finished work, but all those pages of failed experiments are hard to swallow, when I look at just seven pages of pretty pictures I am scared of getting a reviewer like myself! Im hoping I am being too hard on myself because I know the work too well I can see the hurdles that remain, and most of them involve what Im doing right now — staring at my laptop I feel as if Im 13 and being sent to the principal for smoking, except now it takes four weeks to find out my punishment In any case, I hope that the principal is in a good mood and I just get a slap on the wrist. It is somewhat disheartening to reflect on my years of research and then look at the figures Ive assembled for my first real research paper
 Although weak, nonspecific, transient complexes could give rise to a noisy system, such encounter complexes might be exploited so that interaction partners do not have to be found afresh in the busy milieu of the cell, thus increasing the rate of formation of specific binary and higher-order complexes But it remains to be seen how many of the minor species are true productive encounter complexes, and which are the preferred paths to the specific binding mode of the final complex But Tang and colleagues go farther, and use computation-based structural models to build an ensemble of conformations that satisfy the experimental data Computational simulations also show that desolvation energy plays a part in orientating the encounter complexes interacting subunits around the final, specific complex state  Essentially, the partners bump into one another and are held loosely, allowing them time to become reorientated and repositioned on the surface or to adjust their shape to fit together more tightly For instance, in the interaction between the Cu A domain of the ba 3 oxidase and its interaction partner cytochrome c 552 , a single complex cannot fully account for the restraints on the amino acids observed in NMR-based experiments, leaving open the possibility that an ensemble of conformations coexist in a weakly complexed state  Furthermore, the population of non-specific complexes can be restricted by the order in which the different subunits are assembled Greater understanding of the route to longer-term relationships between molecules will no doubt emerge from integrating a wide variety of experimental data with theoretically sound computer modelling of their brief encounters. How do the molecular assemblies in cells achieve the required sensitivity and specificity? Efficient signal transduction must maintain fidelity and decrease noise while amplifying the signal Indeed, populations of alternative encounter complexes will probably be even more evident in highly transient protein–protein interactions , such as those involved in the inter-protein electron-transfer processes that occur in cellular metabolism Indeed, rigid-body docking calculations based on optimization of the binding energy of the interacting molecules already describe a pool of alternative encounter complexes on the way to forming the functional complex Interactions between proteins are highly prevalent in biology, and the sorts of transient interaction revealed by Tang et al . are not captured in the crystals that are the basis of many structural studies, so this dynamic approach will be useful in many other cases It has been suggested that hydrophobicity is involved in reorientating the molecules to form the final, productive complex  It is becoming increasingly clear that most switches, transducers and adaptors in living systems are created by the assembly and disassembly of multi-component complexes of proteins, nucleic acids and other molecules  It is now apparent that rare encounter complexes might control not only the kinetics of the assembly process, but also the way the complex is put together and hence its cooperativity Just like electrical and engineering control systems, living cells have complex signalling pathways that are moderated by feedback mechanisms Less studied, however, is the role of short-range desolvation effects — where the protein–protein interactions force solvent molecules away from the proteins — during and after collisions Living cells, particularly during growth and proliferation, need regulatory processes of great sensitivity and high specificity Many fundamental questions remain about the structure and energetics of these encounter complexes Molecular-dynamics simulations show that some encounter complexes could be sufficiently long-lived for their side chains to acquire a variety of conformational states, some of which are similar to those in the final, functional complex  Neither the final, specific complex structure (previously solved by NMR) nor any other single alternative conformation alone can account fully for their data On page 383 of this issue, Tang et al . follow the formation of such complexes, and provide structural evidence for the transient interactions necessary to build them *  Rather, it seems to lie in first assembling weak binary complexes, and then using cooperative interactions to produce multi-component complexes in which the weak interactions are replaced by much stronger and more specific interactions  Recent studies are beginning to describe the dynamics of the assembly processes and to show that nonspecific, transient collisions play an important role in macromolecular associations So the solution cannot be explained in terms of tightly bound, enduring molecular complexes, because the signals could not then be turned off Tang et al . describe structural features of the encounter complexes (assuming that they interact as rigid bodies), and their results are consistent with the general idea of a funnel-shaped binding-energy well that narrows as the two proteins approach one another Tang et al . study a bacterial signalling system called the phosphotransferase system, and describe evidence for rare encounter complexes involving the amino-terminal domain of enzyme I and the phosphocarrier protein HPr The authors mutated one of the proteins at specific sites, introducing a paramagnetic atom that causes local perturbations in the magnetic field The role of long-range electrostatic forces in bringing molecules together before they collide has been studied from both experimental and theoretical viewpoints , and it is clearly a major driving force in the formation of the rare encounter complexes described by Tang and colleagues They thus provide structural evidence for the rare encounter complexes, and suggest that electrostatic interactions have a major role in forming these intermediates ( Fig. 1 ; see also Fig. 3a of the paper on page 385 ) This implies that there are many possible routes for arriving at the final complex at the bottom of the energy well, and that these are determined by transient interactions between the partners in the encounter complexes, with the pathways converging as they get lower in energy and closer to the final complex This paramagnetic approach has already proved helpful for detecting rare equilibrium intermediates in protein–DNA interactions  To achieve this, signal-to-noise ratios must be high when information is received and transmitted between the cell surface, the cytoplasm and the nucleus Using a technique that is sensitive to these perturbations (intermolecular paramagnetic relaxation enhancement), they show that a variety of transient, nonspecific encounter complexes of the two proteins are present under equilibrium conditions Whether these ensembles of orientations reflect the true binding-energy landscape will depend on the accuracy of the energy description of these computer models and the efficiency of the sampling method, an area of current debate
 Glutamate-mediated damage to oligodendrocytes contributes to mental or physical impairment in periventricular leukomalacia (pre- or perinatal white matter injury leading to cerebral palsy), spinal cord injury, multiple sclerosis and stroke  Here we show that precursor, immature and mature oligodendrocytes in the white matter of the cerebellum and corpus callosum exhibit NMDA-evoked currents, mediated by receptors that are blocked only weakly by Mg 2+ and that may contain NR1 , NR2C and NR3 NMDA receptor subunits It is believed that glutamate damages oligodendrocytes, especially their precursor cells, by acting on calcium-permeable AMPA (α-amino-3-hydroxy-5-methyl-4-isoxazole propionic acid)/kainate receptors alone or by reversing cystine–glutamate exchange and depriving cells of antioxidant protection  NMDA receptors are present in the myelinating processes of oligodendrocytes, where the small intracellular space could lead to a large rise in intracellular ion concentration in response to NMDA receptor activation Simulating ischaemia led to development of an inward current in oligodendrocytes, which was partly mediated by NMDA receptors These results point to NMDA receptors of unusual subunit composition as a potential therapeutic target for preventing white matter damage in a variety of diseases. Unlike neurons , white matter oligodendrocytes reportedly lack NMDA ( N -methyl- d -aspartate) receptors  Antibody against the oligodendrocyte transcription factor Olig2 labelled all ten cells tested (seven precursors, one immature and two mature cells) Cells were identified on the basis of post-recording dye-fill morphology and antibody labelling Electrode junction potentials were compensated However, some NG2 cells may be a glial class distinct from oligodendrocytes , or (in grey matter) neuronal precursors  I – V relations were from responses to 200-ms voltage steps Immunocytochemistry Antibody labelling and post-embedding electron microscopic immunocytochemistry are described in the Supplementary Material  MBP antibody labelled all 17 cells with mature morphology that were tested Methods Brain slices Cerebellar or forebrain slices (225-µm thick) were prepared from P7–14 rats in solution containing 1 mM sodium kynurenate to block glutamate receptors NG2 antibody labelled 15 out of 15 tested cells with precursor morphology. (We take NG2 labelling to indicate oligodendrocyte precursors  Oligodendrocytes could be distinguished from astrocytes, which showed gap junction coupling (as revealed by Lucifer yellow spreading to other cells and GFAP labelling; 5 out of 5 cells) Omitting glycine or adding d -serine did not affect the NMDA receptor current (see text) P values are from Students two-tailed t -tests except for multiple comparisons, which were done using one-way analysis of variance (ANOVA) and Tukeys post-hoc tests. Recording and cell identification White matter cells (avoiding cerebellar nuclei) were whole-cell clamped with pipettes containing a K + -based solution (for glutamate application) consisting of 130 mM KCl, 4 mM NaCl, 0.5 mM CaCl 2 , 10 mM HEPES, 10 mM EGTA, 2 mM MgATP, 0.5 mM Na 2 GTP, 2 mM K-Lucifer yellow, pH 7.2 (adjusted with KOH), or a Cs + -based solution (for NMDA application and ischaemia) consisting of 130 mM CsCl, 4 mM NaCl, 0.5 mM CaCl 2 , 10 mM HEPES, 10 mM BAPTA, 2 mM MgATP, 0.5 mM Na 2 GTP, 2 mM K-Lucifer yellow, pH 7.2 (adjusted with CsOH) Series resistance was 8–20 MΩ, before 60% compensation Showing that oligodendrocytes express NMDA receptors does not depend on recording precursor cells, as NMDA receptor currents were also seen in immature and mature cells.) O4 antibody labelled 6 out of 6 cells with immature morphology Slices were superfused at 33 ± 1 °C with bicarbonate-buffered solution (for ischaemia experiments) containing 126 mM NaCl, 24 mM NaHCO 3 , 1 mM NaH 2 PO4, 2.5 mM KCl, 2 mM MgCl 2 , 2.5 mM CaCl 2 , 10 mM glucose, 0.1 mM glycine (which activates the NMDA receptor glycine-binding site) and 0.005 mM strychnine (which blocks glycine receptors), bubbled with 95% O 2 , 5% CO 2 (pH 7.4); or at 24 ± 1 °C with HEPES-buffered solution (for non-ischaemia experiments) containing 144 mM NaCl, 2.5 mM KCl, 2 mM MgCl 2 , 10 mM HEPES, 1 mM NaH 2 PO 4 , 2.5 mM CaCl 2 , 10 mM glucose, 0.1 mM glycine and 0.005 mM strychnine, with the pH set to 7.4 using NaOH Statistics Data are presented as mean ± s.e.m The cerebellum myelinates relatively late, facilitating investigation of different developmental stages The corpus callosum is an area that becomes thinned in severe periventricular leukomalacia To simulate ischaemia, we replaced external O 2 with N 2 , and external glucose with 7 mM sucrose, added 2 mM iodoacetate to block glycolysis, and added 100 µM rotenone or 25 µM antimycin to block oxidative phosphorylation  Without iodoacetate and rotenone/antimycin, it took ∼3-fold longer for the ischaemia-evoked inward current to develop, probably because in an open chamber O 2 can diffuse to the slice, allowing glycogen metabolism in mitochondria for longer than would occur in vivo  A solution simulating ischaemia evoked a slowly developing inward current in precursor and mature oligodendrocytes ( Fig. 4 , peak inward current at -63 mV after ∼7 min was 307 ± 83 pA and 280 ± 48 pA in 7 precursor and 8 mature cells, respectively, in 2 mM Mg 2+ ) Although the NMDA receptor subunit composition currently remains uncertain, it allows these receptors to generate a significant current even at the resting potential in a physiological extracellular Mg 2+ concentration Antibodies directed against NMDA receptor subunits labelled the myelinating processes, and some cell bodies, of oligodendrocytes in the cerebellar white matter Antibody labelling ( Fig. 3 ) and the voltage-dependence of the current ( Fig. 2m ) show that oligodendrocytes themselves express NMDA receptors As oligodendrocyte NMDA receptor currents occur in both the cerebellum and corpus callosum ( Fig. 2 ), they may represent a general property of white matter oligodendrocytes Blocking AMPA/kainate receptors attenuates white matter injury in animal models of hypoxia/ischaemia , spinal cord injury and multiple sclerosis  By quantifying the immunogold particles in the myelin and in the postsynaptic densities of mossy fibre–granule cell synapses ( Supplementary Fig. 5 ) and parallel fibre–Purkinje cell synapses, we found that the density of NMDA receptors throughout the myelin is as high as at the mossy fibre–granule cell synapse ( Fig. 3g ) Changing from Mg 2+ -free superfusion solution to solution containing 2 mM Mg 2+ decreased the NMDA-evoked current at -63 mV three- to fivefold, independent of developmental age ( Fig. 2k , l ) Double-labelling showed colocalization of NR3 and NR2C subunits, and of NR1 and NR2C subunits in oligodendrocyte processes ( Supplementary Figs 3, 4 ) Further work is needed to establish the origin of the part of the inward current that is not generated by glutamate release Here we have shown that oligodendrocytes express functional NMDA receptors However, NMDA receptors have been found in some cultured oligodendrocyte precursors and in spinal grey (but not white) matter oligodendrocytes , and NMDA receptor blockers have been shown to slow the loss of action potentials in white matter and reduce damage to white matter in ischaemia and in a model of multiple sclerosis  Ifenprodil (10 µM), which blocks NR2B-containing NMDA receptors, had no effect on the NMDA-evoked current ( Fig. 2j ) Immature cells ( Fig. 1b ) had some processes aligned with adjacent axons, and were labelled by an antibody against O4 lipid sulphatide In cerebellar oligodendrocytes, the NMDA-evoked current was largest in mature cells ( Fig. 2f , P = 0.042 compared with precursors) although the increased membrane area of mature cells may imply a lower current density In mature oligodendrocytes, the fraction of the inward current that was generated by glutamate was smaller than in precursor cells ( Fig. 4d ), suggesting that (as mature cells can generate larger glutamate- and NMDA-evoked currents; Figs 1f , 2f ) less glutamate release occurs around mature cells during ischaemia In mature oligodendrocytes, the I – V relationship often failed to reverse at positive potentials, which might reflect the NMDA receptors being electrotonically distant from the soma in the cell processes (see below), or NMDA receptor activation leading to Na + entry and block of a K + current in the cell  In precursor oligodendrocytes, the NMDA-evoked current reversed around 0 mV ( Fig. 2m ), and in 2 mM Mg 2+ the current–voltage ( I – V ) relationship showed a region of negative slope that was similar to, but less marked than, that produced by Mg 2+ -block of neuronal NMDA receptor channels In some precursor oligodendrocytes ( Fig. 4a , c ), the inward current early in ischaemia included an increased frequency of synaptic current-like events ( Fig. 1d ), presumably reflecting exocytotic transmitter release triggered by action potentials or an increase in axonal [Ca 2+ ] i  Indeed, in the optic nerve, activation of NMDA receptors on oligodendrocyte processes when glutamate is released during ischaemia leads to the disintegration of those processes  Labelling was also seen for NR1 subunits, which colocalized with MBP in mature cells (data not shown), and for NR3 subunits ( Fig. 3c , d and Supplementary Fig. 2 ) Mature cells ( Fig. 1c ) had most of their processes aligned with axons, and were labelled by an antibody against myelin basic protein (MBP) NMDA (60 µM) evoked an inward current in corpus callosum ( Fig. 2a–c ) and cerebellum ( Fig. 2d , e ) oligodendrocytes that was comparable in size (at -63 mV in 0 mM Mg 2+ ) to the current produced by AMPA (20 µM) or kainate (30 µM), and was larger than that produced by the metabotropic glutamate receptor agonist (1 S ,3 R )-ACPD ((1 S ,3 R )-1-aminocyclopentane-1,3-dicarboxylic acid; 100 µM) Notably, NMDA receptors are present in the myelinating processes of oligodendrocytes, where the intracellular volume is small and receptor-mediated ion influx may produce large increases in intracellular ion concentration and osmotic water flux, which could disrupt myelination C labelling ( Fig. 3a , b ) was abolished by omitting the primary antibody, or by preabsorption with the peptide to which it was raised ( Supplementary Fig. 2 ) Oligodendrocyte membrane resistance decreased with maturity ( Fig. 1e ) Oligodendrocyte NMDA receptors are likely to have a role in controlling oligodendrocyte development and myelination , and in damaging oligodendrocytes under pathological conditions Our data ( Fig. 2a ) contradict the absence of NMDA responses reported in corpus callosum oligodendrocytes  Our electrophysiological recordings are from precursor, immature and mature oligodendrocytes in postnatal day (P)7–14 rats, and remain to be extended to the adult; however, NMDA receptor subunits are also present in adult oligodendrocytes ( Fig. 3e ) Post-embedding electron microscopic immunochemistry showed that NR1 subunits were present in the myelinating processes of adult cerebellar oligodendrocytes ( Fig. 3e , f and Supplementary Fig. 5 ), in the outer- and innermost membranes and also within the myelin (perhaps remaining from earlier in development) Precursor cells ( Fig. 1a ) had short processes not aligned with nearby axons, were labelled by antibodies against NG2 proteoglycan (see Methods for details regarding specificity), and often showed spontaneous synaptic currents (similar to grey matter oligodendrocyte precursors ) that were blocked by tetrodotoxin (TTX; Fig. 1d ) Precursor, immature and mature cerebellar white matter oligodendrocytes responded to glutamate (100 µM) with an inward current at -63 mV, which was unaffected by application of 1 µM TTX ( P = 0.4; Fig. 1f–h and Supplementary Fig. 1 ), showing that axonal action potentials generated by glutamate depolarizing neurons did not contribute to the current (for example, by releasing K + ) Previous work that failed to detect NMDA receptor currents in oligodendrocytes was partly on cultured cells , which may downregulate their NMDA receptor expression The current was also unaffected by pregnenolone sulphate (100 µM, which potentiates NR1/NR2A and NR1/NR2B receptors by 60–82% but inhibits NR1/NR2C and NR1/NR2D receptors by 32%), d -cycloserine (1 mM, with no added glycine, which potentiates NR1/NR2C receptors but inhibits NR1/NR2A and NR1/NR2B receptors) or d -serine (100 µM, with no glycine, which potentiates receptors lacking NR3 subunits but inhibits NR3-containing receptors) ( Fig. 2j ) The current was potentiated when the local glutamate concentration was raised by blocking glutamate transporters with TBOA (threo-β-benzyloxyaspartate, P = 0.016; Fig. 1g and Supplementary Fig. 1 ) The density of particles in the outer membrane of the myelin (where the receptors may sense glutamate released from surrounding cells; 36.4 ± 8.3 particles per µm 2 ) tended to be larger than that in the innermost membrane (where the receptors may sense glutamate released from the axon; 17.7 ± 4.3 particles per µm 2 , P = 0.064), but both were similar to the average density measured over all of the myelin (33.6 ± 4.5 particles per µm 2 ) The higher glutamate affinity of NMDA receptors relative to AMPA receptors makes them more likely to be activated in neurodegenerative disorders that involve a small but prolonged increase in extracellular glutamate concentration, as can occur in multiple sclerosis The NMDA receptor antagonists d -AP5 ( d (-)-2-amino-5-phosphonovaleric acid) and MK801, and the AMPA receptor antagonist NBQX (2,3-dioxo-6-nitro-1,2,3,4-tetrahydrobenzo[f]quinoxaline-7-sulphonamide) all reduced the glutamate-evoked current ( Fig. 1h , i ), suggesting the presence of both NMDA and AMPA/kainate receptors The NMDA receptor-mediated current in precursor oligodendrocytes was on average 50% larger than that mediated by AMPA/kainate receptors ( Fig. 4b–d ), and in some cells comprised almost all of the current ( Fig. 4c ) The NMDA-evoked current ran down slightly with time ( Fig. 2g ), so current measurements in the presence of drug treatments were quantified relative to the average of control responses before and after drug application The NMDA-evoked current was blocked by d -AP5 ( Fig. 2h , j ) but unaffected by TTX, NBQX or strychnine + bicuculline ( Fig. 2i , j ), and was not significantly affected ( P = 0.072) when glycine (100 µM, with 5 µM strychnine) was present, implying that the glycine-binding sites on these NMDA receptors are well-activated by endogenous glycine or d -serine The NMDA-evoked currents that we observe are unlikely to be produced by an agent released secondarily from neurons because they are unaffected by TTX or by block of AMPA/kainate, metabotropic glutamate receptors, GABA A or glycine receptors ( Figs 1i , 2j ), and oligodendrocytes show no current in response to application of noradrenaline, dopamine, histamine, serotonin, ATP, adenosine or acetylcholine (data not shown) The relative contribution of NMDA and AMPA receptors to the glutamate-mediated current was analysed in Mg 2+ -free solution to detect NMDA receptor currents more accurately (in 2 mM Mg 2+ , the NMDA component at -63 mV would be fourfold smaller ( Fig. 2l ), but would be increased in unclamped cells by the ischaemia-evoked current depolarizing cells and reducing NMDA receptor Mg 2+ -block) The resting potential was approximately -60 mV (- 57.5 ± 2.9 mV in 37 mature cells; without shunting by the electrode seal it would be ∼4 mV more negative) The unusual subunit combination of these receptors, which may contain NR1, NR2C and NR3 subunits, suggests that they might be a useful therapeutic target in a variety of brain disorders. These data, together with the lack of ifenprodil-induced block and the weak Mg 2+ -block of the NMDA-evoked current, suggest that oligodendrocyte NMDA receptors contain at least NR1, NR2C and NR3 subunits These results suggest either (1) the presence of a subunit (perhaps NR3) that suppresses modulatory actions on NR2 subunits, or (2) the presence of a combination of subunits that these agents modulate in opposite directions (for example, NR1/NR2A/NR2C or NR1/NR2/NR3), or (3) a mixture of receptors with different subunit combinations They show only weak block by Mg 2+ at the cells resting potential ( Fig. 2l ), and mediate part of the inward current generated in oligodendrocytes in response to simulation of the energy deprivation that occurs in periventricular leukomalacia, in stroke, and after ischaemia in spinal cord injury This current was generated partly by an increase in extracellular glutamate concentration, as it was reduced by d -AP5 and NBQX ( Fig. 4a ) This decrease is much less than is found for most neurons or for most cloned NMDA receptors , which show a 60-fold reduction for receptors comprising NR1 and NR2A or NR2B subunits, and a 20-fold reduction for receptors comprising NR1 and NR2C or NR2D subunits, but is comparable to that seen for cloned receptors comprising NR1, NR2A and NR3A subunits  Thus, oligodendrocyte NMDA receptors could contribute to causing the white matter damage that occurs when the extracellular glutamate concentration is increased in periventricular leukomalacia, spinal cord injury, multiple sclerosis and stroke  To examine the role of oligodendrocyte NMDA receptors in pathological situations, we simulated the energy deprivation that contributes to periventricular leukomalacia or that occurs after ischaemia in spinal cord injury We have therefore re-examined the involvement of NMDA receptors in the physiology and pathology of oligodendrocytes Weaker labelling was seen for NR2A, NR2B and NR2D, and was abolished by omitting the primary antibody (NR2A, NR2B and NR2D) or by peptide absorption (NR2D) Whole-cell clamped precursor, immature and mature oligodendrocytes in white matter were distinguished by their morphology and antibody labelling ( Fig. 1a–c )
 Beneath other continents, azimuthal anisotropy is only weakly correlated with plate motion and its depth location is similar to that found beneath oceans Differences in the thickness of the high-velocity lid underlying continents as imaged by seismic tomography, have fuelled a long debate on the origin of the ‘roots’ of continents  Here we report global observations of surface-wave azimuthal anisotropy, which indicate that only the continental portion of the Australian plate displays significant azimuthal anisotropy and strong correlation with present-day plate motion in the depth range 175–300 km Simple shear leading to anisotropy with a plunging axis of symmetry may explain the smaller azimuthal anisotropy beneath other continents. Some of these differences may be reconciled by observations of radial anisotropy between 250 and 300 km depth, with horizontally polarized shear waves travelling faster than vertically polarized ones  Such deformation would also produce significant azimuthal variation, owing to the preferred alignment of highly anisotropic minerals  This azimuthally averaged anisotropy could arise from present-day deformation at the base of the plate, as has been found for shallower depths beneath ocean basins  We infer that the fast-moving Australian plate contains the only continental region with a sufficiently large deformation at its base to be transformed into azimuthal anisotropy Azimuthal anisotropy is guaranteed to be resolved when the size of the Voronoi cells in Supplementary Fig. 3 is smaller than, or comparable to, a circular surface with a minimum diameter of about 1,000 km Azimuthal anisotropy resolution is achieved for 1,000-km circular regions beneath most continents and at the Voronoi level for western Africa and Antartica Both the non-azimuthal term and the direction of fast seismic velocities extracted from the cos(2 θ ), sin(2 θ ) azimuthal terms are represented on Fig. 1  First, an automated nonlinear waveform inversion technique is used to model each individual Rayleigh waveform in terms of a depth-dependent SV-wave velocity model representing the average mantle structure along the path For an olivine model, the direction of maximum velocity coincides with the horizontal projection of the fast a axis of olivine crystals Furthermore, vertical smearing ( Supplementary Fig. 5 ) can bias the splitting prediction ( Supplementary Fig. 6b ), and the SKS predictions themselves ( Supplementary Fig. 6c ) rely on a theory that does not properly handle inclined symmetry axes and is only effective for rather long period waves. However, it provides a useful proxy for resolution when combined with the horizontal degree of smoothing imposed a priori on the tomographic inversion In a long period approximation, the one-dimensional SV-wave velocity models obtained after the waveform fitting depend on these three combinations of elastic parameters, which control the velocities of SV waves propagating horizontally for azimuth θ (ref. 29 ) In fact, the length scales over which SKS results vary in continental regions are often below the horizontal resolution of surface waves Methods Our model is an ‘SV’ model constrained by fundamental and higher mode Rayleigh waves (as in ref. 4 ), but we include azimuthal anisotropy in the inversion and include many short epicentre–station paths (see Supplementary Fig. 2 ) to improve the lateral resolution of upper mantle structure  Model construction Our model is built using a two step tomographic procedure  Resolution issues and model tests A Voronoi diagram built using the approach of ref. 25 (see Supplementary Fig. 3 ) provides a useful guide to our ability to resolve azimuthal anisotropy with our data coverage The azimuthal terms can also be inverted in depth, as they depend on several combinations of the elastic parameters via a set of partial derivatives proportional to the partial derivatives of a transversely isotropic medium with a vertical axis of symmetry  The cells in Supplementary Fig. 3 are the smallest for which the local distribution of rays ensures that the cos(2 θ ), sin(2 θ ) SV-wave azimuthal variation can be resolved The combinations of elastic parameters best resolved by Rayleigh waves involve at each depth an isotropic term that corresponds to the SV-wave velocity and two azimuthal terms that display a variation in cos(2 θ ), sin(2 θ ) relative to the direction of maximum velocity The data set consists of 100,779 Rayleigh waveforms that provide a dense global coverage (see Supplementary Fig. 1 ), although variations due to the uneven distribution of events and station are inevitable The number of crossing rays per cell (400 × 400 km) varies between 20 and 2,800 for continents, ensuring redundancy in the data even where ray coverage is the poorest (Africa and Antarctica) The one-dimensional path-average models are then combined in a tomographic inversion to retrieve simultaneously the three-dimensional SV-wave velocity structure and the azimuthal anisotropy of SV waves The procedure exploits the azimuthal dependence of the Rayleigh wave phase and group velocities in a slightly anisotropic medium  This azimuthal dependence contains terms in cos(2 θ ), sin(2 θ ) and cos(4 θ ), sin(4 θ ), where θ is the azimuth relative to north, and has been recently inverted to retrieve the global azimuthal variations in the group or phase velocities at different periods  This ‘optimized Voronoi’ diagram is based on the ray distribution alone and does not incorporate any a priori information on the data or the model, nor does it take into account the influence of different parameter choices We have found (1) that contamination by non-inverted parameters, such as the 4 θ azimuthal variation of the Rayleigh waves phase velocity or the B and H combinations of elastic coefficients as defined in ref. 28 , is weak ( Supplementary Fig. 4 ), (2) that our vertical resolution is sufficient to recover a change in anisotropic direction at the bottom of continental plates ( Supplementary Fig. 5 ), and (3) that it is not possible to make accurate predictions of SKS observations from our tomographic model We have performed a variety of tests using real and synthetic data to estimate potential leakage by non-inverted parameters, vertical resolution and how well our model can predict SKS observations We impose lateral smoothness through a gaussian correlation function with a standard deviation of 400 km, chosen to minimize the trade-off between isotropic and anisotropic parameters A vertically travelling wave passing through two anisotropic layers with orthogonal directions as found beneath Australia ( Fig. 1 ) would undergo a null or very weak splitting if each layer produced a similar time separation between the fast and slow polarized S-waves Additional data will be needed to investigate in more detail the global pattern of radial anisotropy in seismic parameters and to reconcile it with other anisotropic observations Although an accurate prediction of SKS splitting from surface wave azimuthal anisotropy models is not possible (see Methods), we believe that our results provide a qualitative explanation for the differences in SKS observations between Australia and the other continents  Although seismic anisotropy provides a unique way to investigate deformation of the upper mantle, it is increasingly clear that the assumptions underlying anisotropic observations must continue to be questioned. At 100 and 150 km depth, the regions where anisotropy correlates with APM shift to the old oceanic basins At 100 km depth, the amplitude of azimuthal anisotropy generally exceeds 2% beneath young oceans, and exhibits highly variable amplitudes beneath continents and old oceanic basins At 200 km depth, the only continent where plate-scale anisotropy is larger than 2% is Australia At depths greater than 220 km, enrichment in clinopyroxene may also contribute to the vanishing of anisotropy  Azimuthal anisotropy of continents other than Australia does not correlate at any depth with APM Beneath other continents, weak influence of basal drag on the lithosphere may explain why azimuthal anisotropy is observed only in a layer located in the uppermost 100 km of the mantle Complications occur under water-rich conditions that are not common in the upper mantle and are probably confined to subduction zones or regions where upwelling material contains a large amount of water  Direct estimates of fast SV directions provide better vertical resolution compared to group or phase velocity measurements, which represent a weighted average of the structure/anisotropy over a frequency-dependent depth interval Except in the upper 100 km, Australia is completely different from other continents, which display a gentle decrease of anisotropy from 1.4% at 50 km to about 0.6% at 300 km depth Fast anisotropy directions beneath Australia do not correlate with APM at depths shallower than 150 km, but show strong correlation from 150 km to 300 km depth with a maximum near 200 km Figure 1 shows the azimuthal variations for SV waves superimposed on the pattern of seismic heterogeneities at 100 and 200 km depth in the upper mantle Figure 2a shows the average amplitude of azimuthal anisotropy as a function of depth in the upper mantle, calculated for Australia, other continents, and oceanic basins Figure 2b shows the average correlation between APM and fast anisotropic directions calculated for Australia, other continents, and oceanic basins For relatively water-poor olivine, modest simple shear should therefore produce anisotropy with a plunging a axis For surface waves, although the azimuthal variation of Rayleigh wave velocity gradually reduces when the a axis departs from the horizontal, the direction of the fastest Rayleigh waves remains in the vertical plane containing the a axis  Further, Australia is the only continental plate where azimuthal anisotropy correlates significantly with present-day plate motion However, the large SH SV radial anisotropy observed at the base of continents from 250 to 400 km depth by Gung et al. is hard to reconcile with our observation of small azimuthal anisotropy and with the typical 1 s delay time in SKS studies If the lattice-preferred orientation of olivine crystals is the main mechanism responsible for upper mantle anisotropy , the existence of significant azimuthal anisotropy with coherent directions over broad regions beneath Australia implies that radial anisotropy with SH (horizontally polarized) waves faster than SV waves should also be present to the same depth  In oceanic regions, the maximum amplitude of azimuthal anisotropy occurs near 100 km depth, in agreement with previous studies that have suggested an intense deformation at the base of oceanic plates  In the upper mantle, horizontally travelling surface waves provide better vertical resolution than body waves, which are more subject to vertical smearing owing to their steep incidence In young oceanic regions where the lithosphere is expected to be thin, significant correlation between anisotropy and APM is observed at 50 km depth ( Fig. 3 ) and extends over large regions around the mid-ocean ridges beneath the Pacific, Indian and Atlantic Oceans Laboratory experiments on olivine aggregates suggest that simple shear at the base of a moving plate will produce anisotropy in olivine with a fast a axis that follows the principal extension direction for modestly deformed aggregates and aligns with the direction of flow for large deformation  None of the other continents show significant plate-scale correlation between anisotropic directions and APM Other continents are associated with weak anisotropy, except locally beneath the Tibetan plateau and the Andean subduction zone Our finding comes in the context of the building of a new surface wave tomographic model of the upper mantle designed to investigate shear wave heterogeneities and azimuthal anisotropy Our model provides an explanation for SKS observations in continental regions, on the simple basis that anisotropy due to plate motion differs between continental plates Our path coverage (see Supplementary Fig. 1 ) allows us to resolve anisotropic variations with horizontal wavelengths matching the scale of the lithospheric blocks that have coalesced to form continents (about 1,000–1,500 km) Our results therefore suggest that the Australian plate is the only continental plate whose motion is fast enough to produce large scale deformation at its base Plate-scale anisotropy has also disappeared beneath oceans except beneath the northern Pacific, where weak ( 1%) azimuthal anisotropy extends over a broad region Radial anisotropy with SH velocities greater than SV velocities (‘SH SV’) has indeed been observed beneath Australia down to at least 250 km depth in previous regional and global studies  SKS studies generally show typical delay times close to 1 s in most continental regions , but only null or very weak splitting beneath Australia Small scale convection due to irregularities of the base of the high-velocity lid or perturbations by mantle plumes can produce such effects The anisotropic signature of the Australian plate is similar to that observed at shallower depths beneath oceans The complex organization of surface wave azimuthal anisotropy present within this layer, and the good agreement between SKS fast directions and fossil geological trends generally observed for continents other than Australia, form the basis for attributing this shallow anisotropic layer (whose thickness is compatible with typical observed SKS delay times) to deformation frozen in the lithosphere The depth configuration of azimuthal anisotropy beneath Australia in the depth range 150–300 km is similar to that beneath oceans in the depth range 50–200 km but shifted downward by 100 km The fast direction beneath the oceans displays, on average, a weaker correlation with APM between 100 and 250 km depth The novelty of our approach is to directly extract from surface waves the directions of fast propagation for horizontally travelling ‘SV’ (vertically polarized) waves, with an unprecedented lateral resolution at a global scale, instead of determining anisotropy in group or phase velocity, as in other recent studies  The similar depth behaviour and complex organization of anisotropy down to about 150 km depth observed beneath Australia and other continents ( Figs 1 and 2a ) suggests that frozen deformation in the lithosphere is also the explanation of shallow upper mantle azimuthal anisotropy beneath Australia The slower horizontal motion of other continental plates may produce smaller basal deformation, and thus a larger proportion of olivine crystals with a plunging axis of symmetry and a weaker azimuthal anisotropy The strong correlation between Australian anisotropy and APM is prominent between 150 and 300 km depth There is no systematic difference in the depth location of azimuthal anisotropy between continents and oceans, except beneath Australia This agrees with previous regional surface wave tomography for the continent  This basal drag mechanism can explain both the radial and the azimuthal anisotropy of the Australian continent This incompatibility provides a global scale illustration of the problem of explaining the amplitude of surface wave radial anisotropy with current petrological models, a well-documented problem in regional studies  This peculiar behaviour of the Australian continent is highlighted in the global correlation ( Fig. 3 ) between azimuthal anisotropy and the present-day absolute plate motion (APM) This shift suggests that the depth of plate-motion-induced deformation increases with the age of the sea floor and the thickness of the oceanic lithosphere This weaker correlation between oceanic anisotropy and APM can be related to the observation that azimuthal anisotropy beneath oceans aligns better with the largest axis of the finite-strain ellipsoid than with the absolute plate motion al anisotropy with weak azimuthal anisotropy, the olivine crystals need to be preferentially aligned in the horizontal plane, but randomly oriented We can therefore better differentiate between different ways of producing anisotropy: the effect of plate motion would be expected to be smooth at continental scale, whereas ancient deformation frozen in the lithosphere displays shorter-scale lateral variations owing to the complex tectonic history of continents Weak azimuthal anisotropy as observed under other continents is compatible with a modest SH SV radial anisotropy depending on the dip and proportion of oriented olivine crystals When old continents are underlain by significant azimuthal anisotropy (as in Australia, India, and North and South America), the anisotropy varies over short horizontal distances
 But multiple traps are not the only benefit of holographic optical trapping. “You can select from a variety of trap shapes with different properties,” says Mueth. “There are plenty of other advantages that are more subtle but can have an impact, and have to do with optimizing performance and the ability to work with particular samples.”  M.E. Cell Robotics of Albuquerque, New Mexico, also offers an off-the-shelf system: LaserTweezers, an adjustable single-trap system that is designed for integration with a standard inverted microscope, and which can also be incorporated as a module of a larger workstation to allow computerized control and full automation Many current users build their systems from scratch — a daunting and expensive prospect for the optics novice Never mind Star Wars, lasers are good for more than burning and cutting, and in fact can be surprisingly gentle Since their development in 1986, optical tweezers have generated a veritable bounty of valuable information, including insights into the physical properties of DNA molecules and the fundamental mechanisms of various enzymes and molecular motors Single-beam traps enable impressive experiments, but the future clearly lies in higher-throughput platforms. “The technology has always been associated with one to ten particles,” says Dholakia. “I would like to see thousands of particles being ordered and sorted in a really rapid fashion.”  Enter Arryx of Chicago, Illinois; its BioRyx 200 system uses holographic technology to expand the number of tweezers simultaneously available to users. “It can generate up to 200 traps in a three-dimensional working volume, each of which is independently movable in real-time,” says chief technology officer Dan Mueth. “You can pull on cells and sense or measure how they stretch, grab cells and move them around, probe the adhesion of cells, position cells for investigation, or isolate cells.”  The BioRyx 200 also offers a software interface that enables real-time manipulation or automation of the traps Take ‘optical tweezers’, for example — a laser focused on a microscopic object creates an optical force trap that enables the precise manipulation of that object within a three-dimensional space The E3100 is available from Elliot Scientific in Harpenden, UK They have also shown considerable promise for cell manipulation, although biologists have yet to fully explore their potential. “We have to educate people and make them comfortable with optical technology,” says Kishan Dholakia, who heads the optical-trapping group at the University of St Andrews, UK To remedy this, Dholakias team has lent its expertise to develop an entry-level, single-beam optical-tweezers workstation — the E3100 — for biologists looking to get their feet wet
 Around M-dwarf stars (the most common stars in our Galaxy), this model favours the formation of Earth-mass ( M ⊕ ) to Neptune-mass planets with orbital radii of 1 to 10 astronomical units ( au) , which is consistent with the small number of gas giant planets known to orbit M-dwarf host stars  Here we report the discovery of a 5.5 +5.5-2.7 M ⊕  planetary companion at a separation of 2.6 +1.5-0.6   au from a 0.22 +0.21-0.11 M circdot; M-dwarf star, where M circdot; refers to a solar mass. (We propose to name it OGLE-2005-BLG-390Lb, indicating a planetary mass companion to the lens star of the microlensing event.) The mass is lower than that of GJ876d (ref. 5 ), although the error bars overlap In the favoured core-accretion model of formation of planetary systems, solid planetesimals accumulate to build up planetary cores, which then accrete nebular gas if they are sufficiently massive More than 170 extrasolar planets have been discovered with a wide range of masses and orbital periods, but planets of Neptunes mass or less have not hitherto been detected at separations of more than 0.15  au from normal stars Our detection suggests that such cool, sub-Neptune-mass planets may be more common than gas giant planets, as predicted by the core accretion theory. A decade of pioneering microlensing searches has resulted in the recent detections of two Jupiter-mass extrasolar planets with orbital separations of a few au by the combined observations of the OGLE, MOA, MicroFUN and PLANET collaborations After peaking at a maximum magnification of A max = 3.0 on 31 July 2005, a short-duration deviation from a single lens light curve was detected on 9 August 2005 by PLANET Although the planet and star masses are not directly determined for planetary microlensing events, we can derive their probability densities As described below, this deviation was due to a low-mass planet orbiting the lens star Figure 1 shows our photometric data for microlensing event OGLE-2005-BLG-390 and the best planetary binary lens model Four different binary lens modelling codes were used to confirm that the model we present is the only acceptable model for the observed light curve From analysis of colour-magnitude diagrams, we derive the following reddening-corrected colours and magnitudes for the source star: ( V - I ) 0 = 0.85, I 0 = 14.25 and ( V - K ) 0 = 1.9 Gravitational microlensing events can reveal extrasolar planets orbiting the foreground lens stars if the light curves are measured frequently enough to characterize planetary light curve deviations with features lasting a few hours  However, as shown in Fig. 1 , this model fails to account for the PLANET-Perth, PLANET-Danish and OGLE measurements near the end of the planetary deviation, and it is formally excluded by Δ χ  2 = 46.25 with one less model parameter In modelling the light curve, we adopted linear limb darkening laws with Γ  I = 0.538 and Γ  R = 0.626, appropriate for this G4 III giant source star, to describe the centre-to-limb variation of the intensity profile in the I and R bands Microlensing is most sensitive to planets in Earth-to-Jupiter-like orbits with semi-major axes in the range 1–5  au  Model length parameters in Table 1 are expressed in units of the Einstein ring radius R E (typically ∼2  au for a Galactic Bulge system), the size of the ring image that would be seen in the case of perfect lens–source alignment On 11 July 2005, the OGLE Early Warning System announced the microlensing event OGLE-2005-BLG-390 (right ascension α = 17 h 54 min 19.2 s, declination δ = -30° 22′ 38″, J2000) with a relatively bright clump giant as a source star Our discovery of such a low-mass planet by gravitational microlensing lends further support to this model, but more detections of similar and lower-mass planets over a wide range of orbits are clearly needed Planets with q 10 -3 and d ≈ 1 are much easier to detect, and so it may be that the parameters of OGLE-2005-BLG-390Lb represent a more common type of planet Planets with separations of ∼0.1  au will be detected routinely by the radial velocity method or space observations of planetary transits in the coming years , but the best chance to increase our understanding of such planets over orbits of 1–10  au in the next 5–10 years is by future interferometer programs and more advanced microlensing surveys . Similarly, the first detection of a sub-Neptune-mass planet at the outer edge of the ‘lensing zone’ provides a hint that these sub-Neptune-mass planets may tend to reside in orbits with semi-major axes a 2  au  Subsequently, PLANET, OGLE and MOA monitored it with their different telescopes The absence of perturbations to stellar microlensing events can be used to constrain the presence of planetary lens companions The best alternative model is one with a large-flux-ratio binary source with a single lens, which has gross features that are similar to a planetary microlensing event  The best-fit model has χ  2 = 562.26 for 650 data points, seven lens parameters, and 12 flux normalization parameters, for a total of 631 degrees of freedom The core-accretion model of planet formation predicts that rocky/icy 5–15 M ⊕  planets orbiting their host stars at 1–10  au are much more common than Jupiter-mass planets, and this prediction is consistent with the small fraction of M-dwarfs with planets detected by radial velocities and with previous limits from microlensing  The host star and planet parameter probability densities for a main sequence lens star are shown in Fig. 2 for the Galactic model used in ref. 23  The medians of the lens parameter probability distributions yield a companion mass of 5.5 - 2.7 + 5.5 M ⊕  and an orbital separation of 2.6 - 0.6 + 1.5   au from the 0.22 +0.21-0.11 M circdot; lens star, which is located at a distance of D L = 6.6 ± 1.0 kpc The microlensing fit only directly determines the planet–star mass ratio, q = 7.6 ± 0.7 × 10 -5 , and the projected planet–star separation, d = 1.610 ± 0.008 R E  The parameters of this event are near the limits of microlensing planet detectability for a giant source star The PLANET collaboration maintains the high sampling rate required to detect low-mass planets while monitoring the most promising of the 500 microlensing events discovered annually by the OGLE collaboration, as well as events discovered by MOA The planet is designated OGLE-2005-BLG-390Lb, where the ‘Lb’ suffix indicates the secondary component of the lens system with a planetary mass ratio The sensitivity of the microlensing method to low-mass planets is restricted by the finite angular size of the source stars , limiting detections to planets of a few M ⊕  for giant source stars, but allowing the detection of planets as small as 0.1 M ⊕  for main-sequence source stars in the Galactic Bulge The separation of d = 1.61 is near the outer edge of the so-called lensing zone , which has the highest planet detection probability, and the planets mass is about a factor of two above the detection limit set by the finite size of the source star The source star colours indicate that it is a 5,200 K giant, which corresponds to a G4 III spectral type These error bars indicate the central 68% confidence interval These median parameters imply that the planet receives radiation from its host star that is only 0.1% of the radiation that the Earth receives from the Sun, so the probable surface temperature of the planet is ∼50 K, similar to the temperatures of Neptune and Pluto This analysis gives a 95% probability that the planetary host star is a main-sequence star, a 4% probability that it is a white dwarf, and a probability of 1% that it is a neutron star or black hole This can be quantified by simulating planetary light curves with different values of q and θ (where θ is the angle of source motion with respect to the lens axis) but the remaining parameters are fixed to the values for the three known microlensing planets This suggests that, at the orbital separations probed by microlensing, sub-Neptune-mass planets are significantly more common than large gas giants around the most common stars in our Galaxy We averaged over the distances and velocities of the lens and source stars, subject to the constraints due to the angular diameter of the source and the measured parameters given in Table 1  We find that the probability of detecting a q ≈ 4–7 × 10 -3 planet, like the first two microlens planets , is ∼50 times larger than the probability of detecting a q = 7.6 × 10 -5 planet like OGLE-2005-BLG-390Lb We have performed a bayesian analysis employing the Galactic models and mass functions described in refs 11 and 23  We used the surface brightness relation linking the emerging flux per solid angle of a light-emitting body to its colour, calibrated by interferometric observations, to derive an angular radius of 5.25 ± 0.73 µas, which corresponds to a source radius of 9.6 ± 1.3 R circdot; (where R circdot; is the radius of the Sun) if the source star is at a distance of 8.5 kpc With large samples of events, upper limits on the frequency of Jupiter-mass planets have been placed over an orbital range of 1–10  au , down to M ⊕  planets for the most common stars of our galaxy
 A spokesman for Google says that it will “respect the rights of copyright holders”, and that it “prefers to work directly with publishers to bring copyrighted books online” But Google has not yet struck any legal agreements with publishers, either individually or collectively, for the research-library initiative, says Sally Morris, chief executive of the Association of Learned and Professional Society Publishers, the international trade body for not-for-profit publishers But some publishers complain that they werent consulted by Google, and that scanning library collections could be illegal Clicking on a title would allow them to browse images of the full text of works in the public domain Copyright material generally carries some variation of a warning banning the reproduction, storage or distribution of copies of the work without the publishers permission Few publishers would want to opt out of the library scheme, Morris says — but they need to be asked to provide the appropriate permission Google describes the initiative as an extension of Google Print ( http://www.print.google.com ), which is based on agreements with publishers and allows the full text of books to be searched Google Prints results provide a brief excerpt of the text, together with a link to publishers or booksellers that sell the book and to libraries that hold it Google “has been working closely with publishers to help them connect with more readers online”, he adds Harvard is carrying out a pilot with Google on 40,000 titles before making a decision on digitizing its entire 15-million-volume collection. “We have a number of questions that will be answered by the pilot project, and that includes copyright issues,” he says. “We think it is a great programme Google has put together.” Late last year, Google, based in Mountain View, California, announced a decade-long project to scan millions of volumes at the universities of Harvard, Stanford, Michigan and Oxford, as well as the New York Public Library Nor would making copies for ‘fair use’, given that Google is a commercial company Only brief excerpts and bibliographic data would be shown for material under copyright Paris A spat is brewing between academic publishers and Google over the Internet-search companys plans to digitize and index library collections at major research universities Part of the uncertainty stems from the fact that there seems to have been little discussion so far between Google and publishers, says Terry Hulbert, head of electronic development and strategy at the UK Institute of Physics. “Someone clearly needs to have a chat with the 800-pound gorilla sat in the corner,” he observes. “There is no question that Google should have spoken to the learned societies and publishers beforehand Participating libraries would also be given a digital copy of their collection Scanning a book constitutes making a copy and so is only allowed with permission, say lawyers from several publishers Systematic digitization of copyright content is absolutely something they cannot do without seeking approval of the rights holders.”  Peter Kosewski, director of publications and communications at Harvard University Library, says the library believes that the way Google intends to handle copyright works is consistent with the law The resulting archive would allow computer users worldwide to search the texts online They also argue that an exception under US law that allows libraries to copy texts for preservation purposes would not apply in this case Under the scheme, people searching with Google would find library volumes relevant to their query at the top of their search results
 Bacterial pathogens are amazing because once you have the sequence, you can apply the awesome power of bacterial genetics to dig deeper into a bacterium than any other organism First we were part of decoding the human genome reference sequence George Weinstock from the Human Genome Sequencing Center at Baylor College of Medicine in Houston, Texas, drew on the skills of 174 collaborators to analyse the bees molecular features and gene content Given the large number of diseases that are being studied, the amount of sequencing is huge Having the human genome sequence was not the end — it provided the reference against which other human genomes can be compared for analysing disease How will your sequences contribute to personalized medicine in the future? They will have a big pay-off Many small changes account for this and it is possible that this reflects our limited knowledge of behavioural genetics Next was the HapMap project sampling human diversity Now we are scaling up for human mutation and disease-gene discovery Second, new sequencing technologies are just coming to market, offering greater capacity at lower cost, and this should have a dramatic effect. Studying a social insect such as the honeybee requires a social approach The group found tantalizing hints about how bees manage their societies — such as genes for nursing and gathering pollen — but no clear-cut drivers of social organization (see page 931 ) The human genome was our grail and accomplishing that still sends chills down my spine These activities will form the bedrock for personalized medicine We will tackle as many diseases as possible in the next few years, from cancer to psychiatric disorders Weinstock told Nature about his genetic hunt for animal behaviour What are you doing with the human genome? We are shifting the emphasis from deciphering whole genome sequences of animals to human mutation and disease-gene discovery What is the future of genome sequencing? First, there is a need for more DNA sequencing than ever before What was the biggest surprise about the bees genome? That we did not come up with breakthroughs in understanding social behaviour of the bee Which was the most fun? They all have their own beauty and fascination You have sequenced the genomes of humans, wasps, sea urchins, slime mould and bacteria
 A strain of avian flu that spread through a family in Indonesia, killing seven of the eight people infected, was accumulating mutations as it spread from person to person, according to confidential sequence data seen by Nature And he adds that although calls for more complete genome data and wider sharing of samples are “a valid point”, labs are stretched during outbreaks, and dont have the time or resources to do high-quality sequencing. newsad; He agrees that sharing samples with other researchers would allow such work to be done And there were no amino-acid changes in key receptor binding sites known to affect pathogenicity and transmissibility But experts say they cannot conclude that the changes arent significant. “It is interesting that we saw all these mutations in viruses that had gone human-to-human,” says one scientist who was present at the Jakarta meeting but did not wish to be named because he was commenting on confidential data. “But I dont think anyone knows enough about the H5N1 genome to say how significant that is.”  Elodie Ghedin, a genome scientist at the University of Pittsburgh School of Medicine in Pennsylvania, says shes surprised that the virus from the father had so many mutations compared with others in the cluster, apparently arising in just a few days. “I have a hard time believing that the father acquired the virus from his son,” she says, adding that the nine mutations in one gene in the fathers virus are almost identical to those in viruses isolated from human cases in Thailand and Vietnam in 2004 But he says the WHO must work within the constraints set by its member states — they own the data, and decide whether to share it. “As more countries share data, hopefully that research will get done,” he says But influenza researchers say the finding reiterates the need for sequence data to be made more widely available, if the virus is to be better understood But Paul Gully, who joined the WHO two months ago as senior adviser to Margaret Chan, head of the agencys pandemic-flu efforts, defends the agencys position Eight members of an extended family in Kubu Sembelang, in north Sumatra, were affected Ghedin, for example, works on how mutations in one area of a genome can predispose other areas to further changes He points out that the WHOs priority is investigating outbreaks, not academic research In the case of the father who is thought to have caught the virus from his son — a second-generation spread — there were twenty-one mutations across seven of the eight flu genes Instead, the agency released a statement on 23 May stating that there was “no evidence of genetic reassortment with human or pig influenza viruses and no evidence of significant mutations” Many of the genetic changes did not result in the use of different amino acids by the virus Nature has now obtained more detail on the genetic changes, which suggest that although the WHO statement was not incorrect, plenty more could have been said None of the sequence data from the Indonesian cluster has been deposited in public databases — access is restricted to a small network of researchers linked to the WHO and the US Centers for Disease Control and Prevention in Atlanta, Georgia One of the mutations confers resistance to the antiviral drug amantadine, a fact not mentioned in the WHO statement One of these, her 10-year-old nephew, who died on 13 May, is thought to have passed the disease to his 32-year-old father (see Flu cluster in Indonesia) One possibility is that the father simply caught a different strain of virus from birds, although other mutations in his virus are similar to those in the strain isolated from his son Or perhaps the virus from the son reassorted with another flu strain circulating in his father at the time, Ghedin says Part of the reason the picture is so unclear, say virologists contacted by Nature , is that the continued withholding of genetic data is hampering study of the virus She is part of a project started in 2004 to sequence thousands of human and bird-flu strains, but she has little access to H5N1 virus from humans. “Flu researchers dont all look at the data from the same angle,” she says. “The more diverse analyses that are performed, the better we will understand the evolution of this virus.”  “If all of the H5N1 isolates were available, thered be quite a few people focused on understanding these data,” agrees David Lipman, director of the US National Center for Biotechnology Information in Bethesda, Maryland The cluster of cases of the deadly H5N1 strain, which occurred earlier this year, is the first in which the World Health Organization (WHO) has admitted that human-to-human transmission was the most likely cause of spread (see Nature 441 , 554 – 555 ; 2006 ) The data were presented by Malik Pereis, a virologist at the University of Hong Kong, at a closed meeting of around a dozen international experts in animal and human health, held in Jakarta, Indonesia, in late June The first patient, a 37-year-old woman who became ill on 24 April and died on 4 May, is thought to have caught the disease from poultry, then transmitted it to six relatives The functional significance of the mutations isnt clear — most of them seem unimportant The virus did not evolve into a pandemic strain — the combination of mutations was not even enough to allow it to spread beyond close family The WHO has not formally asked Indonesia to share the sequences, Gully adds. “We would rather wait and see what Indonesia decides.” This suggests that the virus was evolving rapidly as it spread from person to person Virus isolates from six of the eight family members have been sequenced, but the WHO has not released the data, saying that they belong to Indonesia Viruses from five of the cases had between one and four mutations each compared with the sequence shared by most of the strains
 Birds are unique among living vertebrates in possessing pneumaticity of the postcranial skeleton, with invasion of bone by the pulmonary air-sac system  Caudally positioned abdominal and thoracic air sacs are critical components of the avian aspiration pump, facilitating flow-through ventilation of the lung and near-constant airflow during both inspiration and expiration, highlighting a design optimized for efficient gas exchange  Here we report, on the basis of a comparative analysis of region-specific pneumaticity with extant birds, evidence for cervical and abdominal air-sac systems in non-avian theropods, along with thoracic skeletal prerequisites of an avian-style aspiration pump However, the relationship between osseous pneumaticity and the evolution of the avian respiratory apparatus has long remained ambiguous Postcranial skeletal pneumaticity has also been reported in numerous extinct archosaurs including non-avian theropod dinosaurs and Archaeopteryx  Taken together, these specializations imply the existence of the basic avian pulmonary Bauplan in basal neotheropods, indicating that flow-through ventilation of the lung is not restricted to birds but is probably a general theropod characteristic. The avian respiratory system includes high-compliance air sacs that ventilate a dorsally fixed, non-expanding parabronchial lung  The early acquisition of this system among theropods is demonstrated by examination of an exceptional new specimen of Majungatholus atopus , documenting these features in a taxon only distantly related to birds A detailed taxonomic list of included taxa and pulmonary injection and cineradiographic protocols is given in the Supplementary Information . All cineradiographic experiments were conducted in accordance with state and institutional guidelines Methods Birds used in pulmonary studies were salvage specimens obtained from wildlife rehabilitators and museums A recently recovered spectacularly preserved specimen of the basal neotheropod Majungatholus atopus (UA 8678) reveals the presence of pneumatic vertebrae in cervical, thoracic (dorsal) and sacral regions of the vertebral column ( Figs 3 and 4 ) A reduction in both size and number of neural arch foramina in thoracic vertebrae 12 and 13, along with enhanced pneumaticity of sacral neural arches, indicates two different sources of pneumatization: one source for the thoracic region and one for the sacral region Although not serving ventilatory roles, nor pneumatizing the postcranial skeleton, air sacs or diverticular complexes develop on the caudal end of the lung in chameleons, varanids and snakes , indicating that the caudalmost region of the sauropsid lung might be relatively plastic Although our model does not predict the specific type of intrapulmonary air flow in non-avian theropods (unidirectional versus bidirectional), it does establish both pulmonary and skeletal prerequisites required for flow-through ventilation, a plausible early stage in the evolution of the highly derived avian pulmonary apparatus An evaluation of postcranial pneumaticity in non-avian theropods reveals consistent regional patterns similar to those of living birds An examination of 234 air-sac-injected birds reveals the following invariant patterns: first, cervical air-sac diverticula ( Fig. 1 ) pneumatize cervical vertebrae and ribs and the cranialmost thoracic (dorsal) vertebrae; second, abdominal air-sac diverticula invade caudal, synsacral and caudalmost thoracic vertebrae; and third, in most birds the lung itself pneumatizes adjacent thoracic vertebrae and ribs (see Supplementary Table 1 ) An initial cranial position for air sacs, as has been predicted previously for theropods , would result only in expansion/contraction of the cranial air sac, and would serve little role in ventilating a caudally positioned lung Ancillary evidence for this model comes from extant non-avian sauropsids that also possess similarly heterogeneous pulmonary systems As a result, the largest ventilatory volume changes are produced caudal to the exchanger (lung), establishing the necessary pressure gradient required for flow-through ventilation Cineradiographic (high-speed X-ray film) studies of skeletal and visceral kinematics during lung ventilation show greater expansion of the ventrocaudal trunk, with a larger ventral excursion of the caudal sternal margin relative to the cranial sternal margin (see Supplementary Table 2 and Supplementary Movie 1 ) Correlations between regional pneumaticity and specific air sacs in both birds and theropods have long remained ambiguous , particularly with regard to the extent of the vertebral column pneumatized by the cervical air-sac system Either implicitly or explicitly, these studies have linked anatomical, physiological or behavioural inferences with an increased metabolic potential, suggesting that if not bird-like in metabolism, theropods were at least ‘more similar’ to birds than to reptiles Flow-through ventilation of the lung provides numerous potential benefits, including increased tidal volume, decreased anatomical dead space, and airflow past gas-exchange tissues during both inspiration and expiration High-compliance pulmonary systems also use less energy for ventilation and require relatively small adjustments of the body wall  However, explicit statements about higher-level pulmonary organization and functional hypotheses for ventilating a pulmonary air-sac system in theropods have been speculative at best However, inferences related to pulmonary organization and ventilation are necessarily limited in non-theropod groups because they lack extant descendants that can be used as reference taxa However, results from this study indicate that regional patterns of axial pneumaticity can be unequivocally associated with specific components of the air-sac system, and include both cervical and abdominal diverticula in addition to the lung itself In no cases do cervical air-sac diverticula extend caudally along the column to pneumatize vertebrae beyond the middle thoracic series In the cranial ribcage, the vertical arrangement of the diapophysis and parapophysis, the two vertebral joints that articulate with the two heads of each rib, ensures a rigid and relatively incompressible skeletal framework around the pulmonary cavity It is only when higher-compliance air sacs are positioned caudal to the lung that air will be moved through it on ventilation Models proposed for the evolution of the avian pulmonary apparatus postulate a cranial to caudal developmental sequence for air sacs in the theropod lineage, with the caudal components critical for establishing flow-through ventilation predicted to occur only in derived coelurosaurs Moreover, the locations of pneumatic foramina within bones are virtually identical between theropod dinosaurs and extant birds ( Fig. 3 ) Moreover, the possibility that pulmonary air sacs also functioned in non-respiratory capacities (for example, density reduction) might be particularly important in these large-bodied and flying taxa, meriting further research Movements of the sternum, ribs and pectoral girdle change trunk volume to create pressure differences that drive ventilatory airflow  Notably, the cervical ribs have the relatively largest pneumatic foramina known among non-avian theropods  Other air sacs ( Fig. 1 ) either do not pneumatize the skeleton (for example the caudal thoracic sac) or variably invade the sternum, sternal ribs, shoulder girdle and forelimb elements (for example the cranial thoracic, clavicular sacs) Our study indicates that basal neotheropods possessed the anatomical potential for flow-through ventilation of the pulmonary system, emphasizing the early evolution of respiratory adaptations that are consistent with elevated metabolic rates in predatory dinosaurs. Pneumatic foramina in cervical vertebrae and ribs are consistent with pneumatization by cervical air-sac diverticula ( Fig. 4b , f ) Pneumatic postcranial bones are present in all clades of non-avian theropods ( Fig. 2 ) and are typically restricted to the axial skeleton (for example, the vertebrae and ribs) Pneumaticity of caudal thoracic and sacral vertebrae is restricted to neural arches and is consistent with pneumatization by abdominal air-sac diverticula ( Fig. 4e ) Pneumaticity of vertebral centra in the thoracic series is limited to the first four vertebrae ( Fig. 4c ), whereas neural arches are pneumatized throughout the entire region ( Fig. 4d ) Postcranial pneumatic features have also been identified in the extinct large-bodied sauropod dinosaurs and flying pterosaurs ; the ability to pneumatize the skeleton might therefore be an ornithodiran synapomorphy Recent studies of non-avian theropod dinosaurs have documented several features once thought solely to characterize living birds, including the presence of feather-like integumentary specializations , rapid, avian-like growth rates , and even bird-like behaviours captured in the fossil record  Recent studies of non-avian theropod dinosaurs, the extinct ancestors of living birds , have proposed a crocodylian-like pulmonary system with a hepatic-piston model of ventilation  Sacral pneumaticity in theropod dinosaurs, the basis for inferring caudally positioned air sacs, is consistent with a ‘caudal origin model’ and establishes the potential for flow-through ventilation in the dinosaurian ancestors of living birds Sacral pneumaticity is present in at least some members of abelisauroid, spinosauroid, allosauroid, ornithomimid, tyrannosauroid and maniraptoran clades, indicating a consistent and widespread pattern of pneumatic invasion by caudally located air sacs in non-avian theropods Skeletal adaptations consistent with an avian-like aspiration pump are already present in basal neotheropods, including a relatively rigid thoracic vertebral column with accessory hyposphene–hypantra articulations and a robust cranial thorax Skeletal and soft-tissue specializations in the cranial half of the avian trunk maintain a near-constant volume of the pulmonary cavity  The general pattern of pneumaticity in Majungatholus is expressed throughout Theropoda (see Supplementary Table 1 ), being evident in representatives of all major neotheropod clades ( Fig. 2 ) The greater capacity for lateral excursion of these ribs in theropods, along with movements of the gastralial apparatus, a system recently proposed to work as a ventrally positioned accessory aspiration pump , provides a mechanism for establishing greater volumetric changes in the caudal half of the theropod trunk, a key characteristic essential for establishing flow-through ventilation in birds  The orientation of the vertebrocostal articulations gradually changes to a horizontal position between thoracic vertebrae 4 and 9, thereby allowing larger lateral excursions of the more caudally positioned ribs The postcranial pneumaticity observed in non-avian theropods implies the potential for a degree of pulmonary air sac development similar to that observed only in living birds These studies counter long-held views that pneumatic vertebrae in theropods resulted from an avian-like pulmonary air-sac system ( Fig. 1 ) This is significant because it has been asserted that all pneumatization of the vertebral column in birds and non-avian theropods results from cervical air-sac diverticula, thereby ignoring the dominant role of abdominal air sacs and the lung for pneumatization of the postcranial axial skeleton This pattern of pneumaticity in thoracic centra is widespread in theropods, probably reflecting pneumatization by a firmly attached, dorsally positioned lung in the cranial half of the thorax Together these traits highlight a system with the potential for high gas exchange efficiency We predict that in any biophysical model for the evolution of flow-through ventilation, areas of increased lung compliance must initially be located caudal to the gas-exchange portion of the pulmonary apparatus
 A degree in maths was always what I was going to do, a masters followed, and the possibility of staying in academia is something Ive been considering since I left school A recurring theme is what maths actually is, with letters at times verging on philosophy And what saddened me was that Letters to a Young Mathematician did not leave me with a sense of wonder and beauty, or even pride, in mathematics, as other books have As a young female mathematician, I found the book somewhat disappointing As Meg progresses, the letters move on to what professional mathematicians do and how they do it But at any one time, the book has too little to offer, and the rest of it is either below you or not written in a general enough way to interest you But I could do with more information on the more personal aspects of how one goes about doing maths, and the possibilities for being a professional mathematician, even as I approach the end of my masters But the books major problem is the timescale But there is a general lack of information — Stewart tends to waffle slightly Each letter covers a different topic, answering concerns that Stewart feels young mathematicians may have For instance, the letter about the career ladder is written in the context of finding a good PhD supervisor For that I would recommend Paul Hoffmans The Man Who Loved Only Numbers (Fourth Estate, 1998), Robert Kanigels The Man Who Knew Infinity (Scribner, 1991) and most of Stewarts other books, especially The Magical Maze (Weidenfeld Nicolson, 1997). He starts on familiar ground with the differences between school and university mathematics, and moves on to what to expect from a maths degree I was lucky: Ive always found the concepts behind maths easy to understand, and in some way natural I wouldnt have understood any of these terms as a 17-year-old In Letters to a Young Mathematician , Stewart writes to a fictional girl, Meg, following her career in mathematics from high school to a tenured position It offers good advice in some areas, such as how to work at maths at university level Mathematics seems to be something that you either get or you dont Meg ages 15 or 20 years; the reader a few hours Nowhere does he describe the actual professional ladder and where you can expect a career in mathematics to take you — information that would be welcome to a student deciding on a degree subject, and to an undergraduate deciding between an academic career and moving out The advice seems to get better the further Meg gets The book also suffers from being written entirely for a US audience, from the spelling to the description of how your career progresses The first few chapters are good for school pupils and as an introduction to ‘higher level’ mathematics The letter in which Stewart tells Meg how to teach undergraduates should be compulsory reading for all lecturers and tutors The next few can be read when youre getting to the end of your degree, and then again when you gain your PhD There are already a number of ‘popular’ maths books (many by Ian Stewart), which gave me a good idea of what the transition from school to university maths would be like There is also too much jargon: Meg gets a postdoc position, then an assistant professorship, and ends up with tenure There is an amusing chapter on learning from others mistakes, and his description of the community of mathematicians is true and appealing These are mainly discussions on proof — what it is, why we feel the need to do it, and how Stewart likes to think of it This is a real shame, as the differences are at times enough to make the book all but useless to students outside the United States
 As fields mature and the methodologies used to generate the data become well known and established, it is both appropriate and valuable to have standardized, easy-to-use software But standardized approaches are not always appropriate for developing software to support new research using novel methodologies in exciting new ways But that is not a bad thing — as science charts a particular path, the appropriate tools, if given room to evolve, do emerge and rise to the top, becoming better documented and more robust But the community has many excellent quantitative scientists and software developers — and with the advent of genomics, an increasing number of physicists, mathematicians, statisticians, computer scientists and engineers have joined the ranks of biologists But we have concerns about the proposed solution, which is presented as a ‘top-down’ approach that ignores many existing and emerging standards Cassman and his colleagues argue that standards are needed because much software developed in research settings is not reusable by other groups of working biologists, who are not appropriately trained Creating a rigid standard before a field has matured can result in a failed and unused standard, in the best of circumstances, and, in the worst, can have the effect of stifling innovation. Engineering this ahead of time, particularly when the field and the tools were evolving so rapidly, quite simply would have failed Even with the relatively straightforward task of assembling and annotating genome-sequencing data, computationally elegant solutions to software interoperability (such as the common object request broker architecture, or CORBA) were ultimately abandoned in favour of FASTA-formatted sequence data and tab-delimited output from various analytical tools strung together using Perl It is not a lack of training that influences software design, but the realities of developing software in a research environment where developing a professional software system is not the primary goal It seems based on false assumptions about the research community and ignores the community it is intended to serve It wasnt elegant or pretty, but it delivered what was needed in a way that sophisticated users at various locations could replicate and adapt to suit their needs Our collective experience, gained through the Microarray Gene Expression Data Society and the BioConductor project, clearly demonstrates that flexible systems are needed and that most initial efforts are neither well documented nor widely used Sir Marvin Cassman and his colleagues, in their Commentary “Barriers to progress in systems biology” ( Nature 438 , 1079 ; 2005 ), discuss the development of standards in systems-biology research We agree with the need for well-curated databases, software systems that can work together to analyse such data and integrated models that can deliver the fruits of systems-based research to laboratory biologists We believe that the centralized approach proposed by Cassman and colleagues would not fare well compared with more democratic, community-based approaches that understand and include research-driven development efforts When combined with well-engineered databases and websites to provide access, the genome projects also delivered the fruits of their work to the broader community in a form that has been extremely useful and continues to evolve
 According to the artist: “These natural creations still carry meaning: how we, as a species, reveal our needs, activities, and fears through nature... a carnival for the curious.” As the Naturalis organizers suggest, “McMillens creativity is closer to the way our brains work than we might want to admit.”  In Shank , Ed Moses displays a large set of stuffed specimens presented on shelves as they would be stored in the museums vaults, but surrounded by chicken wire All of this together signals a living future.”  According to Dirk Houtgraaf, the exhibitions curator, attendance of Conversations has been significantly lower than other areas of Naturalis And his amalgamation of an elephant skeleton with a crocodile head surrounded by toy ladders in Crocodelephant also provokes the eye And one can readily recognize Outterbridges description: “Nature in the city, the city in nature.. Burial , he explains, “raises a number of questions for natural history museums But I agree with Vanda Vitali, who originated the exhibition in Los Angeles, that such an experiment is destined to be a minority interest But I found myself wishing that Moses had absorbed his reflections into the subtleties and ambiguities of his art, instead of reducing them to a rather trivial visual concept But the closer visual artists get to artfulness — to sheer visual creativity — in their response to exhibits, the more likely they are to resonate with the visitors. But the question remains whether it proves its point — that artists responses and provocations are worth the effort to a museum audience Children demonstrably enjoy it for this reason Conceits and provocations As you walk through the grounds of Leidens Naturalis — the national natural-history museum of the Netherlands — you pass compact seventeenth-century buildings, neat plant borders and lawns In so doing, he seeks to question the very act of collecting In The Flying Dutchman , he places porpoise skeletons in a shoal flying above the visitors head, with schooner sails attached as a reference to Dutch sea-going It has an aesthetic, intriguing appeal It is a microcosm of our environment, a fertile garden from which we can harvest ideas and reflect on our history and present existence.. McCarthy intends his piece, Burial , to reverse the normal process of palaeontologists digging up natural specimens More telling is the behaviour of those visitors who choose to attend Much more successful for me was John Outterbridge, whose Sankofa is a pastel garden of stuffed specimens, bones, plants, crops and artefacts Only if you happen to visit the exhibition Conversations: Nature and the City, which can be seen at Naturalis until the end of December, will you be told about it and see a video of the event Or that he himself buried it Other visual exhibits are conceptually more substantive The exhibition is an experiment inspired by a similar exercise at the Natural History Museum of Los Angeles County The exhibition is the result of an invitation to four visual artists and a composer to respond to the content of Naturalis The piece makes a visual impact and it is good that artists seek to provoke debate among visitors to museum displays This they have done, with installations intended to extend and provoke the visitors responses to what the museum is collecting and displaying Those of Michael McMillen combine a sense of visual play that adds to the cultural value of the specimens To judge by the attention showed by the visitors I witnessed, the exhibition provides another dimension to the collections appeal What conclusion can be drawn about artists in a museum context? I would suggest that, on this evidence, cumbersome attempts by artists to pose philosophical questions in a visual form tend to smack of conceit, rather than stimulate While specimens and objects are still buried, do they really exist? Before theyre dug up, do they have any value?” To my no-doubt blinkered eye, at least, that question of invisible value is the sort of pseudo-profundity that gives such exercises a bad name You have no idea that under the grass is buried a sculpture by the Los Angeles-based artist Paul McCarthy, valued at around US$250,000
 Arguments made by other Japanese scientists that the tests should have been carried out by a larger team are convincing At a press conference, Japans chief cabinet secretary, Hiroyuki Hosoda, reportedly alleged that Nature s article contained “inadequate expressions” and that it misrepresented the scientists statements At issue is whether Megumi Yokota, a Japanese woman kidnapped by North Korea in 1977 at the age of 13, is still alive But its interpretation of the DNA tests has crossed the boundary of sciences freedom from political interference But Japans tests show that the DNA is someone elses — raising the spectre that the North Korean military is still using her to train spies But the DNA tests that Japan is counting on wont resolve the issue But the friction between North Korea and Japan will not be decided by a DNA test Claims that most of the victims, including Yokota, have died are unconvincing Could Japan, with US backing, have pulled other levers with North Korea? The answer is not clear, but the question can be put another way Dealing with North Korea is no fun, but it doesnt justify breaking the rules of separation between science and politics. If a totalitarian country had abducted US citizens from a beach and carried them back to teach language to potential spies for 25 years, would George Bush or any other US president be standing there with a bag of ashes haggling over DNA test results? Part of the burden for Japans political and diplomatic failure is being shifted to a scientist for doing his job — deriving conclusions from experiments and presenting reasonable doubts about them In 2002, North Korea admitted to abducting 13 Japanese nationals, several of them taken from beaches while on dates It is also entirely possible that North Korea is lying Japan is right to doubt North Koreas every statement Likewise, the interpretation of DNA test results cannot be decided by the government of either country Nature s interview with the scientist who carried out the tests raised the possibility that the remains were merely contaminated, making the DNA tests inconclusive North Korea says the remains that it passed to Japan last year are hers Science runs on the premise that experiments, and all the uncertainty involved in them, should be open for scrutiny Since then, North Koreas half-hearted efforts to account for the victims have caused turmoil in the relationship between the two countries (see Nature 433 , 445; 2005 ) The alliance gives the United States rights to place unpopular bases in Japan in exchange for its role in contributing “to the security of Japan and the maintenance of international peace and security in the Far East” The cabinet of Japans prime minister, Junichiro Koizumi, is “burying its head in its hands” in frustration, in the words of one popular Japanese weekly, over a news article that appeared in Nature last month The government has responded sharply to the article The inescapable fact is that the bones may have been contaminated The opinions expressed in the article were “general knowledge” but were not meant to apply to the case at hand, Hosoda said, adding that his statements were checked with the scientist The problem is not in the science but in the fact that the government is meddling in scientific matters at all The scientist himself, meanwhile, is apparently no longer available for interviews This suggestion is uncomfortable for a Japanese government that wants to have North Korea seen as unambiguously fraudulent Who knows what they have been through during this hellish episode? According to North Korea, the body was buried for two years before being dug up and cremated at 1,200 °C, and then kept at the womans husbands home, before a small sample was passed to Japan Why did Japan entrust them to one scientist working alone — one who no longer seems to be free to talk about them? Japans policy seems a desperate effort to make up for what has been a diplomatic failure — or more precisely, a failure of the security alliance between Japan and the United States
